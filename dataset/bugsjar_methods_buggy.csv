ProjectName,BranchName,Severity,ClassName,StartLine,EndLine,SourceCode
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1044_9396979b,Critical,server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java,75,228,"public List<Short> check(Environment env, Mutation mutation) {
    ArrayList<Short> violations = null;
    Collection<ColumnUpdate> colUpdates = mutation.getUpdates();
    // check the row, it should contains at least one ; or end with <
    boolean containsSemiC = false;
    byte[] row = mutation.getRow();
    // always allow rows that fall within reserved area
    if (row.length > 0 && row[0] == '~')
        return null;
    for (byte b : row) {
        if (b == ';') {
            containsSemiC = true;
        }
        if (b == ';' || b == '<')
            break;
        if (!validTableNameChars[0xff & b]) {
            if (violations == null)
                violations = new ArrayList<Short>();
            if (!violations.contains((short) 4))
                violations.add((short) 4);
        }
    }
    if (!containsSemiC) {
        // see if last row char is <
        if (row.length == 0 || row[row.length - 1] != '<') {
            if (violations == null)
                violations = new ArrayList<Short>();
            if (!violations.contains((short) 4))
                violations.add((short) 4);
        }
    } else {
        if (row.length == 0) {
            if (violations == null)
                violations = new ArrayList<Short>();
            if (!violations.contains((short) 4))
                violations.add((short) 4);
        }
    }
    if (row.length > 0 && row[0] == '!') {
        if (row.length < 3 || row[1] != '0' || (row[2] != '<' && row[2] != ';')) {
            if (violations == null)
                violations = new ArrayList<Short>();
            if (!violations.contains((short) 4))
                violations.add((short) 4);
        }
    }
    // ensure row is not less than Constants.METADATA_TABLE_ID
    if (new Text(row).compareTo(new Text(Constants.METADATA_TABLE_ID)) < 0) {
        if (violations == null)
            violations = new ArrayList<Short>();
        violations.add((short) 5);
    }
    for (ColumnUpdate columnUpdate : colUpdates) {
        Text columnFamily = new Text(columnUpdate.getColumnFamily());
        if (columnUpdate.isDeleted()) {
            if (!isValidColumn(columnUpdate)) {
                if (violations == null)
                    violations = new ArrayList<Short>();
                violations.add((short) 2);
            }
            continue;
        }
        if (columnUpdate.getValue().length == 0 && !columnFamily.equals(Constants.METADATA_SCANFILE_COLUMN_FAMILY)) {
            if (violations == null)
                violations = new ArrayList<Short>();
            violations.add((short) 6);
        }
        if (columnFamily.equals(Constants.METADATA_DATAFILE_COLUMN_FAMILY)) {
            try {
                DataFileValue dfv = new DataFileValue(columnUpdate.getValue());
                if (dfv.getSize() < 0 || dfv.getNumEntries() < 0) {
                    if (violations == null)
                        violations = new ArrayList<Short>();
                    violations.add((short) 1);
                }
            } catch (NumberFormatException nfe) {
                if (violations == null)
                    violations = new ArrayList<Short>();
                violations.add((short) 1);
            } catch (ArrayIndexOutOfBoundsException aiooe) {
                if (violations == null)
                    violations = new ArrayList<Short>();
                violations.add((short) 1);
            }
        } else if (columnFamily.equals(Constants.METADATA_SCANFILE_COLUMN_FAMILY)) {
        } else {
            if (!isValidColumn(columnUpdate)) {
                if (violations == null)
                    violations = new ArrayList<Short>();
                violations.add((short) 2);
            } else if (new ColumnFQ(columnUpdate).equals(Constants.METADATA_PREV_ROW_COLUMN) && columnUpdate.getValue().length > 0 && (violations == null || !violations.contains((short) 4))) {
                KeyExtent ke = new KeyExtent(new Text(mutation.getRow()), (Text) null);
                Text per = KeyExtent.decodePrevEndRow(new Value(columnUpdate.getValue()));
                boolean prevEndRowLessThanEndRow = per == null || ke.getEndRow() == null || per.compareTo(ke.getEndRow()) < 0;
                if (!prevEndRowLessThanEndRow) {
                    if (violations == null)
                        violations = new ArrayList<Short>();
                    violations.add((short) 3);
                }
            } else if (new ColumnFQ(columnUpdate).equals(Constants.METADATA_LOCK_COLUMN)) {
                if (zooCache == null) {
                    zooCache = new ZooCache();
                }
                if (zooRoot == null) {
                    zooRoot = ZooUtil.getRoot(HdfsZooInstance.getInstance());
                }
                boolean lockHeld = false;
                String lockId = new String(columnUpdate.getValue());
                try {
                    lockHeld = ZooLock.isLockHeld(zooCache, new ZooUtil.LockID(zooRoot, lockId));
                } catch (Exception e) {
                    log.debug(""Failed to verify lock was held "" + lockId + "" "" + e.getMessage());
                }
                if (!lockHeld) {
                    if (violations == null)
                        violations = new ArrayList<Short>();
                    violations.add((short) 7);
                }
            }
        }
    }
    if (violations != null) {
        log.debug("" violating metadata mutation : "" + mutation);
    }
    return violations;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1044_9396979b,Critical,server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java,230,248,"public String getViolationDescription(short violationCode) {
    switch(violationCode) {
        case 1:
            return ""data file size must be a non-negative integer"";
        case 2:
            return ""Invalid column name given."";
        case 3:
            return ""Prev end row is greater than or equal to end row."";
        case 4:
            return ""Invalid metadata row format"";
        case 5:
            return ""Row can not be less than "" + Constants.METADATA_TABLE_ID;
        case 6:
            return ""Empty values are not allowed for any "" + Constants.METADATA_TABLE_NAME + "" column"";
        case 7:
            return ""Lock not held in zookeeper by writer"";
    }
    return null;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1044_ea2f9856,Critical,server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java,75,228,"public List<Short> check(Environment env, Mutation mutation) {
    ArrayList<Short> violations = null;
    Collection<ColumnUpdate> colUpdates = mutation.getUpdates();
    // check the row, it should contains at least one ; or end with <
    boolean containsSemiC = false;
    byte[] row = mutation.getRow();
    // always allow rows that fall within reserved area
    if (row.length > 0 && row[0] == '~')
        return null;
    for (byte b : row) {
        if (b == ';') {
            containsSemiC = true;
        }
        if (b == ';' || b == '<')
            break;
        if (!validTableNameChars[0xff & b]) {
            if (violations == null)
                violations = new ArrayList<Short>();
            if (!violations.contains((short) 4))
                violations.add((short) 4);
        }
    }
    if (!containsSemiC) {
        // see if last row char is <
        if (row.length == 0 || row[row.length - 1] != '<') {
            if (violations == null)
                violations = new ArrayList<Short>();
            if (!violations.contains((short) 4))
                violations.add((short) 4);
        }
    } else {
        if (row.length == 0) {
            if (violations == null)
                violations = new ArrayList<Short>();
            if (!violations.contains((short) 4))
                violations.add((short) 4);
        }
    }
    if (row.length > 0 && row[0] == '!') {
        if (row.length < 3 || row[1] != '0' || (row[2] != '<' && row[2] != ';')) {
            if (violations == null)
                violations = new ArrayList<Short>();
            if (!violations.contains((short) 4))
                violations.add((short) 4);
        }
    }
    // ensure row is not less than Constants.METADATA_TABLE_ID
    if (new Text(row).compareTo(new Text(Constants.METADATA_TABLE_ID)) < 0) {
        if (violations == null)
            violations = new ArrayList<Short>();
        violations.add((short) 5);
    }
    for (ColumnUpdate columnUpdate : colUpdates) {
        Text columnFamily = new Text(columnUpdate.getColumnFamily());
        if (columnUpdate.isDeleted()) {
            if (!isValidColumn(columnUpdate)) {
                if (violations == null)
                    violations = new ArrayList<Short>();
                violations.add((short) 2);
            }
            continue;
        }
        if (columnUpdate.getValue().length == 0 && !columnFamily.equals(Constants.METADATA_SCANFILE_COLUMN_FAMILY)) {
            if (violations == null)
                violations = new ArrayList<Short>();
            violations.add((short) 6);
        }
        if (columnFamily.equals(Constants.METADATA_DATAFILE_COLUMN_FAMILY)) {
            try {
                DataFileValue dfv = new DataFileValue(columnUpdate.getValue());
                if (dfv.getSize() < 0 || dfv.getNumEntries() < 0) {
                    if (violations == null)
                        violations = new ArrayList<Short>();
                    violations.add((short) 1);
                }
            } catch (NumberFormatException nfe) {
                if (violations == null)
                    violations = new ArrayList<Short>();
                violations.add((short) 1);
            } catch (ArrayIndexOutOfBoundsException aiooe) {
                if (violations == null)
                    violations = new ArrayList<Short>();
                violations.add((short) 1);
            }
        } else if (columnFamily.equals(Constants.METADATA_SCANFILE_COLUMN_FAMILY)) {
        } else {
            if (!isValidColumn(columnUpdate)) {
                if (violations == null)
                    violations = new ArrayList<Short>();
                violations.add((short) 2);
            } else if (new ColumnFQ(columnUpdate).equals(Constants.METADATA_PREV_ROW_COLUMN) && columnUpdate.getValue().length > 0 && (violations == null || !violations.contains((short) 4))) {
                KeyExtent ke = new KeyExtent(new Text(mutation.getRow()), (Text) null);
                Text per = KeyExtent.decodePrevEndRow(new Value(columnUpdate.getValue()));
                boolean prevEndRowLessThanEndRow = per == null || ke.getEndRow() == null || per.compareTo(ke.getEndRow()) < 0;
                if (!prevEndRowLessThanEndRow) {
                    if (violations == null)
                        violations = new ArrayList<Short>();
                    violations.add((short) 3);
                }
            } else if (new ColumnFQ(columnUpdate).equals(Constants.METADATA_LOCK_COLUMN)) {
                if (zooCache == null) {
                    zooCache = new ZooCache();
                }
                if (zooRoot == null) {
                    zooRoot = ZooUtil.getRoot(HdfsZooInstance.getInstance());
                }
                boolean lockHeld = false;
                String lockId = new String(columnUpdate.getValue());
                try {
                    lockHeld = ZooLock.isLockHeld(zooCache, new ZooUtil.LockID(zooRoot, lockId));
                } catch (Exception e) {
                    log.debug(""Failed to verify lock was held "" + lockId + "" "" + e.getMessage());
                }
                if (!lockHeld) {
                    if (violations == null)
                        violations = new ArrayList<Short>();
                    violations.add((short) 7);
                }
            }
        }
    }
    if (violations != null) {
        log.debug("" violating metadata mutation : "" + mutation);
    }
    return violations;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1044_ea2f9856,Critical,server/src/main/java/org/apache/accumulo/server/constraints/MetadataConstraints.java,230,248,"public String getViolationDescription(short violationCode) {
    switch(violationCode) {
        case 1:
            return ""data file size must be a non-negative integer"";
        case 2:
            return ""Invalid column name given."";
        case 3:
            return ""Prev end row is greater than or equal to end row."";
        case 4:
            return ""Invalid metadata row format"";
        case 5:
            return ""Row can not be less than "" + Constants.METADATA_TABLE_ID;
        case 6:
            return ""Empty values are not allowed for any "" + Constants.METADATA_TABLE_NAME + "" column"";
        case 7:
            return ""Lock not held in zookeeper by writer"";
    }
    return null;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1051_25cf3ccd,Trivial,core/src/main/java/org/apache/accumulo/core/security/Authorizations.java,180,191,"@Override
public String toString() {
    StringBuilder sb = new StringBuilder();
    String sep = """";
    for (ByteSequence auth : auths) {
        sb.append(sep);
        sep = "","";
        sb.append(new String(auth.toArray()));
    }
    return sb.toString();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1051_25cf3ccd,Trivial,core/src/main/java/org/apache/accumulo/core/security/Authorizations.java,201,214,"@Override
public boolean equals(Object o) {
    if (o == null) {
        return false;
    }
    if (o instanceof Authorizations) {
        Authorizations ao = (Authorizations) o;
        return auths.equals(ao.auths);
    }
    return false;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1051_25cf3ccd,Trivial,core/src/main/java/org/apache/accumulo/core/security/Authorizations.java,216,222,"@Override
public int hashCode() {
    int result = 0;
    for (ByteSequence b : auths) result += b.hashCode();
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1120_474b2577,Blocker,core/src/main/java/org/apache/accumulo/core/cli/ClientOpts.java,112,120,"public SecurityToken getToken() {
    PasswordToken pt = new PasswordToken();
    if (securePassword == null) {
        if (password.value == null)
            return null;
        return pt.setPassword(password.value);
    }
    return pt.setPassword(securePassword.value);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1183_742960f1,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,785,833,"@Override
public String createBatchScanner(ByteBuffer login, String tableName, BatchScanOptions opts) throws TException {
    try {
        Connector connector = getConnector(login);
        int threads = 10;
        Authorizations auth;
        if (opts != null && opts.isSetAuthorizations()) {
            auth = getAuthorizations(opts.authorizations);
        } else {
            auth = connector.securityOperations().getUserAuthorizations(connector.whoami());
        }
        if (opts != null && opts.threads > 0)
            threads = opts.threads;
        BatchScanner scanner = connector.createBatchScanner(tableName, auth, threads);
        if (opts != null) {
            if (opts.iterators != null) {
                for (org.apache.accumulo.proxy.thrift.IteratorSetting iter : opts.iterators) {
                    IteratorSetting is = new IteratorSetting(iter.getPriority(), iter.getName(), iter.getIteratorClass(), iter.getProperties());
                    scanner.addScanIterator(is);
                }
            }
            ArrayList<Range> ranges = new ArrayList<Range>();
            if (opts.ranges == null) {
                ranges.add(new Range());
            } else {
                for (org.apache.accumulo.proxy.thrift.Range range : opts.ranges) {
                    Range aRange = new Range(range.getStart() == null ? null : Util.fromThrift(range.getStart()), true, range.getStop() == null ? null : Util.fromThrift(range.getStop()), false);
                    ranges.add(aRange);
                }
            }
            scanner.setRanges(ranges);
        }
        UUID uuid = UUID.randomUUID();
        ScannerPlusIterator spi = new ScannerPlusIterator();
        spi.scanner = scanner;
        spi.iterator = scanner.iterator();
        scannerCache.put(uuid, spi);
        return uuid.toString();
    } catch (Exception e) {
        throw translateException(e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1183_cfbf5999,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,785,833,"@Override
public String createBatchScanner(ByteBuffer login, String tableName, BatchScanOptions opts) throws TException {
    try {
        Connector connector = getConnector(login);
        int threads = 10;
        Authorizations auth;
        if (opts != null && opts.isSetAuthorizations()) {
            auth = getAuthorizations(opts.authorizations);
        } else {
            auth = connector.securityOperations().getUserAuthorizations(connector.whoami());
        }
        if (opts != null && opts.threads > 0)
            threads = opts.threads;
        BatchScanner scanner = connector.createBatchScanner(tableName, auth, threads);
        if (opts != null) {
            if (opts.iterators != null) {
                for (org.apache.accumulo.proxy.thrift.IteratorSetting iter : opts.iterators) {
                    IteratorSetting is = new IteratorSetting(iter.getPriority(), iter.getName(), iter.getIteratorClass(), iter.getProperties());
                    scanner.addScanIterator(is);
                }
            }
            ArrayList<Range> ranges = new ArrayList<Range>();
            if (opts.ranges == null) {
                ranges.add(new Range());
            } else {
                for (org.apache.accumulo.proxy.thrift.Range range : opts.ranges) {
                    Range aRange = new Range(range.getStart() == null ? null : Util.fromThrift(range.getStart()), true, range.getStop() == null ? null : Util.fromThrift(range.getStop()), false);
                    ranges.add(aRange);
                }
            }
            scanner.setRanges(ranges);
        }
        UUID uuid = UUID.randomUUID();
        ScannerPlusIterator spi = new ScannerPlusIterator();
        spi.scanner = scanner;
        spi.iterator = scanner.iterator();
        scannerCache.put(uuid, spi);
        return uuid.toString();
    } catch (Exception e) {
        throw translateException(e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,108,115,"@Override
public void onRemoval(RemovalNotification<UUID, BatchWriter> notification) {
    try {
        notification.getValue().close();
    } catch (MutationsRejectedException e) {
        logger.warn(e, e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,904,914,"@Override
public void updateAndFlush(ByteBuffer login, String tableName, Map<ByteBuffer, List<ColumnUpdate>> cells) throws TException {
    try {
        BatchWriter writer = getWriter(login, tableName, null);
        addCellsToWriter(cells, writer);
        writer.flush();
        writer.close();
    } catch (Exception e) {
        throw translateException(e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,918,952,"private void addCellsToWriter(Map<ByteBuffer, List<ColumnUpdate>> cells, BatchWriter writer) throws MutationsRejectedException {
    HashMap<Text, ColumnVisibility> vizMap = new HashMap<Text, ColumnVisibility>();
    for (Entry<ByteBuffer, List<ColumnUpdate>> entry : cells.entrySet()) {
        Mutation m = new Mutation(ByteBufferUtil.toBytes(entry.getKey()));
        for (ColumnUpdate update : entry.getValue()) {
            ColumnVisibility viz = EMPTY_VIS;
            if (update.isSetColVisibility()) {
                Text vizText = new Text(update.getColVisibility());
                viz = vizMap.get(vizText);
                if (viz == null) {
                    vizMap.put(vizText, viz = new ColumnVisibility(vizText));
                }
            }
            byte[] value = new byte[0];
            if (update.isSetValue())
                value = update.getValue();
            if (update.isSetTimestamp()) {
                if (update.isSetDeleteCell()) {
                    m.putDelete(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp());
                } else {
                    if (update.isSetDeleteCell()) {
                        m.putDelete(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp());
                    } else {
                        m.put(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp(), value);
                    }
                }
            } else {
                m.put(update.getColFamily(), update.getColQualifier(), viz, value);
            }
        }
        writer.addMutation(m);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,954,964,"@Override
public String createWriter(ByteBuffer login, String tableName, WriterOptions opts) throws TException {
    try {
        BatchWriter writer = getWriter(login, tableName, opts);
        UUID uuid = UUID.randomUUID();
        writerCache.put(uuid, writer);
        return uuid.toString();
    } catch (Exception e) {
        throw translateException(e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,966,977,"@Override
public void update(String writer, Map<ByteBuffer, List<ColumnUpdate>> cells) throws TException {
    try {
        BatchWriter batchwriter = writerCache.getIfPresent(UUID.fromString(writer));
        if (batchwriter == null) {
            throw new UnknownWriter(""Writer never existed or no longer exists"");
        }
        addCellsToWriter(cells, batchwriter);
    } catch (Exception e) {
        throw translateException(e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,979,990,"@Override
public void flush(String writer) throws TException {
    try {
        BatchWriter batchwriter = writerCache.getIfPresent(UUID.fromString(writer));
        if (batchwriter == null) {
            throw new UnknownWriter(""Writer never existed or no longer exists"");
        }
        batchwriter.flush();
    } catch (Exception e) {
        throw translateException(e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,992,1004,"@Override
public void closeWriter(String writer) throws TException {
    try {
        BatchWriter batchwriter = writerCache.getIfPresent(UUID.fromString(writer));
        if (batchwriter == null) {
            throw new UnknownWriter(""Writer never existed or no longer exists"");
        }
        batchwriter.close();
        writerCache.invalidate(UUID.fromString(writer));
    } catch (Exception e) {
        throw translateException(e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,1006,1019,"private BatchWriter getWriter(ByteBuffer login, String tableName, WriterOptions opts) throws Exception {
    BatchWriterConfig cfg = new BatchWriterConfig();
    if (opts != null) {
        if (opts.maxMemory != 0)
            cfg.setMaxMemory(opts.maxMemory);
        if (opts.threads != 0)
            cfg.setMaxWriteThreads(opts.threads);
        if (opts.timeoutMs != 0)
            cfg.setTimeout(opts.timeoutMs, TimeUnit.MILLISECONDS);
        if (opts.latencyMs != 0)
            cfg.setMaxLatency(opts.latencyMs, TimeUnit.MILLISECONDS);
    }
    return getConnector(login).createBatchWriter(tableName, cfg);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,185,185,"public void update(String writer, Map<ByteBuffer, List<ColumnUpdate>> cells) throws UnknownWriter, MutationsRejectedException, org.apache.thrift.TException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,2361,2365,"public void update(String writer, Map<ByteBuffer, List<ColumnUpdate>> cells) throws UnknownWriter, MutationsRejectedException, org.apache.thrift.TException {
    send_update(writer, cells);
    recv_update();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,2375,2386,"public void recv_update() throws UnknownWriter, MutationsRejectedException, org.apache.thrift.TException {
    update_result result = new update_result();
    receiveBase(result, ""update"");
    if (result.ouch1 != null) {
        throw result.ouch1;
    }
    if (result.ouch2 != null) {
        throw result.ouch2;
    }
    return;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,5011,5018,"public void getResult() throws UnknownWriter, MutationsRejectedException, org.apache.thrift.TException {
    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
        throw new IllegalStateException(""Method call not finished!"");
    }
    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
    (new Client(prot)).recv_update();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,7013,7023,"public update_result getResult(I iface, update_args args) throws org.apache.thrift.TException {
    update_result result = new update_result();
    try {
        iface.update(args.writer, args.cells);
    } catch (UnknownWriter ouch1) {
        result.ouch1 = ouch1;
    } catch (MutationsRejectedException ouch2) {
        result.ouch2 = ouch2;
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,81745,81747,"public update_result deepCopy() {
    return new update_result(this);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,81759,81762,"public update_result setOuch1(UnknownWriter ouch1) {
    this.ouch1 = ouch1;
    return this;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,81783,81786,"public update_result setOuch2(MutationsRejectedException ouch2) {
    this.ouch2 = ouch2;
    return this;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,81851,81858,"@Override
public boolean equals(Object that) {
    if (that == null)
        return false;
    if (that instanceof update_result)
        return this.equals((update_result) that);
    return false;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,81860,81883,"public boolean equals(update_result that) {
    if (that == null)
        return false;
    boolean this_present_ouch1 = true && this.isSetOuch1();
    boolean that_present_ouch1 = true && that.isSetOuch1();
    if (this_present_ouch1 || that_present_ouch1) {
        if (!(this_present_ouch1 && that_present_ouch1))
            return false;
        if (!this.ouch1.equals(that.ouch1))
            return false;
    }
    boolean this_present_ouch2 = true && this.isSetOuch2();
    boolean that_present_ouch2 = true && that.isSetOuch2();
    if (this_present_ouch2 || that_present_ouch2) {
        if (!(this_present_ouch2 && that_present_ouch2))
            return false;
        if (!this.ouch2.equals(that.ouch2))
            return false;
    }
    return true;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,81890,81919,"public int compareTo(update_result other) {
    if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
    }
    int lastComparison = 0;
    update_result typedOther = (update_result) other;
    lastComparison = Boolean.valueOf(isSetOuch1()).compareTo(typedOther.isSetOuch1());
    if (lastComparison != 0) {
        return lastComparison;
    }
    if (isSetOuch1()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.ouch1, typedOther.ouch1);
        if (lastComparison != 0) {
            return lastComparison;
        }
    }
    lastComparison = Boolean.valueOf(isSetOuch2()).compareTo(typedOther.isSetOuch2());
    if (lastComparison != 0) {
        return lastComparison;
    }
    if (isSetOuch2()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.ouch2, typedOther.ouch2);
        if (lastComparison != 0) {
            return lastComparison;
        }
    }
    return 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,81933,81955,"@Override
public String toString() {
    StringBuilder sb = new StringBuilder(""update_result("");
    boolean first = true;
    sb.append(""ouch1:"");
    if (this.ouch1 == null) {
        sb.append(""null"");
    } else {
        sb.append(this.ouch1);
    }
    first = false;
    if (!first)
        sb.append("", "");
    sb.append(""ouch2:"");
    if (this.ouch2 == null) {
        sb.append(""null"");
    } else {
        sb.append(this.ouch2);
    }
    first = false;
    sb.append("")"");
    return sb.toString();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,81979,81981,"public update_resultStandardScheme getScheme() {
    return new update_resultStandardScheme();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,81986,82023,"public void read(org.apache.thrift.protocol.TProtocol iprot, update_result struct) throws org.apache.thrift.TException {
    org.apache.thrift.protocol.TField schemeField;
    iprot.readStructBegin();
    while (true) {
        schemeField = iprot.readFieldBegin();
        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {
            break;
        }
        switch(schemeField.id) {
            case // OUCH1
            1:
                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                    struct.ouch1 = new UnknownWriter();
                    struct.ouch1.read(iprot);
                    struct.setOuch1IsSet(true);
                } else {
                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
                }
                break;
            case // OUCH2
            2:
                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                    struct.ouch2 = new MutationsRejectedException();
                    struct.ouch2.read(iprot);
                    struct.setOuch2IsSet(true);
                } else {
                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
                }
                break;
            default:
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
        }
        iprot.readFieldEnd();
    }
    iprot.readStructEnd();
    // check for required fields of primitive type, which can't be checked in the validate method
    struct.validate();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,82025,82041,"public void write(org.apache.thrift.protocol.TProtocol oprot, update_result struct) throws org.apache.thrift.TException {
    struct.validate();
    oprot.writeStructBegin(STRUCT_DESC);
    if (struct.ouch1 != null) {
        oprot.writeFieldBegin(OUCH1_FIELD_DESC);
        struct.ouch1.write(oprot);
        oprot.writeFieldEnd();
    }
    if (struct.ouch2 != null) {
        oprot.writeFieldBegin(OUCH2_FIELD_DESC);
        struct.ouch2.write(oprot);
        oprot.writeFieldEnd();
    }
    oprot.writeFieldStop();
    oprot.writeStructEnd();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,82046,82048,"public update_resultTupleScheme getScheme() {
    return new update_resultTupleScheme();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,82053,82070,"@Override
public void write(org.apache.thrift.protocol.TProtocol prot, update_result struct) throws org.apache.thrift.TException {
    TTupleProtocol oprot = (TTupleProtocol) prot;
    BitSet optionals = new BitSet();
    if (struct.isSetOuch1()) {
        optionals.set(0);
    }
    if (struct.isSetOuch2()) {
        optionals.set(1);
    }
    oprot.writeBitSet(optionals, 2);
    if (struct.isSetOuch1()) {
        struct.ouch1.write(oprot);
    }
    if (struct.isSetOuch2()) {
        struct.ouch2.write(oprot);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1190_e29dc4f5,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,82072,82086,"@Override
public void read(org.apache.thrift.protocol.TProtocol prot, update_result struct) throws org.apache.thrift.TException {
    TTupleProtocol iprot = (TTupleProtocol) prot;
    BitSet incoming = iprot.readBitSet(2);
    if (incoming.get(0)) {
        struct.ouch1 = new UnknownWriter();
        struct.ouch1.read(iprot);
        struct.setOuch1IsSet(true);
    }
    if (incoming.get(1)) {
        struct.ouch2 = new MutationsRejectedException();
        struct.ouch2.read(iprot);
        struct.setOuch2IsSet(true);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1192_9476b877,Minor,core/src/main/java/org/apache/accumulo/core/util/TableDiskUsage.java,128,222,"public static void printDiskUsage(AccumuloConfiguration acuConf, Collection<String> tables, FileSystem fs, Connector conn, Printer printer) throws TableNotFoundException, IOException {
    TableDiskUsage tdu = new TableDiskUsage();
    HashSet<String> tableIds = new HashSet<String>();
    for (String tableName : tables) {
        String tableId = conn.tableOperations().tableIdMap().get(tableName);
        if (tableId == null)
            throw new TableNotFoundException(null, tableName, ""Table "" + tableName + "" not found"");
        tableIds.add(tableId);
    }
    for (String tableId : tableIds) tdu.addTable(tableId);
    HashSet<String> tablesReferenced = new HashSet<String>(tableIds);
    for (String tableId : tableIds) {
        Scanner mdScanner = conn.createScanner(Constants.METADATA_TABLE_NAME, Constants.NO_AUTHS);
        mdScanner.fetchColumnFamily(Constants.METADATA_DATAFILE_COLUMN_FAMILY);
        mdScanner.setRange(new KeyExtent(new Text(tableId), null, null).toMetadataRange());
        for (Entry<Key, Value> entry : mdScanner) {
            String file = entry.getKey().getColumnQualifier().toString();
            if (file.startsWith(""../"")) {
                file = file.substring(2);
                tablesReferenced.add(file.split(""\\/"")[1]);
            } else
                file = ""/"" + tableId + file;
            tdu.linkFileAndTable(tableId, file);
        }
    }
    for (String tableId : tablesReferenced) {
        FileStatus[] files = fs.globStatus(new Path(Constants.getTablesDir(acuConf) + ""/"" + tableId + ""/*/*""));
        for (FileStatus fileStatus : files) {
            String dir = fileStatus.getPath().getParent().getName();
            String name = fileStatus.getPath().getName();
            tdu.addFileSize(""/"" + tableId + ""/"" + dir + ""/"" + name, fileStatus.getLen());
        }
    }
    HashMap<String, String> reverseTableIdMap = new HashMap<String, String>();
    for (Entry<String, String> entry : conn.tableOperations().tableIdMap().entrySet()) reverseTableIdMap.put(entry.getValue(), entry.getKey());
    TreeMap<TreeSet<String>, Long> usage = new TreeMap<TreeSet<String>, Long>(new Comparator<TreeSet<String>>() {

        @Override
        public int compare(TreeSet<String> o1, TreeSet<String> o2) {
            int len1 = o1.size();
            int len2 = o2.size();
            int min = Math.min(len1, len2);
            Iterator<String> iter1 = o1.iterator();
            Iterator<String> iter2 = o2.iterator();
            int count = 0;
            while (count < min) {
                String s1 = iter1.next();
                String s2 = iter2.next();
                int cmp = s1.compareTo(s2);
                if (cmp != 0)
                    return cmp;
                count++;
            }
            return len1 - len2;
        }
    });
    for (Entry<List<String>, Long> entry : tdu.calculateUsage().entrySet()) {
        TreeSet<String> tableNames = new TreeSet<String>();
        for (String tableId : entry.getKey()) tableNames.add(reverseTableIdMap.get(tableId));
        usage.put(tableNames, entry.getValue());
    }
    for (Entry<TreeSet<String>, Long> entry : usage.entrySet()) printer.print(String.format(""%,24d %s"", entry.getValue(), entry.getKey()));
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1192_c489d866,Minor,core/src/main/java/org/apache/accumulo/core/util/TableDiskUsage.java,128,222,"public static void printDiskUsage(AccumuloConfiguration acuConf, Collection<String> tables, FileSystem fs, Connector conn, Printer printer) throws TableNotFoundException, IOException {
    TableDiskUsage tdu = new TableDiskUsage();
    HashSet<String> tableIds = new HashSet<String>();
    for (String tableName : tables) {
        String tableId = conn.tableOperations().tableIdMap().get(tableName);
        if (tableId == null)
            throw new TableNotFoundException(null, tableName, ""Table "" + tableName + "" not found"");
        tableIds.add(tableId);
    }
    for (String tableId : tableIds) tdu.addTable(tableId);
    HashSet<String> tablesReferenced = new HashSet<String>(tableIds);
    for (String tableId : tableIds) {
        Scanner mdScanner = conn.createScanner(Constants.METADATA_TABLE_NAME, Constants.NO_AUTHS);
        mdScanner.fetchColumnFamily(Constants.METADATA_DATAFILE_COLUMN_FAMILY);
        mdScanner.setRange(new KeyExtent(new Text(tableId), null, null).toMetadataRange());
        for (Entry<Key, Value> entry : mdScanner) {
            String file = entry.getKey().getColumnQualifier().toString();
            if (file.startsWith(""../"")) {
                file = file.substring(2);
                tablesReferenced.add(file.split(""\\/"")[1]);
            } else
                file = ""/"" + tableId + file;
            tdu.linkFileAndTable(tableId, file);
        }
    }
    for (String tableId : tablesReferenced) {
        FileStatus[] files = fs.globStatus(new Path(Constants.getTablesDir(acuConf) + ""/"" + tableId + ""/*/*""));
        for (FileStatus fileStatus : files) {
            String dir = fileStatus.getPath().getParent().getName();
            String name = fileStatus.getPath().getName();
            tdu.addFileSize(""/"" + tableId + ""/"" + dir + ""/"" + name, fileStatus.getLen());
        }
    }
    HashMap<String, String> reverseTableIdMap = new HashMap<String, String>();
    for (Entry<String, String> entry : conn.tableOperations().tableIdMap().entrySet()) reverseTableIdMap.put(entry.getValue(), entry.getKey());
    TreeMap<TreeSet<String>, Long> usage = new TreeMap<TreeSet<String>, Long>(new Comparator<TreeSet<String>>() {

        @Override
        public int compare(TreeSet<String> o1, TreeSet<String> o2) {
            int len1 = o1.size();
            int len2 = o2.size();
            int min = Math.min(len1, len2);
            Iterator<String> iter1 = o1.iterator();
            Iterator<String> iter2 = o2.iterator();
            int count = 0;
            while (count < min) {
                String s1 = iter1.next();
                String s2 = iter2.next();
                int cmp = s1.compareTo(s2);
                if (cmp != 0)
                    return cmp;
                count++;
            }
            return len1 - len2;
        }
    });
    for (Entry<List<String>, Long> entry : tdu.calculateUsage().entrySet()) {
        TreeSet<String> tableNames = new TreeSet<String>();
        for (String tableId : entry.getKey()) tableNames.add(reverseTableIdMap.get(tableId));
        usage.put(tableNames, entry.getValue());
    }
    for (Entry<TreeSet<String>, Long> entry : usage.entrySet()) printer.print(String.format(""%,24d %s"", entry.getValue(), entry.getKey()));
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,174,203,"private TException translateException(Exception ex) {
    try {
        throw ex;
    } catch (MutationsRejectedException e) {
        logger.debug(e, e);
        return new org.apache.accumulo.proxy.thrift.MutationsRejectedException(e.toString());
    } catch (AccumuloException e) {
        logger.debug(e, e);
        return new org.apache.accumulo.proxy.thrift.AccumuloException(e.toString());
    } catch (AccumuloSecurityException e) {
        logger.debug(e, e);
        if (e.getSecurityErrorCode().equals(SecurityErrorCode.TABLE_DOESNT_EXIST))
            return new org.apache.accumulo.proxy.thrift.TableNotFoundException(e.toString());
        return new org.apache.accumulo.proxy.thrift.AccumuloSecurityException(e.toString());
    } catch (TableNotFoundException e) {
        logger.debug(e, e);
        return new org.apache.accumulo.proxy.thrift.TableNotFoundException(e.toString());
    } catch (TableExistsException e) {
        logger.debug(e, e);
        return new org.apache.accumulo.proxy.thrift.TableExistsException(e.toString());
    } catch (RuntimeException e) {
        if (e.getCause() != null) {
            if (e.getCause() instanceof Exception)
                return translateException((Exception) e.getCause());
        }
        return new TException(e);
    } catch (Exception e) {
        return new TException(ex);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,107,107,"public void removeConstraint(ByteBuffer login, String tableName, int constraint) throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,111,111,"public void removeTableProperty(ByteBuffer login, String tableName, String property) throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,117,117,"public void setTableProperty(ByteBuffer login, String tableName, String property, String value) throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,1209,1213,"public void removeConstraint(ByteBuffer login, String tableName, int constraint) throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException {
    send_removeConstraint(login, tableName, constraint);
    recv_removeConstraint();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,1224,1235,"public void recv_removeConstraint() throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException {
    removeConstraint_result result = new removeConstraint_result();
    receiveBase(result, ""removeConstraint"");
    if (result.ouch1 != null) {
        throw result.ouch1;
    }
    if (result.ouch2 != null) {
        throw result.ouch2;
    }
    return;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,1269,1273,"public void removeTableProperty(ByteBuffer login, String tableName, String property) throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException {
    send_removeTableProperty(login, tableName, property);
    recv_removeTableProperty();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,1284,1295,"public void recv_removeTableProperty() throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException {
    removeTableProperty_result result = new removeTableProperty_result();
    receiveBase(result, ""removeTableProperty"");
    if (result.ouch1 != null) {
        throw result.ouch1;
    }
    if (result.ouch2 != null) {
        throw result.ouch2;
    }
    return;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,1362,1366,"public void setTableProperty(ByteBuffer login, String tableName, String property, String value) throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException {
    send_setTableProperty(login, tableName, property, value);
    recv_setTableProperty();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,1378,1389,"public void recv_setTableProperty() throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException {
    setTableProperty_result result = new setTableProperty_result();
    receiveBase(result, ""setTableProperty"");
    if (result.ouch1 != null) {
        throw result.ouch1;
    }
    if (result.ouch2 != null) {
        throw result.ouch2;
    }
    return;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,3578,3585,"public void getResult() throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException {
    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
        throw new IllegalStateException(""Method call not finished!"");
    }
    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
    (new Client(prot)).recv_removeConstraint();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,3657,3664,"public void getResult() throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException {
    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
        throw new IllegalStateException(""Method call not finished!"");
    }
    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
    (new Client(prot)).recv_removeTableProperty();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,3774,3781,"public void getResult() throws AccumuloException, AccumuloSecurityException, org.apache.thrift.TException {
    if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
        throw new IllegalStateException(""Method call not finished!"");
    }
    org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
    org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
    (new Client(prot)).recv_setTableProperty();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,5978,5988,"public removeConstraint_result getResult(I iface, removeConstraint_args args) throws org.apache.thrift.TException {
    removeConstraint_result result = new removeConstraint_result();
    try {
        iface.removeConstraint(args.login, args.tableName, args.constraint);
    } catch (AccumuloException ouch1) {
        result.ouch1 = ouch1;
    } catch (AccumuloSecurityException ouch2) {
        result.ouch2 = ouch2;
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,6032,6042,"public removeTableProperty_result getResult(I iface, removeTableProperty_args args) throws org.apache.thrift.TException {
    removeTableProperty_result result = new removeTableProperty_result();
    try {
        iface.removeTableProperty(args.login, args.tableName, args.property);
    } catch (AccumuloException ouch1) {
        result.ouch1 = ouch1;
    } catch (AccumuloSecurityException ouch2) {
        result.ouch2 = ouch2;
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,6116,6126,"public setTableProperty_result getResult(I iface, setTableProperty_args args) throws org.apache.thrift.TException {
    setTableProperty_result result = new setTableProperty_result();
    try {
        iface.setTableProperty(args.login, args.tableName, args.property, args.value);
    } catch (AccumuloException ouch1) {
        result.ouch1 = ouch1;
    } catch (AccumuloSecurityException ouch2) {
        result.ouch2 = ouch2;
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,40169,40192,"public boolean equals(removeConstraint_result that) {
    if (that == null)
        return false;
    boolean this_present_ouch1 = true && this.isSetOuch1();
    boolean that_present_ouch1 = true && that.isSetOuch1();
    if (this_present_ouch1 || that_present_ouch1) {
        if (!(this_present_ouch1 && that_present_ouch1))
            return false;
        if (!this.ouch1.equals(that.ouch1))
            return false;
    }
    boolean this_present_ouch2 = true && this.isSetOuch2();
    boolean that_present_ouch2 = true && that.isSetOuch2();
    if (this_present_ouch2 || that_present_ouch2) {
        if (!(this_present_ouch2 && that_present_ouch2))
            return false;
        if (!this.ouch2.equals(that.ouch2))
            return false;
    }
    return true;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,40199,40228,"public int compareTo(removeConstraint_result other) {
    if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
    }
    int lastComparison = 0;
    removeConstraint_result typedOther = (removeConstraint_result) other;
    lastComparison = Boolean.valueOf(isSetOuch1()).compareTo(typedOther.isSetOuch1());
    if (lastComparison != 0) {
        return lastComparison;
    }
    if (isSetOuch1()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.ouch1, typedOther.ouch1);
        if (lastComparison != 0) {
            return lastComparison;
        }
    }
    lastComparison = Boolean.valueOf(isSetOuch2()).compareTo(typedOther.isSetOuch2());
    if (lastComparison != 0) {
        return lastComparison;
    }
    if (isSetOuch2()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.ouch2, typedOther.ouch2);
        if (lastComparison != 0) {
            return lastComparison;
        }
    }
    return 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,40242,40264,"@Override
public String toString() {
    StringBuilder sb = new StringBuilder(""removeConstraint_result("");
    boolean first = true;
    sb.append(""ouch1:"");
    if (this.ouch1 == null) {
        sb.append(""null"");
    } else {
        sb.append(this.ouch1);
    }
    first = false;
    if (!first)
        sb.append("", "");
    sb.append(""ouch2:"");
    if (this.ouch2 == null) {
        sb.append(""null"");
    } else {
        sb.append(this.ouch2);
    }
    first = false;
    sb.append("")"");
    return sb.toString();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,40295,40332,"public void read(org.apache.thrift.protocol.TProtocol iprot, removeConstraint_result struct) throws org.apache.thrift.TException {
    org.apache.thrift.protocol.TField schemeField;
    iprot.readStructBegin();
    while (true) {
        schemeField = iprot.readFieldBegin();
        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {
            break;
        }
        switch(schemeField.id) {
            case // OUCH1
            1:
                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                    struct.ouch1 = new AccumuloException();
                    struct.ouch1.read(iprot);
                    struct.setOuch1IsSet(true);
                } else {
                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
                }
                break;
            case // OUCH2
            2:
                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                    struct.ouch2 = new AccumuloSecurityException();
                    struct.ouch2.read(iprot);
                    struct.setOuch2IsSet(true);
                } else {
                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
                }
                break;
            default:
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
        }
        iprot.readFieldEnd();
    }
    iprot.readStructEnd();
    // check for required fields of primitive type, which can't be checked in the validate method
    struct.validate();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,40334,40350,"public void write(org.apache.thrift.protocol.TProtocol oprot, removeConstraint_result struct) throws org.apache.thrift.TException {
    struct.validate();
    oprot.writeStructBegin(STRUCT_DESC);
    if (struct.ouch1 != null) {
        oprot.writeFieldBegin(OUCH1_FIELD_DESC);
        struct.ouch1.write(oprot);
        oprot.writeFieldEnd();
    }
    if (struct.ouch2 != null) {
        oprot.writeFieldBegin(OUCH2_FIELD_DESC);
        struct.ouch2.write(oprot);
        oprot.writeFieldEnd();
    }
    oprot.writeFieldStop();
    oprot.writeStructEnd();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,40362,40379,"@Override
public void write(org.apache.thrift.protocol.TProtocol prot, removeConstraint_result struct) throws org.apache.thrift.TException {
    TTupleProtocol oprot = (TTupleProtocol) prot;
    BitSet optionals = new BitSet();
    if (struct.isSetOuch1()) {
        optionals.set(0);
    }
    if (struct.isSetOuch2()) {
        optionals.set(1);
    }
    oprot.writeBitSet(optionals, 2);
    if (struct.isSetOuch1()) {
        struct.ouch1.write(oprot);
    }
    if (struct.isSetOuch2()) {
        struct.ouch2.write(oprot);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,40381,40395,"@Override
public void read(org.apache.thrift.protocol.TProtocol prot, removeConstraint_result struct) throws org.apache.thrift.TException {
    TTupleProtocol iprot = (TTupleProtocol) prot;
    BitSet incoming = iprot.readBitSet(2);
    if (incoming.get(0)) {
        struct.ouch1 = new AccumuloException();
        struct.ouch1.read(iprot);
        struct.setOuch1IsSet(true);
    }
    if (incoming.get(1)) {
        struct.ouch2 = new AccumuloSecurityException();
        struct.ouch2.read(iprot);
        struct.setOuch2IsSet(true);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,42469,42492,"public boolean equals(removeTableProperty_result that) {
    if (that == null)
        return false;
    boolean this_present_ouch1 = true && this.isSetOuch1();
    boolean that_present_ouch1 = true && that.isSetOuch1();
    if (this_present_ouch1 || that_present_ouch1) {
        if (!(this_present_ouch1 && that_present_ouch1))
            return false;
        if (!this.ouch1.equals(that.ouch1))
            return false;
    }
    boolean this_present_ouch2 = true && this.isSetOuch2();
    boolean that_present_ouch2 = true && that.isSetOuch2();
    if (this_present_ouch2 || that_present_ouch2) {
        if (!(this_present_ouch2 && that_present_ouch2))
            return false;
        if (!this.ouch2.equals(that.ouch2))
            return false;
    }
    return true;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,42499,42528,"public int compareTo(removeTableProperty_result other) {
    if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
    }
    int lastComparison = 0;
    removeTableProperty_result typedOther = (removeTableProperty_result) other;
    lastComparison = Boolean.valueOf(isSetOuch1()).compareTo(typedOther.isSetOuch1());
    if (lastComparison != 0) {
        return lastComparison;
    }
    if (isSetOuch1()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.ouch1, typedOther.ouch1);
        if (lastComparison != 0) {
            return lastComparison;
        }
    }
    lastComparison = Boolean.valueOf(isSetOuch2()).compareTo(typedOther.isSetOuch2());
    if (lastComparison != 0) {
        return lastComparison;
    }
    if (isSetOuch2()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.ouch2, typedOther.ouch2);
        if (lastComparison != 0) {
            return lastComparison;
        }
    }
    return 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,42542,42564,"@Override
public String toString() {
    StringBuilder sb = new StringBuilder(""removeTableProperty_result("");
    boolean first = true;
    sb.append(""ouch1:"");
    if (this.ouch1 == null) {
        sb.append(""null"");
    } else {
        sb.append(this.ouch1);
    }
    first = false;
    if (!first)
        sb.append("", "");
    sb.append(""ouch2:"");
    if (this.ouch2 == null) {
        sb.append(""null"");
    } else {
        sb.append(this.ouch2);
    }
    first = false;
    sb.append("")"");
    return sb.toString();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,42595,42632,"public void read(org.apache.thrift.protocol.TProtocol iprot, removeTableProperty_result struct) throws org.apache.thrift.TException {
    org.apache.thrift.protocol.TField schemeField;
    iprot.readStructBegin();
    while (true) {
        schemeField = iprot.readFieldBegin();
        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {
            break;
        }
        switch(schemeField.id) {
            case // OUCH1
            1:
                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                    struct.ouch1 = new AccumuloException();
                    struct.ouch1.read(iprot);
                    struct.setOuch1IsSet(true);
                } else {
                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
                }
                break;
            case // OUCH2
            2:
                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                    struct.ouch2 = new AccumuloSecurityException();
                    struct.ouch2.read(iprot);
                    struct.setOuch2IsSet(true);
                } else {
                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
                }
                break;
            default:
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
        }
        iprot.readFieldEnd();
    }
    iprot.readStructEnd();
    // check for required fields of primitive type, which can't be checked in the validate method
    struct.validate();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,42634,42650,"public void write(org.apache.thrift.protocol.TProtocol oprot, removeTableProperty_result struct) throws org.apache.thrift.TException {
    struct.validate();
    oprot.writeStructBegin(STRUCT_DESC);
    if (struct.ouch1 != null) {
        oprot.writeFieldBegin(OUCH1_FIELD_DESC);
        struct.ouch1.write(oprot);
        oprot.writeFieldEnd();
    }
    if (struct.ouch2 != null) {
        oprot.writeFieldBegin(OUCH2_FIELD_DESC);
        struct.ouch2.write(oprot);
        oprot.writeFieldEnd();
    }
    oprot.writeFieldStop();
    oprot.writeStructEnd();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,42662,42679,"@Override
public void write(org.apache.thrift.protocol.TProtocol prot, removeTableProperty_result struct) throws org.apache.thrift.TException {
    TTupleProtocol oprot = (TTupleProtocol) prot;
    BitSet optionals = new BitSet();
    if (struct.isSetOuch1()) {
        optionals.set(0);
    }
    if (struct.isSetOuch2()) {
        optionals.set(1);
    }
    oprot.writeBitSet(optionals, 2);
    if (struct.isSetOuch1()) {
        struct.ouch1.write(oprot);
    }
    if (struct.isSetOuch2()) {
        struct.ouch2.write(oprot);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,42681,42695,"@Override
public void read(org.apache.thrift.protocol.TProtocol prot, removeTableProperty_result struct) throws org.apache.thrift.TException {
    TTupleProtocol iprot = (TTupleProtocol) prot;
    BitSet incoming = iprot.readBitSet(2);
    if (incoming.get(0)) {
        struct.ouch1 = new AccumuloException();
        struct.ouch1.read(iprot);
        struct.setOuch1IsSet(true);
    }
    if (incoming.get(1)) {
        struct.ouch2 = new AccumuloSecurityException();
        struct.ouch2.read(iprot);
        struct.setOuch2IsSet(true);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,46043,46066,"public boolean equals(setTableProperty_result that) {
    if (that == null)
        return false;
    boolean this_present_ouch1 = true && this.isSetOuch1();
    boolean that_present_ouch1 = true && that.isSetOuch1();
    if (this_present_ouch1 || that_present_ouch1) {
        if (!(this_present_ouch1 && that_present_ouch1))
            return false;
        if (!this.ouch1.equals(that.ouch1))
            return false;
    }
    boolean this_present_ouch2 = true && this.isSetOuch2();
    boolean that_present_ouch2 = true && that.isSetOuch2();
    if (this_present_ouch2 || that_present_ouch2) {
        if (!(this_present_ouch2 && that_present_ouch2))
            return false;
        if (!this.ouch2.equals(that.ouch2))
            return false;
    }
    return true;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,46073,46102,"public int compareTo(setTableProperty_result other) {
    if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
    }
    int lastComparison = 0;
    setTableProperty_result typedOther = (setTableProperty_result) other;
    lastComparison = Boolean.valueOf(isSetOuch1()).compareTo(typedOther.isSetOuch1());
    if (lastComparison != 0) {
        return lastComparison;
    }
    if (isSetOuch1()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.ouch1, typedOther.ouch1);
        if (lastComparison != 0) {
            return lastComparison;
        }
    }
    lastComparison = Boolean.valueOf(isSetOuch2()).compareTo(typedOther.isSetOuch2());
    if (lastComparison != 0) {
        return lastComparison;
    }
    if (isSetOuch2()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.ouch2, typedOther.ouch2);
        if (lastComparison != 0) {
            return lastComparison;
        }
    }
    return 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,46116,46138,"@Override
public String toString() {
    StringBuilder sb = new StringBuilder(""setTableProperty_result("");
    boolean first = true;
    sb.append(""ouch1:"");
    if (this.ouch1 == null) {
        sb.append(""null"");
    } else {
        sb.append(this.ouch1);
    }
    first = false;
    if (!first)
        sb.append("", "");
    sb.append(""ouch2:"");
    if (this.ouch2 == null) {
        sb.append(""null"");
    } else {
        sb.append(this.ouch2);
    }
    first = false;
    sb.append("")"");
    return sb.toString();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,46169,46206,"public void read(org.apache.thrift.protocol.TProtocol iprot, setTableProperty_result struct) throws org.apache.thrift.TException {
    org.apache.thrift.protocol.TField schemeField;
    iprot.readStructBegin();
    while (true) {
        schemeField = iprot.readFieldBegin();
        if (schemeField.type == org.apache.thrift.protocol.TType.STOP) {
            break;
        }
        switch(schemeField.id) {
            case // OUCH1
            1:
                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                    struct.ouch1 = new AccumuloException();
                    struct.ouch1.read(iprot);
                    struct.setOuch1IsSet(true);
                } else {
                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
                }
                break;
            case // OUCH2
            2:
                if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
                    struct.ouch2 = new AccumuloSecurityException();
                    struct.ouch2.read(iprot);
                    struct.setOuch2IsSet(true);
                } else {
                    org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
                }
                break;
            default:
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
        }
        iprot.readFieldEnd();
    }
    iprot.readStructEnd();
    // check for required fields of primitive type, which can't be checked in the validate method
    struct.validate();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,46208,46224,"public void write(org.apache.thrift.protocol.TProtocol oprot, setTableProperty_result struct) throws org.apache.thrift.TException {
    struct.validate();
    oprot.writeStructBegin(STRUCT_DESC);
    if (struct.ouch1 != null) {
        oprot.writeFieldBegin(OUCH1_FIELD_DESC);
        struct.ouch1.write(oprot);
        oprot.writeFieldEnd();
    }
    if (struct.ouch2 != null) {
        oprot.writeFieldBegin(OUCH2_FIELD_DESC);
        struct.ouch2.write(oprot);
        oprot.writeFieldEnd();
    }
    oprot.writeFieldStop();
    oprot.writeStructEnd();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,46236,46253,"@Override
public void write(org.apache.thrift.protocol.TProtocol prot, setTableProperty_result struct) throws org.apache.thrift.TException {
    TTupleProtocol oprot = (TTupleProtocol) prot;
    BitSet optionals = new BitSet();
    if (struct.isSetOuch1()) {
        optionals.set(0);
    }
    if (struct.isSetOuch2()) {
        optionals.set(1);
    }
    oprot.writeBitSet(optionals, 2);
    if (struct.isSetOuch1()) {
        struct.ouch1.write(oprot);
    }
    if (struct.isSetOuch2()) {
        struct.ouch2.write(oprot);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1199_813109d7,Minor,proxy/src/main/java/org/apache/accumulo/proxy/thrift/AccumuloProxy.java,46255,46269,"@Override
public void read(org.apache.thrift.protocol.TProtocol prot, setTableProperty_result struct) throws org.apache.thrift.TException {
    TTupleProtocol iprot = (TTupleProtocol) prot;
    BitSet incoming = iprot.readBitSet(2);
    if (incoming.get(0)) {
        struct.ouch1 = new AccumuloException();
        struct.ouch1.read(iprot);
        struct.setOuch1IsSet(true);
    }
    if (incoming.get(1)) {
        struct.ouch2 = new AccumuloSecurityException();
        struct.ouch2.read(iprot);
        struct.setOuch2IsSet(true);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1312_d9ab8449,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockInstance.java,151,159,"@Override
public Connector getConnector(String principal, AuthenticationToken token) throws AccumuloException, AccumuloSecurityException {
    Connector conn = new MockConnector(principal, acu, this);
    if (!acu.users.containsKey(principal))
        conn.securityOperations().createLocalUser(principal, (PasswordToken) token);
    else if (!acu.users.get(principal).token.equals(token))
        throw new AccumuloSecurityException(principal, SecurityErrorCode.BAD_CREDENTIALS);
    return conn;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1312_d9ab8449,Major,core/src/main/java/org/apache/accumulo/core/security/Credentials.java,60,62,"/**
 * Converts the current object to the relevant thrift type. The object returned from this contains a non-destroyable version of the
 * {@link AuthenticationToken}, so this should be used just before placing on the wire, and references to it should be tightly controlled.
 */
public TCredentials toThrift(Instance instance) {
    return new TCredentials(principal, token.getClass().getName(), ByteBuffer.wrap(AuthenticationTokenSerializer.serialize(token)), instance.getInstanceID());
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1348_6ff92b12,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockShell.java,71,103,"public int start() throws IOException {
    if (configError)
        return 1;
    String input;
    if (isVerbose())
        printInfo();
    if (execFile != null) {
        java.util.Scanner scanner = new java.util.Scanner(new File(execFile));
        while (scanner.hasNextLine()) execCommand(scanner.nextLine(), true, isVerbose());
    } else if (execCommand != null) {
        for (String command : execCommand.split(""\n"")) {
            execCommand(command, true, isVerbose());
        }
        return exitCode;
    }
    while (true) {
        if (hasExited())
            return exitCode;
        reader.setDefaultPrompt(getDefaultPrompt());
        input = reader.readLine();
        if (input == null) {
            reader.printNewline();
            return exitCode;
        }
        // user canceled
        execCommand(input, false, false);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1348_6ff92b12,Major,core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java,421,484,"public int start() throws IOException {
    if (configError)
        return 1;
    String input;
    if (isVerbose())
        printInfo();
    String home = System.getProperty(""HOME"");
    if (home == null)
        home = System.getenv(""HOME"");
    String configDir = home + ""/"" + HISTORY_DIR_NAME;
    String historyPath = configDir + ""/"" + HISTORY_FILE_NAME;
    File accumuloDir = new File(configDir);
    if (!accumuloDir.exists() && !accumuloDir.mkdirs())
        log.warn(""Unable to make directory for history at "" + accumuloDir);
    try {
        History history = new History();
        history.setHistoryFile(new File(historyPath));
        reader.setHistory(history);
    } catch (IOException e) {
        log.warn(""Unable to load history file at "" + historyPath);
    }
    ShellCompletor userCompletor = null;
    if (execFile != null) {
        java.util.Scanner scanner = new java.util.Scanner(new File(execFile));
        try {
            while (scanner.hasNextLine()) execCommand(scanner.nextLine(), true, isVerbose());
        } finally {
            scanner.close();
        }
    } else if (execCommand != null) {
        for (String command : execCommand.split(""\n"")) {
            execCommand(command, true, isVerbose());
        }
        return exitCode;
    }
    while (true) {
        if (hasExited())
            return exitCode;
        // If tab completion is true we need to reset
        if (tabCompletion) {
            if (userCompletor != null)
                reader.removeCompletor(userCompletor);
            userCompletor = setupCompletion();
            reader.addCompletor(userCompletor);
        }
        reader.setDefaultPrompt(getDefaultPrompt());
        input = reader.readLine();
        if (input == null) {
            reader.printNewline();
            return exitCode;
        }
        // user canceled
        execCommand(input, disableAuthTimeout, false);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1348_ef0f6ddc,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockShell.java,71,103,"public int start() throws IOException {
    if (configError)
        return 1;
    String input;
    if (isVerbose())
        printInfo();
    if (execFile != null) {
        java.util.Scanner scanner = new java.util.Scanner(new File(execFile));
        while (scanner.hasNextLine()) execCommand(scanner.nextLine(), true, isVerbose());
    } else if (execCommand != null) {
        for (String command : execCommand.split(""\n"")) {
            execCommand(command, true, isVerbose());
        }
        return exitCode;
    }
    while (true) {
        if (hasExited())
            return exitCode;
        reader.setDefaultPrompt(getDefaultPrompt());
        input = reader.readLine();
        if (input == null) {
            reader.printNewline();
            return exitCode;
        }
        // user canceled
        execCommand(input, false, false);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1348_ef0f6ddc,Major,core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java,413,472,"public int start() throws IOException {
    if (configError)
        return 1;
    String input;
    if (isVerbose())
        printInfo();
    String home = System.getProperty(""HOME"");
    if (home == null)
        home = System.getenv(""HOME"");
    String configDir = home + ""/.accumulo"";
    String historyPath = configDir + ""/shell_history.txt"";
    File accumuloDir = new File(configDir);
    if (!accumuloDir.exists() && !accumuloDir.mkdirs())
        log.warn(""Unable to make directory for history at "" + accumuloDir);
    try {
        History history = new History();
        history.setHistoryFile(new File(historyPath));
        reader.setHistory(history);
    } catch (IOException e) {
        log.warn(""Unable to load history file at "" + historyPath);
    }
    ShellCompletor userCompletor = null;
    if (execFile != null) {
        java.util.Scanner scanner = new java.util.Scanner(new File(execFile));
        while (scanner.hasNextLine()) execCommand(scanner.nextLine(), true, isVerbose());
    } else if (execCommand != null) {
        for (String command : execCommand.split(""\n"")) {
            execCommand(command, true, isVerbose());
        }
        return exitCode;
    }
    while (true) {
        if (hasExited())
            return exitCode;
        // If tab completion is true we need to reset
        if (tabCompletion) {
            if (userCompletor != null)
                reader.removeCompletor(userCompletor);
            userCompletor = setupCompletion();
            reader.addCompletor(userCompletor);
        }
        reader.setDefaultPrompt(getDefaultPrompt());
        input = reader.readLine();
        if (input == null) {
            reader.printNewline();
            return exitCode;
        }
        // user canceled
        execCommand(input, disableAuthTimeout, false);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1358_4d10c92f,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java,168,257,"private static String setUpOptions(ClassLoader classloader, final ConsoleReader reader, final String className, final Map<String, String> options) throws IOException, ShellCommandException {
    String input;
    OptionDescriber skvi;
    Class<? extends OptionDescriber> clazz;
    try {
        clazz = classloader.loadClass(className).asSubclass(OptionDescriber.class);
        skvi = clazz.newInstance();
    } catch (ClassNotFoundException e) {
        throw new IllegalArgumentException(e.getMessage());
    } catch (InstantiationException e) {
        throw new IllegalArgumentException(e.getMessage());
    } catch (IllegalAccessException e) {
        throw new IllegalArgumentException(e.getMessage());
    } catch (ClassCastException e) {
        throw new ShellCommandException(ErrorCode.INITIALIZATION_FAILURE, ""Unable to load "" + className + "" as type "" + OptionDescriber.class.getName() + ""; configure with 'config' instead"");
    }
    final IteratorOptions itopts = skvi.describeOptions();
    if (itopts.getName() == null) {
        throw new IllegalArgumentException(className + "" described its default distinguishing name as null"");
    }
    String shortClassName = className;
    if (className.contains(""."")) {
        shortClassName = className.substring(className.lastIndexOf('.') + 1);
    }
    final Map<String, String> localOptions = new HashMap<String, String>();
    do {
        // clean up the overall options that caused things to fail
        for (String key : localOptions.keySet()) {
            options.remove(key);
        }
        localOptions.clear();
        reader.printString(itopts.getDescription());
        reader.printNewline();
        String prompt;
        if (itopts.getNamedOptions() != null) {
            for (Entry<String, String> e : itopts.getNamedOptions().entrySet()) {
                prompt = Shell.repeat(""-"", 10) + ""> set "" + shortClassName + "" parameter "" + e.getKey() + "", "" + e.getValue() + "": "";
                reader.flushConsole();
                input = reader.readLine(prompt);
                if (input == null) {
                    reader.printNewline();
                    throw new IOException(""Input stream closed"");
                } else {
                    input = new String(input);
                }
                // Places all Parameters and Values into the LocalOptions, even if the value is """".
                // This allows us to check for """" values when setting the iterators and allows us to remove
                // the parameter and value from the table property.
                localOptions.put(e.getKey(), input);
            }
        }
        if (itopts.getUnnamedOptionDescriptions() != null) {
            for (String desc : itopts.getUnnamedOptionDescriptions()) {
                reader.printString(Shell.repeat(""-"", 10) + ""> entering options: "" + desc + ""\n"");
                input = ""start"";
                while (true) {
                    prompt = Shell.repeat(""-"", 10) + ""> set "" + shortClassName + "" option (<name> <value>, hit enter to skip): "";
                    reader.flushConsole();
                    input = reader.readLine(prompt);
                    if (input == null) {
                        reader.printNewline();
                        throw new IOException(""Input stream closed"");
                    } else {
                        input = new String(input);
                    }
                    if (input.length() == 0)
                        break;
                    String[] sa = input.split("" "", 2);
                    localOptions.put(sa[0], sa[1]);
                }
            }
        }
        options.putAll(localOptions);
        if (!skvi.validateOptions(options))
            reader.printString(""invalid options for "" + clazz.getName() + ""\n"");
    } while (!skvi.validateOptions(options));
    return itopts.getName();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1358_6c565dfb,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/SetIterCommand.java,168,257,"private static String setUpOptions(ClassLoader classloader, final ConsoleReader reader, final String className, final Map<String, String> options) throws IOException, ShellCommandException {
    String input;
    OptionDescriber skvi;
    Class<? extends OptionDescriber> clazz;
    try {
        clazz = classloader.loadClass(className).asSubclass(OptionDescriber.class);
        skvi = clazz.newInstance();
    } catch (ClassNotFoundException e) {
        throw new IllegalArgumentException(e.getMessage());
    } catch (InstantiationException e) {
        throw new IllegalArgumentException(e.getMessage());
    } catch (IllegalAccessException e) {
        throw new IllegalArgumentException(e.getMessage());
    } catch (ClassCastException e) {
        throw new ShellCommandException(ErrorCode.INITIALIZATION_FAILURE, ""Unable to load "" + className + "" as type "" + OptionDescriber.class.getName() + ""; configure with 'config' instead"");
    }
    final IteratorOptions itopts = skvi.describeOptions();
    if (itopts.getName() == null) {
        throw new IllegalArgumentException(className + "" described its default distinguishing name as null"");
    }
    String shortClassName = className;
    if (className.contains(""."")) {
        shortClassName = className.substring(className.lastIndexOf('.') + 1);
    }
    final Map<String, String> localOptions = new HashMap<String, String>();
    do {
        // clean up the overall options that caused things to fail
        for (String key : localOptions.keySet()) {
            options.remove(key);
        }
        localOptions.clear();
        reader.printString(itopts.getDescription());
        reader.printNewline();
        String prompt;
        if (itopts.getNamedOptions() != null) {
            for (Entry<String, String> e : itopts.getNamedOptions().entrySet()) {
                prompt = Shell.repeat(""-"", 10) + ""> set "" + shortClassName + "" parameter "" + e.getKey() + "", "" + e.getValue() + "": "";
                reader.flushConsole();
                input = reader.readLine(prompt);
                if (input == null) {
                    reader.printNewline();
                    throw new IOException(""Input stream closed"");
                } else {
                    input = new String(input);
                }
                // Places all Parameters and Values into the LocalOptions, even if the value is """".
                // This allows us to check for """" values when setting the iterators and allows us to remove
                // the parameter and value from the table property.
                localOptions.put(e.getKey(), input);
            }
        }
        if (itopts.getUnnamedOptionDescriptions() != null) {
            for (String desc : itopts.getUnnamedOptionDescriptions()) {
                reader.printString(Shell.repeat(""-"", 10) + ""> entering options: "" + desc + ""\n"");
                input = ""start"";
                while (true) {
                    prompt = Shell.repeat(""-"", 10) + ""> set "" + shortClassName + "" option (<name> <value>, hit enter to skip): "";
                    reader.flushConsole();
                    input = reader.readLine(prompt);
                    if (input == null) {
                        reader.printNewline();
                        throw new IOException(""Input stream closed"");
                    } else {
                        input = new String(input);
                    }
                    if (input.length() == 0)
                        break;
                    String[] sa = input.split("" "", 2);
                    localOptions.put(sa[0], sa[1]);
                }
            }
        }
        options.putAll(localOptions);
        if (!skvi.validateOptions(options))
            reader.printString(""invalid options for "" + clazz.getName() + ""\n"");
    } while (!skvi.validateOptions(options));
    return itopts.getName();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1505_994df698,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockBatchWriter.java,33,36,"@Override
public void addMutation(Mutation m) throws MutationsRejectedException {
    acu.addMutation(tablename, m);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1505_994df698,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockBatchWriter.java,38,43,"@Override
public void addMutations(Iterable<Mutation> iterable) throws MutationsRejectedException {
    for (Mutation m : iterable) {
        acu.addMutation(tablename, m);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1505_994df698,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockTable.java,103,119,"synchronized void addMutation(Mutation m) {
    long now = System.currentTimeMillis();
    mutationCount++;
    for (ColumnUpdate u : m.getUpdates()) {
        Key key = new Key(m.getRow(), 0, m.getRow().length, u.getColumnFamily(), 0, u.getColumnFamily().length, u.getColumnQualifier(), 0, u.getColumnQualifier().length, u.getColumnVisibility(), 0, u.getColumnVisibility().length, u.getTimestamp());
        if (u.isDeleted())
            key.setDeleted(true);
        if (!u.hasTimestamp())
            if (timeType.equals(TimeType.LOGICAL))
                key.setTimestamp(mutationCount);
            else
                key.setTimestamp(now);
        table.put(new MockMemKey(key, mutationCount), new Value(u.getValue()));
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1505_b082fc1e,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockBatchWriter.java,33,36,"@Override
public void addMutation(Mutation m) throws MutationsRejectedException {
    acu.addMutation(tablename, m);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1505_b082fc1e,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockBatchWriter.java,38,43,"@Override
public void addMutations(Iterable<Mutation> iterable) throws MutationsRejectedException {
    for (Mutation m : iterable) {
        acu.addMutation(tablename, m);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1505_b082fc1e,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockTable.java,103,119,"synchronized void addMutation(Mutation m) {
    long now = System.currentTimeMillis();
    mutationCount++;
    for (ColumnUpdate u : m.getUpdates()) {
        Key key = new Key(m.getRow(), 0, m.getRow().length, u.getColumnFamily(), 0, u.getColumnFamily().length, u.getColumnQualifier(), 0, u.getColumnQualifier().length, u.getColumnVisibility(), 0, u.getColumnVisibility().length, u.getTimestamp());
        if (u.isDeleted())
            key.setDeleted(true);
        if (!u.hasTimestamp())
            if (timeType.equals(TimeType.LOGICAL))
                key.setTimestamp(mutationCount);
            else
                key.setTimestamp(now);
        table.put(new MockMemKey(key, mutationCount), new Value(u.getValue()));
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1514_fb25913c,Major,start/src/main/java/org/apache/accumulo/start/classloader/vfs/AccumuloVFSClassLoader.java,116,164,"static FileObject[] resolve(FileSystemManager vfs, String uris, ArrayList<FileObject> pathsToMonitor) throws FileSystemException {
    if (uris == null)
        return new FileObject[0];
    ArrayList<FileObject> classpath = new ArrayList<FileObject>();
    pathsToMonitor.clear();
    for (String path : uris.split("","")) {
        path = path.trim();
        if (path.equals(""""))
            continue;
        path = AccumuloClassLoader.replaceEnvVars(path, System.getenv());
        FileObject fo = vfs.resolveFile(path);
        switch(fo.getType()) {
            case FILE:
            case FOLDER:
                classpath.add(fo);
                pathsToMonitor.add(fo);
                break;
            case IMAGINARY:
                // assume its a pattern
                String pattern = fo.getName().getBaseName();
                if (fo.getParent() != null && fo.getParent().getType() == FileType.FOLDER) {
                    pathsToMonitor.add(fo.getParent());
                    FileObject[] children = fo.getParent().getChildren();
                    for (FileObject child : children) {
                        if (child.getType() == FileType.FILE && child.getName().getBaseName().matches(pattern)) {
                            classpath.add(child);
                        }
                    }
                } else {
                    log.warn(""ignoring classpath entry "" + fo);
                }
                break;
            default:
                log.warn(""ignoring classpath entry "" + fo);
                break;
        }
    }
    return classpath.toArray(new FileObject[classpath.size()]);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1518_dc95cb69,Major,core/src/main/java/org/apache/accumulo/core/file/FileOperations.java,39,63,"private FileOperations findFileFactory(String file) {
    Path p = new Path(file);
    String name = p.getName();
    if (name.startsWith(Constants.MAPFILE_EXTENSION + ""_"")) {
        return new MapFileOperations();
    }
    String[] sp = name.split(""\\."");
    if (sp.length != 2) {
        throw new IllegalArgumentException(""File name "" + name + "" has no extension"");
    }
    String extension = sp[1];
    if (extension.equals(Constants.MAPFILE_EXTENSION) || extension.equals(Constants.MAPFILE_EXTENSION + ""_tmp"")) {
        return new MapFileOperations();
    } else if (extension.equals(RFile.EXTENSION) || extension.equals(RFile.EXTENSION + ""_tmp"")) {
        return new RFileOperations();
    } else {
        throw new IllegalArgumentException(""File type "" + extension + "" not supported"");
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1518_df4b1985,Major,core/src/main/java/org/apache/accumulo/core/file/FileOperations.java,39,63,"private FileOperations findFileFactory(String file) {
    Path p = new Path(file);
    String name = p.getName();
    if (name.startsWith(Constants.MAPFILE_EXTENSION + ""_"")) {
        return new MapFileOperations();
    }
    String[] sp = name.split(""\\."");
    if (sp.length != 2) {
        throw new IllegalArgumentException(""File name "" + name + "" has no extension"");
    }
    String extension = sp[1];
    if (extension.equals(Constants.MAPFILE_EXTENSION) || extension.equals(Constants.MAPFILE_EXTENSION + ""_tmp"")) {
        return new MapFileOperations();
    } else if (extension.equals(RFile.EXTENSION) || extension.equals(RFile.EXTENSION + ""_tmp"")) {
        return new RFileOperations();
    } else {
        throw new IllegalArgumentException(""File type "" + extension + "" not supported"");
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-151_b007b22e,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/Combiner.java,159,173,"/*
   * Sets the topKey and topValue based on the top key of the source. If the column of the source top key is in the set of combiners, or if there are no columns
   * in the set of combiners, topKey will be the top key of the source and topValue will be the result of the reduce method. Otherwise, topKey and topValue will
   * be null.
   */
private void findTop() throws IOException {
    // check if aggregation is needed
    if (super.hasTop()) {
        workKey.set(super.getTopKey());
        if (combiners.isEmpty() || combiners.contains(workKey)) {
            if (workKey.isDeleted())
                return;
            topKey = workKey;
            Iterator<Value> viter = new ValueIterator(getSource());
            topValue = reduce(topKey, viter);
            while (viter.hasNext()) viter.next();
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1544_0cf2ff72,Major,minicluster/src/main/java/org/apache/accumulo/minicluster/MiniAccumuloCluster.java,315,364,"/**
 * Starts Accumulo and Zookeeper processes. Can only be called once.
 *
 * @throws IllegalStateException
 *           if already started
 */
public void start() throws IOException, InterruptedException {
    if (!initialized) {
        Runtime.getRuntime().addShutdownHook(new Thread() {

            @Override
            public void run() {
                try {
                    MiniAccumuloCluster.this.stop();
                } catch (IOException e) {
                    e.printStackTrace();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        });
    }
    if (zooKeeperProcess == null) {
        zooKeeperProcess = exec(Main.class, ServerType.ZOOKEEPER, ZooKeeperServerMain.class.getName(), zooCfgFile.getAbsolutePath());
    }
    if (!initialized) {
        // sleep a little bit to let zookeeper come up before calling init, seems to work better
        UtilWaitThread.sleep(250);
        Process initProcess = exec(Initialize.class, ""--instance-name"", config.getInstanceName(), ""--password"", config.getRootPassword(), ""--username"", ""root"");
        int ret = initProcess.waitFor();
        if (ret != 0) {
            throw new RuntimeException(""Initialize process returned "" + ret);
        }
        initialized = true;
    }
    for (int i = tabletServerProcesses.size(); i < config.getNumTservers(); i++) {
        tabletServerProcesses.add(exec(TabletServer.class, ServerType.TABLET_SERVER));
    }
    int ret = 0;
    for (int i = 0; i < 5; i++) {
        ret = exec(Main.class, SetGoalState.class.getName(), MasterGoalState.NORMAL.toString()).waitFor();
        if (ret == 0)
            break;
        UtilWaitThread.sleep(1000);
    }
    if (ret != 0) {
        throw new RuntimeException(""Could not set master goal state, process returned "" + ret);
    }
    if (masterProcess == null) {
        masterProcess = exec(Master.class, ServerType.MASTER);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1661_13eb19c2,Major,core/src/main/java/org/apache/accumulo/core/client/mapreduce/lib/util/InputConfigurator.java,239,243,"/**
 * Gets the columns to be mapped over from this job.
 *
 * @param implementingClass
 *          the class whose name will be used as a prefix for the property configuration key
 * @param conf
 *          the Hadoop configuration object to configure
 * @return a set of columns
 * @since 1.5.0
 * @see #fetchColumns(Class, Configuration, Collection)
 */
public static Set<Pair<Text, Text>> getFetchedColumns(Class<?> implementingClass, Configuration conf) {
    ArgumentChecker.notNull(conf);
    return deserializeFetchedColumns(conf.getStringCollection(enumToConfKey(implementingClass, ScanOpts.COLUMNS)));
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1730_872b6db3,Trivial,core/src/main/java/org/apache/accumulo/core/security/ColumnVisibility.java,247,352,"Node parse_(byte[] expression) {
    Node result = null;
    Node expr = null;
    int wholeTermStart = index;
    int subtermStart = index;
    boolean subtermComplete = false;
    while (index < expression.length) {
        switch(expression[index++]) {
            case '&':
                {
                    expr = processTerm(subtermStart, index - 1, expr, expression);
                    if (result != null) {
                        if (!result.type.equals(NodeType.AND))
                            throw new BadArgumentException(""cannot mix & and |"", new String(expression), index - 1);
                    } else {
                        result = new Node(NodeType.AND, wholeTermStart);
                    }
                    result.add(expr);
                    expr = null;
                    subtermStart = index;
                    subtermComplete = false;
                    break;
                }
            case '|':
                {
                    expr = processTerm(subtermStart, index - 1, expr, expression);
                    if (result != null) {
                        if (!result.type.equals(NodeType.OR))
                            throw new BadArgumentException(""cannot mix | and &"", new String(expression), index - 1);
                    } else {
                        result = new Node(NodeType.OR, wholeTermStart);
                    }
                    result.add(expr);
                    expr = null;
                    subtermStart = index;
                    subtermComplete = false;
                    break;
                }
            case '(':
                {
                    parens++;
                    if (subtermStart != index - 1 || expr != null)
                        throw new BadArgumentException(""expression needs & or |"", new String(expression), index - 1);
                    expr = parse_(expression);
                    subtermStart = index;
                    subtermComplete = false;
                    break;
                }
            case ')':
                {
                    parens--;
                    Node child = processTerm(subtermStart, index - 1, expr, expression);
                    if (child == null && result == null)
                        throw new BadArgumentException(""empty expression not allowed"", new String(expression), index);
                    if (result == null)
                        return child;
                    if (result.type == child.type)
                        for (Node c : child.children) result.add(c);
                    else
                        result.add(child);
                    return result;
                }
            case '""':
                {
                    if (subtermStart != index - 1)
                        throw new BadArgumentException(""expression needs & or |"", new String(expression), index - 1);
                    while (index < expression.length && expression[index] != '""') {
                        if (expression[index] == '\\') {
                            index++;
                            if (expression[index] != '\\' && expression[index] != '""')
                                throw new BadArgumentException(""invalid escaping within quotes"", new String(expression), index - 1);
                        }
                        index++;
                    }
                    if (index == expression.length)
                        throw new BadArgumentException(""unclosed quote"", new String(expression), subtermStart);
                    if (subtermStart + 1 == index)
                        throw new BadArgumentException(""empty term"", new String(expression), subtermStart);
                    index++;
                    subtermComplete = true;
                    break;
                }
            default:
                {
                    if (subtermComplete)
                        throw new BadArgumentException(""expression needs & or |"", new String(expression), index - 1);
                    byte c = expression[index - 1];
                    if (!Authorizations.isValidAuthChar(c))
                        throw new BadArgumentException(""bad character ("" + c + "")"", new String(expression), index - 1);
                }
        }
    }
    Node child = processTerm(subtermStart, index, expr, expression);
    if (result != null) {
        result.add(child);
        result.end = index;
    } else
        result = child;
    if (result.type != NodeType.TERM)
        if (result.children.size() < 2)
            throw new BadArgumentException(""missing term"", new String(expression), index);
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1732_941e3cb1,Minor,core/src/main/java/org/apache/accumulo/core/client/mapred/AbstractInputFormat.java,354,407,"/**
 * Initialize a scanner over the given input split using this task attempt configuration.
 */
public void initialize(InputSplit inSplit, JobConf job) throws IOException {
    Scanner scanner;
    split = (RangeInputSplit) inSplit;
    log.debug(""Initializing input split: "" + split.getRange());
    Instance instance = getInstance(job);
    String principal = getPrincipal(job);
    AuthenticationToken token = getAuthenticationToken(job);
    Authorizations authorizations = getScanAuthorizations(job);
    // in case the table name changed, we can still use the previous name for terms of configuration,
    // but the scanner will use the table id resolved at job setup time
    BatchScanConfig tableConfig = getBatchScanConfig(job, split.getTableName());
    try {
        log.debug(""Creating connector with user: "" + principal);
        log.debug(""Creating scanner for table: "" + split.getTableName());
        log.debug(""Authorizations are: "" + authorizations);
        if (tableConfig.isOfflineScan()) {
            scanner = new OfflineScanner(instance, new Credentials(principal, token), split.getTableId(), authorizations);
        } else {
            scanner = new ScannerImpl(instance, new Credentials(principal, token), split.getTableId(), authorizations);
        }
        if (tableConfig.shouldUseIsolatedScanners()) {
            log.info(""Creating isolated scanner"");
            scanner = new IsolatedScanner(scanner);
        }
        if (tableConfig.shouldUseLocalIterators()) {
            log.info(""Using local iterators"");
            scanner = new ClientSideIteratorScanner(scanner);
        }
        setupIterators(job, scanner, split.getTableId());
    } catch (Exception e) {
        throw new IOException(e);
    }
    // setup a scanner within the bounds of this split
    for (Pair<Text, Text> c : tableConfig.getFetchedColumns()) {
        if (c.getSecond() != null) {
            log.debug(""Fetching column "" + c.getFirst() + "":"" + c.getSecond());
            scanner.fetchColumn(c.getFirst(), c.getSecond());
        } else {
            log.debug(""Fetching column family "" + c.getFirst());
            scanner.fetchColumnFamily(c.getFirst());
        }
    }
    scanner.setRange(split.getRange());
    numKeysRead = 0;
    // do this last after setting all scanner options
    scannerIterator = scanner.iterator();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1732_941e3cb1,Minor,core/src/main/java/org/apache/accumulo/core/client/mapred/AbstractInputFormat.java,440,533,"/**
 * Read the metadata table to get tablets and match up ranges to them.
 */
@Override
public InputSplit[] getSplits(JobConf job, int numSplits) throws IOException {
    log.setLevel(getLogLevel(job));
    validateOptions(job);
    LinkedList<InputSplit> splits = new LinkedList<InputSplit>();
    Map<String, BatchScanConfig> tableConfigs = getBatchScanConfigs(job);
    for (Map.Entry<String, BatchScanConfig> tableConfigEntry : tableConfigs.entrySet()) {
        String tableName = tableConfigEntry.getKey();
        BatchScanConfig tableConfig = tableConfigEntry.getValue();
        boolean autoAdjust = tableConfig.shouldAutoAdjustRanges();
        String tableId = null;
        List<Range> ranges = autoAdjust ? Range.mergeOverlapping(tableConfig.getRanges()) : tableConfig.getRanges();
        if (ranges.isEmpty()) {
            ranges = new ArrayList<Range>(1);
            ranges.add(new Range());
        }
        // get the metadata information for these ranges
        Map<String, Map<KeyExtent, List<Range>>> binnedRanges = new HashMap<String, Map<KeyExtent, List<Range>>>();
        TabletLocator tl;
        try {
            // resolve table name to id once, and use id from this point forward
            tableId = Tables.getTableId(getInstance(job), tableName);
            if (tableConfig.isOfflineScan()) {
                binnedRanges = binOfflineTable(job, tableId, ranges);
                while (binnedRanges == null) {
                    // Some tablets were still online, try again
                    // sleep randomly between 100 and 200 ms
                    UtilWaitThread.sleep(100 + (int) (Math.random() * 100));
                    binnedRanges = binOfflineTable(job, tableId, ranges);
                }
            } else {
                Instance instance = getInstance(job);
                tl = getTabletLocator(job, tableId);
                // its possible that the cache could contain complete, but old information about a tables tablets... so clear it
                tl.invalidateCache();
                Credentials creds = new Credentials(getPrincipal(job), getAuthenticationToken(job));
                while (!tl.binRanges(creds, ranges, binnedRanges).isEmpty()) {
                    if (!(instance instanceof MockInstance)) {
                        if (!Tables.exists(instance, tableId))
                            throw new TableDeletedException(tableId);
                        if (Tables.getTableState(instance, tableId) == TableState.OFFLINE)
                            throw new TableOfflineException(instance, tableId);
                    }
                    binnedRanges.clear();
                    log.warn(""Unable to locate bins for specified ranges. Retrying."");
                    // sleep randomly between 100 and 200 ms
                    UtilWaitThread.sleep(100 + (int) (Math.random() * 100));
                    tl.invalidateCache();
                }
            }
        } catch (Exception e) {
            throw new IOException(e);
        }
        HashMap<Range, ArrayList<String>> splitsToAdd = null;
        if (!autoAdjust)
            splitsToAdd = new HashMap<Range, ArrayList<String>>();
        HashMap<String, String> hostNameCache = new HashMap<String, String>();
        for (Map.Entry<String, Map<KeyExtent, List<Range>>> tserverBin : binnedRanges.entrySet()) {
            String ip = tserverBin.getKey().split("":"", 2)[0];
            String location = hostNameCache.get(ip);
            if (location == null) {
                InetAddress inetAddress = InetAddress.getByName(ip);
                location = inetAddress.getHostName();
                hostNameCache.put(ip, location);
            }
            for (Map.Entry<KeyExtent, List<Range>> extentRanges : tserverBin.getValue().entrySet()) {
                Range ke = extentRanges.getKey().toDataRange();
                for (Range r : extentRanges.getValue()) {
                    if (autoAdjust) {
                        // divide ranges into smaller ranges, based on the tablets
                        splits.add(new RangeInputSplit(tableName, tableId, ke.clip(r), new String[] { location }));
                    } else {
                        // don't divide ranges
                        ArrayList<String> locations = splitsToAdd.get(r);
                        if (locations == null)
                            locations = new ArrayList<String>(1);
                        locations.add(location);
                        splitsToAdd.put(r, locations);
                    }
                }
            }
        }
        if (!autoAdjust)
            for (Map.Entry<Range, ArrayList<String>> entry : splitsToAdd.entrySet()) splits.add(new RangeInputSplit(tableName, tableId, entry.getKey(), entry.getValue().toArray(new String[0])));
    }
    return splits.toArray(new InputSplit[splits.size()]);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1732_941e3cb1,Minor,core/src/main/java/org/apache/accumulo/core/client/mapreduce/AbstractInputFormat.java,367,421,"/**
 * Initialize a scanner over the given input split using this task attempt configuration.
 */
@Override
public void initialize(InputSplit inSplit, TaskAttemptContext attempt) throws IOException {
    Scanner scanner;
    split = (RangeInputSplit) inSplit;
    log.debug(""Initializing input split: "" + split.getRange());
    Instance instance = getInstance(attempt);
    String principal = getPrincipal(attempt);
    AuthenticationToken token = getAuthenticationToken(attempt);
    Authorizations authorizations = getScanAuthorizations(attempt);
    // in case the table name changed, we can still use the previous name for terms of configuration,
    // but the scanner will use the table id resolved at job setup time
    BatchScanConfig tableConfig = getBatchScanConfig(attempt, split.getTableName());
    try {
        log.debug(""Creating connector with user: "" + principal);
        log.debug(""Creating scanner for table: "" + split.getTableName());
        log.debug(""Authorizations are: "" + authorizations);
        if (tableConfig.isOfflineScan()) {
            scanner = new OfflineScanner(instance, new Credentials(principal, token), split.getTableId(), authorizations);
        } else {
            scanner = new ScannerImpl(instance, new Credentials(principal, token), split.getTableId(), authorizations);
        }
        if (tableConfig.shouldUseIsolatedScanners()) {
            log.info(""Creating isolated scanner"");
            scanner = new IsolatedScanner(scanner);
        }
        if (tableConfig.shouldUseLocalIterators()) {
            log.info(""Using local iterators"");
            scanner = new ClientSideIteratorScanner(scanner);
        }
        setupIterators(attempt, scanner, split.getTableId());
    } catch (Exception e) {
        throw new IOException(e);
    }
    // setup a scanner within the bounds of this split
    for (Pair<Text, Text> c : tableConfig.getFetchedColumns()) {
        if (c.getSecond() != null) {
            log.debug(""Fetching column "" + c.getFirst() + "":"" + c.getSecond());
            scanner.fetchColumn(c.getFirst(), c.getSecond());
        } else {
            log.debug(""Fetching column family "" + c.getFirst());
            scanner.fetchColumnFamily(c.getFirst());
        }
    }
    scanner.setRange(split.getRange());
    numKeysRead = 0;
    // do this last after setting all scanner options
    scannerIterator = scanner.iterator();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1732_941e3cb1,Minor,core/src/main/java/org/apache/accumulo/core/client/mapreduce/AbstractInputFormat.java,467,561,"/**
 * Gets the splits of the tables that have been set on the job.
 *
 * @param context
 *          the configuration of the job
 * @return the splits from the tables based on the ranges.
 * @throws java.io.IOException
 *           if a table set on the job doesn't exist or an error occurs initializing the tablet locator
 */
public List<InputSplit> getSplits(JobContext context) throws IOException {
    log.setLevel(getLogLevel(context));
    validateOptions(context);
    LinkedList<InputSplit> splits = new LinkedList<InputSplit>();
    Map<String, BatchScanConfig> tableConfigs = getBatchScanConfigs(context);
    for (Map.Entry<String, BatchScanConfig> tableConfigEntry : tableConfigs.entrySet()) {
        String tableName = tableConfigEntry.getKey();
        BatchScanConfig tableConfig = tableConfigEntry.getValue();
        boolean autoAdjust = tableConfig.shouldAutoAdjustRanges();
        String tableId = null;
        List<Range> ranges = autoAdjust ? Range.mergeOverlapping(tableConfig.getRanges()) : tableConfig.getRanges();
        if (ranges.isEmpty()) {
            ranges = new ArrayList<Range>(1);
            ranges.add(new Range());
        }
        // get the metadata information for these ranges
        Map<String, Map<KeyExtent, List<Range>>> binnedRanges = new HashMap<String, Map<KeyExtent, List<Range>>>();
        TabletLocator tl;
        try {
            // resolve table name to id once, and use id from this point forward
            tableId = Tables.getTableId(getInstance(context), tableName);
            if (tableConfig.isOfflineScan()) {
                binnedRanges = binOfflineTable(context, tableId, ranges);
                while (binnedRanges == null) {
                    // Some tablets were still online, try again
                    // sleep randomly between 100 and 200 ms
                    UtilWaitThread.sleep(100 + (int) (Math.random() * 100));
                    binnedRanges = binOfflineTable(context, tableId, ranges);
                }
            } else {
                Instance instance = getInstance(context);
                tl = getTabletLocator(context, tableId);
                // its possible that the cache could contain complete, but old information about a tables tablets... so clear it
                tl.invalidateCache();
                Credentials creds = new Credentials(getPrincipal(context), getAuthenticationToken(context));
                while (!tl.binRanges(creds, ranges, binnedRanges).isEmpty()) {
                    if (!(instance instanceof MockInstance)) {
                        if (!Tables.exists(instance, tableId))
                            throw new TableDeletedException(tableId);
                        if (Tables.getTableState(instance, tableId) == TableState.OFFLINE)
                            throw new TableOfflineException(instance, tableId);
                    }
                    binnedRanges.clear();
                    log.warn(""Unable to locate bins for specified ranges. Retrying."");
                    // sleep randomly between 100 and 200 ms
                    UtilWaitThread.sleep(100 + (int) (Math.random() * 100));
                    tl.invalidateCache();
                }
            }
        } catch (Exception e) {
            throw new IOException(e);
        }
        HashMap<Range, ArrayList<String>> splitsToAdd = null;
        if (!autoAdjust)
            splitsToAdd = new HashMap<Range, ArrayList<String>>();
        HashMap<String, String> hostNameCache = new HashMap<String, String>();
        for (Map.Entry<String, Map<KeyExtent, List<Range>>> tserverBin : binnedRanges.entrySet()) {
            String ip = tserverBin.getKey().split("":"", 2)[0];
            String location = hostNameCache.get(ip);
            if (location == null) {
                InetAddress inetAddress = InetAddress.getByName(ip);
                location = inetAddress.getHostName();
                hostNameCache.put(ip, location);
            }
            for (Map.Entry<KeyExtent, List<Range>> extentRanges : tserverBin.getValue().entrySet()) {
                Range ke = extentRanges.getKey().toDataRange();
                for (Range r : extentRanges.getValue()) {
                    if (autoAdjust) {
                        // divide ranges into smaller ranges, based on the tablets
                        splits.add(new RangeInputSplit(tableName, tableId, ke.clip(r), new String[] { location }));
                    } else {
                        // don't divide ranges
                        ArrayList<String> locations = splitsToAdd.get(r);
                        if (locations == null)
                            locations = new ArrayList<String>(1);
                        locations.add(location);
                        splitsToAdd.put(r, locations);
                    }
                }
            }
        }
        if (!autoAdjust)
            for (Map.Entry<Range, ArrayList<String>> entry : splitsToAdd.entrySet()) splits.add(new RangeInputSplit(tableName, tableId, entry.getKey(), entry.getValue().toArray(new String[0])));
    }
    return splits;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-178_2f0643a9,Trivial,src/core/src/main/java/org/apache/accumulo/core/iterators/FamilyIntersectingIterator.java,141,159,"protected Key buildDocKey() {
    if (log.isTraceEnabled())
        log.trace(""building doc key for "" + currentPartition + "" "" + currentDocID);
    int zeroIndex = currentDocID.find(""\0"");
    if (zeroIndex < 0)
        throw new IllegalArgumentException(""bad current docID"");
    Text colf = new Text(docColf);
    colf.append(nullByte, 0, 1);
    colf.append(currentDocID.getBytes(), 0, zeroIndex);
    docColfSet = Collections.singleton((ByteSequence) new ArrayByteSequence(colf.getBytes(), 0, colf.getLength()));
    if (log.isTraceEnabled())
        log.trace(zeroIndex + "" "" + currentDocID.getLength());
    Text colq = new Text();
    colq.set(currentDocID.getBytes(), zeroIndex + 1, currentDocID.getLength() - zeroIndex - 2);
    Key k = new Key(currentPartition, colf, colq);
    if (log.isTraceEnabled())
        log.trace(""built doc key for seek: "" + k.toString());
    return k;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-178_efef09b0,Trivial,src/core/src/main/java/org/apache/accumulo/core/iterators/FamilyIntersectingIterator.java,141,159,"protected Key buildDocKey() {
    if (log.isTraceEnabled())
        log.trace(""building doc key for "" + currentPartition + "" "" + currentDocID);
    int zeroIndex = currentDocID.find(""\0"");
    if (zeroIndex < 0)
        throw new IllegalArgumentException(""bad current docID"");
    Text colf = new Text(docColf);
    colf.append(nullByte, 0, 1);
    colf.append(currentDocID.getBytes(), 0, zeroIndex);
    docColfSet = Collections.singleton((ByteSequence) new ArrayByteSequence(colf.getBytes(), 0, colf.getLength()));
    if (log.isTraceEnabled())
        log.trace(zeroIndex + "" "" + currentDocID.getLength());
    Text colq = new Text();
    colq.set(currentDocID.getBytes(), zeroIndex + 1, currentDocID.getLength() - zeroIndex - 2);
    Key k = new Key(currentPartition, colf, colq);
    if (log.isTraceEnabled())
        log.trace(""built doc key for seek: "" + k.toString());
    return k;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1800_3143b9c5,Critical,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,1104,1145,"private void addCellsToWriter(Map<ByteBuffer, List<ColumnUpdate>> cells, BatchWriterPlusException bwpe) {
    if (bwpe.exception != null)
        return;
    HashMap<Text, ColumnVisibility> vizMap = new HashMap<Text, ColumnVisibility>();
    for (Map.Entry<ByteBuffer, List<ColumnUpdate>> entry : cells.entrySet()) {
        Mutation m = new Mutation(ByteBufferUtil.toBytes(entry.getKey()));
        for (ColumnUpdate update : entry.getValue()) {
            ColumnVisibility viz = EMPTY_VIS;
            if (update.isSetColVisibility()) {
                Text vizText = new Text(update.getColVisibility());
                viz = vizMap.get(vizText);
                if (viz == null) {
                    vizMap.put(vizText, viz = new ColumnVisibility(vizText));
                }
            }
            byte[] value = new byte[0];
            if (update.isSetValue())
                value = update.getValue();
            if (update.isSetTimestamp()) {
                if (update.isSetDeleteCell()) {
                    m.putDelete(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp());
                } else {
                    if (update.isSetDeleteCell()) {
                        m.putDelete(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp());
                    } else {
                        m.put(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp(), value);
                    }
                }
            } else {
                m.put(update.getColFamily(), update.getColQualifier(), viz, value);
            }
        }
        try {
            bwpe.writer.addMutation(m);
        } catch (MutationsRejectedException mre) {
            bwpe.exception = mre;
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-1800_8ec4cb84,Critical,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,1164,1187,"private void addUpdatesToMutation(HashMap<Text, ColumnVisibility> vizMap, Mutation m, List<ColumnUpdate> cu) {
    for (ColumnUpdate update : cu) {
        ColumnVisibility viz = EMPTY_VIS;
        if (update.isSetColVisibility()) {
            viz = getCahcedCV(vizMap, update.getColVisibility());
        }
        byte[] value = new byte[0];
        if (update.isSetValue())
            value = update.getValue();
        if (update.isSetTimestamp()) {
            if (update.isSetDeleteCell()) {
                m.putDelete(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp());
            } else {
                if (update.isSetDeleteCell()) {
                    m.putDelete(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp());
                } else {
                    m.put(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp(), value);
                }
            }
        } else {
            m.put(update.getColFamily(), update.getColQualifier(), viz, value);
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-189_6dbbdc21,Minor,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,38,48,"@Override
public SortedKeyValueIterator<Key, Value> deepCopy(IteratorEnvironment env) {
    RegExFilter result = new RegExFilter();
    result.setSource(getSource().deepCopy(env));
    result.rowMatcher = rowMatcher.pattern().matcher("""");
    result.colfMatcher = colfMatcher.pattern().matcher("""");
    result.colqMatcher = colqMatcher.pattern().matcher("""");
    result.valueMatcher = valueMatcher.pattern().matcher("""");
    result.orFields = orFields;
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-189_cd7feb4d,Minor,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,38,48,"@Override
public SortedKeyValueIterator<Key, Value> deepCopy(IteratorEnvironment env) {
    RegExFilter result = new RegExFilter();
    result.setSource(getSource().deepCopy(env));
    result.rowMatcher = rowMatcher.pattern().matcher("""");
    result.colfMatcher = colfMatcher.pattern().matcher("""");
    result.colqMatcher = colqMatcher.pattern().matcher("""");
    result.valueMatcher = valueMatcher.pattern().matcher("""");
    result.orFields = orFields;
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-193_8ad5a888,Minor,src/core/src/main/java/org/apache/accumulo/core/data/Key.java,446,464,"public static String toPrintableString(byte[] ba, int offset, int len, int maxLen) {
    StringBuilder sb = new StringBuilder();
    int plen = Math.min(len, maxLen);
    for (int i = 0; i < plen; i++) {
        int c = 0xff & ba[offset + i];
        if (c >= 32 && c <= 126)
            sb.append((char) c);
        else
            sb.append(""%"" + String.format(""%02x;"", c));
    }
    if (len > maxLen) {
        sb.append(""... TRUNCATED"");
    }
    return sb.toString();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-193_8ad5a888,Minor,src/core/src/main/java/org/apache/accumulo/core/data/Key.java,466,474,"public String toString() {
    String labelString = new ColumnVisibility(colVisibility).toString();
    String s = toPrintableString(row, 0, row.length, Constants.MAX_DATA_TO_PRINT) + "" "" + toPrintableString(colFamily, 0, colFamily.length, Constants.MAX_DATA_TO_PRINT) + "":"" + toPrintableString(colQualifier, 0, colQualifier.length, Constants.MAX_DATA_TO_PRINT) + "" "" + labelString + "" "" + Long.toString(timestamp) + "" "" + deleted;
    return s;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-193_8ad5a888,Minor,src/core/src/main/java/org/apache/accumulo/core/data/Key.java,476,483,"public String toStringNoTime() {
    String labelString = new ColumnVisibility(colVisibility).toString();
    String s = new String(row, 0, row.length) + "" "" + new String(colFamily, 0, colFamily.length) + "":"" + new String(colQualifier, 0, colQualifier.length) + "" "" + labelString;
    return s;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-193_c831e44d,Minor,src/core/src/main/java/org/apache/accumulo/core/data/Key.java,446,464,"public static String toPrintableString(byte[] ba, int offset, int len, int maxLen) {
    StringBuilder sb = new StringBuilder();
    int plen = Math.min(len, maxLen);
    for (int i = 0; i < plen; i++) {
        int c = 0xff & ba[offset + i];
        if (c >= 32 && c <= 126)
            sb.append((char) c);
        else
            sb.append(""%"" + String.format(""%02x;"", c));
    }
    if (len > maxLen) {
        sb.append(""... TRUNCATED"");
    }
    return sb.toString();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-193_c831e44d,Minor,src/core/src/main/java/org/apache/accumulo/core/data/Key.java,466,474,"public String toString() {
    String labelString = new ColumnVisibility(colVisibility).toString();
    String s = toPrintableString(row, 0, row.length, Constants.MAX_DATA_TO_PRINT) + "" "" + toPrintableString(colFamily, 0, colFamily.length, Constants.MAX_DATA_TO_PRINT) + "":"" + toPrintableString(colQualifier, 0, colQualifier.length, Constants.MAX_DATA_TO_PRINT) + "" "" + labelString + "" "" + Long.toString(timestamp) + "" "" + deleted;
    return s;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-193_c831e44d,Minor,src/core/src/main/java/org/apache/accumulo/core/data/Key.java,476,483,"public String toStringNoTime() {
    String labelString = new ColumnVisibility(colVisibility).toString();
    String s = new String(row, 0, row.length) + "" "" + new String(colFamily, 0, colFamily.length) + "":"" + new String(colQualifier, 0, colQualifier.length) + "" "" + labelString;
    return s;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_397f86f6,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,72,80,"private boolean matches(Matcher matcher, ByteSequence bs) {
    if (matcher != null) {
        babcs.set(bs);
        matcher.reset(babcs);
        return matcher.matches();
    }
    return !orFields;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_397f86f6,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,82,90,"private boolean matches(Matcher matcher, byte[] data, int offset, int len) {
    if (matcher != null) {
        babcs.set(data, offset, len);
        matcher.reset(babcs);
        return matcher.matches();
    }
    return !orFields;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_397f86f6,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,101,133,"@Override
public void init(SortedKeyValueIterator<Key, Value> source, Map<String, String> options, IteratorEnvironment env) throws IOException {
    super.init(source, options, env);
    if (options.containsKey(ROW_REGEX)) {
        rowMatcher = Pattern.compile(options.get(ROW_REGEX)).matcher("""");
    } else {
        rowMatcher = null;
    }
    if (options.containsKey(COLF_REGEX)) {
        colfMatcher = Pattern.compile(options.get(COLF_REGEX)).matcher("""");
    } else {
        colfMatcher = null;
    }
    if (options.containsKey(COLQ_REGEX)) {
        colqMatcher = Pattern.compile(options.get(COLQ_REGEX)).matcher("""");
    } else {
        colqMatcher = null;
    }
    if (options.containsKey(VALUE_REGEX)) {
        valueMatcher = Pattern.compile(options.get(VALUE_REGEX)).matcher("""");
    } else {
        valueMatcher = null;
    }
    if (options.containsKey(OR_FIELDS)) {
        orFields = Boolean.parseBoolean(options.get(OR_FIELDS));
    } else {
        orFields = false;
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_397f86f6,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,135,146,"@Override
public IteratorOptions describeOptions() {
    IteratorOptions io = super.describeOptions();
    io.setName(""regex"");
    io.setDescription(""The RegExFilter/Iterator allows you to filter for key/value pairs based on regular expressions"");
    io.addNamedOption(RegExFilter.ROW_REGEX, ""regular expression on row"");
    io.addNamedOption(RegExFilter.COLF_REGEX, ""regular expression on column family"");
    io.addNamedOption(RegExFilter.COLQ_REGEX, ""regular expression on column qualifier"");
    io.addNamedOption(RegExFilter.VALUE_REGEX, ""regular expression on value"");
    io.addNamedOption(RegExFilter.OR_FIELDS, ""use OR instread of AND when multiple regexes given"");
    return io;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_397f86f6,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,148,164,"@Override
public boolean validateOptions(Map<String, String> options) {
    super.validateOptions(options);
    if (options.containsKey(ROW_REGEX))
        Pattern.compile(options.get(ROW_REGEX)).matcher("""");
    if (options.containsKey(COLF_REGEX))
        Pattern.compile(options.get(COLF_REGEX)).matcher("""");
    if (options.containsKey(COLQ_REGEX))
        Pattern.compile(options.get(COLQ_REGEX)).matcher("""");
    if (options.containsKey(VALUE_REGEX))
        Pattern.compile(options.get(VALUE_REGEX)).matcher("""");
    return true;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_76d727f0,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,72,80,"private boolean matches(Matcher matcher, ByteSequence bs) {
    if (matcher != null) {
        babcs.set(bs);
        matcher.reset(babcs);
        return matcher.matches();
    }
    return !orFields;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_76d727f0,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,82,90,"private boolean matches(Matcher matcher, byte[] data, int offset, int len) {
    if (matcher != null) {
        babcs.set(data, offset, len);
        matcher.reset(babcs);
        return matcher.matches();
    }
    return !orFields;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_76d727f0,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,101,133,"@Override
public void init(SortedKeyValueIterator<Key, Value> source, Map<String, String> options, IteratorEnvironment env) throws IOException {
    super.init(source, options, env);
    if (options.containsKey(ROW_REGEX)) {
        rowMatcher = Pattern.compile(options.get(ROW_REGEX)).matcher("""");
    } else {
        rowMatcher = null;
    }
    if (options.containsKey(COLF_REGEX)) {
        colfMatcher = Pattern.compile(options.get(COLF_REGEX)).matcher("""");
    } else {
        colfMatcher = null;
    }
    if (options.containsKey(COLQ_REGEX)) {
        colqMatcher = Pattern.compile(options.get(COLQ_REGEX)).matcher("""");
    } else {
        colqMatcher = null;
    }
    if (options.containsKey(VALUE_REGEX)) {
        valueMatcher = Pattern.compile(options.get(VALUE_REGEX)).matcher("""");
    } else {
        valueMatcher = null;
    }
    if (options.containsKey(OR_FIELDS)) {
        orFields = Boolean.parseBoolean(options.get(OR_FIELDS));
    } else {
        orFields = false;
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_76d727f0,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,135,146,"@Override
public IteratorOptions describeOptions() {
    IteratorOptions io = super.describeOptions();
    io.setName(""regex"");
    io.setDescription(""The RegExFilter/Iterator allows you to filter for key/value pairs based on regular expressions"");
    io.addNamedOption(RegExFilter.ROW_REGEX, ""regular expression on row"");
    io.addNamedOption(RegExFilter.COLF_REGEX, ""regular expression on column family"");
    io.addNamedOption(RegExFilter.COLQ_REGEX, ""regular expression on column qualifier"");
    io.addNamedOption(RegExFilter.VALUE_REGEX, ""regular expression on value"");
    io.addNamedOption(RegExFilter.OR_FIELDS, ""use OR instread of AND when multiple regexes given"");
    return io;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-209_76d727f0,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,148,164,"@Override
public boolean validateOptions(Map<String, String> options) {
    super.validateOptions(options);
    if (options.containsKey(ROW_REGEX))
        Pattern.compile(options.get(ROW_REGEX)).matcher("""");
    if (options.containsKey(COLF_REGEX))
        Pattern.compile(options.get(COLF_REGEX)).matcher("""");
    if (options.containsKey(COLQ_REGEX))
        Pattern.compile(options.get(COLQ_REGEX)).matcher("""");
    if (options.containsKey(VALUE_REGEX))
        Pattern.compile(options.get(VALUE_REGEX)).matcher("""");
    return true;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsHelper.java,48,62,"@Override
public void removeIterator(String tableName, String name, EnumSet<IteratorScope> scopes) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {
    Map<String, String> copy = new TreeMap<String, String>();
    for (Entry<String, String> property : this.getProperties(tableName)) {
        copy.put(property.getKey(), property.getValue());
    }
    for (IteratorScope scope : scopes) {
        String root = String.format(""%s%s.%s"", Property.TABLE_ITERATOR_PREFIX, scope.name().toLowerCase(), name);
        for (Entry<String, String> property : copy.entrySet()) {
            if (property.getKey().equals(root) || property.getKey().startsWith(root + "".opt.""))
                this.removeProperty(tableName, property.getKey());
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsHelper.java,64,89,"@Override
public IteratorSetting getIteratorSetting(String tableName, String name, IteratorScope scope) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {
    int priority = -1;
    String classname = null;
    Map<String, String> settings = new HashMap<String, String>();
    String root = String.format(""%s%s.%s"", Property.TABLE_ITERATOR_PREFIX, scope.name().toLowerCase(), name);
    String opt = root + "".opt."";
    for (Entry<String, String> property : this.getProperties(tableName)) {
        if (property.getKey().equals(root)) {
            String[] parts = property.getValue().split("","");
            if (parts.length != 2) {
                throw new AccumuloException(""Bad value for iterator setting: "" + property.getValue());
            }
            priority = Integer.parseInt(parts[0]);
            classname = parts[1];
        } else if (property.getKey().startsWith(opt)) {
            settings.put(property.getKey().substring(opt.length()), property.getValue());
        }
    }
    if (priority <= 0 || classname == null) {
        return null;
    }
    return new IteratorSetting(priority, name, classname, EnumSet.of(scope), settings);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsHelper.java,91,106,"@Override
public Set<String> listIterators(String tableName) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {
    Set<String> result = new HashSet<String>();
    Set<String> lifecycles = new HashSet<String>();
    for (IteratorScope scope : IteratorScope.values()) lifecycles.add(scope.name().toLowerCase());
    for (Entry<String, String> property : this.getProperties(tableName)) {
        String name = property.getKey();
        String[] parts = name.split(""\\."");
        if (parts.length == 4) {
            if (parts[0].equals(""table"") && parts[1].equals(""iterator"") && lifecycles.contains(parts[2]))
                result.add(parts[3]);
        }
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsHelper.java,108,137,"@Override
public void checkIteratorConflicts(String tableName, IteratorSetting setting) throws AccumuloException, TableNotFoundException {
    for (IteratorScope scope : setting.getScopes()) {
        String scopeStr = String.format(""%s%s"", Property.TABLE_ITERATOR_PREFIX, scope.name().toLowerCase());
        String nameStr = String.format(""%s.%s"", scopeStr, setting.getName());
        String optStr = String.format(""%s.opt."", nameStr);
        Map<String, String> optionConflicts = new TreeMap<String, String>();
        for (Entry<String, String> property : this.getProperties(tableName)) {
            if (property.getKey().startsWith(scopeStr)) {
                if (property.getKey().equals(nameStr))
                    throw new IllegalArgumentException(""iterator name conflict for "" + setting.getName() + "": "" + property.getKey() + ""="" + property.getValue());
                if (property.getKey().startsWith(optStr))
                    optionConflicts.put(property.getKey(), property.getValue());
                if (property.getKey().contains("".opt.""))
                    continue;
                String[] parts = property.getValue().split("","");
                if (parts.length != 2)
                    throw new AccumuloException(""Bad value for existing iterator setting: "" + property.getKey() + ""="" + property.getValue());
                try {
                    if (Integer.parseInt(parts[0]) == setting.getPriority())
                        throw new IllegalArgumentException(""iterator priority conflict: "" + property.getKey() + ""="" + property.getValue());
                } catch (NumberFormatException e) {
                    throw new AccumuloException(""Bad value for existing iterator setting: "" + property.getKey() + ""="" + property.getValue());
                }
            }
        }
        if (optionConflicts.size() > 0)
            throw new IllegalArgumentException(""iterator options conflict for "" + setting.getName() + "": "" + optionConflicts);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,79,85,"@Override
public void create(String tableName, boolean versioningIter, TimeType timeType) throws AccumuloException, AccumuloSecurityException, TableExistsException {
    if (!tableName.matches(Constants.VALID_TABLE_NAME_REGEX)) {
        throw new IllegalArgumentException();
    }
    acu.createTable(username, tableName, versioningIter, timeType);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,90,94,"/**
 * @deprecated since 1.4 {@link #attachIterator(String, IteratorSetting)}
 */
@Override
public void addAggregators(String tableName, List<? extends PerColumnIteratorConfig> aggregators) throws AccumuloSecurityException, TableNotFoundException, AccumuloException {
    acu.addAggregators(tableName, aggregators);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,96,97,"@Override
public void addSplits(String tableName, SortedSet<Text> partitionKeys) throws TableNotFoundException, AccumuloException, AccumuloSecurityException {
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,99,102,"@Override
public Collection<Text> getSplits(String tableName) {
    return Collections.emptyList();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,104,107,"@Override
public Collection<Text> getSplits(String tableName, int maxSplits) {
    return Collections.emptyList();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,109,112,"@Override
public void delete(String tableName) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
    acu.tables.remove(tableName);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,114,119,"@Override
public void rename(String oldTableName, String newTableName) throws AccumuloSecurityException, TableNotFoundException, AccumuloException, TableExistsException {
    MockTable t = acu.tables.remove(oldTableName);
    acu.tables.put(newTableName, t);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,134,137,"@Override
public Iterable<Entry<String, String>> getProperties(String tableName) throws TableNotFoundException {
    return acu.tables.get(tableName).settings.entrySet();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,139,140,"@Override
public void setLocalityGroups(String tableName, Map<String, Set<Text>> groups) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,142,145,"@Override
public Map<String, Set<Text>> getLocalityGroups(String tableName) throws AccumuloException, TableNotFoundException {
    return null;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,165,166,"@Override
public void offline(String tableName) throws AccumuloSecurityException, AccumuloException {
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_46f62443,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,171,172,"@Override
public void clearLocatorCache(String tableName) throws TableNotFoundException {
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsHelper.java,48,62,"@Override
public void removeIterator(String tableName, String name, EnumSet<IteratorScope> scopes) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {
    Map<String, String> copy = new HashMap<String, String>();
    for (Entry<String, String> property : this.getProperties(tableName)) {
        copy.put(property.getKey(), property.getValue());
    }
    for (IteratorScope scope : scopes) {
        String root = String.format(""%s%s.%s"", Property.TABLE_ITERATOR_PREFIX, scope.name().toLowerCase(), name);
        for (Entry<String, String> property : copy.entrySet()) {
            if (property.getKey().equals(root) || property.getKey().startsWith(root + "".opt.""))
                this.removeProperty(tableName, property.getKey());
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsHelper.java,64,89,"@Override
public IteratorSetting getIteratorSetting(String tableName, String name, IteratorScope scope) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {
    int priority = -1;
    String classname = null;
    Map<String, String> settings = new HashMap<String, String>();
    String root = String.format(""%s%s.%s"", Property.TABLE_ITERATOR_PREFIX, scope.name().toLowerCase(), name);
    String opt = root + "".opt."";
    for (Entry<String, String> property : this.getProperties(tableName)) {
        if (property.getKey().equals(root)) {
            String[] parts = property.getValue().split("","");
            if (parts.length != 2) {
                throw new AccumuloException(""Bad value for iterator setting: "" + property.getValue());
            }
            priority = Integer.parseInt(parts[0]);
            classname = parts[1];
        } else if (property.getKey().startsWith(opt)) {
            settings.put(property.getKey().substring(opt.length()), property.getValue());
        }
    }
    if (priority <= 0 || classname == null) {
        return null;
    }
    return new IteratorSetting(priority, name, classname, EnumSet.of(scope), settings);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsHelper.java,91,106,"@Override
public Set<String> listIterators(String tableName) throws AccumuloSecurityException, AccumuloException, TableNotFoundException {
    Set<String> result = new HashSet<String>();
    Set<String> lifecycles = new HashSet<String>();
    for (IteratorScope scope : IteratorScope.values()) lifecycles.add(scope.name().toLowerCase());
    for (Entry<String, String> property : this.getProperties(tableName)) {
        String name = property.getKey();
        String[] parts = name.split(""\\."");
        if (parts.length == 4) {
            if (parts[0].equals(""table"") && parts[1].equals(""iterator"") && lifecycles.contains(parts[2]))
                result.add(parts[3]);
        }
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsHelper.java,108,137,"@Override
public void checkIteratorConflicts(String tableName, IteratorSetting setting) throws AccumuloException, TableNotFoundException {
    for (IteratorScope scope : setting.getScopes()) {
        String scopeStr = String.format(""%s%s"", Property.TABLE_ITERATOR_PREFIX, scope.name().toLowerCase());
        String nameStr = String.format(""%s.%s"", scopeStr, setting.getName());
        String optStr = String.format(""%s.opt."", nameStr);
        Map<String, String> optionConflicts = new TreeMap<String, String>();
        for (Entry<String, String> property : this.getProperties(tableName)) {
            if (property.getKey().startsWith(scopeStr)) {
                if (property.getKey().equals(nameStr))
                    throw new IllegalArgumentException(""iterator name conflict for "" + setting.getName() + "": "" + property.getKey() + ""="" + property.getValue());
                if (property.getKey().startsWith(optStr))
                    optionConflicts.put(property.getKey(), property.getValue());
                if (property.getKey().contains("".opt.""))
                    continue;
                String[] parts = property.getValue().split("","");
                if (parts.length != 2)
                    throw new AccumuloException(""Bad value for existing iterator setting: "" + property.getKey() + ""="" + property.getValue());
                try {
                    if (Integer.parseInt(parts[0]) == setting.getPriority())
                        throw new IllegalArgumentException(""iterator priority conflict: "" + property.getKey() + ""="" + property.getValue());
                } catch (NumberFormatException e) {
                    throw new AccumuloException(""Bad value for existing iterator setting: "" + property.getKey() + ""="" + property.getValue());
                }
            }
        }
        if (optionConflicts.size() > 0)
            throw new IllegalArgumentException(""iterator options conflict for "" + setting.getName() + "": "" + optionConflicts);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,80,86,"@Override
public void create(String tableName, boolean versioningIter, TimeType timeType) throws AccumuloException, AccumuloSecurityException, TableExistsException {
    if (!tableName.matches(Constants.VALID_TABLE_NAME_REGEX)) {
        throw new IllegalArgumentException();
    }
    acu.createTable(username, tableName, versioningIter, timeType);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,91,95,"/**
 * @deprecated since 1.4 {@link #attachIterator(String, IteratorSetting)}
 */
@Override
public void addAggregators(String tableName, List<? extends PerColumnIteratorConfig> aggregators) throws AccumuloSecurityException, TableNotFoundException, AccumuloException {
    acu.addAggregators(tableName, aggregators);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,97,98,"@Override
public void addSplits(String tableName, SortedSet<Text> partitionKeys) throws TableNotFoundException, AccumuloException, AccumuloSecurityException {
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,100,103,"@Override
public Collection<Text> getSplits(String tableName) {
    return Collections.emptyList();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,105,108,"@Override
public Collection<Text> getSplits(String tableName, int maxSplits) {
    return Collections.emptyList();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,110,113,"@Override
public void delete(String tableName) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
    acu.tables.remove(tableName);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,115,120,"@Override
public void rename(String oldTableName, String newTableName) throws AccumuloSecurityException, TableNotFoundException, AccumuloException, TableExistsException {
    MockTable t = acu.tables.remove(oldTableName);
    acu.tables.put(newTableName, t);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,135,138,"@Override
public Iterable<Entry<String, String>> getProperties(String tableName) throws TableNotFoundException {
    return acu.tables.get(tableName).settings.entrySet();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,140,141,"@Override
public void setLocalityGroups(String tableName, Map<String, Set<Text>> groups) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,143,146,"@Override
public Map<String, Set<Text>> getLocalityGroups(String tableName) throws AccumuloException, TableNotFoundException {
    return null;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,166,167,"@Override
public void offline(String tableName) throws AccumuloSecurityException, AccumuloException {
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-217_add180fb,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,172,173,"@Override
public void clearLocatorCache(String tableName) throws TableNotFoundException {
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-218_15476a0d,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTable.java,64,79,"@Override
public int compareTo(Key o) {
    int compare = super.compareTo(o);
    if (compare != 0)
        return compare;
    if (o instanceof MockMemKey) {
        MockMemKey other = (MockMemKey) o;
        if (count < other.count)
            return -1;
        if (count > other.count)
            return 1;
    } else {
        return 1;
    }
    return 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-218_3d55560a,Major,src/core/src/main/java/org/apache/accumulo/core/client/mock/MockTable.java,64,79,"@Override
public int compareTo(Key o) {
    int compare = super.compareTo(o);
    if (compare != 0)
        return compare;
    if (o instanceof MockMemKey) {
        MockMemKey other = (MockMemKey) o;
        if (count < other.count)
            return -1;
        if (count > other.count)
            return 1;
    } else {
        return 1;
    }
    return 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2390_28294266,Major,src/trace/src/main/java/org/apache/accumulo/cloudtrace/instrument/TraceProxy.java,37,57,"@SuppressWarnings(""unchecked"")
public static <T> T trace(final T instance, final Sampler sampler) {
    InvocationHandler handler = new InvocationHandler() {

        @Override
        public Object invoke(Object obj, Method method, Object[] args) throws Throwable {
            if (!sampler.next()) {
                return method.invoke(instance, args);
            }
            Span span = Trace.on(method.getName());
            try {
                return method.invoke(instance, args);
            } catch (Throwable ex) {
                ex.printStackTrace();
                throw ex;
            } finally {
                span.stop();
            }
        }
    };
    return (T) Proxy.newProxyInstance(instance.getClass().getClassLoader(), instance.getClass().getInterfaces(), handler);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2390_28294266,Major,src/trace/src/main/java/org/apache/accumulo/cloudtrace/instrument/TraceProxy.java,40,54,"@Override
public Object invoke(Object obj, Method method, Object[] args) throws Throwable {
    if (!sampler.next()) {
        return method.invoke(instance, args);
    }
    Span span = Trace.on(method.getName());
    try {
        return method.invoke(instance, args);
    } catch (Throwable ex) {
        ex.printStackTrace();
        throw ex;
    } finally {
        span.stop();
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2487_f2920c26,Critical,core/src/main/java/org/apache/accumulo/core/data/Value.java,111,116,"/**
 * Get the data from the BytesWritable.
 *
 * @return The data is only valid between 0 and getSize() - 1.
 */
public byte[] get() {
    if (this.value == null) {
        throw new IllegalStateException(""Uninitialized. Null constructor "" + ""called w/o accompanying readFields invocation"");
    }
    return this.value;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2487_f2920c26,Critical,core/src/main/java/org/apache/accumulo/core/data/Value.java,122,124,"/**
 * @param b
 *          Use passed bytes as backing array for this instance.
 */
public void set(final byte[] b) {
    this.value = b;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2487_f2920c26,Critical,core/src/main/java/org/apache/accumulo/core/data/Value.java,131,134,"/**
 * @param b
 *          copy bytes
 */
public void copy(byte[] b) {
    this.value = new byte[b.length];
    System.arraycopy(b, 0, this.value, 0, b.length);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2487_f2920c26,Critical,core/src/main/java/org/apache/accumulo/core/data/Value.java,139,144,"/**
 * @return the current size of the buffer.
 */
public int getSize() {
    if (this.value == null) {
        throw new IllegalStateException(""Uninitialized. Null constructor "" + ""called w/o accompanying readFields invocation"");
    }
    return this.value.length;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2494_0dc92ca1,Major,core/src/main/java/org/apache/accumulo/core/util/Stat.java,27,38,"public void addStat(long stat) {
    if (stat > max)
        max = stat;
    if (stat < min)
        min = stat;
    sum += stat;
    partialStdDev += stat * stat;
    count++;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2494_0dc92ca1,Major,core/src/main/java/org/apache/accumulo/core/util/Stat.java,40,42,"public long getMin() {
    return min;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2494_0dc92ca1,Major,core/src/main/java/org/apache/accumulo/core/util/Stat.java,44,46,"public long getMax() {
    return max;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2494_0dc92ca1,Major,core/src/main/java/org/apache/accumulo/core/util/Stat.java,48,50,"public double getAverage() {
    return ((double) sum) / count;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2494_0dc92ca1,Major,core/src/main/java/org/apache/accumulo/core/util/Stat.java,52,54,"public double getStdDev() {
    return Math.sqrt(partialStdDev / count - getAverage() * getAverage());
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2494_0dc92ca1,Major,core/src/main/java/org/apache/accumulo/core/util/Stat.java,56,58,"public String toString() {
    return String.format(""%,d %,d %,.2f %,d"", getMin(), getMax(), getAverage(), count);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2494_0dc92ca1,Major,core/src/main/java/org/apache/accumulo/core/util/Stat.java,60,64,"public void clear() {
    sum = 0;
    count = 0;
    partialStdDev = 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2494_0dc92ca1,Major,core/src/main/java/org/apache/accumulo/core/util/Stat.java,66,68,"public long getSum() {
    return sum;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2520_a64151e6,Critical,server/gc/src/main/java/org/apache/accumulo/gc/GarbageCollectionAlgorithm.java,54,108,"private String makeRelative(String path, int expectedLen) {
    String relPath = path;
    if (relPath.startsWith(""../""))
        relPath = relPath.substring(3);
    while (relPath.endsWith(""/"")) relPath = relPath.substring(0, relPath.length() - 1);
    while (relPath.startsWith(""/"")) relPath = relPath.substring(1);
    String[] tokens = relPath.split(""/"");
    // handle paths like a//b///c
    boolean containsEmpty = false;
    for (String token : tokens) {
        if (token.equals("""")) {
            containsEmpty = true;
            break;
        }
    }
    if (containsEmpty) {
        ArrayList<String> tmp = new ArrayList<String>();
        for (String token : tokens) {
            if (!token.equals("""")) {
                tmp.add(token);
            }
        }
        tokens = tmp.toArray(new String[tmp.size()]);
    }
    if (tokens.length > 3) {
        if (!path.contains("":""))
            throw new IllegalArgumentException(path);
        if (tokens[tokens.length - 4].equals(ServerConstants.TABLE_DIR) && (expectedLen == 0 || expectedLen == 3)) {
            relPath = tokens[tokens.length - 3] + ""/"" + tokens[tokens.length - 2] + ""/"" + tokens[tokens.length - 1];
        } else if (tokens[tokens.length - 3].equals(ServerConstants.TABLE_DIR) && (expectedLen == 0 || expectedLen == 2)) {
            relPath = tokens[tokens.length - 2] + ""/"" + tokens[tokens.length - 1];
        } else {
            throw new IllegalArgumentException(path);
        }
    } else if (tokens.length == 3 && (expectedLen == 0 || expectedLen == 3)) {
        relPath = tokens[0] + ""/"" + tokens[1] + ""/"" + tokens[2];
    } else if (tokens.length == 2 && (expectedLen == 0 || expectedLen == 2)) {
        relPath = tokens[0] + ""/"" + tokens[1];
    } else {
        throw new IllegalArgumentException(path);
    }
    return relPath;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2520_a64151e6,Critical,server/gc/src/main/java/org/apache/accumulo/gc/GarbageCollectionAlgorithm.java,110,120,"private SortedMap<String, String> makeRelative(Collection<String> candidates) {
    SortedMap<String, String> ret = new TreeMap<String, String>();
    for (String candidate : candidates) {
        String relPath = makeRelative(candidate, 0);
        ret.put(relPath, candidate);
    }
    return ret;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2544_7ec60f1b,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,312,319,"@Override
public void deleteRows(String tableName, Text start, Text end) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
    if (!exists(tableName))
        throw new TableNotFoundException(tableName, tableName, """");
    MockTable t = acu.tables.get(tableName);
    Set<Key> keep = new TreeSet<Key>(t.table.tailMap(new Key(start)).headMap(new Key(end)).keySet());
    t.table.keySet().removeAll(keep);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2659_019edb16,Blocker,core/src/main/java/org/apache/accumulo/core/client/mapred/InputFormatBase.java,317,328,"@Override
protected void setupIterators(JobConf job, Scanner scanner, String tableName, org.apache.accumulo.core.client.mapred.RangeInputSplit split) {
    List<IteratorSetting> iterators = null;
    if (null == split) {
        iterators = getIterators(job);
    } else {
        iterators = split.getIterators();
    }
    setupIterators(iterators, scanner);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2671_17344890,Major,core/src/main/java/org/apache/accumulo/core/security/crypto/BlockedOutputStream.java,73,84,"@Override
public void write(byte[] b, int off, int len) throws IOException {
    if (bb.remaining() >= len) {
        bb.put(b, off, len);
        if (bb.remaining() == 0)
            flush();
    } else {
        int remaining = bb.remaining();
        write(b, off, remaining);
        write(b, off + remaining, len - remaining);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2713_6138a80f,Blocker,core/src/main/java/org/apache/accumulo/core/security/crypto/CryptoModuleFactory.java,257,264,"public static CryptoModuleParameters fillParamsObjectFromConfiguration(CryptoModuleParameters params, AccumuloConfiguration conf) {
    // Get all the options from the configuration
    Map<String, String> cryptoOpts = conf.getAllPropertiesWithPrefix(Property.CRYPTO_PREFIX);
    cryptoOpts.putAll(conf.getAllPropertiesWithPrefix(Property.INSTANCE_PREFIX));
    cryptoOpts.put(Property.CRYPTO_BLOCK_STREAM_SIZE.getKey(), Integer.toString((int) conf.getMemoryInBytes(Property.CRYPTO_BLOCK_STREAM_SIZE)));
    return fillParamsObjectFromStringMap(params, cryptoOpts);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2742_1f7dd2d5,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/HistoryCommand.java,36,47,"@SuppressWarnings(""unchecked"")
@Override
public int execute(final String fullCommand, final CommandLine cl, final Shell shellState) throws IOException {
    if (cl.hasOption(clearHist.getOpt())) {
        shellState.getReader().getHistory().clear();
    } else {
        ListIterator<Entry> it = shellState.getReader().getHistory().entries();
        shellState.printLines(new HistoryLineIterator(it), !cl.hasOption(disablePaginationOpt.getOpt()));
    }
    return 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2742_1f7dd2d5,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/HistoryCommand.java,57,60,"@Override
public String next() {
    return super.next().toString();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2748_ff8c2383,Critical,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,312,323,"@Override
public void deleteRows(String tableName, Text start, Text end) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
    if (!exists(tableName))
        throw new TableNotFoundException(tableName, tableName, """");
    MockTable t = acu.tables.get(tableName);
    Text startText = new Text(start);
    Text endText = new Text(end);
    startText.append(ZERO, 0, 1);
    endText.append(ZERO, 0, 1);
    Set<Key> keep = new TreeSet<Key>(t.table.subMap(new Key(startText), new Key(endText)).keySet());
    t.table.keySet().removeAll(keep);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2857_9fcca2ed,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockAccumulo.java,78,82,"public void createTable(String username, String tableName, boolean useVersions, TimeType timeType) {
    MockTable t = new MockTable(useVersions, timeType);
    t.userPermissions.put(username, EnumSet.allOf(TablePermission.class));
    tables.put(tableName, t);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2857_9fcca2ed,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,296,303,"@Override
public Map<String, String> tableIdMap() {
    Map<String, String> result = new HashMap<String, String>();
    for (String table : acu.tables.keySet()) {
        result.put(table, table);
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2899_31aea2ad,Blocker,server/base/src/main/java/org/apache/accumulo/server/fs/VolumeManagerImpl.java,530,543,"@Override
public Path getFullPath(FileType fileType, String path) {
    if (path.contains("":""))
        return new Path(path);
    // normalize the path
    Path fullPath = new Path(defaultVolume.getBasePath(), fileType.getDirectory());
    if (path.startsWith(""/""))
        path = path.substring(1);
    fullPath = new Path(fullPath, path);
    FileSystem fs = getVolumeByPath(fullPath).getFileSystem();
    return fs.makeQualified(fullPath);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2899_31aea2ad,Blocker,server/base/src/main/java/org/apache/accumulo/server/master/recovery/RecoveryPath.java,31,54,"// given a wal path, transform it to a recovery path
public static Path getRecoveryPath(VolumeManager fs, Path walPath) throws IOException {
    if (walPath.depth() >= 3 && walPath.toUri().getScheme() != null) {
        // its a fully qualified path
        String uuid = walPath.getName();
        // drop uuid
        walPath = walPath.getParent();
        // drop server
        walPath = walPath.getParent();
        if (!walPath.getName().equals(FileType.WAL.getDirectory()))
            throw new IllegalArgumentException(""Bad path "" + walPath);
        // drop wal
        walPath = walPath.getParent();
        walPath = new Path(walPath, FileType.RECOVERY.getDirectory());
        walPath = new Path(walPath, uuid);
        return walPath;
    }
    throw new IllegalArgumentException(""Bad path "" + walPath);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2899_31aea2ad,Blocker,server/gc/src/main/java/org/apache/accumulo/gc/GarbageCollectWriteAheadLogs.java,277,299,"private int removeMetadataEntries(Map<String, Path> nameToFileMap, Map<String, Path> sortedWALogs, GCStatus status) throws IOException, KeeperException, InterruptedException {
    int count = 0;
    Iterator<LogEntry> iterator = MetadataTableUtil.getLogEntries(SystemCredentials.get());
    while (iterator.hasNext()) {
        for (String entry : iterator.next().logSet) {
            String uuid = new Path(entry).getName();
            if (!isUUID(uuid)) {
                // fully expect this to be a uuid, if its not then something is wrong and walog GC should not proceed!
                throw new IllegalArgumentException(""Expected uuid, but got "" + uuid + "" from "" + entry);
            }
            Path pathFromNN = nameToFileMap.remove(uuid);
            if (pathFromNN != null) {
                status.currentLog.inUse++;
                sortedWALogs.remove(uuid);
            }
            count++;
        }
    }
    return count;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2899_31aea2ad,Blocker,server/gc/src/main/java/org/apache/accumulo/gc/GarbageCollectWriteAheadLogs.java,305,349,"// TODO Remove deprecation warning suppression when Hadoop1 support is dropped
@SuppressWarnings(""deprecation"")
/**
 * Scans write-ahead log directories for logs. The maps passed in are
 * populated with scan information.
 *
 * @param walDirs write-ahead log directories
 * @param fileToServerMap map of file paths to servers
 * @param nameToFileMap map of file names to paths
 * @return number of servers located (including those with no logs present)
 */
int scanServers(String[] walDirs, Map<Path, String> fileToServerMap, Map<String, Path> nameToFileMap) throws Exception {
    Set<String> servers = new HashSet<String>();
    for (String walDir : walDirs) {
        Path walRoot = new Path(walDir);
        FileStatus[] listing = null;
        try {
            listing = fs.listStatus(walRoot);
        } catch (FileNotFoundException e) {
        // ignore dir
        }
        if (listing == null)
            continue;
        for (FileStatus status : listing) {
            String server = status.getPath().getName();
            servers.add(server);
            if (status.isDir()) {
                for (FileStatus file : fs.listStatus(new Path(walRoot, server))) {
                    if (isUUID(file.getPath().getName())) {
                        fileToServerMap.put(file.getPath(), server);
                        nameToFileMap.put(file.getPath().getName(), file.getPath());
                    } else {
                        log.info(""Ignoring file "" + file.getPath() + "" because it doesn't look like a uuid"");
                    }
                }
            } else if (isUUID(server)) {
                // old-style WAL are not under a directory
                fileToServerMap.put(status.getPath(), """");
            } else {
                log.info(""Ignoring file "" + status.getPath() + "" because it doesn't look like a uuid"");
            }
        }
    }
    return servers.size();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2899_31aea2ad,Blocker,server/tserver/src/main/java/org/apache/accumulo/tserver/Tablet.java,3649,3688,"private Set<String> beginClearingUnusedLogs() {
    Set<String> doomed = new HashSet<String>();
    ArrayList<String> otherLogsCopy = new ArrayList<String>();
    ArrayList<String> currentLogsCopy = new ArrayList<String>();
    // do not hold tablet lock while acquiring the log lock
    logLock.lock();
    synchronized (this) {
        if (removingLogs)
            throw new IllegalStateException(""Attempted to clear logs when removal of logs in progress"");
        for (DfsLogger logger : otherLogs) {
            otherLogsCopy.add(logger.toString());
            doomed.add(logger.toString());
        }
        for (DfsLogger logger : currentLogs) {
            currentLogsCopy.add(logger.toString());
            doomed.remove(logger.toString());
        }
        otherLogs = Collections.emptySet();
        if (doomed.size() > 0)
            removingLogs = true;
    }
    // do debug logging outside tablet lock
    for (String logger : otherLogsCopy) {
        log.debug(""Logs for memory compacted: "" + getExtent() + "" "" + logger.toString());
    }
    for (String logger : currentLogsCopy) {
        log.debug(""Logs for current memory: "" + getExtent() + "" "" + logger);
    }
    return doomed;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2899_31aea2ad,Blocker,server/tserver/src/main/java/org/apache/accumulo/tserver/log/DfsLogger.java,310,393,"public synchronized void open(String address) throws IOException {
    String filename = UUID.randomUUID().toString();
    String logger = StringUtil.join(Arrays.asList(address.split("":"")), ""+"");
    log.debug(""DfsLogger.open() begin"");
    VolumeManager fs = conf.getFileSystem();
    logPath = fs.choose(ServerConstants.getWalDirs()) + ""/"" + logger + ""/"" + filename;
    try {
        short replication = (short) conf.getConfiguration().getCount(Property.TSERV_WAL_REPLICATION);
        if (replication == 0)
            replication = fs.getDefaultReplication(new Path(logPath));
        long blockSize = conf.getConfiguration().getMemoryInBytes(Property.TSERV_WAL_BLOCKSIZE);
        if (blockSize == 0)
            blockSize = (long) (conf.getConfiguration().getMemoryInBytes(Property.TSERV_WALOG_MAX_SIZE) * 1.1);
        if (conf.getConfiguration().getBoolean(Property.TSERV_WAL_SYNC))
            logFile = fs.createSyncable(new Path(logPath), 0, replication, blockSize);
        else
            logFile = fs.create(new Path(logPath), true, 0, replication, blockSize);
        String syncMethod = conf.getConfiguration().get(Property.TSERV_WAL_SYNC_METHOD);
        try {
            // hsync: send data to datanodes and sync the data to disk
            sync = logFile.getClass().getMethod(syncMethod);
        } catch (Exception ex) {
            log.warn(""Could not find configured "" + syncMethod + "" method, trying to fall back to old Hadoop sync method"", ex);
            try {
                // sync: send data to datanodes
                sync = logFile.getClass().getMethod(""sync"");
            } catch (Exception e) {
                throw new RuntimeException(e);
            }
        }
        // Initialize the crypto operations.
        org.apache.accumulo.core.security.crypto.CryptoModule cryptoModule = org.apache.accumulo.core.security.crypto.CryptoModuleFactory.getCryptoModule(conf.getConfiguration().get(Property.CRYPTO_MODULE_CLASS));
        // Initialize the log file with a header and the crypto params used to set up this log file.
        logFile.write(LOG_FILE_HEADER_V3.getBytes(Constants.UTF8));
        CryptoModuleParameters params = CryptoModuleFactory.createParamsObjectFromAccumuloConfiguration(conf.getConfiguration());
        NoFlushOutputStream nfos = new NoFlushOutputStream(logFile);
        params.setPlaintextOutputStream(nfos);
        // In order to bootstrap the reading of this file later, we have to record the CryptoModule that was used to encipher it here,
        // so that that crypto module can re-read its own parameters.
        logFile.writeUTF(conf.getConfiguration().get(Property.CRYPTO_MODULE_CLASS));
        params = cryptoModule.getEncryptingOutputStream(params);
        OutputStream encipheringOutputStream = params.getEncryptedOutputStream();
        // another data OutputStream.
        if (encipheringOutputStream == nfos) {
            log.debug(""No enciphering, using raw output stream"");
            encryptingLogFile = nfos;
        } else {
            log.debug(""Enciphering found, wrapping in DataOutputStream"");
            encryptingLogFile = new DataOutputStream(encipheringOutputStream);
        }
        LogFileKey key = new LogFileKey();
        key.event = OPEN;
        key.tserverSession = filename;
        key.filename = filename;
        write(key, EMPTY);
        sync.invoke(logFile);
        log.debug(""Got new write-ahead log: "" + this);
    } catch (Exception ex) {
        if (logFile != null)
            logFile.close();
        logFile = null;
        encryptingLogFile = null;
        throw new IOException(ex);
    }
    syncThread = new Daemon(new LoggingRunnable(log, new LogSyncingTask()));
    syncThread.setName(""Accumulo WALog thread "" + toString());
    syncThread.start();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2952_11d11e0d,Major,server/base/src/main/java/org/apache/accumulo/server/master/balancer/DefaultLoadBalancer.java,106,180,"public boolean getMigrations(Map<TServerInstance, TabletServerStatus> current, List<TabletMigration> result) {
    boolean moreBalancingNeeded = false;
    try {
        // no moves possible
        if (current.size() < 2) {
            return false;
        }
        final Map<String, Map<KeyExtent, TabletStats>> donerTabletStats = new HashMap<String, Map<KeyExtent, TabletStats>>();
        // Sort by total number of online tablets, per server
        int total = 0;
        ArrayList<ServerCounts> totals = new ArrayList<ServerCounts>();
        for (Entry<TServerInstance, TabletServerStatus> entry : current.entrySet()) {
            int serverTotal = 0;
            if (entry.getValue() != null && entry.getValue().tableMap != null) {
                for (Entry<String, TableInfo> e : entry.getValue().tableMap.entrySet()) {
                    /**
                     * The check below was on entry.getKey(), but that resolves to a tabletserver not a tablename. Believe it should be e.getKey() which is a tablename
                     */
                    if (tableToBalance == null || tableToBalance.equals(e.getKey()))
                        serverTotal += e.getValue().onlineTablets;
                }
            }
            totals.add(new ServerCounts(serverTotal, entry.getKey(), entry.getValue()));
            total += serverTotal;
        }
        // order from low to high
        Collections.sort(totals);
        Collections.reverse(totals);
        int even = total / totals.size();
        int numServersOverEven = total % totals.size();
        // Move tablets from the servers with too many to the servers with
        // the fewest but only nominate tablets to move once. This allows us
        // to fill new servers with tablets from a mostly balanced server
        // very quickly. However, it may take several balancing passes to move
        // tablets from one hugely overloaded server to many slightly
        // under-loaded servers.
        int end = totals.size() - 1;
        int movedAlready = 0;
        int tooManyIndex = 0;
        while (tooManyIndex < totals.size() && end > tooManyIndex) {
            ServerCounts tooMany = totals.get(tooManyIndex);
            int goal = even;
            if (tooManyIndex < numServersOverEven) {
                goal++;
            }
            int needToUnload = tooMany.count - goal;
            ServerCounts tooLittle = totals.get(end);
            int needToLoad = goal - tooLittle.count - movedAlready;
            if (needToUnload < 1 && needToLoad < 1) {
                break;
            }
            if (needToUnload >= needToLoad) {
                result.addAll(move(tooMany, tooLittle, needToLoad, donerTabletStats));
                end--;
                movedAlready = 0;
            } else {
                result.addAll(move(tooMany, tooLittle, needToUnload, donerTabletStats));
                movedAlready += needToUnload;
            }
            if (needToUnload > needToLoad) {
                moreBalancingNeeded = true;
            } else {
                tooManyIndex++;
                donerTabletStats.clear();
            }
        }
    } finally {
        log.debug(""balance ended with "" + result.size() + "" migrations"");
    }
    return moreBalancingNeeded;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2952_11d11e0d,Major,server/base/src/main/java/org/apache/accumulo/server/master/balancer/DefaultLoadBalancer.java,195,262,"/**
 * Select a tablet based on differences between table loads; if the loads are even, use the busiest table
 */
List<TabletMigration> move(ServerCounts tooMuch, ServerCounts tooLittle, int count, Map<String, Map<KeyExtent, TabletStats>> donerTabletStats) {
    List<TabletMigration> result = new ArrayList<TabletMigration>();
    if (count == 0)
        return result;
    // Copy counts so we can update them as we propose migrations
    Map<String, Integer> tooMuchMap = tabletCountsPerTable(tooMuch.status);
    Map<String, Integer> tooLittleMap = tabletCountsPerTable(tooLittle.status);
    for (int i = 0; i < count; i++) {
        String table;
        Integer tooLittleCount;
        if (tableToBalance == null) {
            // find a table to migrate
            // look for an uneven table count
            int biggestDifference = 0;
            String biggestDifferenceTable = null;
            for (Entry<String, Integer> tableEntry : tooMuchMap.entrySet()) {
                String tableID = tableEntry.getKey();
                if (tooLittleMap.get(tableID) == null)
                    tooLittleMap.put(tableID, 0);
                int diff = tableEntry.getValue() - tooLittleMap.get(tableID);
                if (diff > biggestDifference) {
                    biggestDifference = diff;
                    biggestDifferenceTable = tableID;
                }
            }
            if (biggestDifference < 2) {
                table = busiest(tooMuch.status.tableMap);
            } else {
                table = biggestDifferenceTable;
            }
        } else {
            // just balance the given table
            table = tableToBalance;
        }
        Map<KeyExtent, TabletStats> onlineTabletsForTable = donerTabletStats.get(table);
        try {
            if (onlineTabletsForTable == null) {
                onlineTabletsForTable = new HashMap<KeyExtent, TabletStats>();
                for (TabletStats stat : getOnlineTabletsForTable(tooMuch.server, table)) onlineTabletsForTable.put(new KeyExtent(stat.extent), stat);
                donerTabletStats.put(table, onlineTabletsForTable);
            }
        } catch (Exception ex) {
            log.error(""Unable to select a tablet to move"", ex);
            return result;
        }
        KeyExtent extent = selectTablet(tooMuch.server, onlineTabletsForTable);
        onlineTabletsForTable.remove(extent);
        if (extent == null)
            return result;
        tooMuchMap.put(table, tooMuchMap.get(table) - 1);
        /**
         * If a table grows from 1 tablet then tooLittleMap.get(table) can return a null, since there is only one tabletserver that holds all of the tablets. Here
         * we check to see if in fact that is the case and if so set the value to 0.
         */
        tooLittleCount = tooLittleMap.get(table);
        if (tooLittleCount == null) {
            tooLittleCount = 0;
        }
        tooLittleMap.put(table, tooLittleCount + 1);
        result.add(new TabletMigration(extent, tooMuch.server, tooLittle.server));
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2962_023be574,Critical,core/src/main/java/org/apache/accumulo/core/client/mapreduce/RangeInputSplit.java,144,210,"@Override
public void readFields(DataInput in) throws IOException {
    range.readFields(in);
    int numLocs = in.readInt();
    locations = new String[numLocs];
    for (int i = 0; i < numLocs; ++i) locations[i] = in.readUTF();
    if (in.readBoolean()) {
        isolatedScan = in.readBoolean();
    }
    if (in.readBoolean()) {
        offline = in.readBoolean();
    }
    if (in.readBoolean()) {
        localIterators = in.readBoolean();
    }
    if (in.readBoolean()) {
        mockInstance = in.readBoolean();
    }
    if (in.readBoolean()) {
        int numColumns = in.readInt();
        List<String> columns = new ArrayList<String>(numColumns);
        for (int i = 0; i < numColumns; i++) {
            columns.add(in.readUTF());
        }
        fetchedColumns = InputConfigurator.deserializeFetchedColumns(columns);
    }
    if (in.readBoolean()) {
        String strAuths = in.readUTF();
        auths = new Authorizations(strAuths.getBytes(Charset.forName(""UTF-8"")));
    }
    if (in.readBoolean()) {
        principal = in.readUTF();
    }
    if (in.readBoolean()) {
        String tokenClass = in.readUTF();
        byte[] base64TokenBytes = in.readUTF().getBytes(Charset.forName(""UTF-8""));
        byte[] tokenBytes = Base64.decodeBase64(base64TokenBytes);
        try {
            token = CredentialHelper.extractToken(tokenClass, tokenBytes);
        } catch (AccumuloSecurityException e) {
            throw new IOException(e);
        }
    }
    if (in.readBoolean()) {
        instanceName = in.readUTF();
    }
    if (in.readBoolean()) {
        zooKeepers = in.readUTF();
    }
    if (in.readBoolean()) {
        level = Level.toLevel(in.readInt());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2962_023be574,Critical,core/src/main/java/org/apache/accumulo/core/client/mapreduce/RangeInputSplit.java,212,282,"@Override
public void write(DataOutput out) throws IOException {
    range.write(out);
    out.writeInt(locations.length);
    for (int i = 0; i < locations.length; ++i) out.writeUTF(locations[i]);
    out.writeBoolean(null != isolatedScan);
    if (null != isolatedScan) {
        out.writeBoolean(isolatedScan);
    }
    out.writeBoolean(null != offline);
    if (null != offline) {
        out.writeBoolean(offline);
    }
    out.writeBoolean(null != localIterators);
    if (null != localIterators) {
        out.writeBoolean(localIterators);
    }
    out.writeBoolean(null != mockInstance);
    if (null != mockInstance) {
        out.writeBoolean(mockInstance);
    }
    out.writeBoolean(null != fetchedColumns);
    if (null != fetchedColumns) {
        String[] cols = InputConfigurator.serializeColumns(fetchedColumns);
        out.writeInt(cols.length);
        for (String col : cols) {
            out.writeUTF(col);
        }
    }
    out.writeBoolean(null != auths);
    if (null != auths) {
        out.writeUTF(auths.serialize());
    }
    out.writeBoolean(null != principal);
    if (null != principal) {
        out.writeUTF(principal);
    }
    out.writeBoolean(null != token);
    if (null != token) {
        out.writeUTF(token.getClass().getCanonicalName());
        try {
            out.writeUTF(CredentialHelper.tokenAsBase64(token));
        } catch (AccumuloSecurityException e) {
            throw new IOException(e);
        }
    }
    out.writeBoolean(null != instanceName);
    if (null != instanceName) {
        out.writeUTF(instanceName);
    }
    out.writeBoolean(null != zooKeepers);
    if (null != zooKeepers) {
        out.writeUTF(zooKeepers);
    }
    out.writeBoolean(null != level);
    if (null != level) {
        out.writeInt(level.toInt());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2962_2fd7633f,Critical,core/src/main/java/org/apache/accumulo/core/client/mapreduce/RangeInputSplit.java,144,210,"@Override
public void readFields(DataInput in) throws IOException {
    range.readFields(in);
    int numLocs = in.readInt();
    locations = new String[numLocs];
    for (int i = 0; i < numLocs; ++i) locations[i] = in.readUTF();
    if (in.readBoolean()) {
        isolatedScan = in.readBoolean();
    }
    if (in.readBoolean()) {
        offline = in.readBoolean();
    }
    if (in.readBoolean()) {
        localIterators = in.readBoolean();
    }
    if (in.readBoolean()) {
        mockInstance = in.readBoolean();
    }
    if (in.readBoolean()) {
        int numColumns = in.readInt();
        List<String> columns = new ArrayList<String>(numColumns);
        for (int i = 0; i < numColumns; i++) {
            columns.add(in.readUTF());
        }
        fetchedColumns = InputConfigurator.deserializeFetchedColumns(columns);
    }
    if (in.readBoolean()) {
        String strAuths = in.readUTF();
        auths = new Authorizations(strAuths.getBytes(Charset.forName(""UTF-8"")));
    }
    if (in.readBoolean()) {
        principal = in.readUTF();
    }
    if (in.readBoolean()) {
        String tokenClass = in.readUTF();
        byte[] base64TokenBytes = in.readUTF().getBytes(Charset.forName(""UTF-8""));
        byte[] tokenBytes = Base64.decodeBase64(base64TokenBytes);
        try {
            token = CredentialHelper.extractToken(tokenClass, tokenBytes);
        } catch (AccumuloSecurityException e) {
            throw new IOException(e);
        }
    }
    if (in.readBoolean()) {
        instanceName = in.readUTF();
    }
    if (in.readBoolean()) {
        zooKeepers = in.readUTF();
    }
    if (in.readBoolean()) {
        level = Level.toLevel(in.readInt());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2962_2fd7633f,Critical,core/src/main/java/org/apache/accumulo/core/client/mapreduce/RangeInputSplit.java,212,282,"@Override
public void write(DataOutput out) throws IOException {
    range.write(out);
    out.writeInt(locations.length);
    for (int i = 0; i < locations.length; ++i) out.writeUTF(locations[i]);
    out.writeBoolean(null != isolatedScan);
    if (null != isolatedScan) {
        out.writeBoolean(isolatedScan);
    }
    out.writeBoolean(null != offline);
    if (null != offline) {
        out.writeBoolean(offline);
    }
    out.writeBoolean(null != localIterators);
    if (null != localIterators) {
        out.writeBoolean(localIterators);
    }
    out.writeBoolean(null != mockInstance);
    if (null != mockInstance) {
        out.writeBoolean(mockInstance);
    }
    out.writeBoolean(null != fetchedColumns);
    if (null != fetchedColumns) {
        String[] cols = InputConfigurator.serializeColumns(fetchedColumns);
        out.writeInt(cols.length);
        for (String col : cols) {
            out.writeUTF(col);
        }
    }
    out.writeBoolean(null != auths);
    if (null != auths) {
        out.writeUTF(auths.serialize());
    }
    out.writeBoolean(null != principal);
    if (null != principal) {
        out.writeUTF(principal);
    }
    out.writeBoolean(null != token);
    if (null != token) {
        out.writeUTF(token.getClass().getCanonicalName());
        try {
            out.writeUTF(CredentialHelper.tokenAsBase64(token));
        } catch (AccumuloSecurityException e) {
            throw new IOException(e);
        }
    }
    out.writeBoolean(null != instanceName);
    if (null != instanceName) {
        out.writeUTF(instanceName);
    }
    out.writeBoolean(null != zooKeepers);
    if (null != zooKeepers) {
        out.writeUTF(zooKeepers);
    }
    out.writeBoolean(null != level);
    if (null != level) {
        out.writeInt(level.toInt());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2974_5eceb10e,Blocker,server/base/src/main/java/org/apache/accumulo/server/fs/VolumeManagerImpl.java,529,549,"@Override
public Path getFullPath(FileType fileType, String path) {
    int colon = path.indexOf(':');
    if (colon > -1) {
        // Check if this is really an absolute path or if this is a 1.4 style relative path for a WAL
        if (fileType == FileType.WAL && path.charAt(colon + 1) != '/') {
            path = path.substring(path.indexOf('/'));
        } else {
            return new Path(path);
        }
    }
    // normalize the path
    Path fullPath = new Path(defaultVolume.getBasePath(), fileType.getDirectory());
    if (path.startsWith(""/""))
        path = path.substring(1);
    fullPath = new Path(fullPath, path);
    FileSystem fs = getVolumeByPath(fullPath).getFileSystem();
    return fs.makeQualified(fullPath);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-2974_5eceb10e,Blocker,server/master/src/main/java/org/apache/accumulo/master/TabletGroupWatcher.java,475,552,"private void deleteTablets(MergeInfo info) throws AccumuloException {
    KeyExtent extent = info.getExtent();
    String targetSystemTable = extent.isMeta() ? RootTable.NAME : MetadataTable.NAME;
    Master.log.debug(""Deleting tablets for "" + extent);
    char timeType = '\0';
    KeyExtent followingTablet = null;
    if (extent.getEndRow() != null) {
        Key nextExtent = new Key(extent.getEndRow()).followingKey(PartialKey.ROW);
        followingTablet = getHighTablet(new KeyExtent(extent.getTableId(), nextExtent.getRow(), extent.getEndRow()));
        Master.log.debug(""Found following tablet "" + followingTablet);
    }
    try {
        Connector conn = this.master.getConnector();
        Text start = extent.getPrevEndRow();
        if (start == null) {
            start = new Text();
        }
        Master.log.debug(""Making file deletion entries for "" + extent);
        Range deleteRange = new Range(KeyExtent.getMetadataEntry(extent.getTableId(), start), false, KeyExtent.getMetadataEntry(extent.getTableId(), extent.getEndRow()), true);
        Scanner scanner = conn.createScanner(targetSystemTable, Authorizations.EMPTY);
        scanner.setRange(deleteRange);
        TabletsSection.ServerColumnFamily.DIRECTORY_COLUMN.fetch(scanner);
        TabletsSection.ServerColumnFamily.TIME_COLUMN.fetch(scanner);
        scanner.fetchColumnFamily(DataFileColumnFamily.NAME);
        scanner.fetchColumnFamily(TabletsSection.CurrentLocationColumnFamily.NAME);
        Set<FileRef> datafiles = new TreeSet<FileRef>();
        for (Entry<Key, Value> entry : scanner) {
            Key key = entry.getKey();
            if (key.compareColumnFamily(DataFileColumnFamily.NAME) == 0) {
                datafiles.add(new FileRef(this.master.fs, key));
                if (datafiles.size() > 1000) {
                    MetadataTableUtil.addDeleteEntries(extent, datafiles, SystemCredentials.get());
                    datafiles.clear();
                }
            } else if (TabletsSection.ServerColumnFamily.TIME_COLUMN.hasColumns(key)) {
                timeType = entry.getValue().toString().charAt(0);
            } else if (key.compareColumnFamily(TabletsSection.CurrentLocationColumnFamily.NAME) == 0) {
                throw new IllegalStateException(""Tablet "" + key.getRow() + "" is assigned during a merge!"");
            } else if (TabletsSection.ServerColumnFamily.DIRECTORY_COLUMN.hasColumns(key)) {
                datafiles.add(new FileRef(entry.getValue().toString(), this.master.fs.getFullPath(FileType.TABLE, entry.getValue().toString())));
                if (datafiles.size() > 1000) {
                    MetadataTableUtil.addDeleteEntries(extent, datafiles, SystemCredentials.get());
                    datafiles.clear();
                }
            }
        }
        MetadataTableUtil.addDeleteEntries(extent, datafiles, SystemCredentials.get());
        BatchWriter bw = conn.createBatchWriter(targetSystemTable, new BatchWriterConfig());
        try {
            deleteTablets(info, deleteRange, bw, conn);
        } finally {
            bw.close();
        }
        if (followingTablet != null) {
            Master.log.debug(""Updating prevRow of "" + followingTablet + "" to "" + extent.getPrevEndRow());
            bw = conn.createBatchWriter(targetSystemTable, new BatchWriterConfig());
            try {
                Mutation m = new Mutation(followingTablet.getMetadataEntry());
                TabletsSection.TabletColumnFamily.PREV_ROW_COLUMN.put(m, KeyExtent.encodePrevEndRow(extent.getPrevEndRow()));
                ChoppedColumnFamily.CHOPPED_COLUMN.putDelete(m);
                bw.addMutation(m);
                bw.flush();
            } finally {
                bw.close();
            }
        } else {
            // Recreate the default tablet to hold the end of the table
            Master.log.debug(""Recreating the last tablet to point to "" + extent.getPrevEndRow());
            String tdir = master.getFileSystem().choose(ServerConstants.getTablesDirs()) + ""/"" + extent.getTableId() + Constants.DEFAULT_TABLET_LOCATION;
            MetadataTableUtil.addTablet(new KeyExtent(extent.getTableId(), null, extent.getPrevEndRow()), tdir, SystemCredentials.get(), timeType, this.master.masterLock);
        }
    } catch (Exception ex) {
        throw new AccumuloException(ex);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3006_d6472040,Blocker,server/base/src/main/java/org/apache/accumulo/server/fs/VolumeManagerImpl.java,217,286,"protected void ensureSyncIsEnabled() {
    for (Entry<String, Volume> entry : getFileSystems().entrySet()) {
        final String volumeName = entry.getKey();
        FileSystem fs = entry.getValue().getFileSystem();
        if (ViewFSUtils.isViewFS(fs)) {
            try {
                FileSystem resolvedFs = ViewFSUtils.resolvePath(fs, new Path(""/"")).getFileSystem(fs.getConf());
                log.debug(""resolved "" + fs.getUri() + "" to "" + resolvedFs.getUri() + "" for sync check"");
                fs = resolvedFs;
            } catch (IOException e) {
                log.warn(""Failed to resolve "" + fs.getUri(), e);
            }
        }
        if (fs instanceof DistributedFileSystem) {
            final String DFS_DURABLE_SYNC = ""dfs.durable.sync"", DFS_SUPPORT_APPEND = ""dfs.support.append"";
            final String ticketMessage = ""See ACCUMULO-623 and ACCUMULO-1637 for more details."";
            // Check to make sure that we have proper defaults configured
            try {
                // If the default is off (0.20.205.x or 1.0.x)
                DFSConfigKeys configKeys = new DFSConfigKeys();
                // Can't use the final constant itself as Java will inline it at compile time
                Field dfsSupportAppendDefaultField = configKeys.getClass().getField(""DFS_SUPPORT_APPEND_DEFAULT"");
                boolean dfsSupportAppendDefaultValue = dfsSupportAppendDefaultField.getBoolean(configKeys);
                if (!dfsSupportAppendDefaultValue) {
                    // See if the user did the correct override
                    if (!fs.getConf().getBoolean(DFS_SUPPORT_APPEND, false)) {
                        String msg = ""Accumulo requires that dfs.support.append to true. "" + ticketMessage;
                        log.fatal(msg);
                        throw new RuntimeException(msg);
                    }
                }
            } catch (NoSuchFieldException e) {
            // If we can't find DFSConfigKeys.DFS_SUPPORT_APPEND_DEFAULT, the user is running
            // 1.1.x or 1.2.x. This is ok, though, as, by default, these versions have append/sync enabled.
            } catch (Exception e) {
                log.warn(""Error while checking for "" + DFS_SUPPORT_APPEND + "" on volume "" + volumeName + "". The user should ensure that Hadoop is configured to properly supports append and sync. "" + ticketMessage, e);
            }
            // This is a sign that someone is writing bad configuration.
            if (!fs.getConf().getBoolean(DFS_SUPPORT_APPEND, true) || !fs.getConf().getBoolean(DFS_DURABLE_SYNC, true)) {
                String msg = ""Accumulo requires that "" + DFS_SUPPORT_APPEND + "" and "" + DFS_DURABLE_SYNC + "" not be configured as false. "" + ticketMessage;
                log.fatal(msg);
                throw new RuntimeException(msg);
            }
            try {
                // Check DFSConfigKeys to see if DFS_DATANODE_SYNCONCLOSE_KEY exists (should be everything >=1.1.1 and the 0.23 line)
                Class<?> dfsConfigKeysClz = Class.forName(""org.apache.hadoop.hdfs.DFSConfigKeys"");
                dfsConfigKeysClz.getDeclaredField(""DFS_DATANODE_SYNCONCLOSE_KEY"");
                // Everything else
                if (!fs.getConf().getBoolean(""dfs.datanode.synconclose"", false)) {
                    log.warn(""dfs.datanode.synconclose set to false in hdfs-site.xml: data loss is possible on system reset or power loss"");
                }
            } catch (ClassNotFoundException ex) {
            // hadoop 1.0.X or hadoop 1.1.0
            } catch (SecurityException e) {
            // hadoop 1.0.X or hadoop 1.1.0
            } catch (NoSuchFieldException e) {
            // hadoop 1.0.X or hadoop 1.1.0
            }
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3006_d6472040,Blocker,server/base/src/main/java/org/apache/accumulo/server/fs/VolumeManagerImpl.java,403,422,"public static VolumeManager get(AccumuloConfiguration conf) throws IOException {
    final Map<String, Volume> volumes = new HashMap<String, Volume>();
    final Configuration hadoopConf = CachedConfiguration.getInstance();
    // The ""default"" Volume for Accumulo (in case no volumes are specified)
    for (String volumeUriOrDir : VolumeConfiguration.getVolumeUris(conf)) {
        if (volumeUriOrDir.equals(DEFAULT))
            // Cannot re-define the default volume
            throw new IllegalArgumentException();
        // We require a URI here, fail if it doesn't look like one
        if (volumeUriOrDir.contains("":"")) {
            volumes.put(volumeUriOrDir, VolumeConfiguration.create(new Path(volumeUriOrDir), hadoopConf));
        } else {
            throw new IllegalArgumentException(""Expected fully qualified URI for "" + Property.INSTANCE_VOLUMES.getKey() + "" got "" + volumeUriOrDir);
        }
    }
    return new VolumeManagerImpl(volumes, VolumeConfiguration.getDefaultVolume(hadoopConf, conf), conf);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3006_d6472040,Blocker,server/base/src/main/java/org/apache/accumulo/server/fs/VolumeManagerImpl.java,424,478,"@Override
public boolean isReady() throws IOException {
    for (Volume volume : getFileSystems().values()) {
        FileSystem fs = volume.getFileSystem();
        if (ViewFSUtils.isViewFS(fs)) {
            try {
                FileSystem resolvedFs = ViewFSUtils.resolvePath(fs, new Path(""/"")).getFileSystem(fs.getConf());
                log.debug(""resolved "" + fs.getUri() + "" to "" + resolvedFs.getUri() + "" for ready check"");
                fs = resolvedFs;
            } catch (IOException e) {
                log.warn(""Failed to resolve "" + fs.getUri(), e);
            }
        }
        if (!(fs instanceof DistributedFileSystem))
            continue;
        DistributedFileSystem dfs = (DistributedFileSystem) fs;
        // So this: if (!dfs.setSafeMode(SafeModeAction.SAFEMODE_GET))
        // Becomes this:
        Class<?> safeModeAction;
        try {
            // hadoop 2.0
            safeModeAction = Class.forName(""org.apache.hadoop.hdfs.protocol.HdfsConstants$SafeModeAction"");
        } catch (ClassNotFoundException ex) {
            // hadoop 1.0
            try {
                safeModeAction = Class.forName(""org.apache.hadoop.hdfs.protocol.FSConstants$SafeModeAction"");
            } catch (ClassNotFoundException e) {
                throw new RuntimeException(""Cannot figure out the right class for Constants"");
            }
        }
        Object get = null;
        for (Object obj : safeModeAction.getEnumConstants()) {
            if (obj.toString().equals(""SAFEMODE_GET""))
                get = obj;
        }
        if (get == null) {
            throw new RuntimeException(""cannot find SAFEMODE_GET"");
        }
        try {
            Method setSafeMode = dfs.getClass().getMethod(""setSafeMode"", safeModeAction);
            boolean inSafeMode = (Boolean) setSafeMode.invoke(dfs, get);
            if (inSafeMode) {
                return false;
            }
        } catch (IllegalArgumentException exception) {
            /* Send IAEs back as-is, so that those that wrap UnknownHostException can be handled in the same place as similar sources of failure. */
            throw exception;
        } catch (Exception ex) {
            throw new RuntimeException(""cannot find method setSafeMode"");
        }
    }
    return true;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3015_f848178e,Major,core/src/main/java/org/apache/accumulo/core/client/mapreduce/RangeInputSplit.java,144,218,"@Override
public void readFields(DataInput in) throws IOException {
    range.readFields(in);
    int numLocs = in.readInt();
    locations = new String[numLocs];
    for (int i = 0; i < numLocs; ++i) locations[i] = in.readUTF();
    if (in.readBoolean()) {
        isolatedScan = in.readBoolean();
    }
    if (in.readBoolean()) {
        offline = in.readBoolean();
    }
    if (in.readBoolean()) {
        localIterators = in.readBoolean();
    }
    if (in.readBoolean()) {
        mockInstance = in.readBoolean();
    }
    if (in.readBoolean()) {
        int numColumns = in.readInt();
        List<String> columns = new ArrayList<String>(numColumns);
        for (int i = 0; i < numColumns; i++) {
            columns.add(in.readUTF());
        }
        fetchedColumns = InputConfigurator.deserializeFetchedColumns(columns);
    }
    if (in.readBoolean()) {
        String strAuths = in.readUTF();
        auths = new Authorizations(strAuths.getBytes(Charset.forName(""UTF-8"")));
    }
    if (in.readBoolean()) {
        principal = in.readUTF();
    }
    if (in.readBoolean()) {
        String tokenClass = in.readUTF();
        byte[] base64TokenBytes = in.readUTF().getBytes(Charset.forName(""UTF-8""));
        byte[] tokenBytes = Base64.decodeBase64(base64TokenBytes);
        try {
            token = CredentialHelper.extractToken(tokenClass, tokenBytes);
        } catch (AccumuloSecurityException e) {
            throw new IOException(e);
        }
    }
    if (in.readBoolean()) {
        instanceName = in.readUTF();
    }
    if (in.readBoolean()) {
        zooKeepers = in.readUTF();
    }
    if (in.readBoolean()) {
        int numIterators = in.readInt();
        iterators = new ArrayList<IteratorSetting>(numIterators);
        for (int i = 0; i < numIterators; i++) {
            iterators.add(new IteratorSetting(in));
        }
    }
    if (in.readBoolean()) {
        level = Level.toLevel(in.readInt());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3015_f848178e,Major,core/src/main/java/org/apache/accumulo/core/client/mapreduce/RangeInputSplit.java,220,298,"@Override
public void write(DataOutput out) throws IOException {
    range.write(out);
    out.writeInt(locations.length);
    for (int i = 0; i < locations.length; ++i) out.writeUTF(locations[i]);
    out.writeBoolean(null != isolatedScan);
    if (null != isolatedScan) {
        out.writeBoolean(isolatedScan);
    }
    out.writeBoolean(null != offline);
    if (null != offline) {
        out.writeBoolean(offline);
    }
    out.writeBoolean(null != localIterators);
    if (null != localIterators) {
        out.writeBoolean(localIterators);
    }
    out.writeBoolean(null != mockInstance);
    if (null != mockInstance) {
        out.writeBoolean(mockInstance);
    }
    out.writeBoolean(null != fetchedColumns);
    if (null != fetchedColumns) {
        String[] cols = InputConfigurator.serializeColumns(fetchedColumns);
        out.writeInt(cols.length);
        for (String col : cols) {
            out.writeUTF(col);
        }
    }
    out.writeBoolean(null != auths);
    if (null != auths) {
        out.writeUTF(auths.serialize());
    }
    out.writeBoolean(null != principal);
    if (null != principal) {
        out.writeUTF(principal);
    }
    out.writeBoolean(null != token);
    if (null != token) {
        out.writeUTF(token.getClass().getCanonicalName());
        try {
            out.writeUTF(CredentialHelper.tokenAsBase64(token));
        } catch (AccumuloSecurityException e) {
            throw new IOException(e);
        }
    }
    out.writeBoolean(null != instanceName);
    if (null != instanceName) {
        out.writeUTF(instanceName);
    }
    out.writeBoolean(null != zooKeepers);
    if (null != zooKeepers) {
        out.writeUTF(zooKeepers);
    }
    out.writeBoolean(null != iterators);
    if (null != iterators) {
        out.writeInt(iterators.size());
        for (IteratorSetting iterator : iterators) {
            iterator.write(out);
        }
    }
    out.writeBoolean(null != level);
    if (null != level) {
        out.writeInt(level.toInt());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3055_94c2a31f,Critical,minicluster/src/main/java/org/apache/accumulo/minicluster/MiniAccumuloCluster.java,309,349,"/**
 * Starts Accumulo and Zookeeper processes. Can only be called once.
 *
 * @throws IllegalStateException
 *           if already started
 */
public void start() throws IOException, InterruptedException {
    if (zooKeeperProcess != null)
        throw new IllegalStateException(""Already started"");
    Runtime.getRuntime().addShutdownHook(new Thread() {

        @Override
        public void run() {
            try {
                MiniAccumuloCluster.this.stop();
            } catch (IOException e) {
                e.printStackTrace();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    });
    zooKeeperProcess = exec(Main.class, ZooKeeperServerMain.class.getName(), zooCfgFile.getAbsolutePath());
    // sleep a little bit to let zookeeper come up before calling init, seems to work better
    UtilWaitThread.sleep(250);
    Process initProcess = exec(Initialize.class, ""--instance-name"", INSTANCE_NAME, ""--password"", config.getRootPassword());
    int ret = initProcess.waitFor();
    if (ret != 0) {
        throw new RuntimeException(""Initialize process returned "" + ret + "". Check the logs in "" + logDir + "" for errors."");
    }
    tabletServerProcesses = new Process[config.getNumTservers()];
    for (int i = 0; i < config.getNumTservers(); i++) {
        tabletServerProcesses[i] = exec(TabletServer.class);
    }
    masterProcess = exec(Master.class);
    gcProcess = exec(SimpleGarbageCollector.class);
    if (null == executor) {
        executor = Executors.newSingleThreadExecutor();
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3055_94c2a31f,Critical,minicluster/src/main/java/org/apache/accumulo/minicluster/MiniAccumuloCluster.java,371,426,"/**
 * Stops Accumulo and Zookeeper processes. If stop is not called, there is a shutdown hook that is setup to kill the processes. Howerver its probably best to
 * call stop in a finally block as soon as possible.
 */
public void stop() throws IOException, InterruptedException {
    if (zooKeeperProcess != null) {
        try {
            stopProcessWithTimeout(zooKeeperProcess, 30, TimeUnit.SECONDS);
        } catch (ExecutionException e) {
            log.warn(""ZooKeeper did not fully stop after 30 seconds"", e);
        } catch (TimeoutException e) {
            log.warn(""ZooKeeper did not fully stop after 30 seconds"", e);
        }
    }
    if (masterProcess != null) {
        try {
            stopProcessWithTimeout(masterProcess, 30, TimeUnit.SECONDS);
        } catch (ExecutionException e) {
            log.warn(""Master did not fully stop after 30 seconds"", e);
        } catch (TimeoutException e) {
            log.warn(""Master did not fully stop after 30 seconds"", e);
        }
    }
    if (tabletServerProcesses != null) {
        for (Process tserver : tabletServerProcesses) {
            try {
                stopProcessWithTimeout(tserver, 30, TimeUnit.SECONDS);
            } catch (ExecutionException e) {
                log.warn(""TabletServer did not fully stop after 30 seconds"", e);
            } catch (TimeoutException e) {
                log.warn(""TabletServer did not fully stop after 30 seconds"", e);
            }
        }
    }
    for (LogWriter lw : logWriters) lw.flush();
    if (gcProcess != null) {
        try {
            stopProcessWithTimeout(gcProcess, 30, TimeUnit.SECONDS);
        } catch (ExecutionException e) {
            log.warn(""GarbageCollector did not fully stop after 30 seconds"", e);
        } catch (TimeoutException e) {
            log.warn(""GarbageCollector did not fully stop after 30 seconds"", e);
        }
    }
    // ACCUMULO-2985 stop the ExecutorService after we finished using it to stop accumulo procs
    if (null != executor) {
        List<Runnable> tasksRemaining = executor.shutdownNow();
        // the single thread executor shouldn't have any pending tasks, but check anyways
        if (!tasksRemaining.isEmpty()) {
            log.warn(""Unexpectedly had "" + tasksRemaining.size() + "" task(s) remaining in threadpool for execution when being stopped"");
        }
        executor = null;
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3055_94c2a31f,Critical,minicluster/src/main/java/org/apache/accumulo/minicluster/MiniAccumuloCluster.java,438,450,"private int stopProcessWithTimeout(final Process proc, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {
    FutureTask<Integer> future = new FutureTask<Integer>(new Callable<Integer>() {

        @Override
        public Integer call() throws InterruptedException {
            proc.destroy();
            return proc.waitFor();
        }
    });
    executor.execute(future);
    return future.get(timeout, unit);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3077_17654199,Critical,server/base/src/main/java/org/apache/accumulo/server/init/Initialize.java,109,111,"/**
 * Sets this class's ZooKeeper reader/writer.
 *
 * @param izoo
 *          reader/writer
 */
static void setZooReaderWriter(IZooReaderWriter izoo) {
    zoo = izoo;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3077_17654199,Critical,server/base/src/main/java/org/apache/accumulo/server/init/Initialize.java,118,120,"/**
 * Gets this class's ZooKeeper reader/writer.
 *
 * @return reader/writer
 */
static IZooReaderWriter getZooReaderWriter() {
    return zoo;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3077_17654199,Critical,server/base/src/main/java/org/apache/accumulo/server/init/Initialize.java,566,569,"protected static void initMetadataConfig() throws IOException {
    initMetadataConfig(RootTable.ID);
    initMetadataConfig(MetadataTable.ID);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3077_17654199,Critical,server/base/src/main/java/org/apache/accumulo/server/util/ReplicationTableUtil.java,81,83,"/**
 * For testing purposes only -- should not be called by server code
 * <p>
 * Allows mocking of a Writer for testing
 *
 * @param creds
 *          Credentials
 * @param writer
 *          A Writer to use for the given credentials
 */
protected static synchronized void addWriter(Credentials creds, Writer writer) {
    writers.put(creds, writer);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3077_17654199,Critical,server/base/src/main/java/org/apache/accumulo/server/util/ReplicationTableUtil.java,188,202,"/**
 * Write replication ingest entries for each provided file with the given {@link Status}.
 */
public static void updateFiles(Credentials creds, KeyExtent extent, Collection<String> files, Status stat) {
    if (log.isDebugEnabled()) {
        log.debug(""Updating replication for "" + extent + "" with "" + files + "" using "" + ProtobufUtil.toString(stat));
    }
    // TODO could use batch writer, would need to handle failure and retry like update does - ACCUMULO-1294
    if (files.isEmpty()) {
        return;
    }
    Value v = ProtobufUtil.toValue(stat);
    for (String file : files) {
        // TODO Can preclude this addition if the extent is for a table we don't need to replicate
        update(creds, createUpdateMutation(new Path(file), v, extent), extent);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3077_17654199,Critical,server/tserver/src/main/java/org/apache/accumulo/tserver/log/TabletServerLogger.java,243,353,"private int write(final Collection<CommitSession> sessions, boolean mincFinish, Writer writer) throws IOException {
    // Work very hard not to lock this during calls to the outside world
    int currentLogSet = logSetId.get();
    int seq = -1;
    int attempt = 1;
    boolean success = false;
    while (!success) {
        try {
            // get a reference to the loggers that no other thread can touch
            ArrayList<DfsLogger> copy = new ArrayList<DfsLogger>();
            currentLogSet = initializeLoggers(copy);
            if (currentLogSet == logSetId.get()) {
                for (CommitSession commitSession : sessions) {
                    if (commitSession.beginUpdatingLogsUsed(copy, mincFinish)) {
                        try {
                            // Scribble out a tablet definition and then write to the metadata table
                            defineTablet(commitSession);
                            if (currentLogSet == logSetId.get())
                                tserver.addLoggersToMetadata(copy, commitSession.getExtent(), commitSession.getLogId());
                        } finally {
                            commitSession.finishUpdatingLogsUsed();
                        }
                        // Need to release
                        KeyExtent extent = commitSession.getExtent();
                        if (ReplicationConfigurationUtil.isEnabled(extent, tserver.getTableConfiguration(extent))) {
                            Set<String> logs = new HashSet<String>();
                            for (DfsLogger logger : copy) {
                                logs.add(logger.getFileName());
                            }
                            Status status = StatusUtil.fileCreated(System.currentTimeMillis());
                            log.debug(""Writing "" + ProtobufUtil.toString(status) + "" to replication table for "" + logs);
                            // Got some new WALs, note this in the replication table
                            ReplicationTableUtil.updateFiles(SystemCredentials.get(), commitSession.getExtent(), logs, status);
                        }
                    }
                }
            }
            // Make sure that the logs haven't changed out from underneath our copy
            if (currentLogSet == logSetId.get()) {
                // write the mutation to the logs
                seq = seqGen.incrementAndGet();
                if (seq < 0)
                    throw new RuntimeException(""Logger sequence generator wrapped!  Onos!!!11!eleven"");
                ArrayList<LoggerOperation> queuedOperations = new ArrayList<LoggerOperation>(copy.size());
                for (DfsLogger wal : copy) {
                    LoggerOperation lop = writer.write(wal, seq);
                    if (lop != null)
                        queuedOperations.add(lop);
                }
                for (LoggerOperation lop : queuedOperations) {
                    lop.await();
                }
                // double-check: did the log set change?
                success = (currentLogSet == logSetId.get());
            }
        } catch (DfsLogger.LogClosedException ex) {
            log.debug(""Logs closed while writing, retrying "" + attempt);
        } catch (Exception t) {
            if (attempt != 1) {
                log.error(""Unexpected error writing to log, retrying attempt "" + attempt, t);
            }
            UtilWaitThread.sleep(100);
        } finally {
            attempt++;
        }
        // Some sort of write failure occurred. Grab the write lock and reset the logs.
        // But since multiple threads will attempt it, only attempt the reset when
        // the logs haven't changed.
        final int finalCurrent = currentLogSet;
        if (!success) {
            testLockAndRun(logSetLock, new TestCallWithWriteLock() {

                @Override
                boolean test() {
                    return finalCurrent == logSetId.get();
                }

                @Override
                void withWriteLock() throws IOException {
                    close();
                    closeForReplication(sessions);
                }
            });
        }
    }
    // if the log gets too big, reset it .. grab the write lock first
    // event, tid, seq overhead
    logSizeEstimate.addAndGet(4 * 3);
    testLockAndRun(logSetLock, new TestCallWithWriteLock() {

        @Override
        boolean test() {
            return logSizeEstimate.get() > maxSize;
        }

        @Override
        void withWriteLock() throws IOException {
            close();
            closeForReplication(sessions);
        }
    });
    return seq;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3077_17654199,Critical,server/tserver/src/main/java/org/apache/accumulo/tserver/tablet/DatafileManager.java,344,480,"void bringMinorCompactionOnline(FileRef tmpDatafile, FileRef newDatafile, FileRef absMergeFile, DataFileValue dfv, CommitSession commitSession, long flushId) throws IOException {
    IZooReaderWriter zoo = ZooReaderWriter.getRetryingInstance();
    if (tablet.getExtent().isRootTablet()) {
        try {
            if (!zoo.isLockHeld(tablet.getTabletServer().getLock().getLockID())) {
                throw new IllegalStateException();
            }
        } catch (Exception e) {
            throw new IllegalStateException(""Can not bring major compaction online, lock not held"", e);
        }
    }
    // always exist
    do {
        try {
            if (dfv.getNumEntries() == 0) {
                tablet.getTabletServer().getFileSystem().deleteRecursively(tmpDatafile.path());
            } else {
                if (tablet.getTabletServer().getFileSystem().exists(newDatafile.path())) {
                    log.warn(""Target map file already exist "" + newDatafile);
                    tablet.getTabletServer().getFileSystem().deleteRecursively(newDatafile.path());
                }
                rename(tablet.getTabletServer().getFileSystem(), tmpDatafile.path(), newDatafile.path());
            }
            break;
        } catch (IOException ioe) {
            log.warn(""Tablet "" + tablet.getExtent() + "" failed to rename "" + newDatafile + "" after MinC, will retry in 60 secs..."", ioe);
            UtilWaitThread.sleep(60 * 1000);
        }
    } while (true);
    long t1, t2;
    // the code below always assumes merged files are in use by scans... this must be done
    // because the in memory list of files is not updated until after the metadata table
    // therefore the file is available to scans until memory is updated, but want to ensure
    // the file is not available for garbage collection... if memory were updated
    // before this point (like major compactions do), then the following code could wait
    // for scans to finish like major compactions do.... used to wait for scans to finish
    // here, but that was incorrect because a scan could start after waiting but before
    // memory was updated... assuming the file is always in use by scans leads to
    // one uneeded metadata update when it was not actually in use
    Set<FileRef> filesInUseByScans = Collections.emptySet();
    if (absMergeFile != null)
        filesInUseByScans = Collections.singleton(absMergeFile);
    // this metadata write does not go up... it goes sideways or to itself
    if (absMergeFile != null)
        MetadataTableUtil.addDeleteEntries(tablet.getExtent(), Collections.singleton(absMergeFile), SystemCredentials.get());
    Set<String> unusedWalLogs = tablet.beginClearingUnusedLogs();
    boolean replicate = ReplicationConfigurationUtil.isEnabled(tablet.getExtent(), tablet.getTableConfiguration());
    Set<String> logFileOnly = null;
    if (replicate) {
        // unusedWalLogs is of the form host/fileURI, need to strip off the host portion
        logFileOnly = new HashSet<>();
        for (String unusedWalLog : unusedWalLogs) {
            int index = unusedWalLog.indexOf('/');
            if (-1 == index) {
                log.warn(""Could not find host component to strip from DFSLogger representation of WAL"");
            } else {
                unusedWalLog = unusedWalLog.substring(index + 1);
            }
            logFileOnly.add(unusedWalLog);
        }
    }
    try {
        // the order of writing to metadata and walog is important in the face of machine/process failures
        // need to write to metadata before writing to walog, when things are done in the reverse order
        // data could be lost... the minor compaction start even should be written before the following metadata
        // write is made
        tablet.updateTabletDataFile(commitSession.getMaxCommittedTime(), newDatafile, absMergeFile, dfv, unusedWalLogs, filesInUseByScans, flushId);
        // but it is *not* closed
        if (replicate) {
            ReplicationTableUtil.updateFiles(SystemCredentials.get(), tablet.getExtent(), logFileOnly, StatusUtil.openWithUnknownLength());
        }
    } finally {
        tablet.finishClearingUnusedLogs();
    }
    do {
        try {
            // the purpose of making this update use the new commit session, instead of the old one passed in,
            // is because the new one will reference the logs used by current memory...
            tablet.getTabletServer().minorCompactionFinished(tablet.getTabletMemory().getCommitSession(), newDatafile.toString(), commitSession.getWALogSeq() + 2);
            break;
        } catch (IOException e) {
            log.error(""Failed to write to write-ahead log "" + e.getMessage() + "" will retry"", e);
            UtilWaitThread.sleep(1 * 1000);
        }
    } while (true);
    synchronized (tablet) {
        t1 = System.currentTimeMillis();
        if (datafileSizes.containsKey(newDatafile)) {
            log.error(""Adding file that is already in set "" + newDatafile);
        }
        if (dfv.getNumEntries() > 0) {
            datafileSizes.put(newDatafile, dfv);
        }
        if (absMergeFile != null) {
            datafileSizes.remove(absMergeFile);
        }
        unreserveMergingMinorCompactionFile(absMergeFile);
        tablet.flushComplete(flushId);
        t2 = System.currentTimeMillis();
    }
    // must do this after list of files in memory is updated above
    removeFilesAfterScan(filesInUseByScans);
    if (absMergeFile != null)
        log.log(TLevel.TABLET_HIST, tablet.getExtent() + "" MinC ["" + absMergeFile + "",memory] -> "" + newDatafile);
    else
        log.log(TLevel.TABLET_HIST, tablet.getExtent() + "" MinC [memory] -> "" + newDatafile);
    log.debug(String.format(""MinC finish lock %.2f secs %s"", (t2 - t1) / 1000.0, tablet.getExtent().toString()));
    long splitSize = tablet.getTableConfiguration().getMemoryInBytes(Property.TABLE_SPLIT_THRESHOLD);
    if (dfv.getSize() > splitSize) {
        log.debug(String.format(""Minor Compaction wrote out file larger than split threshold.  split threshold = %,d  file size = %,d"", splitSize, dfv.getSize()));
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3143_ddd2c3bc,Critical,core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputTableConfig.java,250,284,"/**
 * Writes the state for the current object out to the specified {@link DataOutput}
 *
 * @param dataOutput
 *          the output for which to write the object's state
 */
@Override
public void write(DataOutput dataOutput) throws IOException {
    if (iterators != null) {
        dataOutput.writeInt(iterators.size());
        for (IteratorSetting setting : iterators) setting.write(dataOutput);
    } else {
        dataOutput.writeInt(0);
    }
    if (ranges != null) {
        dataOutput.writeInt(ranges.size());
        for (Range range : ranges) range.write(dataOutput);
    } else {
        dataOutput.writeInt(0);
    }
    if (columns != null) {
        dataOutput.writeInt(columns.size());
        for (Pair<Text, Text> column : columns) {
            if (column.getSecond() == null) {
                dataOutput.writeInt(1);
                column.getFirst().write(dataOutput);
            } else {
                dataOutput.writeInt(2);
                column.getFirst().write(dataOutput);
                column.getSecond().write(dataOutput);
            }
        }
    } else {
        dataOutput.writeInt(0);
    }
    dataOutput.writeBoolean(autoAdjustRanges);
    dataOutput.writeBoolean(useLocalIterators);
    dataOutput.writeBoolean(useIsolatedScanners);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3143_ddd2c3bc,Critical,core/src/main/java/org/apache/accumulo/core/client/mapreduce/InputTableConfig.java,292,328,"/**
 * Reads the fields in the {@link DataInput} into the current object
 *
 * @param dataInput
 *          the input fields to read into the current object
 */
@Override
public void readFields(DataInput dataInput) throws IOException {
    // load iterators
    long iterSize = dataInput.readInt();
    if (iterSize > 0)
        iterators = new ArrayList<IteratorSetting>();
    for (int i = 0; i < iterSize; i++) iterators.add(new IteratorSetting(dataInput));
    // load ranges
    long rangeSize = dataInput.readInt();
    if (rangeSize > 0)
        ranges = new ArrayList<Range>();
    for (int i = 0; i < rangeSize; i++) {
        Range range = new Range();
        range.readFields(dataInput);
        ranges.add(range);
    }
    // load columns
    long columnSize = dataInput.readInt();
    if (columnSize > 0)
        columns = new HashSet<Pair<Text, Text>>();
    for (int i = 0; i < columnSize; i++) {
        long numPairs = dataInput.readInt();
        Text colFam = new Text();
        colFam.readFields(dataInput);
        if (numPairs == 1) {
            columns.add(new Pair<Text, Text>(colFam, null));
        } else if (numPairs == 2) {
            Text colQual = new Text();
            colQual.readFields(dataInput);
            columns.add(new Pair<Text, Text>(colFam, colQual));
        }
    }
    autoAdjustRanges = dataInput.readBoolean();
    useLocalIterators = dataInput.readBoolean();
    useIsolatedScanners = dataInput.readBoolean();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3229_891584fb,Major,core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java,488,513,"public void printVerboseInfo() throws IOException {
    StringBuilder sb = new StringBuilder(""-\n"");
    sb.append(""- Current user: "").append(connector.whoami()).append(""\n"");
    if (execFile != null)
        sb.append(""- Executing commands from: "").append(execFile).append(""\n"");
    if (disableAuthTimeout)
        sb.append(""- Authorization timeout: disabled\n"");
    else
        sb.append(""- Authorization timeout: "").append(String.format(""%.2fs%n"", TimeUnit.NANOSECONDS.toSeconds(authTimeout)));
    sb.append(""- Debug: "").append(isDebuggingEnabled() ? ""on"" : ""off"").append(""\n"");
    if (!scanIteratorOptions.isEmpty()) {
        for (Entry<String, List<IteratorSetting>> entry : scanIteratorOptions.entrySet()) {
            sb.append(""- Session scan iterators for table "").append(entry.getKey()).append("":\n"");
            for (IteratorSetting setting : entry.getValue()) {
                sb.append(""-    Iterator "").append(setting.getName()).append("" options:\n"");
                sb.append(""-        "").append(""iteratorPriority"").append("" = "").append(setting.getPriority()).append(""\n"");
                sb.append(""-        "").append(""iteratorClassName"").append("" = "").append(setting.getIteratorClass()).append(""\n"");
                for (Entry<String, String> optEntry : setting.getOptions().entrySet()) {
                    sb.append(""-        "").append(optEntry.getKey()).append("" = "").append(optEntry.getValue()).append(""\n"");
                }
            }
        }
    }
    sb.append(""-\n"");
    reader.printString(sb.toString());
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3242_15e83709,Major,fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooCache.java,148,185,"private synchronized void retry(ZooRunnable op) {
    int sleepTime = 100;
    while (true) {
        ZooKeeper zooKeeper = getZooKeeper();
        try {
            op.run(zooKeeper);
            return;
        } catch (KeeperException e) {
            final Code code = e.code();
            if (code == Code.NONODE) {
                log.error(""Looked up non-existent node in cache "" + e.getPath(), e);
            } else if (code == Code.CONNECTIONLOSS || code == Code.OPERATIONTIMEOUT || code == Code.SESSIONEXPIRED) {
                log.warn(""Saw (possibly) transient exception communicating with ZooKeeper, wil retry"", e);
                continue;
            }
            log.warn(""Zookeeper error, will retry"", e);
        } catch (InterruptedException e) {
            log.info(""Zookeeper error, will retry"", e);
        } catch (ConcurrentModificationException e) {
            log.debug(""Zookeeper was modified, will retry"");
        }
        try {
            // do not hold lock while sleeping
            wait(sleepTime);
        } catch (InterruptedException e) {
            log.info(""Interrupted waiting before retrying ZooKeeper operation"", e);
        }
        if (sleepTime < 10000)
            sleepTime = (int) (sleepTime + sleepTime * Math.random());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3242_15e83709,Major,fate/src/main/java/org/apache/accumulo/fate/zookeeper/ZooUtil.java,309,354,"public static void recursiveCopyPersistent(ZooKeeperConnectionInfo info, String source, String destination, NodeExistsPolicy policy) throws KeeperException, InterruptedException {
    Stat stat = null;
    if (!exists(info, source))
        throw KeeperException.create(Code.NONODE, source);
    if (exists(info, destination)) {
        switch(policy) {
            case OVERWRITE:
                break;
            case SKIP:
                return;
            case FAIL:
            default:
                throw KeeperException.create(Code.NODEEXISTS, source);
        }
    }
    stat = new Stat();
    byte[] data = getData(info, source, stat);
    if (stat.getEphemeralOwner() == 0) {
        if (data == null)
            throw KeeperException.create(Code.NONODE, source);
        putPersistentData(info, destination, data, policy);
        if (stat.getNumChildren() > 0) {
            List<String> children;
            final Retry retry = RETRY_FACTORY.create();
            while (true) {
                try {
                    children = getZooKeeper(info).getChildren(source, false);
                    break;
                } catch (KeeperException e) {
                    final Code c = e.code();
                    if (c == Code.CONNECTIONLOSS || c == Code.OPERATIONTIMEOUT || c == Code.SESSIONEXPIRED) {
                        retryOrThrow(retry, e);
                    } else {
                        throw e;
                    }
                }
                retry.waitForNextAttempt();
            }
            for (String child : children) recursiveCopyPersistent(info, source + ""/"" + child, destination + ""/"" + child, policy);
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-334_9d8cc45d,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/AgeOffFilter.java,94,97,"@Override
public SortedKeyValueIterator<Key, Value> deepCopy(IteratorEnvironment env) {
    return new AgeOffFilter(getSource(), threshold, currentTime);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-334_9d8cc45d,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/ColumnAgeOffFilter.java,88,91,"@Override
public SortedKeyValueIterator<Key, Value> deepCopy(IteratorEnvironment env) {
    return new ColumnAgeOffFilter(getSource(), ttls, currentTime);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-334_9d8cc45d,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/RegExFilter.java,38,48,"@Override
public SortedKeyValueIterator<Key, Value> deepCopy(IteratorEnvironment env) {
    RegExFilter result = new RegExFilter();
    result.setSource(getSource().deepCopy(env));
    result.rowMatcher = copyMatcher(rowMatcher);
    result.colfMatcher = copyMatcher(colfMatcher);
    result.colqMatcher = copyMatcher(colqMatcher);
    result.valueMatcher = copyMatcher(valueMatcher);
    result.orFields = orFields;
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-334_9d8cc45d,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java,113,116,"@Override
public SortedKeyValueIterator<Key, Value> deepCopy(IteratorEnvironment env) {
    return new TimestampFilter(getSource(), hasStart, start, startInclusive, hasEnd, end, endInclusive);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-334_9d8cc45d,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/VersioningIterator.java,42,45,"@Override
public VersioningIterator deepCopy(IteratorEnvironment env) {
    return new VersioningIterator(this, env);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3383_97f16db4,Minor,start/src/main/java/org/apache/accumulo/start/classloader/vfs/AccumuloVFSClassLoader.java,247,291,"public static FileSystemManager generateVfs() throws FileSystemException {
    DefaultFileSystemManager vfs = new DefaultFileSystemManager();
    vfs.addProvider(""res"", new org.apache.commons.vfs2.provider.res.ResourceFileProvider());
    vfs.addProvider(""zip"", new org.apache.commons.vfs2.provider.zip.ZipFileProvider());
    vfs.addProvider(""gz"", new org.apache.commons.vfs2.provider.gzip.GzipFileProvider());
    vfs.addProvider(""ram"", new org.apache.commons.vfs2.provider.ram.RamFileProvider());
    vfs.addProvider(""file"", new org.apache.commons.vfs2.provider.local.DefaultLocalFileProvider());
    vfs.addProvider(""jar"", new org.apache.commons.vfs2.provider.jar.JarFileProvider());
    vfs.addProvider(""http"", new org.apache.commons.vfs2.provider.http.HttpFileProvider());
    vfs.addProvider(""https"", new org.apache.commons.vfs2.provider.https.HttpsFileProvider());
    vfs.addProvider(""ftp"", new org.apache.commons.vfs2.provider.ftp.FtpFileProvider());
    vfs.addProvider(""ftps"", new org.apache.commons.vfs2.provider.ftps.FtpsFileProvider());
    vfs.addProvider(""war"", new org.apache.commons.vfs2.provider.jar.JarFileProvider());
    vfs.addProvider(""par"", new org.apache.commons.vfs2.provider.jar.JarFileProvider());
    vfs.addProvider(""ear"", new org.apache.commons.vfs2.provider.jar.JarFileProvider());
    vfs.addProvider(""sar"", new org.apache.commons.vfs2.provider.jar.JarFileProvider());
    vfs.addProvider(""ejb3"", new org.apache.commons.vfs2.provider.jar.JarFileProvider());
    vfs.addProvider(""tmp"", new org.apache.commons.vfs2.provider.temp.TemporaryFileProvider());
    vfs.addProvider(""tar"", new org.apache.commons.vfs2.provider.tar.TarFileProvider());
    vfs.addProvider(""tbz2"", new org.apache.commons.vfs2.provider.tar.TarFileProvider());
    vfs.addProvider(""tgz"", new org.apache.commons.vfs2.provider.tar.TarFileProvider());
    vfs.addProvider(""bz2"", new org.apache.commons.vfs2.provider.bzip2.Bzip2FileProvider());
    vfs.addProvider(""hdfs"", new HdfsFileProvider());
    vfs.addExtensionMap(""jar"", ""jar"");
    vfs.addExtensionMap(""zip"", ""zip"");
    vfs.addExtensionMap(""gz"", ""gz"");
    vfs.addExtensionMap(""tar"", ""tar"");
    vfs.addExtensionMap(""tbz2"", ""tar"");
    vfs.addExtensionMap(""tgz"", ""tar"");
    vfs.addExtensionMap(""bz2"", ""bz2"");
    vfs.addMimeTypeMap(""application/x-tar"", ""tar"");
    vfs.addMimeTypeMap(""application/x-gzip"", ""gz"");
    vfs.addMimeTypeMap(""application/zip"", ""zip"");
    vfs.setFileContentInfoFactory(new FileContentInfoFilenameFactory());
    vfs.setFilesCache(new SoftRefFilesCache());
    String cacheDirPath = AccumuloClassLoader.getAccumuloString(VFS_CACHE_DIR, """");
    File cacheDir = computeTopCacheDir();
    if (!cacheDirPath.isEmpty())
        cacheDir = new File(cacheDirPath, """" + uniqueDirectoryGenerator.getAndIncrement());
    vfs.setReplicator(new UniqueFileReplicator(cacheDir));
    vfs.setCacheStrategy(CacheStrategy.ON_RESOLVE);
    vfs.init();
    vfsInstances.add(new WeakReference<DefaultFileSystemManager>(vfs));
    return vfs;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3383_97f16db4,Minor,start/src/main/java/org/apache/accumulo/start/classloader/vfs/AccumuloVFSClassLoader.java,293,296,"private static File computeTopCacheDir() {
    String procName = ManagementFactory.getRuntimeMXBean().getName();
    return new File(System.getProperty(""java.io.tmpdir""), ""accumulo-vfs-cache-"" + procName + ""-"" + System.getProperty(""user.name"", ""nouser""));
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3408_81d25bc2,Minor,server/monitor/src/main/java/org/apache/accumulo/monitor/servlets/PreciseNumberType.java,29,31,"public static String bigNumber(long big, String[] SUFFIXES, long base) {
    return String.format(""%,d"", big);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3424_27d4ee21,Major,core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java,244,398,"// Not for client use
public boolean config(String... args) {
    ShellOptionsJC options = new ShellOptionsJC();
    JCommander jc = new JCommander();
    jc.setProgramName(""accumulo shell"");
    jc.addObject(options);
    try {
        jc.parse(args);
    } catch (ParameterException e) {
        configError = true;
    }
    if (options.isHelpEnabled()) {
        configError = true;
    }
    if (!configError && options.getUnrecognizedOptions() != null) {
        configError = true;
        logError(""Unrecognized Options: "" + options.getUnrecognizedOptions().toString());
    }
    if (configError) {
        jc.usage();
        return true;
    }
    setDebugging(options.isDebugEnabled());
    authTimeout = TimeUnit.MINUTES.toNanos(options.getAuthTimeout());
    disableAuthTimeout = options.isAuthTimeoutDisabled();
    // get the options that were parsed
    String user = options.getUsername();
    String password = options.getPassword();
    tabCompletion = !options.isTabCompletionDisabled();
    // Use a fake (Mock), ZK, or HdfsZK Accumulo instance
    setInstance(options);
    // AuthenticationToken options
    token = options.getAuthenticationToken();
    Map<String, String> loginOptions = options.getTokenProperties();
    // process default parameters if unspecified
    try {
        boolean hasToken = (token != null);
        boolean hasTokenOptions = !loginOptions.isEmpty();
        if (hasToken && password != null) {
            throw new ParameterException(""Can not supply '--pass' option with '--tokenClass' option"");
        }
        Runtime.getRuntime().addShutdownHook(new Thread() {

            @Override
            public void run() {
                reader.getTerminal().setEchoEnabled(true);
            }
        });
        // Need either both a token and options, or neither, but not just one.
        if (hasToken != hasTokenOptions) {
            throw new ParameterException(""Must supply either both or neither of '--tokenClass' and '--tokenProperty'"");
        } else if (hasToken) {
            // implied hasTokenOptions
            // Fully qualified name so we don't shadow java.util.Properties
            org.apache.accumulo.core.client.security.tokens.AuthenticationToken.Properties props;
            // and line wrap it because the package name is so long
            props = new org.apache.accumulo.core.client.security.tokens.AuthenticationToken.Properties();
            props.putAllStrings(loginOptions);
            token.init(props);
        } else {
            // Read password if the user explicitly asked for it, or didn't specify anything at all
            if (""stdin"".equals(password) || password == null) {
                password = reader.readLine(""Password: "", '*');
            }
            if (password == null) {
                // User cancel, e.g. Ctrl-D pressed
                throw new ParameterException(""No password or token option supplied"");
            } else {
                this.token = new PasswordToken(password);
            }
        }
        if (!options.isFake()) {
            ZooReader zr = new ZooReader(instance.getZooKeepers(), instance.getZooKeepersSessionTimeOut());
            DistributedTrace.enable(instance, zr, ""shell"", InetAddress.getLocalHost().getHostName());
        }
        this.setTableName("""");
        this.principal = user;
        connector = instance.getConnector(this.principal, token);
    } catch (Exception e) {
        printException(e);
        configError = true;
    }
    // decide whether to execute commands from a file and quit
    if (options.getExecFile() != null) {
        execFile = options.getExecFile();
        verbose = false;
    } else if (options.getExecFileVerbose() != null) {
        execFile = options.getExecFileVerbose();
        verbose = true;
    }
    execCommand = options.getExecCommand();
    if (execCommand != null) {
        verbose = false;
    }
    rootToken = new Token();
    Command[] dataCommands = { new DeleteCommand(), new DeleteManyCommand(), new DeleteRowsCommand(), new EGrepCommand(), new FormatterCommand(), new InterpreterCommand(), new GrepCommand(), new ImportDirectoryCommand(), new InsertCommand(), new MaxRowCommand(), new ScanCommand() };
    Command[] debuggingCommands = { new ClasspathCommand(), new DebugCommand(), new ListScansCommand(), new ListCompactionsCommand(), new TraceCommand(), new PingCommand() };
    Command[] execCommands = { new ExecfileCommand(), new HistoryCommand(), new ExtensionCommand(), new ScriptCommand() };
    Command[] exitCommands = { new ByeCommand(), new ExitCommand(), new QuitCommand() };
    Command[] helpCommands = { new AboutCommand(), new HelpCommand(), new InfoCommand(), new QuestionCommand() };
    Command[] iteratorCommands = { new DeleteIterCommand(), new DeleteScanIterCommand(), new ListIterCommand(), new SetIterCommand(), new SetScanIterCommand(), new SetShellIterCommand(), new ListShellIterCommand(), new DeleteShellIterCommand() };
    Command[] otherCommands = { new HiddenCommand() };
    Command[] permissionsCommands = { new GrantCommand(), new RevokeCommand(), new SystemPermissionsCommand(), new TablePermissionsCommand(), new UserPermissionsCommand(), new NamespacePermissionsCommand() };
    Command[] stateCommands = { new AuthenticateCommand(), new ClsCommand(), new ClearCommand(), new FateCommand(), new NoTableCommand(), new SleepCommand(), new TableCommand(), new UserCommand(), new WhoAmICommand() };
    Command[] tableCommands = { new CloneTableCommand(), new ConfigCommand(), new CreateTableCommand(), new DeleteTableCommand(), new DropTableCommand(), new DUCommand(), new ExportTableCommand(), new ImportTableCommand(), new OfflineCommand(), new OnlineCommand(), new RenameTableCommand(), new TablesCommand(), new NamespacesCommand(), new CreateNamespaceCommand(), new DeleteNamespaceCommand(), new RenameNamespaceCommand() };
    Command[] tableControlCommands = { new AddSplitsCommand(), new CompactCommand(), new ConstraintCommand(), new FlushCommand(), new GetGroupsCommand(), new GetSplitsCommand(), new MergeCommand(), new SetGroupsCommand() };
    Command[] userCommands = { new AddAuthsCommand(), new CreateUserCommand(), new DeleteUserCommand(), new DropUserCommand(), new GetAuthsCommand(), new PasswdCommand(), new SetAuthsCommand(), new UsersCommand() };
    commandGrouping.put(""-- Writing, Reading, and Removing Data --"", dataCommands);
    commandGrouping.put(""-- Debugging Commands -------------------"", debuggingCommands);
    commandGrouping.put(""-- Shell Execution Commands -------------"", execCommands);
    commandGrouping.put(""-- Exiting Commands ---------------------"", exitCommands);
    commandGrouping.put(""-- Help Commands ------------------------"", helpCommands);
    commandGrouping.put(""-- Iterator Configuration ---------------"", iteratorCommands);
    commandGrouping.put(""-- Permissions Administration Commands --"", permissionsCommands);
    commandGrouping.put(""-- Shell State Commands -----------------"", stateCommands);
    commandGrouping.put(""-- Table Administration Commands --------"", tableCommands);
    commandGrouping.put(""-- Table Control Commands ---------------"", tableControlCommands);
    commandGrouping.put(""-- User Administration Commands ---------"", userCommands);
    for (Command[] cmds : commandGrouping.values()) {
        for (Command cmd : cmds) commandFactory.put(cmd.getName(), cmd);
    }
    for (Command cmd : otherCommands) {
        commandFactory.put(cmd.getName(), cmd);
    }
    return configError;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3474_cfb832a1,Minor,proxy/src/main/java/org/apache/accumulo/proxy/ProxyServer.java,1105,1146,"private void addCellsToWriter(Map<ByteBuffer, List<ColumnUpdate>> cells, BatchWriterPlusException bwpe) {
    if (bwpe.exception != null)
        return;
    HashMap<Text, ColumnVisibility> vizMap = new HashMap<Text, ColumnVisibility>();
    for (Map.Entry<ByteBuffer, List<ColumnUpdate>> entry : cells.entrySet()) {
        Mutation m = new Mutation(ByteBufferUtil.toBytes(entry.getKey()));
        for (ColumnUpdate update : entry.getValue()) {
            ColumnVisibility viz = EMPTY_VIS;
            if (update.isSetColVisibility()) {
                Text vizText = new Text(update.getColVisibility());
                viz = vizMap.get(vizText);
                if (viz == null) {
                    vizMap.put(vizText, viz = new ColumnVisibility(vizText));
                }
            }
            byte[] value = new byte[0];
            if (update.isSetValue())
                value = update.getValue();
            if (update.isSetTimestamp()) {
                if (update.isSetDeleteCell()) {
                    m.putDelete(update.getColFamily(), update.getColQualifier(), viz, update.getTimestamp());
                } else {
                    m.put(new Text(update.getColFamily()), new Text(update.getColQualifier()), viz, update.getTimestamp(), new Value(value));
                }
            } else {
                if (update.isSetDeleteCell()) {
                    m.putDelete(new Text(update.getColFamily()), new Text(update.getColQualifier()), viz);
                } else {
                    m.put(new Text(update.getColFamily()), new Text(update.getColQualifier()), viz, new Value(value));
                }
            }
        }
        try {
            bwpe.writer.addMutation(m);
        } catch (MutationsRejectedException mre) {
            bwpe.exception = mre;
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3475_7651b777,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockShell.java,47,65,"public boolean config(String... args) {
    configError = super.config(args);
    // Update the ConsoleReader with the input and output ""redirected""
    try {
        this.reader = new ConsoleReader(in, writer);
    } catch (Exception e) {
        printException(e);
        configError = true;
    }
    // Don't need this for testing purposes
    this.reader.setUseHistory(false);
    this.reader.setUsePagination(false);
    // Make the parsing from the client easier;
    this.verbose = false;
    return configError;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3475_7651b777,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockShell.java,73,110,"public int start() throws IOException {
    if (configError)
        return 1;
    String input;
    if (isVerbose())
        printInfo();
    if (execFile != null) {
        java.util.Scanner scanner = new java.util.Scanner(new File(execFile), UTF_8.name());
        try {
            while (scanner.hasNextLine() && !hasExited()) {
                execCommand(scanner.nextLine(), true, isVerbose());
            }
        } finally {
            scanner.close();
        }
    } else if (execCommand != null) {
        for (String command : execCommand.split(""\n"")) {
            execCommand(command, true, isVerbose());
        }
        return exitCode;
    }
    while (true) {
        if (hasExited())
            return exitCode;
        reader.setDefaultPrompt(getDefaultPrompt());
        input = reader.readLine();
        if (input == null) {
            reader.printNewline();
            return exitCode;
        }
        // user canceled
        execCommand(input, false, false);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3475_7651b777,Major,core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java,219,377,"// Not for client use
public boolean config(String... args) {
    CommandLine cl;
    try {
        cl = new BasicParser().parse(opts, args);
        if (cl.getArgs().length > 0)
            throw new ParseException(""Unrecognized arguments: "" + cl.getArgList());
        if (cl.hasOption(helpOpt.getOpt())) {
            configError = true;
            printHelp(""shell"", SHELL_DESCRIPTION, opts);
            return true;
        }
        setDebugging(cl.hasOption(debugOption.getLongOpt()));
        authTimeout = TimeUnit.MINUTES.toNanos(Integer.parseInt(cl.getOptionValue(authTimeoutOpt.getLongOpt(), DEFAULT_AUTH_TIMEOUT)));
        disableAuthTimeout = cl.hasOption(disableAuthTimeoutOpt.getLongOpt());
        if (cl.hasOption(zooKeeperInstance.getOpt()) && cl.getOptionValues(zooKeeperInstance.getOpt()).length != 2)
            throw new MissingArgumentException(zooKeeperInstance);
    } catch (Exception e) {
        configError = true;
        printException(e);
        printHelp(""shell"", SHELL_DESCRIPTION, opts);
        return true;
    }
    // get the options that were parsed
    String sysUser = System.getProperty(""user.name"");
    if (sysUser == null)
        sysUser = ""root"";
    String user = cl.getOptionValue(usernameOption.getOpt(), sysUser);
    String passw = cl.getOptionValue(passwOption.getOpt(), null);
    tabCompletion = !cl.hasOption(tabCompleteOption.getLongOpt());
    String[] loginOptions = cl.getOptionValues(loginOption.getOpt());
    // Use a fake (Mock), ZK, or HdfsZK Accumulo instance
    setInstance(cl);
    // process default parameters if unspecified
    try {
        if (loginOptions != null && !cl.hasOption(tokenOption.getOpt()))
            throw new IllegalArgumentException(""Must supply '-"" + tokenOption.getOpt() + ""' option with '-"" + loginOption.getOpt() + ""' option"");
        if (loginOptions == null && cl.hasOption(tokenOption.getOpt()))
            throw new IllegalArgumentException(""Must supply '-"" + loginOption.getOpt() + ""' option with '-"" + tokenOption.getOpt() + ""' option"");
        if (passw != null && cl.hasOption(tokenOption.getOpt()))
            throw new IllegalArgumentException(""Can not supply '-"" + passwOption.getOpt() + ""' option with '-"" + tokenOption.getOpt() + ""' option"");
        if (user == null)
            throw new MissingArgumentException(usernameOption);
        if (loginOptions != null && cl.hasOption(tokenOption.getOpt())) {
            Properties props = new Properties();
            for (String loginOption : loginOptions) for (String lo : loginOption.split("","")) {
                String[] split = lo.split(""="");
                props.put(split[0], split[1]);
            }
            this.token = Class.forName(cl.getOptionValue(tokenOption.getOpt())).asSubclass(AuthenticationToken.class).newInstance();
            this.token.init(props);
        }
        if (!cl.hasOption(fakeOption.getLongOpt())) {
            DistributedTrace.enable(instance, new ZooReader(instance.getZooKeepers(), instance.getZooKeepersSessionTimeOut()), ""shell"", InetAddress.getLocalHost().getHostName());
        }
        Runtime.getRuntime().addShutdownHook(new Thread() {

            @Override
            public void start() {
                reader.getTerminal().enableEcho();
            }
        });
        if (passw != null) {
            this.token = new PasswordToken(passw);
        }
        if (this.token == null) {
            passw = readMaskedLine(""Password: "", '*');
            if (passw != null)
                this.token = new PasswordToken(passw);
        }
        if (this.token == null) {
            reader.printNewline();
            throw new MissingArgumentException(""No password or token option supplied"");
        }
        // user canceled
        this.setTableName("""");
        this.principal = user;
        connector = instance.getConnector(this.principal, token);
    } catch (Exception e) {
        printException(e);
        configError = true;
    }
    // decide whether to execute commands from a file and quit
    if (cl.hasOption(execfileOption.getOpt())) {
        execFile = cl.getOptionValue(execfileOption.getOpt());
        verbose = false;
    } else if (cl.hasOption(execfileVerboseOption.getOpt())) {
        execFile = cl.getOptionValue(execfileVerboseOption.getOpt());
    }
    if (cl.hasOption(execCommandOpt.getOpt())) {
        execCommand = cl.getOptionValue(execCommandOpt.getOpt());
        verbose = false;
    }
    rootToken = new Token();
    Command[] dataCommands = { new DeleteCommand(), new DeleteManyCommand(), new DeleteRowsCommand(), new EGrepCommand(), new FormatterCommand(), new InterpreterCommand(), new GrepCommand(), new ImportDirectoryCommand(), new InsertCommand(), new MaxRowCommand(), new ScanCommand() };
    Command[] debuggingCommands = { new ClasspathCommand(), new DebugCommand(), new ListScansCommand(), new ListCompactionsCommand(), new TraceCommand(), new PingCommand() };
    Command[] execCommands = { new ExecfileCommand(), new HistoryCommand() };
    Command[] exitCommands = { new ByeCommand(), new ExitCommand(), new QuitCommand() };
    Command[] helpCommands = { new AboutCommand(), new HelpCommand(), new InfoCommand(), new QuestionCommand() };
    Command[] iteratorCommands = { new DeleteIterCommand(), new DeleteScanIterCommand(), new ListIterCommand(), new SetIterCommand(), new SetScanIterCommand(), new SetShellIterCommand(), new ListShellIterCommand(), new DeleteShellIterCommand() };
    Command[] otherCommands = { new HiddenCommand() };
    Command[] permissionsCommands = { new GrantCommand(), new RevokeCommand(), new SystemPermissionsCommand(), new TablePermissionsCommand(), new UserPermissionsCommand() };
    Command[] stateCommands = { new AuthenticateCommand(), new ClsCommand(), new ClearCommand(), new NoTableCommand(), new SleepCommand(), new TableCommand(), new UserCommand(), new WhoAmICommand() };
    Command[] tableCommands = { new CloneTableCommand(), new ConfigCommand(), new CreateTableCommand(), new DeleteTableCommand(), new DropTableCommand(), new DUCommand(), new ExportTableCommand(), new ImportTableCommand(), new OfflineCommand(), new OnlineCommand(), new RenameTableCommand(), new TablesCommand() };
    Command[] tableControlCommands = { new AddSplitsCommand(), new CompactCommand(), new ConstraintCommand(), new FlushCommand(), new GetGroupsCommand(), new GetSplitsCommand(), new MergeCommand(), new SetGroupsCommand() };
    Command[] userCommands = { new AddAuthsCommand(), new CreateUserCommand(), new DeleteUserCommand(), new DropUserCommand(), new GetAuthsCommand(), new PasswdCommand(), new SetAuthsCommand(), new UsersCommand() };
    commandGrouping.put(""-- Writing, Reading, and Removing Data --"", dataCommands);
    commandGrouping.put(""-- Debugging Commands -------------------"", debuggingCommands);
    commandGrouping.put(""-- Shell Execution Commands -------------"", execCommands);
    commandGrouping.put(""-- Exiting Commands ---------------------"", exitCommands);
    commandGrouping.put(""-- Help Commands ------------------------"", helpCommands);
    commandGrouping.put(""-- Iterator Configuration ---------------"", iteratorCommands);
    commandGrouping.put(""-- Permissions Administration Commands --"", permissionsCommands);
    commandGrouping.put(""-- Shell State Commands -----------------"", stateCommands);
    commandGrouping.put(""-- Table Administration Commands --------"", tableCommands);
    commandGrouping.put(""-- Table Control Commands ---------------"", tableControlCommands);
    commandGrouping.put(""-- User Administration Commands ---------"", userCommands);
    for (Command[] cmds : commandGrouping.values()) {
        for (Command cmd : cmds) commandFactory.put(cmd.getName(), cmd);
    }
    for (Command cmd : otherCommands) {
        commandFactory.put(cmd.getName(), cmd);
    }
    return configError;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3475_7651b777,Major,core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java,409,414,"public static void main(String[] args) throws IOException {
    Shell shell = new Shell();
    shell.config(args);
    System.exit(shell.start());
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3475_7651b777,Major,core/src/main/java/org/apache/accumulo/core/util/shell/Shell.java,416,480,"public int start() throws IOException {
    if (configError)
        return 1;
    String input;
    if (isVerbose())
        printInfo();
    String home = System.getProperty(""HOME"");
    if (home == null)
        home = System.getenv(""HOME"");
    String configDir = home + ""/.accumulo"";
    String historyPath = configDir + ""/shell_history.txt"";
    File accumuloDir = new File(configDir);
    if (!accumuloDir.exists() && !accumuloDir.mkdirs())
        log.warn(""Unable to make directory for history at "" + accumuloDir);
    try {
        History history = new History();
        history.setHistoryFile(new File(historyPath));
        reader.setHistory(history);
    } catch (IOException e) {
        log.warn(""Unable to load history file at "" + historyPath);
    }
    ShellCompletor userCompletor = null;
    if (execFile != null) {
        java.util.Scanner scanner = new java.util.Scanner(new File(execFile), UTF_8.name());
        try {
            while (scanner.hasNextLine() && !hasExited()) {
                execCommand(scanner.nextLine(), true, isVerbose());
            }
        } finally {
            scanner.close();
        }
    } else if (execCommand != null) {
        for (String command : execCommand.split(""\n"")) {
            execCommand(command, true, isVerbose());
        }
        return exitCode;
    }
    while (true) {
        if (hasExited())
            return exitCode;
        // If tab completion is true we need to reset
        if (tabCompletion) {
            if (userCompletor != null)
                reader.removeCompletor(userCompletor);
            userCompletor = setupCompletion();
            reader.addCompletor(userCompletor);
        }
        reader.setDefaultPrompt(getDefaultPrompt());
        input = reader.readLine();
        if (input == null) {
            reader.printNewline();
            return exitCode;
        }
        // user canceled
        execCommand(input, disableAuthTimeout, false);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3634_9339ecf8,Minor,server/base/src/main/java/org/apache/accumulo/server/security/delegation/ZooAuthenticationKeyWatcher.java,130,140,"private int updateAuthKeys(String path) throws KeeperException, InterruptedException {
    int keysAdded = 0;
    for (String child : zk.getChildren(path, this)) {
        String childPath = path + ""/"" + child;
        // Get the node data and reset the watcher
        AuthenticationKey key = deserializeKey(zk.getData(childPath, this, null));
        secretManager.addKey(key);
        keysAdded++;
    }
    return keysAdded;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/core/src/main/java/org/apache/accumulo/core/zookeeper/ZooCache.java,121,154,"private synchronized void retry(ZooRunnable op) {
    int sleepTime = 100;
    while (true) {
        ZooKeeper zooKeeper = getZooKeeper();
        try {
            op.run(zooKeeper);
            return;
        } catch (KeeperException e) {
            if (e.code() == Code.NONODE) {
                log.error(""Looked up non existant node in cache "" + e.getPath(), e);
            }
            log.warn(""Zookeeper error, will retry"", e);
        } catch (InterruptedException e) {
            log.warn(""Zookeeper error, will retry"", e);
        } catch (ConcurrentModificationException e) {
            log.debug(""Zookeeper was modified, will retry"");
        }
        try {
            // do not hold lock while sleeping
            wait(sleepTime);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        if (sleepTime < 10000)
            sleepTime = (int) (sleepTime + sleepTime * Math.random());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/examples/wikisearch/ingest/src/main/java/org/apache/accumulo/examples/wikisearch/ingest/WikipediaInputFormat.java,73,84,"@Override
public void readFields(DataInput in) throws IOException {
    Path file = new Path(in.readUTF());
    long start = in.readLong();
    long length = in.readLong();
    int numHosts = in.readInt();
    String[] hosts = new String[numHosts];
    for (int i = 0; i < numHosts; i++) hosts[i] = in.readUTF();
    fileSplit = new FileSplit(file, start, length, hosts);
    partition = in.readInt();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/examples/wikisearch/ingest/src/main/java/org/apache/accumulo/examples/wikisearch/ingest/WikipediaInputFormat.java,86,97,"@Override
public void write(DataOutput out) throws IOException {
    out.writeUTF(fileSplit.getPath().toString());
    out.writeLong(fileSplit.getStart());
    out.writeLong(fileSplit.getLength());
    String[] hosts = fileSplit.getLocations();
    out.writeInt(hosts.length);
    for (String host : hosts) out.writeUTF(host);
    fileSplit.write(out);
    out.writeInt(partition);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java,2239,2281,"void flush(long tableFlushID) {
    boolean updateMetadata = false;
    boolean initiateMinor = false;
    try {
        synchronized (this) {
            // only want one thing at a time to update flush ID to ensure that metadata table and tablet in memory state are consistent
            if (updatingFlushID)
                return;
            if (lastFlushID >= tableFlushID)
                return;
            if (closing || closed || tabletMemory.memoryReservedForMinC())
                return;
            if (tabletMemory.getMemTable().getNumEntries() == 0) {
                lastFlushID = tableFlushID;
                updatingFlushID = true;
                updateMetadata = true;
            } else
                initiateMinor = true;
        }
        if (updateMetadata) {
            AuthInfo creds = SecurityConstants.getSystemCredentials();
            // if multiple threads were allowed to update this outside of a sync block, then it would be
            // a race condition
            MetadataTable.updateTabletFlushID(extent, tableFlushID, creds, tabletServer.getLock());
        } else if (initiateMinor)
            initiateMinorCompaction(tableFlushID);
    } finally {
        if (updateMetadata) {
            synchronized (this) {
                updatingFlushID = false;
            }
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java,2283,2287,"boolean initiateMinorCompaction() {
    // get the flush id before the new memmap is made available for write
    long flushId = getFlushID();
    return initiateMinorCompaction(flushId);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java,2341,2349,"long getFlushID() {
    try {
        String zTablePath = Constants.ZROOT + ""/"" + HdfsZooInstance.getInstance().getInstanceID() + Constants.ZTABLES + ""/"" + extent.getTableId() + Constants.ZTABLE_FLUSH_ID;
        return Long.parseLong(new String(ZooReaderWriter.getRetryingInstance().getData(zTablePath, null)));
    } catch (Exception e) {
        throw new RuntimeException(e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java,2351,2359,"long getCompactionID() {
    try {
        String zTablePath = Constants.ZROOT + ""/"" + HdfsZooInstance.getInstance().getInstanceID() + Constants.ZTABLES + ""/"" + extent.getTableId() + Constants.ZTABLE_COMPACT_ID;
        return Long.parseLong(new String(ZooReaderWriter.getRetryingInstance().getData(zTablePath, null)));
    } catch (Exception e) {
        throw new RuntimeException(e);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java,2520,2578,"void initiateClose(boolean saveState, boolean queueMinC, boolean disableWrites) {
    if (!saveState && queueMinC) {
        throw new IllegalArgumentException(""Not saving state on close and requesting minor compactions queue does not make sense"");
    }
    log.debug(""initiateClose(saveState="" + saveState + "" queueMinC="" + queueMinC + "" disableWrites="" + disableWrites + "") "" + getExtent());
    MinorCompactionTask mct = null;
    synchronized (this) {
        if (closed || closing || closeComplete) {
            String msg = ""Tablet "" + getExtent() + "" already"";
            if (closed)
                msg += "" closed"";
            if (closing)
                msg += "" closing"";
            if (closeComplete)
                msg += "" closeComplete"";
            throw new IllegalStateException(msg);
        }
        // enter the closing state, no splits, minor, or major compactions can start
        // should cause running major compactions to stop
        closing = true;
        this.notifyAll();
        // determines if inserts and queries can still continue while minor compacting
        closed = disableWrites;
        // true should cause any running major compactions to abort
        while (majorCompactionInProgress) {
            try {
                this.wait(50);
            } catch (InterruptedException e) {
                log.error(e.toString());
            }
        }
        if (!saveState || tabletMemory.getMemTable().getNumEntries() == 0) {
            return;
        }
        tabletMemory.waitForMinC();
        mct = prepareForMinC(getFlushID());
        if (queueMinC) {
            tabletResources.executeMinorCompaction(mct);
            return;
        }
    }
    // do minor compaction outside of synch block so that tablet can be read and written to while
    // compaction runs
    mct.run();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java,2582,2653,"synchronized void completeClose(boolean saveState, boolean completeClose) throws IOException {
    if (!closing || closeComplete || closeCompleting) {
        throw new IllegalStateException(""closing = "" + closing + "" closed = "" + closed + "" closeComplete = "" + closeComplete + "" closeCompleting = "" + closeCompleting);
    }
    log.debug(""completeClose(saveState="" + saveState + "" completeClose="" + completeClose + "") "" + getExtent());
    // ensure this method is only called once, also guards against multiple
    // threads entering the method at the same time
    closeCompleting = true;
    closed = true;
    // modify dataSourceDeletions so scans will try to switch data sources and fail because the tablet is closed
    dataSourceDeletions.incrementAndGet();
    for (ScanDataSource activeScan : activeScans) {
        activeScan.interrupt();
    }
    // wait for reads and writes to complete
    while (writesInProgress > 0 || activeScans.size() > 0) {
        try {
            this.wait(50);
        } catch (InterruptedException e) {
            log.error(e.toString());
        }
    }
    tabletMemory.waitForMinC();
    if (saveState && tabletMemory.getMemTable().getNumEntries() > 0) {
        prepareForMinC(getFlushID()).run();
    }
    if (saveState) {
        // at this point all tablet data is flushed, so do a consistency check
        RuntimeException err = null;
        for (int i = 0; i < 5; i++) {
            try {
                closeConsistencyCheck();
                err = null;
            } catch (RuntimeException t) {
                err = t;
                log.error(""Consistency check fails, retrying "" + t);
                UtilWaitThread.sleep(500);
            }
        }
        if (err != null) {
            ProblemReports.getInstance().report(new ProblemReport(extent.getTableId().toString(), ProblemType.TABLET_LOAD, this.extent.toString(), err));
            log.error(""Tablet closed consistency check has failed for "" + this.extent + "" giving up and closing"");
        }
    }
    try {
        tabletMemory.getMemTable().delete(0);
    } catch (Throwable t) {
        log.error(""Failed to delete mem table : "" + t.getMessage(), t);
    }
    tabletMemory = null;
    // close map files
    tabletResources.close();
    log.log(TLevel.TABLET_HIST, extent + "" closed"");
    acuTableConf.removeObserver(configObserver);
    closeComplete = completeClose;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/Tablet.java,3036,3183,"private CompactionStats _majorCompact(MajorCompactionReason reason) throws IOException, CompactionCanceledException {
    boolean propogateDeletes;
    long t1, t2, t3;
    // acquire first and last key info outside of tablet lock
    Map<String, Pair<Key, Key>> falks = null;
    if (reason == MajorCompactionReason.CHOP)
        falks = getFirstAndLastKeys(datafileManager.getDatafileSizes());
    Map<String, Long> filesToCompact;
    int maxFilesToCompact = acuTableConf.getCount(Property.TSERV_MAJC_THREAD_MAXOPEN);
    CompactionStats majCStats = new CompactionStats();
    synchronized (this) {
        // plan all that work that needs to be done in the sync block... then do the actual work
        // outside the sync block
        t1 = System.currentTimeMillis();
        majorCompactionWaitingToStart = true;
        tabletMemory.waitForMinC();
        t2 = System.currentTimeMillis();
        majorCompactionWaitingToStart = false;
        notifyAll();
        if (extent.equals(Constants.ROOT_TABLET_EXTENT)) {
            // very important that we call this before doing major compaction,
            // otherwise deleted compacted files could possible be brought back
            // at some point if the file they were compacted to was legitimately
            // removed by a major compaction
            cleanUpFiles(fs, fs.listStatus(this.location), this.location, false);
        }
        // getFilesToCompact() and cleanUpFiles() both
        // do dir listings, which means two calls to the namenode
        // we should refactor so that there is only one call
        CompactionTuple ret = getFilesToCompact(reason, falks);
        if (ret == null) {
            // nothing to compact
            return majCStats;
        }
        filesToCompact = ret.getFilesToCompact();
        if (!ret.getCompactAll()) {
            // since not all files are being compacted, we want to propagate delete entries
            propogateDeletes = true;
        } else {
            propogateDeletes = false;
        }
        t3 = System.currentTimeMillis();
        datafileManager.reserveMajorCompactingFiles(filesToCompact.keySet());
    }
    try {
        log.debug(String.format(""MajC initiate lock %.2f secs, wait %.2f secs"", (t3 - t2) / 1000.0, (t2 - t1) / 1000.0));
        Long compactionId = null;
        if (!propogateDeletes) {
            // compacting everything, so update the compaction id in !METADATA
            compactionId = getCompactionID();
        }
        // need to handle case where only one file is being major compacted
        while (filesToCompact.size() > 0) {
            int numToCompact = maxFilesToCompact;
            if (filesToCompact.size() > maxFilesToCompact && filesToCompact.size() < 2 * maxFilesToCompact) {
                // on the second to last compaction pass, compact the minimum amount of files possible
                numToCompact = filesToCompact.size() - maxFilesToCompact + 1;
            }
            Set<String> smallestFiles = removeSmallest(filesToCompact, numToCompact);
            String fileName = getNextMapFilename((filesToCompact.size() == 0 && !propogateDeletes) ? ""A"" : ""C"");
            String compactTmpName = fileName + ""_tmp"";
            Span span = Trace.start(""compactFiles"");
            try {
                CompactionEnv cenv = new CompactionEnv() {

                    @Override
                    public boolean isCompactionEnabled() {
                        return Tablet.this.isCompactionEnabled();
                    }

                    @Override
                    public IteratorScope getIteratorScope() {
                        return IteratorScope.majc;
                    }
                };
                HashMap<String, DataFileValue> copy = new HashMap<String, DataFileValue>(datafileManager.getDatafileSizes());
                if (!copy.keySet().containsAll(smallestFiles))
                    throw new IllegalStateException(""Cannot find data file values for "" + smallestFiles);
                copy.keySet().retainAll(smallestFiles);
                log.debug(""Starting MajC "" + extent + "" ("" + reason + "") "" + datafileManager.abs2rel(datafileManager.string2path(copy.keySet())) + "" --> "" + datafileManager.abs2rel(new Path(compactTmpName)));
                Compactor compactor = new // always
                Compactor(// always
                conf, // always
                fs, // always
                copy, // always
                null, // always
                compactTmpName, // always
                filesToCompact.size() == 0 ? propogateDeletes : true, // batch
                acuTableConf, extent, cenv);
                CompactionStats mcs = compactor.call();
                span.data(""files"", """" + smallestFiles.size());
                span.data(""read"", """" + mcs.getEntriesRead());
                span.data(""written"", """" + mcs.getEntriesWritten());
                majCStats.add(mcs);
                datafileManager.bringMajorCompactionOnline(smallestFiles, compactTmpName, fileName, filesToCompact.size() == 0 ? compactionId : null, new DataFileValue(mcs.getFileSize(), mcs.getEntriesWritten()));
                // to add the deleted file
                if (filesToCompact.size() > 0 && mcs.getEntriesWritten() > 0) {
                    filesToCompact.put(fileName, mcs.getFileSize());
                }
            } finally {
                span.stop();
            }
        }
        return majCStats;
    } finally {
        synchronized (Tablet.this) {
            datafileManager.clearMajorCompactingFile();
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java,1865,1894,"@Override
public void flush(TInfo tinfo, AuthInfo credentials, String lock, String tableId, ByteBuffer startRow, ByteBuffer endRow) {
    try {
        checkPermission(credentials, lock, true, ""flush"");
    } catch (ThriftSecurityException e) {
        log.error(e, e);
        throw new RuntimeException(e);
    }
    ArrayList<Tablet> tabletsToFlush = new ArrayList<Tablet>();
    KeyExtent ke = new KeyExtent(new Text(tableId), ByteBufferUtil.toText(endRow), ByteBufferUtil.toText(startRow));
    synchronized (onlineTablets) {
        for (Tablet tablet : onlineTablets.values()) if (ke.overlaps(tablet.getExtent()))
            tabletsToFlush.add(tablet);
    }
    Long flushID = null;
    for (Tablet tablet : tabletsToFlush) {
        if (flushID == null) {
            // read the flush id once from zookeeper instead of reading
            // it for each tablet
            flushID = tablet.getFlushID();
        }
        tablet.flush(flushID);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java,1896,1909,"@Override
public void flushTablet(TInfo tinfo, AuthInfo credentials, String lock, TKeyExtent textent) throws TException {
    try {
        checkPermission(credentials, lock, true, ""flushTablet"");
    } catch (ThriftSecurityException e) {
        log.error(e, e);
        throw new RuntimeException(e);
    }
    Tablet tablet = onlineTablets.get(new KeyExtent(textent));
    if (tablet != null) {
        log.info(""Flushing "" + tablet.getExtent());
        tablet.flush(tablet.getFlushID());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-366_db4a291f,Major,src/server/src/main/java/org/apache/accumulo/server/tabletserver/TabletServer.java,1978,2006,"@Override
public void compact(TInfo tinfo, AuthInfo credentials, String lock, String tableId, ByteBuffer startRow, ByteBuffer endRow) throws TException {
    try {
        if (!authenticator.hasSystemPermission(credentials, credentials.user, SystemPermission.SYSTEM))
            throw new ThriftSecurityException(credentials.user, SecurityErrorCode.PERMISSION_DENIED);
    } catch (Exception e) {
        throw new RuntimeException(e);
    }
    KeyExtent ke = new KeyExtent(new Text(tableId), ByteBufferUtil.toText(endRow), ByteBufferUtil.toText(startRow));
    ArrayList<Tablet> tabletsToCompact = new ArrayList<Tablet>();
    synchronized (onlineTablets) {
        for (Tablet tablet : onlineTablets.values()) if (ke.overlaps(tablet.getExtent()))
            tabletsToCompact.add(tablet);
    }
    Long compactionId = null;
    for (Tablet tablet : tabletsToCompact) {
        // compaction id once
        if (compactionId == null)
            compactionId = tablet.getCompactionID();
        tablet.compactAll(compactionId);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3718_73ce9cfb,Blocker,core/src/main/java/org/apache/accumulo/core/data/Mutation.java,692,695,"@Override
public int hashCode() {
    return toThrift().hashCode();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3718_73ce9cfb,Blocker,core/src/main/java/org/apache/accumulo/core/data/Mutation.java,697,716,"public boolean equals(Mutation m) {
    serialize();
    m.serialize();
    if (Arrays.equals(row, m.row) && entries == m.entries && Arrays.equals(data, m.data)) {
        if (values == null && m.values == null)
            return true;
        if (values != null && m.values != null && values.size() == m.values.size()) {
            for (int i = 0; i < values.size(); i++) {
                if (!Arrays.equals(values.get(i), m.values.get(i)))
                    return false;
            }
            return true;
        }
    }
    return false;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3718_73ce9cfb,Blocker,core/src/main/java/org/apache/accumulo/core/data/Mutation.java,718,721,"public TMutation toThrift() {
    serialize();
    return new TMutation(java.nio.ByteBuffer.wrap(row), java.nio.ByteBuffer.wrap(data), ByteBufferUtil.toByteBuffers(values), entries);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3746_47c64d9a,Blocker,core/src/main/java/org/apache/accumulo/core/client/ClientConfiguration.java,302,312,"/**
 * Gets all properties under the given prefix in this configuration.
 *
 * @param property
 *          prefix property, must be of type PropertyType.PREFIX
 * @return a map of property keys to values
 * @throws IllegalArgumentException
 *           if property is not a prefix
 */
public Map<String, String> getAllPropertiesWithPrefix(ClientProperty property) {
    checkType(property, PropertyType.PREFIX);
    Map<String, String> propMap = new HashMap<String, String>();
    Iterator<?> iter = this.getKeys(property.getKey());
    while (iter.hasNext()) {
        String p = (String) iter.next();
        propMap.put(p, getString(p));
    }
    return propMap;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3897_699b8bf0,Minor,server/master/src/main/java/org/apache/accumulo/master/tserverOps/ShutdownTServer.java,49,88,"@Override
public long isReady(long tid, Master master) throws Exception {
    // suppress assignment of tablets to the server
    if (force) {
        return 0;
    }
    // only send this request once
    if (!requestedShutdown) {
        master.shutdownTServer(server);
    }
    if (master.onlineTabletServers().contains(server)) {
        TServerConnection connection = master.getConnection(server);
        if (connection != null) {
            try {
                TabletServerStatus status = connection.getTableMap(false);
                if (status.tableMap != null && status.tableMap.isEmpty()) {
                    log.info(""tablet server hosts no tablets "" + server);
                    connection.halt(master.getMasterLock());
                    log.info(""tablet server asked to halt "" + server);
                    return 0;
                }
            } catch (TTransportException ex) {
            // expected
            } catch (Exception ex) {
                log.error(""Error talking to tablet server "" + server + "": "" + ex);
            }
            // tserver to ack the request and stop itself.
            return 1000;
        }
    }
    return 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-3945_36225565,Minor,shell/src/main/java/org/apache/accumulo/shell/ShellOptionsJC.java,303,319,"public ClientConfiguration getClientConfiguration() throws ConfigurationException, FileNotFoundException {
    ClientConfiguration clientConfig = clientConfigFile == null ? ClientConfiguration.loadDefault() : new ClientConfiguration(getClientConfigFile());
    if (useSsl()) {
        clientConfig.setProperty(ClientProperty.INSTANCE_RPC_SSL_ENABLED, ""true"");
    }
    if (useSasl()) {
        clientConfig.setProperty(ClientProperty.INSTANCE_RPC_SASL_ENABLED, ""true"");
    }
    // Automatically try to add in the proper ZK from accumulo-site for backwards compat.
    if (!clientConfig.containsKey(ClientProperty.INSTANCE_ZK_HOST.getKey())) {
        AccumuloConfiguration siteConf = SiteConfiguration.getInstance(ClientContext.convertClientConfig(clientConfig));
        clientConfig.withZkHosts(siteConf.get(Property.INSTANCE_ZK_HOST));
    }
    return clientConfig;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4029_5ca779a0,Major,core/src/main/java/org/apache/accumulo/core/data/Mutation.java,599,602,"@Override
public int hashCode() {
    return toThrift(false).hashCode();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4113_27300d81,Critical,core/src/main/java/org/apache/accumulo/core/data/ArrayByteSequence.java,121,123,"public String toString() {
    return new String(data, offset, length, UTF_8);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4113_27300d81,Critical,core/src/main/java/org/apache/accumulo/core/util/ByteBufferUtil.java,31,35,"public static byte[] toBytes(ByteBuffer buffer) {
    if (buffer == null)
        return null;
    return Arrays.copyOfRange(buffer.array(), buffer.position(), buffer.limit());
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4113_27300d81,Critical,core/src/main/java/org/apache/accumulo/core/util/ByteBufferUtil.java,47,55,"public static List<byte[]> toBytesList(Collection<ByteBuffer> bytesList) {
    if (bytesList == null)
        return null;
    ArrayList<byte[]> result = new ArrayList<byte[]>();
    for (ByteBuffer bytes : bytesList) {
        result.add(toBytes(bytes));
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4113_27300d81,Critical,core/src/main/java/org/apache/accumulo/core/util/ByteBufferUtil.java,57,63,"public static Text toText(ByteBuffer bytes) {
    if (bytes == null)
        return null;
    Text result = new Text();
    result.set(bytes.array(), bytes.position(), bytes.remaining());
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4113_27300d81,Critical,core/src/main/java/org/apache/accumulo/core/util/ByteBufferUtil.java,65,67,"public static String toString(ByteBuffer bytes) {
    return new String(bytes.array(), bytes.position(), bytes.remaining(), UTF_8);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4113_27300d81,Critical,core/src/main/java/org/apache/accumulo/core/util/ByteBufferUtil.java,69,79,"public static ByteBuffer toByteBuffers(ByteSequence bs) {
    if (bs == null)
        return null;
    if (bs.isBackedByArray()) {
        return ByteBuffer.wrap(bs.getBackingArray(), bs.offset(), bs.length());
    } else {
        // TODO create more efficient impl
        return ByteBuffer.wrap(bs.toArray());
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_5594b2e0,Major,src/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java,109,267,"public AssignmentStats importFiles(List<String> files, Path failureDir) throws IOException, AccumuloException, AccumuloSecurityException, ThriftTableOperationException {
    int numThreads = acuConf.getCount(Property.TSERV_BULK_PROCESS_THREADS);
    int numAssignThreads = acuConf.getCount(Property.TSERV_BULK_ASSIGNMENT_THREADS);
    timer = new StopWatch<Timers>(Timers.class);
    timer.start(Timers.TOTAL);
    Configuration conf = CachedConfiguration.getInstance();
    final FileSystem fs = FileSystem.get(conf);
    Set<Path> paths = new HashSet<Path>();
    for (String file : files) {
        paths.add(new Path(file));
    }
    AssignmentStats assignmentStats = new AssignmentStats(paths.size());
    final Map<Path, List<KeyExtent>> completeFailures = Collections.synchronizedSortedMap(new TreeMap<Path, List<KeyExtent>>());
    if (!fs.exists(failureDir)) {
        log.error(failureDir + "" does not exist"");
        throw new RuntimeException(""Directory does not exist "" + failureDir);
    }
    ClientService.Iface client = null;
    final TabletLocator locator = TabletLocator.getInstance(instance, credentials, new Text(tableId));
    try {
        final Map<Path, List<TabletLocation>> assignments = Collections.synchronizedSortedMap(new TreeMap<Path, List<TabletLocation>>());
        timer.start(Timers.EXAMINE_MAP_FILES);
        ExecutorService threadPool = Executors.newFixedThreadPool(numThreads);
        for (Path path : paths) {
            final Path mapFile = path;
            Runnable getAssignments = new Runnable() {

                public void run() {
                    List<TabletLocation> tabletsToAssignMapFileTo = Collections.emptyList();
                    try {
                        tabletsToAssignMapFileTo = findOverlappingTablets(instance.getConfiguration(), fs, locator, mapFile);
                    } catch (Exception ex) {
                        log.warn(""Unable to find tablets that overlap file "" + mapFile.toString());
                    }
                    if (tabletsToAssignMapFileTo.size() == 0) {
                        List<KeyExtent> empty = Collections.emptyList();
                        completeFailures.put(mapFile, empty);
                    } else
                        assignments.put(mapFile, tabletsToAssignMapFileTo);
                }
            };
            threadPool.submit(new TraceRunnable(new LoggingRunnable(log, getAssignments)));
        }
        threadPool.shutdown();
        while (!threadPool.isTerminated()) {
            try {
                threadPool.awaitTermination(60, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
        }
        timer.stop(Timers.EXAMINE_MAP_FILES);
        assignmentStats.attemptingAssignments(assignments);
        Map<Path, List<KeyExtent>> assignmentFailures = assignMapFiles(acuConf, instance, conf, credentials, fs, tableId, assignments, paths, numAssignThreads, numThreads);
        assignmentStats.assignmentsFailed(assignmentFailures);
        Map<Path, Integer> failureCount = new TreeMap<Path, Integer>();
        for (Entry<Path, List<KeyExtent>> entry : assignmentFailures.entrySet()) failureCount.put(entry.getKey(), 1);
        while (assignmentFailures.size() > 0) {
            locator.invalidateCache();
            // assumption about assignment failures is that it caused by a split
            // happening or a missing location
            // 
            // for splits we need to find children key extents that cover the
            // same key range and are contiguous (no holes, no overlap)
            timer.start(Timers.SLEEP);
            UtilWaitThread.sleep(4000);
            timer.stop(Timers.SLEEP);
            log.debug(""Trying to assign "" + assignmentFailures.size() + "" map files that previously failed on some key extents"");
            assignments.clear();
            // assign to
            for (Entry<Path, List<KeyExtent>> entry : assignmentFailures.entrySet()) {
                Iterator<KeyExtent> keListIter = entry.getValue().iterator();
                List<TabletLocation> tabletsToAssignMapFileTo = new ArrayList<TabletLocation>();
                while (keListIter.hasNext()) {
                    KeyExtent ke = keListIter.next();
                    try {
                        timer.start(Timers.QUERY_METADATA);
                        tabletsToAssignMapFileTo.addAll(findOverlappingTablets(instance.getConfiguration(), fs, locator, entry.getKey(), ke));
                        timer.stop(Timers.QUERY_METADATA);
                        keListIter.remove();
                    } catch (Exception ex) {
                        log.warn(""Exception finding overlapping tablets, will retry tablet "" + ke);
                    }
                }
                if (tabletsToAssignMapFileTo.size() > 0)
                    assignments.put(entry.getKey(), tabletsToAssignMapFileTo);
            }
            assignmentStats.attemptingAssignments(assignments);
            Map<Path, List<KeyExtent>> assignmentFailures2 = assignMapFiles(acuConf, instance, conf, credentials, fs, tableId, assignments, paths, numAssignThreads, numThreads);
            assignmentStats.assignmentsFailed(assignmentFailures2);
            // merge assignmentFailures2 into assignmentFailures
            for (Entry<Path, List<KeyExtent>> entry : assignmentFailures2.entrySet()) {
                assignmentFailures.get(entry.getKey()).addAll(entry.getValue());
                Integer fc = failureCount.get(entry.getKey());
                if (fc == null)
                    fc = 0;
                failureCount.put(entry.getKey(), fc + 1);
            }
            // remove map files that have no more key extents to assign
            Iterator<Entry<Path, List<KeyExtent>>> afIter = assignmentFailures.entrySet().iterator();
            while (afIter.hasNext()) {
                Entry<Path, List<KeyExtent>> entry = afIter.next();
                if (entry.getValue().size() == 0)
                    afIter.remove();
            }
            Set<Entry<Path, Integer>> failureIter = failureCount.entrySet();
            for (Entry<Path, Integer> entry : failureIter) {
                if (entry.getValue() > acuConf.getCount(Property.TSERV_BULK_RETRY) && assignmentFailures.get(entry.getKey()) != null) {
                    log.error(""Map file "" + entry.getKey() + "" failed more than three times, giving up."");
                    completeFailures.put(entry.getKey(), assignmentFailures.get(entry.getKey()));
                    assignmentFailures.remove(entry.getKey());
                }
            }
        }
        assignmentStats.assignmentsAbandoned(completeFailures);
        Set<Path> failedFailures = processFailures(conf, fs, failureDir, completeFailures);
        assignmentStats.unrecoveredMapFiles(failedFailures);
        timer.stop(Timers.TOTAL);
        printReport();
        return assignmentStats;
    } finally {
        if (client != null)
            ServerClient.close(client);
        locator.invalidateCache();
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_5594b2e0,Major,src/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java,146,159,"public void run() {
    List<TabletLocation> tabletsToAssignMapFileTo = Collections.emptyList();
    try {
        tabletsToAssignMapFileTo = findOverlappingTablets(instance.getConfiguration(), fs, locator, mapFile);
    } catch (Exception ex) {
        log.warn(""Unable to find tablets that overlap file "" + mapFile.toString());
    }
    if (tabletsToAssignMapFileTo.size() == 0) {
        List<KeyExtent> empty = Collections.emptyList();
        completeFailures.put(mapFile, empty);
    } else
        assignments.put(mapFile, tabletsToAssignMapFileTo);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_5594b2e0,Major,src/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java,655,683,"public static List<TabletLocation> findOverlappingTablets(AccumuloConfiguration acuConf, FileSystem fs, TabletLocator locator, Path file, Text startRow, Text endRow) throws Exception {
    List<TabletLocation> result = new ArrayList<TabletLocation>();
    Collection<ByteSequence> columnFamilies = Collections.emptyList();
    FileSKVIterator reader = FileOperations.getInstance().openReader(file.toString(), true, fs, fs.getConf(), acuConf);
    try {
        Text row = startRow;
        if (row == null)
            row = new Text();
        while (true) {
            reader.seek(new Range(row, null), columnFamilies, false);
            if (!reader.hasTop())
                break;
            row = reader.getTopKey().getRow();
            TabletLocation tabletLocation = locator.locateTablet(row, false, true);
            result.add(tabletLocation);
            row = tabletLocation.tablet_extent.getEndRow();
            if (row != null && (endRow == null || row.compareTo(endRow) < 0))
                row = Range.followingPrefix(row);
            else
                break;
        }
    } finally {
        reader.close();
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_5594b2e0,Major,src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java,371,450,"@Override
public Repo<Master> call(final long tid, Master master) throws Exception {
    FileSystem fs = TraceFileSystem.wrap(org.apache.accumulo.core.file.FileUtil.getFileSystem(CachedConfiguration.getInstance(), ServerConfiguration.getSiteConfiguration()));
    List<FileStatus> files = new ArrayList<FileStatus>();
    for (FileStatus entry : fs.listStatus(new Path(bulk))) {
        files.add(entry);
    }
    log.debug(""tid "" + tid + "" importing "" + files.size() + "" files"");
    Path writable = new Path(this.errorDir, "".iswritable"");
    if (!fs.createNewFile(writable)) {
        // Maybe this is a re-try... clear the flag and try again
        fs.delete(writable, false);
        if (!fs.createNewFile(writable))
            throw new ThriftTableOperationException(tableId, null, TableOperation.BULK_IMPORT, TableOperationExceptionType.BULK_BAD_ERROR_DIRECTORY, ""Unable to write to "" + this.errorDir);
    }
    fs.delete(writable, false);
    // group files into N-sized chunks, send the chunks to random servers
    final int SERVERS_TO_USE = Math.min(ServerConfiguration.getSystemConfiguration().getCount(Property.MASTER_BULK_SERVERS), master.onlineTabletServers().size());
    log.debug(""tid "" + tid + "" using "" + SERVERS_TO_USE + "" servers"");
    // wait for success, repeat failures R times
    final List<String> filesToLoad = Collections.synchronizedList(new ArrayList<String>());
    for (FileStatus f : files) filesToLoad.add(f.getPath().toString());
    final int RETRIES = Math.max(1, ServerConfiguration.getSystemConfiguration().getCount(Property.MASTER_BULK_RETRIES));
    for (int i = 0; i < RETRIES && filesToLoad.size() > 0; i++) {
        List<Future<?>> results = new ArrayList<Future<?>>();
        for (List<String> chunk : groupFiles(filesToLoad, SERVERS_TO_USE)) {
            final List<String> attempt = chunk;
            results.add(threadPool.submit(new LoggingRunnable(log, new Runnable() {

                @Override
                public void run() {
                    ClientService.Iface client = null;
                    try {
                        client = ServerClient.getConnection(HdfsZooInstance.getInstance());
                        List<String> fail = client.bulkImportFiles(null, SecurityConstants.getSystemCredentials(), tid, tableId, attempt, errorDir, setTime);
                        attempt.removeAll(fail);
                        filesToLoad.removeAll(attempt);
                    } catch (Exception ex) {
                        log.error(ex, ex);
                    } finally {
                        ServerClient.close(client);
                    }
                }
            })));
        }
        for (Future<?> f : results) f.get();
        if (filesToLoad.size() > 0) {
            log.debug(""tid "" + tid + "" attempt "" + (i + 1) + "" "" + filesToLoad + "" failed"");
            UtilWaitThread.sleep(100);
        }
    }
    // Copy/Create failed file markers
    for (String f : filesToLoad) {
        Path orig = new Path(f);
        Path dest = new Path(errorDir, orig.getName());
        try {
            FileUtil.copy(fs, orig, fs, dest, false, true, CachedConfiguration.getInstance());
            log.debug(""tid "" + tid + "" copied "" + orig + "" to "" + dest + "": failed"");
        } catch (IOException ex) {
            try {
                fs.create(dest).close();
                log.debug(""tid "" + tid + "" marked "" + dest + "" failed"");
            } catch (IOException e) {
                log.error(""Unable to create failure flag file "" + dest, e);
            }
        }
    }
    // return the next step, which will perform cleanup
    return new CompleteBulkImport(tableId, source, bulk, errorDir);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_5594b2e0,Major,src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java,408,421,"@Override
public void run() {
    ClientService.Iface client = null;
    try {
        client = ServerClient.getConnection(HdfsZooInstance.getInstance());
        List<String> fail = client.bulkImportFiles(null, SecurityConstants.getSystemCredentials(), tid, tableId, attempt, errorDir, setTime);
        attempt.removeAll(fail);
        filesToLoad.removeAll(attempt);
    } catch (Exception ex) {
        log.error(ex, ex);
    } finally {
        ServerClient.close(client);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_5594b2e0,Major,src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java,452,463,"private List<List<String>> groupFiles(List<String> files, int groups) {
    List<List<String>> result = new ArrayList<List<String>>();
    Iterator<String> iter = files.iterator();
    for (int i = 0; i < groups && iter.hasNext(); i++) {
        List<String> group = new ArrayList<String>();
        for (int j = 0; j < Math.ceil(files.size() / (double) groups) && iter.hasNext(); j++) {
            group.add(iter.next());
        }
        result.add(group);
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_be2fdba7,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/Filter.java,71,79,"/**
 * Iterates over the source until an acceptable key/value pair is found.
 */
protected void findTop() {
    while (getSource().hasTop() && (negate == accept(getSource().getTopKey(), getSource().getTopValue()))) {
        try {
            getSource().next();
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_be2fdba7,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/SortedKeyValueIterator.java,71,71,"/**
 * Advances to the next K,V pair.
 *
 * @throws IOException
 *           if an I/O error occurs.
 * @exception IllegalStateException
 *              if called before seek.
 * @exception NoSuchElementException
 *              if next element doesn't exist.
 */
void next() throws IOException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_be2fdba7,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/SortedKeyValueIterator.java,99,99,"/**
 * Returns top key. Can be called 0 or more times without affecting behavior of next() or hasTop().
 *
 * @return <tt>K</tt>
 * @exception IllegalStateException
 *              if called before seek.
 * @exception NoSuchElementException
 *              if top element doesn't exist.
 */
K getTopKey();"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_be2fdba7,Major,src/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java,109,267,"public AssignmentStats importFiles(List<String> files, Path failureDir) throws IOException, AccumuloException, AccumuloSecurityException, ThriftTableOperationException {
    int numThreads = acuConf.getCount(Property.TSERV_BULK_PROCESS_THREADS);
    int numAssignThreads = acuConf.getCount(Property.TSERV_BULK_ASSIGNMENT_THREADS);
    timer = new StopWatch<Timers>(Timers.class);
    timer.start(Timers.TOTAL);
    Configuration conf = CachedConfiguration.getInstance();
    final FileSystem fs = FileSystem.get(conf);
    Set<Path> paths = new HashSet<Path>();
    for (String file : files) {
        paths.add(new Path(file));
    }
    AssignmentStats assignmentStats = new AssignmentStats(paths.size());
    final Map<Path, List<KeyExtent>> completeFailures = Collections.synchronizedSortedMap(new TreeMap<Path, List<KeyExtent>>());
    if (!fs.exists(failureDir)) {
        log.error(failureDir + "" does not exist"");
        throw new RuntimeException(""Directory does not exist "" + failureDir);
    }
    ClientService.Iface client = null;
    final TabletLocator locator = TabletLocator.getInstance(instance, credentials, new Text(tableId));
    try {
        final Map<Path, List<TabletLocation>> assignments = Collections.synchronizedSortedMap(new TreeMap<Path, List<TabletLocation>>());
        timer.start(Timers.EXAMINE_MAP_FILES);
        ExecutorService threadPool = Executors.newFixedThreadPool(numThreads);
        for (Path path : paths) {
            final Path mapFile = path;
            Runnable getAssignments = new Runnable() {

                public void run() {
                    List<TabletLocation> tabletsToAssignMapFileTo = Collections.emptyList();
                    try {
                        tabletsToAssignMapFileTo = findOverlappingTablets(instance.getConfiguration(), fs, locator, mapFile);
                    } catch (Exception ex) {
                        log.warn(""Unable to find tablets that overlap file "" + mapFile.toString());
                    }
                    if (tabletsToAssignMapFileTo.size() == 0) {
                        List<KeyExtent> empty = Collections.emptyList();
                        completeFailures.put(mapFile, empty);
                    } else
                        assignments.put(mapFile, tabletsToAssignMapFileTo);
                }
            };
            threadPool.submit(new TraceRunnable(new LoggingRunnable(log, getAssignments)));
        }
        threadPool.shutdown();
        while (!threadPool.isTerminated()) {
            try {
                threadPool.awaitTermination(60, TimeUnit.SECONDS);
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
        }
        timer.stop(Timers.EXAMINE_MAP_FILES);
        assignmentStats.attemptingAssignments(assignments);
        Map<Path, List<KeyExtent>> assignmentFailures = assignMapFiles(acuConf, instance, conf, credentials, fs, tableId, assignments, paths, numAssignThreads, numThreads);
        assignmentStats.assignmentsFailed(assignmentFailures);
        Map<Path, Integer> failureCount = new TreeMap<Path, Integer>();
        for (Entry<Path, List<KeyExtent>> entry : assignmentFailures.entrySet()) failureCount.put(entry.getKey(), 1);
        while (assignmentFailures.size() > 0) {
            locator.invalidateCache();
            // assumption about assignment failures is that it caused by a split
            // happening or a missing location
            // 
            // for splits we need to find children key extents that cover the
            // same key range and are contiguous (no holes, no overlap)
            timer.start(Timers.SLEEP);
            UtilWaitThread.sleep(4000);
            timer.stop(Timers.SLEEP);
            log.debug(""Trying to assign "" + assignmentFailures.size() + "" map files that previously failed on some key extents"");
            assignments.clear();
            // assign to
            for (Entry<Path, List<KeyExtent>> entry : assignmentFailures.entrySet()) {
                Iterator<KeyExtent> keListIter = entry.getValue().iterator();
                List<TabletLocation> tabletsToAssignMapFileTo = new ArrayList<TabletLocation>();
                while (keListIter.hasNext()) {
                    KeyExtent ke = keListIter.next();
                    try {
                        timer.start(Timers.QUERY_METADATA);
                        tabletsToAssignMapFileTo.addAll(findOverlappingTablets(instance.getConfiguration(), fs, locator, entry.getKey(), ke));
                        timer.stop(Timers.QUERY_METADATA);
                        keListIter.remove();
                    } catch (Exception ex) {
                        log.warn(""Exception finding overlapping tablets, will retry tablet "" + ke);
                    }
                }
                if (tabletsToAssignMapFileTo.size() > 0)
                    assignments.put(entry.getKey(), tabletsToAssignMapFileTo);
            }
            assignmentStats.attemptingAssignments(assignments);
            Map<Path, List<KeyExtent>> assignmentFailures2 = assignMapFiles(acuConf, instance, conf, credentials, fs, tableId, assignments, paths, numAssignThreads, numThreads);
            assignmentStats.assignmentsFailed(assignmentFailures2);
            // merge assignmentFailures2 into assignmentFailures
            for (Entry<Path, List<KeyExtent>> entry : assignmentFailures2.entrySet()) {
                assignmentFailures.get(entry.getKey()).addAll(entry.getValue());
                Integer fc = failureCount.get(entry.getKey());
                if (fc == null)
                    fc = 0;
                failureCount.put(entry.getKey(), fc + 1);
            }
            // remove map files that have no more key extents to assign
            Iterator<Entry<Path, List<KeyExtent>>> afIter = assignmentFailures.entrySet().iterator();
            while (afIter.hasNext()) {
                Entry<Path, List<KeyExtent>> entry = afIter.next();
                if (entry.getValue().size() == 0)
                    afIter.remove();
            }
            Set<Entry<Path, Integer>> failureIter = failureCount.entrySet();
            for (Entry<Path, Integer> entry : failureIter) {
                if (entry.getValue() > acuConf.getCount(Property.TSERV_BULK_RETRY) && assignmentFailures.get(entry.getKey()) != null) {
                    log.error(""Map file "" + entry.getKey() + "" failed more than three times, giving up."");
                    completeFailures.put(entry.getKey(), assignmentFailures.get(entry.getKey()));
                    assignmentFailures.remove(entry.getKey());
                }
            }
        }
        assignmentStats.assignmentsAbandoned(completeFailures);
        Set<Path> failedFailures = processFailures(conf, fs, failureDir, completeFailures);
        assignmentStats.unrecoveredMapFiles(failedFailures);
        timer.stop(Timers.TOTAL);
        printReport();
        return assignmentStats;
    } finally {
        if (client != null)
            ServerClient.close(client);
        locator.invalidateCache();
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_be2fdba7,Major,src/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java,146,159,"public void run() {
    List<TabletLocation> tabletsToAssignMapFileTo = Collections.emptyList();
    try {
        tabletsToAssignMapFileTo = findOverlappingTablets(instance.getConfiguration(), fs, locator, mapFile);
    } catch (Exception ex) {
        log.warn(""Unable to find tablets that overlap file "" + mapFile.toString());
    }
    if (tabletsToAssignMapFileTo.size() == 0) {
        List<KeyExtent> empty = Collections.emptyList();
        completeFailures.put(mapFile, empty);
    } else
        assignments.put(mapFile, tabletsToAssignMapFileTo);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_be2fdba7,Major,src/server/src/main/java/org/apache/accumulo/server/client/BulkImporter.java,655,683,"public static List<TabletLocation> findOverlappingTablets(AccumuloConfiguration acuConf, FileSystem fs, TabletLocator locator, Path file, Text startRow, Text endRow) throws Exception {
    List<TabletLocation> result = new ArrayList<TabletLocation>();
    Collection<ByteSequence> columnFamilies = Collections.emptyList();
    FileSKVIterator reader = FileOperations.getInstance().openReader(file.toString(), true, fs, fs.getConf(), acuConf);
    try {
        Text row = startRow;
        if (row == null)
            row = new Text();
        while (true) {
            reader.seek(new Range(row, null), columnFamilies, false);
            if (!reader.hasTop())
                break;
            row = reader.getTopKey().getRow();
            TabletLocation tabletLocation = locator.locateTablet(row, false, true);
            result.add(tabletLocation);
            row = tabletLocation.tablet_extent.getEndRow();
            if (row != null && (endRow == null || row.compareTo(endRow) < 0))
                row = Range.followingPrefix(row);
            else
                break;
        }
    } finally {
        reader.close();
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_be2fdba7,Major,src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java,371,450,"@Override
public Repo<Master> call(final long tid, Master master) throws Exception {
    FileSystem fs = TraceFileSystem.wrap(org.apache.accumulo.core.file.FileUtil.getFileSystem(CachedConfiguration.getInstance(), ServerConfiguration.getSiteConfiguration()));
    List<FileStatus> files = new ArrayList<FileStatus>();
    for (FileStatus entry : fs.listStatus(new Path(bulk))) {
        files.add(entry);
    }
    log.debug(""tid "" + tid + "" importing "" + files.size() + "" files"");
    Path writable = new Path(this.errorDir, "".iswritable"");
    if (!fs.createNewFile(writable)) {
        // Maybe this is a re-try... clear the flag and try again
        fs.delete(writable, false);
        if (!fs.createNewFile(writable))
            throw new ThriftTableOperationException(tableId, null, TableOperation.BULK_IMPORT, TableOperationExceptionType.BULK_BAD_ERROR_DIRECTORY, ""Unable to write to "" + this.errorDir);
    }
    fs.delete(writable, false);
    // group files into N-sized chunks, send the chunks to random servers
    final int SERVERS_TO_USE = Math.min(ServerConfiguration.getSystemConfiguration().getCount(Property.MASTER_BULK_SERVERS), master.onlineTabletServers().size());
    log.debug(""tid "" + tid + "" using "" + SERVERS_TO_USE + "" servers"");
    // wait for success, repeat failures R times
    final List<String> filesToLoad = Collections.synchronizedList(new ArrayList<String>());
    for (FileStatus f : files) filesToLoad.add(f.getPath().toString());
    final int RETRIES = Math.max(1, ServerConfiguration.getSystemConfiguration().getCount(Property.MASTER_BULK_RETRIES));
    for (int i = 0; i < RETRIES && filesToLoad.size() > 0; i++) {
        List<Future<?>> results = new ArrayList<Future<?>>();
        for (List<String> chunk : groupFiles(filesToLoad, SERVERS_TO_USE)) {
            final List<String> attempt = chunk;
            results.add(threadPool.submit(new LoggingRunnable(log, new Runnable() {

                @Override
                public void run() {
                    ClientService.Iface client = null;
                    try {
                        client = ServerClient.getConnection(HdfsZooInstance.getInstance());
                        List<String> fail = client.bulkImportFiles(null, SecurityConstants.getSystemCredentials(), tid, tableId, attempt, errorDir, setTime);
                        attempt.removeAll(fail);
                        filesToLoad.removeAll(attempt);
                    } catch (Exception ex) {
                        log.error(ex, ex);
                    } finally {
                        ServerClient.close(client);
                    }
                }
            })));
        }
        for (Future<?> f : results) f.get();
        if (filesToLoad.size() > 0) {
            log.debug(""tid "" + tid + "" attempt "" + (i + 1) + "" "" + filesToLoad + "" failed"");
            UtilWaitThread.sleep(100);
        }
    }
    // Copy/Create failed file markers
    for (String f : filesToLoad) {
        Path orig = new Path(f);
        Path dest = new Path(errorDir, orig.getName());
        try {
            FileUtil.copy(fs, orig, fs, dest, false, true, CachedConfiguration.getInstance());
            log.debug(""tid "" + tid + "" copied "" + orig + "" to "" + dest + "": failed"");
        } catch (IOException ex) {
            try {
                fs.create(dest).close();
                log.debug(""tid "" + tid + "" marked "" + dest + "" failed"");
            } catch (IOException e) {
                log.error(""Unable to create failure flag file "" + dest, e);
            }
        }
    }
    // return the next step, which will perform cleanup
    return new CompleteBulkImport(tableId, source, bulk, errorDir);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_be2fdba7,Major,src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java,408,421,"@Override
public void run() {
    ClientService.Iface client = null;
    try {
        client = ServerClient.getConnection(HdfsZooInstance.getInstance());
        List<String> fail = client.bulkImportFiles(null, SecurityConstants.getSystemCredentials(), tid, tableId, attempt, errorDir, setTime);
        attempt.removeAll(fail);
        filesToLoad.removeAll(attempt);
    } catch (Exception ex) {
        log.error(ex, ex);
    } finally {
        ServerClient.close(client);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-412_be2fdba7,Major,src/server/src/main/java/org/apache/accumulo/server/master/tableOps/BulkImport.java,452,463,"private List<List<String>> groupFiles(List<String> files, int groups) {
    List<List<String>> result = new ArrayList<List<String>>();
    Iterator<String> iter = files.iterator();
    for (int i = 0; i < groups && iter.hasNext(); i++) {
        List<String> group = new ArrayList<String>();
        for (int j = 0; j < Math.ceil(files.size() / (double) groups) && iter.hasNext(); j++) {
            group.add(iter.next());
        }
        result.add(group);
    }
    return result;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_4d23d784,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/OptUtil.java,119,123,"public static Option startRowOpt() {
    final Option o = new Option(START_ROW_OPT, ""begin-row"", true, ""begin row (NOT) inclusive"");
    o.setArgName(""begin-row"");
    return o;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_50db442b,Major,core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java,269,269,"/**
 * Starts a full major compaction of the tablets in the range (start, end]. The compaction is preformed even for tablets that have only one file.
 *
 * @param tableName
 *          the table to compact
 * @param start
 *          first tablet to be compacted contains the row after this row, null means the first tablet in table
 * @param end
 *          last tablet to be merged contains this row, null means the last tablet in table
 * @param flush
 *          when true, table memory is flushed before compaction starts
 * @param wait
 *          when true, the call will not return until compactions are finished
 */
void compact(String tableName, Text start, Text end, boolean flush, boolean wait) throws AccumuloSecurityException, TableNotFoundException, AccumuloException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_50db442b,Major,core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java,288,289,"/**
 * Starts a full major compaction of the tablets in the range (start, end]. The compaction is preformed even for tablets that have only one file.
 *
 * @param tableName
 *          the table to compact
 * @param start
 *          first tablet to be compacted contains the row after this row, null means the first tablet in table
 * @param end
 *          last tablet to be merged contains this row, null means the last tablet in table
 * @param iterators
 *          A set of iterators that will be applied to each tablet compacted
 * @param flush
 *          when true, table memory is flushed before compaction starts
 * @param wait
 *          when true, the call will not return until compactions are finished
 * @since 1.5.0
 */
void compact(String tableName, Text start, Text end, List<IteratorSetting> iterators, boolean flush, boolean wait) throws AccumuloSecurityException, TableNotFoundException, AccumuloException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_50db442b,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/DeleteRowsCommand.java,53,64,"@Override
public Options getOptions() {
    final Options o = new Options();
    forceOpt = new Option(""f"", ""force"", false, ""delete data even if start or end are not specified"");
    startRowOptExclusive = new Option(OptUtil.START_ROW_OPT, ""begin-row"", true, ""begin row (exclusive)"");
    startRowOptExclusive.setArgName(""begin-row"");
    o.addOption(startRowOptExclusive);
    o.addOption(OptUtil.endRowOpt());
    o.addOption(OptUtil.tableOpt(""table to delete a row range from""));
    o.addOption(forceOpt);
    return o;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_50db442b,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/MergeCommand.java,92,109,"@Override
public Options getOptions() {
    final Options o = new Options();
    verboseOpt = new Option(""v"", ""verbose"", false, ""verbose output during merge"");
    sizeOpt = new Option(""s"", ""size"", true, ""merge tablets to the given size over the entire table"");
    forceOpt = new Option(""f"", ""force"", false, ""merge small tablets to large tablets, even if it goes over the given size"");
    allOpt = new Option("""", ""all"", false, ""allow an entire table to be merged into one tablet without prompting the user for confirmation"");
    Option startRowOpt = OptUtil.startRowOpt();
    startRowOpt.setDescription(""begin row (NOT inclusive)"");
    o.addOption(startRowOpt);
    o.addOption(OptUtil.endRowOpt());
    o.addOption(OptUtil.tableOpt(""table to be merged""));
    o.addOption(verboseOpt);
    o.addOption(sizeOpt);
    o.addOption(forceOpt);
    o.addOption(allOpt);
    return o;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_50db442b,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/OptUtil.java,119,123,"public static Option startRowOpt() {
    final Option o = new Option(START_ROW_OPT, ""begin-row"", true, ""begin row (inclusive)"");
    o.setArgName(""begin-row"");
    return o;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_50db442b,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/ScanCommand.java,286,338,"@Override
public Options getOptions() {
    final Options o = new Options();
    scanOptAuths = new Option(""s"", ""scan-authorizations"", true, ""scan authorizations (all user auths are used if this argument is not specified)"");
    optStartRowExclusive = new Option(""be"", ""begin-exclusive"", false, ""make start row exclusive (by default it's inclusive)"");
    optStartRowExclusive.setArgName(""begin-exclusive"");
    optEndRowExclusive = new Option(""ee"", ""end-exclusive"", false, ""make end row exclusive (by default it's inclusive)"");
    optEndRowExclusive.setArgName(""end-exclusive"");
    scanOptRow = new Option(""r"", ""row"", true, ""row to scan"");
    scanOptColumns = new Option(""c"", ""columns"", true, ""comma-separated columns"");
    timestampOpt = new Option(""st"", ""show-timestamps"", false, ""display timestamps"");
    disablePaginationOpt = new Option(""np"", ""no-pagination"", false, ""disable pagination of output"");
    showFewOpt = new Option(""f"", ""show-few"", true, ""show only a specified number of characters"");
    formatterOpt = new Option(""fm"", ""formatter"", true, ""fully qualified name of the formatter class to use"");
    interpreterOpt = new Option(""i"", ""interpreter"", true, ""fully qualified name of the interpreter class to use"");
    formatterInterpeterOpt = new Option(""fi"", ""fmt-interpreter"", true, ""fully qualified name of a class that is a formatter and interpreter"");
    timeoutOption = new Option(null, ""timeout"", true, ""time before scan should fail if no data is returned. If no unit is given assumes seconds.  Units d,h,m,s,and ms are supported.  e.g. 30s or 100ms"");
    outputFileOpt = new Option(""o"", ""output"", true, ""local file to write the scan output to"");
    scanOptAuths.setArgName(""comma-separated-authorizations"");
    scanOptRow.setArgName(""row"");
    scanOptColumns.setArgName(""<columnfamily>[:<columnqualifier>]{,<columnfamily>[:<columnqualifier>]}"");
    showFewOpt.setRequired(false);
    showFewOpt.setArgName(""int"");
    formatterOpt.setArgName(""className"");
    timeoutOption.setArgName(""timeout"");
    outputFileOpt.setArgName(""file"");
    profileOpt = new Option(""pn"", ""profile"", true, ""iterator profile name"");
    profileOpt.setArgName(""profile"");
    o.addOption(scanOptAuths);
    o.addOption(scanOptRow);
    o.addOption(OptUtil.startRowOpt());
    o.addOption(OptUtil.endRowOpt());
    o.addOption(optStartRowExclusive);
    o.addOption(optEndRowExclusive);
    o.addOption(scanOptColumns);
    o.addOption(timestampOpt);
    o.addOption(disablePaginationOpt);
    o.addOption(OptUtil.tableOpt(""table to be scanned""));
    o.addOption(showFewOpt);
    o.addOption(formatterOpt);
    o.addOption(interpreterOpt);
    o.addOption(formatterInterpeterOpt);
    o.addOption(timeoutOption);
    o.addOption(outputFileOpt);
    o.addOption(profileOpt);
    return o;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_eb0f9b41,Major,core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java,269,269,"/**
 * Starts a full major compaction of the tablets in the range (start, end]. The compaction is preformed even for tablets that have only one file.
 *
 * @param tableName
 *          the table to compact
 * @param start
 *          first tablet to be compacted contains the row after this row, null means the first tablet in table
 * @param end
 *          last tablet to be merged contains this row, null means the last tablet in table
 * @param flush
 *          when true, table memory is flushed before compaction starts
 * @param wait
 *          when true, the call will not return until compactions are finished
 */
void compact(String tableName, Text start, Text end, boolean flush, boolean wait) throws AccumuloSecurityException, TableNotFoundException, AccumuloException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_eb0f9b41,Major,core/src/main/java/org/apache/accumulo/core/client/admin/TableOperations.java,288,289,"/**
 * Starts a full major compaction of the tablets in the range (start, end]. The compaction is preformed even for tablets that have only one file.
 *
 * @param tableName
 *          the table to compact
 * @param start
 *          first tablet to be compacted contains the row after this row, null means the first tablet in table
 * @param end
 *          last tablet to be merged contains this row, null means the last tablet in table
 * @param iterators
 *          A set of iterators that will be applied to each tablet compacted
 * @param flush
 *          when true, table memory is flushed before compaction starts
 * @param wait
 *          when true, the call will not return until compactions are finished
 * @since 1.5.0
 */
void compact(String tableName, Text start, Text end, List<IteratorSetting> iterators, boolean flush, boolean wait) throws AccumuloSecurityException, TableNotFoundException, AccumuloException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_eb0f9b41,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/DeleteRowsCommand.java,53,64,"@Override
public Options getOptions() {
    final Options o = new Options();
    forceOpt = new Option(""f"", ""force"", false, ""delete data even if start or end are not specified"");
    startRowOptExclusive = new Option(OptUtil.START_ROW_OPT, ""begin-row"", true, ""begin row (exclusive)"");
    startRowOptExclusive.setArgName(""begin-row"");
    o.addOption(startRowOptExclusive);
    o.addOption(OptUtil.endRowOpt());
    o.addOption(OptUtil.tableOpt(""table to delete a row range from""));
    o.addOption(forceOpt);
    return o;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_eb0f9b41,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/MergeCommand.java,92,109,"@Override
public Options getOptions() {
    final Options o = new Options();
    verboseOpt = new Option(""v"", ""verbose"", false, ""verbose output during merge"");
    sizeOpt = new Option(""s"", ""size"", true, ""merge tablets to the given size over the entire table"");
    forceOpt = new Option(""f"", ""force"", false, ""merge small tablets to large tablets, even if it goes over the given size"");
    allOpt = new Option("""", ""all"", false, ""allow an entire table to be merged into one tablet without prompting the user for confirmation"");
    Option startRowOpt = OptUtil.startRowOpt();
    startRowOpt.setDescription(""begin row (NOT inclusive)"");
    o.addOption(startRowOpt);
    o.addOption(OptUtil.endRowOpt());
    o.addOption(OptUtil.tableOpt(""table to be merged""));
    o.addOption(verboseOpt);
    o.addOption(sizeOpt);
    o.addOption(forceOpt);
    o.addOption(allOpt);
    return o;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_eb0f9b41,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/OptUtil.java,119,123,"public static Option startRowOpt() {
    final Option o = new Option(START_ROW_OPT, ""begin-row"", true, ""begin row (inclusive)"");
    o.setArgName(""begin-row"");
    return o;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-4138_eb0f9b41,Major,core/src/main/java/org/apache/accumulo/core/util/shell/commands/ScanCommand.java,286,338,"@Override
public Options getOptions() {
    final Options o = new Options();
    scanOptAuths = new Option(""s"", ""scan-authorizations"", true, ""scan authorizations (all user auths are used if this argument is not specified)"");
    optStartRowExclusive = new Option(""be"", ""begin-exclusive"", false, ""make start row exclusive (by default it's inclusive)"");
    optStartRowExclusive.setArgName(""begin-exclusive"");
    optEndRowExclusive = new Option(""ee"", ""end-exclusive"", false, ""make end row exclusive (by default it's inclusive)"");
    optEndRowExclusive.setArgName(""end-exclusive"");
    scanOptRow = new Option(""r"", ""row"", true, ""row to scan"");
    scanOptColumns = new Option(""c"", ""columns"", true, ""comma-separated columns"");
    timestampOpt = new Option(""st"", ""show-timestamps"", false, ""display timestamps"");
    disablePaginationOpt = new Option(""np"", ""no-pagination"", false, ""disable pagination of output"");
    showFewOpt = new Option(""f"", ""show-few"", true, ""show only a specified number of characters"");
    formatterOpt = new Option(""fm"", ""formatter"", true, ""fully qualified name of the formatter class to use"");
    interpreterOpt = new Option(""i"", ""interpreter"", true, ""fully qualified name of the interpreter class to use"");
    formatterInterpeterOpt = new Option(""fi"", ""fmt-interpreter"", true, ""fully qualified name of a class that is a formatter and interpreter"");
    timeoutOption = new Option(null, ""timeout"", true, ""time before scan should fail if no data is returned. If no unit is given assumes seconds.  Units d,h,m,s,and ms are supported.  e.g. 30s or 100ms"");
    outputFileOpt = new Option(""o"", ""output"", true, ""local file to write the scan output to"");
    scanOptAuths.setArgName(""comma-separated-authorizations"");
    scanOptRow.setArgName(""row"");
    scanOptColumns.setArgName(""<columnfamily>[:<columnqualifier>]{,<columnfamily>[:<columnqualifier>]}"");
    showFewOpt.setRequired(false);
    showFewOpt.setArgName(""int"");
    formatterOpt.setArgName(""className"");
    timeoutOption.setArgName(""timeout"");
    outputFileOpt.setArgName(""file"");
    profileOpt = new Option(""pn"", ""profile"", true, ""iterator profile name"");
    profileOpt.setArgName(""profile"");
    o.addOption(scanOptAuths);
    o.addOption(scanOptRow);
    o.addOption(OptUtil.startRowOpt());
    o.addOption(OptUtil.endRowOpt());
    o.addOption(optStartRowExclusive);
    o.addOption(optEndRowExclusive);
    o.addOption(scanOptColumns);
    o.addOption(timestampOpt);
    o.addOption(disablePaginationOpt);
    o.addOption(OptUtil.tableOpt(""table to be scanned""));
    o.addOption(showFewOpt);
    o.addOption(formatterOpt);
    o.addOption(interpreterOpt);
    o.addOption(formatterInterpeterOpt);
    o.addOption(timeoutOption);
    o.addOption(outputFileOpt);
    o.addOption(profileOpt);
    return o;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-414_116d5928,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/GrepIterator.java,37,49,"@Override
protected void consume() throws IOException {
    while (getSource().hasTop()) {
        Key k = getSource().getTopKey();
        Value v = getSource().getTopValue();
        if (match(v.get()) || match(k.getRowData()) || match(k.getColumnFamilyData()) || match(k.getColumnQualifierData())) {
            break;
        }
        getSource().next();
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-414_116d5928,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/user/GrepIterator.java,89,92,"@Override
public SortedKeyValueIterator<Key, Value> deepCopy(IteratorEnvironment env) {
    throw new UnsupportedOperationException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-414_ebf22df0,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/Filter.java,71,79,"/**
 * Iterates over the source until an acceptable key/value pair is found.
 */
protected void findTop() {
    while (getSource().hasTop() && (negate == accept(getSource().getTopKey(), getSource().getTopValue()))) {
        try {
            getSource().next();
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-414_ebf22df0,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/SortedKeyValueIterator.java,71,71,"/**
 * Advances to the next K,V pair.
 *
 * @throws IOException
 *           if an I/O error occurs.
 * @exception IllegalStateException
 *              if called before seek.
 * @exception NoSuchElementException
 *              if next element doesn't exist.
 */
void next() throws IOException;"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-414_ebf22df0,Major,src/core/src/main/java/org/apache/accumulo/core/iterators/SortedKeyValueIterator.java,99,99,"/**
 * Returns top key. Can be called 0 or more times without affecting behavior of next() or hasTop().
 *
 * @return <tt>K</tt>
 * @exception IllegalStateException
 *              if called before seek.
 * @exception NoSuchElementException
 *              if top element doesn't exist.
 */
K getTopKey();"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-633_8dad5e0f,Minor,core/src/main/java/org/apache/accumulo/core/iterators/FirstEntryInRowIterator.java,76,96,"// this is only ever called immediately after getting ""next"" entry
@Override
protected void consume() throws IOException {
    int count = 0;
    while (getSource().hasTop() && lastRowFound.equals(getSource().getTopKey().getRow())) {
        // try to efficiently jump to the next matching key
        if (count < numscans) {
            ++count;
            // scan
            getSource().next();
        } else {
            // too many scans, just seek
            count = 0;
            // determine where to seek to, but don't go beyond the user-specified range
            Key nextKey = getSource().getTopKey().followingKey(PartialKey.ROW);
            if (!latestRange.afterEndKey(nextKey))
                getSource().seek(new Range(nextKey, true, latestRange.getEndKey(), latestRange.isEndKeyInclusive()), latestColumnFamilies, latestInclusive);
        }
    }
    lastRowFound = getSource().hasTop() ? getSource().getTopKey().getRow(lastRowFound) : null;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-633_8dad5e0f,Minor,core/src/main/java/org/apache/accumulo/core/iterators/FirstEntryInRowIterator.java,98,108,"@Override
public void seek(Range range, Collection<ByteSequence> columnFamilies, boolean inclusive) throws IOException {
    // save parameters for future internal seeks
    latestRange = range;
    latestColumnFamilies = columnFamilies;
    latestInclusive = inclusive;
    // seek to first possible pattern in range
    super.seek(range, columnFamilies, inclusive);
    lastRowFound = getSource().hasTop() ? getSource().getTopKey().getRow() : null;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-776_dc9f23d9,Minor,core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java,69,100,"@Override
public void init(SortedKeyValueIterator<Key, Value> source, Map<String, String> options, IteratorEnvironment env) throws IOException {
    super.init(source, options, env);
    if (options == null)
        throw new IllegalArgumentException(""start and/or end must be set for "" + TimestampFilter.class.getName());
    hasStart = false;
    hasEnd = false;
    startInclusive = true;
    endInclusive = true;
    if (options.containsKey(START))
        hasStart = true;
    if (options.containsKey(END))
        hasEnd = true;
    if (!hasStart && !hasEnd)
        throw new IllegalArgumentException(""must have either start or end for "" + TimestampFilter.class.getName());
    try {
        if (hasStart)
            start = dateParser.parse(options.get(START)).getTime();
        if (hasEnd)
            end = dateParser.parse(options.get(END)).getTime();
    } catch (Exception e) {
        throw new IllegalArgumentException(e);
    }
    if (options.get(START_INCL) != null)
        startInclusive = Boolean.parseBoolean(options.get(START_INCL));
    if (options.get(END_INCL) != null)
        endInclusive = Boolean.parseBoolean(options.get(END_INCL));
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-776_dc9f23d9,Minor,core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java,114,124,"@Override
public IteratorOptions describeOptions() {
    IteratorOptions io = super.describeOptions();
    io.setName(""tsfilter"");
    io.setDescription(""TimestampFilter displays entries with timestamps between specified values"");
    io.addNamedOption(""start"", ""start timestamp (yyyyMMddHHmmssz)"");
    io.addNamedOption(""end"", ""end timestamp (yyyyMMddHHmmssz)"");
    io.addNamedOption(""startInclusive"", ""true or false"");
    io.addNamedOption(""endInclusive"", ""true or false"");
    return io;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-776_dc9f23d9,Minor,core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java,126,142,"@Override
public boolean validateOptions(Map<String, String> options) {
    super.validateOptions(options);
    try {
        if (options.containsKey(START))
            dateParser.parse(options.get(START));
        if (options.containsKey(END))
            dateParser.parse(options.get(END));
        if (options.get(START_INCL) != null)
            Boolean.parseBoolean(options.get(START_INCL));
        if (options.get(END_INCL) != null)
            Boolean.parseBoolean(options.get(END_INCL));
    } catch (Exception e) {
        return false;
    }
    return true;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-776_dc9f23d9,Minor,core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java,187,190,"/**
 * A convenience method for setting the start timestamp accepted by the timestamp filter.
 *
 * @param is
 *          the iterator setting object to configure
 * @param start
 *          the start timestamp (yyyyMMddHHmmssz)
 * @param startInclusive
 *          boolean indicating whether the start is inclusive
 */
public static void setStart(IteratorSetting is, String start, boolean startInclusive) {
    is.addOption(START, start);
    is.addOption(START_INCL, Boolean.toString(startInclusive));
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-776_dc9f23d9,Minor,core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java,202,205,"/**
 * A convenience method for setting the end timestamp accepted by the timestamp filter.
 *
 * @param is
 *          the iterator setting object to configure
 * @param end
 *          the end timestamp (yyyyMMddHHmmssz)
 * @param endInclusive
 *          boolean indicating whether the end is inclusive
 */
public static void setEnd(IteratorSetting is, String end, boolean endInclusive) {
    is.addOption(END, end);
    is.addOption(END_INCL, Boolean.toString(endInclusive));
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-776_dc9f23d9,Minor,core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java,250,254,"/**
 * A convenience method for setting the start timestamp accepted by the timestamp filter.
 *
 * @param is
 *          the iterator setting object to configure
 * @param start
 *          the start timestamp
 * @param startInclusive
 *          boolean indicating whether the start is inclusive
 */
public static void setStart(IteratorSetting is, long start, boolean startInclusive) {
    SimpleDateFormat dateParser = initDateParser();
    is.addOption(START, dateParser.format(new Date(start)));
    is.addOption(START_INCL, Boolean.toString(startInclusive));
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-776_dc9f23d9,Minor,core/src/main/java/org/apache/accumulo/core/iterators/user/TimestampFilter.java,266,270,"/**
 * A convenience method for setting the end timestamp accepted by the timestamp filter.
 *
 * @param is
 *          the iterator setting object to configure
 * @param end
 *          the end timestamp
 * @param endInclusive
 *          boolean indicating whether the end is inclusive
 */
public static void setEnd(IteratorSetting is, long end, boolean endInclusive) {
    SimpleDateFormat dateParser = initDateParser();
    is.addOption(END, dateParser.format(new Date(end)));
    is.addOption(END_INCL, Boolean.toString(endInclusive));
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-795_9453bcfa,Minor,core/src/main/java/org/apache/accumulo/core/client/admin/TableOperationsImpl.java,188,205,"/**
 * @param tableName
 *          the name of the table
 * @param timeType
 *          specifies logical or real-time based time recording for entries in the table
 * @param limitVersion
 *          Enables/disables the versioning iterator, which will limit the number of Key versions kept.
 */
public void create(String tableName, boolean limitVersion, TimeType timeType) throws AccumuloException, AccumuloSecurityException, TableExistsException {
    ArgumentChecker.notNull(tableName, timeType);
    List<ByteBuffer> args = Arrays.asList(ByteBuffer.wrap(tableName.getBytes()), ByteBuffer.wrap(timeType.name().getBytes()));
    Map<String, String> opts;
    if (limitVersion) {
        opts = IteratorUtil.generateInitialTableProperties();
    } else
        opts = Collections.emptyMap();
    try {
        doTableOperation(TableOperation.CREATE, args, opts);
    } catch (TableNotFoundException e1) {
        // should not happen
        throw new RuntimeException(e1);
    }
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-795_9453bcfa,Minor,core/src/main/java/org/apache/accumulo/core/iterators/IteratorUtil.java,66,74,"public static Map<String, String> generateInitialTableProperties() {
    TreeMap<String, String> props = new TreeMap<String, String>();
    for (IteratorScope iterScope : IteratorScope.values()) {
        props.put(Property.TABLE_ITERATOR_PREFIX + iterScope.name() + "".vers"", ""20,"" + VersioningIterator.class.getName());
        props.put(Property.TABLE_ITERATOR_PREFIX + iterScope.name() + "".vers.opt.maxVersions"", ""1"");
    }
    return props;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-795_9453bcfa,Minor,core/src/main/java/org/apache/accumulo/core/util/shell/commands/CreateTableCommand.java,56,147,"public int execute(final String fullCommand, final CommandLine cl, final Shell shellState) throws AccumuloException, AccumuloSecurityException, TableExistsException, TableNotFoundException, IOException, ClassNotFoundException {
    final String testTableName = cl.getArgs()[0];
    if (!testTableName.matches(Constants.VALID_TABLE_NAME_REGEX)) {
        shellState.getReader().printString(""Only letters, numbers and underscores are allowed for use in table names. \n"");
        throw new IllegalArgumentException();
    }
    final String tableName = cl.getArgs()[0];
    if (shellState.getConnector().tableOperations().exists(tableName)) {
        throw new TableExistsException(null, tableName, null);
    }
    final SortedSet<Text> partitions = new TreeSet<Text>();
    final boolean decode = cl.hasOption(base64Opt.getOpt());
    if (cl.hasOption(createTableOptSplit.getOpt())) {
        final String f = cl.getOptionValue(createTableOptSplit.getOpt());
        String line;
        Scanner file = new Scanner(new File(f));
        while (file.hasNextLine()) {
            line = file.nextLine();
            if (!line.isEmpty()) {
                partitions.add(decode ? new Text(Base64.decodeBase64(line.getBytes())) : new Text(line));
            }
        }
    } else if (cl.hasOption(createTableOptCopySplits.getOpt())) {
        final String oldTable = cl.getOptionValue(createTableOptCopySplits.getOpt());
        if (!shellState.getConnector().tableOperations().exists(oldTable)) {
            throw new TableNotFoundException(null, oldTable, null);
        }
        partitions.addAll(shellState.getConnector().tableOperations().getSplits(oldTable));
    }
    if (cl.hasOption(createTableOptCopyConfig.getOpt())) {
        final String oldTable = cl.getOptionValue(createTableOptCopyConfig.getOpt());
        if (!shellState.getConnector().tableOperations().exists(oldTable)) {
            throw new TableNotFoundException(null, oldTable, null);
        }
    }
    TimeType timeType = TimeType.MILLIS;
    if (cl.hasOption(createTableOptTimeLogical.getOpt())) {
        timeType = TimeType.LOGICAL;
    }
    // create table
    shellState.getConnector().tableOperations().create(tableName, true, timeType);
    if (partitions.size() > 0) {
        shellState.getConnector().tableOperations().addSplits(tableName, partitions);
    }
    // switch shell to new table
    shellState.setTableName(tableName);
    if (cl.hasOption(createTableNoDefaultIters.getOpt())) {
        for (String key : IteratorUtil.generateInitialTableProperties().keySet()) {
            shellState.getConnector().tableOperations().removeProperty(tableName, key);
        }
    }
    // Copy options if flag was set
    if (cl.hasOption(createTableOptCopyConfig.getOpt())) {
        if (shellState.getConnector().tableOperations().exists(tableName)) {
            final Iterable<Entry<String, String>> configuration = shellState.getConnector().tableOperations().getProperties(cl.getOptionValue(createTableOptCopyConfig.getOpt()));
            for (Entry<String, String> entry : configuration) {
                if (Property.isValidTablePropertyKey(entry.getKey())) {
                    shellState.getConnector().tableOperations().setProperty(tableName, entry.getKey(), entry.getValue());
                }
            }
        }
    }
    if (cl.hasOption(createTableOptEVC.getOpt())) {
        try {
            shellState.getConnector().tableOperations().addConstraint(tableName, VisibilityConstraint.class.getName());
        } catch (AccumuloException e) {
            Shell.log.warn(e.getMessage() + "" while setting visibility constraint, but table was created"");
        }
    }
    // Load custom formatter if set
    if (cl.hasOption(createTableOptFormatter.getOpt())) {
        final String formatterClass = cl.getOptionValue(createTableOptFormatter.getOpt());
        shellState.getConnector().tableOperations().setProperty(tableName, Property.TABLE_FORMATTER_CLASS.toString(), formatterClass);
    }
    return 0;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-821_a450ac2f,Major,core/src/main/java/org/apache/accumulo/core/client/mock/MockBatchScanner.java,71,90,"@SuppressWarnings(""unchecked"")
@Override
public Iterator<Entry<Key, Value>> iterator() {
    if (ranges == null) {
        throw new IllegalStateException(""ranges not set"");
    }
    IteratorChain chain = new IteratorChain();
    for (Range range : ranges) {
        SortedKeyValueIterator<Key, Value> i = new SortedMapIterator(table.table);
        try {
            i = new RangesFilter(createFilter(i), ranges);
            i.seek(range, createColumnBSS(fetchedColumns), !fetchedColumns.isEmpty());
            chain.addIterator(new IteratorAdapter(i));
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }
    return chain;
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,156,159,"@Override
public void setLocalityGroups(String tableName, Map<String, Set<Text>> groups) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
    throw new NotImplementedException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,161,164,"@Override
public Map<String, Set<Text>> getLocalityGroups(String tableName) throws AccumuloException, TableNotFoundException {
    throw new NotImplementedException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,166,170,"@Override
public Set<Range> splitRangeByTablets(String tableName, Range range, int maxSplits) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
    return Collections.singleton(range);
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,263,266,"@Override
public void offline(String tableName) throws AccumuloSecurityException, AccumuloException {
    throw new NotImplementedException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,268,269,"@Override
public void online(String tableName) throws AccumuloSecurityException, AccumuloException {
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,271,274,"@Override
public void clearLocatorCache(String tableName) throws TableNotFoundException {
    throw new NotImplementedException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,285,288,"@Override
public void merge(String tableName, Text start, Text end) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
    throw new NotImplementedException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,290,293,"@Override
public void deleteRows(String tableName, Text start, Text end) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
    throw new NotImplementedException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,295,299,"@Override
public void compact(String tableName, Text start, Text end, boolean flush, boolean wait) throws AccumuloSecurityException, TableNotFoundException, AccumuloException {
    throw new NotImplementedException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,301,305,"@Override
public void compact(String tableName, Text start, Text end, List<IteratorSetting> iterators, boolean flush, boolean wait) throws AccumuloSecurityException, TableNotFoundException, AccumuloException {
    throw new NotImplementedException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-843_65390f8c,Minor,core/src/main/java/org/apache/accumulo/core/client/mock/MockTableOperations.java,313,316,"@Override
public void flush(String tableName, Text start, Text end, boolean wait) throws AccumuloException, AccumuloSecurityException, TableNotFoundException {
    throw new NotImplementedException();
}"
accumulo,remotes/origin/bugs-dot-jar_ACCUMULO-844_692efde2,Critical,core/src/main/java/org/apache/accumulo/core/iterators/system/VisibilityFilter.java,56,77,"@Override
public boolean accept(Key k, Value v) {
    Text testVis = k.getColumnVisibility(tmpVis);
    if (testVis.getLength() == 0 && defaultVisibility.getLength() == 0)
        return true;
    else if (testVis.getLength() == 0)
        testVis = defaultVisibility;
    Boolean b = (Boolean) cache.get(testVis);
    if (b != null)
        return b;
    try {
        Boolean bb = ve.evaluate(new ColumnVisibility(testVis));
        cache.put(new Text(testVis), bb);
        return bb;
    } catch (VisibilityParseException e) {
        log.error(""Parse Error"", e);
        return false;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3276_205420e2,Minor,camel-core/src/main/java/org/apache/camel/util/ExchangeHelper.java,191,223,"/**
 * Copies the results of a message exchange from the source exchange to the result exchange
 * which will copy the out and fault message contents and the exception
 *
 * @param result the result exchange which will have the output and error state added
 * @param source the source exchange which is not modified
 */
public static void copyResults(Exchange result, Exchange source) {
    if (result != source) {
        result.setException(source.getException());
        if (source.hasOut()) {
            result.getOut().copyFrom(source.getOut());
        } else if (result.getPattern() == ExchangePattern.InOptionalOut) {
            // special case where the result is InOptionalOut and with no OUT response
            // so we should return null to indicate this fact
            result.setOut(null);
        } else {
            // so lets assume the last IN is the OUT
            if (result.getPattern().isOutCapable()) {
                // only set OUT if its OUT capable
                result.getOut().copyFrom(source.getIn());
            } else {
                // if not replace IN instead to keep the MEP
                result.getIn().copyFrom(source.getIn());
            }
        }
        if (source.hasProperties()) {
            result.getProperties().putAll(source.getProperties());
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3281_f7dd2fff,Major,camel-core/src/main/java/org/apache/camel/builder/RouteBuilder.java,138,142,"/**
 * Installs the given <a href=""http://camel.apache.org/error-handler.html"">error handler</a> builder
 *
 * @param errorHandlerBuilder  the error handler to be used by default for all child routes
 * @return the current builder with the error handler configured
 */
public RouteBuilder errorHandler(ErrorHandlerBuilder errorHandlerBuilder) {
    routeCollection.setCamelContext(getContext());
    setErrorHandlerBuilder(errorHandlerBuilder);
    return this;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3281_f7dd2fff,Major,camel-core/src/main/java/org/apache/camel/builder/RouteBuilder.java,149,152,"/**
 * Adds a route for an interceptor that intercepts every processing step.
 *
 * @return the builder
 */
public InterceptDefinition intercept() {
    routeCollection.setCamelContext(getContext());
    return routeCollection.intercept();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3281_f7dd2fff,Major,camel-core/src/main/java/org/apache/camel/builder/RouteBuilder.java,159,162,"/**
 * Adds a route for an interceptor that intercepts incoming messages on any inputs in this route
 *
 * @return the builder
 */
public InterceptFromDefinition interceptFrom() {
    routeCollection.setCamelContext(getContext());
    return routeCollection.interceptFrom();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3281_f7dd2fff,Major,camel-core/src/main/java/org/apache/camel/builder/RouteBuilder.java,170,173,"/**
 * Adds a route for an interceptor that intercepts incoming messages on the given endpoint.
 *
 * @param uri  endpoint uri
 * @return the builder
 */
public InterceptFromDefinition interceptFrom(String uri) {
    routeCollection.setCamelContext(getContext());
    return routeCollection.interceptFrom(uri);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3281_f7dd2fff,Major,camel-core/src/main/java/org/apache/camel/builder/RouteBuilder.java,181,184,"/**
 * Applies a route for an interceptor if an exchange is send to the given endpoint
 *
 * @param uri  endpoint uri
 * @return the builder
 */
public InterceptSendToEndpointDefinition interceptSendToEndpoint(String uri) {
    routeCollection.setCamelContext(getContext());
    return routeCollection.interceptSendToEndpoint(uri);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3281_f7dd2fff,Major,camel-core/src/main/java/org/apache/camel/builder/RouteBuilder.java,193,196,"/**
 * <a href=""http://camel.apache.org/exception-clause.html"">Exception clause</a>
 * for catching certain exceptions and handling them.
 *
 * @param exception exception to catch
 * @return the builder
 */
public OnExceptionDefinition onException(Class exception) {
    routeCollection.setCamelContext(getContext());
    return routeCollection.onException(exception);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3281_f7dd2fff,Major,camel-core/src/main/java/org/apache/camel/builder/RouteBuilder.java,219,222,"/**
 * <a href=""http://camel.apache.org/oncompletion.html"">On completion</a>
 * callback for doing custom routing when the {@link org.apache.camel.Exchange} is complete.
 *
 * @return the builder
 */
public OnCompletionDefinition onCompletion() {
    routeCollection.setCamelContext(getContext());
    return routeCollection.onCompletion();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3314_4badd9c5,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,345,377,"protected Processor createOutputsProcessor(RouteContext routeContext, Collection<ProcessorDefinition> outputs) throws Exception {
    List<Processor> list = new ArrayList<Processor>();
    for (ProcessorDefinition<?> output : outputs) {
        Processor processor = null;
        // at first use custom factory
        if (routeContext.getCamelContext().getProcessorFactory() != null) {
            processor = routeContext.getCamelContext().getProcessorFactory().createProcessor(routeContext, output);
        }
        // fallback to default implementation if factory did not create the processor
        if (processor == null) {
            processor = output.createProcessor(routeContext);
        }
        if (output instanceof Channel && processor == null) {
            continue;
        }
        Processor channel = wrapChannel(routeContext, processor, output);
        list.add(channel);
    }
    // if more than one output wrap than in a composite processor else just keep it as is
    Processor processor = null;
    if (!list.isEmpty()) {
        if (list.size() == 1) {
            processor = list.get(0);
        } else {
            processor = createCompositeProcessor(routeContext, list);
        }
    }
    return processor;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3314_4badd9c5,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,382,402,"/**
 * Creates the processor and wraps it in any necessary interceptors and error handlers
 */
protected Processor makeProcessor(RouteContext routeContext) throws Exception {
    Processor processor = null;
    // resolve properties before we create the processor
    resolvePropertyPlaceholders(routeContext);
    // at first use custom factory
    if (routeContext.getCamelContext().getProcessorFactory() != null) {
        processor = routeContext.getCamelContext().getProcessorFactory().createProcessor(routeContext, this);
    }
    // fallback to default implementation if factory did not create the processor
    if (processor == null) {
        processor = createProcessor(routeContext);
    }
    if (processor == null) {
        // no processor to make
        return null;
    }
    return wrapProcessor(routeContext, processor);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3314_4badd9c5,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,415,448,"/**
 * Inspects this processor definition and resolves any property placeholders from its properties.
 * <p/>
 * This implementation will check all the getter/setter pairs on this instance and for all the values
 * (which is a String type) will be property placeholder resolved.
 *
 * @param routeContext the route context
 * @throws Exception is thrown if property placeholders was used and there was an error resolving them
 * @see org.apache.camel.CamelContext#resolvePropertyPlaceholders(String)
 * @see org.apache.camel.component.properties.PropertiesComponent
 */
protected void resolvePropertyPlaceholders(RouteContext routeContext) throws Exception {
    if (log.isTraceEnabled()) {
        log.trace(""Resolving property placeholders for: "" + this);
    }
    // find all String getter/setter
    Map<Object, Object> properties = new HashMap<Object, Object>();
    IntrospectionSupport.getProperties(this, properties, null);
    if (!properties.isEmpty()) {
        if (log.isTraceEnabled()) {
            log.trace(""There are "" + properties.size() + "" properties on: "" + this);
        }
        // lookup and resolve properties for String based properties
        for (Map.Entry entry : properties.entrySet()) {
            // the name is always a String
            String name = (String) entry.getKey();
            Object value = entry.getValue();
            if (value instanceof String) {
                // we can only resolve String typed values
                String text = (String) value;
                text = routeContext.getCamelContext().resolvePropertyPlaceholders(text);
                if (text != value) {
                    // invoke setter as the text has changed
                    IntrospectionSupport.setProperty(this, name, text);
                    if (log.isDebugEnabled()) {
                        log.debug(""Changed property ["" + name + ""] from: "" + value + "" to: "" + text);
                    }
                }
            }
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3388_0919a0f6,Major,camel-core/src/main/java/org/apache/camel/builder/ExpressionBuilder.java,259,270,"/**
 * Returns an expression for the outbound message headers
 *
 * @return an expression object which will return the headers
 */
public static Expression outHeadersExpression() {
    return new ExpressionAdapter() {

        public Object evaluate(Exchange exchange) {
            return exchange.getOut().getHeaders();
        }

        @Override
        public String toString() {
            return ""outHeaders"";
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3388_0919a0f6,Major,camel-core/src/main/java/org/apache/camel/builder/ExpressionBuilder.java,261,263,"public Object evaluate(Exchange exchange) {
    return exchange.getOut().getHeaders();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3394_18e1a142,Minor,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,171,206,"public boolean process(Exchange exchange, AsyncCallback callback) {
    final AtomicExchange result = new AtomicExchange();
    final Iterable<ProcessorExchangePair> pairs;
    // so use try .. catch to cater for this
    try {
        boolean sync = true;
        pairs = createProcessorExchangePairs(exchange);
        if (isParallelProcessing()) {
            // ensure an executor is set when running in parallel
            ObjectHelper.notNull(executorService, ""executorService"", this);
            doProcessParallel(exchange, result, pairs, isStreaming(), callback);
        } else {
            sync = doProcessSequential(exchange, result, pairs, callback);
        }
        if (!sync) {
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return false;
        }
    } catch (Throwable e) {
        exchange.setException(e);
        // and do the done work
        doDone(exchange, null, callback, true);
        return true;
    }
    // multicasting was processed successfully
    // and do the done work
    Exchange subExchange = result.get() != null ? result.get() : null;
    doDone(exchange, subExchange, callback, true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3394_18e1a142,Minor,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,405,540,"private boolean doProcessSequential(final Exchange original, final AtomicExchange result, final Iterable<ProcessorExchangePair> pairs, final Iterator<ProcessorExchangePair> it, final ProcessorExchangePair pair, final AsyncCallback callback, final AtomicInteger total) {
    boolean sync = true;
    final Exchange exchange = pair.getExchange();
    Processor processor = pair.getProcessor();
    Producer producer = pair.getProducer();
    TracedRouteNodes traced = exchange.getUnitOfWork() != null ? exchange.getUnitOfWork().getTracedRouteNodes() : null;
    // compute time taken if sending to another endpoint
    StopWatch watch = null;
    if (producer != null) {
        watch = new StopWatch();
    }
    try {
        // prepare tracing starting from a new block
        if (traced != null) {
            traced.pushBlock();
        }
        // let the prepared process it, remember to begin the exchange pair
        AsyncProcessor async = AsyncProcessorTypeConverter.convert(processor);
        pair.begin();
        sync = AsyncProcessorHelper.process(async, exchange, new AsyncCallback() {

            public void done(boolean doneSync) {
                // we are done with the exchange pair
                pair.done();
                // we only have to handle async completion of the routing slip
                if (doneSync) {
                    return;
                }
                // continue processing the multicast asynchronously
                Exchange subExchange = exchange;
                // Decide whether to continue with the multicast or not; similar logic to the Pipeline
                // remember to test for stop on exception and aggregate before copying back results
                boolean continueProcessing = PipelineHelper.continueProcessing(subExchange, ""Sequential processing failed for number "" + total.get(), LOG);
                if (stopOnException && !continueProcessing) {
                    if (subExchange.getException() != null) {
                        // wrap in exception to explain where it failed
                        subExchange.setException(new CamelExchangeException(""Sequential processing failed for number "" + total, subExchange, subExchange.getException()));
                    } else {
                        // we want to stop on exception, and the exception was handled by the error handler
                        // this is similar to what the pipeline does, so we should do the same to not surprise end users
                        // so we should set the failed exchange as the result and be done
                        result.set(subExchange);
                    }
                    // and do the done work
                    doDone(original, subExchange, callback, false);
                    return;
                }
                try {
                    doAggregate(getAggregationStrategy(subExchange), result, subExchange);
                } catch (Throwable e) {
                    // wrap in exception to explain where it failed
                    subExchange.setException(new CamelExchangeException(""Sequential processing failed for number "" + total, subExchange, e));
                    // and do the done work
                    doDone(original, subExchange, callback, false);
                    return;
                }
                total.incrementAndGet();
                // maybe there are more processors to multicast
                while (it.hasNext()) {
                    // prepare and run the next
                    ProcessorExchangePair pair = it.next();
                    subExchange = pair.getExchange();
                    updateNewExchange(subExchange, total.get(), pairs, it);
                    boolean sync = doProcessSequential(original, result, pairs, it, pair, callback, total);
                    if (!sync) {
                        if (LOG.isTraceEnabled()) {
                            LOG.trace(""Processing exchangeId: "" + original.getExchangeId() + "" is continued being processed asynchronously"");
                        }
                        return;
                    }
                    // Decide whether to continue with the multicast or not; similar logic to the Pipeline
                    // remember to test for stop on exception and aggregate before copying back results
                    continueProcessing = PipelineHelper.continueProcessing(subExchange, ""Sequential processing failed for number "" + total.get(), LOG);
                    if (stopOnException && !continueProcessing) {
                        if (subExchange.getException() != null) {
                            // wrap in exception to explain where it failed
                            subExchange.setException(new CamelExchangeException(""Sequential processing failed for number "" + total, subExchange, subExchange.getException()));
                        } else {
                            // we want to stop on exception, and the exception was handled by the error handler
                            // this is similar to what the pipeline does, so we should do the same to not surprise end users
                            // so we should set the failed exchange as the result and be done
                            result.set(subExchange);
                        }
                        // and do the done work
                        doDone(original, subExchange, callback, false);
                        return;
                    }
                    try {
                        doAggregate(getAggregationStrategy(subExchange), result, subExchange);
                    } catch (Throwable e) {
                        // wrap in exception to explain where it failed
                        subExchange.setException(new CamelExchangeException(""Sequential processing failed for number "" + total, subExchange, e));
                        // and do the done work
                        doDone(original, subExchange, callback, false);
                        return;
                    }
                    total.incrementAndGet();
                }
                // do the done work
                subExchange = result.get() != null ? result.get() : null;
                doDone(original, subExchange, callback, false);
            }
        });
    } finally {
        // pop the block so by next round we have the same staring point and thus the tracing looks accurate
        if (traced != null) {
            traced.popBlock();
        }
        if (producer != null) {
            long timeTaken = watch.stop();
            Endpoint endpoint = producer.getEndpoint();
            // emit event that the exchange was sent to the endpoint
            EventHelper.notifyExchangeSent(exchange.getContext(), exchange, endpoint, timeTaken);
        }
    }
    return sync;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3394_18e1a142,Minor,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,432,524,"public void done(boolean doneSync) {
    // we are done with the exchange pair
    pair.done();
    // we only have to handle async completion of the routing slip
    if (doneSync) {
        return;
    }
    // continue processing the multicast asynchronously
    Exchange subExchange = exchange;
    // Decide whether to continue with the multicast or not; similar logic to the Pipeline
    // remember to test for stop on exception and aggregate before copying back results
    boolean continueProcessing = PipelineHelper.continueProcessing(subExchange, ""Sequential processing failed for number "" + total.get(), LOG);
    if (stopOnException && !continueProcessing) {
        if (subExchange.getException() != null) {
            // wrap in exception to explain where it failed
            subExchange.setException(new CamelExchangeException(""Sequential processing failed for number "" + total, subExchange, subExchange.getException()));
        } else {
            // we want to stop on exception, and the exception was handled by the error handler
            // this is similar to what the pipeline does, so we should do the same to not surprise end users
            // so we should set the failed exchange as the result and be done
            result.set(subExchange);
        }
        // and do the done work
        doDone(original, subExchange, callback, false);
        return;
    }
    try {
        doAggregate(getAggregationStrategy(subExchange), result, subExchange);
    } catch (Throwable e) {
        // wrap in exception to explain where it failed
        subExchange.setException(new CamelExchangeException(""Sequential processing failed for number "" + total, subExchange, e));
        // and do the done work
        doDone(original, subExchange, callback, false);
        return;
    }
    total.incrementAndGet();
    // maybe there are more processors to multicast
    while (it.hasNext()) {
        // prepare and run the next
        ProcessorExchangePair pair = it.next();
        subExchange = pair.getExchange();
        updateNewExchange(subExchange, total.get(), pairs, it);
        boolean sync = doProcessSequential(original, result, pairs, it, pair, callback, total);
        if (!sync) {
            if (LOG.isTraceEnabled()) {
                LOG.trace(""Processing exchangeId: "" + original.getExchangeId() + "" is continued being processed asynchronously"");
            }
            return;
        }
        // Decide whether to continue with the multicast or not; similar logic to the Pipeline
        // remember to test for stop on exception and aggregate before copying back results
        continueProcessing = PipelineHelper.continueProcessing(subExchange, ""Sequential processing failed for number "" + total.get(), LOG);
        if (stopOnException && !continueProcessing) {
            if (subExchange.getException() != null) {
                // wrap in exception to explain where it failed
                subExchange.setException(new CamelExchangeException(""Sequential processing failed for number "" + total, subExchange, subExchange.getException()));
            } else {
                // we want to stop on exception, and the exception was handled by the error handler
                // this is similar to what the pipeline does, so we should do the same to not surprise end users
                // so we should set the failed exchange as the result and be done
                result.set(subExchange);
            }
            // and do the done work
            doDone(original, subExchange, callback, false);
            return;
        }
        try {
            doAggregate(getAggregationStrategy(subExchange), result, subExchange);
        } catch (Throwable e) {
            // wrap in exception to explain where it failed
            subExchange.setException(new CamelExchangeException(""Sequential processing failed for number "" + total, subExchange, e));
            // and do the done work
            doDone(original, subExchange, callback, false);
            return;
        }
        total.incrementAndGet();
    }
    // do the done work
    subExchange = result.get() != null ? result.get() : null;
    doDone(original, subExchange, callback, false);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3394_18e1a142,Minor,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,593,607,"/**
 * Common work which must be done when we are done multicasting.
 * <p/>
 * This logic applies for both running synchronous and asynchronous as there are multiple exist points
 * when using the asynchronous routing engine. And therefore we want the logic in one method instead
 * of being scattered.
 *
 * @param original    the original exchange
 * @param subExchange the current sub exchange, can be <tt>null</tt> for the synchronous part
 * @param callback    the callback
 * @param doneSync    the <tt>doneSync</tt> parameter to call on callback
 */
protected void doDone(Exchange original, Exchange subExchange, AsyncCallback callback, boolean doneSync) {
    // cleanup any per exchange aggregation strategy
    removeAggregationStrategyFromExchange(original);
    if (original.getException() != null) {
        // multicast uses error handling on its output processors and they have tried to redeliver
        // so we shall signal back to the other error handlers that we are exhausted and they should not
        // also try to redeliver as we will then do that twice
        original.setProperty(Exchange.REDELIVERY_EXHAUSTED, Boolean.TRUE);
    }
    if (subExchange != null) {
        // and copy the current result to original so it will contain this exception
        ExchangeHelper.copyResults(original, subExchange);
    }
    callback.done(doneSync);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3395_8433e6db,Minor,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,108,157,"@SuppressWarnings(""unchecked"")
private Iterable<ProcessorExchangePair> createProcessorExchangePairsIterable(final Exchange exchange, final Object value) {
    final Iterator iterator = ObjectHelper.createIterator(value);
    return new Iterable() {

        public Iterator iterator() {
            return new Iterator() {

                private int index;

                private boolean closed;

                public boolean hasNext() {
                    if (closed) {
                        return false;
                    }
                    boolean answer = iterator.hasNext();
                    if (!answer) {
                        // we are now closed
                        closed = true;
                        // nothing more so we need to close the expression value in case it needs to be
                        if (value instanceof Closeable) {
                            IOHelper.close((Closeable) value, value.getClass().getName(), LOG);
                        } else if (value instanceof Scanner) {
                            // special for Scanner as it does not implement Closeable
                            ((Scanner) value).close();
                        }
                    }
                    return answer;
                }

                public Object next() {
                    Object part = iterator.next();
                    Exchange newExchange = exchange.copy();
                    if (part instanceof Message) {
                        newExchange.setIn((Message) part);
                    } else {
                        Message in = newExchange.getIn();
                        in.setBody(part);
                    }
                    return createProcessorExchangePair(index++, getProcessors().iterator().next(), newExchange);
                }

                public void remove() {
                    throw new UnsupportedOperationException(""Remove is not supported by this iterator"");
                }
            };
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3395_8433e6db,Minor,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,113,154,"public Iterator iterator() {
    return new Iterator() {

        private int index;

        private boolean closed;

        public boolean hasNext() {
            if (closed) {
                return false;
            }
            boolean answer = iterator.hasNext();
            if (!answer) {
                // we are now closed
                closed = true;
                // nothing more so we need to close the expression value in case it needs to be
                if (value instanceof Closeable) {
                    IOHelper.close((Closeable) value, value.getClass().getName(), LOG);
                } else if (value instanceof Scanner) {
                    // special for Scanner as it does not implement Closeable
                    ((Scanner) value).close();
                }
            }
            return answer;
        }

        public Object next() {
            Object part = iterator.next();
            Exchange newExchange = exchange.copy();
            if (part instanceof Message) {
                newExchange.setIn((Message) part);
            } else {
                Message in = newExchange.getIn();
                in.setBody(part);
            }
            return createProcessorExchangePair(index++, getProcessors().iterator().next(), newExchange);
        }

        public void remove() {
            throw new UnsupportedOperationException(""Remove is not supported by this iterator"");
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3395_8433e6db,Minor,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,138,148,"public Object next() {
    Object part = iterator.next();
    Exchange newExchange = exchange.copy();
    if (part instanceof Message) {
        newExchange.setIn((Message) part);
    } else {
        Message in = newExchange.getIn();
        in.setBody(part);
    }
    return createProcessorExchangePair(index++, getProcessors().iterator().next(), newExchange);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3395_8433e6db,Minor,camel-core/src/main/java/org/apache/camel/util/ExchangeHelper.java,170,182,"/**
 * Creates a new instance and copies from the current message exchange so that it can be
 * forwarded to another destination as a new instance. Unlike regular copy this operation
 * will not share the same {@link org.apache.camel.spi.UnitOfWork} so its should be used
 * for async messaging, where the original and copied exchange are independent.
 *
 * @param exchange original copy of the exchange
 * @param handover whether the on completion callbacks should be handed over to the new copy.
 */
public static Exchange createCorrelatedCopy(Exchange exchange, boolean handover) {
    Exchange copy = exchange.copy();
    // do not share the unit of work
    copy.setUnitOfWork(null);
    // hand over on completion to the copy if we got any
    UnitOfWork uow = exchange.getUnitOfWork();
    if (handover && uow != null) {
        uow.handoverSynchronization(copy);
    }
    // set a correlation id so we can track back the original exchange
    copy.setProperty(Exchange.CORRELATION_ID, exchange.getExchangeId());
    return copy;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3428_320545cd,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,466,478,"public <T extends Endpoint> T getEndpoint(String name, Class<T> endpointType) {
    Endpoint endpoint = getEndpoint(name);
    if (endpoint instanceof InterceptSendToEndpoint) {
        endpoint = ((InterceptSendToEndpoint) endpoint).getDelegate();
    }
    if (endpointType.isInstance(endpoint)) {
        return endpointType.cast(endpoint);
    } else {
        throw new IllegalArgumentException(""The endpoint is not of type: "" + endpointType + "" but is: "" + endpoint.getClass().getCanonicalName());
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3433_e76d23b0,Minor,camel-core/src/main/java/org/apache/camel/builder/ExpressionBuilder.java,934,946,"/**
 * Returns an expression which converts the given expression to the given type
 */
@SuppressWarnings(""unchecked"")
public static Expression convertToExpression(final Expression expression, final Class type) {
    return new ExpressionAdapter() {

        public Object evaluate(Exchange exchange) {
            return expression.evaluate(exchange, type);
        }

        @Override
        public String toString() {
            return """" + expression + "".convertTo("" + type.getCanonicalName() + "".class)"";
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3433_e76d23b0,Minor,camel-core/src/main/java/org/apache/camel/builder/ExpressionBuilder.java,937,939,"public Object evaluate(Exchange exchange) {
    return expression.evaluate(exchange, type);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3433_e76d23b0,Minor,camel-core/src/main/java/org/apache/camel/builder/ExpressionBuilder.java,941,944,"@Override
public String toString() {
    return """" + expression + "".convertTo("" + type.getCanonicalName() + "".class)"";
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3433_e76d23b0,Minor,camel-core/src/main/java/org/apache/camel/builder/ExpressionBuilder.java,952,963,"/**
 * Returns an expression which converts the given expression to the given type the type
 * expression is evaluated to
 */
public static Expression convertToExpression(final Expression expression, final Expression type) {
    return new ExpressionAdapter() {

        public Object evaluate(Exchange exchange) {
            return expression.evaluate(exchange, type.evaluate(exchange, Object.class).getClass());
        }

        @Override
        public String toString() {
            return """" + expression + "".convertToEvaluatedType("" + type + "")"";
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3433_e76d23b0,Minor,camel-core/src/main/java/org/apache/camel/builder/ExpressionBuilder.java,954,956,"public Object evaluate(Exchange exchange) {
    return expression.evaluate(exchange, type.evaluate(exchange, Object.class).getClass());
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3433_e76d23b0,Minor,camel-core/src/main/java/org/apache/camel/builder/ExpressionBuilder.java,958,961,"@Override
public String toString() {
    return """" + expression + "".convertToEvaluatedType("" + type + "")"";
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3448_b345dd82,Critical,camel-core/src/main/java/org/apache/camel/processor/ErrorHandlerSupport.java,45,55,"public void addExceptionPolicy(OnExceptionDefinition exceptionType) {
    Processor processor = exceptionType.getErrorHandler();
    addChildService(processor);
    List<Class> list = exceptionType.getExceptionClasses();
    for (Class clazz : list) {
        ExceptionPolicyKey key = new ExceptionPolicyKey(clazz, exceptionType.getOnWhen());
        exceptionPolicies.put(key, exceptionType);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3448_b345dd82,Critical,camel-core/src/main/java/org/apache/camel/processor/exceptionpolicy/DefaultExceptionPolicyStrategy.java,60,86,"public OnExceptionDefinition getExceptionPolicy(Map<ExceptionPolicyKey, OnExceptionDefinition> exceptionPolicies, Exchange exchange, Throwable exception) {
    Map<Integer, OnExceptionDefinition> candidates = new TreeMap<Integer, OnExceptionDefinition>();
    // recursive up the tree using the iterator
    boolean exactMatch = false;
    Iterator<Throwable> it = createExceptionIterator(exception);
    while (!exactMatch && it.hasNext()) {
        // we should stop looking if we have found an exact match
        exactMatch = findMatchedExceptionPolicy(exceptionPolicies, exchange, it.next(), candidates);
    }
    if (LOG.isTraceEnabled()) {
        LOG.trace(""Found "" + candidates.size() + "" candidates"");
    }
    if (candidates.isEmpty()) {
        // no type found
        return null;
    } else {
        // return the first in the map as its sorted and
        return candidates.values().iterator().next();
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3448_b345dd82,Critical,camel-core/src/main/java/org/apache/camel/processor/exceptionpolicy/ExceptionPolicyKey.java,45,47,"public static ExceptionPolicyKey newInstance(Class exceptionClass) {
    return new ExceptionPolicyKey(exceptionClass, null);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3448_b345dd82,Critical,camel-core/src/main/java/org/apache/camel/processor/exceptionpolicy/ExceptionPolicyKey.java,49,51,"public static ExceptionPolicyKey newInstance(Class exceptionClass, WhenDefinition when) {
    return new ExceptionPolicyKey(exceptionClass, when);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3448_b345dd82,Critical,camel-core/src/main/java/org/apache/camel/processor/exceptionpolicy/ExceptionPolicyKey.java,53,72,"@Override
public boolean equals(Object o) {
    if (this == o) {
        return true;
    }
    if (o == null || getClass() != o.getClass()) {
        return false;
    }
    ExceptionPolicyKey that = (ExceptionPolicyKey) o;
    if (!exceptionClass.equals(that.exceptionClass)) {
        return false;
    }
    if (when != null ? !when.equals(that.when) : that.when != null) {
        return false;
    }
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3448_b345dd82,Critical,camel-core/src/main/java/org/apache/camel/processor/exceptionpolicy/ExceptionPolicyKey.java,74,79,"@Override
public int hashCode() {
    int result = exceptionClass.hashCode();
    result = 31 * result + (when != null ? when.hashCode() : 0);
    return result;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3448_b345dd82,Critical,camel-core/src/main/java/org/apache/camel/processor/exceptionpolicy/ExceptionPolicyKey.java,81,84,"@Override
public String toString() {
    return ""ExceptionPolicyKey["" + exceptionClass + (when != null ? "" "" + when : """") + ""]"";
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3498_b4606700,Major,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,108,157,"@SuppressWarnings(""unchecked"")
private Iterable<ProcessorExchangePair> createProcessorExchangePairsIterable(final Exchange exchange, final Object value) {
    final Iterator iterator = ObjectHelper.createIterator(value);
    return new Iterable() {

        public Iterator iterator() {
            return new Iterator() {

                private int index;

                private boolean closed;

                public boolean hasNext() {
                    if (closed) {
                        return false;
                    }
                    boolean answer = iterator.hasNext();
                    if (!answer) {
                        // we are now closed
                        closed = true;
                        // nothing more so we need to close the expression value in case it needs to be
                        if (value instanceof Closeable) {
                            IOHelper.close((Closeable) value, value.getClass().getName(), LOG);
                        } else if (value instanceof Scanner) {
                            // special for Scanner as it does not implement Closeable
                            ((Scanner) value).close();
                        }
                    }
                    return answer;
                }

                public Object next() {
                    Object part = iterator.next();
                    Exchange newExchange = ExchangeHelper.createCopy(exchange, true);
                    if (part instanceof Message) {
                        newExchange.setIn((Message) part);
                    } else {
                        Message in = newExchange.getIn();
                        in.setBody(part);
                    }
                    return createProcessorExchangePair(index++, getProcessors().iterator().next(), newExchange);
                }

                public void remove() {
                    throw new UnsupportedOperationException(""Remove is not supported by this iterator"");
                }
            };
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3498_b4606700,Major,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,113,154,"public Iterator iterator() {
    return new Iterator() {

        private int index;

        private boolean closed;

        public boolean hasNext() {
            if (closed) {
                return false;
            }
            boolean answer = iterator.hasNext();
            if (!answer) {
                // we are now closed
                closed = true;
                // nothing more so we need to close the expression value in case it needs to be
                if (value instanceof Closeable) {
                    IOHelper.close((Closeable) value, value.getClass().getName(), LOG);
                } else if (value instanceof Scanner) {
                    // special for Scanner as it does not implement Closeable
                    ((Scanner) value).close();
                }
            }
            return answer;
        }

        public Object next() {
            Object part = iterator.next();
            Exchange newExchange = ExchangeHelper.createCopy(exchange, true);
            if (part instanceof Message) {
                newExchange.setIn((Message) part);
            } else {
                Message in = newExchange.getIn();
                in.setBody(part);
            }
            return createProcessorExchangePair(index++, getProcessors().iterator().next(), newExchange);
        }

        public void remove() {
            throw new UnsupportedOperationException(""Remove is not supported by this iterator"");
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3498_b4606700,Major,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,138,148,"public Object next() {
    Object part = iterator.next();
    Exchange newExchange = ExchangeHelper.createCopy(exchange, true);
    if (part instanceof Message) {
        newExchange.setIn((Message) part);
    } else {
        Message in = newExchange.getIn();
        in.setBody(part);
    }
    return createProcessorExchangePair(index++, getProcessors().iterator().next(), newExchange);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3531_41e4b5b9,Major,camel-core/src/main/java/org/apache/camel/util/ObjectHelper.java,1112,1123,"/**
 * Evaluate the value as a predicate which attempts to convert the value to
 * a boolean otherwise true is returned if the value is not null
 */
public static boolean evaluateValuePredicate(Object value) {
    if (value instanceof Boolean) {
        return (Boolean) value;
    } else if (value instanceof String) {
        if (""true"".equalsIgnoreCase((String) value)) {
            return true;
        } else if (""false"".equalsIgnoreCase((String) value)) {
            return false;
        }
    }
    return value != null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3535_b56d2962,Major,camel-core/src/main/java/org/apache/camel/processor/aggregate/AggregateProcessor.java,160,189,"public void process(Exchange exchange) throws Exception {
    // compute correlation expression
    String key = correlationExpression.evaluate(exchange, String.class);
    if (ObjectHelper.isEmpty(key)) {
        // we have a bad correlation key
        if (isIgnoreInvalidCorrelationKeys()) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(""Invalid correlation key. This Exchange will be ignored: "" + exchange);
            }
            return;
        } else {
            throw new CamelExchangeException(""Invalid correlation key"", exchange);
        }
    }
    // is the correlation key closed?
    if (closedCorrelationKeys != null && closedCorrelationKeys.containsKey(key)) {
        throw new ClosedCorrelationKeyException(key, exchange);
    }
    // when memory based then its fast using synchronized, but if the aggregation repository is IO
    // bound such as JPA etc then concurrent aggregation per correlation key could
    // improve performance as we can run aggregation repository get/add in parallel
    lock.lock();
    try {
        doAggregation(key, exchange);
    } finally {
        lock.unlock();
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3545_050c542e,Major,camel-core/src/main/java/org/apache/camel/model/language/MethodCallExpression.java,128,146,"@Override
public Expression createExpression(CamelContext camelContext) {
    if (beanType != null) {
        instance = ObjectHelper.newInstance(beanType);
        return new BeanExpression(instance, getMethod(), parameterType);
    } else if (instance != null) {
        return new BeanExpression(instance, getMethod(), parameterType);
    } else {
        String ref = beanName();
        // if its a ref then check that the ref exists
        BeanHolder holder = new RegistryBean(camelContext, ref);
        // get the bean which will check that it exists
        instance = holder.getBean();
        // only validate when it was a ref for a bean, so we can eager check
        // this on startup of Camel
        validateHasMethod(camelContext, instance, getMethod(), parameterType);
        return new BeanExpression(ref, getMethod(), parameterType);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3545_050c542e,Major,camel-core/src/main/java/org/apache/camel/model/language/MethodCallExpression.java,161,175,"/**
 * Validates the given bean has the method
 *
 * @param context  camel context
 * @param bean     the bean instance
 * @param method   the method, can be <tt>null</tt> if no method name provided
 * @throws org.apache.camel.RuntimeCamelException is thrown if bean does not have the method
 */
@SuppressWarnings(""rawtypes"")
protected void validateHasMethod(CamelContext context, Object bean, String method, Class parameterType) {
    if (method == null) {
        return;
    }
    BeanInfo info = new BeanInfo(context, bean.getClass());
    List<Class> parameterTypes = new ArrayList<Class>();
    if (parameterType != null) {
        parameterTypes.add(parameterType);
    }
    if (!info.hasMethod(method, parameterTypes)) {
        throw ObjectHelper.wrapRuntimeCamelException(new MethodNotFoundException(null, bean, method, parameterTypes));
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3617_02626724,Major,camel-core/src/main/java/org/apache/camel/component/file/FileConsumer.java,123,166,"/**
 * Creates a new GenericFile<File> based on the given file.
 *
 * @param endpointPath the starting directory the endpoint was configured with
 * @param file the source file
 * @return wrapped as a GenericFile
 */
public static GenericFile<File> asGenericFile(String endpointPath, File file) {
    GenericFile<File> answer = new GenericFile<File>();
    // use file specific binding
    answer.setBinding(new FileBinding());
    answer.setEndpointPath(endpointPath);
    answer.setFile(file);
    answer.setFileNameOnly(file.getName());
    answer.setFileLength(file.length());
    // must use FileUtil.isAbsolute to have consistent check for whether the file is
    // absolute or not. As windows do not consider \ paths as absolute where as all
    // other OS platforms will consider \ as absolute. The logic in Camel mandates
    // that we align this for all OS. That is why we must use FileUtil.isAbsolute
    // to return a consistent answer for all OS platforms.
    answer.setAbsolute(FileUtil.isAbsolute(file));
    answer.setAbsoluteFilePath(file.getAbsolutePath());
    answer.setLastModified(file.lastModified());
    if (answer.isAbsolute()) {
        // use absolute path as relative
        answer.setRelativeFilePath(file.getAbsolutePath());
    } else {
        File path;
        String endpointNormalized = FileUtil.normalizePath(endpointPath);
        if (file.getPath().startsWith(endpointNormalized)) {
            // skip duplicate endpoint path
            path = new File(ObjectHelper.after(file.getPath(), endpointNormalized + File.separator));
        } else {
            path = new File(file.getPath());
        }
        if (path.getParent() != null) {
            answer.setRelativeFilePath(path.getParent() + File.separator + file.getName());
        } else {
            answer.setRelativeFilePath(path.getName());
        }
    }
    // the file name should be the relative path
    answer.setFileName(answer.getRelativeFilePath());
    // use file as body as we have converters if needed as stream
    answer.setBody(file);
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3690_2a3f3392,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,875,899,"public void addService(Object object) throws Exception {
    if (object instanceof Service) {
        Service service = (Service) object;
        for (LifecycleStrategy strategy : lifecycleStrategies) {
            if (service instanceof Endpoint) {
                // use specialized endpoint add
                strategy.onEndpointAdd((Endpoint) service);
            } else {
                strategy.onServiceAdd(this, service, null);
            }
        }
        // only add to services to close if its a singleton
        // otherwise we could for example end up with a lot of prototype scope endpoints
        // assume singleton by default
        boolean singleton = true;
        if (service instanceof IsSingleton) {
            singleton = ((IsSingleton) service).isSingleton();
        }
        if (singleton) {
            servicesToClose.add(service);
        }
    }
    startServices(object);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3709_4c37e773,Minor,camel-core/src/main/java/org/apache/camel/model/FromDefinition.java,80,82,"// Properties
// -----------------------------------------------------------------------
public String getUri() {
    return uri;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3727_ff2713d1,Major,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,877,894,"protected void doStart() throws Exception {
    if (isParallelProcessing() && executorService == null) {
        throw new IllegalArgumentException(""ParallelProcessing is enabled but ExecutorService has not been set"");
    }
    if (timeout > 0 && !isParallelProcessing()) {
        throw new IllegalArgumentException(""Timeout is used but ParallelProcessing has not been enabled"");
    }
    if (isParallelProcessing() && aggregateExecutorService == null) {
        // use unbounded thread pool so we ensure the aggregate on-the-fly task always will have assigned a thread
        // and run the tasks when the task is submitted. If not then the aggregate task may not be able to run
        // and signal completion during processing, which would lead to a dead-lock
        // keep at least one thread in the pool so we re-use the thread avoiding to create new threads because
        // the pool shrank to zero.
        String name = getClass().getSimpleName() + ""-AggregateTask"";
        aggregateExecutorService = camelContext.getExecutorServiceStrategy().newThreadPool(this, name, 1, Integer.MAX_VALUE);
    }
    ServiceHelper.startServices(processors);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3727_ff2713d1,Major,camel-core/src/main/java/org/apache/camel/processor/RecipientList.java,107,125,"/**
 * Sends the given exchange to the recipient list
 */
public boolean sendToRecipientList(Exchange exchange, Object recipientList, AsyncCallback callback) {
    Iterator<Object> iter = ObjectHelper.createIterator(recipientList, delimiter);
    RecipientListProcessor rlp = new RecipientListProcessor(exchange.getContext(), producerCache, iter, getAggregationStrategy(), isParallelProcessing(), getExecutorService(), isStreaming(), isStopOnException(), getTimeout());
    rlp.setIgnoreInvalidEndpoints(isIgnoreInvalidEndpoints());
    // start the service
    try {
        ServiceHelper.startService(rlp);
    } catch (Exception e) {
        exchange.setException(e);
        callback.done(true);
        return true;
    }
    // now let the multicast process the exchange
    return AsyncProcessorHelper.process(rlp, exchange, callback);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3757_c1b2f2f8,Minor,camel-core/src/main/java/org/apache/camel/builder/AdviceWithRouteBuilder.java,70,73,"/**
 * Mock all endpoints in the route.
 *
 * @throws Exception can be thrown if error occurred
 */
public void mockEndpoints() throws Exception {
    getContext().removeEndpoints(""*"");
    getContext().addRegisterEndpointCallback(new InterceptSendToMockEndpointStrategy(null));
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3757_c1b2f2f8,Minor,camel-core/src/main/java/org/apache/camel/builder/AdviceWithRouteBuilder.java,82,85,"/**
 * Mock all endpoints matching the given pattern.
 *
 * @param pattern the pattern.
 * @throws Exception can be thrown if error occurred
 * @see org.apache.camel.util.EndpointHelper#matchEndpoint(String, String)
 */
public void mockEndpoints(String pattern) throws Exception {
    getContext().removeEndpoints(pattern);
    getContext().addRegisterEndpointCallback(new InterceptSendToMockEndpointStrategy(pattern));
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3757_c1b2f2f8,Minor,camel-core/src/main/java/org/apache/camel/impl/InterceptSendToEndpoint.java,92,160,"public Producer createProducer() throws Exception {
    producer = delegate.createProducer();
    return new Producer() {

        public Endpoint getEndpoint() {
            return producer.getEndpoint();
        }

        public Exchange createExchange() {
            return producer.createExchange();
        }

        public Exchange createExchange(ExchangePattern pattern) {
            return producer.createExchange(pattern);
        }

        public Exchange createExchange(Exchange exchange) {
            return producer.createExchange(exchange);
        }

        public void process(Exchange exchange) throws Exception {
            // process the detour so we do the detour routing
            if (LOG.isDebugEnabled()) {
                LOG.debug(""Sending to endpoint: "" + getEndpointUri() + "" is intercepted and detoured to: "" + detour + "" for exchange: "" + exchange);
            }
            // add header with the real endpoint uri
            exchange.getIn().setHeader(Exchange.INTERCEPTED_ENDPOINT, delegate.getEndpointUri());
            try {
                detour.process(exchange);
            } catch (Exception e) {
                exchange.setException(e);
            }
            // check for error if so we should break out
            if (!continueProcessing(exchange, ""skip sending to original intended destination: "" + getEndpointUri(), LOG)) {
                return;
            }
            if (!skip) {
                if (exchange.hasOut()) {
                    // replace OUT with IN as detour changed something
                    exchange.setIn(exchange.getOut());
                    exchange.setOut(null);
                }
                // route to original destination
                producer.process(exchange);
            } else {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Stop() means skip sending exchange to original intended destination: "" + getEndpointUri() + "" for exchange: "" + exchange);
                }
            }
        }

        public boolean isSingleton() {
            return producer.isSingleton();
        }

        public void start() throws Exception {
            ServiceHelper.startService(detour);
        }

        public void stop() throws Exception {
            ServiceHelper.stopService(detour);
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3757_c1b2f2f8,Minor,camel-core/src/main/java/org/apache/camel/impl/InterceptSendToEndpoint.java,112,146,"public void process(Exchange exchange) throws Exception {
    // process the detour so we do the detour routing
    if (LOG.isDebugEnabled()) {
        LOG.debug(""Sending to endpoint: "" + getEndpointUri() + "" is intercepted and detoured to: "" + detour + "" for exchange: "" + exchange);
    }
    // add header with the real endpoint uri
    exchange.getIn().setHeader(Exchange.INTERCEPTED_ENDPOINT, delegate.getEndpointUri());
    try {
        detour.process(exchange);
    } catch (Exception e) {
        exchange.setException(e);
    }
    // check for error if so we should break out
    if (!continueProcessing(exchange, ""skip sending to original intended destination: "" + getEndpointUri(), LOG)) {
        return;
    }
    if (!skip) {
        if (exchange.hasOut()) {
            // replace OUT with IN as detour changed something
            exchange.setIn(exchange.getOut());
            exchange.setOut(null);
        }
        // route to original destination
        producer.process(exchange);
    } else {
        if (LOG.isDebugEnabled()) {
            LOG.debug(""Stop() means skip sending exchange to original intended destination: "" + getEndpointUri() + "" for exchange: "" + exchange);
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3757_c1b2f2f8,Minor,camel-core/src/main/java/org/apache/camel/impl/InterceptSendToMockEndpointStrategy.java,59,92,"public Endpoint registerEndpoint(String uri, Endpoint endpoint) {
    if (endpoint instanceof InterceptSendToEndpoint) {
        // endpoint already decorated
        return endpoint;
    } else if (endpoint instanceof MockEndpoint) {
        // we should not intercept mock endpoints
        return endpoint;
    } else if (uri == null || pattern == null || EndpointHelper.matchEndpoint(uri, pattern)) {
        // if pattern is null then it mean to match all
        // only proxy if the uri is matched decorate endpoint with our proxy
        // should be false by default
        InterceptSendToEndpoint proxy = new InterceptSendToEndpoint(endpoint, false);
        // create mock endpoint which we will use as interceptor
        // replace :// from scheme to make it easy to lookup the mock endpoint without having double :// in uri
        String key = ""mock:"" + endpoint.getEndpointKey().replaceFirst(""://"", "":"");
        LOG.info(""Adviced endpoint ["" + uri + ""] with mock endpoint ["" + key + ""]"");
        MockEndpoint mock = endpoint.getCamelContext().getEndpoint(key, MockEndpoint.class);
        Processor producer;
        try {
            producer = mock.createProducer();
        } catch (Exception e) {
            throw wrapRuntimeCamelException(e);
        }
        proxy.setDetour(producer);
        return proxy;
    } else {
        // no proxy so return regular endpoint
        return endpoint;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3760_5225e6e3,Minor,camel-core/src/main/java/org/apache/camel/management/DefaultManagementNamingStrategy.java,252,263,"public ObjectName getObjectNameForThreadPool(CamelContext context, ThreadPoolExecutor threadPool, String id, String sourceId) throws MalformedObjectNameException {
    StringBuilder buffer = new StringBuilder();
    buffer.append(domainName).append("":"");
    buffer.append(KEY_CONTEXT + ""="").append(getContextId(context)).append("","");
    buffer.append(KEY_TYPE + ""="" + TYPE_THREAD_POOL + "","");
    buffer.append(KEY_NAME + ""="").append(id);
    if (sourceId != null) {
        // provide source id if we know it, this helps end user to know where the pool is used
        buffer.append(""("").append(sourceId).append("")"");
    }
    return createObjectName(buffer);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/FileOperations.java,73,116,"public boolean buildDirectory(String directory, boolean absolute) throws GenericFileOperationFailedException {
    ObjectHelper.notNull(endpoint, ""endpoint"");
    // always create endpoint defined directory
    if (endpoint.isAutoCreate() && !endpoint.getFile().exists()) {
        LOG.trace(""Building starting directory: {}"", endpoint.getFile());
        endpoint.getFile().mkdirs();
    }
    if (ObjectHelper.isEmpty(directory)) {
        // no directory to build so return true to indicate ok
        return true;
    }
    File endpointPath = endpoint.getFile();
    File target = new File(directory);
    File path;
    if (absolute) {
        // absolute path
        path = target;
    } else if (endpointPath.equals(target)) {
        // its just the root of the endpoint path
        path = endpointPath;
    } else {
        // relative after the endpoint path
        String afterRoot = ObjectHelper.after(directory, endpointPath.getPath() + File.separator);
        if (ObjectHelper.isNotEmpty(afterRoot)) {
            // dir is under the root path
            path = new File(endpoint.getFile(), afterRoot);
        } else {
            // dir is relative to the root path
            path = new File(endpoint.getFile(), directory);
        }
    }
    if (path.isDirectory() && path.exists()) {
        // the directory already exists
        return true;
    } else {
        LOG.trace(""Building directory: {}"", path);
        return path.mkdirs();
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/FileOperations.java,146,211,"public boolean storeFile(String fileName, Exchange exchange) throws GenericFileOperationFailedException {
    ObjectHelper.notNull(endpoint, ""endpoint"");
    File file = new File(fileName);
    // if an existing file already exists what should we do?
    if (file.exists()) {
        if (endpoint.getFileExist() == GenericFileExist.Ignore) {
            // ignore but indicate that the file was written
            LOG.trace(""An existing file already exists: {}. Ignore and do not override it."", file);
            return true;
        } else if (endpoint.getFileExist() == GenericFileExist.Fail) {
            throw new GenericFileOperationFailedException(""File already exist: "" + file + "". Cannot write new file."");
        }
    }
    // 3. write stream to file
    try {
        // is the body file based
        File source = null;
        // get the File Object from in message
        source = exchange.getIn().getBody(File.class);
        if (source != null) {
            // okay we know the body is a file type
            // so try to see if we can optimize by renaming the local work path file instead of doing
            // a full file to file copy, as the local work copy is to be deleted afterwards anyway
            // local work path
            File local = exchange.getIn().getHeader(Exchange.FILE_LOCAL_WORK_PATH, File.class);
            if (local != null && local.exists()) {
                boolean renamed = writeFileByLocalWorkPath(local, file);
                if (renamed) {
                    // try to keep last modified timestamp if configured to do so
                    keepLastModified(exchange, file);
                    // clear header as we have renamed the file
                    exchange.getIn().setHeader(Exchange.FILE_LOCAL_WORK_PATH, null);
                    // to the target.
                    return true;
                }
            } else if (source.exists()) {
                // no there is no local work file so use file to file copy if the source exists
                writeFileByFile(source, file);
                // try to keep last modified timestamp if configured to do so
                keepLastModified(exchange, file);
                return true;
            }
        }
        // fallback and use stream based
        InputStream in = ExchangeHelper.getMandatoryInBody(exchange, InputStream.class);
        writeFileByStream(in, file);
        // try to keep last modified timestamp if configured to do so
        keepLastModified(exchange, file);
        return true;
    } catch (IOException e) {
        throw new GenericFileOperationFailedException(""Cannot store file: "" + file, e);
    } catch (InvalidPayloadException e) {
        throw new GenericFileOperationFailedException(""Cannot store file: "" + file, e);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/FileOperations.java,213,228,"private void keepLastModified(Exchange exchange, File file) {
    if (endpoint.isKeepLastModified()) {
        Long last;
        Date date = exchange.getIn().getHeader(Exchange.FILE_LAST_MODIFIED, Date.class);
        if (date != null) {
            last = date.getTime();
        } else {
            // fallback and try a long
            last = exchange.getIn().getHeader(Exchange.FILE_LAST_MODIFIED, Long.class);
        }
        if (last != null) {
            boolean result = file.setLastModified(last);
            LOG.trace(""Keeping last modified timestamp: {} on file: {} with result: {}"", new Object[] { last, file, result });
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/FileOperations.java,230,234,"private boolean writeFileByLocalWorkPath(File source, File file) {
    LOG.trace(""Using local work file being renamed from: {} to: {}"", source, file);
    return FileUtil.renameFile(source, file);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/FileOperations.java,236,253,"private void writeFileByFile(File source, File target) throws IOException {
    FileChannel in = new FileInputStream(source).getChannel();
    FileChannel out = null;
    try {
        out = prepareOutputFileChannel(target, out);
        LOG.trace(""Using FileChannel to transfer from: {} to: {}"", in, out);
        long size = in.size();
        long position = 0;
        while (position < size) {
            position += in.transferTo(position, endpoint.getBufferSize(), out);
        }
    } finally {
        IOHelper.close(in, source.getName(), LOG);
        IOHelper.close(out, source.getName(), LOG);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/FileOperations.java,255,276,"private void writeFileByStream(InputStream in, File target) throws IOException {
    FileChannel out = null;
    try {
        out = prepareOutputFileChannel(target, out);
        LOG.trace(""Using InputStream to transfer from: {} to: {}"", in, out);
        int size = endpoint.getBufferSize();
        byte[] buffer = new byte[size];
        ByteBuffer byteBuffer = ByteBuffer.wrap(buffer);
        int bytesRead;
        while ((bytesRead = in.read(buffer)) != -1) {
            if (bytesRead < size) {
                byteBuffer.limit(bytesRead);
            }
            out.write(byteBuffer);
            byteBuffer.clear();
        }
    } finally {
        IOHelper.close(in, target.getName(), LOG);
        IOHelper.close(out, target.getName(), LOG);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/FileOperations.java,282,291,"/**
 * Creates and prepares the output file channel. Will position itself in correct position if the file is writable
 *  eg. it should append or override any existing content.
 */
private FileChannel prepareOutputFileChannel(File target, FileChannel out) throws IOException {
    if (endpoint.getFileExist() == GenericFileExist.Append) {
        out = new RandomAccessFile(target, ""rw"").getChannel();
        out = out.position(out.size());
    } else {
        // will override
        out = new FileOutputStream(target).getChannel();
    }
    return out;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/strategy/GenericFileDeleteProcessStrategy.java,30,47,"@Override
public boolean begin(GenericFileOperations<T> operations, GenericFileEndpoint<T> endpoint, Exchange exchange, GenericFile<T> file) throws Exception {
    // must invoke super
    boolean result = super.begin(operations, endpoint, exchange, file);
    if (!result) {
        return false;
    }
    if (beginRenamer != null) {
        GenericFile<T> newName = beginRenamer.renameFile(exchange, file);
        GenericFile<T> to = renameFile(operations, file, newName);
        if (to != null) {
            to.bindToExchange(exchange);
        }
    }
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/strategy/GenericFileRenameProcessStrategy.java,32,49,"@Override
public boolean begin(GenericFileOperations<T> operations, GenericFileEndpoint<T> endpoint, Exchange exchange, GenericFile<T> file) throws Exception {
    // must invoke super
    boolean result = super.begin(operations, endpoint, exchange, file);
    if (!result) {
        return false;
    }
    if (beginRenamer != null) {
        GenericFile<T> newName = beginRenamer.renameFile(exchange, file);
        GenericFile<T> to = renameFile(operations, file, newName);
        if (to != null) {
            to.bindToExchange(exchange);
        }
    }
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/strategy/MarkerFileExclusiveReadLockStrategy.java,51,65,"public boolean acquireExclusiveReadLock(GenericFileOperations<File> operations, GenericFile<File> file, Exchange exchange) throws Exception {
    lockFileName = file.getAbsoluteFilePath() + FileComponent.DEFAULT_LOCK_FILE_POSTFIX;
    LOG.trace(""Locking the file: {} using the lock file name: {}"", file, lockFileName);
    // create a plain file as marker filer for locking (do not use FileLock)
    lock = new File(lockFileName);
    boolean acquired = lock.createNewFile();
    if (!acquired) {
        lock = null;
    }
    return acquired;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3789_9319e139,Major,camel-core/src/main/java/org/apache/camel/component/file/strategy/MarkerFileExclusiveReadLockStrategy.java,67,75,"public void releaseExclusiveReadLock(GenericFileOperations<File> operations, GenericFile<File> file, Exchange exchange) throws Exception {
    if (lock != null) {
        LOG.trace(""Unlocking file: {}"", lockFileName);
        boolean deleted = FileUtil.deleteFile(lock);
        LOG.trace(""Lock file: {} was deleted: {}"", lockFileName, deleted);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3791_52106681,Major,camel-core/src/main/java/org/apache/camel/processor/RedeliveryErrorHandler.java,567,654,"/**
 * All redelivery attempts failed so move the exchange to the dead letter queue
 */
protected boolean deliverToFailureProcessor(final Processor processor, final Exchange exchange, final RedeliveryData data, final AsyncCallback callback) {
    boolean sync = true;
    Exception caught = exchange.getException();
    // we did not success with the redelivery so now we let the failure processor handle it
    // clear exception as we let the failure processor handle it
    exchange.setException(null);
    boolean handled = false;
    // regard both handled or continued as being handled
    if (shouldHandled(exchange, data) || shouldContinue(exchange, data)) {
        // its handled then remove traces of redelivery attempted
        exchange.getIn().removeHeader(Exchange.REDELIVERED);
        exchange.getIn().removeHeader(Exchange.REDELIVERY_COUNTER);
        exchange.getIn().removeHeader(Exchange.REDELIVERY_MAX_COUNTER);
        handled = true;
    } else {
        // must decrement the redelivery counter as we didn't process the redelivery but is
        // handling by the failure handler. So we must -1 to not let the counter be out-of-sync
        decrementRedeliveryCounter(exchange);
    }
    // is the a failure processor to process the Exchange
    if (processor != null) {
        // reset cached streams so they can be read again
        MessageHelper.resetStreamCache(exchange.getIn());
        // prepare original IN body if it should be moved instead of current body
        if (data.useOriginalInMessage) {
            if (log.isTraceEnabled()) {
                log.trace(""Using the original IN message instead of current"");
            }
            Message original = exchange.getUnitOfWork().getOriginalInMessage();
            exchange.setIn(original);
        }
        if (log.isTraceEnabled()) {
            log.trace(""Failure processor "" + processor + "" is processing Exchange: "" + exchange);
        }
        // store the last to endpoint as the failure endpoint
        exchange.setProperty(Exchange.FAILURE_ENDPOINT, exchange.getProperty(Exchange.TO_ENDPOINT));
        // the failure processor could also be asynchronous
        AsyncProcessor afp = AsyncProcessorTypeConverter.convert(processor);
        sync = AsyncProcessorHelper.process(afp, exchange, new AsyncCallback() {

            public void done(boolean sync) {
                if (log.isTraceEnabled()) {
                    log.trace(""Failure processor done: "" + processor + "" processing Exchange: "" + exchange);
                }
                try {
                    prepareExchangeAfterFailure(exchange, data);
                    // fire event as we had a failure processor to handle it, which there is a event for
                    boolean deadLetterChannel = processor == data.deadLetterProcessor && data.deadLetterProcessor != null;
                    EventHelper.notifyExchangeFailureHandled(exchange.getContext(), exchange, processor, deadLetterChannel);
                } finally {
                    // if the fault was handled asynchronously, this should be reflected in the callback as well
                    data.sync &= sync;
                    callback.done(data.sync);
                }
            }
        });
    } else {
        try {
            // no processor but we need to prepare after failure as well
            prepareExchangeAfterFailure(exchange, data);
        } finally {
            // callback we are done
            callback.done(data.sync);
        }
    }
    // create log message
    String msg = ""Failed delivery for exchangeId: "" + exchange.getExchangeId();
    msg = msg + "". Exhausted after delivery attempt: "" + data.redeliveryCounter + "" caught: "" + caught;
    if (processor != null) {
        msg = msg + "". Processed by failure processor: "" + processor;
    }
    // log that we failed delivery as we are exhausted
    logFailedDelivery(false, handled, false, exchange, msg, data, null);
    return sync;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3847_de9399f3,Minor,camel-core/src/main/java/org/apache/camel/impl/converter/BaseTypeConverterRegistry.java,148,232,"@SuppressWarnings(""unchecked"")
protected Object doConvertTo(final Class type, final Exchange exchange, final Object value) {
    if (log.isTraceEnabled()) {
        log.trace(""Converting {} -> {} with value: {}"", new Object[] { value == null ? ""null"" : value.getClass().getCanonicalName(), type.getCanonicalName(), value });
    }
    if (value == null) {
        // lets avoid NullPointerException when converting to boolean for null values
        if (boolean.class.isAssignableFrom(type)) {
            return Boolean.FALSE;
        }
        return null;
    }
    // same instance type
    if (type.isInstance(value)) {
        return type.cast(value);
    }
    // check if we have tried it before and if its a miss
    TypeMapping key = new TypeMapping(type, value.getClass());
    if (misses.containsKey(key)) {
        // we have tried before but we cannot convert this one
        return Void.TYPE;
    }
    // try to find a suitable type converter
    TypeConverter converter = getOrFindTypeConverter(type, value);
    if (converter != null) {
        log.trace(""Using converter: {} to convert {}"", converter, key);
        Object rc = converter.convertTo(type, exchange, value);
        if (rc != null) {
            return rc;
        }
    }
    // fallback converters
    for (FallbackTypeConverter fallback : fallbackConverters) {
        Object rc = fallback.getFallbackTypeConverter().convertTo(type, exchange, value);
        if (Void.TYPE.equals(rc)) {
            // it cannot be converted so give up
            return Void.TYPE;
        }
        if (rc != null) {
            // if fallback can promote then let it be promoted to a first class type converter
            if (fallback.isCanPromote()) {
                // add it as a known type converter since we found a fallback that could do it
                if (log.isDebugEnabled()) {
                    log.debug(""Promoting fallback type converter as a known type converter to convert from: {} to: {} for the fallback converter: {}"", new Object[] { type.getCanonicalName(), value.getClass().getCanonicalName(), fallback.getFallbackTypeConverter() });
                }
                addTypeConverter(type, value.getClass(), fallback.getFallbackTypeConverter());
            }
            if (log.isTraceEnabled()) {
                log.trace(""Fallback type converter {} converted type from: {} to: {}"", new Object[] { fallback.getFallbackTypeConverter(), type.getCanonicalName(), value.getClass().getCanonicalName() });
            }
            // return converted value
            return rc;
        }
    }
    // not found with that type then if it was a primitive type then try again with the wrapper type
    if (type.isPrimitive()) {
        Class primitiveType = ObjectHelper.convertPrimitiveTypeToWrapperType(type);
        if (primitiveType != type) {
            return convertTo(primitiveType, exchange, value);
        }
    }
    // Could not find suitable conversion, so remember it
    synchronized (misses) {
        misses.put(key, key);
    }
    // Could not find suitable conversion, so return Void to indicate not found
    return Void.TYPE;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3847_de9399f3,Minor,camel-core/src/main/java/org/apache/camel/impl/converter/BaseTypeConverterRegistry.java,234,248,"public void addTypeConverter(Class<?> toType, Class<?> fromType, TypeConverter typeConverter) {
    log.trace(""Adding type converter: {}"", typeConverter);
    TypeMapping key = new TypeMapping(toType, fromType);
    synchronized (typeMappings) {
        TypeConverter converter = typeMappings.get(key);
        // as race conditions can lead to many threads trying to promote the same fallback converter
        if (typeConverter != converter) {
            if (converter != null) {
                log.warn(""Overriding type converter from: "" + converter + "" to: "" + typeConverter);
            }
            typeMappings.put(key, typeConverter);
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-3878_b9094cb5,Major,camel-core/src/main/java/org/apache/camel/processor/RedeliveryErrorHandler.java,841,844,"@Override
protected void doStop() throws Exception {
    ServiceHelper.stopServices(deadLetter, output, outputAsync);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4011_cbffff59,Trivial,camel-core/src/main/java/org/apache/camel/converter/ObjectConverter.java,135,147,"/**
 * Returns the converted value, or null if the value is null
 */
@Converter
public static Short toShort(Object value) {
    if (value instanceof Short) {
        return (Short) value;
    } else if (value instanceof Number) {
        Number number = (Number) value;
        return number.shortValue();
    } else if (value instanceof String) {
        return Short.valueOf((String) value);
    } else {
        return null;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4011_cbffff59,Trivial,camel-core/src/main/java/org/apache/camel/converter/ObjectConverter.java,152,164,"/**
 * Returns the converted value, or null if the value is null
 */
@Converter
public static Integer toInteger(Object value) {
    if (value instanceof Integer) {
        return (Integer) value;
    } else if (value instanceof Number) {
        Number number = (Number) value;
        return number.intValue();
    } else if (value instanceof String) {
        return Integer.valueOf((String) value);
    } else {
        return null;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4011_cbffff59,Trivial,camel-core/src/main/java/org/apache/camel/converter/ObjectConverter.java,169,181,"/**
 * Returns the converted value, or null if the value is null
 */
@Converter
public static Long toLong(Object value) {
    if (value instanceof Long) {
        return (Long) value;
    } else if (value instanceof Number) {
        Number number = (Number) value;
        return number.longValue();
    } else if (value instanceof String) {
        return Long.valueOf((String) value);
    } else {
        return null;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4011_cbffff59,Trivial,camel-core/src/main/java/org/apache/camel/converter/ObjectConverter.java,186,198,"/**
 * Returns the converted value, or null if the value is null
 */
@Converter
public static Float toFloat(Object value) {
    if (value instanceof Float) {
        return (Float) value;
    } else if (value instanceof Number) {
        Number number = (Number) value;
        return number.floatValue();
    } else if (value instanceof String) {
        return Float.valueOf((String) value);
    } else {
        return null;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4211_4efddb3f,Major,camel-core/src/main/java/org/apache/camel/util/URISupport.java,60,89,"public static Map<String, Object> parseQuery(String uri) throws URISyntaxException {
    // must check for trailing & as the uri.split(""&"") will ignore those
    if (uri != null && uri.endsWith(""&"")) {
        throw new URISyntaxException(uri, ""Invalid uri syntax: Trailing & marker found. "" + ""Check the uri and remove the trailing & marker."");
    }
    try {
        // use a linked map so the parameters is in the same order
        Map<String, Object> rc = new LinkedHashMap<String, Object>();
        if (uri != null) {
            String[] parameters = uri.split(""&"");
            for (String parameter : parameters) {
                int p = parameter.indexOf(""="");
                if (p >= 0) {
                    String name = URLDecoder.decode(parameter.substring(0, p), CHARSET);
                    String value = URLDecoder.decode(parameter.substring(p + 1), CHARSET);
                    rc.put(name, value);
                } else {
                    rc.put(parameter, null);
                }
            }
        }
        return rc;
    } catch (UnsupportedEncodingException e) {
        URISyntaxException se = new URISyntaxException(e.toString(), ""Invalid encoding"");
        se.initCause(e);
        throw se;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4211_4efddb3f,Major,camel-core/src/main/java/org/apache/camel/util/URISupport.java,137,167,"public static String createQueryString(Map<Object, Object> options) throws URISyntaxException {
    try {
        if (options.size() > 0) {
            StringBuilder rc = new StringBuilder();
            boolean first = true;
            for (Object o : options.keySet()) {
                if (first) {
                    first = false;
                } else {
                    rc.append(""&"");
                }
                String key = (String) o;
                String value = (String) options.get(key);
                rc.append(URLEncoder.encode(key, CHARSET));
                // only append if value is not null
                if (value != null) {
                    rc.append(""="");
                    rc.append(URLEncoder.encode(value, CHARSET));
                }
            }
            return rc.toString();
        } else {
            return """";
        }
    } catch (UnsupportedEncodingException e) {
        URISyntaxException se = new URISyntaxException(e.toString(), ""Invalid encoding"");
        se.initCause(e);
        throw se;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4354_96e40c3c,Major,camel-core/src/main/java/org/apache/camel/impl/ProducerCache.java,262,313,"/**
 * Sends an exchange to an endpoint using a supplied callback supporting the asynchronous routing engine.
 * <p/>
 * If an exception was thrown during processing, it would be set on the given Exchange
 *
 * @param endpoint         the endpoint to send the exchange to
 * @param exchange         the exchange, can be <tt>null</tt> if so then create a new exchange from the producer
 * @param pattern          the exchange pattern, can be <tt>null</tt>
 * @param callback         the asynchronous callback
 * @param producerCallback the producer template callback to be executed
 * @return (doneSync) <tt>true</tt> to continue execute synchronously, <tt>false</tt> to continue being executed asynchronously
 */
public boolean doInAsyncProducer(Endpoint endpoint, Exchange exchange, ExchangePattern pattern, AsyncCallback callback, AsyncProducerCallback producerCallback) {
    boolean sync = true;
    // get the producer and we do not mind if its pooled as we can handle returning it back to the pool
    Producer producer = doGetProducer(endpoint, true);
    if (producer == null) {
        if (isStopped()) {
            LOG.warn(""Ignoring exchange sent after processor is stopped: "" + exchange);
            return false;
        } else {
            throw new IllegalStateException(""No producer, this processor has not been started: "" + this);
        }
    }
    StopWatch watch = null;
    if (exchange != null) {
        // record timing for sending the exchange using the producer
        watch = new StopWatch();
    }
    try {
        // invoke the callback
        AsyncProcessor asyncProcessor = AsyncProcessorTypeConverter.convert(producer);
        sync = producerCallback.doInAsyncProducer(producer, asyncProcessor, exchange, pattern, callback);
    } catch (Throwable e) {
        // ensure exceptions is caught and set on the exchange
        if (exchange != null) {
            exchange.setException(e);
        }
    } finally {
        if (exchange != null && exchange.getException() == null) {
            long timeTaken = watch.stop();
            // emit event that the exchange was sent to the endpoint
            EventHelper.notifyExchangeSent(exchange.getContext(), exchange, endpoint, timeTaken);
        }
        if (producer instanceof ServicePoolAware) {
            // release back to the pool
            pool.release(endpoint, producer);
        } else if (!producer.isSingleton()) {
            // stop non singleton producers as we should not leak resources
            try {
                ServiceHelper.stopService(producer);
            } catch (Exception e) {
                // ignore and continue
                LOG.warn(""Error stopping producer: "" + producer, e);
            }
        }
    }
    return sync;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4370_7345fefc,Major,camel-core/src/main/java/org/apache/camel/component/file/GenericFile.java,95,100,"/**
 * Bind this GenericFile to an Exchange
 */
public void bindToExchange(Exchange exchange) {
    exchange.setProperty(FileComponent.FILE_EXCHANGE_FILE, this);
    GenericFileMessage<T> in = new GenericFileMessage<T>(this);
    exchange.setIn(in);
    populateHeaders(in);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4388_f39bc60d,Major,camel-core/src/main/java/org/apache/camel/processor/LogProcessor.java,44,49,"@Override
public boolean process(Exchange exchange, AsyncCallback callback) {
    String msg = expression.evaluate(exchange, String.class);
    logger.log(msg);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4467_79168a23,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,1369,1475,"private void doStartCamel() throws Exception {
    if (isStreamCaching()) {
        // only add a new stream cache if not already configured
        if (StreamCaching.getStreamCaching(this) == null) {
            log.info(""StreamCaching is enabled on CamelContext: "" + getName());
            addInterceptStrategy(new StreamCaching());
        }
    }
    if (isTracing()) {
        // tracing is added in the DefaultChannel so we can enable it on the fly
        log.info(""Tracing is enabled on CamelContext: "" + getName());
    }
    if (isUseMDCLogging()) {
        // log if MDC has been enabled
        log.info(""MDC logging is enabled on CamelContext: "" + getName());
    }
    if (isHandleFault()) {
        // only add a new handle fault if not already configured
        if (HandleFault.getHandleFault(this) == null) {
            log.info(""HandleFault is enabled on CamelContext: "" + getName());
            addInterceptStrategy(new HandleFault());
        }
    }
    if (getDelayer() != null && getDelayer() > 0) {
        // only add a new delayer if not already configured
        if (Delayer.getDelayer(this) == null) {
            long millis = getDelayer();
            log.info(""Delayer is enabled with: "" + millis + "" ms. on CamelContext: "" + getName());
            addInterceptStrategy(new Delayer(millis));
        }
    }
    // register debugger
    if (getDebugger() != null) {
        log.info(""Debugger: "" + getDebugger() + "" is enabled on CamelContext: "" + getName());
        // register this camel context on the debugger
        getDebugger().setCamelContext(this);
        startService(getDebugger());
        addInterceptStrategy(new Debug(getDebugger()));
    }
    // start management strategy before lifecycles are started
    getManagementStrategy().start();
    // start lifecycle strategies
    Iterator<LifecycleStrategy> it = lifecycleStrategies.iterator();
    while (it.hasNext()) {
        LifecycleStrategy strategy = it.next();
        try {
            strategy.onContextStart(this);
        } catch (VetoCamelContextStartException e) {
            // okay we should not start Camel since it was vetoed
            log.warn(""Lifecycle strategy vetoed starting CamelContext ("" + getName() + "")"", e);
            throw e;
        } catch (Exception e) {
            log.warn(""Lifecycle strategy "" + strategy + "" failed starting CamelContext ("" + getName() + "")"", e);
            throw e;
        }
    }
    // start notifiers as services
    for (EventNotifier notifier : getManagementStrategy().getEventNotifiers()) {
        if (notifier instanceof Service) {
            Service service = (Service) notifier;
            for (LifecycleStrategy strategy : lifecycleStrategies) {
                strategy.onServiceAdd(this, service, null);
            }
        }
        if (notifier instanceof Service) {
            startService((Service) notifier);
        }
    }
    // must let some bootstrap service be started before we can notify the starting event
    EventHelper.notifyCamelContextStarting(this);
    forceLazyInitialization();
    // re-create endpoint registry as the cache size limit may be set after the constructor of this instance was called.
    // and we needed to create endpoints up-front as it may be accessed before this context is started
    endpoints = new EndpointRegistry(this, endpoints);
    addService(endpoints);
    addService(executorServiceManager);
    addService(producerServicePool);
    addService(inflightRepository);
    addService(shutdownStrategy);
    addService(packageScanClassResolver);
    startServices(components.values());
    // start the route definitions before the routes is started
    startRouteDefinitions(routeDefinitions);
    // start routes
    if (doNotStartRoutesOnFirstStart) {
        log.info(""Cannot start routes as CamelContext has been configured with autoStartup=false"");
    }
    // invoke this logic to warmup the routes and if possible also start the routes
    doStartOrResumeRoutes(routeServices, true, !doNotStartRoutesOnFirstStart, false, true);
// starting will continue in the start method
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4467_79168a23,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,1477,1541,"protected synchronized void doStop() throws Exception {
    stopWatch.restart();
    log.info(""Apache Camel "" + getVersion() + "" (CamelContext:"" + getName() + "") is shutting down"");
    EventHelper.notifyCamelContextStopping(this);
    // stop route inputs in the same order as they was started so we stop the very first inputs first
    try {
        shutdownStrategy.shutdown(this, getRouteStartupOrder());
    } catch (Throwable e) {
        log.warn(""Error occurred while shutting down routes. This exception will be ignored."", e);
    }
    getRouteStartupOrder().clear();
    shutdownServices(routeServices.values());
    // do not clear route services or startup listeners as we can start Camel again and get the route back as before
    // but clear any suspend routes
    suspendedRouteServices.clear();
    // the stop order is important
    // shutdown debugger
    ServiceHelper.stopAndShutdownService(getDebugger());
    shutdownServices(endpoints.values());
    endpoints.clear();
    shutdownServices(components.values());
    components.clear();
    try {
        for (LifecycleStrategy strategy : lifecycleStrategies) {
            strategy.onContextStop(this);
        }
    } catch (Throwable e) {
        log.warn(""Error occurred while stopping lifecycle strategies. This exception will be ignored."", e);
    }
    // shutdown services as late as possible
    shutdownServices(servicesToClose);
    servicesToClose.clear();
    // must notify that we are stopped before stopping the management strategy
    EventHelper.notifyCamelContextStopped(this);
    // stop the notifier service
    for (EventNotifier notifier : getManagementStrategy().getEventNotifiers()) {
        shutdownServices(notifier);
    }
    // shutdown management as the last one
    shutdownServices(managementStrategy);
    // stop the lazy created so they can be re-created on restart
    forceStopLazyInitialization();
    stopWatch.stop();
    if (log.isInfoEnabled()) {
        log.info(""Uptime: "" + getUptime());
        log.info(""Apache Camel "" + getVersion() + "" (CamelContext: "" + getName() + "") is shutdown in "" + TimeUtils.printDuration(stopWatch.taken()));
    }
    // and clear start date
    startDate = null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4474_06a8489a,Major,camel-core/src/main/java/org/apache/camel/component/file/FileEndpoint.java,48,92,"public FileConsumer createConsumer(Processor processor) throws Exception {
    ObjectHelper.notNull(operations, ""operations"");
    ObjectHelper.notNull(file, ""file"");
    // we assume its a file if the name has a dot in it (eg foo.txt)
    boolean isDirectory = file.isDirectory();
    if (!isDirectory && file.getName().contains(""."")) {
        throw new IllegalArgumentException(""Only directory is supported. Endpoint must be configured with a valid starting directory: "" + file);
    }
    // auto create starting directory if needed
    if (!file.exists() && !isDirectory) {
        if (isAutoCreate()) {
            log.debug(""Creating non existing starting directory: {}"", file);
            boolean absolute = FileUtil.isAbsolute(file);
            operations.buildDirectory(file.getPath(), absolute);
        } else if (isStartingDirectoryMustExist()) {
            throw new FileNotFoundException(""Starting directory does not exist: "" + file);
        }
    }
    FileConsumer result = new FileConsumer(this, processor, operations);
    if (isDelete() && getMove() != null) {
        throw new IllegalArgumentException(""You cannot set both delete=true and move options"");
    }
    // if noop=true then idempotent should also be configured
    if (isNoop() && !isIdempotentSet()) {
        log.info(""Endpoint is configured with noop=true so forcing endpoint to be idempotent as well"");
        setIdempotent(true);
    }
    // if idempotent and no repository set then create a default one
    if (isIdempotentSet() && isIdempotent() && idempotentRepository == null) {
        log.info(""Using default memory based idempotent repository with cache max size: "" + DEFAULT_IDEMPOTENT_CACHE_SIZE);
        idempotentRepository = MemoryIdempotentRepository.memoryIdempotentRepository(DEFAULT_IDEMPOTENT_CACHE_SIZE);
    }
    // set max messages per poll
    result.setMaxMessagesPerPoll(getMaxMessagesPerPoll());
    configureConsumer(result);
    return result;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4482_e38494f1,Major,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,782,801,"protected Iterable<ProcessorExchangePair> createProcessorExchangePairs(Exchange exchange) throws Exception {
    List<ProcessorExchangePair> result = new ArrayList<ProcessorExchangePair>(processors.size());
    int index = 0;
    for (Processor processor : processors) {
        // copy exchange, and do not share the unit of work
        Exchange copy = ExchangeHelper.createCorrelatedCopy(exchange, false);
        // if we share unit of work, we need to prepare the child exchange
        if (isShareUnitOfWork()) {
            prepareSharedUnitOfWork(copy, exchange);
        }
        // and add the pair
        RouteContext routeContext = exchange.getUnitOfWork() != null ? exchange.getUnitOfWork().getRouteContext() : null;
        result.add(createProcessorExchangePair(index++, processor, copy, routeContext));
    }
    return result;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4482_e38494f1,Major,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,100,109,"@Override
protected Iterable<ProcessorExchangePair> createProcessorExchangePairs(Exchange exchange) {
    Object value = expression.evaluate(exchange, Object.class);
    if (isStreaming()) {
        return createProcessorExchangePairsIterable(exchange, value);
    } else {
        return createProcessorExchangePairsList(exchange, value);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4486_f98ac676,Major,camel-core/src/main/java/org/apache/camel/processor/RoutingSlip.java,173,245,"private boolean doRoutingSlip(Exchange exchange, AsyncCallback callback) {
    Exchange current = exchange;
    RoutingSlipIterator iter;
    try {
        iter = createRoutingSlipIterator(exchange);
    } catch (Exception e) {
        exchange.setException(e);
        callback.done(true);
        return true;
    }
    // ensure the slip is empty when we start
    if (current.hasProperties()) {
        current.setProperty(Exchange.SLIP_ENDPOINT, null);
    }
    while (iter.hasNext(current)) {
        Endpoint endpoint;
        try {
            endpoint = resolveEndpoint(iter, exchange);
            // if no endpoint was resolved then try the next
            if (endpoint == null) {
                continue;
            }
        } catch (Exception e) {
            // error resolving endpoint so we should break out
            exchange.setException(e);
            return true;
        }
        // prepare and process the routing slip
        Exchange copy = prepareExchangeForRoutingSlip(current, endpoint);
        boolean sync = processExchange(endpoint, copy, exchange, callback, iter);
        current = copy;
        if (!sync) {
            log.trace(""Processing exchangeId: {} is continued being processed asynchronously"", exchange.getExchangeId());
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return false;
        }
        log.trace(""Processing exchangeId: {} is continued being processed synchronously"", exchange.getExchangeId());
        // we ignore some kind of exceptions and allow us to continue
        if (isIgnoreInvalidEndpoints()) {
            FailedToCreateProducerException e = current.getException(FailedToCreateProducerException.class);
            if (e != null) {
                if (log.isDebugEnabled()) {
                    log.debug(""Endpoint uri is invalid: "" + endpoint + "". This exception will be ignored."", e);
                }
                current.setException(null);
            }
        }
        // check for error if so we should break out
        if (!continueProcessing(current, ""so breaking out of the routing slip"", log)) {
            break;
        }
    }
    // logging nextExchange as it contains the exchange that might have altered the payload and since
    // we are logging the completion if will be confusing if we log the original instead
    // we could also consider logging the original and the nextExchange then we have *before* and *after* snapshots
    log.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), current);
    // copy results back to the original exchange
    ExchangeHelper.copyResults(exchange, current);
    callback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4509_8e3450f4,Major,camel-core/src/main/java/org/apache/camel/processor/MarshalProcessor.java,46,61,"public void process(Exchange exchange) throws Exception {
    ObjectHelper.notNull(dataFormat, ""dataFormat"");
    ByteArrayOutputStream buffer = new ByteArrayOutputStream();
    Message in = exchange.getIn();
    Object body = in.getBody();
    // lets setup the out message before we invoke the dataFormat
    // so that it can mutate it if necessary
    Message out = exchange.getOut();
    out.copyFrom(in);
    dataFormat.marshal(exchange, body, buffer);
    byte[] data = buffer.toByteArray();
    out.setBody(data);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4509_8e3450f4,Major,camel-core/src/main/java/org/apache/camel/processor/UnmarshalProcessor.java,47,64,"public void process(Exchange exchange) throws Exception {
    ObjectHelper.notNull(dataFormat, ""dataFormat"");
    InputStream stream = ExchangeHelper.getMandatoryInBody(exchange, InputStream.class);
    try {
        // lets setup the out message before we invoke the dataFormat
        // so that it can mutate it if necessary
        Message out = exchange.getOut();
        out.copyFrom(exchange.getIn());
        Object result = dataFormat.unmarshal(exchange, stream);
        out.setBody(result);
    } finally {
        if (stream != null) {
            stream.close();
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4513_9e05f77f,Minor,camel-core/src/main/java/org/apache/camel/language/bean/BeanExpression.java,147,169,"public void process(Exchange exchange) throws Exception {
    BeanProcessor processor = new BeanProcessor(beanHolder);
    if (methodName != null) {
        processor.setMethod(methodName);
        // enable OGNL like invocation
        processor.setShorthandMethod(true);
    }
    try {
        // copy the original exchange to avoid side effects on it
        Exchange resultExchange = exchange.copy();
        // force to use InOut to retrieve the result on the OUT message
        resultExchange.setPattern(ExchangePattern.InOut);
        processor.process(resultExchange);
        result = resultExchange.getOut().getBody();
        // propagate exceptions
        if (resultExchange.getException() != null) {
            exchange.setException(resultExchange.getException());
        }
    } catch (Exception e) {
        throw new RuntimeBeanExpressionException(exchange, beanName, methodName, e);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4513_9e05f77f,Minor,camel-core/src/main/java/org/apache/camel/language/bean/BeanExpression.java,195,264,"public void process(Exchange exchange) throws Exception {
    // copy the original exchange to avoid side effects on it
    Exchange resultExchange = exchange.copy();
    // force to use InOut to retrieve the result on the OUT message
    resultExchange.setPattern(ExchangePattern.InOut);
    // do not propagate any method name when using OGNL, as with OGNL we
    // compute and provide the method name to explicit to invoke
    resultExchange.getIn().removeHeader(Exchange.BEAN_METHOD_NAME);
    // current ognl path as we go along
    String ognlPath = """";
    // loop and invoke each method
    Object beanToCall = beanHolder.getBean();
    // there must be a bean to call with, we currently does not support OGNL expressions on using purely static methods
    if (beanToCall == null) {
        throw new IllegalArgumentException(""Bean instance is null. OGNL bean expressions requires bean instances."");
    }
    // Split ognl except when this is not a Map, Array
    // and we would like to keep the dots within the key name
    List<String> methods = OgnlHelper.splitOgnl(ognl);
    for (String methodName : methods) {
        BeanHolder holder = new ConstantBeanHolder(beanToCall, exchange.getContext());
        // support the null safe operator
        boolean nullSafe = OgnlHelper.isNullSafeOperator(methodName);
        // keep up with how far are we doing
        ognlPath += methodName;
        // get rid of leading ?. or . as we only needed that to determine if null safe was enabled or not
        methodName = OgnlHelper.removeLeadingOperators(methodName);
        // are we doing an index lookup (eg in Map/List/array etc)?
        String key = null;
        KeyValueHolder<String, String> index = OgnlHelper.isOgnlIndex(methodName);
        if (index != null) {
            methodName = index.getKey();
            key = index.getValue();
        }
        // only invoke if we have a method name to use to invoke
        if (methodName != null) {
            InvokeProcessor invoke = new InvokeProcessor(holder, methodName);
            invoke.process(resultExchange);
            // check for exception and rethrow if we failed
            if (resultExchange.getException() != null) {
                throw new RuntimeBeanExpressionException(exchange, beanName, methodName, resultExchange.getException());
            }
            result = invoke.getResult();
        }
        // if there was a key then we need to lookup using the key
        if (key != null) {
            result = lookupResult(resultExchange, key, result, nullSafe, ognlPath, holder.getBean());
        }
        // check null safe for null results
        if (result == null && nullSafe) {
            return;
        }
        // prepare for next bean to invoke
        beanToCall = result;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4542_c408c3ed,Major,camel-core/src/main/java/org/apache/camel/model/language/MethodCallExpression.java,145,178,"@Override
public Expression createExpression(CamelContext camelContext) {
    Expression answer;
    if (beanType == null && beanTypeName != null) {
        try {
            beanType = camelContext.getClassResolver().resolveMandatoryClass(beanTypeName);
        } catch (ClassNotFoundException e) {
            throw ObjectHelper.wrapRuntimeCamelException(e);
        }
    }
    if (beanType != null) {
        // create a bean if there is a default public no-arg constructor
        if (ObjectHelper.hasDefaultPublicNoArgConstructor(beanType)) {
            instance = camelContext.getInjector().newInstance(beanType);
            answer = new BeanExpression(instance, getMethod());
        } else {
            answer = new BeanExpression(beanType, getMethod());
        }
    } else if (instance != null) {
        answer = new BeanExpression(instance, getMethod());
    } else {
        String ref = beanName();
        // if its a ref then check that the ref exists
        BeanHolder holder = new RegistryBean(camelContext, ref);
        // get the bean which will check that it exists
        instance = holder.getBean();
        answer = new BeanExpression(ref, getMethod());
    }
    validateHasMethod(camelContext, instance, beanType, getMethod());
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-4682_1e54865c,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,1510,1576,"protected synchronized void doStop() throws Exception {
    stopWatch.restart();
    log.info(""Apache Camel "" + getVersion() + "" (CamelContext:"" + getName() + "") is shutting down"");
    EventHelper.notifyCamelContextStopping(this);
    // stop route inputs in the same order as they was started so we stop the very first inputs first
    try {
        shutdownStrategy.shutdown(this, getRouteStartupOrder());
    } catch (Throwable e) {
        log.warn(""Error occurred while shutting down routes. This exception will be ignored."", e);
    }
    getRouteStartupOrder().clear();
    shutdownServices(routeServices.values());
    // do not clear route services or startup listeners as we can start Camel again and get the route back as before
    // but clear any suspend routes
    suspendedRouteServices.clear();
    // the stop order is important
    // shutdown debugger
    ServiceHelper.stopAndShutdownService(getDebugger());
    shutdownServices(endpoints.values());
    endpoints.clear();
    shutdownServices(components.values());
    components.clear();
    try {
        for (LifecycleStrategy strategy : lifecycleStrategies) {
            strategy.onContextStop(this);
        }
    } catch (Throwable e) {
        log.warn(""Error occurred while stopping lifecycle strategies. This exception will be ignored."", e);
    }
    // shutdown services as late as possible
    shutdownServices(servicesToClose);
    servicesToClose.clear();
    // must notify that we are stopped before stopping the management strategy
    EventHelper.notifyCamelContextStopped(this);
    // stop the notifier service
    for (EventNotifier notifier : getManagementStrategy().getEventNotifiers()) {
        shutdownServices(notifier);
    }
    // shutdown management as the last one
    shutdownServices(managementStrategy);
    shutdownServices(lifecycleStrategies);
    lifecycleStrategies.clear();
    // stop the lazy created so they can be re-created on restart
    forceStopLazyInitialization();
    stopWatch.stop();
    if (log.isInfoEnabled()) {
        log.info(""Uptime: "" + getUptime());
        log.info(""Apache Camel "" + getVersion() + "" (CamelContext: "" + getName() + "") is shutdown in "" + TimeUtils.printDuration(stopWatch.taken()));
    }
    // and clear start date
    startDate = null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5137_afa1d132,Minor,camel-core/src/main/java/org/apache/camel/component/timer/TimerConsumer.java,45,73,"@Override
protected void doStart() throws Exception {
    task = new TimerTask() {

        // counter
        private final AtomicLong counter = new AtomicLong();

        @Override
        public void run() {
            try {
                long count = counter.incrementAndGet();
                boolean fire = endpoint.getRepeatCount() <= 0 || count <= endpoint.getRepeatCount();
                if (fire) {
                    sendTimerExchange(count);
                } else {
                    // no need to fire anymore as we exceeded repeat count
                    LOG.debug(""Cancelling {} timer as repeat count limit reached after {} counts."", endpoint.getTimerName(), endpoint.getRepeatCount());
                    cancel();
                }
            } catch (Throwable e) {
                // catch all to avoid the JVM closing the thread and not firing again
                LOG.warn(""Error processing exchange. This exception will be ignored, to let the timer be able to trigger again."", e);
            }
        }
    };
    Timer timer = endpoint.getTimer();
    configureTask(task, timer);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5137_afa1d132,Minor,camel-core/src/main/java/org/apache/camel/component/timer/TimerConsumer.java,51,68,"@Override
public void run() {
    try {
        long count = counter.incrementAndGet();
        boolean fire = endpoint.getRepeatCount() <= 0 || count <= endpoint.getRepeatCount();
        if (fire) {
            sendTimerExchange(count);
        } else {
            // no need to fire anymore as we exceeded repeat count
            LOG.debug(""Cancelling {} timer as repeat count limit reached after {} counts."", endpoint.getTimerName(), endpoint.getRepeatCount());
            cancel();
        }
    } catch (Throwable e) {
        // catch all to avoid the JVM closing the thread and not firing again
        LOG.warn(""Error processing exchange. This exception will be ignored, to let the timer be able to trigger again."", e);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5140_8898d491,Minor,camel-core/src/main/java/org/apache/camel/component/bean/BeanProcessor.java,76,201,"public boolean process(Exchange exchange, AsyncCallback callback) {
    // do we have an explicit method name we always should invoke (either configured on endpoint or as a header)
    String explicitMethodName = exchange.getIn().getHeader(Exchange.BEAN_METHOD_NAME, method, String.class);
    Object bean;
    BeanInfo beanInfo;
    try {
        bean = beanHolder.getBean();
        beanInfo = beanHolder.getBeanInfo();
    } catch (Throwable e) {
        exchange.setException(e);
        callback.done(true);
        return true;
    }
    // do we have a custom adapter for this POJO to a Processor
    // should not be invoked if an explicit method has been set
    Processor processor = getProcessor();
    if (explicitMethodName == null && processor != null) {
        LOG.trace(""Using a custom adapter as bean invocation: {}"", processor);
        try {
            processor.process(exchange);
        } catch (Throwable e) {
            exchange.setException(e);
        }
        callback.done(true);
        return true;
    }
    Message in = exchange.getIn();
    // is the message proxied using a BeanInvocation?
    BeanInvocation beanInvoke = null;
    if (in.getBody() != null && in.getBody() instanceof BeanInvocation) {
        // BeanInvocation would be stored directly as the message body
        // do not force any type conversion attempts as it would just be unnecessary and cost a bit performance
        // so a regular instanceof check is sufficient
        beanInvoke = (BeanInvocation) in.getBody();
    }
    if (beanInvoke != null) {
        // Now it gets a bit complicated as ProxyHelper can proxy beans which we later
        // intend to invoke (for example to proxy and invoke using spring remoting).
        // and therefore the message body contains a BeanInvocation object.
        // However this can causes problem if we in a Camel route invokes another bean,
        // so we must test whether BeanHolder and BeanInvocation is the same bean or not
        LOG.trace(""Exchange IN body is a BeanInvocation instance: {}"", beanInvoke);
        Class<?> clazz = beanInvoke.getMethod().getDeclaringClass();
        boolean sameBean = clazz.isInstance(bean);
        if (LOG.isDebugEnabled()) {
            LOG.debug(""BeanHolder bean: {} and beanInvocation bean: {} is same instance: {}"", new Object[] { bean.getClass(), clazz, sameBean });
        }
        if (sameBean) {
            beanInvoke.invoke(bean, exchange);
            // propagate headers
            exchange.getOut().getHeaders().putAll(exchange.getIn().getHeaders());
            callback.done(true);
            return true;
        }
    }
    // set temporary header which is a hint for the bean info that introspect the bean
    if (in.getHeader(Exchange.BEAN_MULTI_PARAMETER_ARRAY) == null) {
        in.setHeader(Exchange.BEAN_MULTI_PARAMETER_ARRAY, isMultiParameterArray());
    }
    MethodInvocation invocation;
    // set explicit method name to invoke as a header, which is how BeanInfo can detect it
    if (explicitMethodName != null) {
        in.setHeader(Exchange.BEAN_METHOD_NAME, explicitMethodName);
    }
    try {
        invocation = beanInfo.createInvocation(bean, exchange);
    } catch (Throwable e) {
        exchange.setException(e);
        callback.done(true);
        return true;
    } finally {
        // must remove headers as they were provisional
        in.removeHeader(Exchange.BEAN_MULTI_PARAMETER_ARRAY);
        in.removeHeader(Exchange.BEAN_METHOD_NAME);
    }
    if (invocation == null) {
        throw new IllegalStateException(""No method invocation could be created, no matching method could be found on: "" + bean);
    }
    Object value;
    try {
        AtomicBoolean sync = new AtomicBoolean(true);
        value = invocation.proceed(callback, sync);
        if (!sync.get()) {
            LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", exchange.getExchangeId());
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return false;
        }
        LOG.trace(""Processing exchangeId: {} is continued being processed synchronously"", exchange.getExchangeId());
    } catch (InvocationTargetException e) {
        // let's unwrap the exception when it's an invocation target exception
        exchange.setException(e.getCause());
        callback.done(true);
        return true;
    } catch (Throwable e) {
        exchange.setException(e);
        callback.done(true);
        return true;
    }
    // if the method returns something then set the value returned on the Exchange
    if (!invocation.getMethod().getReturnType().equals(Void.TYPE) && value != Void.TYPE) {
        if (exchange.getPattern().isOutCapable()) {
            // force out creating if not already created (as its lazy)
            LOG.debug(""Setting bean invocation result on the OUT message: {}"", value);
            exchange.getOut().setBody(value);
            // propagate headers
            exchange.getOut().getHeaders().putAll(exchange.getIn().getHeaders());
        } else {
            // if not out then set it on the in
            LOG.debug(""Setting bean invocation result on the IN message: {}"", value);
            exchange.getIn().setBody(value);
        }
    }
    callback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5154_a8586a69,Minor,camel-core/src/main/java/org/apache/camel/component/bean/BeanInfo.java,282,324,"/**
 * Introspects the given method
 *
 * @param clazz the class
 * @param method the method
 * @return the method info, is newer <tt>null</tt>
 */
private MethodInfo introspect(Class<?> clazz, Method method) {
    LOG.trace(""Introspecting class: {}, method: {}"", clazz, method);
    String opName = method.getName();
    MethodInfo methodInfo = createMethodInfo(clazz, method);
    // methods already registered should be preferred to use instead of super classes of existing methods
    // we want to us the method from the sub class over super classes, so if we have already registered
    // the method then use it (we are traversing upwards: sub (child) -> super (farther) )
    MethodInfo existingMethodInfo = overridesExistingMethod(methodInfo);
    if (existingMethodInfo != null) {
        LOG.trace(""This method is already overridden in a subclass, so the method from the sub class is preferred: {}"", existingMethodInfo);
        return existingMethodInfo;
    }
    LOG.trace(""Adding operation: {} for method: {}"", opName, methodInfo);
    if (hasMethod(opName)) {
        // we have an overloaded method so add the method info to the same key
        List<MethodInfo> existing = getOperations(opName);
        existing.add(methodInfo);
    } else {
        // its a new method we have not seen before so wrap it in a list and add it
        List<MethodInfo> methods = new ArrayList<MethodInfo>();
        methods.add(methodInfo);
        operations.put(opName, methods);
    }
    if (methodInfo.hasCustomAnnotation()) {
        operationsWithCustomAnnotation.add(methodInfo);
    } else if (methodInfo.hasBodyParameter()) {
        operationsWithBody.add(methodInfo);
    }
    if (methodInfo.hasHandlerAnnotation()) {
        operationsWithHandlerAnnotation.add(methodInfo);
    }
    // must add to method map last otherwise we break stuff
    methodMap.put(method, methodInfo);
    return methodInfo;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5154_a8586a69,Minor,camel-core/src/main/java/org/apache/camel/component/bean/BeanInfo.java,436,492,"/**
 * Choose one of the available methods to invoke if we can match
 * the message body to the body parameter
 *
 * @param pojo the bean to invoke a method on
 * @param exchange the message exchange
 * @param name an optional name of the method that must match, use <tt>null</tt> to indicate all methods
 * @return the method to invoke or null if no definitive method could be matched
 * @throws AmbiguousMethodCallException is thrown if cannot choose method due to ambiguity
 */
protected MethodInfo chooseMethod(Object pojo, Exchange exchange, String name) throws AmbiguousMethodCallException {
    // @Handler should be select first
    // then any single method that has a custom @annotation
    // or any single method that has a match parameter type that matches the Exchange payload
    // and last then try to select the best among the rest
    // must use defensive copy, to avoid altering the shared lists
    // and we want to remove unwanted operations from these local lists
    final List<MethodInfo> localOperationsWithBody = new ArrayList<MethodInfo>(operationsWithBody);
    final List<MethodInfo> localOperationsWithCustomAnnotation = new ArrayList<MethodInfo>(operationsWithCustomAnnotation);
    final List<MethodInfo> localOperationsWithHandlerAnnotation = new ArrayList<MethodInfo>(operationsWithHandlerAnnotation);
    if (name != null) {
        // filter all lists to only include methods with this name
        removeNonMatchingMethods(localOperationsWithHandlerAnnotation, name);
        removeNonMatchingMethods(localOperationsWithCustomAnnotation, name);
        removeNonMatchingMethods(localOperationsWithBody, name);
    } else {
        // remove all getter/setter as we do not want to consider these methods
        removeAllSetterOrGetterMethods(localOperationsWithHandlerAnnotation);
        removeAllSetterOrGetterMethods(localOperationsWithCustomAnnotation);
        removeAllSetterOrGetterMethods(localOperationsWithBody);
    }
    if (localOperationsWithHandlerAnnotation.size() > 1) {
        // if we have more than 1 @Handler then its ambiguous
        throw new AmbiguousMethodCallException(exchange, localOperationsWithHandlerAnnotation);
    }
    if (localOperationsWithHandlerAnnotation.size() == 1) {
        // methods with handler should be preferred
        return localOperationsWithHandlerAnnotation.get(0);
    } else if (localOperationsWithCustomAnnotation.size() == 1) {
        // if there is one method with an annotation then use that one
        return localOperationsWithCustomAnnotation.get(0);
    } else if (localOperationsWithBody.size() == 1) {
        // if there is one method with body then use that one
        return localOperationsWithBody.get(0);
    }
    Collection<MethodInfo> possibleOperations = new ArrayList<MethodInfo>();
    possibleOperations.addAll(localOperationsWithBody);
    possibleOperations.addAll(localOperationsWithCustomAnnotation);
    if (!possibleOperations.isEmpty()) {
        // multiple possible operations so find the best suited if possible
        MethodInfo answer = chooseMethodWithMatchingBody(exchange, possibleOperations, localOperationsWithCustomAnnotation);
        if (answer == null) {
            throw new AmbiguousMethodCallException(exchange, possibleOperations);
        } else {
            return answer;
        }
    }
    // not possible to determine
    return null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5187_8cadc344,Minor,camel-core/src/main/java/org/apache/camel/management/DefaultManagementAgent.java,242,248,"public void unregister(ObjectName name) throws JMException {
    if (server.isRegistered(name)) {
        server.unregisterMBean(name);
        LOG.debug(""Unregistered MBean with ObjectName: {}"", name);
    }
    mbeansRegistered.remove(name);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5187_8cadc344,Minor,camel-core/src/main/java/org/apache/camel/management/DefaultManagementAgent.java,250,252,"public boolean isRegistered(ObjectName name) {
    return server.isRegistered(name);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5187_8cadc344,Minor,camel-core/src/main/java/org/apache/camel/management/DefaultManagementAgent.java,266,299,"protected void doStop() throws Exception {
    // close JMX Connector
    if (cs != null) {
        try {
            cs.stop();
        } catch (IOException e) {
            LOG.debug(""Error occurred during stopping JMXConnectorService: "" + cs + "". This exception will be ignored."");
        }
        cs = null;
    }
    if (mbeansRegistered.isEmpty()) {
        return;
    }
    // Using the array to hold the busMBeans to avoid the CurrentModificationException
    ObjectName[] mBeans = mbeansRegistered.toArray(new ObjectName[mbeansRegistered.size()]);
    int caught = 0;
    for (ObjectName name : mBeans) {
        try {
            mbeansRegistered.remove(name);
            unregister(name);
        } catch (Exception e) {
            LOG.info(""Exception unregistering MBean with name "" + name, e);
            caught++;
        }
    }
    if (caught > 0) {
        LOG.warn(""A number of "" + caught + "" exceptions caught while unregistering MBeans during stop operation."" + "" See INFO log for details."");
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5187_8cadc344,Minor,camel-core/src/main/java/org/apache/camel/management/DefaultManagementAgent.java,301,329,"private void registerMBeanWithServer(Object obj, ObjectName name, boolean forceRegistration) throws JMException {
    // have we already registered the bean, there can be shared instances in the camel routes
    boolean exists = server.isRegistered(name);
    if (exists) {
        if (forceRegistration) {
            LOG.info(""ForceRegistration enabled, unregistering existing MBean with ObjectName: {}"", name);
            server.unregisterMBean(name);
        } else {
            // okay ignore we do not want to force it and it could be a shared instance
            LOG.debug(""MBean already registered with ObjectName: {}"", name);
        }
    }
    // register bean if by force or not exists
    ObjectInstance instance = null;
    if (forceRegistration || !exists) {
        LOG.trace(""Registering MBean with ObjectName: {}"", name);
        instance = server.registerMBean(obj, name);
    }
    // need to use the name returned from the server as some JEE servers may modify the name
    if (instance != null) {
        ObjectName registeredName = instance.getObjectName();
        LOG.debug(""Registered MBean with ObjectName: {}"", registeredName);
        mbeansRegistered.add(registeredName);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5215_033eb6fe,Minor,camel-core/src/main/java/org/apache/camel/component/file/FileBinding.java,54,62,"public void loadContent(Exchange exchange, GenericFile<?> file) throws IOException {
    if (content == null) {
        try {
            content = exchange.getContext().getTypeConverter().mandatoryConvertTo(byte[].class, file.getFile());
        } catch (NoTypeConversionAvailableException e) {
            throw new IOException(""Cannot load file content: "" + file.getAbsoluteFilePath(), e);
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5215_033eb6fe,Minor,camel-core/src/main/java/org/apache/camel/component/file/FileOperations.java,154,219,"public boolean storeFile(String fileName, Exchange exchange) throws GenericFileOperationFailedException {
    ObjectHelper.notNull(endpoint, ""endpoint"");
    File file = new File(fileName);
    // if an existing file already exists what should we do?
    if (file.exists()) {
        if (endpoint.getFileExist() == GenericFileExist.Ignore) {
            // ignore but indicate that the file was written
            LOG.trace(""An existing file already exists: {}. Ignore and do not override it."", file);
            return true;
        } else if (endpoint.getFileExist() == GenericFileExist.Fail) {
            throw new GenericFileOperationFailedException(""File already exist: "" + file + "". Cannot write new file."");
        }
    }
    // 3. write stream to file
    try {
        // is the body file based
        File source = null;
        // get the File Object from in message
        source = exchange.getIn().getBody(File.class);
        if (source != null) {
            // okay we know the body is a file type
            // so try to see if we can optimize by renaming the local work path file instead of doing
            // a full file to file copy, as the local work copy is to be deleted afterwards anyway
            // local work path
            File local = exchange.getIn().getHeader(Exchange.FILE_LOCAL_WORK_PATH, File.class);
            if (local != null && local.exists()) {
                boolean renamed = writeFileByLocalWorkPath(local, file);
                if (renamed) {
                    // try to keep last modified timestamp if configured to do so
                    keepLastModified(exchange, file);
                    // clear header as we have renamed the file
                    exchange.getIn().setHeader(Exchange.FILE_LOCAL_WORK_PATH, null);
                    // to the target.
                    return true;
                }
            } else if (source.exists()) {
                // no there is no local work file so use file to file copy if the source exists
                writeFileByFile(source, file);
                // try to keep last modified timestamp if configured to do so
                keepLastModified(exchange, file);
                return true;
            }
        }
        // fallback and use stream based
        InputStream in = exchange.getIn().getMandatoryBody(InputStream.class);
        writeFileByStream(in, file);
        // try to keep last modified timestamp if configured to do so
        keepLastModified(exchange, file);
        return true;
    } catch (IOException e) {
        throw new GenericFileOperationFailedException(""Cannot store file: "" + file, e);
    } catch (InvalidPayloadException e) {
        throw new GenericFileOperationFailedException(""Cannot store file: "" + file, e);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5215_033eb6fe,Minor,camel-core/src/main/java/org/apache/camel/component/file/GenericFileConverter.java,66,80,"@Converter
public static InputStream genericFileToInputStream(GenericFile<?> file, Exchange exchange) throws IOException {
    if (exchange != null) {
        // use a file input stream if its a java.io.File
        if (file.getFile() instanceof java.io.File) {
            return IOHelper.buffered(new FileInputStream((File) file.getFile()));
        }
        // otherwise ensure the body is loaded as we want the input stream of the body
        file.getBinding().loadContent(exchange, file);
        return exchange.getContext().getTypeConverter().convertTo(InputStream.class, exchange, file.getBody());
    } else {
        // should revert to fallback converter if we don't have an exchange
        return null;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5215_033eb6fe,Minor,camel-core/src/main/java/org/apache/camel/component/file/GenericFileProducer.java,61,85,"public void process(Exchange exchange) throws Exception {
    endpoint.configureExchange(exchange);
    String target = createFileName(exchange);
    // use lock for same file name to avoid concurrent writes to the same file
    // for example when you concurrently append to the same file
    Lock lock;
    synchronized (locks) {
        lock = locks.get(target);
        if (lock == null) {
            lock = new ReentrantLock();
            locks.put(target, lock);
        }
    }
    lock.lock();
    try {
        processExchange(exchange, target);
    } finally {
        // do not remove as the locks cache has an upper bound
        // this ensure the locks is appropriate reused
        lock.unlock();
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5215_033eb6fe,Minor,camel-core/src/main/java/org/apache/camel/converter/IOConverter.java,102,105,"/**
 * @deprecated will be removed in Camel 3.0. Use the method which has 2 parameters.
 */
@Deprecated
public static BufferedWriter toWriter(File file) throws IOException {
    return toWriter(file, null);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5215_033eb6fe,Minor,camel-core/src/main/java/org/apache/camel/converter/IOConverter.java,107,110,"@Converter
public static BufferedWriter toWriter(File file, Exchange exchange) throws IOException {
    return IOHelper.buffered(new EncodingFileWriter(file, IOHelper.getCharsetName(exchange)));
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5224_2db5570f,Major,camel-core/src/main/java/org/apache/camel/component/file/GenericFileOnCompletion.java,105,137,"/**
 * Strategy when the file was processed and a commit should be executed.
 *
 * @param processStrategy the strategy to perform the commit
 * @param exchange        the exchange
 * @param file            the file processed
 */
protected void processStrategyCommit(GenericFileProcessStrategy<T> processStrategy, Exchange exchange, GenericFile<T> file) {
    if (endpoint.isIdempotent()) {
        // only add to idempotent repository if we could process the file
        endpoint.getIdempotentRepository().add(absoluteFileName);
    }
    // delete done file if used
    if (endpoint.getDoneFileName() != null) {
        // done file must be in same path as the original input file
        String doneFileName = endpoint.createDoneFileName(absoluteFileName);
        ObjectHelper.notEmpty(doneFileName, ""doneFileName"", endpoint);
        try {
            // delete done file
            boolean deleted = operations.deleteFile(doneFileName);
            log.trace(""Done file: {} was deleted: {}"", doneFileName, deleted);
            if (!deleted) {
                log.warn(""Done file: "" + doneFileName + "" could not be deleted"");
            }
        } catch (Exception e) {
            handleException(e);
        }
    }
    try {
        log.trace(""Commit file strategy: {} for file: {}"", processStrategy, file);
        processStrategy.commit(operations, endpoint, exchange, file);
    } catch (Exception e) {
        handleException(e);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5261_55c2e2d8,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaComponent.java,56,85,"public synchronized BlockingQueue<Exchange> createQueue(String uri, Map<String, Object> parameters) {
    String key = getQueueKey(uri);
    QueueReference ref = getQueues().get(key);
    if (ref != null) {
        // add the reference before returning queue
        ref.addReference();
        return ref.getQueue();
    }
    // create queue
    BlockingQueue<Exchange> queue;
    Integer size = getAndRemoveParameter(parameters, ""size"", Integer.class);
    if (size != null && size > 0) {
        queue = new LinkedBlockingQueue<Exchange>(size);
    } else {
        if (getQueueSize() > 0) {
            queue = new LinkedBlockingQueue<Exchange>(getQueueSize());
        } else {
            queue = new LinkedBlockingQueue<Exchange>();
        }
    }
    // create and add a new reference queue
    ref = new QueueReference(queue);
    ref.addReference();
    getQueues().put(key, ref);
    return queue;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5261_55c2e2d8,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaComponent.java,91,102,"@Override
protected Endpoint createEndpoint(String uri, String remaining, Map<String, Object> parameters) throws Exception {
    int consumers = getAndRemoveParameter(parameters, ""concurrentConsumers"", Integer.class, defaultConcurrentConsumers);
    boolean limitConcurrentConsumers = getAndRemoveParameter(parameters, ""limitConcurrentConsumers"", Boolean.class, true);
    if (limitConcurrentConsumers && consumers > maxConcurrentConsumers) {
        throw new IllegalArgumentException(""The limitConcurrentConsumers flag in set to true. ConcurrentConsumers cannot be set at a value greater than "" + maxConcurrentConsumers + "" was "" + consumers);
    }
    SedaEndpoint answer = new SedaEndpoint(uri, this, createQueue(uri, parameters), consumers);
    answer.configureProperties(parameters);
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5261_55c2e2d8,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaEndpoint.java,95,104,"public synchronized BlockingQueue<Exchange> getQueue() {
    if (queue == null) {
        if (size > 0) {
            queue = new LinkedBlockingQueue<Exchange>(size);
        } else {
            queue = new LinkedBlockingQueue<Exchange>();
        }
    }
    return queue;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5261_55c2e2d8,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaEndpoint.java,355,367,"@Override
protected void doShutdown() throws Exception {
    // notify component we are shutting down this endpoint
    if (getComponent() != null) {
        getComponent().onShutdownEndpoint(this);
    }
    // shutdown thread pool if it was in use
    if (multicastExecutor != null) {
        getCamelContext().getExecutorServiceManager().shutdownNow(multicastExecutor);
        multicastExecutor = null;
    }
    super.doShutdown();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5357_4cf7e80e,Major,camel-core/src/main/java/org/apache/camel/util/UnsafeUriCharactersEncoder.java,52,83,"public static String encode(String s) {
    int n = s == null ? 0 : s.length();
    if (n == 0) {
        return s;
    }
    // First check whether we actually need to encode
    char[] chars = s.toCharArray();
    for (int i = 0; ; ) {
        // just deal with the ascii character
        if (chars[i] > 0 && chars[i] < 128) {
            if (unsafeCharacters.get(chars[i])) {
                break;
            }
        }
        if (++i >= chars.length) {
            return s;
        }
    }
    // okay there are some unsafe characters so we do need to encode
    StringBuilder sb = new StringBuilder();
    for (char ch : chars) {
        if (ch > 0 && ch < 128 && unsafeCharacters.get(ch)) {
            appendEscape(sb, (byte) ch);
        } else {
            sb.append(ch);
        }
    }
    return sb.toString();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5432_93935780,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaEndpoint.java,87,89,"public Producer createProducer() throws Exception {
    return new SedaProducer(this, getQueue(), getWaitForTaskToComplete(), getTimeout(), isBlockWhenFull());
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5432_93935780,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaProducer.java,59,155,"@Override
public boolean process(final Exchange exchange, final AsyncCallback callback) {
    WaitForTaskToComplete wait = waitForTaskToComplete;
    if (exchange.getProperty(Exchange.ASYNC_WAIT) != null) {
        wait = exchange.getProperty(Exchange.ASYNC_WAIT, WaitForTaskToComplete.class);
    }
    if (wait == WaitForTaskToComplete.Always || (wait == WaitForTaskToComplete.IfReplyExpected && ExchangeHelper.isOutCapable(exchange))) {
        // do not handover the completion as we wait for the copy to complete, and copy its result back when it done
        Exchange copy = prepareCopy(exchange, false);
        // latch that waits until we are complete
        final CountDownLatch latch = new CountDownLatch(1);
        // we should wait for the reply so install a on completion so we know when its complete
        copy.addOnCompletion(new SynchronizationAdapter() {

            @Override
            public void onDone(Exchange response) {
                // check for timeout, which then already would have invoked the latch
                if (latch.getCount() == 0) {
                    if (log.isTraceEnabled()) {
                        log.trace(""{}. Timeout occurred so response will be ignored: {}"", this, response.hasOut() ? response.getOut() : response.getIn());
                    }
                    return;
                } else {
                    if (log.isTraceEnabled()) {
                        log.trace(""{} with response: {}"", this, response.hasOut() ? response.getOut() : response.getIn());
                    }
                    try {
                        ExchangeHelper.copyResults(exchange, response);
                    } finally {
                        // always ensure latch is triggered
                        latch.countDown();
                    }
                }
            }

            @Override
            public boolean allowHandover() {
                // at this point in the routing (at this leg), instead of at the very last (this ensure timeout is honored)
                return false;
            }

            @Override
            public String toString() {
                return ""onDone at endpoint: "" + endpoint;
            }
        });
        log.trace(""Adding Exchange to queue: {}"", copy);
        addToQueue(copy);
        if (timeout > 0) {
            if (log.isTraceEnabled()) {
                log.trace(""Waiting for task to complete using timeout (ms): {} at [{}]"", timeout, endpoint.getEndpointUri());
            }
            // lets see if we can get the task done before the timeout
            boolean done = false;
            try {
                done = latch.await(timeout, TimeUnit.MILLISECONDS);
            } catch (InterruptedException e) {
            // ignore
            }
            if (!done) {
                exchange.setException(new ExchangeTimedOutException(exchange, timeout));
                // remove timed out Exchange from queue
                queue.remove(copy);
                // count down to indicate timeout
                latch.countDown();
            }
        } else {
            if (log.isTraceEnabled()) {
                log.trace(""Waiting for task to complete (blocking) at [{}]"", endpoint.getEndpointUri());
            }
            // no timeout then wait until its done
            try {
                latch.await();
            } catch (InterruptedException e) {
            // ignore
            }
        }
    } else {
        // no wait, eg its a InOnly then just add to queue and return
        // handover the completion so its the copy which performs that, as we do not wait
        Exchange copy = prepareCopy(exchange, true);
        log.trace(""Adding Exchange to queue: {}"", copy);
        addToQueue(copy);
    }
    // we use OnCompletion on the Exchange to callback and wait for the Exchange to be done
    // so we should just signal the callback we are done synchronously
    callback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5432_93935780,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaProducer.java,185,196,"/**
 * Strategy method for adding the exchange to the queue.
 * <p>
 * Will perform a blocking ""put"" if blockWhenFull is true, otherwise it will
 * simply add which will throw exception if the queue is full
 *
 * @param exchange the exchange to add to the queue
 */
protected void addToQueue(Exchange exchange) {
    if (blockWhenFull) {
        try {
            queue.put(exchange);
        } catch (InterruptedException e) {
            // ignore
            log.debug(""Put interrupted, are we stopping? {}"", isStopping() || isStopped());
        }
    } else {
        queue.add(exchange);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5515_b3bb8670,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,1132,1137,"/**
 * Continues processing the {@link org.apache.camel.Exchange} using asynchronous routing engine.
 *
 * @param poolSize the core pool size
 * @return the builder
 */
public ThreadsDefinition threads(int poolSize) {
    ThreadsDefinition answer = threads();
    answer.setPoolSize(poolSize);
    addOutput(answer);
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5515_b3bb8670,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,1146,1152,"/**
 * Continues processing the {@link org.apache.camel.Exchange} using asynchronous routing engine.
 *
 * @param poolSize    the core pool size
 * @param maxPoolSize the maximum pool size
 * @return the builder
 */
public ThreadsDefinition threads(int poolSize, int maxPoolSize) {
    ThreadsDefinition answer = threads();
    answer.setPoolSize(poolSize);
    answer.setMaxPoolSize(maxPoolSize);
    addOutput(answer);
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5515_b3bb8670,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,1162,1169,"/**
 * Continues processing the {@link org.apache.camel.Exchange} using asynchronous routing engine.
 *
 * @param poolSize    the core pool size
 * @param maxPoolSize the maximum pool size
 * @param threadName the thread pool name
 * @return the builder
 */
public ThreadsDefinition threads(int poolSize, int maxPoolSize, String threadName) {
    ThreadsDefinition answer = threads();
    answer.setPoolSize(poolSize);
    answer.setMaxPoolSize(maxPoolSize);
    answer.setThreadName(threadName);
    addOutput(answer);
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5570_a57830ed,Minor,camel-core/src/main/java/org/apache/camel/model/OnExceptionDefinition.java,142,157,"/**
 * Allows an exception handler to create a new redelivery policy for this exception type
 *
 * @param context      the camel context
 * @param parentPolicy the current redelivery policy, is newer <tt>null</tt>
 * @return a newly created redelivery policy, or return the original policy if no customization is required
 *         for this exception handler.
 */
public RedeliveryPolicy createRedeliveryPolicy(CamelContext context, RedeliveryPolicy parentPolicy) {
    if (redeliveryPolicyRef != null) {
        return CamelContextHelper.mandatoryLookup(context, redeliveryPolicyRef, RedeliveryPolicy.class);
    } else if (redeliveryPolicy != null) {
        return redeliveryPolicy.createRedeliveryPolicy(context, parentPolicy);
    } else if (!outputs.isEmpty() && parentPolicy.getMaximumRedeliveries() > 0) {
        // if we have outputs, then do not inherit parent maximumRedeliveries
        // as you would have to explicit configure maximumRedeliveries on this onException to use it
        // this is the behavior Camel has always had
        RedeliveryPolicy answer = parentPolicy.copy();
        answer.setMaximumRedeliveries(0);
        return answer;
    } else {
        return parentPolicy;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5571_0e87b84f,Major,camel-core/src/main/java/org/apache/camel/component/bean/AbstractCamelInvocationHandler.java,70,107,"protected Object invokeWithbody(final Method method, Object body, final ExchangePattern pattern) throws InterruptedException, Throwable {
    final Exchange exchange = new DefaultExchange(endpoint, pattern);
    exchange.getIn().setBody(body);
    // is the return type a future
    final boolean isFuture = method.getReturnType() == Future.class;
    // create task to execute the proxy and gather the reply
    FutureTask<Object> task = new FutureTask<Object>(new Callable<Object>() {

        public Object call() throws Exception {
            // process the exchange
            LOG.trace(""Proxied method call {} invoking producer: {}"", method.getName(), producer);
            producer.process(exchange);
            Object answer = afterInvoke(method, exchange, pattern, isFuture);
            LOG.trace(""Proxied method call {} returning: {}"", method.getName(), answer);
            return answer;
        }
    });
    if (isFuture) {
        // submit task and return future
        if (LOG.isTraceEnabled()) {
            LOG.trace(""Submitting task for exchange id {}"", exchange.getExchangeId());
        }
        getExecutorService(exchange.getContext()).submit(task);
        return task;
    } else {
        // execute task now
        try {
            task.run();
            return task.get();
        } catch (ExecutionException e) {
            // we don't want the wrapped exception from JDK
            throw e.getCause();
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5571_0e87b84f,Major,camel-core/src/main/java/org/apache/camel/component/bean/CamelInvocationHandler.java,40,45,"public Object invoke(final Object proxy, final Method method, final Object[] args) throws Throwable {
    BeanInvocation invocation = new BeanInvocation(method, args);
    MethodInfo methodInfo = methodInfoCache.getMethodInfo(method);
    final ExchangePattern pattern = methodInfo != null ? methodInfo.getPattern() : ExchangePattern.InOut;
    return invokeWithbody(method, invocation, pattern);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5571_0e87b84f,Major,camel-core/src/main/java/org/apache/camel/component/bean/PojoMessageInvocationHandler.java,37,46,"public Object invoke(final Object proxy, final Method method, final Object[] args) throws Throwable {
    int argsLength = (args == null) ? 0 : args.length;
    if (argsLength != 1) {
        throw new RuntimeCamelException(String.format(""Error creating proxy for %s.%s Number of arguments must be 1 but is %d"", method.getDeclaringClass().getName(), method.getName(), argsLength));
    }
    final ExchangePattern pattern = method.getReturnType() != Void.TYPE ? ExchangePattern.InOut : ExchangePattern.InOnly;
    return invokeWithbody(method, args[0], pattern);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5644_15d0fd9b,Minor,camel-core/src/main/java/org/apache/camel/component/bean/BeanInfo.java,551,608,"private MethodInfo chooseBestPossibleMethodInfo(Exchange exchange, Collection<MethodInfo> operationList, Object body, List<MethodInfo> possibles, List<MethodInfo> possiblesWithException, List<MethodInfo> possibleWithCustomAnnotation) throws AmbiguousMethodCallException {
    Exception exception = ExpressionBuilder.exchangeExceptionExpression().evaluate(exchange, Exception.class);
    if (exception != null && possiblesWithException.size() == 1) {
        LOG.trace(""Exchange has exception set so we prefer method that also has exception as parameter"");
        // prefer the method that accepts exception in case we have an exception also
        return possiblesWithException.get(0);
    } else if (possibles.size() == 1) {
        return possibles.get(0);
    } else if (possibles.isEmpty()) {
        LOG.trace(""No possible methods so now trying to convert body to parameter types"");
        // let's try converting
        Object newBody = null;
        MethodInfo matched = null;
        int matchCounter = 0;
        for (MethodInfo methodInfo : operationList) {
            if (methodInfo.getBodyParameterType().isInstance(body)) {
                return methodInfo;
            }
            Object value = convertToType(exchange, methodInfo.getBodyParameterType(), body);
            if (value != null) {
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""Converted body from: {} to: {}"", body.getClass().getCanonicalName(), methodInfo.getBodyParameterType().getCanonicalName());
                }
                matchCounter++;
                newBody = value;
                matched = methodInfo;
            }
        }
        if (matchCounter > 1) {
            throw new AmbiguousMethodCallException(exchange, Arrays.asList(matched, matched));
        }
        if (matched != null) {
            LOG.trace(""Setting converted body: {}"", body);
            Message in = exchange.getIn();
            in.setBody(newBody);
            return matched;
        }
    } else {
        // if we only have a single method with custom annotations, let's use that one
        if (possibleWithCustomAnnotation.size() == 1) {
            MethodInfo answer = possibleWithCustomAnnotation.get(0);
            LOG.trace(""There are only one method with annotations so we choose it: {}"", answer);
            return answer;
        }
        // phew try to choose among multiple methods with annotations
        return chooseMethodWithCustomAnnotations(exchange, possibles);
    }
    // cannot find a good method to use
    return null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5681_78c73502,Major,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,199,241,"public boolean process(Exchange exchange, AsyncCallback callback) {
    final AtomicExchange result = new AtomicExchange();
    final Iterable<ProcessorExchangePair> pairs;
    // multicast uses fine grained error handling on the output processors
    // so use try .. catch to cater for this
    boolean exhaust = false;
    try {
        boolean sync = true;
        pairs = createProcessorExchangePairs(exchange);
        // after we have created the processors we consider the exchange as exhausted if an unhandled
        // exception was thrown, (used in the catch block)
        // if the processors is working in Streaming model, the exchange could not be processed at this point.
        exhaust = !isStreaming();
        if (isParallelProcessing()) {
            // ensure an executor is set when running in parallel
            ObjectHelper.notNull(executorService, ""executorService"", this);
            doProcessParallel(exchange, result, pairs, isStreaming(), callback);
        } else {
            sync = doProcessSequential(exchange, result, pairs, callback);
        }
        if (!sync) {
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return false;
        }
    } catch (Throwable e) {
        exchange.setException(e);
        // and do the done work
        doDone(exchange, null, callback, true, exhaust);
        return true;
    }
    // multicasting was processed successfully
    // and do the done work
    Exchange subExchange = result.get() != null ? result.get() : null;
    doDone(exchange, subExchange, callback, true, exhaust);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5681_78c73502,Major,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,243,344,"protected void doProcessParallel(final Exchange original, final AtomicExchange result, final Iterable<ProcessorExchangePair> pairs, final boolean streaming, final AsyncCallback callback) throws Exception {
    ObjectHelper.notNull(executorService, ""ExecutorService"", this);
    ObjectHelper.notNull(aggregateExecutorService, ""AggregateExecutorService"", this);
    final CompletionService<Exchange> completion;
    if (streaming) {
        // execute tasks in parallel+streaming and aggregate in the order they are finished (out of order sequence)
        completion = new ExecutorCompletionService<Exchange>(executorService);
    } else {
        // execute tasks in parallel and aggregate in the order the tasks are submitted (in order sequence)
        completion = new SubmitOrderedCompletionService<Exchange>(executorService);
    }
    final AtomicInteger total = new AtomicInteger(0);
    final Iterator<ProcessorExchangePair> it = pairs.iterator();
    if (it.hasNext()) {
        // when parallel then aggregate on the fly
        final AtomicBoolean running = new AtomicBoolean(true);
        final AtomicBoolean allTasksSubmitted = new AtomicBoolean();
        final CountDownLatch aggregationOnTheFlyDone = new CountDownLatch(1);
        final AtomicException executionException = new AtomicException();
        // issue task to execute in separate thread so it can aggregate on-the-fly
        // while we submit new tasks, and those tasks complete concurrently
        // this allows us to optimize work and reduce memory consumption
        final AggregateOnTheFlyTask aggregateOnTheFlyTask = new AggregateOnTheFlyTask(result, original, total, completion, running, aggregationOnTheFlyDone, allTasksSubmitted, executionException);
        final AtomicBoolean aggregationTaskSubmitted = new AtomicBoolean();
        LOG.trace(""Starting to submit parallel tasks"");
        while (it.hasNext()) {
            final ProcessorExchangePair pair = it.next();
            final Exchange subExchange = pair.getExchange();
            updateNewExchange(subExchange, total.intValue(), pairs, it);
            completion.submit(new Callable<Exchange>() {

                public Exchange call() throws Exception {
                    // the aggregation task to early and pile up too many threads
                    if (aggregationTaskSubmitted.compareAndSet(false, true)) {
                        // but only submit the task once
                        aggregateExecutorService.submit(aggregateOnTheFlyTask);
                    }
                    if (!running.get()) {
                        // do not start processing the task if we are not running
                        return subExchange;
                    }
                    try {
                        doProcessParallel(pair);
                    } catch (Throwable e) {
                        subExchange.setException(e);
                    }
                    // Decide whether to continue with the multicast or not; similar logic to the Pipeline
                    Integer number = getExchangeIndex(subExchange);
                    boolean continueProcessing = PipelineHelper.continueProcessing(subExchange, ""Parallel processing failed for number "" + number, LOG);
                    if (stopOnException && !continueProcessing) {
                        // signal to stop running
                        running.set(false);
                        // throw caused exception
                        if (subExchange.getException() != null) {
                            // wrap in exception to explain where it failed
                            throw new CamelExchangeException(""Parallel processing failed for number "" + number, subExchange, subExchange.getException());
                        }
                    }
                    LOG.trace(""Parallel processing complete for exchange: {}"", subExchange);
                    return subExchange;
                }
            });
            total.incrementAndGet();
        }
        // signal all tasks has been submitted
        LOG.trace(""Signaling that all {} tasks has been submitted."", total.get());
        allTasksSubmitted.set(true);
        // its to hard to do parallel async routing so we let the caller thread be synchronously
        // and have it pickup the replies and do the aggregation (eg we use a latch to wait)
        // wait for aggregation to be done
        LOG.debug(""Waiting for on-the-fly aggregation to complete aggregating {} responses for exchangeId: {}"", total.get(), original.getExchangeId());
        aggregationOnTheFlyDone.await();
        // did we fail for whatever reason, if so throw that caused exception
        if (executionException.get() != null) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(""Parallel processing failed due {}"", executionException.get().getMessage());
            }
            throw executionException.get();
        }
    }
    // no everything is okay so we are done
    LOG.debug(""Done parallel processing {} exchanges"", total);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5681_78c73502,Major,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,283,317,"public Exchange call() throws Exception {
    // the aggregation task to early and pile up too many threads
    if (aggregationTaskSubmitted.compareAndSet(false, true)) {
        // but only submit the task once
        aggregateExecutorService.submit(aggregateOnTheFlyTask);
    }
    if (!running.get()) {
        // do not start processing the task if we are not running
        return subExchange;
    }
    try {
        doProcessParallel(pair);
    } catch (Throwable e) {
        subExchange.setException(e);
    }
    // Decide whether to continue with the multicast or not; similar logic to the Pipeline
    Integer number = getExchangeIndex(subExchange);
    boolean continueProcessing = PipelineHelper.continueProcessing(subExchange, ""Parallel processing failed for number "" + number, LOG);
    if (stopOnException && !continueProcessing) {
        // signal to stop running
        running.set(false);
        // throw caused exception
        if (subExchange.getException() != null) {
            // wrap in exception to explain where it failed
            throw new CamelExchangeException(""Parallel processing failed for number "" + number, subExchange, subExchange.getException());
        }
    }
    LOG.trace(""Parallel processing complete for exchange: {}"", subExchange);
    return subExchange;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5681_78c73502,Major,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,501,549,"protected boolean doProcessSequential(Exchange original, AtomicExchange result, Iterable<ProcessorExchangePair> pairs, AsyncCallback callback) throws Exception {
    AtomicInteger total = new AtomicInteger();
    Iterator<ProcessorExchangePair> it = pairs.iterator();
    while (it.hasNext()) {
        ProcessorExchangePair pair = it.next();
        Exchange subExchange = pair.getExchange();
        updateNewExchange(subExchange, total.get(), pairs, it);
        boolean sync = doProcessSequential(original, result, pairs, it, pair, callback, total);
        if (!sync) {
            if (LOG.isTraceEnabled()) {
                LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", pair.getExchange().getExchangeId());
            }
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return false;
        }
        if (LOG.isTraceEnabled()) {
            LOG.trace(""Processing exchangeId: {} is continued being processed synchronously"", pair.getExchange().getExchangeId());
        }
        // Decide whether to continue with the multicast or not; similar logic to the Pipeline
        // remember to test for stop on exception and aggregate before copying back results
        boolean continueProcessing = PipelineHelper.continueProcessing(subExchange, ""Sequential processing failed for number "" + total.get(), LOG);
        if (stopOnException && !continueProcessing) {
            if (subExchange.getException() != null) {
                // wrap in exception to explain where it failed
                throw new CamelExchangeException(""Sequential processing failed for number "" + total.get(), subExchange, subExchange.getException());
            } else {
                // we want to stop on exception, and the exception was handled by the error handler
                // this is similar to what the pipeline does, so we should do the same to not surprise end users
                // so we should set the failed exchange as the result and be done
                result.set(subExchange);
                return true;
            }
        }
        LOG.trace(""Sequential processing complete for number {} exchange: {}"", total, subExchange);
        doAggregate(getAggregationStrategy(subExchange), result, subExchange);
        total.incrementAndGet();
    }
    LOG.debug(""Done sequential processing {} exchanges"", total);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5681_78c73502,Major,camel-core/src/main/java/org/apache/camel/processor/TryProcessor.java,350,406,"@Override
protected boolean processNext(final Exchange exchange, final AsyncCallback callback) {
    final Exception caught = exchange.getException();
    if (caught == null) {
        return true;
    }
    // store the last to endpoint as the failure endpoint
    if (exchange.getProperty(Exchange.FAILURE_ENDPOINT) == null) {
        exchange.setProperty(Exchange.FAILURE_ENDPOINT, exchange.getProperty(Exchange.TO_ENDPOINT));
    }
    // give the rest of the pipeline another chance
    exchange.setProperty(Exchange.EXCEPTION_CAUGHT, caught);
    exchange.setException(null);
    // is the exception handled by the catch clause
    final Boolean handled = catchClause.handles(exchange);
    if (LOG.isDebugEnabled()) {
        LOG.debug(""The exception is handled: {} for the exception: {} caused by: {}"", new Object[] { handled, caught.getClass().getName(), caught.getMessage() });
    }
    boolean sync = super.processNext(exchange, new AsyncCallback() {

        public void done(boolean doneSync) {
            // we only have to handle async completion of the pipeline
            if (doneSync) {
                return;
            }
            if (!handled) {
                if (exchange.getException() == null) {
                    exchange.setException(exchange.getProperty(Exchange.EXCEPTION_CAUGHT, Exception.class));
                }
            }
            // always clear redelivery exhausted in a catch clause
            exchange.removeProperty(Exchange.REDELIVERY_EXHAUSTED);
            // signal callback to continue routing async
            ExchangeHelper.prepareOutToIn(exchange);
            callback.done(false);
        }
    });
    if (sync) {
        // set exception back on exchange
        if (!handled) {
            if (exchange.getException() == null) {
                exchange.setException(exchange.getProperty(Exchange.EXCEPTION_CAUGHT, Exception.class));
            }
        }
        // always clear redelivery exhausted in a catch clause
        exchange.removeProperty(Exchange.REDELIVERY_EXHAUSTED);
    }
    return sync;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5683_0c3c7d1b,Major,camel-core/src/main/java/org/apache/camel/impl/ConsumerCache.java,68,71,"/**
 * Creates the {@link LRUCache} to be used.
 * <p/>
 * This implementation returns a {@link org.apache.camel.util.LRUSoftCache} instance.
 *
 * @param cacheSize the cache size
 * @return the cache
 */
protected static LRUCache<String, PollingConsumer> createLRUCache(int cacheSize) {
    // We use a soft reference cache to allow the JVM to re-claim memory if it runs low on memory.
    return new LRUSoftCache<String, PollingConsumer>(cacheSize);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5683_0c3c7d1b,Major,camel-core/src/main/java/org/apache/camel/impl/ProducerCache.java,86,89,"/**
 * Creates the {@link LRUCache} to be used.
 * <p/>
 * This implementation returns a {@link LRUSoftCache} instance.
 *
 * @param cacheSize the cache size
 * @return the cache
 */
protected static LRUCache<String, Producer> createLRUCache(int cacheSize) {
    // We use a soft reference cache to allow the JVM to re-claim memory if it runs low on memory.
    return new LRUSoftCache<String, Producer>(cacheSize);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5699_6d63a502,Minor,camel-core/src/main/java/org/apache/camel/component/log/LogFormatter.java,53,176,"public String format(Exchange exchange) {
    Message in = exchange.getIn();
    StringBuilder sb = new StringBuilder();
    if (showAll || showExchangeId) {
        if (multiline) {
            sb.append(LS);
        }
        sb.append("", Id:"").append(exchange.getExchangeId());
    }
    if (showAll || showExchangePattern) {
        if (multiline) {
            sb.append(LS);
        }
        sb.append("", ExchangePattern:"").append(exchange.getPattern());
    }
    if (showAll || showProperties) {
        if (multiline) {
            sb.append(LS);
        }
        sb.append("", Properties:"").append(exchange.getProperties());
    }
    if (showAll || showHeaders) {
        if (multiline) {
            sb.append(LS);
        }
        sb.append("", Headers:"").append(in.getHeaders());
    }
    if (showAll || showBodyType) {
        if (multiline) {
            sb.append(LS);
        }
        sb.append("", BodyType:"").append(getBodyTypeAsString(in));
    }
    if (showAll || showBody) {
        if (multiline) {
            sb.append(LS);
        }
        sb.append("", Body:"").append(getBodyAsString(in));
    }
    if (showAll || showException || showCaughtException) {
        // try exception on exchange first
        Exception exception = exchange.getException();
        boolean caught = false;
        if ((showAll || showCaughtException) && exception == null) {
            // fallback to caught exception
            exception = exchange.getProperty(Exchange.EXCEPTION_CAUGHT, Exception.class);
            caught = true;
        }
        if (exception != null) {
            if (multiline) {
                sb.append(LS);
            }
            if (caught) {
                sb.append("", CaughtExceptionType:"").append(exception.getClass().getCanonicalName());
                sb.append("", CaughtExceptionMessage:"").append(exception.getMessage());
            } else {
                sb.append("", ExceptionType:"").append(exception.getClass().getCanonicalName());
                sb.append("", ExceptionMessage:"").append(exception.getMessage());
            }
            if (showAll || showStackTrace) {
                StringWriter sw = new StringWriter();
                exception.printStackTrace(new PrintWriter(sw));
                sb.append("", StackTrace:"").append(sw.toString());
            }
        }
    }
    if (showAll || showOut) {
        if (exchange.hasOut()) {
            Message out = exchange.getOut();
            if (showAll || showHeaders) {
                if (multiline) {
                    sb.append(LS);
                }
                sb.append("", OutHeaders:"").append(out.getHeaders());
            }
            if (showAll || showBodyType) {
                if (multiline) {
                    sb.append(LS);
                }
                sb.append("", OutBodyType:"").append(getBodyTypeAsString(out));
            }
            if (showAll || showBody) {
                if (multiline) {
                    sb.append(LS);
                }
                sb.append("", OutBody:"").append(getBodyAsString(out));
            }
        } else {
            if (multiline) {
                sb.append(LS);
            }
            sb.append("", Out: null"");
        }
    }
    if (maxChars > 0) {
        StringBuilder answer = new StringBuilder();
        for (String s : sb.toString().split(LS)) {
            if (s != null) {
                if (s.length() > maxChars) {
                    s = s.substring(0, maxChars);
                    answer.append(s).append(""..."");
                } else {
                    answer.append(s);
                }
                if (multiline) {
                    answer.append(LS);
                }
            }
        }
        // get rid of the leading space comma if needed
        return ""Exchange["" + (multiline ? answer.append(']').toString() : answer.toString().substring(2) + ""]"");
    }
    // get rid of the leading space comma if needed
    return ""Exchange["" + (multiline ? sb.append(']').toString() : sb.toString().substring(2) + ""]"");
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5704_708e756d,Major,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,1000,1010,"/**
 * Sets the given {@link org.apache.camel.processor.aggregate.AggregationStrategy} on the {@link Exchange}.
 *
 * @param exchange            the exchange
 * @param aggregationStrategy the strategy
 */
protected void setAggregationStrategyOnExchange(Exchange exchange, AggregationStrategy aggregationStrategy) {
    Map<?, ?> property = exchange.getProperty(Exchange.AGGREGATION_STRATEGY, Map.class);
    Map<Object, AggregationStrategy> map = CastUtils.cast(property);
    if (map == null) {
        map = new HashMap<Object, AggregationStrategy>();
    }
    // store the strategy using this processor as the key
    // (so we can store multiple strategies on the same exchange)
    map.put(this, aggregationStrategy);
    exchange.setProperty(Exchange.AGGREGATION_STRATEGY, map);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5707_3f70d612,Minor,camel-core/src/main/java/org/apache/camel/builder/NotifyBuilder.java,429,477,"/**
 * Sets a condition when tne <tt>n'th</tt> (by index) {@link Exchange} is done being processed.
 * <p/>
 * The difference between <i>done</i> and <i>completed</i> is that done can also include failed
 * messages, where as completed is only successful processed messages.
 *
 * @param index the message by index to be done
 * @return the builder
 */
public NotifyBuilder whenDoneByIndex(final int index) {
    stack.add(new EventPredicateSupport() {

        private AtomicInteger current = new AtomicInteger();

        private String id;

        private AtomicBoolean done = new AtomicBoolean();

        @Override
        public boolean onExchangeCreated(Exchange exchange) {
            if (current.get() == index) {
                id = exchange.getExchangeId();
            }
            current.incrementAndGet();
            return true;
        }

        @Override
        public boolean onExchangeCompleted(Exchange exchange) {
            if (exchange.getExchangeId().equals(id)) {
                done.set(false);
            }
            return true;
        }

        @Override
        public boolean onExchangeFailed(Exchange exchange) {
            if (exchange.getExchangeId().equals(id)) {
                done.set(true);
            }
            return true;
        }

        public boolean matches() {
            return done.get();
        }

        @Override
        public void reset() {
            current.set(0);
            id = null;
            done.set(false);
        }

        @Override
        public String toString() {
            return ""whenDoneByIndex("" + index + "")"";
        }
    });
    return this;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5707_3f70d612,Minor,camel-core/src/main/java/org/apache/camel/builder/NotifyBuilder.java,444,450,"@Override
public boolean onExchangeCompleted(Exchange exchange) {
    if (exchange.getExchangeId().equals(id)) {
        done.set(false);
    }
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5720_4a05eccf,Minor,camel-core/src/main/java/org/apache/camel/processor/aggregate/AggregateProcessor.java,302,362,"/**
 * Tests whether the given exchange is complete or not
 *
 * @param key      the correlation key
 * @param exchange the incoming exchange
 * @return <tt>null</tt> if not completed, otherwise a String with the type that triggered the completion
 */
protected String isCompleted(String key, Exchange exchange) {
    if (getCompletionPredicate() != null) {
        boolean answer = getCompletionPredicate().matches(exchange);
        if (answer) {
            return ""predicate"";
        }
    }
    if (getCompletionSizeExpression() != null) {
        Integer value = getCompletionSizeExpression().evaluate(exchange, Integer.class);
        if (value != null && value > 0) {
            int size = exchange.getProperty(Exchange.AGGREGATED_SIZE, 1, Integer.class);
            if (size >= value) {
                return ""size"";
            }
        }
    }
    if (getCompletionSize() > 0) {
        int size = exchange.getProperty(Exchange.AGGREGATED_SIZE, 1, Integer.class);
        if (size >= getCompletionSize()) {
            return ""size"";
        }
    }
    // timeout can be either evaluated based on an expression or from a fixed value
    // expression takes precedence
    boolean timeoutSet = false;
    if (getCompletionTimeoutExpression() != null) {
        Long value = getCompletionTimeoutExpression().evaluate(exchange, Long.class);
        if (value != null && value > 0) {
            if (LOG.isTraceEnabled()) {
                LOG.trace(""Updating correlation key {} to timeout after {} ms. as exchange received: {}"", new Object[] { key, value, exchange });
            }
            addExchangeToTimeoutMap(key, exchange, value);
            timeoutSet = true;
        }
    }
    if (!timeoutSet && getCompletionTimeout() > 0) {
        // timeout is used so use the timeout map to keep an eye on this
        if (LOG.isTraceEnabled()) {
            LOG.trace(""Updating correlation key {} to timeout after {} ms. as exchange received: {}"", new Object[] { key, getCompletionTimeout(), exchange });
        }
        addExchangeToTimeoutMap(key, exchange, getCompletionTimeout());
    }
    if (isCompletionFromBatchConsumer()) {
        batchConsumerCorrelationKeys.add(key);
        batchConsumerCounter.incrementAndGet();
        int size = exchange.getProperty(Exchange.BATCH_SIZE, 0, Integer.class);
        if (size > 0 && batchConsumerCounter.intValue() >= size) {
            // batch consumer is complete then reset the counter
            batchConsumerCounter.set(0);
            return ""consumer"";
        }
    }
    // not complete
    return null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5796_de6dd425,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,366,402,"protected Processor createOutputsProcessor(RouteContext routeContext, Collection<ProcessorDefinition<?>> outputs) throws Exception {
    List<Processor> list = new ArrayList<Processor>();
    for (ProcessorDefinition<?> output : outputs) {
        // resolve properties before we create the processor
        resolvePropertyPlaceholders(routeContext, output);
        Processor processor = null;
        // at first use custom factory
        if (routeContext.getCamelContext().getProcessorFactory() != null) {
            processor = routeContext.getCamelContext().getProcessorFactory().createProcessor(routeContext, output);
        }
        // fallback to default implementation if factory did not create the processor
        if (processor == null) {
            processor = output.createProcessor(routeContext);
        }
        if (output instanceof Channel && processor == null) {
            continue;
        }
        Processor channel = wrapChannel(routeContext, processor, output);
        list.add(channel);
    }
    // if more than one output wrap than in a composite processor else just keep it as is
    Processor processor = null;
    if (!list.isEmpty()) {
        if (list.size() == 1) {
            processor = list.get(0);
        } else {
            processor = createCompositeProcessor(routeContext, list);
        }
    }
    return processor;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5796_de6dd425,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,461,526,"/**
 * Inspects the given definition and resolves any property placeholders from its properties.
 * <p/>
 * This implementation will check all the getter/setter pairs on this instance and for all the values
 * (which is a String type) will be property placeholder resolved.
 *
 * @param routeContext the route context
 * @param definition   the definition
 * @throws Exception is thrown if property placeholders was used and there was an error resolving them
 * @see org.apache.camel.CamelContext#resolvePropertyPlaceholders(String)
 * @see org.apache.camel.component.properties.PropertiesComponent
 */
protected void resolvePropertyPlaceholders(RouteContext routeContext, Object definition) throws Exception {
    log.trace(""Resolving property placeholders for: {}"", definition);
    // find all getter/setter which we can use for property placeholders
    Map<String, Object> properties = new HashMap<String, Object>();
    IntrospectionSupport.getProperties(definition, properties, null);
    ProcessorDefinition<?> processorDefinition = null;
    if (definition instanceof ProcessorDefinition) {
        processorDefinition = (ProcessorDefinition<?>) definition;
    }
    // and when the definition parameter is this (otherAttributes belong to this)
    if (processorDefinition != null && processorDefinition.getOtherAttributes() != null) {
        for (Object key : processorDefinition.getOtherAttributes().keySet()) {
            QName qname = (QName) key;
            if (Constants.PLACEHOLDER_QNAME.equals(qname.getNamespaceURI())) {
                String local = qname.getLocalPart();
                Object value = processorDefinition.getOtherAttributes().get(key);
                if (value != null && value instanceof String) {
                    // value must be enclosed with placeholder tokens
                    String s = (String) value;
                    String prefixToken = routeContext.getCamelContext().getPropertyPrefixToken();
                    String suffixToken = routeContext.getCamelContext().getPropertySuffixToken();
                    if (prefixToken == null) {
                        throw new IllegalArgumentException(""Property with name ["" + local + ""] uses property placeholders; however, no properties component is configured."");
                    }
                    if (!s.startsWith(prefixToken)) {
                        s = prefixToken + s;
                    }
                    if (!s.endsWith(suffixToken)) {
                        s = s + suffixToken;
                    }
                    value = s;
                }
                properties.put(local, value);
            }
        }
    }
    if (!properties.isEmpty()) {
        log.trace(""There are {} properties on: {}"", properties.size(), definition);
        // lookup and resolve properties for String based properties
        for (Map.Entry<String, Object> entry : properties.entrySet()) {
            // the name is always a String
            String name = entry.getKey();
            Object value = entry.getValue();
            if (value instanceof String) {
                // value must be a String, as a String is the key for a property placeholder
                String text = (String) value;
                text = routeContext.getCamelContext().resolvePropertyPlaceholders(text);
                if (text != value) {
                    // invoke setter as the text has changed
                    boolean changed = IntrospectionSupport.setProperty(routeContext.getCamelContext().getTypeConverter(), definition, name, text);
                    if (!changed) {
                        throw new IllegalArgumentException(""No setter to set property: "" + name + "" to: "" + text + "" on: "" + definition);
                    }
                    if (log.isDebugEnabled()) {
                        log.debug(""Changed property [{}] from: {} to: {}"", new Object[] { name, value, text });
                    }
                }
            }
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5826_a04674f2,Major,camel-core/src/main/java/org/apache/camel/support/TokenXMLPairExpressionIterator.java,106,142,"@Override
String getNext(boolean first) {
    String next = scanner.next();
    if (next == null) {
        return null;
    }
    // initialize inherited namespaces on first
    if (first && inheritNamespaceToken != null) {
        rootTokenNamespaces = getNamespacesFromNamespaceToken(next);
    }
    // make sure next is positioned at start token as we can have leading data
    // or we reached EOL and there is no more start tags
    Matcher matcher = startTokenPattern.matcher(next);
    if (!matcher.find()) {
        return null;
    } else {
        int index = matcher.start();
        next = next.substring(index);
    }
    // build answer accordingly to whether namespaces should be inherited or not
    StringBuilder sb = new StringBuilder();
    if (inheritNamespaceToken != null && rootTokenNamespaces != null) {
        // append root namespaces to local start token
        String tag = ObjectHelper.before(next, "">"");
        // grab the text
        String text = ObjectHelper.after(next, "">"");
        // build result with inherited namespaces
        next = sb.append(tag).append(rootTokenNamespaces).append("">"").append(text).append(endToken).toString();
    } else {
        next = sb.append(next).append(endToken).toString();
    }
    return next;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-5844_e775071b,Minor,camel-core/src/main/java/org/apache/camel/processor/WrapProcessor.java,42,44,"public String getTraceLabel() {
    return ""wrap["" + wrapped + ""]"";
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6447_020c451a,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,1297,1313,"/**
 * Ends the current block and returns back to the {@link ChoiceDefinition choice()} DSL.
 *
 * @return the builder
 */
public ChoiceDefinition endChoice() {
    // are we already a choice?
    ProcessorDefinition<?> def = this;
    if (def instanceof ChoiceDefinition) {
        return (ChoiceDefinition) def;
    }
    // okay end this and get back to the choice
    def = end();
    if (def instanceof WhenDefinition) {
        return (ChoiceDefinition) def.getParent();
    } else if (def instanceof OtherwiseDefinition) {
        return (ChoiceDefinition) def.getParent();
    } else {
        return (ChoiceDefinition) def;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6447_020c451a,Major,camel-core/src/main/java/org/apache/camel/processor/ChoiceProcessor.java,59,90,"public boolean process(Exchange exchange, AsyncCallback callback) {
    Iterator<Processor> processors = next().iterator();
    exchange.setProperty(Exchange.FILTER_MATCHED, false);
    while (continueRouting(processors, exchange)) {
        // get the next processor
        Processor processor = processors.next();
        AsyncProcessor async = AsyncProcessorConverterHelper.convert(processor);
        boolean sync = process(exchange, callback, processors, async);
        // continue as long its being processed synchronously
        if (!sync) {
            LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", exchange.getExchangeId());
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return false;
        }
        LOG.trace(""Processing exchangeId: {} is continued being processed synchronously"", exchange.getExchangeId());
        // check for error if so we should break out
        if (!continueProcessing(exchange, ""so breaking out of content based router"", LOG)) {
            break;
        }
    }
    LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
    callback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6447_020c451a,Major,camel-core/src/main/java/org/apache/camel/processor/ChoiceProcessor.java,92,106,"protected boolean continueRouting(Iterator<Processor> it, Exchange exchange) {
    boolean answer = it.hasNext();
    if (answer) {
        Object matched = exchange.getProperty(Exchange.FILTER_MATCHED);
        if (matched != null) {
            boolean hasMatched = exchange.getContext().getTypeConverter().convertTo(Boolean.class, matched);
            if (hasMatched) {
                LOG.debug(""ExchangeId: {} has been matched: {}"", exchange.getExchangeId(), exchange);
                answer = false;
            }
        }
    }
    LOG.trace(""ExchangeId: {} should continue matching: {}"", exchange.getExchangeId(), answer);
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6447_020c451a,Major,camel-core/src/main/java/org/apache/camel/processor/ChoiceProcessor.java,108,144,"private boolean process(final Exchange exchange, final AsyncCallback callback, final Iterator<Processor> processors, final AsyncProcessor asyncProcessor) {
    // this does the actual processing so log at trace level
    LOG.trace(""Processing exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
    // implement asynchronous routing logic in callback so we can have the callback being
    // triggered and then continue routing where we left
    boolean sync = asyncProcessor.process(exchange, new AsyncCallback() {

        public void done(boolean doneSync) {
            // we only have to handle async completion of the pipeline
            if (doneSync) {
                return;
            }
            // continue processing the pipeline asynchronously
            while (continueRouting(processors, exchange)) {
                AsyncProcessor processor = AsyncProcessorConverterHelper.convert(processors.next());
                // check for error if so we should break out
                if (!continueProcessing(exchange, ""so breaking out of pipeline"", LOG)) {
                    break;
                }
                doneSync = process(exchange, callback, processors, processor);
                if (!doneSync) {
                    LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", exchange.getExchangeId());
                    return;
                }
            }
            LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
            callback.done(false);
        }
    });
    return sync;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6447_020c451a,Major,camel-core/src/main/java/org/apache/camel/processor/ChoiceProcessor.java,116,140,"public void done(boolean doneSync) {
    // we only have to handle async completion of the pipeline
    if (doneSync) {
        return;
    }
    // continue processing the pipeline asynchronously
    while (continueRouting(processors, exchange)) {
        AsyncProcessor processor = AsyncProcessorConverterHelper.convert(processors.next());
        // check for error if so we should break out
        if (!continueProcessing(exchange, ""so breaking out of pipeline"", LOG)) {
            break;
        }
        doneSync = process(exchange, callback, processors, processor);
        if (!doneSync) {
            LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", exchange.getExchangeId());
            return;
        }
    }
    LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
    callback.done(false);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6557_2c5a42db,Major,camel-core/src/main/java/org/apache/camel/processor/aggregate/AbstractListAggregationStrategy.java,81,100,"/**
 * This method will aggregate the old and new exchange and return the result.
 *
 * @param oldExchange The oldest exchange, can be null
 * @param newExchange The newest exchange, can be null
 * @return a composite exchange of the old and/or new exchanges
 */
public Exchange aggregate(Exchange oldExchange, Exchange newExchange) {
    List<V> list;
    Exchange answer = oldExchange;
    if (oldExchange == null) {
        answer = new DefaultExchange(newExchange);
        list = getList(answer);
    } else {
        list = getList(oldExchange);
    }
    if (newExchange != null) {
        V value = getValue(newExchange);
        if (value != null) {
            list.add(value);
        }
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6593_7f8a295a,Minor,camel-core/src/main/java/org/apache/camel/model/ExpressionNode.java,129,146,"@Override
protected void preCreateProcessor() {
    Expression exp = expression;
    if (expression != null && expression.getExpressionValue() != null) {
        exp = expression.getExpressionValue();
    }
    if (exp instanceof ExpressionClause) {
        ExpressionClause<?> clause = (ExpressionClause<?>) exp;
        if (clause.getExpressionType() != null) {
            // if using the Java DSL then the expression may have been set using the
            // ExpressionClause which is a fancy builder to define expressions and predicates
            // using fluent builders in the DSL. However we need afterwards a callback to
            // reset the expression to the expression type the ExpressionClause did build for us
            expression = clause.getExpressionType();
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6593_7f8a295a,Minor,camel-core/src/main/java/org/apache/camel/model/language/ExpressionDefinition.java,245,260,"/**
 * Returns some descriptive text to describe this node
 */
public String getLabel() {
    String language = getExpression();
    if (ObjectHelper.isEmpty(language)) {
        Predicate predicate = getPredicate();
        if (predicate != null) {
            return predicate.toString();
        }
        Expression expressionValue = getExpressionValue();
        if (expressionValue != null) {
            return expressionValue.toString();
        }
    } else {
        return language;
    }
    return """";
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6604_4209fabb,Major,camel-core/src/main/java/org/apache/camel/processor/RecipientListProcessor.java,99,103,"public void begin() {
    // we have already acquired and prepare the producer
    LOG.trace(""RecipientProcessorExchangePair #{} begin: {}"", index, exchange);
    exchange.setProperty(Exchange.RECIPIENT_LIST_ENDPOINT, endpoint.getEndpointUri());
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6604_55751402,Major,camel-core/src/main/java/org/apache/camel/processor/RoutingSlip.java,262,272,"protected Exchange prepareExchangeForRoutingSlip(Exchange current, Endpoint endpoint) {
    Exchange copy = new DefaultExchange(current);
    // we must use the same id as this is a snapshot strategy where Camel copies a snapshot
    // before processing the next step in the pipeline, so we have a snapshot of the exchange
    // just before. This snapshot is used if Camel should do redeliveries (re try) using
    // DeadLetterChannel. That is why it's important the id is the same, as it is the *same*
    // exchange being routed.
    copy.setExchangeId(current.getExchangeId());
    copyOutToIn(copy, current);
    return copy;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6610_ed7e7c9f,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,1012,1034,"/**
 * Sets the id of this node.
 * <p/>
 * <b>Important:</b> If you want to set the id of the route,
 * then you <b>must</b> use {@link #routeId(String)} instead.
 *
 * @param id  the id
 * @return the builder
 */
@SuppressWarnings(""unchecked"")
public Type id(String id) {
    if (isOutputSupported() && getOutputs().isEmpty()) {
        // set id on this
        setId(id);
    } else {
        // set it on last output as this is what the user means to do
        // for Block(s) with non empty getOutputs() the id probably refers
        // to the last definition in the current Block
        List<ProcessorDefinition<?>> outputs = getOutputs();
        if (!blocks.isEmpty()) {
            if (blocks.getLast() instanceof ProcessorDefinition) {
                ProcessorDefinition<?> block = (ProcessorDefinition<?>) blocks.getLast();
                if (!block.getOutputs().isEmpty()) {
                    outputs = block.getOutputs();
                }
            }
        }
        outputs.get(outputs.size() - 1).setId(id);
    }
    return (Type) this;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6667_1fc7bd7a,Major,camel-core/src/main/java/org/apache/camel/processor/LoopProcessor.java,46,94,"@Override
public boolean process(Exchange exchange, AsyncCallback callback) {
    // use atomic integer to be able to pass reference and keep track on the values
    AtomicInteger index = new AtomicInteger();
    AtomicInteger count = new AtomicInteger();
    // Intermediate conversion to String is needed when direct conversion to Integer is not available
    // but evaluation result is a textual representation of a numeric value.
    String text = expression.evaluate(exchange, String.class);
    try {
        int num = ExchangeHelper.convertToMandatoryType(exchange, Integer.class, text);
        count.set(num);
    } catch (NoTypeConversionAvailableException e) {
        exchange.setException(e);
        callback.done(true);
        return true;
    }
    Exchange target = exchange;
    // set the size before we start
    exchange.setProperty(Exchange.LOOP_SIZE, count);
    // loop synchronously
    while (index.get() < count.get()) {
        // and prepare for next iteration
        target = prepareExchange(exchange, index.get());
        boolean sync = process(target, callback, index, count);
        if (!sync) {
            LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", target.getExchangeId());
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return false;
        }
        LOG.trace(""Processing exchangeId: {} is continued being processed synchronously"", target.getExchangeId());
        // increment counter before next loop
        index.getAndIncrement();
    }
    // we are done so prepare the result
    ExchangeHelper.copyResults(exchange, target);
    LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
    callback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6667_1fc7bd7a,Major,camel-core/src/main/java/org/apache/camel/processor/LoopProcessor.java,96,142,"protected boolean process(final Exchange exchange, final AsyncCallback callback, final AtomicInteger index, final AtomicInteger count) {
    // set current index as property
    LOG.debug(""LoopProcessor: iteration #{}"", index.get());
    exchange.setProperty(Exchange.LOOP_INDEX, index.get());
    boolean sync = processor.process(exchange, new AsyncCallback() {

        public void done(boolean doneSync) {
            // we only have to handle async completion of the routing slip
            if (doneSync) {
                return;
            }
            Exchange target = exchange;
            // increment index as we have just processed once
            index.getAndIncrement();
            // continue looping asynchronously
            while (index.get() < count.get()) {
                // and prepare for next iteration
                target = prepareExchange(exchange, index.get());
                // process again
                boolean sync = process(target, callback, index, count);
                if (!sync) {
                    LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", target.getExchangeId());
                    // so we break out now, then the callback will be invoked which then continue routing from where we left here
                    return;
                }
                // increment counter before next loop
                index.getAndIncrement();
            }
            // we are done so prepare the result
            ExchangeHelper.copyResults(exchange, target);
            LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
            callback.done(false);
        }
    });
    return sync;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6667_1fc7bd7a,Major,camel-core/src/main/java/org/apache/camel/processor/LoopProcessor.java,104,138,"public void done(boolean doneSync) {
    // we only have to handle async completion of the routing slip
    if (doneSync) {
        return;
    }
    Exchange target = exchange;
    // increment index as we have just processed once
    index.getAndIncrement();
    // continue looping asynchronously
    while (index.get() < count.get()) {
        // and prepare for next iteration
        target = prepareExchange(exchange, index.get());
        // process again
        boolean sync = process(target, callback, index, count);
        if (!sync) {
            LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", target.getExchangeId());
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return;
        }
        // increment counter before next loop
        index.getAndIncrement();
    }
    // we are done so prepare the result
    ExchangeHelper.copyResults(exchange, target);
    LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
    callback.done(false);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6667_1fc7bd7a,Major,camel-core/src/main/java/org/apache/camel/processor/LoopProcessor.java,151,159,"/**
 * Prepares the exchange for the next iteration
 *
 * @param exchange the exchange
 * @param index the index of the next iteration
 * @return the exchange to use
 */
protected Exchange prepareExchange(Exchange exchange, int index) {
    if (copy) {
        // use a copy but let it reuse the same exchange id so it appear as one exchange
        return ExchangeHelper.createCopy(exchange, true);
    } else {
        ExchangeHelper.prepareOutToIn(exchange);
        return exchange;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6687_617eab1c,Major,camel-core/src/main/java/org/apache/camel/component/bean/MethodInfo.java,403,597,"protected Expression createParametersExpression() {
    final int size = parameters.size();
    LOG.trace(""Creating parameters expression for {} parameters"", size);
    final Expression[] expressions = new Expression[size];
    for (int i = 0; i < size; i++) {
        Expression parameterExpression = parameters.get(i).getExpression();
        expressions[i] = parameterExpression;
        LOG.trace(""Parameter #{} has expression: {}"", i, parameterExpression);
    }
    return new Expression() {

        @SuppressWarnings(""unchecked"")
        public <T> T evaluate(Exchange exchange, Class<T> type) {
            Object[] answer = new Object[size];
            Object body = exchange.getIn().getBody();
            boolean multiParameterArray = false;
            if (exchange.getIn().getHeader(Exchange.BEAN_MULTI_PARAMETER_ARRAY) != null) {
                multiParameterArray = exchange.getIn().getHeader(Exchange.BEAN_MULTI_PARAMETER_ARRAY, Boolean.class);
            }
            // if there was an explicit method name to invoke, then we should support using
            // any provided parameter values in the method name
            String methodName = exchange.getIn().getHeader(Exchange.BEAN_METHOD_NAME, """", String.class);
            // the parameter values is between the parenthesis
            String methodParameters = ObjectHelper.between(methodName, ""("", "")"");
            // use an iterator to walk the parameter values
            Iterator<?> it = null;
            if (methodParameters != null) {
                // split the parameters safely separated by comma, but beware that we can have
                // quoted parameters which contains comma as well, so do a safe quote split
                String[] parameters = StringQuoteHelper.splitSafeQuote(methodParameters, ',', true);
                it = ObjectHelper.createIterator(parameters, "","", true);
            }
            // remove headers as they should not be propagated
            // we need to do this before the expressions gets evaluated as it may contain
            // a @Bean expression which would by mistake read these headers. So the headers
            // must be removed at this point of time
            exchange.getIn().removeHeader(Exchange.BEAN_MULTI_PARAMETER_ARRAY);
            exchange.getIn().removeHeader(Exchange.BEAN_METHOD_NAME);
            for (int i = 0; i < size; i++) {
                // grab the parameter value for the given index
                Object parameterValue = it != null && it.hasNext() ? it.next() : null;
                // and the expected parameter type
                Class<?> parameterType = parameters.get(i).getType();
                // the value for the parameter to use
                Object value = null;
                if (multiParameterArray) {
                    // get the value from the array
                    value = ((Object[]) body)[i];
                } else {
                    // we should skip * as its a type placeholder to indicate any type
                    if (parameterValue != null && !parameterValue.equals(""*"")) {
                        // evaluate the parameter value binding
                        value = evaluateParameterValue(exchange, i, parameterValue, parameterType);
                    }
                    // use bean parameter binding, if still no value
                    Expression expression = expressions[i];
                    if (value == null && expression != null) {
                        value = evaluateParameterBinding(exchange, expression, i, parameterType);
                    }
                }
                // remember the value to use
                if (value != Void.TYPE) {
                    answer[i] = value;
                }
            }
            return (T) answer;
        }

        /**
         * Evaluate using parameter values where the values can be provided in the method name syntax.
         * <p/>
         * This methods returns accordingly:
         * <ul>
         *     <li><tt>null</tt> - if not a parameter value</li>
         *     <li><tt>Void.TYPE</tt> - if an explicit null, forcing Camel to pass in <tt>null</tt> for that given parameter</li>
         *     <li>a non <tt>null</tt> value - if the parameter was a parameter value, and to be used</li>
         * </ul>
         *
         * @since 2.9
         */
        private Object evaluateParameterValue(Exchange exchange, int index, Object parameterValue, Class<?> parameterType) {
            Object answer = null;
            // convert the parameter value to a String
            String exp = exchange.getContext().getTypeConverter().convertTo(String.class, exchange, parameterValue);
            if (exp != null) {
                // check if its a valid parameter value
                boolean valid = BeanHelper.isValidParameterValue(exp);
                if (!valid) {
                    // it may be a parameter type instead, and if so, then we should return null,
                    // as this method is only for evaluating parameter values
                    Boolean isClass = BeanHelper.isAssignableToExpectedType(exchange.getContext().getClassResolver(), exp, parameterType);
                    // the method will return a non null value if exp is a class
                    if (isClass != null) {
                        return null;
                    }
                }
                // use simple language to evaluate the expression, as it may use the simple language to refer to message body, headers etc.
                Expression expression = null;
                try {
                    expression = exchange.getContext().resolveLanguage(""simple"").createExpression(exp);
                    parameterValue = expression.evaluate(exchange, Object.class);
                } catch (Exception e) {
                    throw new ExpressionEvaluationException(expression, ""Cannot create/evaluate simple expression: "" + exp + "" to be bound to parameter at index: "" + index + "" on method: "" + getMethod(), exchange, e);
                }
                if (parameterValue != null) {
                    // see method javadoc for details
                    if (""null"".equals(parameterValue)) {
                        return Void.TYPE;
                    }
                    // the parameter value was not already valid, but since the simple language have evaluated the expression
                    // which may change the parameterValue, so we have to check it again to see if its now valid
                    exp = exchange.getContext().getTypeConverter().convertTo(String.class, parameterValue);
                    // String values from the simple language is always valid
                    if (!valid) {
                        // re validate if the parameter was not valid the first time (String values should be accepted)
                        valid = parameterValue instanceof String || BeanHelper.isValidParameterValue(exp);
                    }
                    if (valid) {
                        // we need to unquote String parameters, as the enclosing quotes is there to denote a parameter value
                        if (parameterValue instanceof String) {
                            parameterValue = StringHelper.removeLeadingAndEndingQuotes((String) parameterValue);
                        }
                        if (parameterValue != null) {
                            try {
                                // its a valid parameter value, so convert it to the expected type of the parameter
                                answer = exchange.getContext().getTypeConverter().mandatoryConvertTo(parameterType, exchange, parameterValue);
                                if (LOG.isTraceEnabled()) {
                                    LOG.trace(""Parameter #{} evaluated as: {} type: "", new Object[] { index, answer, ObjectHelper.type(answer) });
                                }
                            } catch (Exception e) {
                                if (LOG.isDebugEnabled()) {
                                    LOG.debug(""Cannot convert from type: {} to type: {} for parameter #{}"", new Object[] { ObjectHelper.type(parameterValue), parameterType, index });
                                }
                                throw new ParameterBindingException(e, method, index, parameterType, parameterValue);
                            }
                        }
                    }
                }
            }
            return answer;
        }

        /**
         * Evaluate using classic parameter binding using the pre compute expression
         */
        private Object evaluateParameterBinding(Exchange exchange, Expression expression, int index, Class<?> parameterType) {
            Object answer = null;
            // use object first to avoid type conversion so we know if there is a value or not
            Object result = expression.evaluate(exchange, Object.class);
            if (result != null) {
                // we got a value now try to convert it to the expected type
                try {
                    answer = exchange.getContext().getTypeConverter().mandatoryConvertTo(parameterType, result);
                    if (LOG.isTraceEnabled()) {
                        LOG.trace(""Parameter #{} evaluated as: {} type: "", new Object[] { index, answer, ObjectHelper.type(answer) });
                    }
                } catch (NoTypeConversionAvailableException e) {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""Cannot convert from type: {} to type: {} for parameter #{}"", new Object[] { ObjectHelper.type(result), parameterType, index });
                    }
                    throw new ParameterBindingException(e, method, index, parameterType, result);
                }
            } else {
                LOG.trace(""Parameter #{} evaluated as null"", index);
            }
            return answer;
        }

        @Override
        public String toString() {
            return ""ParametersExpression: "" + Arrays.asList(expressions);
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6687_617eab1c,Major,camel-core/src/main/java/org/apache/camel/component/bean/MethodInfo.java,491,561,"/**
 * Evaluate using parameter values where the values can be provided in the method name syntax.
 * <p/>
 * This methods returns accordingly:
 * <ul>
 *     <li><tt>null</tt> - if not a parameter value</li>
 *     <li><tt>Void.TYPE</tt> - if an explicit null, forcing Camel to pass in <tt>null</tt> for that given parameter</li>
 *     <li>a non <tt>null</tt> value - if the parameter was a parameter value, and to be used</li>
 * </ul>
 *
 * @since 2.9
 */
private Object evaluateParameterValue(Exchange exchange, int index, Object parameterValue, Class<?> parameterType) {
    Object answer = null;
    // convert the parameter value to a String
    String exp = exchange.getContext().getTypeConverter().convertTo(String.class, exchange, parameterValue);
    if (exp != null) {
        // check if its a valid parameter value
        boolean valid = BeanHelper.isValidParameterValue(exp);
        if (!valid) {
            // it may be a parameter type instead, and if so, then we should return null,
            // as this method is only for evaluating parameter values
            Boolean isClass = BeanHelper.isAssignableToExpectedType(exchange.getContext().getClassResolver(), exp, parameterType);
            // the method will return a non null value if exp is a class
            if (isClass != null) {
                return null;
            }
        }
        // use simple language to evaluate the expression, as it may use the simple language to refer to message body, headers etc.
        Expression expression = null;
        try {
            expression = exchange.getContext().resolveLanguage(""simple"").createExpression(exp);
            parameterValue = expression.evaluate(exchange, Object.class);
        } catch (Exception e) {
            throw new ExpressionEvaluationException(expression, ""Cannot create/evaluate simple expression: "" + exp + "" to be bound to parameter at index: "" + index + "" on method: "" + getMethod(), exchange, e);
        }
        if (parameterValue != null) {
            // see method javadoc for details
            if (""null"".equals(parameterValue)) {
                return Void.TYPE;
            }
            // the parameter value was not already valid, but since the simple language have evaluated the expression
            // which may change the parameterValue, so we have to check it again to see if its now valid
            exp = exchange.getContext().getTypeConverter().convertTo(String.class, parameterValue);
            // String values from the simple language is always valid
            if (!valid) {
                // re validate if the parameter was not valid the first time (String values should be accepted)
                valid = parameterValue instanceof String || BeanHelper.isValidParameterValue(exp);
            }
            if (valid) {
                // we need to unquote String parameters, as the enclosing quotes is there to denote a parameter value
                if (parameterValue instanceof String) {
                    parameterValue = StringHelper.removeLeadingAndEndingQuotes((String) parameterValue);
                }
                if (parameterValue != null) {
                    try {
                        // its a valid parameter value, so convert it to the expected type of the parameter
                        answer = exchange.getContext().getTypeConverter().mandatoryConvertTo(parameterType, exchange, parameterValue);
                        if (LOG.isTraceEnabled()) {
                            LOG.trace(""Parameter #{} evaluated as: {} type: "", new Object[] { index, answer, ObjectHelper.type(answer) });
                        }
                    } catch (Exception e) {
                        if (LOG.isDebugEnabled()) {
                            LOG.debug(""Cannot convert from type: {} to type: {} for parameter #{}"", new Object[] { ObjectHelper.type(parameterValue), parameterType, index });
                        }
                        throw new ParameterBindingException(e, method, index, parameterType, parameterValue);
                    }
                }
            }
        }
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6723_b92d6237,Major,camel-core/src/main/java/org/apache/camel/impl/DefaultExchange.java,98,103,"private static Map<String, Object> safeCopy(Map<String, Object> properties) {
    if (properties == null) {
        return null;
    }
    return new ConcurrentHashMap<String, Object>(properties);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6723_b92d6237,Major,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,251,256,"private static Exchange copyExchangeNoAttachments(Exchange exchange, boolean preserveExchangeId) {
    Exchange answer = ExchangeHelper.createCopy(exchange, preserveExchangeId);
    // we do not want attachments for the splitted sub-messages
    answer.getIn().setAttachments(null);
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6723_b92d6237,Major,camel-core/src/main/java/org/apache/camel/util/ExchangeHelper.java,816,821,"private static Map<String, Object> safeCopy(Map<String, Object> properties) {
    if (properties == null) {
        return null;
    }
    return new ConcurrentHashMap<String, Object>(properties);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6743_745a85ab,Major,camel-core/src/main/java/org/apache/camel/component/bean/DefaultAnnotationExpressionFactory.java,35,46,"public Expression createExpression(CamelContext camelContext, Annotation annotation, LanguageAnnotation languageAnnotation, Class<?> expressionReturnType) {
    String languageName = languageAnnotation.language();
    if (languageName == null) {
        throw new IllegalArgumentException(""Cannot determine the language from the annotation: "" + annotation);
    }
    Language language = camelContext.resolveLanguage(languageName);
    if (language == null) {
        throw new IllegalArgumentException(""Cannot find the language: "" + languageName + "" on the classpath"");
    }
    String expression = getExpressionFromAnnotation(annotation);
    return language.createExpression(expression);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6779_f412d744,Major,camel-core/src/main/java/org/apache/camel/converter/jaxp/StaxConverter.java,166,174,"@Converter
public XMLStreamReader createXMLStreamReader(InputStream in, Exchange exchange) throws XMLStreamException {
    XMLInputFactory factory = getInputFactory();
    try {
        return factory.createXMLStreamReader(IOHelper.buffered(in), IOHelper.getCharsetName(exchange));
    } finally {
        returnXMLInputFactory(factory);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6779_f412d744,Major,camel-core/src/main/java/org/apache/camel/converter/jaxp/StaxConverter.java,235,243,"@Converter
public XMLEventReader createXMLEventReader(InputStream in, Exchange exchange) throws XMLStreamException {
    XMLInputFactory factory = getInputFactory();
    try {
        return factory.createXMLEventReader(IOHelper.buffered(in), IOHelper.getCharsetName(exchange));
    } finally {
        returnXMLInputFactory(factory);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6810_6b210169,Minor,camel-core/src/main/java/org/apache/camel/component/bean/MethodInfo.java,399,405,"/**
 * Returns true if this method is covariant with the specified method
 * (this method may above or below the specified method in the class hierarchy)
 * @param method
 * @return
 */
public boolean isCovariantWith(MethodInfo method) {
    return method.getMethod().getName().equals(this.getMethod().getName()) && (method.getMethod().getReturnType().isAssignableFrom(this.getMethod().getReturnType()) || this.getMethod().getReturnType().isAssignableFrom(method.getMethod().getReturnType())) && Arrays.deepEquals(method.getMethod().getParameterTypes(), this.getMethod().getParameterTypes());
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6810_6b210169,Minor,camel-core/src/main/java/org/apache/camel/component/bean/MethodInfo.java,417,612,"protected Expression createParametersExpression() {
    final int size = parameters.size();
    LOG.trace(""Creating parameters expression for {} parameters"", size);
    final Expression[] expressions = new Expression[size];
    for (int i = 0; i < size; i++) {
        Expression parameterExpression = parameters.get(i).getExpression();
        expressions[i] = parameterExpression;
        LOG.trace(""Parameter #{} has expression: {}"", i, parameterExpression);
    }
    return new Expression() {

        @SuppressWarnings(""unchecked"")
        public <T> T evaluate(Exchange exchange, Class<T> type) {
            Object[] answer = new Object[size];
            Object body = exchange.getIn().getBody();
            boolean multiParameterArray = false;
            if (exchange.getIn().getHeader(Exchange.BEAN_MULTI_PARAMETER_ARRAY) != null) {
                multiParameterArray = exchange.getIn().getHeader(Exchange.BEAN_MULTI_PARAMETER_ARRAY, Boolean.class);
            }
            // if there was an explicit method name to invoke, then we should support using
            // any provided parameter values in the method name
            String methodName = exchange.getIn().getHeader(Exchange.BEAN_METHOD_NAME, """", String.class);
            // the parameter values is between the parenthesis
            String methodParameters = ObjectHelper.between(methodName, ""("", "")"");
            // use an iterator to walk the parameter values
            Iterator<?> it = null;
            if (methodParameters != null) {
                // split the parameters safely separated by comma, but beware that we can have
                // quoted parameters which contains comma as well, so do a safe quote split
                String[] parameters = StringQuoteHelper.splitSafeQuote(methodParameters, ',', true);
                it = ObjectHelper.createIterator(parameters, "","", true);
            }
            // remove headers as they should not be propagated
            // we need to do this before the expressions gets evaluated as it may contain
            // a @Bean expression which would by mistake read these headers. So the headers
            // must be removed at this point of time
            exchange.getIn().removeHeader(Exchange.BEAN_MULTI_PARAMETER_ARRAY);
            exchange.getIn().removeHeader(Exchange.BEAN_METHOD_NAME);
            for (int i = 0; i < size; i++) {
                // grab the parameter value for the given index
                Object parameterValue = it != null && it.hasNext() ? it.next() : null;
                // and the expected parameter type
                Class<?> parameterType = parameters.get(i).getType();
                // the value for the parameter to use
                Object value = null;
                if (multiParameterArray) {
                    // get the value from the array
                    value = ((Object[]) body)[i];
                } else {
                    // we should skip * as its a type placeholder to indicate any type
                    if (parameterValue != null && !parameterValue.equals(""*"")) {
                        // evaluate the parameter value binding
                        value = evaluateParameterValue(exchange, i, parameterValue, parameterType);
                    }
                    // use bean parameter binding, if still no value
                    Expression expression = expressions[i];
                    if (value == null && expression != null) {
                        value = evaluateParameterBinding(exchange, expression, i, parameterType);
                    }
                }
                // remember the value to use
                if (value != Void.TYPE) {
                    answer[i] = value;
                }
            }
            return (T) answer;
        }

        /**
         * Evaluate using parameter values where the values can be provided in the method name syntax.
         * <p/>
         * This methods returns accordingly:
         * <ul>
         *     <li><tt>null</tt> - if not a parameter value</li>
         *     <li><tt>Void.TYPE</tt> - if an explicit null, forcing Camel to pass in <tt>null</tt> for that given parameter</li>
         *     <li>a non <tt>null</tt> value - if the parameter was a parameter value, and to be used</li>
         * </ul>
         *
         * @since 2.9
         */
        private Object evaluateParameterValue(Exchange exchange, int index, Object parameterValue, Class<?> parameterType) {
            Object answer = null;
            // convert the parameter value to a String
            String exp = exchange.getContext().getTypeConverter().convertTo(String.class, exchange, parameterValue);
            if (exp != null) {
                // check if its a valid parameter value
                boolean valid = BeanHelper.isValidParameterValue(exp);
                if (!valid) {
                    // it may be a parameter type instead, and if so, then we should return null,
                    // as this method is only for evaluating parameter values
                    Boolean isClass = BeanHelper.isAssignableToExpectedType(exchange.getContext().getClassResolver(), exp, parameterType);
                    // the method will return a non null value if exp is a class
                    if (isClass != null) {
                        return null;
                    }
                }
                // use simple language to evaluate the expression, as it may use the simple language to refer to message body, headers etc.
                Expression expression = null;
                try {
                    expression = exchange.getContext().resolveLanguage(""simple"").createExpression(exp);
                    parameterValue = expression.evaluate(exchange, Object.class);
                    // use ""null"" to indicate the expression returned a null value which is a valid response we need to honor
                    if (parameterValue == null) {
                        parameterValue = ""null"";
                    }
                } catch (Exception e) {
                    throw new ExpressionEvaluationException(expression, ""Cannot create/evaluate simple expression: "" + exp + "" to be bound to parameter at index: "" + index + "" on method: "" + getMethod(), exchange, e);
                }
                // see method javadoc for details
                if (""null"".equals(parameterValue)) {
                    return Void.TYPE;
                }
                // the parameter value was not already valid, but since the simple language have evaluated the expression
                // which may change the parameterValue, so we have to check it again to see if its now valid
                exp = exchange.getContext().getTypeConverter().convertTo(String.class, parameterValue);
                // String values from the simple language is always valid
                if (!valid) {
                    // re validate if the parameter was not valid the first time (String values should be accepted)
                    valid = parameterValue instanceof String || BeanHelper.isValidParameterValue(exp);
                }
                if (valid) {
                    // we need to unquote String parameters, as the enclosing quotes is there to denote a parameter value
                    if (parameterValue instanceof String) {
                        parameterValue = StringHelper.removeLeadingAndEndingQuotes((String) parameterValue);
                    }
                    if (parameterValue != null) {
                        try {
                            // its a valid parameter value, so convert it to the expected type of the parameter
                            answer = exchange.getContext().getTypeConverter().mandatoryConvertTo(parameterType, exchange, parameterValue);
                            if (LOG.isTraceEnabled()) {
                                LOG.trace(""Parameter #{} evaluated as: {} type: "", new Object[] { index, answer, ObjectHelper.type(answer) });
                            }
                        } catch (Exception e) {
                            if (LOG.isDebugEnabled()) {
                                LOG.debug(""Cannot convert from type: {} to type: {} for parameter #{}"", new Object[] { ObjectHelper.type(parameterValue), parameterType, index });
                            }
                            throw new ParameterBindingException(e, method, index, parameterType, parameterValue);
                        }
                    }
                }
            }
            return answer;
        }

        /**
         * Evaluate using classic parameter binding using the pre compute expression
         */
        private Object evaluateParameterBinding(Exchange exchange, Expression expression, int index, Class<?> parameterType) {
            Object answer = null;
            // use object first to avoid type conversion so we know if there is a value or not
            Object result = expression.evaluate(exchange, Object.class);
            if (result != null) {
                // we got a value now try to convert it to the expected type
                try {
                    answer = exchange.getContext().getTypeConverter().mandatoryConvertTo(parameterType, result);
                    if (LOG.isTraceEnabled()) {
                        LOG.trace(""Parameter #{} evaluated as: {} type: "", new Object[] { index, answer, ObjectHelper.type(answer) });
                    }
                } catch (NoTypeConversionAvailableException e) {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""Cannot convert from type: {} to type: {} for parameter #{}"", new Object[] { ObjectHelper.type(result), parameterType, index });
                    }
                    throw new ParameterBindingException(e, method, index, parameterType, result);
                }
            } else {
                LOG.trace(""Parameter #{} evaluated as null"", index);
            }
            return answer;
        }

        @Override
        public String toString() {
            return ""ParametersExpression: "" + Arrays.asList(expressions);
        }
    };
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6810_6b210169,Minor,camel-core/src/main/java/org/apache/camel/component/bean/MethodInfo.java,505,576,"/**
 * Evaluate using parameter values where the values can be provided in the method name syntax.
 * <p/>
 * This methods returns accordingly:
 * <ul>
 *     <li><tt>null</tt> - if not a parameter value</li>
 *     <li><tt>Void.TYPE</tt> - if an explicit null, forcing Camel to pass in <tt>null</tt> for that given parameter</li>
 *     <li>a non <tt>null</tt> value - if the parameter was a parameter value, and to be used</li>
 * </ul>
 *
 * @since 2.9
 */
private Object evaluateParameterValue(Exchange exchange, int index, Object parameterValue, Class<?> parameterType) {
    Object answer = null;
    // convert the parameter value to a String
    String exp = exchange.getContext().getTypeConverter().convertTo(String.class, exchange, parameterValue);
    if (exp != null) {
        // check if its a valid parameter value
        boolean valid = BeanHelper.isValidParameterValue(exp);
        if (!valid) {
            // it may be a parameter type instead, and if so, then we should return null,
            // as this method is only for evaluating parameter values
            Boolean isClass = BeanHelper.isAssignableToExpectedType(exchange.getContext().getClassResolver(), exp, parameterType);
            // the method will return a non null value if exp is a class
            if (isClass != null) {
                return null;
            }
        }
        // use simple language to evaluate the expression, as it may use the simple language to refer to message body, headers etc.
        Expression expression = null;
        try {
            expression = exchange.getContext().resolveLanguage(""simple"").createExpression(exp);
            parameterValue = expression.evaluate(exchange, Object.class);
            // use ""null"" to indicate the expression returned a null value which is a valid response we need to honor
            if (parameterValue == null) {
                parameterValue = ""null"";
            }
        } catch (Exception e) {
            throw new ExpressionEvaluationException(expression, ""Cannot create/evaluate simple expression: "" + exp + "" to be bound to parameter at index: "" + index + "" on method: "" + getMethod(), exchange, e);
        }
        // see method javadoc for details
        if (""null"".equals(parameterValue)) {
            return Void.TYPE;
        }
        // the parameter value was not already valid, but since the simple language have evaluated the expression
        // which may change the parameterValue, so we have to check it again to see if its now valid
        exp = exchange.getContext().getTypeConverter().convertTo(String.class, parameterValue);
        // String values from the simple language is always valid
        if (!valid) {
            // re validate if the parameter was not valid the first time (String values should be accepted)
            valid = parameterValue instanceof String || BeanHelper.isValidParameterValue(exp);
        }
        if (valid) {
            // we need to unquote String parameters, as the enclosing quotes is there to denote a parameter value
            if (parameterValue instanceof String) {
                parameterValue = StringHelper.removeLeadingAndEndingQuotes((String) parameterValue);
            }
            if (parameterValue != null) {
                try {
                    // its a valid parameter value, so convert it to the expected type of the parameter
                    answer = exchange.getContext().getTypeConverter().mandatoryConvertTo(parameterType, exchange, parameterValue);
                    if (LOG.isTraceEnabled()) {
                        LOG.trace(""Parameter #{} evaluated as: {} type: "", new Object[] { index, answer, ObjectHelper.type(answer) });
                    }
                } catch (Exception e) {
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""Cannot convert from type: {} to type: {} for parameter #{}"", new Object[] { ObjectHelper.type(parameterValue), parameterType, index });
                    }
                    throw new ParameterBindingException(e, method, index, parameterType, parameterValue);
                }
            }
        }
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6889_cd40b712,Major,camel-core/src/main/java/org/apache/camel/processor/ChoiceProcessor.java,54,109,"public boolean process(final Exchange exchange, final AsyncCallback callback) {
    Iterator<Processor> processors = next().iterator();
    // callback to restore existing FILTER_MATCHED property on the Exchange
    final Object existing = exchange.getProperty(Exchange.FILTER_MATCHED);
    final AsyncCallback choiceCallback = new AsyncCallback() {

        @Override
        public void done(boolean doneSync) {
            if (existing != null) {
                exchange.setProperty(Exchange.FILTER_MATCHED, existing);
            } else {
                exchange.removeProperty(Exchange.FILTER_MATCHED);
            }
            callback.done(doneSync);
        }
    };
    // and if not, we just continue without using any processor
    while (processors.hasNext()) {
        // get the next processor
        Processor processor = processors.next();
        // evaluate the predicate on filter predicate early to be faster
        // and avoid issues when having nested choices
        // as we should only pick one processor
        boolean matches = true;
        if (processor instanceof FilterProcessor) {
            FilterProcessor filter = (FilterProcessor) processor;
            try {
                matches = filter.getPredicate().matches(exchange);
                exchange.setProperty(Exchange.FILTER_MATCHED, matches);
            } catch (Throwable e) {
                exchange.setException(e);
                choiceCallback.done(true);
                return true;
            }
            // as we have pre evaluated the predicate then use its processor directly when routing
            processor = filter.getProcessor();
        }
        // if we did not match then continue to next filter
        if (!matches) {
            continue;
        }
        // okay we found a filter or its the otherwise we are processing
        AsyncProcessor async = AsyncProcessorConverterHelper.convert(processor);
        return async.process(exchange, choiceCallback);
    }
    // when no filter matches and there is no otherwise, then just continue
    choiceCallback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6918_5761250c,Major,camel-core/src/main/java/org/apache/camel/processor/SendProcessor.java,89,142,"public boolean process(Exchange exchange, final AsyncCallback callback) {
    if (!isStarted()) {
        exchange.setException(new IllegalStateException(""SendProcessor has not been started: "" + this));
        callback.done(true);
        return true;
    }
    // we should preserve existing MEP so remember old MEP
    // if you want to permanently to change the MEP then use .setExchangePattern in the DSL
    final ExchangePattern existingPattern = exchange.getPattern();
    // if we have a producer then use that as its optimized
    if (producer != null) {
        // record timing for sending the exchange using the producer
        final StopWatch watch = new StopWatch();
        final Exchange target = configureExchange(exchange, pattern);
        EventHelper.notifyExchangeSending(exchange.getContext(), target, destination);
        LOG.debug("">>>> {} {}"", destination, exchange);
        return producer.process(exchange, new AsyncCallback() {

            @Override
            public void done(boolean doneSync) {
                try {
                    // restore previous MEP
                    target.setPattern(existingPattern);
                    // emit event that the exchange was sent to the endpoint
                    long timeTaken = watch.stop();
                    EventHelper.notifyExchangeSent(target.getContext(), target, destination, timeTaken);
                } finally {
                    callback.done(doneSync);
                }
            }
        });
    }
    // send the exchange to the destination using the producer cache for the non optimized producers
    return producerCache.doInAsyncProducer(destination, exchange, pattern, callback, new AsyncProducerCallback() {

        public boolean doInAsyncProducer(Producer producer, AsyncProcessor asyncProducer, final Exchange exchange, ExchangePattern pattern, final AsyncCallback callback) {
            final Exchange target = configureExchange(exchange, pattern);
            LOG.debug("">>>> {} {}"", destination, exchange);
            return asyncProducer.process(target, new AsyncCallback() {

                public void done(boolean doneSync) {
                    // restore previous MEP
                    target.setPattern(existingPattern);
                    // signal we are done
                    callback.done(doneSync);
                }
            });
        }
    });
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6936_4954d573,Major,camel-core/src/main/java/org/apache/camel/component/file/GenericFileConsumer.java,473,503,"/**
 * Strategy for validating if the given remote file should be included or not
 *
 * @param file        the file
 * @param isDirectory whether the file is a directory or a file
 * @param files       files in the directory
 * @return <tt>true</tt> to include the file, <tt>false</tt> to skip it
 */
protected boolean isValidFile(GenericFile<T> file, boolean isDirectory, List<T> files) {
    if (!isMatched(file, isDirectory, files)) {
        log.trace(""File did not match. Will skip this file: {}"", file);
        return false;
    }
    // if its a file then check if its already in progress
    if (!isDirectory && isInProgress(file)) {
        if (log.isTraceEnabled()) {
            log.trace(""Skipping as file is already in progress: {}"", file.getFileName());
        }
        return false;
    }
    // if its a file then check we have the file in the idempotent registry already
    if (!isDirectory && endpoint.isIdempotent()) {
        // use absolute file path as default key, but evaluate if an expression key was configured
        String key = file.getAbsoluteFilePath();
        if (endpoint.getIdempotentKey() != null) {
            Exchange dummy = endpoint.createExchange(file);
            key = endpoint.getIdempotentKey().evaluate(dummy, String.class);
        }
        if (key != null && endpoint.getIdempotentRepository().contains(key)) {
            log.trace(""This consumer is idempotent and the file has been consumed before. Will skip this file: {}"", file);
            return false;
        }
    }
    // file matched
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6936_4954d573,Major,camel-core/src/main/java/org/apache/camel/component/file/GenericFileConsumer.java,608,611,"/**
 * Is the given file already in progress.
 *
 * @param file the file
 * @return <tt>true</tt> if the file is already in progress
 */
protected boolean isInProgress(GenericFile<T> file) {
    String key = file.getAbsoluteFilePath();
    return !endpoint.getInProgressRepository().add(key);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6948_f744afd9,Minor,camel-core/src/main/java/org/apache/camel/impl/ProducerCache.java,133,141,"/**
 * Releases an acquired producer back after usage.
 *
 * @param endpoint the endpoint
 * @param producer the producer to release
 * @throws Exception can be thrown if error stopping producer if that was needed.
 */
public void releaseProducer(Endpoint endpoint, Producer producer) throws Exception {
    if (producer instanceof ServicePoolAware) {
        // release back to the pool
        pool.release(endpoint, producer);
    } else if (!producer.isSingleton()) {
        // stop non singleton producers as we should not leak resources
        producer.stop();
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6964_6b2ffb30,Major,camel-core/src/main/java/org/apache/camel/component/file/GenericFileOnCompletion.java,103,148,"/**
 * Strategy when the file was processed and a commit should be executed.
 *
 * @param processStrategy the strategy to perform the commit
 * @param exchange        the exchange
 * @param file            the file processed
 */
protected void processStrategyCommit(GenericFileProcessStrategy<T> processStrategy, Exchange exchange, GenericFile<T> file) {
    if (endpoint.isIdempotent()) {
        // use absolute file path as default key, but evaluate if an expression key was configured
        String key = absoluteFileName;
        if (endpoint.getIdempotentKey() != null) {
            Exchange dummy = endpoint.createExchange(file);
            key = endpoint.getIdempotentKey().evaluate(dummy, String.class);
        }
        // only add to idempotent repository if we could process the file
        if (key != null) {
            endpoint.getIdempotentRepository().add(key);
        }
    }
    // must be last in batch to delete the done file name
    // delete done file if used (and not noop=true)
    boolean complete = exchange.getProperty(Exchange.BATCH_COMPLETE, false, Boolean.class);
    if (endpoint.getDoneFileName() != null && !endpoint.isNoop()) {
        // done file must be in same path as the original input file
        String doneFileName = endpoint.createDoneFileName(absoluteFileName);
        ObjectHelper.notEmpty(doneFileName, ""doneFileName"", endpoint);
        // we should delete the dynamic done file
        if (endpoint.getDoneFileName().indexOf(""{file:name"") > 0 || complete) {
            try {
                // delete done file
                boolean deleted = operations.deleteFile(doneFileName);
                log.trace(""Done file: {} was deleted: {}"", doneFileName, deleted);
                if (!deleted) {
                    log.warn(""Done file: "" + doneFileName + "" could not be deleted"");
                }
            } catch (Exception e) {
                handleException(""Error deleting done file: "" + doneFileName, exchange, e);
            }
        }
    }
    try {
        log.trace(""Commit file strategy: {} for file: {}"", processStrategy, file);
        processStrategy.commit(operations, endpoint, exchange, file);
    } catch (Exception e) {
        handleException(""Error during commit"", exchange, e);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6964_6b2ffb30,Major,camel-core/src/main/java/org/apache/camel/component/file/GenericFileOnCompletion.java,157,168,"/**
 * Strategy when the file was not processed and a rollback should be executed.
 *
 * @param processStrategy the strategy to perform the commit
 * @param exchange        the exchange
 * @param file            the file processed
 */
protected void processStrategyRollback(GenericFileProcessStrategy<T> processStrategy, Exchange exchange, GenericFile<T> file) {
    if (log.isWarnEnabled()) {
        log.warn(""Rollback file strategy: "" + processStrategy + "" for file: "" + file);
    }
    try {
        processStrategy.rollback(operations, endpoint, exchange, file);
    } catch (Exception e) {
        handleException(""Error during rollback"", exchange, e);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-6987_37e0e6bb,Minor,camel-core/src/main/java/org/apache/camel/util/MessageHelper.java,200,272,"/**
 * Extracts the body for logging purpose.
 * <p/>
 * Will clip the body if its too big for logging.
 *
 * @see org.apache.camel.Exchange#LOG_DEBUG_BODY_MAX_CHARS
 * @param message the message
 * @param prepend a message to prepend
 * @param allowStreams whether or not streams is allowed
 * @param allowFiles whether or not files is allowed (currently not in use)
 * @param maxChars limit to maximum number of chars. Use 0 for not limit, and -1 for turning logging message body off.
 * @return the logging message
 */
public static String extractBodyForLogging(Message message, String prepend, boolean allowStreams, boolean allowFiles, int maxChars) {
    if (maxChars < 0) {
        return prepend + ""[Body is not logged]"";
    }
    Object obj = message.getBody();
    if (obj == null) {
        return prepend + ""[Body is null]"";
    }
    if (!allowStreams) {
        if (obj instanceof Source && !(obj instanceof StringSource || obj instanceof BytesSource)) {
            // all other kinds we should not touch the body
            return prepend + ""[Body is instance of java.xml.transform.Source]"";
        } else if (obj instanceof StreamCache) {
            return prepend + ""[Body is instance of org.apache.camel.StreamCache]"";
        } else if (obj instanceof InputStream) {
            return prepend + ""[Body is instance of java.io.InputStream]"";
        } else if (obj instanceof OutputStream) {
            return prepend + ""[Body is instance of java.io.OutputStream]"";
        } else if (obj instanceof Reader) {
            return prepend + ""[Body is instance of java.io.Reader]"";
        } else if (obj instanceof Writer) {
            return prepend + ""[Body is instance of java.io.Writer]"";
        } else if (obj instanceof WrappedFile || obj instanceof File) {
            return prepend + ""[Body is file based: "" + obj + ""]"";
        }
    }
    if (!allowFiles) {
        if (obj instanceof WrappedFile || obj instanceof File) {
            return prepend + ""[Body is file based: "" + obj + ""]"";
        }
    }
    // is the body a stream cache
    StreamCache cache;
    if (obj instanceof StreamCache) {
        cache = (StreamCache) obj;
    } else {
        cache = null;
    }
    // grab the message body as a string
    String body = null;
    if (message.getExchange() != null) {
        try {
            body = message.getExchange().getContext().getTypeConverter().convertTo(String.class, message.getExchange(), obj);
        } catch (Exception e) {
        // ignore as the body is for logging purpose
        }
    }
    if (body == null) {
        body = obj.toString();
    }
    // reset stream cache after use
    if (cache != null) {
        cache.reset();
    }
    if (body == null) {
        return prepend + ""[Body is null]"";
    }
    // clip body if length enabled and the body is too big
    if (maxChars > 0 && body.length() > maxChars) {
        body = body.substring(0, maxChars) + ""... [Body clipped after "" + maxChars + "" chars, total length is "" + body.length() + ""]"";
    }
    return prepend + body;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7016_4ed448c7,Minor,camel-core/src/main/java/org/apache/camel/management/mbean/ManagedRoute.java,226,235,"public void updateRouteFromXml(String xml) throws Exception {
    // convert to model from xml
    RouteDefinition def = ModelHelper.createModelFromXml(xml, RouteDefinition.class);
    if (def == null) {
        return;
    }
    // add will remove existing route first
    context.addRouteDefinition(def);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7018_3244c1e5,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaEndpoint.java,311,313,"public boolean isSingleton() {
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7018_3244c1e5,Major,camel-core/src/main/java/org/apache/camel/management/DefaultManagementMBeanAssembler.java,53,100,"public ModelMBean assemble(MBeanServer mBeanServer, Object obj, ObjectName name) throws JMException {
    ModelMBeanInfo mbi = null;
    // prefer to use the managed instance if it has been annotated with JMX annotations
    if (obj instanceof ManagedInstance) {
        // there may be a custom embedded instance which have additional methods
        Object custom = ((ManagedInstance) obj).getInstance();
        if (custom != null && ObjectHelper.hasAnnotation(custom.getClass().getAnnotations(), ManagedResource.class)) {
            LOG.trace(""Assembling MBeanInfo for: {} from custom @ManagedResource object: {}"", name, custom);
            // get the mbean info from the custom managed object
            mbi = assembler.getMBeanInfo(obj, custom, name.toString());
            // and let the custom object be registered in JMX
            obj = custom;
        }
    }
    if (mbi == null) {
        // use the default provided mbean which has been annotated with JMX annotations
        LOG.trace(""Assembling MBeanInfo for: {} from @ManagedResource object: {}"", name, obj);
        mbi = assembler.getMBeanInfo(obj, null, name.toString());
    }
    if (mbi == null) {
        return null;
    }
    RequiredModelMBean mbean;
    boolean sanitize = camelContext.getManagementStrategy().getManagementAgent().getMask() != null && camelContext.getManagementStrategy().getManagementAgent().getMask();
    if (sanitize) {
        mbean = new MaskRequiredModelMBean(mbi, sanitize);
    } else {
        mbean = (RequiredModelMBean) mBeanServer.instantiate(RequiredModelMBean.class.getName());
        mbean.setModelMBeanInfo(mbi);
    }
    try {
        mbean.setManagedResource(obj, ""ObjectReference"");
    } catch (InvalidTargetObjectTypeException e) {
        throw new JMException(e.getMessage());
    }
    // Allows the managed object to send notifications
    if (obj instanceof NotificationSenderAware) {
        ((NotificationSenderAware) obj).setNotificationSender(new NotificationSenderAdapter(mbean));
    }
    return mbean;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7018_3244c1e5,Major,camel-core/src/main/java/org/apache/camel/management/MBeanInfoAssembler.java,98,136,"/**
 * Gets the {@link ModelMBeanInfo} for the given managed bean
 *
 * @param defaultManagedBean  the default managed bean
 * @param customManagedBean   an optional custom managed bean
 * @param objectName   the object name
 * @return the model info, or <tt>null</tt> if not possible to create, for example due the managed bean is a proxy class
 * @throws JMException is thrown if error creating the model info
 */
public ModelMBeanInfo getMBeanInfo(Object defaultManagedBean, Object customManagedBean, String objectName) throws JMException {
    // skip proxy classes
    if (Proxy.isProxyClass(defaultManagedBean.getClass())) {
        LOG.trace(""Skip creating ModelMBeanInfo due proxy class {}"", defaultManagedBean.getClass());
        return null;
    }
    // maps and lists to contain information about attributes and operations
    Map<String, ManagedAttributeInfo> attributes = new LinkedHashMap<String, ManagedAttributeInfo>();
    Set<ManagedOperationInfo> operations = new LinkedHashSet<ManagedOperationInfo>();
    Set<ModelMBeanAttributeInfo> mBeanAttributes = new LinkedHashSet<ModelMBeanAttributeInfo>();
    Set<ModelMBeanOperationInfo> mBeanOperations = new LinkedHashSet<ModelMBeanOperationInfo>();
    Set<ModelMBeanNotificationInfo> mBeanNotifications = new LinkedHashSet<ModelMBeanNotificationInfo>();
    // extract details from default managed bean
    extractAttributesAndOperations(defaultManagedBean.getClass(), attributes, operations);
    extractMbeanAttributes(defaultManagedBean, attributes, mBeanAttributes, mBeanOperations);
    extractMbeanOperations(defaultManagedBean, operations, mBeanOperations);
    extractMbeanNotifications(defaultManagedBean, mBeanNotifications);
    // extract details from custom managed bean
    if (customManagedBean != null) {
        extractAttributesAndOperations(customManagedBean.getClass(), attributes, operations);
        extractMbeanAttributes(customManagedBean, attributes, mBeanAttributes, mBeanOperations);
        extractMbeanOperations(customManagedBean, operations, mBeanOperations);
        extractMbeanNotifications(customManagedBean, mBeanNotifications);
    }
    // create the ModelMBeanInfo
    String name = getName(customManagedBean != null ? customManagedBean : defaultManagedBean, objectName);
    String description = getDescription(customManagedBean != null ? customManagedBean : defaultManagedBean, objectName);
    ModelMBeanAttributeInfo[] arrayAttributes = mBeanAttributes.toArray(new ModelMBeanAttributeInfo[mBeanAttributes.size()]);
    ModelMBeanOperationInfo[] arrayOperations = mBeanOperations.toArray(new ModelMBeanOperationInfo[mBeanOperations.size()]);
    ModelMBeanNotificationInfo[] arrayNotifications = mBeanNotifications.toArray(new ModelMBeanNotificationInfo[mBeanNotifications.size()]);
    ModelMBeanInfo info = new ModelMBeanInfoSupport(name, description, arrayAttributes, null, arrayOperations, arrayNotifications);
    LOG.trace(""Created ModelMBeanInfo {}"", info);
    return info;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7055_15e1077d,Major,camel-core/src/main/java/org/apache/camel/converter/stream/CachedOutputStream.java,81,91,"@Override
public void onDone(Exchange exchange) {
    try {
        if (fileInputStreamCache != null) {
            fileInputStreamCache.close();
        }
        close();
    } catch (Exception e) {
        LOG.warn(""Error deleting temporary cache file: "" + tempFile, e);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7055_15e1077d,Major,camel-core/src/main/java/org/apache/camel/converter/stream/CachedOutputStream.java,105,108,"public void close() throws IOException {
    currentStream.close();
    cleanUpTempFile();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7100_00a9b02b,Major,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,193,207,"@Override
public void close() throws IOException {
    if (value instanceof Closeable) {
        IOHelper.close((Closeable) value, value.getClass().getName(), LOG);
    } else if (value instanceof Scanner) {
        // special for Scanner as it does not implement Closeable
        Scanner scanner = (Scanner) value;
        scanner.close();
        IOException ioException = scanner.ioException();
        if (ioException != null) {
            throw ioException;
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7100_00a9b02b,Major,camel-core/src/main/java/org/apache/camel/util/GroupIterator.java,66,78,"@Override
public void close() throws IOException {
    if (it instanceof Closeable) {
        IOHelper.close((Closeable) it);
    } else if (it instanceof Scanner) {
        // special for Scanner as it does not implement Closeable
        ((Scanner) it).close();
    }
    // close the buffer as well
    bos.close();
    // we are now closed
    closed = true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7130_cc192f87,Major,camel-core/src/main/java/org/apache/camel/builder/xml/XsltBuilder.java,449,495,"/**
 * Converts the inbound body to a {@link Source}, if the body is <b>not</b> already a {@link Source}.
 * <p/>
 * This implementation will prefer to source in the following order:
 * <ul>
 *   <li>StAX - Is StAX is allowed</li>
 *   <li>SAX - SAX as 2nd choice</li>
 *   <li>Stream - Stream as 3rd choice</li>
 *   <li>DOM - DOM as 4th choice</li>
 * </ul>
 */
protected Source getSource(Exchange exchange, Object body) {
    // body may already be a source
    if (body instanceof Source) {
        return (Source) body;
    }
    Source source = null;
    if (body instanceof InputStream) {
        return new StreamSource((InputStream) body);
    }
    if (body != null) {
        if (isAllowStAX()) {
            source = exchange.getContext().getTypeConverter().tryConvertTo(StAXSource.class, exchange, body);
        }
        if (source == null) {
            // then try SAX
            source = exchange.getContext().getTypeConverter().tryConvertTo(SAXSource.class, exchange, body);
        }
        if (source == null) {
            // then try stream
            source = exchange.getContext().getTypeConverter().tryConvertTo(StreamSource.class, exchange, body);
        }
        if (source == null) {
            // and fallback to DOM
            source = exchange.getContext().getTypeConverter().tryConvertTo(DOMSource.class, exchange, body);
        }
        // now we just put the call of source converter at last
        if (source == null) {
            TypeConverter tc = exchange.getContext().getTypeConverterRegistry().lookup(Source.class, body.getClass());
            if (tc != null) {
                source = tc.convertTo(Source.class, exchange, body);
            }
        }
    }
    if (source == null) {
        if (isFailOnNullBody()) {
            throw new ExpectedBodyTypeException(exchange, Source.class);
        } else {
            try {
                source = converter.toDOMSource(converter.createDocument());
            } catch (ParserConfigurationException e) {
                throw new RuntimeTransformException(e);
            }
        }
    }
    return source;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7146_b6981cfd,Trivial,camel-core/src/main/java/org/apache/camel/processor/aggregate/AggregateProcessor.java,477,522,"protected Exchange onCompletion(final String key, final Exchange original, final Exchange aggregated, boolean fromTimeout) {
    // store the correlation key as property before we remove so the repository has that information
    if (original != null) {
        original.setProperty(Exchange.AGGREGATED_CORRELATION_KEY, key);
    }
    aggregated.setProperty(Exchange.AGGREGATED_CORRELATION_KEY, key);
    // remove from repository as its completed, we do this first as to trigger any OptimisticLockingException's
    aggregationRepository.remove(aggregated.getContext(), key, original);
    if (!fromTimeout && timeoutMap != null) {
        // cleanup timeout map if it was a incoming exchange which triggered the timeout (and not the timeout checker)
        timeoutMap.remove(key);
    }
    // this key has been closed so add it to the closed map
    if (closedCorrelationKeys != null) {
        closedCorrelationKeys.put(key, key);
    }
    if (fromTimeout) {
        // to allow any custom processing before discarding the exchange
        if (aggregationStrategy instanceof TimeoutAwareAggregationStrategy) {
            long timeout = getCompletionTimeout() > 0 ? getCompletionTimeout() : -1;
            ((TimeoutAwareAggregationStrategy) aggregationStrategy).timeout(aggregated, -1, -1, timeout);
        }
    }
    Exchange answer;
    if (fromTimeout && isDiscardOnCompletionTimeout()) {
        // discard due timeout
        LOG.debug(""Aggregation for correlation key {} discarding aggregated exchange: {}"", key, aggregated);
        // must confirm the discarded exchange
        aggregationRepository.confirm(aggregated.getContext(), aggregated.getExchangeId());
        // and remove redelivery state as well
        redeliveryState.remove(aggregated.getExchangeId());
        // the completion was from timeout and we should just discard it
        answer = null;
    } else {
        // the aggregated exchange should be published (sent out)
        answer = aggregated;
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7146_b6981cfd,Trivial,camel-core/src/main/java/org/apache/camel/spi/AggregationRepository.java,41,41,"/**
 * Add the given {@link Exchange} under the correlation key.
 * <p/>
 * Will replace any existing exchange.
 *
 * @param camelContext   the current CamelContext
 * @param key            the correlation key
 * @param exchange       the aggregated exchange
 * @return the old exchange if any existed
 */
Exchange add(CamelContext camelContext, String key, Exchange exchange);"
camel,remotes/origin/bugs-dot-jar_CAMEL-7146_b6981cfd,Trivial,camel-core/src/main/java/org/apache/camel/spi/AggregationRepository.java,50,50,"/**
 * Gets the given exchange with the correlation key
 *
 * @param camelContext   the current CamelContext
 * @param key            the correlation key
 * @return the exchange, or <tt>null</tt> if no exchange was previously added
 */
Exchange get(CamelContext camelContext, String key);"
camel,remotes/origin/bugs-dot-jar_CAMEL-7146_b6981cfd,Trivial,camel-core/src/main/java/org/apache/camel/spi/AggregationRepository.java,60,60,"/**
 * Removes the exchange with the given correlation key, which should happen
 * when an {@link Exchange} is completed
 *
 * @param camelContext   the current CamelContext
 * @param key            the correlation key
 * @param exchange       the exchange to remove
 */
void remove(CamelContext camelContext, String key, Exchange exchange);"
camel,remotes/origin/bugs-dot-jar_CAMEL-7146_b6981cfd,Trivial,camel-core/src/main/java/org/apache/camel/spi/AggregationRepository.java,68,68,"/**
 * Confirms the completion of the {@link Exchange}.
 *
 * @param camelContext  the current CamelContext
 * @param exchangeId    exchange id to confirm
 */
void confirm(CamelContext camelContext, String exchangeId);"
camel,remotes/origin/bugs-dot-jar_CAMEL-7160_095fa2b4,Major,camel-core/src/main/java/org/apache/camel/processor/Throttler.java,105,133,"// Implementation methods
// -----------------------------------------------------------------------
protected long calculateDelay(Exchange exchange) {
    // evaluate as Object first to see if we get any result at all
    Object result = maxRequestsPerPeriodExpression.evaluate(exchange, Object.class);
    if (result == null) {
        throw new RuntimeExchangeException(""The max requests per period expression was evaluated as null: "" + maxRequestsPerPeriodExpression, exchange);
    }
    // then must convert value to long
    Long longValue = exchange.getContext().getTypeConverter().convertTo(Long.class, result);
    if (longValue != null) {
        // log if we changed max period after initial setting
        if (maximumRequestsPerPeriod > 0 && longValue.longValue() != maximumRequestsPerPeriod) {
            log.debug(""Throttler changed maximum requests per period from {} to {}"", maximumRequestsPerPeriod, longValue);
        }
        maximumRequestsPerPeriod = longValue;
    }
    if (maximumRequestsPerPeriod <= 0) {
        throw new IllegalStateException(""The maximumRequestsPerPeriod must be a positive number, was: "" + maximumRequestsPerPeriod);
    }
    TimeSlot slot = nextSlot();
    if (!slot.isActive()) {
        long delay = slot.startTime - currentSystemTime();
        return delay;
    } else {
        return 0;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7160_095fa2b4,Major,camel-core/src/main/java/org/apache/camel/processor/Throttler.java,138,147,"/*
     * Determine what the next available time slot is for handling an Exchange
     */
protected synchronized TimeSlot nextSlot() {
    if (slot == null) {
        slot = new TimeSlot();
    }
    if (slot.isFull() || !slot.isActive()) {
        slot = slot.next();
    }
    slot.assign();
    return slot;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7163_5f726d0b,Major,camel-core/src/main/java/org/apache/camel/api/management/mbean/ManagedBacklogDebuggerMBean.java,56,57,"@ManagedOperation(description = ""Updates the message body on the suspended breakpoint at the given node id"")
void setMessageBodyOnBreakpoint(String nodeId, String body);"
camel,remotes/origin/bugs-dot-jar_CAMEL-7163_5f726d0b,Major,camel-core/src/main/java/org/apache/camel/api/management/mbean/ManagedBacklogDebuggerMBean.java,59,60,"@ManagedOperation(description = ""Updates/adds the message header on the suspended breakpoint at the given node id"")
void setMessageHeaderOnBreakpoint(String nodeId, String headerName, String value);"
camel,remotes/origin/bugs-dot-jar_CAMEL-7163_5f726d0b,Major,camel-core/src/main/java/org/apache/camel/management/mbean/ManagedBacklogDebugger.java,94,96,"public void setMessageBodyOnBreakpoint(String nodeId, String body) {
    backlogDebugger.setMessageBodyOnBreakpoint(nodeId, body);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7163_5f726d0b,Major,camel-core/src/main/java/org/apache/camel/management/mbean/ManagedBacklogDebugger.java,98,100,"public void setMessageHeaderOnBreakpoint(String nodeId, String headerName, String value) {
    backlogDebugger.setMessageHeaderOnBreakpoint(nodeId, headerName, value);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7163_5f726d0b,Major,camel-core/src/main/java/org/apache/camel/processor/interceptor/BacklogDebugger.java,271,281,"public void setMessageBodyOnBreakpoint(String nodeId, String body) {
    SuspendedExchange se = suspendedBreakpoints.get(nodeId);
    if (se != null) {
        logger.log(""Breakpoint at node "" + nodeId + "" is updating message body on exchangeId: "" + se.getExchange().getExchangeId() + "" with new body: "" + body);
        if (se.getExchange().hasOut()) {
            se.getExchange().getOut().setBody(body);
        } else {
            se.getExchange().getIn().setBody(body);
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7163_5f726d0b,Major,camel-core/src/main/java/org/apache/camel/processor/interceptor/BacklogDebugger.java,283,293,"public void setMessageHeaderOnBreakpoint(String nodeId, String headerName, String value) {
    SuspendedExchange se = suspendedBreakpoints.get(nodeId);
    if (se != null) {
        logger.log(""Breakpoint at node "" + nodeId + "" is updating message header on exchangeId: "" + se.getExchange().getExchangeId() + "" with header: "" + headerName + "" and value: "" + value);
        if (se.getExchange().hasOut()) {
            se.getExchange().getOut().setHeader(headerName, value);
        } else {
            se.getExchange().getIn().setHeader(headerName, value);
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7167_1e33fcbc,Minor,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,742,786,"/**
 * Common work which must be done when we are done multicasting.
 * <p/>
 * This logic applies for both running synchronous and asynchronous as there are multiple exist points
 * when using the asynchronous routing engine. And therefore we want the logic in one method instead
 * of being scattered.
 *
 * @param original     the original exchange
 * @param subExchange  the current sub exchange, can be <tt>null</tt> for the synchronous part
 * @param pairs        the pairs with the exchanges to process
 * @param callback     the callback
 * @param doneSync     the <tt>doneSync</tt> parameter to call on callback
 * @param forceExhaust whether or not error handling is exhausted
 */
protected void doDone(Exchange original, Exchange subExchange, final Iterable<ProcessorExchangePair> pairs, AsyncCallback callback, boolean doneSync, boolean forceExhaust) {
    // we are done so close the pairs iterator
    if (pairs != null && pairs instanceof Closeable) {
        IOHelper.close((Closeable) pairs, ""pairs"", LOG);
    }
    // cleanup any per exchange aggregation strategy
    removeAggregationStrategyFromExchange(original);
    // we need to know if there was an exception, and if the stopOnException option was enabled
    // also we would need to know if any error handler has attempted redelivery and exhausted
    boolean stoppedOnException = false;
    boolean exception = false;
    boolean exhaust = forceExhaust || subExchange != null && (subExchange.getException() != null || ExchangeHelper.isRedeliveryExhausted(subExchange));
    if (original.getException() != null || subExchange != null && subExchange.getException() != null) {
        // there was an exception and we stopped
        stoppedOnException = isStopOnException();
        exception = true;
    }
    // must copy results at this point
    if (subExchange != null) {
        if (stoppedOnException) {
            // if we stopped due an exception then only propagte the exception
            original.setException(subExchange.getException());
        } else {
            // copy the current result to original so it will contain this result of this eip
            ExchangeHelper.copyResults(original, subExchange);
        }
    }
    // handled has been in use, then the exhaust would be false (if not forced)
    if (exception) {
        // multicast uses error handling on its output processors and they have tried to redeliver
        // so we shall signal back to the other error handlers that we are exhausted and they should not
        // also try to redeliver as we will then do that twice
        original.setProperty(Exchange.REDELIVERY_EXHAUSTED, exhaust);
    }
    callback.done(doneSync);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7209_5f78c646,Major,camel-core/src/main/java/org/apache/camel/converter/NIOConverter.java,84,103,"@Converter
public static ByteBuffer toByteBuffer(String value, Exchange exchange) {
    ByteBuffer buf = ByteBuffer.allocate(value.length());
    byte[] bytes = null;
    if (exchange != null) {
        String charsetName = exchange.getProperty(Exchange.CHARSET_NAME, String.class);
        if (charsetName != null) {
            try {
                bytes = value.getBytes(charsetName);
            } catch (UnsupportedEncodingException e) {
                LOG.warn(""Cannot convert the byte to String with the charset "" + charsetName, e);
            }
        }
    }
    if (bytes == null) {
        bytes = value.getBytes();
    }
    buf.put(bytes);
    return buf;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7213_336663c9,Major,camel-core/src/main/java/org/apache/camel/converter/NIOConverter.java,106,111,"@Converter
public static ByteBuffer toByteBuffer(Short value) {
    ByteBuffer buf = ByteBuffer.allocate(2);
    buf.putShort(value);
    return buf;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7213_336663c9,Major,camel-core/src/main/java/org/apache/camel/converter/NIOConverter.java,113,118,"@Converter
public static ByteBuffer toByteBuffer(Integer value) {
    ByteBuffer buf = ByteBuffer.allocate(4);
    buf.putInt(value);
    return buf;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7213_336663c9,Major,camel-core/src/main/java/org/apache/camel/converter/NIOConverter.java,120,125,"@Converter
public static ByteBuffer toByteBuffer(Long value) {
    ByteBuffer buf = ByteBuffer.allocate(8);
    buf.putLong(value);
    return buf;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7213_336663c9,Major,camel-core/src/main/java/org/apache/camel/converter/NIOConverter.java,127,132,"@Converter
public static ByteBuffer toByteBuffer(Float value) {
    ByteBuffer buf = ByteBuffer.allocate(4);
    buf.putFloat(value);
    return buf;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7213_336663c9,Major,camel-core/src/main/java/org/apache/camel/converter/NIOConverter.java,134,139,"@Converter
public static ByteBuffer toByteBuffer(Double value) {
    ByteBuffer buf = ByteBuffer.allocate(8);
    buf.putDouble(value);
    return buf;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7239_ae419224,Major,camel-core/src/main/java/org/apache/camel/processor/validation/ValidatingProcessor.java,191,196,"// Properties
// -----------------------------------------------------------------------
public Schema getSchema() throws IOException, SAXException {
    if (schema == null) {
        schema = createSchema();
    }
    return schema;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7239_ae419224,Major,camel-core/src/main/java/org/apache/camel/processor/validation/ValidatingProcessor.java,245,250,"public SchemaFactory getSchemaFactory() {
    if (schemaFactory == null) {
        schemaFactory = createSchemaFactory();
    }
    return schemaFactory;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7239_ae419224,Major,camel-core/src/main/java/org/apache/camel/processor/validation/ValidatingProcessor.java,334,354,"protected Schema createSchema() throws SAXException, IOException {
    SchemaFactory factory = getSchemaFactory();
    URL url = getSchemaUrl();
    if (url != null) {
        return factory.newSchema(url);
    }
    File file = getSchemaFile();
    if (file != null) {
        return factory.newSchema(file);
    }
    byte[] bytes = getSchemaAsByteArray();
    if (bytes != null) {
        return factory.newSchema(new StreamSource(new ByteArrayInputStream(schemaAsByteArray)));
    }
    Source source = getSchemaSource();
    return factory.newSchema(source);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7241_18c23fa8,Major,camel-core/src/main/java/org/apache/camel/converter/NIOConverter.java,55,58,"@Converter
public static String toString(ByteBuffer buffer, Exchange exchange) throws IOException {
    return IOConverter.toString(buffer.array(), exchange);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7271_a5a2f750,Major,camel-core/src/main/java/org/apache/camel/processor/aggregate/GroupedExchangeAggregationStrategy.java,44,53,"@Override
public Exchange aggregate(Exchange oldExchange, Exchange newExchange) {
    Exchange answer = super.aggregate(oldExchange, newExchange);
    if (oldExchange == null) {
        // for the first time we must do a copy as the answer, so the outgoing
        // exchange is not one of the grouped exchanges, as that causes a endless circular reference
        answer = answer.copy();
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7275_44cad623,Major,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,885,934,"protected Processor createErrorHandler(RouteContext routeContext, Exchange exchange, Processor processor) {
    Processor answer;
    if (routeContext != null) {
        // wrap the producer in error handler so we have fine grained error handling on
        // the output side instead of the input side
        // this is needed to support redelivery on that output alone and not doing redelivery
        // for the entire multicast block again which will start from scratch again
        // create key for cache
        final PreparedErrorHandler key = new PreparedErrorHandler(routeContext, processor);
        // lookup cached first to reuse and preserve memory
        answer = errorHandlers.get(key);
        if (answer != null) {
            LOG.trace(""Using existing error handler for: {}"", processor);
            return answer;
        }
        LOG.trace(""Creating error handler for: {}"", processor);
        ErrorHandlerFactory builder = routeContext.getRoute().getErrorHandlerBuilder();
        // instead of using ProcessorDefinition.wrapInErrorHandler)
        try {
            processor = builder.createErrorHandler(routeContext, processor);
            // and wrap in unit of work processor so the copy exchange also can run under UoW
            answer = createUnitOfWorkProcessor(routeContext, processor, exchange);
            boolean child = exchange.getProperty(Exchange.PARENT_UNIT_OF_WORK, UnitOfWork.class) != null;
            // must start the error handler
            ServiceHelper.startServices(answer);
            // here we don't cache the child unit of work
            if (!child) {
                // add to cache
                errorHandlers.putIfAbsent(key, answer);
            }
        } catch (Exception e) {
            throw ObjectHelper.wrapRuntimeCamelException(e);
        }
    } else {
        // and wrap in unit of work processor so the copy exchange also can run under UoW
        answer = createUnitOfWorkProcessor(routeContext, processor, exchange);
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7275_44cad623,Major,camel-core/src/main/java/org/apache/camel/processor/TryProcessor.java,69,99,"public boolean process(Exchange exchange, AsyncCallback callback) {
    Iterator<Processor> processors = next().iterator();
    Object lastHandled = exchange.getProperty(Exchange.EXCEPTION_HANDLED);
    exchange.setProperty(Exchange.EXCEPTION_HANDLED, null);
    while (continueRouting(processors, exchange)) {
        ExchangeHelper.prepareOutToIn(exchange);
        // process the next processor
        Processor processor = processors.next();
        AsyncProcessor async = AsyncProcessorConverterHelper.convert(processor);
        boolean sync = process(exchange, callback, processors, async, lastHandled);
        // continue as long its being processed synchronously
        if (!sync) {
            LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", exchange.getExchangeId());
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return false;
        }
        LOG.trace(""Processing exchangeId: {} is continued being processed synchronously"", exchange.getExchangeId());
    }
    ExchangeHelper.prepareOutToIn(exchange);
    exchange.setProperty(Exchange.EXCEPTION_HANDLED, lastHandled);
    LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
    callback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7275_44cad623,Major,camel-core/src/main/java/org/apache/camel/processor/TryProcessor.java,101,140,"protected boolean process(final Exchange exchange, final AsyncCallback callback, final Iterator<Processor> processors, final AsyncProcessor processor, final Object lastHandled) {
    // this does the actual processing so log at trace level
    LOG.trace(""Processing exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
    // implement asynchronous routing logic in callback so we can have the callback being
    // triggered and then continue routing where we left
    boolean sync = processor.process(exchange, new AsyncCallback() {

        public void done(boolean doneSync) {
            // we only have to handle async completion of the pipeline
            if (doneSync) {
                return;
            }
            // continue processing the try .. catch .. finally asynchronously
            while (continueRouting(processors, exchange)) {
                ExchangeHelper.prepareOutToIn(exchange);
                // process the next processor
                AsyncProcessor processor = AsyncProcessorConverterHelper.convert(processors.next());
                doneSync = process(exchange, callback, processors, processor, lastHandled);
                if (!doneSync) {
                    LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", exchange.getExchangeId());
                    // so we break out now, then the callback will be invoked which then continue routing from where we left here
                    return;
                }
            }
            ExchangeHelper.prepareOutToIn(exchange);
            exchange.setProperty(Exchange.EXCEPTION_HANDLED, lastHandled);
            LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
            callback.done(false);
        }
    });
    return sync;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7275_44cad623,Major,camel-core/src/main/java/org/apache/camel/processor/TryProcessor.java,110,136,"public void done(boolean doneSync) {
    // we only have to handle async completion of the pipeline
    if (doneSync) {
        return;
    }
    // continue processing the try .. catch .. finally asynchronously
    while (continueRouting(processors, exchange)) {
        ExchangeHelper.prepareOutToIn(exchange);
        // process the next processor
        AsyncProcessor processor = AsyncProcessorConverterHelper.convert(processors.next());
        doneSync = process(exchange, callback, processors, processor, lastHandled);
        if (!doneSync) {
            LOG.trace(""Processing exchangeId: {} is continued being processed asynchronously"", exchange.getExchangeId());
            // so we break out now, then the callback will be invoked which then continue routing from where we left here
            return;
        }
    }
    ExchangeHelper.prepareOutToIn(exchange);
    exchange.setProperty(Exchange.EXCEPTION_HANDLED, lastHandled);
    LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
    callback.done(false);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7304_fa165d6b,Minor,camel-core/src/main/java/org/apache/camel/model/InterceptSendToEndpointDefinition.java,87,121,"@Override
public Processor createProcessor(final RouteContext routeContext) throws Exception {
    // create the detour
    final Processor detour = this.createChildProcessor(routeContext, true);
    // register endpoint callback so we can proxy the endpoint
    routeContext.getCamelContext().addRegisterEndpointCallback(new EndpointStrategy() {

        public Endpoint registerEndpoint(String uri, Endpoint endpoint) {
            if (endpoint instanceof InterceptSendToEndpoint) {
                // endpoint already decorated
                return endpoint;
            } else if (getUri() == null || EndpointHelper.matchEndpoint(routeContext.getCamelContext(), uri, getUri())) {
                // only proxy if the uri is matched decorate endpoint with our proxy
                // should be false by default
                boolean skip = isSkipSendToOriginalEndpoint();
                InterceptSendToEndpoint proxy = new InterceptSendToEndpoint(endpoint, skip);
                proxy.setDetour(detour);
                return proxy;
            } else {
                // no proxy so return regular endpoint
                return endpoint;
            }
        }
    });
    // remove the original intercepted route from the outputs as we do not intercept as the regular interceptor
    // instead we use the proxy endpoints producer do the triggering. That is we trigger when someone sends
    // an exchange to the endpoint, see InterceptSendToEndpoint for details.
    RouteDefinition route = routeContext.getRoute();
    List<ProcessorDefinition<?>> outputs = route.getOutputs();
    outputs.remove(this);
    return new InterceptEndpointProcessor(uri, detour);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7304_fa165d6b,Minor,camel-core/src/main/java/org/apache/camel/model/InterceptSendToEndpointDefinition.java,94,109,"public Endpoint registerEndpoint(String uri, Endpoint endpoint) {
    if (endpoint instanceof InterceptSendToEndpoint) {
        // endpoint already decorated
        return endpoint;
    } else if (getUri() == null || EndpointHelper.matchEndpoint(routeContext.getCamelContext(), uri, getUri())) {
        // only proxy if the uri is matched decorate endpoint with our proxy
        // should be false by default
        boolean skip = isSkipSendToOriginalEndpoint();
        InterceptSendToEndpoint proxy = new InterceptSendToEndpoint(endpoint, skip);
        proxy.setDetour(detour);
        return proxy;
    } else {
        // no proxy so return regular endpoint
        return endpoint;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7344_91228815,Major,camel-core/src/main/java/org/apache/camel/impl/DefaultEndpoint.java,137,140,"@Override
public String toString() {
    return String.format(""Endpoint[%s]"", URISupport.sanitizeUri(getEndpointUri()));
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7359_9cb09d14,Major,camel-core/src/main/java/org/apache/camel/language/simple/ast/SimpleFunctionExpression.java,193,302,"private Expression createSimpleExpressionBodyOrHeader(String function, boolean strict) {
    // bodyAs
    String remainder = ifStartsWithReturnRemainder(""bodyAs"", function);
    if (remainder != null) {
        String type = ObjectHelper.between(remainder, ""("", "")"");
        remainder = ObjectHelper.after(remainder, "")"");
        if (type == null || ObjectHelper.isNotEmpty(remainder)) {
            throw new SimpleParserException(""Valid syntax: ${bodyAs(type)} was: "" + function, token.getIndex());
        }
        type = StringHelper.removeQuotes(type);
        return ExpressionBuilder.bodyExpression(type);
    }
    // mandatoryBodyAs
    remainder = ifStartsWithReturnRemainder(""mandatoryBodyAs"", function);
    if (remainder != null) {
        String type = ObjectHelper.between(remainder, ""("", "")"");
        remainder = ObjectHelper.after(remainder, "")"");
        if (type == null || ObjectHelper.isNotEmpty(remainder)) {
            throw new SimpleParserException(""Valid syntax: ${mandatoryBodyAs(type)} was: "" + function, token.getIndex());
        }
        type = StringHelper.removeQuotes(type);
        return ExpressionBuilder.mandatoryBodyExpression(type);
    }
    // body OGNL
    remainder = ifStartsWithReturnRemainder(""body"", function);
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""in.body"", function);
    }
    if (remainder != null) {
        boolean invalid = OgnlHelper.isInvalidValidOgnlExpression(remainder);
        if (invalid) {
            throw new SimpleParserException(""Valid syntax: ${body.OGNL} was: "" + function, token.getIndex());
        }
        return ExpressionBuilder.bodyOgnlExpression(remainder);
    }
    // headerAs
    remainder = ifStartsWithReturnRemainder(""headerAs"", function);
    if (remainder != null) {
        String keyAndType = ObjectHelper.between(remainder, ""("", "")"");
        if (keyAndType == null) {
            throw new SimpleParserException(""Valid syntax: ${headerAs(key, type)} was: "" + function, token.getIndex());
        }
        String key = ObjectHelper.before(keyAndType, "","");
        String type = ObjectHelper.after(keyAndType, "","");
        if (ObjectHelper.isEmpty(key) || ObjectHelper.isEmpty(type)) {
            throw new SimpleParserException(""Valid syntax: ${headerAs(key, type)} was: "" + function, token.getIndex());
        }
        key = StringHelper.removeQuotes(key);
        type = StringHelper.removeQuotes(type);
        return ExpressionBuilder.headerExpression(key, type);
    }
    // headers function
    if (""in.headers"".equals(function) || ""headers"".equals(function)) {
        return ExpressionBuilder.headersExpression();
    }
    // in header function
    remainder = ifStartsWithReturnRemainder(""in.headers"", function);
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""in.header"", function);
    }
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""headers"", function);
    }
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""header"", function);
    }
    if (remainder != null) {
        // remove leading character (dot or ?)
        if (remainder.startsWith(""."") || remainder.startsWith(""?"")) {
            remainder = remainder.substring(1);
        }
        // remove starting and ending brackets
        if (remainder.startsWith(""["") && remainder.endsWith(""]"")) {
            remainder = remainder.substring(1, remainder.length() - 1);
        }
        // remove quotes from key
        String key = StringHelper.removeLeadingAndEndingQuotes(remainder);
        // validate syntax
        boolean invalid = OgnlHelper.isInvalidValidOgnlExpression(key);
        if (invalid) {
            throw new SimpleParserException(""Valid syntax: ${header.name[key]} was: "" + function, token.getIndex());
        }
        if (OgnlHelper.isValidOgnlExpression(key)) {
            // ognl based header
            return ExpressionBuilder.headersOgnlExpression(key);
        } else {
            // regular header
            return ExpressionBuilder.headerExpression(key);
        }
    }
    // out header function
    remainder = ifStartsWithReturnRemainder(""out.header."", function);
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""out.headers."", function);
    }
    if (remainder != null) {
        return ExpressionBuilder.outHeaderExpression(remainder);
    }
    return null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7359_e6fbbf04,Major,camel-core/src/main/java/org/apache/camel/language/simple/ast/SimpleFunctionExpression.java,193,299,"private Expression createSimpleExpressionBodyOrHeader(String function, boolean strict) {
    // bodyAs
    String remainder = ifStartsWithReturnRemainder(""bodyAs"", function);
    if (remainder != null) {
        String type = ObjectHelper.between(remainder, ""("", "")"");
        if (type == null) {
            throw new SimpleParserException(""Valid syntax: ${bodyAs(type)} was: "" + function, token.getIndex());
        }
        type = StringHelper.removeQuotes(type);
        return ExpressionBuilder.bodyExpression(type);
    }
    // mandatoryBodyAs
    remainder = ifStartsWithReturnRemainder(""mandatoryBodyAs"", function);
    if (remainder != null) {
        String type = ObjectHelper.between(remainder, ""("", "")"");
        if (type == null) {
            throw new SimpleParserException(""Valid syntax: ${mandatoryBodyAs(type)} was: "" + function, token.getIndex());
        }
        type = StringHelper.removeQuotes(type);
        return ExpressionBuilder.mandatoryBodyExpression(type);
    }
    // body OGNL
    remainder = ifStartsWithReturnRemainder(""body"", function);
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""in.body"", function);
    }
    if (remainder != null) {
        boolean invalid = OgnlHelper.isInvalidValidOgnlExpression(remainder);
        if (invalid) {
            throw new SimpleParserException(""Valid syntax: ${body.OGNL} was: "" + function, token.getIndex());
        }
        return ExpressionBuilder.bodyOgnlExpression(remainder);
    }
    // headerAs
    remainder = ifStartsWithReturnRemainder(""headerAs"", function);
    if (remainder != null) {
        String keyAndType = ObjectHelper.between(remainder, ""("", "")"");
        if (keyAndType == null) {
            throw new SimpleParserException(""Valid syntax: ${headerAs(key, type)} was: "" + function, token.getIndex());
        }
        String key = ObjectHelper.before(keyAndType, "","");
        String type = ObjectHelper.after(keyAndType, "","");
        if (ObjectHelper.isEmpty(key) || ObjectHelper.isEmpty(type)) {
            throw new SimpleParserException(""Valid syntax: ${headerAs(key, type)} was: "" + function, token.getIndex());
        }
        key = StringHelper.removeQuotes(key);
        type = StringHelper.removeQuotes(type);
        return ExpressionBuilder.headerExpression(key, type);
    }
    // headers function
    if (""in.headers"".equals(function) || ""headers"".equals(function)) {
        return ExpressionBuilder.headersExpression();
    }
    // in header function
    remainder = ifStartsWithReturnRemainder(""in.headers"", function);
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""in.header"", function);
    }
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""headers"", function);
    }
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""header"", function);
    }
    if (remainder != null) {
        // remove leading character (dot or ?)
        if (remainder.startsWith(""."") || remainder.startsWith(""?"")) {
            remainder = remainder.substring(1);
        }
        // remove starting and ending brackets
        if (remainder.startsWith(""["") && remainder.endsWith(""]"")) {
            remainder = remainder.substring(1, remainder.length() - 1);
        }
        // remove quotes from key
        String key = StringHelper.removeLeadingAndEndingQuotes(remainder);
        // validate syntax
        boolean invalid = OgnlHelper.isInvalidValidOgnlExpression(key);
        if (invalid) {
            throw new SimpleParserException(""Valid syntax: ${header.name[key]} was: "" + function, token.getIndex());
        }
        if (OgnlHelper.isValidOgnlExpression(key)) {
            // ognl based header
            return ExpressionBuilder.headersOgnlExpression(key);
        } else {
            // regular header
            return ExpressionBuilder.headerExpression(key);
        }
    }
    // out header function
    remainder = ifStartsWithReturnRemainder(""out.header."", function);
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""out.headers."", function);
    }
    if (remainder != null) {
        return ExpressionBuilder.outHeaderExpression(remainder);
    }
    return null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7364_7bbb88ba,Major,camel-core/src/main/java/org/apache/camel/model/rest/RestConfigurationDefinition.java,99,105,"public RestConfigurationDefinition property(String key, String value) {
    /*PropertyDefinition prop = new PropertyDefinition();
        prop.setKey(key);
        prop.setValue(value);
        getProperties().add(prop);*/
    return this;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7364_7bbb88ba,Major,camel-core/src/main/java/org/apache/camel/model/rest/RestConfigurationDefinition.java,117,139,"// Implementation
// -------------------------------------------------------------------------
/**
 * Creates a {@link org.apache.camel.spi.RestConfiguration} instance based on the definition
 *
 * @param context     the camel context
 * @return the configuration
 * @throws Exception is thrown if error creating the configuration
 */
public RestConfiguration asRestConfiguration(CamelContext context) throws Exception {
    RestConfiguration answer = new RestConfiguration();
    if (getComponent() != null) {
        answer.setComponent(CamelContextHelper.parseText(context, getComponent()));
    }
    if (getHost() != null) {
        answer.setHost(CamelContextHelper.parseText(context, getHost()));
    }
    if (getPort() != null) {
        answer.setPort(CamelContextHelper.parseInteger(context, getPort()));
    }
    /*if (!properties.isEmpty()) {
            Map<String, Object> props = new HashMap<String, Object>();
            for (PropertyDefinition prop : properties) {
                String key = prop.getKey();
                String value = CamelContextHelper.parseText(context, prop.getValue());
                props.put(key, value);
            }
            answer.setProperties(props);
        }*/
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7418_cabee0e9,Minor,camel-core/src/main/java/org/apache/camel/impl/JndiRegistry.java,75,91,"public <T> Map<String, T> findByTypeWithName(Class<T> type) {
    Map<String, T> answer = new LinkedHashMap<String, T>();
    try {
        NamingEnumeration<NameClassPair> list = getContext().list("""");
        while (list.hasMore()) {
            NameClassPair pair = list.next();
            if (type.isInstance(pair.getClass()) || type.getName().equals(pair.getClassName())) {
                Object instance = context.lookup(pair.getName());
                answer.put(pair.getName(), type.cast(instance));
            }
        }
    } catch (NamingException e) {
    // ignore
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7418_cabee0e9,Minor,camel-core/src/main/java/org/apache/camel/impl/JndiRegistry.java,93,108,"public <T> Set<T> findByType(Class<T> type) {
    Set<T> answer = new LinkedHashSet<T>();
    try {
        NamingEnumeration<NameClassPair> list = getContext().list("""");
        while (list.hasMore()) {
            NameClassPair pair = list.next();
            if (type.isInstance(pair.getClass()) || type.getName().equals(pair.getClassName())) {
                Object instance = context.lookup(pair.getName());
                answer.add(type.cast(instance));
            }
        }
    } catch (NamingException e) {
    // ignore
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7429_43956f93,Major,camel-core/src/main/java/org/apache/camel/component/properties/DefaultPropertiesParser.java,41,66,"public String parseUri(String text, Properties properties, String prefixToken, String suffixToken, String propertyPrefix, String propertySuffix, boolean fallbackToUnaugmentedProperty) throws IllegalArgumentException {
    String answer = text;
    boolean done = false;
    // the placeholders can contain nested placeholders so we need to do recursive parsing
    // we must therefore also do circular reference check and must keep a list of visited keys
    List<String> visited = new ArrayList<String>();
    while (!done) {
        List<String> replaced = new ArrayList<String>();
        answer = doParseUri(answer, properties, replaced, prefixToken, suffixToken, propertyPrefix, propertySuffix, fallbackToUnaugmentedProperty);
        // check the replaced with the visited to avoid circular reference
        for (String replace : replaced) {
            if (visited.contains(replace)) {
                throw new IllegalArgumentException(""Circular reference detected with key ["" + replace + ""] from text: "" + text);
            }
        }
        // okay all okay so add the replaced as visited
        visited.addAll(replaced);
        // we are done when we can no longer find any prefix tokens in the answer
        done = findTokenPosition(answer, 0, prefixToken) == -1;
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7429_43956f93,Major,camel-core/src/main/java/org/apache/camel/component/properties/DefaultPropertiesParser.java,72,127,"private String doParseUri(String uri, Properties properties, List<String> replaced, String prefixToken, String suffixToken, String propertyPrefix, String propertySuffix, boolean fallbackToUnaugmentedProperty) {
    StringBuilder sb = new StringBuilder();
    int pivot = 0;
    int size = uri.length();
    while (pivot < size) {
        int idx = findTokenPosition(uri, pivot, prefixToken);
        if (idx < 0) {
            sb.append(createConstantPart(uri, pivot, size));
            break;
        } else {
            if (pivot < idx) {
                sb.append(createConstantPart(uri, pivot, idx));
            }
            pivot = idx + prefixToken.length();
            int endIdx = findTokenPosition(uri, pivot, suffixToken);
            if (endIdx < 0) {
                throw new IllegalArgumentException(""Expecting "" + suffixToken + "" but found end of string from text: "" + uri);
            }
            String key = uri.substring(pivot, endIdx);
            String augmentedKey = key;
            if (propertyPrefix != null) {
                log.debug(""Augmenting property key [{}] with prefix: {}"", key, propertyPrefix);
                augmentedKey = propertyPrefix + augmentedKey;
            }
            if (propertySuffix != null) {
                log.debug(""Augmenting property key [{}] with suffix: {}"", key, propertySuffix);
                augmentedKey = augmentedKey + propertySuffix;
            }
            String part = createPlaceholderPart(augmentedKey, properties, replaced, prefixToken, suffixToken);
            // Note: Only fallback to unaugmented when the original key was actually augmented
            if (part == null && fallbackToUnaugmentedProperty && (propertyPrefix != null || propertySuffix != null)) {
                log.debug(""Property wth key [{}] not found, attempting with unaugmented key: {}"", augmentedKey, key);
                part = createPlaceholderPart(key, properties, replaced, prefixToken, suffixToken);
            }
            if (part == null) {
                StringBuilder esb = new StringBuilder();
                esb.append(""Property with key ["").append(augmentedKey).append(""] "");
                if (fallbackToUnaugmentedProperty && (propertyPrefix != null || propertySuffix != null)) {
                    esb.append(""(and original key ["").append(key).append(""]) "");
                }
                esb.append(""not found in properties from text: "").append(uri);
                throw new IllegalArgumentException(esb.toString());
            }
            sb.append(part);
            pivot = endIdx + suffixToken.length();
        }
    }
    return sb.toString();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7429_43956f93,Major,camel-core/src/main/java/org/apache/camel/component/properties/DefaultPropertiesParser.java,129,149,"private int findTokenPosition(String uri, int pivot, String token) {
    int idx = uri.indexOf(token, pivot);
    while (idx > 0) {
        // grab part as the previous char + token + next char, to test if the token is quoted
        String part = null;
        int len = idx + token.length() + 1;
        if (uri.length() >= len) {
            part = uri.substring(idx - 1, len);
        }
        if (StringHelper.isQuoted(part)) {
            // the token was quoted, so regard it as a literal
            // and then try to find from next position
            pivot = idx + token.length() + 1;
            idx = uri.indexOf(token, pivot);
        } else {
            // found token
            return idx;
        }
    }
    return idx;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7429_43956f93,Major,camel-core/src/main/java/org/apache/camel/component/properties/DefaultPropertiesParser.java,151,159,"private boolean isNestProperty(String uri, String prefixToken, String suffixToken) {
    if (ObjectHelper.isNotEmpty(uri)) {
        uri = uri.trim();
        if (uri.startsWith(prefixToken) && uri.endsWith(suffixToken)) {
            return true;
        }
    }
    return false;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7429_43956f93,Major,camel-core/src/main/java/org/apache/camel/component/properties/DefaultPropertiesParser.java,161,165,"private String takeOffNestTokes(String uri, String prefixToken, String suffixToken) {
    int start = prefixToken.length();
    int end = uri.length() - suffixToken.length();
    return uri.substring(start, end);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7429_43956f93,Major,camel-core/src/main/java/org/apache/camel/component/properties/DefaultPropertiesParser.java,167,169,"private String createConstantPart(String uri, int start, int end) {
    return uri.substring(start, end);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7429_43956f93,Major,camel-core/src/main/java/org/apache/camel/component/properties/DefaultPropertiesParser.java,171,202,"private String createPlaceholderPart(String key, Properties properties, List<String> replaced, String prefixToken, String suffixToken) {
    // keep track of which parts we have replaced
    replaced.add(key);
    String propertyValue = System.getProperty(key);
    if (propertyValue != null) {
        log.debug(""Found a JVM system property: {} with value: {} to be used."", key, propertyValue);
    } else if (properties != null) {
        propertyValue = properties.getProperty(key);
    }
    // we need to check if the propertyValue is nested
    // we need to check if there is cycle dependency of the nested properties
    List<String> visited = new ArrayList<String>();
    while (isNestProperty(propertyValue, prefixToken, suffixToken)) {
        visited.add(key);
        // need to take off the token first
        String value = takeOffNestTokes(propertyValue, prefixToken, suffixToken);
        key = parseUri(value, properties, prefixToken, suffixToken);
        if (visited.contains(key)) {
            throw new IllegalArgumentException(""Circular reference detected with key ["" + key + ""] from text: "" + propertyValue);
        }
        propertyValue = System.getProperty(key);
        if (propertyValue != null) {
            log.debug(""Found a JVM system property: {} with value: {} to be used."", key, propertyValue);
        } else if (properties != null) {
            propertyValue = properties.getProperty(key);
        }
    }
    return parseProperty(key, propertyValue, properties);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7448_35bde2b2,Minor,camel-core/src/main/java/org/apache/camel/processor/Throttler.java,108,139,"// Implementation methods
// -----------------------------------------------------------------------
protected long calculateDelay(Exchange exchange) {
    // evaluate as Object first to see if we get any result at all
    Object result = maxRequestsPerPeriodExpression.evaluate(exchange, Object.class);
    if (result == null) {
        throw new RuntimeExchangeException(""The max requests per period expression was evaluated as null: "" + maxRequestsPerPeriodExpression, exchange);
    }
    // then must convert value to long
    Long longValue = exchange.getContext().getTypeConverter().convertTo(Long.class, result);
    if (longValue != null) {
        // log if we changed max period after initial setting
        if (maximumRequestsPerPeriod > 0 && longValue.longValue() != maximumRequestsPerPeriod) {
            log.debug(""Throttler changed maximum requests per period from {} to {}"", maximumRequestsPerPeriod, longValue);
        }
        if (maximumRequestsPerPeriod > longValue) {
            slot.capacity = 0;
        }
        maximumRequestsPerPeriod = longValue;
    }
    if (maximumRequestsPerPeriod <= 0) {
        throw new IllegalStateException(""The maximumRequestsPerPeriod must be a positive number, was: "" + maximumRequestsPerPeriod);
    }
    TimeSlot slot = nextSlot();
    if (!slot.isActive()) {
        long delay = slot.startTime - currentSystemTime();
        return delay;
    } else {
        return 0;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7456_02da984a,Minor,camel-core/src/main/java/org/apache/camel/component/properties/PropertiesComponent.java,205,207,"public void setPropertyPrefix(String propertyPrefix) {
    this.propertyPrefix = propertyPrefix;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7456_02da984a,Minor,camel-core/src/main/java/org/apache/camel/component/properties/PropertiesComponent.java,213,215,"public void setPropertySuffix(String propertySuffix) {
    this.propertySuffix = propertySuffix;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7459_57ba1bde,Minor,camel-core/src/main/java/org/apache/camel/util/URISupport.java,127,232,"/**
 * Parses the query part of the uri (eg the parameters).
 * <p/>
 * The URI parameters will by default be URI encoded. However you can define a parameter
 * values with the syntax: <tt>key=RAW(value)</tt> which tells Camel to not encode the value,
 * and use the value as is (eg key=value) and the value has <b>not</b> been encoded.
 *
 * @param uri the uri
 * @param useRaw whether to force using raw values
 * @return the parameters, or an empty map if no parameters (eg never null)
 * @throws URISyntaxException is thrown if uri has invalid syntax.
 * @see #RAW_TOKEN_START
 * @see #RAW_TOKEN_END
 */
public static Map<String, Object> parseQuery(String uri, boolean useRaw) throws URISyntaxException {
    // must check for trailing & as the uri.split(""&"") will ignore those
    if (uri != null && uri.endsWith(""&"")) {
        throw new URISyntaxException(uri, ""Invalid uri syntax: Trailing & marker found. "" + ""Check the uri and remove the trailing & marker."");
    }
    if (ObjectHelper.isEmpty(uri)) {
        // return an empty map
        return new LinkedHashMap<String, Object>(0);
    }
    try {
        // use a linked map so the parameters is in the same order
        Map<String, Object> rc = new LinkedHashMap<String, Object>();
        boolean isKey = true;
        boolean isValue = false;
        boolean isRaw = false;
        StringBuilder key = new StringBuilder();
        StringBuilder value = new StringBuilder();
        // parse the uri parameters char by char
        for (int i = 0; i < uri.length(); i++) {
            // current char
            char ch = uri.charAt(i);
            // look ahead of the next char
            char next;
            if (i < uri.length() - 2) {
                next = uri.charAt(i + 1);
            } else {
                next = '\u0000';
            }
            // are we a raw value
            isRaw = value.toString().startsWith(RAW_TOKEN_START);
            // if we are in raw mode, then we keep adding until we hit the end marker
            if (isRaw) {
                if (isKey) {
                    key.append(ch);
                } else if (isValue) {
                    value.append(ch);
                }
                // we only end the raw marker if its )& or at the end of the value
                boolean end = ch == RAW_TOKEN_END.charAt(0) && (next == '&' || next == '\u0000');
                if (end) {
                    // raw value end, so add that as a parameter, and reset flags
                    addParameter(key.toString(), value.toString(), rc, useRaw || isRaw);
                    key.setLength(0);
                    value.setLength(0);
                    isKey = true;
                    isValue = false;
                    isRaw = false;
                    // skip to next as we are in raw mode and have already added the value
                    i++;
                }
                continue;
            }
            // if its a key and there is a = sign then the key ends and we are in value mode
            if (isKey && ch == '=') {
                isKey = false;
                isValue = true;
                isRaw = false;
                continue;
            }
            // the & denote parameter is ended
            if (ch == '&') {
                // parameter is ended, as we hit & separator
                addParameter(key.toString(), value.toString(), rc, useRaw || isRaw);
                key.setLength(0);
                value.setLength(0);
                isKey = true;
                isValue = false;
                isRaw = false;
                continue;
            }
            // regular char so add it to the key or value
            if (isKey) {
                key.append(ch);
            } else if (isValue) {
                value.append(ch);
            }
        }
        // any left over parameters, then add that
        if (key.length() > 0) {
            addParameter(key.toString(), value.toString(), rc, useRaw || isRaw);
        }
        return rc;
    } catch (UnsupportedEncodingException e) {
        URISyntaxException se = new URISyntaxException(e.toString(), ""Invalid encoding"");
        se.initCause(e);
        throw se;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7478_69b00a31,Major,camel-core/src/main/java/org/apache/camel/component/bean/BeanInfo.java,183,283,"private MethodInvocation createInvocation(Object pojo, Exchange exchange, Method explicitMethod) throws AmbiguousMethodCallException, MethodNotFoundException {
    MethodInfo methodInfo = null;
    // find the explicit method to invoke
    if (explicitMethod != null) {
        Iterator<List<MethodInfo>> it = operations.values().iterator();
        while (it.hasNext()) {
            List<MethodInfo> infos = it.next();
            for (MethodInfo info : infos) {
                if (explicitMethod.equals(info.getMethod())) {
                    return info.createMethodInvocation(pojo, exchange);
                }
            }
        }
        throw new MethodNotFoundException(exchange, pojo, explicitMethod.getName());
    }
    String methodName = exchange.getIn().getHeader(Exchange.BEAN_METHOD_NAME, String.class);
    if (methodName != null) {
        // do not use qualifier for name
        String name = methodName;
        if (methodName.contains(""("")) {
            name = ObjectHelper.before(methodName, ""("");
        }
        boolean emptyParameters = methodName.endsWith(""()"");
        // for example to log the class type or the likes
        if (""class"".equals(name) || ""getClass"".equals(name)) {
            try {
                Method method = pojo.getClass().getMethod(""getClass"");
                methodInfo = new MethodInfo(exchange.getContext(), pojo.getClass(), method, Collections.<ParameterInfo>emptyList(), Collections.<ParameterInfo>emptyList(), false, false);
            } catch (NoSuchMethodException e) {
                throw new MethodNotFoundException(exchange, pojo, ""getClass"");
            }
        // special for length on an array type
        } else if (""length"".equals(name) && pojo.getClass().isArray()) {
            try {
                // need to use arrayLength method from ObjectHelper as Camel's bean OGNL support is method invocation based
                // and not for accessing fields. And hence we need to create a MethodInfo instance with a method to call
                // and therefore use arrayLength from ObjectHelper to return the array length field.
                Method method = ObjectHelper.class.getMethod(""arrayLength"", Object[].class);
                ParameterInfo pi = new ParameterInfo(0, Object[].class, null, ExpressionBuilder.mandatoryBodyExpression(Object[].class, true));
                List<ParameterInfo> lpi = new ArrayList<ParameterInfo>(1);
                lpi.add(pi);
                methodInfo = new MethodInfo(exchange.getContext(), pojo.getClass(), method, lpi, lpi, false, false);
            } catch (NoSuchMethodException e) {
                throw new MethodNotFoundException(exchange, pojo, ""getClass"");
            }
        } else {
            List<MethodInfo> methods = getOperations(name);
            if (methods != null && methods.size() == 1) {
                // only one method then choose it
                methodInfo = methods.get(0);
                // validate that if we want an explict no-arg method, then that's what we get
                if (emptyParameters && methodInfo.hasParameters()) {
                    throw new MethodNotFoundException(exchange, pojo, methodName, ""(with no parameters)"");
                }
            } else if (methods != null) {
                // there are more methods with that name so we cannot decide which to use
                // but first let's try to choose a method and see if that complies with the name
                // must use the method name which may have qualifiers
                methodInfo = chooseMethod(pojo, exchange, methodName);
                // validate that if we want an explicit no-arg method, then that's what we get
                if (emptyParameters) {
                    if (methodInfo == null || methodInfo.hasParameters()) {
                        // we could not find a no-arg method with that name
                        throw new MethodNotFoundException(exchange, pojo, methodName, ""(with no parameters)"");
                    }
                }
                if (methodInfo == null || !name.equals(methodInfo.getMethod().getName())) {
                    throw new AmbiguousMethodCallException(exchange, methods);
                }
            } else {
                // a specific method was given to invoke but not found
                throw new MethodNotFoundException(exchange, pojo, methodName);
            }
        }
    }
    if (methodInfo == null) {
        // no name or type
        methodInfo = chooseMethod(pojo, exchange, null);
    }
    if (methodInfo == null) {
        methodInfo = defaultMethod;
    }
    if (methodInfo != null) {
        LOG.trace(""Chosen method to invoke: {} on bean: {}"", methodInfo, pojo);
        return methodInfo.createMethodInvocation(pojo, exchange);
    }
    LOG.debug(""Cannot find suitable method to invoke on bean: {}"", pojo);
    return null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7478_69b00a31,Major,camel-core/src/main/java/org/apache/camel/language/bean/BeanExpression.java,233,306,"public void process(Exchange exchange) throws Exception {
    // copy the original exchange to avoid side effects on it
    Exchange resultExchange = exchange.copy();
    // remove any existing exception in case we do OGNL on the exception
    resultExchange.setException(null);
    // force to use InOut to retrieve the result on the OUT message
    resultExchange.setPattern(ExchangePattern.InOut);
    // do not propagate any method name when using OGNL, as with OGNL we
    // compute and provide the method name to explicit to invoke
    resultExchange.getIn().removeHeader(Exchange.BEAN_METHOD_NAME);
    // current ognl path as we go along
    String ognlPath = """";
    // loop and invoke each method
    Object beanToCall = beanHolder.getBean();
    // there must be a bean to call with, we currently does not support OGNL expressions on using purely static methods
    if (beanToCall == null) {
        throw new IllegalArgumentException(""Bean instance is null. OGNL bean expressions requires bean instances."");
    }
    // Split ognl except when this is not a Map, Array
    // and we would like to keep the dots within the key name
    List<String> methods = OgnlHelper.splitOgnl(ognl);
    for (String methodName : methods) {
        BeanHolder holder = new ConstantBeanHolder(beanToCall, exchange.getContext());
        // support the null safe operator
        boolean nullSafe = OgnlHelper.isNullSafeOperator(methodName);
        // keep up with how far are we doing
        ognlPath += methodName;
        // get rid of leading ?. or . as we only needed that to determine if null safe was enabled or not
        methodName = OgnlHelper.removeLeadingOperators(methodName);
        // are we doing an index lookup (eg in Map/List/array etc)?
        String key = null;
        KeyValueHolder<String, String> index = OgnlHelper.isOgnlIndex(methodName);
        if (index != null) {
            methodName = index.getKey();
            key = index.getValue();
        }
        // only invoke if we have a method name to use to invoke
        if (methodName != null) {
            InvokeProcessor invoke = new InvokeProcessor(holder, methodName);
            invoke.process(resultExchange);
            // check for exception and rethrow if we failed
            if (resultExchange.getException() != null) {
                throw new RuntimeBeanExpressionException(exchange, beanName, methodName, resultExchange.getException());
            }
            result = invoke.getResult();
        }
        // if there was a key then we need to lookup using the key
        if (key != null) {
            result = lookupResult(resultExchange, key, result, nullSafe, ognlPath, holder.getBean());
        }
        // check null safe for null results
        if (result == null && nullSafe) {
            return;
        }
        // prepare for next bean to invoke
        beanToCall = result;
        // we need to set the result to the exchange for further processing
        resultExchange.getIn().setBody(result);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7513_85ced066,Major,camel-core/src/main/java/org/apache/camel/processor/aggregate/AggregationStrategyBeanInfo.java,49,116,"protected AggregationStrategyMethodInfo createMethodInfo() {
    Class<?>[] parameterTypes = method.getParameterTypes();
    int size = parameterTypes.length;
    if (LOG.isTraceEnabled()) {
        LOG.trace(""Creating MethodInfo for class: {} method: {} having {} parameters"", new Object[] { type, method, size });
    }
    // must have equal number of parameters
    if (size < 2) {
        throw new IllegalArgumentException(""The method "" + method.getName() + "" must have at least two parameters, has: "" + size);
    } else if (size % 2 != 0) {
        throw new IllegalArgumentException(""The method "" + method.getName() + "" must have equal number of parameters, has: "" + size);
    }
    // must not have annotations as they are not supported (yet)
    for (int i = 0; i < size; i++) {
        Class<?> type = parameterTypes[i];
        if (type.getAnnotations().length > 0) {
            throw new IllegalArgumentException(""Parameter annotations at index "" + i + "" is not supported on method: "" + method);
        }
    }
    List<ParameterInfo> oldParameters = new ArrayList<ParameterInfo>();
    List<ParameterInfo> newParameters = new ArrayList<ParameterInfo>();
    for (int i = 0; i < size / 2; i++) {
        Class<?> oldType = parameterTypes[i];
        if (oldParameters.size() == 0) {
            // the first parameter is the body
            Expression oldBody = ExpressionBuilder.mandatoryBodyExpression(oldType);
            ParameterInfo info = new ParameterInfo(i, oldType, null, oldBody);
            oldParameters.add(info);
        } else if (oldParameters.size() == 1) {
            // the 2nd parameter is the headers
            Expression oldHeaders = ExpressionBuilder.headersExpression();
            ParameterInfo info = new ParameterInfo(i, oldType, null, oldHeaders);
            oldParameters.add(info);
        } else if (oldParameters.size() == 2) {
            // the 3rd parameter is the properties
            Expression oldProperties = ExpressionBuilder.propertiesExpression();
            ParameterInfo info = new ParameterInfo(i, oldType, null, oldProperties);
            oldParameters.add(info);
        }
    }
    for (int i = size / 2; i < size; i++) {
        Class<?> newType = parameterTypes[i];
        if (newParameters.size() == 0) {
            // the first parameter is the body
            Expression newBody = ExpressionBuilder.mandatoryBodyExpression(newType);
            ParameterInfo info = new ParameterInfo(i, newType, null, newBody);
            newParameters.add(info);
        } else if (newParameters.size() == 1) {
            // the 2nd parameter is the headers
            Expression newHeaders = ExpressionBuilder.headersExpression();
            ParameterInfo info = new ParameterInfo(i, newType, null, newHeaders);
            newParameters.add(info);
        } else if (newParameters.size() == 2) {
            // the 3rd parameter is the properties
            Expression newProperties = ExpressionBuilder.propertiesExpression();
            ParameterInfo info = new ParameterInfo(i, newType, null, newProperties);
            newParameters.add(info);
        }
    }
    return new AggregationStrategyMethodInfo(camelContext, type, method, oldParameters, newParameters);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7562_689147e9,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinitionHelper.java,194,260,"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
private static <T> void doFindType(List<ProcessorDefinition<?>> outputs, Class<T> type, List<T> found) {
    if (outputs == null || outputs.isEmpty()) {
        return;
    }
    for (ProcessorDefinition out : outputs) {
        if (type.isInstance(out)) {
            found.add((T) out);
        }
        // send is much common
        if (out instanceof SendDefinition) {
            SendDefinition send = (SendDefinition) out;
            List<ProcessorDefinition<?>> children = send.getOutputs();
            doFindType(children, type, found);
        }
        // special for choice
        if (out instanceof ChoiceDefinition) {
            ChoiceDefinition choice = (ChoiceDefinition) out;
            for (WhenDefinition when : choice.getWhenClauses()) {
                List<ProcessorDefinition<?>> children = when.getOutputs();
                doFindType(children, type, found);
            }
            // otherwise is optional
            if (choice.getOtherwise() != null) {
                List<ProcessorDefinition<?>> children = choice.getOtherwise().getOutputs();
                doFindType(children, type, found);
            }
        }
        // special for try ... catch ... finally
        if (out instanceof TryDefinition) {
            TryDefinition doTry = (TryDefinition) out;
            List<ProcessorDefinition<?>> doTryOut = doTry.getOutputsWithoutCatches();
            doFindType(doTryOut, type, found);
            List<CatchDefinition> doTryCatch = doTry.getCatchClauses();
            for (CatchDefinition doCatch : doTryCatch) {
                doFindType(doCatch.getOutputs(), type, found);
            }
            if (doTry.getFinallyClause() != null) {
                doFindType(doTry.getFinallyClause().getOutputs(), type, found);
            }
            // do not check children as we already did that
            continue;
        }
        // special for some types which has special outputs
        if (out instanceof OutputDefinition) {
            OutputDefinition outDef = (OutputDefinition) out;
            List<ProcessorDefinition<?>> outDefOut = outDef.getOutputs();
            doFindType(outDefOut, type, found);
            // do not check children as we already did that
            continue;
        }
        // try children as well
        List<ProcessorDefinition<?>> children = out.getOutputs();
        doFindType(children, type, found);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7568_b3377b16,Minor,camel-core/src/main/java/org/apache/camel/processor/OnCompletionProcessor.java,127,160,"/**
 * Processes the exchange by the processors
 *
 * @param processor the processor
 * @param exchange the exchange
 */
protected static void doProcess(Processor processor, Exchange exchange) {
    // must remember some properties which we cannot use during onCompletion processing
    // as otherwise we may cause issues
    Object stop = exchange.removeProperty(Exchange.ROUTE_STOP);
    Object failureHandled = exchange.removeProperty(Exchange.FAILURE_HANDLED);
    Object caught = exchange.removeProperty(Exchange.EXCEPTION_CAUGHT);
    Object errorhandlerHandled = exchange.removeProperty(Exchange.ERRORHANDLER_HANDLED);
    Exception cause = exchange.getException();
    exchange.setException(null);
    try {
        processor.process(exchange);
    } catch (Exception e) {
        exchange.setException(e);
    } finally {
        // restore the options
        if (stop != null) {
            exchange.setProperty(Exchange.ROUTE_STOP, stop);
        }
        if (failureHandled != null) {
            exchange.setProperty(Exchange.FAILURE_HANDLED, failureHandled);
        }
        if (caught != null) {
            exchange.setProperty(Exchange.EXCEPTION_CAUGHT, caught);
        }
        if (errorhandlerHandled != null) {
            exchange.setProperty(Exchange.ERRORHANDLER_HANDLED, errorhandlerHandled);
        }
        if (cause != null) {
            exchange.setException(cause);
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7586_1f92fa42,Minor,camel-core/src/main/java/org/apache/camel/api/management/mbean/ManagedCamelContextMBean.java,83,84,"@ManagedAttribute(description = ""Message History"")
Boolean getMessageHistory();"
camel,remotes/origin/bugs-dot-jar_CAMEL-7586_1f92fa42,Minor,camel-core/src/main/java/org/apache/camel/management/mbean/ManagedCamelContext.java,130,132,"public Boolean getMessageHistory() {
    return context.isMessageHistory();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7586_1f92fa42,Minor,camel-core/src/main/java/org/apache/camel/management/mbean/ManagedCamelContext.java,214,216,"public boolean isMessageHistory() {
    return context.isMessageHistory();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7611_e30f1c53,Major,camel-core/src/main/java/org/apache/camel/util/KeyValueHolder.java,42,59,"@SuppressWarnings(""unchecked"")
@Override
public boolean equals(Object o) {
    if (this == o) {
        return true;
    }
    if (o == null || getClass() != o.getClass()) {
        return false;
    }
    KeyValueHolder<K, V> that = (KeyValueHolder<K, V>) o;
    if (key != null ? !key.equals(that.key) : that.key != null) {
        return false;
    }
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7622_faa20255,Major,camel-core/src/main/java/org/apache/camel/builder/AdviceWithTasks.java,320,334,"/**
 * Gets the outputs from the given parent.
 * <p/>
 * This implementation deals with that outputs can be abstract and retrieves the correct non-nested output.
 *
 * @param parent the parent
 * @return <tt>null</tt> if no parent
 */
@SuppressWarnings(""unchecked"")
private static List<ProcessorDefinition> getParentOutputs(ProcessorDefinition parent) {
    if (parent == null) {
        return null;
    }
    List<ProcessorDefinition> outputs = parent.getOutputs();
    if (outputs.size() >= 1) {
        // get the 'actual' outputs from that
        if (outputs.get(0).isAbstract()) {
            outputs = outputs.get(0).getOutputs();
        }
    }
    return outputs;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7736_7ad36e3d,Major,camel-core/src/main/java/org/apache/camel/impl/ProducerCache.java,268,328,"/**
 * Sends an exchange to an endpoint using a supplied callback supporting the asynchronous routing engine.
 * <p/>
 * If an exception was thrown during processing, it would be set on the given Exchange
 *
 * @param endpoint         the endpoint to send the exchange to
 * @param exchange         the exchange, can be <tt>null</tt> if so then create a new exchange from the producer
 * @param pattern          the exchange pattern, can be <tt>null</tt>
 * @param callback         the asynchronous callback
 * @param producerCallback the producer template callback to be executed
 * @return (doneSync) <tt>true</tt> to continue execute synchronously, <tt>false</tt> to continue being executed asynchronously
 */
public boolean doInAsyncProducer(final Endpoint endpoint, final Exchange exchange, final ExchangePattern pattern, final AsyncCallback callback, final AsyncProducerCallback producerCallback) {
    boolean sync = true;
    // get the producer and we do not mind if its pooled as we can handle returning it back to the pool
    final Producer producer = doGetProducer(endpoint, true);
    if (producer == null) {
        if (isStopped()) {
            LOG.warn(""Ignoring exchange sent after processor is stopped: "" + exchange);
            return false;
        } else {
            throw new IllegalStateException(""No producer, this processor has not been started: "" + this);
        }
    }
    // record timing for sending the exchange using the producer
    final StopWatch watch = eventNotifierEnabled && exchange != null ? new StopWatch() : null;
    try {
        if (eventNotifierEnabled && exchange != null) {
            EventHelper.notifyExchangeSending(exchange.getContext(), exchange, endpoint);
        }
        // invoke the callback
        AsyncProcessor asyncProcessor = AsyncProcessorConverterHelper.convert(producer);
        sync = producerCallback.doInAsyncProducer(producer, asyncProcessor, exchange, pattern, new AsyncCallback() {

            @Override
            public void done(boolean doneSync) {
                try {
                    if (eventNotifierEnabled && watch != null) {
                        long timeTaken = watch.stop();
                        // emit event that the exchange was sent to the endpoint
                        EventHelper.notifyExchangeSent(exchange.getContext(), exchange, endpoint, timeTaken);
                    }
                    if (producer instanceof ServicePoolAware) {
                        // release back to the pool
                        pool.release(endpoint, producer);
                    } else if (!producer.isSingleton()) {
                        // stop and shutdown non-singleton producers as we should not leak resources
                        try {
                            ServiceHelper.stopAndShutdownService(producer);
                        } catch (Exception e) {
                            // ignore and continue
                            LOG.warn(""Error stopping/shutting down producer: "" + producer, e);
                        }
                    }
                } finally {
                    callback.done(doneSync);
                }
            }
        });
    } catch (Throwable e) {
        // ensure exceptions is caught and set on the exchange
        if (exchange != null) {
            exchange.setException(e);
        }
    }
    return sync;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7767_eab06182,Major,camel-core/src/main/java/org/apache/camel/util/MessageHelper.java,251,324,"/**
 * Extracts the value for logging purpose.
 * <p/>
 * Will clip the value if its too big for logging.
 *
 * @see org.apache.camel.Exchange#LOG_DEBUG_BODY_MAX_CHARS
 * @param obj     the value
 * @param message the message
 * @param prepend a message to prepend
 * @param allowStreams whether or not streams is allowed
 * @param allowFiles whether or not files is allowed (currently not in use)
 * @param maxChars limit to maximum number of chars. Use 0 for not limit, and -1 for turning logging message body off.
 * @return the logging message
 */
public static String extractValueForLogging(Object obj, Message message, String prepend, boolean allowStreams, boolean allowFiles, int maxChars) {
    if (maxChars < 0) {
        return prepend + ""[Body is not logged]"";
    }
    if (obj == null) {
        return prepend + ""[Body is null]"";
    }
    if (!allowStreams) {
        if (obj instanceof Source && !(obj instanceof StringSource || obj instanceof BytesSource)) {
            // all other kinds we should not touch the body
            return prepend + ""[Body is instance of java.xml.transform.Source]"";
        } else if (obj instanceof StreamCache) {
            return prepend + ""[Body is instance of org.apache.camel.StreamCache]"";
        } else if (obj instanceof InputStream) {
            return prepend + ""[Body is instance of java.io.InputStream]"";
        } else if (obj instanceof OutputStream) {
            return prepend + ""[Body is instance of java.io.OutputStream]"";
        } else if (obj instanceof Reader) {
            return prepend + ""[Body is instance of java.io.Reader]"";
        } else if (obj instanceof Writer) {
            return prepend + ""[Body is instance of java.io.Writer]"";
        } else if (obj instanceof WrappedFile || obj instanceof File) {
            if (!allowFiles) {
                return prepend + ""[Body is file based: "" + obj + ""]"";
            }
        }
    }
    if (!allowFiles) {
        if (obj instanceof WrappedFile || obj instanceof File) {
            return prepend + ""[Body is file based: "" + obj + ""]"";
        }
    }
    // is the body a stream cache
    StreamCache cache;
    if (obj instanceof StreamCache) {
        cache = (StreamCache) obj;
    } else {
        cache = null;
    }
    // grab the message body as a string
    String body = null;
    if (message.getExchange() != null) {
        try {
            body = message.getExchange().getContext().getTypeConverter().convertTo(String.class, message.getExchange(), obj);
        } catch (Exception e) {
        // ignore as the body is for logging purpose
        }
    }
    if (body == null) {
        body = obj.toString();
    }
    // reset stream cache after use
    if (cache != null) {
        cache.reset();
    }
    if (body == null) {
        return prepend + ""[Body is null]"";
    }
    // clip body if length enabled and the body is too big
    if (maxChars > 0 && body.length() > maxChars) {
        body = body.substring(0, maxChars) + ""... [Body clipped after "" + maxChars + "" chars, total length is "" + body.length() + ""]"";
    }
    return prepend + body;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7795_19b2aa31,Major,camel-core/src/main/java/org/apache/camel/impl/MDCUnitOfWork.java,204,231,"public void done(boolean doneSync) {
    try {
        if (!doneSync) {
            // when done asynchronously then restore information from previous thread
            if (breadcrumbId != null) {
                MDC.put(MDC_BREADCRUMB_ID, breadcrumbId);
            }
            if (exchangeId != null) {
                MDC.put(MDC_EXCHANGE_ID, exchangeId);
            }
            if (messageId != null) {
                MDC.put(MDC_MESSAGE_ID, messageId);
            }
            if (correlationId != null) {
                MDC.put(MDC_CORRELATION_ID, correlationId);
            }
            if (routeId != null) {
                MDC.put(MDC_ROUTE_ID, routeId);
            }
            if (camelContextId != null) {
                MDC.put(MDC_CAMEL_CONTEXT_ID, camelContextId);
            }
        }
    } finally {
        // muse ensure delegate is invoked
        delegate.done(doneSync);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7883_d57f402b,Major,camel-core/src/main/java/org/apache/camel/component/validator/DefaultLSResourceResolver.java,118,122,"@Override
public Reader getCharacterStream() {
    InputStream is = getByteStream();
    return camelContext.getTypeConverter().convertTo(Reader.class, is);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7973_799b45df,Minor,camel-core/src/main/java/org/apache/camel/processor/loadbalancer/CircuitBreakerLoadBalancer.java,96,136,"public boolean process(final Exchange exchange, final AsyncCallback callback) {
    // can we still run
    if (!isRunAllowed()) {
        log.trace(""Run not allowed, will reject executing exchange: {}"", exchange);
        if (exchange.getException() == null) {
            exchange.setException(new RejectedExecutionException(""Run is not allowed""));
        }
        callback.done(true);
        return true;
    }
    if (failures.get() >= threshold && System.currentTimeMillis() - lastFailure < halfOpenAfter) {
        exchange.setException(new RejectedExecutionException(""CircuitBreaker Open: failures: "" + failures + "", lastFailure: "" + lastFailure));
    }
    Processor processor = getProcessors().get(0);
    if (processor == null) {
        throw new IllegalStateException(""No processors could be chosen to process CircuitBreaker"");
    }
    AsyncProcessor albp = AsyncProcessorConverterHelper.convert(processor);
    boolean sync = albp.process(exchange, callback);
    boolean failed = hasFailed(exchange);
    if (!failed) {
        failures.set(0);
    } else {
        failures.incrementAndGet();
        lastFailure = System.currentTimeMillis();
    }
    if (!sync) {
        log.trace(""Processing exchangeId: {} is continued being processed asynchronously"", exchange.getExchangeId());
        return false;
    }
    log.trace(""Processing exchangeId: {} is continued being processed synchronously"", exchange.getExchangeId());
    callback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-7990_d581c4a4,Major,camel-core/src/main/java/org/apache/camel/processor/idempotent/IdempotentConsumer.java,80,124,"public boolean process(Exchange exchange, AsyncCallback callback) {
    final String messageId = messageIdExpression.evaluate(exchange, String.class);
    if (messageId == null) {
        throw new NoMessageIdException(exchange, messageIdExpression);
    }
    boolean newKey;
    if (eager) {
        // add the key to the repository
        if (idempotentRepository instanceof ExchangeIdempotentRepository) {
            newKey = ((ExchangeIdempotentRepository<String>) idempotentRepository).add(exchange, messageId);
        } else {
            newKey = idempotentRepository.add(messageId);
        }
    } else {
        // check if we already have the key
        if (idempotentRepository instanceof ExchangeIdempotentRepository) {
            newKey = ((ExchangeIdempotentRepository<String>) idempotentRepository).contains(exchange, messageId);
        } else {
            newKey = !idempotentRepository.contains(messageId);
        }
    }
    if (!newKey) {
        // mark the exchange as duplicate
        exchange.setProperty(Exchange.DUPLICATE_MESSAGE, Boolean.TRUE);
        // we already have this key so its a duplicate message
        onDuplicate(exchange, messageId);
        if (skipDuplicate) {
            // if we should skip duplicate then we are done
            LOG.debug(""Ignoring duplicate message with id: {} for exchange: {}"", messageId, exchange);
            callback.done(true);
            return true;
        }
    }
    // register our on completion callback
    exchange.addOnCompletion(new IdempotentOnCompletion(idempotentRepository, messageId, eager, removeOnFailure));
    // process the exchange
    return processor.process(exchange, callback);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8053_cac72b14,Major,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,930,952,"public synchronized boolean removeRoute(String routeId) throws Exception {
    RouteService routeService = routeServices.get(routeId);
    if (routeService != null) {
        if (getRouteStatus(routeId).isStopped()) {
            routeService.setRemovingRoutes(true);
            shutdownRouteService(routeService);
            removeRouteDefinition(routeId);
            routeServices.remove(routeId);
            // remove route from startup order as well, as it was removed
            Iterator<RouteStartupOrder> it = routeStartupOrder.iterator();
            while (it.hasNext()) {
                RouteStartupOrder order = it.next();
                if (order.getRoute().getId().equals(routeId)) {
                    it.remove();
                }
            }
            return true;
        } else {
            return false;
        }
    }
    return false;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8081_2e985f9b,Major,camel-core/src/main/java/org/apache/camel/processor/MulticastProcessor.java,408,505,"private void aggregateOnTheFly() throws InterruptedException, ExecutionException {
    boolean timedOut = false;
    boolean stoppedOnException = false;
    final StopWatch watch = new StopWatch();
    int aggregated = 0;
    boolean done = false;
    // not a for loop as on the fly may still run
    while (!done) {
        // check if we have already aggregate everything
        if (allTasksSubmitted.get() && aggregated >= total.get()) {
            LOG.debug(""Done aggregating {} exchanges on the fly."", aggregated);
            break;
        }
        Future<Exchange> future;
        if (timedOut) {
            // we are timed out but try to grab if some tasks has been completed
            // poll will return null if no tasks is present
            future = completion.poll();
            LOG.trace(""Polled completion task #{} after timeout to grab already completed tasks: {}"", aggregated, future);
        } else if (timeout > 0) {
            long left = timeout - watch.taken();
            if (left < 0) {
                left = 0;
            }
            LOG.trace(""Polling completion task #{} using timeout {} millis."", aggregated, left);
            future = completion.poll(left, TimeUnit.MILLISECONDS);
        } else {
            LOG.trace(""Polling completion task #{}"", aggregated);
            // we must not block so poll every second
            future = completion.poll(1, TimeUnit.SECONDS);
            if (future == null) {
                // and continue loop which will recheck if we are done
                continue;
            }
        }
        if (future == null && timedOut) {
            // we are timed out and no more tasks complete so break out
            break;
        } else if (future == null) {
            // timeout occurred
            AggregationStrategy strategy = getAggregationStrategy(null);
            if (strategy instanceof TimeoutAwareAggregationStrategy) {
                // notify the strategy we timed out
                Exchange oldExchange = result.get();
                if (oldExchange == null) {
                    // if they all timed out the result may not have been set yet, so use the original exchange
                    oldExchange = original;
                }
                ((TimeoutAwareAggregationStrategy) strategy).timeout(oldExchange, aggregated, total.intValue(), timeout);
            } else {
                // log a WARN we timed out since it will not be aggregated and the Exchange will be lost
                LOG.warn(""Parallel processing timed out after {} millis for number {}. This task will be cancelled and will not be aggregated."", timeout, aggregated);
            }
            LOG.debug(""Timeout occurred after {} millis for number {} task."", timeout, aggregated);
            timedOut = true;
            // any already completed tasks in the next loop
            if (completion instanceof SubmitOrderedCompletionService) {
                ((SubmitOrderedCompletionService<?>) completion).timeoutTask();
            }
        } else {
            // there is a result to aggregate
            Exchange subExchange = future.get();
            // Decide whether to continue with the multicast or not; similar logic to the Pipeline
            Integer number = getExchangeIndex(subExchange);
            boolean continueProcessing = PipelineHelper.continueProcessing(subExchange, ""Parallel processing failed for number "" + number, LOG);
            if (stopOnException && !continueProcessing) {
                // we want to stop on exception and an exception or failure occurred
                // this is similar to what the pipeline does, so we should do the same to not surprise end users
                // so we should set the failed exchange as the result and break out
                result.set(subExchange);
                stoppedOnException = true;
                break;
            }
            // we got a result so aggregate it
            AggregationStrategy strategy = getAggregationStrategy(subExchange);
            doAggregate(strategy, result, subExchange);
        }
        aggregated++;
    }
    if (timedOut || stoppedOnException) {
        if (timedOut) {
            LOG.debug(""Cancelling tasks due timeout after {} millis."", timeout);
        }
        if (stoppedOnException) {
            LOG.debug(""Cancelling tasks due stopOnException."");
        }
        // cancel tasks as we timed out (its safe to cancel done tasks)
        running.set(false);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8106_39ccf5d6,Major,camel-core/src/main/java/org/apache/camel/support/XMLTokenExpressionIterator.java,572,581,"@Override
public Object next() {
    Object o = nextToken;
    try {
        nextToken = getNextToken();
    } catch (XMLStreamException e) {
    // 
    }
    return o;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8125_36e7b668,Minor,camel-core/src/main/java/org/apache/camel/impl/CamelPostProcessorHelper.java,227,263,"public Object getInjectionPropertyValue(Class<?> type, String propertyName, String propertyDefaultValue, String injectionPointName, Object bean, String beanName) {
    try {
        String key;
        String prefix = getCamelContext().getPropertyPrefixToken();
        String suffix = getCamelContext().getPropertySuffixToken();
        if (prefix == null && suffix == null) {
            // if no custom prefix/suffix then use defaults
            prefix = PropertiesComponent.DEFAULT_PREFIX_TOKEN;
            suffix = PropertiesComponent.DEFAULT_SUFFIX_TOKEN;
        }
        if (!propertyName.startsWith(prefix)) {
            // must enclose the property name with prefix/suffix to have it resolved
            key = prefix + propertyName + suffix;
        } else {
            // key has already prefix/suffix so use it as-is as it may be a compound key
            key = propertyName;
        }
        String value = getCamelContext().resolvePropertyPlaceholders(key);
        if (value != null) {
            return getCamelContext().getTypeConverter().mandatoryConvertTo(type, value);
        } else {
            return null;
        }
    } catch (Exception e) {
        if (ObjectHelper.isNotEmpty(propertyDefaultValue)) {
            try {
                return getCamelContext().getTypeConverter().mandatoryConvertTo(type, propertyDefaultValue);
            } catch (Exception e2) {
                throw ObjectHelper.wrapRuntimeCamelException(e2);
            }
        }
        throw ObjectHelper.wrapRuntimeCamelException(e);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8125_36e7b668,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,1451,1490,"public String resolvePropertyPlaceholders(String text) throws Exception {
    // While it is more efficient to only do the lookup if we are sure we need the component,
    // with custom tokens, we cannot know if the URI contains a property or not without having
    // the component.  We also lose fail-fast behavior for the missing component with this change.
    PropertiesComponent pc = getPropertiesComponent();
    // Do not parse uris that are designated for the properties component as it will handle that itself
    if (text != null && !text.startsWith(""properties:"")) {
        // No component, assume default tokens.
        if (pc == null && text.contains(PropertiesComponent.DEFAULT_PREFIX_TOKEN)) {
            // try to lookup component, as we may be initializing CamelContext itself
            Component existing = lookupPropertiesComponent();
            if (existing != null) {
                if (existing instanceof PropertiesComponent) {
                    pc = (PropertiesComponent) existing;
                } else {
                    // properties component must be expected type
                    throw new IllegalArgumentException(""Found properties component of type: "" + existing.getClass() + "" instead of expected: "" + PropertiesComponent.class);
                }
            }
            if (pc == null) {
                // create a default properties component to be used as there may be default values we can use
                log.info(""No existing PropertiesComponent has been configured, creating a new default PropertiesComponent with name: properties"");
                pc = getComponent(""properties"", PropertiesComponent.class);
            }
        }
        if (pc != null && text.contains(pc.getPrefixToken())) {
            // the parser will throw exception if property key was not found
            String answer = pc.parseUri(text);
            log.debug(""Resolved text: {} -> {}"", text, answer);
            return answer;
        }
    }
    // return original text as is
    return text;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8125_36e7b668,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,1999,2167,"private void doStartCamel() throws Exception {
    if (applicationContextClassLoader == null) {
        // Using the TCCL as the default value of ApplicationClassLoader
        ClassLoader cl = Thread.currentThread().getContextClassLoader();
        if (cl == null) {
            // use the classloader that loaded this class
            cl = this.getClass().getClassLoader();
        }
        setApplicationContextClassLoader(cl);
    }
    if (log.isDebugEnabled()) {
        log.debug(""Using ClassResolver={}, PackageScanClassResolver={}, ApplicationContextClassLoader={}"", new Object[] { getClassResolver(), getPackageScanClassResolver(), getApplicationContextClassLoader() });
    }
    if (isStreamCaching()) {
        log.info(""StreamCaching is enabled on CamelContext: {}"", getName());
    }
    if (isTracing()) {
        // tracing is added in the DefaultChannel so we can enable it on the fly
        log.info(""Tracing is enabled on CamelContext: {}"", getName());
    }
    if (isUseMDCLogging()) {
        // log if MDC has been enabled
        log.info(""MDC logging is enabled on CamelContext: {}"", getName());
    }
    if (isHandleFault()) {
        // only add a new handle fault if not already configured
        if (HandleFault.getHandleFault(this) == null) {
            log.info(""HandleFault is enabled on CamelContext: {}"", getName());
            addInterceptStrategy(new HandleFault());
        }
    }
    if (getDelayer() != null && getDelayer() > 0) {
        log.info(""Delayer is enabled with: {} ms. on CamelContext: {}"", getDelayer(), getName());
    }
    // register debugger
    if (getDebugger() != null) {
        log.info(""Debugger: {} is enabled on CamelContext: {}"", getDebugger(), getName());
        // register this camel context on the debugger
        getDebugger().setCamelContext(this);
        startService(getDebugger());
        addInterceptStrategy(new Debug(getDebugger()));
    }
    // start management strategy before lifecycles are started
    ManagementStrategy managementStrategy = getManagementStrategy();
    // inject CamelContext if aware
    if (managementStrategy instanceof CamelContextAware) {
        ((CamelContextAware) managementStrategy).setCamelContext(this);
    }
    ServiceHelper.startService(managementStrategy);
    // start lifecycle strategies
    ServiceHelper.startServices(lifecycleStrategies);
    Iterator<LifecycleStrategy> it = lifecycleStrategies.iterator();
    while (it.hasNext()) {
        LifecycleStrategy strategy = it.next();
        try {
            strategy.onContextStart(this);
        } catch (VetoCamelContextStartException e) {
            // okay we should not start Camel since it was vetoed
            log.warn(""Lifecycle strategy vetoed starting CamelContext ({}) due {}"", getName(), e.getMessage());
            throw e;
        } catch (Exception e) {
            log.warn(""Lifecycle strategy "" + strategy + "" failed starting CamelContext ({}) due {}"", getName(), e.getMessage());
            throw e;
        }
    }
    // start notifiers as services
    for (EventNotifier notifier : getManagementStrategy().getEventNotifiers()) {
        if (notifier instanceof Service) {
            Service service = (Service) notifier;
            for (LifecycleStrategy strategy : lifecycleStrategies) {
                strategy.onServiceAdd(this, service, null);
            }
        }
        if (notifier instanceof Service) {
            startService((Service) notifier);
        }
    }
    // must let some bootstrap service be started before we can notify the starting event
    EventHelper.notifyCamelContextStarting(this);
    forceLazyInitialization();
    // re-create endpoint registry as the cache size limit may be set after the constructor of this instance was called.
    // and we needed to create endpoints up-front as it may be accessed before this context is started
    endpoints = new EndpointRegistry(this, endpoints);
    addService(endpoints);
    // special for executorServiceManager as want to stop it manually
    doAddService(executorServiceManager, false);
    addService(producerServicePool);
    addService(inflightRepository);
    addService(shutdownStrategy);
    addService(packageScanClassResolver);
    addService(restRegistry);
    if (runtimeEndpointRegistry != null) {
        if (runtimeEndpointRegistry instanceof EventNotifier) {
            getManagementStrategy().addEventNotifier((EventNotifier) runtimeEndpointRegistry);
        }
        addService(runtimeEndpointRegistry);
    }
    // eager lookup any configured properties component to avoid subsequent lookup attempts which may impact performance
    // due we use properties component for property placeholder resolution at runtime
    Component existing = lookupPropertiesComponent();
    if (existing != null) {
        // store reference to the existing properties component
        if (existing instanceof PropertiesComponent) {
            propertiesComponent = (PropertiesComponent) existing;
        } else {
            // properties component must be expected type
            throw new IllegalArgumentException(""Found properties component of type: "" + existing.getClass() + "" instead of expected: "" + PropertiesComponent.class);
        }
    }
    // start components
    startServices(components.values());
    // start the route definitions before the routes is started
    startRouteDefinitions(routeDefinitions);
    // is there any stream caching enabled then log an info about this and its limit of spooling to disk, so people is aware of this
    boolean streamCachingInUse = isStreamCaching();
    if (!streamCachingInUse) {
        for (RouteDefinition route : routeDefinitions) {
            Boolean routeCache = CamelContextHelper.parseBoolean(this, route.getStreamCache());
            if (routeCache != null && routeCache) {
                streamCachingInUse = true;
                break;
            }
        }
    }
    if (isAllowUseOriginalMessage()) {
        log.info(""AllowUseOriginalMessage is enabled. If access to the original message is not needed,"" + "" then its recommended to turn this option off as it may improve performance."");
    }
    if (streamCachingInUse) {
        // stream caching is in use so enable the strategy
        getStreamCachingStrategy().setEnabled(true);
        addService(getStreamCachingStrategy());
    } else {
        // log if stream caching is not in use as this can help people to enable it if they use streams
        log.info(""StreamCaching is not in use. If using streams then its recommended to enable stream caching."" + "" See more details at http://camel.apache.org/stream-caching.html"");
    }
    // start routes
    if (doNotStartRoutesOnFirstStart) {
        log.debug(""Skip starting of routes as CamelContext has been configured with autoStartup=false"");
    }
    // invoke this logic to warmup the routes and if possible also start the routes
    doStartOrResumeRoutes(routeServices, true, !doNotStartRoutesOnFirstStart, false, true);
// starting will continue in the start method
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8125_36e7b668,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,3078,3088,"protected Component lookupPropertiesComponent() {
    // no existing properties component so lookup and add as component if possible
    PropertiesComponent answer = (PropertiesComponent) hasComponent(""properties"");
    if (answer == null) {
        answer = getRegistry().lookupByNameAndType(""properties"", PropertiesComponent.class);
        if (answer != null) {
            addComponent(""properties"", answer);
        }
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8125_36e7b668,Minor,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinitionHelper.java,508,572,"/**
 * Inspects the given definition and resolves any property placeholders from its properties.
 * <p/>
 * This implementation will check all the getter/setter pairs on this instance and for all the values
 * (which is a String type) will be property placeholder resolved.
 *
 * @param routeContext the route context
 * @param definition   the definition
 * @throws Exception is thrown if property placeholders was used and there was an error resolving them
 * @see org.apache.camel.CamelContext#resolvePropertyPlaceholders(String)
 * @see org.apache.camel.component.properties.PropertiesComponent
 */
public static void resolvePropertyPlaceholders(RouteContext routeContext, Object definition) throws Exception {
    LOG.trace(""Resolving property placeholders for: {}"", definition);
    // find all getter/setter which we can use for property placeholders
    Map<String, Object> properties = new HashMap<String, Object>();
    IntrospectionSupport.getProperties(definition, properties, null);
    ProcessorDefinition<?> processorDefinition = null;
    if (definition instanceof ProcessorDefinition) {
        processorDefinition = (ProcessorDefinition<?>) definition;
    }
    // and when the definition parameter is this (otherAttributes belong to this)
    if (processorDefinition != null && processorDefinition.getOtherAttributes() != null) {
        for (QName key : processorDefinition.getOtherAttributes().keySet()) {
            if (Constants.PLACEHOLDER_QNAME.equals(key.getNamespaceURI())) {
                String local = key.getLocalPart();
                Object value = processorDefinition.getOtherAttributes().get(key);
                if (value != null && value instanceof String) {
                    // value must be enclosed with placeholder tokens
                    String s = (String) value;
                    String prefixToken = routeContext.getCamelContext().getPropertyPrefixToken();
                    String suffixToken = routeContext.getCamelContext().getPropertySuffixToken();
                    if (prefixToken == null) {
                        throw new IllegalArgumentException(""Property with name ["" + local + ""] uses property placeholders; however, no properties component is configured."");
                    }
                    if (!s.startsWith(prefixToken)) {
                        s = prefixToken + s;
                    }
                    if (!s.endsWith(suffixToken)) {
                        s = s + suffixToken;
                    }
                    value = s;
                }
                properties.put(local, value);
            }
        }
    }
    if (!properties.isEmpty()) {
        LOG.trace(""There are {} properties on: {}"", properties.size(), definition);
        // lookup and resolve properties for String based properties
        for (Map.Entry<String, Object> entry : properties.entrySet()) {
            // the name is always a String
            String name = entry.getKey();
            Object value = entry.getValue();
            if (value instanceof String) {
                // value must be a String, as a String is the key for a property placeholder
                String text = (String) value;
                text = routeContext.getCamelContext().resolvePropertyPlaceholders(text);
                if (text != value) {
                    // invoke setter as the text has changed
                    boolean changed = IntrospectionSupport.setProperty(routeContext.getCamelContext().getTypeConverter(), definition, name, text);
                    if (!changed) {
                        throw new IllegalArgumentException(""No setter to set property: "" + name + "" to: "" + text + "" on: "" + definition);
                    }
                    if (LOG.isDebugEnabled()) {
                        LOG.debug(""Changed property [{}] from: {} to: {}"", new Object[] { name, value, text });
                    }
                }
            }
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8137_53b4e90c,Minor,camel-core/src/main/java/org/apache/camel/component/bean/BeanInfo.java,294,360,"/**
 * Introspects the given class
 *
 * @param clazz the class
 */
private void introspect(Class<?> clazz) {
    // get the target clazz as it could potentially have been enhanced by CGLIB etc.
    clazz = getTargetClass(clazz);
    ObjectHelper.notNull(clazz, ""clazz"", this);
    LOG.trace(""Introspecting class: {}"", clazz);
    // favor declared methods, and then filter out duplicate interface methods
    List<Method> methods;
    if (Modifier.isPublic(clazz.getModifiers())) {
        LOG.trace(""Preferring class methods as class: {} is public accessible"", clazz);
        methods = new ArrayList<Method>(Arrays.asList(clazz.getDeclaredMethods()));
    } else {
        LOG.trace(""Preferring interface methods as class: {} is not public accessible"", clazz);
        methods = getInterfaceMethods(clazz);
        // and then we must add its declared methods as well
        List<Method> extraMethods = Arrays.asList(clazz.getDeclaredMethods());
        methods.addAll(extraMethods);
    }
    // it may have duplicate methods already, even from declared or from interfaces + declared
    Set<Method> overrides = new HashSet<Method>();
    for (Method source : methods) {
        for (Method target : methods) {
            // skip ourselves
            if (ObjectHelper.isOverridingMethod(source, target, true)) {
                continue;
            }
            // skip duplicates which may be assign compatible (favor keep first added method when duplicate)
            if (ObjectHelper.isOverridingMethod(source, target, false)) {
                overrides.add(target);
            }
        }
    }
    methods.removeAll(overrides);
    overrides.clear();
    // if we are a public class, then add non duplicate interface classes also
    if (Modifier.isPublic(clazz.getModifiers())) {
        // add additional interface methods
        List<Method> extraMethods = getInterfaceMethods(clazz);
        for (Method target : extraMethods) {
            for (Method source : methods) {
                if (ObjectHelper.isOverridingMethod(source, target, false)) {
                    overrides.add(target);
                }
            }
        }
        // remove all the overrides methods
        extraMethods.removeAll(overrides);
        methods.addAll(extraMethods);
    }
    // now introspect the methods and filter non valid methods
    for (Method method : methods) {
        boolean valid = isValidMethod(clazz, method);
        LOG.trace(""Method: {} is valid: {}"", method, valid);
        if (valid) {
            introspect(clazz, method);
        }
    }
    Class<?> superclass = clazz.getSuperclass();
    if (superclass != null && !superclass.equals(Object.class)) {
        introspect(superclass);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8146_17475d80,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultScheduledPollConsumerScheduler.java,155,162,"@Override
protected void doStop() throws Exception {
    if (future != null) {
        LOG.debug(""This consumer is stopping, so cancelling scheduled task: "" + future);
        future.cancel(false);
        future = null;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8146_17475d80,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultScheduledPollConsumerScheduler.java,164,171,"@Override
protected void doShutdown() throws Exception {
    if (shutdownExecutor && scheduledExecutorService != null) {
        getCamelContext().getExecutorServiceManager().shutdownNow(scheduledExecutorService);
        scheduledExecutorService = null;
        future = null;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8146_17475d80,Minor,camel-core/src/main/java/org/apache/camel/impl/ScheduledPollConsumer.java,515,525,"@Override
protected void doStop() throws Exception {
    ServiceHelper.stopService(scheduler);
    // clear counters
    backoffCounter = 0;
    idleCounter = 0;
    errorCounter = 0;
    super.doStop();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8227_54d7fc59,Minor,camel-core/src/main/java/org/apache/camel/processor/RecipientListProcessor.java,180,213,"@Override
protected Iterable<ProcessorExchangePair> createProcessorExchangePairs(Exchange exchange) throws Exception {
    // here we iterate the recipient lists and create the exchange pair for each of those
    List<ProcessorExchangePair> result = new ArrayList<ProcessorExchangePair>();
    // at first we must lookup the endpoint and acquire the producer which can send to the endpoint
    int index = 0;
    while (iter.hasNext()) {
        Object recipient = iter.next();
        Endpoint endpoint;
        Producer producer;
        ExchangePattern pattern;
        try {
            endpoint = resolveEndpoint(exchange, recipient);
            pattern = resolveExchangePattern(exchange, recipient);
            producer = producerCache.acquireProducer(endpoint);
        } catch (Exception e) {
            if (isIgnoreInvalidEndpoints()) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Endpoint uri is invalid: "" + recipient + "". This exception will be ignored."", e);
                }
                continue;
            } else {
                // failure so break out
                throw e;
            }
        }
        // then create the exchange pair
        result.add(createProcessorExchangePair(index++, endpoint, producer, exchange, pattern));
    }
    return result;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8227_54d7fc59,Minor,camel-core/src/main/java/org/apache/camel/processor/RecipientListProcessor.java,257,271,"protected ExchangePattern resolveExchangePattern(Exchange exchange, Object recipient) throws UnsupportedEncodingException, URISyntaxException {
    // trim strings as end users might have added spaces between separators
    if (recipient instanceof String) {
        String s = ((String) recipient).trim();
        // see if exchangePattern is a parameter in the url
        s = URISupport.normalizeUri(s);
        URI url = new URI(s);
        Map<String, Object> parameters = URISupport.parseParameters(url);
        String pattern = (String) parameters.get(""exchangePattern"");
        if (pattern != null) {
            return ExchangePattern.asEnum(pattern);
        }
    }
    return null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8227_54d7fc59,Minor,camel-core/src/main/java/org/apache/camel/processor/SendProcessor.java,95,163,"public boolean process(Exchange exchange, final AsyncCallback callback) {
    if (!isStarted()) {
        exchange.setException(new IllegalStateException(""SendProcessor has not been started: "" + this));
        callback.done(true);
        return true;
    }
    // we should preserve existing MEP so remember old MEP
    // if you want to permanently to change the MEP then use .setExchangePattern in the DSL
    final ExchangePattern existingPattern = exchange.getPattern();
    // if we have a producer then use that as its optimized
    if (producer != null) {
        // record timing for sending the exchange using the producer
        final StopWatch watch = new StopWatch();
        final Exchange target = configureExchange(exchange, pattern);
        EventHelper.notifyExchangeSending(exchange.getContext(), target, destination);
        LOG.debug("">>>> {} {}"", destination, exchange);
        boolean sync = true;
        try {
            sync = producer.process(exchange, new AsyncCallback() {

                @Override
                public void done(boolean doneSync) {
                    try {
                        // restore previous MEP
                        target.setPattern(existingPattern);
                        // emit event that the exchange was sent to the endpoint
                        long timeTaken = watch.stop();
                        EventHelper.notifyExchangeSent(target.getContext(), target, destination, timeTaken);
                    } finally {
                        checkException(target);
                        callback.done(doneSync);
                    }
                }
            });
        } catch (Throwable throwable) {
            if (exchange != null) {
                exchange.setException(throwable);
                checkException(exchange);
            }
        }
        return sync;
    }
    // send the exchange to the destination using the producer cache for the non optimized producers
    return producerCache.doInAsyncProducer(destination, exchange, pattern, callback, new AsyncProducerCallback() {

        public boolean doInAsyncProducer(Producer producer, AsyncProcessor asyncProducer, final Exchange exchange, ExchangePattern pattern, final AsyncCallback callback) {
            final Exchange target = configureExchange(exchange, pattern);
            LOG.debug("">>>> {} {}"", destination, exchange);
            return asyncProducer.process(target, new AsyncCallback() {

                public void done(boolean doneSync) {
                    // restore previous MEP
                    target.setPattern(existingPattern);
                    checkException(target);
                    // signal we are done
                    callback.done(doneSync);
                }
            });
        }
    });
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8227_54d7fc59,Minor,camel-core/src/main/java/org/apache/camel/processor/SendProcessor.java,182,189,"protected Exchange configureExchange(Exchange exchange, ExchangePattern pattern) {
    if (pattern != null) {
        exchange.setPattern(pattern);
    }
    // set property which endpoint we send to
    exchange.setProperty(Exchange.TO_ENDPOINT, destination.getEndpointUri());
    return exchange;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8584_dd0f74c0,Major,camel-core/src/main/java/org/apache/camel/processor/loadbalancer/CircuitBreakerLoadBalancer.java,201,210,"private boolean rejectExchange(final Exchange exchange, final AsyncCallback callback) {
    exchange.setException(new RejectedExecutionException(""CircuitBreaker Open: failures: "" + failures + "", lastFailure: "" + lastFailure));
    /*
         * If the circuit opens, we have to prevent the execution of any
         * processor. The failures count can be set to 0.
         */
    failures.set(0);
    callback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8592_57f72cd9,Minor,camel-core/src/main/java/org/apache/camel/processor/aggregate/AbstractListAggregationStrategy.java,63,71,"@SuppressWarnings(""unchecked"")
public void onCompletion(Exchange exchange) {
    if (isStoreAsBodyOnCompletion()) {
        List<V> list = (List<V>) exchange.removeProperty(Exchange.GROUPED_EXCHANGE);
        if (list != null) {
            exchange.getIn().setBody(list);
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8624_597883fa,Major,camel-core/src/main/java/org/apache/camel/component/bean/BeanInfo.java,742,809,"private MethodInfo chooseBestPossibleMethodInfo(Exchange exchange, Collection<MethodInfo> operationList, Object body, List<MethodInfo> possibles, List<MethodInfo> possiblesWithException, List<MethodInfo> possibleWithCustomAnnotation) throws AmbiguousMethodCallException {
    Exception exception = ExpressionBuilder.exchangeExceptionExpression().evaluate(exchange, Exception.class);
    if (exception != null && possiblesWithException.size() == 1) {
        LOG.trace(""Exchange has exception set so we prefer method that also has exception as parameter"");
        // prefer the method that accepts exception in case we have an exception also
        return possiblesWithException.get(0);
    } else if (possibles.size() == 1) {
        return possibles.get(0);
    } else if (possibles.isEmpty()) {
        LOG.trace(""No possible methods so now trying to convert body to parameter types"");
        // let's try converting
        Object newBody = null;
        MethodInfo matched = null;
        int matchCounter = 0;
        for (MethodInfo methodInfo : operationList) {
            if (methodInfo.getBodyParameterType().isInstance(body)) {
                return methodInfo;
            }
            // we should only try to convert, as we are looking for best match
            Object value = exchange.getContext().getTypeConverter().tryConvertTo(methodInfo.getBodyParameterType(), exchange, body);
            if (value != null) {
                if (LOG.isTraceEnabled()) {
                    LOG.trace(""Converted body from: {} to: {}"", body.getClass().getCanonicalName(), methodInfo.getBodyParameterType().getCanonicalName());
                }
                matchCounter++;
                newBody = value;
                matched = methodInfo;
            }
        }
        if (matchCounter > 1) {
            throw new AmbiguousMethodCallException(exchange, Arrays.asList(matched, matched));
        }
        if (matched != null) {
            LOG.trace(""Setting converted body: {}"", body);
            Message in = exchange.getIn();
            in.setBody(newBody);
            return matched;
        }
    } else {
        // if we only have a single method with custom annotations, let's use that one
        if (possibleWithCustomAnnotation.size() == 1) {
            MethodInfo answer = possibleWithCustomAnnotation.get(0);
            LOG.trace(""There are only one method with annotations so we choose it: {}"", answer);
            return answer;
        }
        // try to choose among multiple methods with annotations
        MethodInfo chosen = chooseMethodWithCustomAnnotations(exchange, possibles);
        if (chosen != null) {
            return chosen;
        }
        // just make sure the methods aren't all actually the same
        chosen = getSingleCovariantMethod(possibles);
        if (chosen != null) {
            return chosen;
        }
        throw new AmbiguousMethodCallException(exchange, possibles);
    }
    // cannot find a good method to use
    return null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8626_d063f471,Critical,camel-core/src/main/java/org/apache/camel/management/mbean/ManagedRoute.java,418,422,"@Override
public void init(ManagementStrategy strategy) {
    super.init(strategy);
    exchangesInFlightStartTimestamps.clear();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8954_7b1253db,Minor,camel-core/src/main/java/org/apache/camel/component/file/GenericFile.java,61,85,"/**
 * Creates a copy based on the source
 *
 * @param source the source
 * @return a copy of the source
 */
@SuppressWarnings(""unchecked"")
public GenericFile<T> copyFrom(GenericFile<T> source) {
    GenericFile<T> result;
    try {
        result = source.getClass().newInstance();
    } catch (Exception e) {
        throw ObjectHelper.wrapRuntimeCamelException(e);
    }
    result.setEndpointPath(source.getEndpointPath());
    result.setAbsolute(source.isAbsolute());
    result.setDirectory(source.isDirectory());
    result.setAbsoluteFilePath(source.getAbsoluteFilePath());
    result.setRelativeFilePath(source.getRelativeFilePath());
    result.setFileName(source.getFileName());
    result.setFileNameOnly(source.getFileNameOnly());
    result.setFileLength(source.getFileLength());
    result.setLastModified(source.getLastModified());
    result.setFile(source.getFile());
    result.setBody(source.getBody());
    result.setBinding(source.getBinding());
    result.setCharset(source.getCharset());
    copyFromPopulateAdditional(source, result);
    return result;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8954_7b1253db,Minor,camel-core/src/main/java/org/apache/camel/component/file/strategy/FileLockExclusiveReadLockStrategy.java,53,135,"@Override
public boolean acquireExclusiveReadLock(GenericFileOperations<File> operations, GenericFile<File> file, Exchange exchange) throws Exception {
    // must call super
    if (!super.acquireExclusiveReadLock(operations, file, exchange)) {
        return false;
    }
    File target = new File(file.getAbsoluteFilePath());
    LOG.trace(""Waiting for exclusive read lock to file: {}"", target);
    FileChannel channel = null;
    RandomAccessFile randomAccessFile = null;
    boolean exclusive = false;
    FileLock lock = null;
    try {
        randomAccessFile = new RandomAccessFile(target, ""rw"");
        // try to acquire rw lock on the file before we can consume it
        channel = randomAccessFile.getChannel();
        StopWatch watch = new StopWatch();
        while (!exclusive) {
            // timeout check
            if (timeout > 0) {
                long delta = watch.taken();
                if (delta > timeout) {
                    CamelLogger.log(LOG, readLockLoggingLevel, ""Cannot acquire read lock within "" + timeout + "" millis. Will skip the file: "" + target);
                    // we could not get the lock within the timeout period, so return false
                    return false;
                }
            }
            // get the lock using either try lock or not depending on if we are using timeout or not
            try {
                lock = timeout > 0 ? channel.tryLock() : channel.lock();
            } catch (IllegalStateException ex) {
            // Also catch the OverlappingFileLockException here. Do nothing here
            }
            if (lock != null) {
                LOG.trace(""Acquired exclusive read lock: {} to file: {}"", lock, target);
                exclusive = true;
            } else {
                boolean interrupted = sleep();
                if (interrupted) {
                    // we were interrupted while sleeping, we are likely being shutdown so return false
                    return false;
                }
            }
        }
    } catch (IOException e) {
        // such as AntiVirus or MS Office that has special locks for it's supported files
        if (timeout == 0) {
            // if not using timeout, then we cant retry, so return false
            return false;
        }
        LOG.debug(""Cannot acquire read lock. Will try again."", e);
        boolean interrupted = sleep();
        if (interrupted) {
            // we were interrupted while sleeping, we are likely being shutdown so return false
            return false;
        }
    } finally {
        // close channels if we did not grab the lock
        if (!exclusive) {
            IOHelper.close(channel, ""while acquiring exclusive read lock for file: "" + target, LOG);
            IOHelper.close(randomAccessFile, ""while acquiring exclusive read lock for file: "" + target, LOG);
            // and also must release super lock
            super.releaseExclusiveReadLockOnAbort(operations, file, exchange);
        }
    }
    // we grabbed the lock
    exchange.setProperty(Exchange.FILE_LOCK_EXCLUSIVE_LOCK, lock);
    exchange.setProperty(Exchange.FILE_LOCK_RANDOM_ACCESS_FILE, randomAccessFile);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8954_7b1253db,Minor,camel-core/src/main/java/org/apache/camel/component/file/strategy/FileLockExclusiveReadLockStrategy.java,137,157,"@Override
protected void doReleaseExclusiveReadLock(GenericFileOperations<File> operations, GenericFile<File> file, Exchange exchange) throws Exception {
    // must call super
    super.doReleaseExclusiveReadLock(operations, file, exchange);
    String target = file.getFileName();
    FileLock lock = exchange.getProperty(Exchange.FILE_LOCK_EXCLUSIVE_LOCK, FileLock.class);
    RandomAccessFile rac = exchange.getProperty(Exchange.FILE_LOCK_RANDOM_ACCESS_FILE, RandomAccessFile.class);
    if (lock != null) {
        Channel channel = lock.acquiredBy();
        try {
            lock.release();
        } finally {
            // close channel as well
            IOHelper.close(channel, ""while releasing exclusive read lock for file: "" + target, LOG);
            IOHelper.close(rac, ""while releasing exclusive read lock for file: "" + target, LOG);
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8954_7b1253db,Minor,camel-core/src/main/java/org/apache/camel/component/file/strategy/MarkerFileExclusiveReadLockStrategy.java,62,80,"@Override
public boolean acquireExclusiveReadLock(GenericFileOperations<File> operations, GenericFile<File> file, Exchange exchange) throws Exception {
    if (!markerFile) {
        // if not using marker file then we assume acquired
        return true;
    }
    String lockFileName = getLockFileName(file);
    LOG.trace(""Locking the file: {} using the lock file name: {}"", file, lockFileName);
    // create a plain file as marker filer for locking (do not use FileLock)
    boolean acquired = FileUtil.createNewFile(new File(lockFileName));
    exchange.setProperty(Exchange.FILE_LOCK_FILE_ACQUIRED, acquired);
    exchange.setProperty(Exchange.FILE_LOCK_FILE_NAME, lockFileName);
    return acquired;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8954_7b1253db,Minor,camel-core/src/main/java/org/apache/camel/component/file/strategy/MarkerFileExclusiveReadLockStrategy.java,97,115,"protected void doReleaseExclusiveReadLock(GenericFileOperations<File> operations, GenericFile<File> file, Exchange exchange) throws Exception {
    if (!markerFile) {
        // if not using marker file then nothing to release
        return;
    }
    // only release the file if camel get the lock before
    if (exchange.getProperty(Exchange.FILE_LOCK_FILE_ACQUIRED, false, Boolean.class)) {
        String lockFileName = exchange.getProperty(Exchange.FILE_LOCK_FILE_NAME, getLockFileName(file), String.class);
        File lock = new File(lockFileName);
        if (lock.exists()) {
            LOG.trace(""Unlocking file: {}"", lockFileName);
            boolean deleted = FileUtil.deleteFile(lock);
            LOG.trace(""Lock file: {} was deleted: {}"", lockFileName, deleted);
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8964_ea8ee025,Major,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,977,988,"public synchronized void resumeRoute(String routeId) throws Exception {
    if (!routeSupportsSuspension(routeId)) {
        // start route if suspension is not supported
        startRoute(routeId);
        return;
    }
    RouteService routeService = routeServices.get(routeId);
    if (routeService != null) {
        resumeRouteService(routeService);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8964_ea8ee025,Major,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,1118,1135,"public synchronized void suspendRoute(String routeId) throws Exception {
    if (!routeSupportsSuspension(routeId)) {
        // stop if we suspend is not supported
        stopRoute(routeId);
        return;
    }
    RouteService routeService = routeServices.get(routeId);
    if (routeService != null) {
        List<RouteStartupOrder> routes = new ArrayList<RouteStartupOrder>(1);
        RouteStartupOrder order = new DefaultRouteStartupOrder(1, routeService.getRoutes().iterator().next(), routeService);
        routes.add(order);
        getShutdownStrategy().suspend(this, routes);
        // must suspend route service as well
        suspendRouteService(routeService);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8964_ea8ee025,Major,camel-core/src/main/java/org/apache/camel/impl/DefaultCamelContext.java,1137,1153,"public synchronized void suspendRoute(String routeId, long timeout, TimeUnit timeUnit) throws Exception {
    if (!routeSupportsSuspension(routeId)) {
        stopRoute(routeId, timeout, timeUnit);
        return;
    }
    RouteService routeService = routeServices.get(routeId);
    if (routeService != null) {
        List<RouteStartupOrder> routes = new ArrayList<RouteStartupOrder>(1);
        RouteStartupOrder order = new DefaultRouteStartupOrder(1, routeService.getRoutes().iterator().next(), routeService);
        routes.add(order);
        getShutdownStrategy().suspend(this, routes, timeout, timeUnit);
        // must suspend route service as well
        suspendRouteService(routeService);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8964_ea8ee025,Major,camel-core/src/main/java/org/apache/camel/util/ServiceHelper.java,265,288,"/**
 * Resumes each element of the given {@code services} if {@code services} itself is
 * not {@code null}, otherwise this method would return immediately.
 * <p/>
 * If there's any exception being thrown while resuming the elements one after the
 * other this method would rethrow the <b>first</b> such exception being thrown.
 *
 * @see #resumeService(Service)
 */
public static void resumeServices(Collection<?> services) throws Exception {
    if (services == null) {
        return;
    }
    Exception firstException = null;
    for (Object value : services) {
        if (value instanceof Service) {
            Service service = (Service) value;
            try {
                resumeService(service);
            } catch (Exception e) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Caught exception resuming service: "" + service, e);
                }
                if (firstException == null) {
                    firstException = e;
                }
            }
        }
    }
    if (firstException != null) {
        throw firstException;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8964_ea8ee025,Major,camel-core/src/main/java/org/apache/camel/util/ServiceHelper.java,311,325,"/**
 * Resumes the given {@code service}.
 * <p/>
 * If {@code service} is a {@link org.apache.camel.SuspendableService} then
 * it's {@link org.apache.camel.SuspendableService#resume()} is called but
 * <b>only</b> if {@code service} is already {@link #isSuspended(Object)
 * suspended}.
 * <p/>
 * If {@code service} is <b>not</b> a
 * {@link org.apache.camel.SuspendableService} then it's
 * {@link org.apache.camel.Service#start()} is called.
 * <p/>
 * Calling this method has no effect if {@code service} is {@code null}.
 *
 * @param service the service
 * @return <tt>true</tt> if either <tt>resume</tt> method or
 *         {@link #startService(Service)} was called, <tt>false</tt>
 *         otherwise.
 * @throws Exception is thrown if error occurred
 * @see #startService(Service)
 */
public static boolean resumeService(Service service) throws Exception {
    if (service instanceof SuspendableService) {
        SuspendableService ss = (SuspendableService) service;
        if (ss.isSuspended()) {
            LOG.debug(""Resuming service {}"", service);
            ss.resume();
            return true;
        } else {
            return false;
        }
    } else {
        startService(service);
        return true;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8964_ea8ee025,Major,camel-core/src/main/java/org/apache/camel/util/ServiceHelper.java,336,359,"/**
 * Suspends each element of the given {@code services} if {@code services} itself is
 * not {@code null}, otherwise this method would return immediately.
 * <p/>
 * If there's any exception being thrown while suspending the elements one after the
 * other this method would rethrow the <b>first</b> such exception being thrown.
 *
 * @see #suspendService(Service)
 */
public static void suspendServices(Collection<?> services) throws Exception {
    if (services == null) {
        return;
    }
    Exception firstException = null;
    for (Object value : services) {
        if (value instanceof Service) {
            Service service = (Service) value;
            try {
                suspendService(service);
            } catch (Exception e) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Caught exception suspending service: "" + service, e);
                }
                if (firstException == null) {
                    firstException = e;
                }
            }
        }
    }
    if (firstException != null) {
        throw firstException;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-8964_ea8ee025,Major,camel-core/src/main/java/org/apache/camel/util/ServiceHelper.java,382,396,"/**
 * Suspends the given {@code service}.
 * <p/>
 * If {@code service} is a {@link org.apache.camel.SuspendableService} then
 * it's {@link org.apache.camel.SuspendableService#suspend()} is called but
 * <b>only</b> if {@code service} is <b>not</b> already
 * {@link #isSuspended(Object) suspended}.
 * <p/>
 * If {@code service} is <b>not</b> a
 * {@link org.apache.camel.SuspendableService} then it's
 * {@link org.apache.camel.Service#stop()} is called.
 * <p/>
 * Calling this method has no effect if {@code service} is {@code null}.
 *
 * @param service the service
 * @return <tt>true</tt> if either the <tt>suspend</tt> method or
 *         {@link #stopService(Object)} was called, <tt>false</tt>
 *         otherwise.
 * @throws Exception is thrown if error occurred
 * @see #stopService(Object)
 */
public static boolean suspendService(Service service) throws Exception {
    if (service instanceof SuspendableService) {
        SuspendableService ss = (SuspendableService) service;
        if (!ss.isSuspended()) {
            LOG.trace(""Suspending service {}"", service);
            ss.suspend();
            return true;
        } else {
            return false;
        }
    } else {
        stopService(service);
        return true;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9032_108d94f7,Major,camel-core/src/main/java/org/apache/camel/component/bean/BeanInfo.java,547,627,"/**
 * Choose one of the available methods to invoke if we can match
 * the message body to the body parameter
 *
 * @param pojo the bean to invoke a method on
 * @param exchange the message exchange
 * @param name an optional name of the method that must match, use <tt>null</tt> to indicate all methods
 * @return the method to invoke or null if no definitive method could be matched
 * @throws AmbiguousMethodCallException is thrown if cannot choose method due to ambiguity
 */
protected MethodInfo chooseMethod(Object pojo, Exchange exchange, String name) throws AmbiguousMethodCallException {
    // @Handler should be select first
    // then any single method that has a custom @annotation
    // or any single method that has a match parameter type that matches the Exchange payload
    // and last then try to select the best among the rest
    // must use defensive copy, to avoid altering the shared lists
    // and we want to remove unwanted operations from these local lists
    final List<MethodInfo> localOperationsWithBody = new ArrayList<MethodInfo>(operationsWithBody);
    final List<MethodInfo> localOperationsWithNoBody = new ArrayList<MethodInfo>(operationsWithNoBody);
    final List<MethodInfo> localOperationsWithCustomAnnotation = new ArrayList<MethodInfo>(operationsWithCustomAnnotation);
    final List<MethodInfo> localOperationsWithHandlerAnnotation = new ArrayList<MethodInfo>(operationsWithHandlerAnnotation);
    if (name != null) {
        // filter all lists to only include methods with this name
        removeNonMatchingMethods(localOperationsWithHandlerAnnotation, name);
        removeNonMatchingMethods(localOperationsWithCustomAnnotation, name);
        removeNonMatchingMethods(localOperationsWithBody, name);
        removeNonMatchingMethods(localOperationsWithNoBody, name);
    } else {
        // remove all getter/setter as we do not want to consider these methods
        removeAllSetterOrGetterMethods(localOperationsWithHandlerAnnotation);
        removeAllSetterOrGetterMethods(localOperationsWithCustomAnnotation);
        removeAllSetterOrGetterMethods(localOperationsWithBody);
        removeAllSetterOrGetterMethods(localOperationsWithNoBody);
    }
    if (localOperationsWithHandlerAnnotation.size() > 1) {
        // if we have more than 1 @Handler then its ambiguous
        throw new AmbiguousMethodCallException(exchange, localOperationsWithHandlerAnnotation);
    }
    if (localOperationsWithHandlerAnnotation.size() == 1) {
        // methods with handler should be preferred
        return localOperationsWithHandlerAnnotation.get(0);
    } else if (localOperationsWithCustomAnnotation.size() == 1) {
        // if there is one method with an annotation then use that one
        return localOperationsWithCustomAnnotation.get(0);
    }
    // named method and with no parameters
    boolean noParameters = name != null && name.endsWith(""()"");
    if (noParameters && localOperationsWithNoBody.size() == 1) {
        // if there was a method name configured and it has no parameters, then use the method with no body (eg no parameters)
        return localOperationsWithNoBody.get(0);
    } else if (!noParameters && localOperationsWithBody.size() == 1 && localOperationsWithCustomAnnotation.isEmpty()) {
        // if there is one method with body then use that one
        return localOperationsWithBody.get(0);
    }
    Collection<MethodInfo> possibleOperations = new ArrayList<MethodInfo>();
    possibleOperations.addAll(localOperationsWithBody);
    possibleOperations.addAll(localOperationsWithCustomAnnotation);
    if (!possibleOperations.isEmpty()) {
        // multiple possible operations so find the best suited if possible
        MethodInfo answer = chooseMethodWithMatchingBody(exchange, possibleOperations, localOperationsWithCustomAnnotation);
        if (answer == null && name != null) {
            // do we have hardcoded parameters values provided from the method name then fallback and try that
            String parameters = ObjectHelper.between(name, ""("", "")"");
            if (parameters != null) {
                // special as we have hardcoded parameters, so we need to choose method that matches those parameters the best
                answer = chooseMethodWithMatchingParameters(exchange, parameters, possibleOperations);
            }
        }
        if (answer == null && possibleOperations.size() > 1) {
            answer = getSingleCovariantMethod(possibleOperations);
        }
        if (answer == null) {
            throw new AmbiguousMethodCallException(exchange, possibleOperations);
        } else {
            return answer;
        }
    }
    // not possible to determine
    return null;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9032_108d94f7,Major,camel-core/src/main/java/org/apache/camel/component/bean/BeanInfo.java,820,845,"/**
 * Validates whether the given method is a valid candidate for Camel Bean Binding.
 *
 * @param clazz   the class
 * @param method  the method
 * @return true if valid, false to skip the method
 */
protected boolean isValidMethod(Class<?> clazz, Method method) {
    // must not be in the excluded list
    for (Method excluded : EXCLUDED_METHODS) {
        if (ObjectHelper.isOverridingMethod(excluded, method)) {
            // the method is overriding an excluded method so its not valid
            return false;
        }
    }
    // must be a public method
    if (!Modifier.isPublic(method.getModifiers())) {
        return false;
    }
    // must not be abstract
    if (Modifier.isAbstract(method.getModifiers())) {
        return false;
    }
    // return type must not be an Exchange and it should not be a bridge method
    if ((method.getReturnType() != null && Exchange.class.isAssignableFrom(method.getReturnType())) || method.isBridge()) {
        return false;
    }
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9124_9da2c05a,Minor,camel-core/src/main/java/org/apache/camel/model/RedeliveryPolicyDefinition.java,85,172,"public RedeliveryPolicy createRedeliveryPolicy(CamelContext context, RedeliveryPolicy parentPolicy) {
    RedeliveryPolicy answer;
    if (parentPolicy != null) {
        answer = parentPolicy.copy();
    } else {
        answer = new RedeliveryPolicy();
    }
    try {
        // copy across the properties - if they are set
        if (maximumRedeliveries != null) {
            answer.setMaximumRedeliveries(CamelContextHelper.parseInteger(context, maximumRedeliveries));
        }
        if (redeliveryDelay != null) {
            answer.setRedeliveryDelay(CamelContextHelper.parseLong(context, redeliveryDelay));
        }
        if (asyncDelayedRedelivery != null) {
            if (CamelContextHelper.parseBoolean(context, asyncDelayedRedelivery)) {
                answer.asyncDelayedRedelivery();
            }
        }
        if (retriesExhaustedLogLevel != null) {
            answer.setRetriesExhaustedLogLevel(retriesExhaustedLogLevel);
        }
        if (retryAttemptedLogLevel != null) {
            answer.setRetryAttemptedLogLevel(retryAttemptedLogLevel);
        }
        if (backOffMultiplier != null) {
            answer.setBackOffMultiplier(CamelContextHelper.parseDouble(context, backOffMultiplier));
        }
        if (useExponentialBackOff != null) {
            answer.setUseExponentialBackOff(CamelContextHelper.parseBoolean(context, useExponentialBackOff));
        }
        if (collisionAvoidanceFactor != null) {
            answer.setCollisionAvoidanceFactor(CamelContextHelper.parseDouble(context, collisionAvoidanceFactor));
        }
        if (useCollisionAvoidance != null) {
            answer.setUseCollisionAvoidance(CamelContextHelper.parseBoolean(context, useCollisionAvoidance));
        }
        if (maximumRedeliveryDelay != null) {
            answer.setMaximumRedeliveryDelay(CamelContextHelper.parseLong(context, maximumRedeliveryDelay));
        }
        if (logStackTrace != null) {
            answer.setLogStackTrace(CamelContextHelper.parseBoolean(context, logStackTrace));
        }
        if (logRetryStackTrace != null) {
            answer.setLogRetryStackTrace(CamelContextHelper.parseBoolean(context, logRetryStackTrace));
        }
        if (logHandled != null) {
            answer.setLogHandled(CamelContextHelper.parseBoolean(context, logHandled));
        }
        if (logNewException != null) {
            answer.setLogNewException(CamelContextHelper.parseBoolean(context, logNewException));
        }
        if (logContinued != null) {
            answer.setLogContinued(CamelContextHelper.parseBoolean(context, logContinued));
        }
        if (logRetryAttempted != null) {
            answer.setLogRetryAttempted(CamelContextHelper.parseBoolean(context, logRetryAttempted));
        }
        if (logExhausted != null) {
            answer.setLogExhausted(CamelContextHelper.parseBoolean(context, logExhausted));
        }
        if (logExhaustedMessageHistory != null) {
            answer.setLogExhaustedMessageHistory(CamelContextHelper.parseBoolean(context, logExhaustedMessageHistory));
        }
        if (disableRedelivery != null) {
            if (CamelContextHelper.parseBoolean(context, disableRedelivery)) {
                answer.setMaximumRedeliveries(0);
            }
        }
        if (delayPattern != null) {
            answer.setDelayPattern(delayPattern);
        }
        if (allowRedeliveryWhileStopping != null) {
            answer.setAllowRedeliveryWhileStopping(CamelContextHelper.parseBoolean(context, allowRedeliveryWhileStopping));
        }
        if (exchangeFormatterRef != null) {
            answer.setExchangeFormatterRef(exchangeFormatterRef);
        }
    } catch (Exception e) {
        throw ObjectHelper.wrapRuntimeCamelException(e);
    }
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9143_08077733,Major,camel-core/src/main/java/org/apache/camel/impl/ProducerCache.java,469,484,"protected void doStop() throws Exception {
    // when stopping we intend to shutdown
    ServiceHelper.stopAndShutdownServices(statistics, pool);
    try {
        ServiceHelper.stopAndShutdownServices(producers.values());
    } finally {
        // ensure producers are removed, and also from JMX
        for (Producer producer : producers.values()) {
            getCamelContext().removeService(producer);
        }
    }
    producers.clear();
    if (statistics != null) {
        statistics.clear();
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9217_e7ac45b6,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultComponent.java,198,221,"/**
 * Strategy for validation of the uri when creating the endpoint.
 *
 * @param uri        the uri
 * @param path       the path - part after the scheme
 * @param parameters the parameters, an empty map if no parameters given
 * @throws ResolveEndpointFailedException should be thrown if the URI validation failed
 */
protected void validateURI(String uri, String path, Map<String, Object> parameters) {
    // check for uri containing & but no ? marker
    if (uri.contains(""&"") && !uri.contains(""?"")) {
        throw new ResolveEndpointFailedException(uri, ""Invalid uri syntax: no ? marker however the uri "" + ""has & parameter separators. Check the uri if its missing a ? marker."");
    }
    // check for uri containing double && markers without include by RAW
    if (uri.contains(""&&"")) {
        Pattern pattern = Pattern.compile(""RAW(.*&&.*)"");
        Matcher m = pattern.matcher(uri);
        // we should skip the RAW part
        if (!m.find()) {
            throw new ResolveEndpointFailedException(uri, ""Invalid uri syntax: Double && marker found. "" + ""Check the uri and remove the duplicate & marker."");
        }
    }
    // if we have a trailing & then that is invalid as well
    if (uri.endsWith(""&"")) {
        throw new ResolveEndpointFailedException(uri, ""Invalid uri syntax: Trailing & marker found. "" + ""Check the uri and remove the trailing & marker."");
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9238_169b981e,Major,camel-core/src/main/java/org/apache/camel/component/file/GenericFile.java,183,241,"/**
 * Changes the name of this remote file. This method alters the absolute and
 * relative names as well.
 *
 * @param newName the new name
 */
public void changeFileName(String newName) {
    LOG.trace(""Changing name to: {}"", newName);
    // Make sure the names is normalized.
    String newFileName = FileUtil.normalizePath(newName);
    String newEndpointPath = FileUtil.normalizePath(endpointPath);
    LOG.trace(""Normalized endpointPath: {}"", newEndpointPath);
    LOG.trace(""Normalized newFileName: ()"", newFileName);
    File file = new File(newFileName);
    if (!absolute) {
        // for relative then we should avoid having the endpoint path duplicated so clip it
        if (ObjectHelper.isNotEmpty(newEndpointPath) && newFileName.startsWith(newEndpointPath)) {
            // in this logic here
            if (newEndpointPath.endsWith("""" + File.separatorChar)) {
                newFileName = ObjectHelper.after(newFileName, newEndpointPath);
            } else {
                newFileName = ObjectHelper.after(newFileName, newEndpointPath + File.separatorChar);
            }
            // reconstruct file with clipped name
            file = new File(newFileName);
        }
    }
    // store the file name only
    setFileNameOnly(file.getName());
    setFileName(file.getName());
    // relative path
    if (file.getParent() != null) {
        setRelativeFilePath(file.getParent() + getFileSeparator() + file.getName());
    } else {
        setRelativeFilePath(file.getName());
    }
    // absolute path
    if (isAbsolute(newFileName)) {
        setAbsolute(true);
        setAbsoluteFilePath(newFileName);
    } else {
        setAbsolute(false);
        // construct a pseudo absolute filename that the file operations uses even for relative only
        String path = ObjectHelper.isEmpty(endpointPath) ? """" : endpointPath + getFileSeparator();
        setAbsoluteFilePath(path + getRelativeFilePath());
    }
    if (LOG.isTraceEnabled()) {
        LOG.trace(""FileNameOnly: {}"", getFileNameOnly());
        LOG.trace(""FileName: {}"", getFileName());
        LOG.trace(""Absolute: {}"", isAbsolute());
        LOG.trace(""Relative path: {}"", getRelativeFilePath());
        LOG.trace(""Absolute path: {}"", getAbsoluteFilePath());
        LOG.trace(""Name changed to: {}"", this);
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9243_1957a828,Major,camel-core/src/main/java/org/apache/camel/component/bean/BeanInfo.java,986,995,"private void removeAllAbstractMethods(List<MethodInfo> methods) {
    Iterator<MethodInfo> it = methods.iterator();
    while (it.hasNext()) {
        MethodInfo info = it.next();
        if (Modifier.isAbstract(info.getMethod().getModifiers())) {
            // we cannot invoke an abstract method
            it.remove();
        }
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9269_62b2042b,Major,camel-core/src/main/java/org/apache/camel/builder/NotifyBuilder.java,145,172,"/**
 * Optionally a <tt>from</tt> route which means that this expression should only be based
 * on {@link Exchange} which is originated from the particular route(s).
 *
 * @param routeId id of route or pattern (see the EndpointHelper javadoc)
 * @return the builder
 * @see org.apache.camel.util.EndpointHelper#matchEndpoint(org.apache.camel.CamelContext, String, String)
 */
public NotifyBuilder fromRoute(final String routeId) {
    stack.add(new EventPredicateSupport() {

        @Override
        public boolean isAbstract() {
            // is abstract as its a filter
            return true;
        }

        @Override
        public boolean onExchange(Exchange exchange) {
            String id = EndpointHelper.getRouteIdFromEndpoint(exchange.getFromEndpoint());
            // filter non matching exchanges
            return EndpointHelper.matchPattern(id, routeId);
        }

        public boolean matches() {
            // should be true as we use the onExchange to filter
            return true;
        }

        @Override
        public String toString() {
            return ""fromRoute("" + routeId + "")"";
        }
    });
    return this;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9269_62b2042b,Major,camel-core/src/main/java/org/apache/camel/builder/NotifyBuilder.java,154,159,"@Override
public boolean onExchange(Exchange exchange) {
    String id = EndpointHelper.getRouteIdFromEndpoint(exchange.getFromEndpoint());
    // filter non matching exchanges
    return EndpointHelper.matchPattern(id, routeId);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9340_1cab39f6,Trivial,camel-core/src/main/java/org/apache/camel/processor/idempotent/FileIdempotentRepository.java,288,320,"/**
 * Loads the given file store into the 1st level cache
 */
protected void loadStore() throws IOException {
    // auto create starting directory if needed
    if (!fileStore.exists()) {
        LOG.debug(""Creating filestore: {}"", fileStore);
        File parent = fileStore.getParentFile();
        parent.mkdirs();
        boolean created = FileUtil.createNewFile(fileStore);
        if (!created) {
            throw new IOException(""Cannot create filestore: "" + fileStore);
        }
    }
    LOG.trace(""Loading to 1st level cache from idempotent filestore: {}"", fileStore);
    cache.clear();
    Scanner scanner = null;
    try {
        scanner = new Scanner(fileStore);
        scanner.useDelimiter(STORE_DELIMITER);
        while (scanner.hasNextLine()) {
            String line = scanner.nextLine();
            cache.put(line, line);
        }
    } catch (IOException e) {
        throw ObjectHelper.wrapRuntimeCamelException(e);
    } finally {
        if (scanner != null) {
            scanner.close();
        }
    }
    LOG.debug(""Loaded {} to the 1st level cache from idempotent filestore: {}"", cache.size(), fileStore);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9444_baece126,Major,camel-core/src/main/java/org/apache/camel/model/MulticastDefinition.java,289,316,"protected Processor createCompositeProcessor(RouteContext routeContext, List<Processor> list) throws Exception {
    AggregationStrategy strategy = createAggregationStrategy(routeContext);
    if (strategy == null) {
        // default to use latest aggregation strategy
        strategy = new UseLatestAggregationStrategy();
    }
    boolean isParallelProcessing = getParallelProcessing() != null && getParallelProcessing();
    boolean isShareUnitOfWork = getShareUnitOfWork() != null && getShareUnitOfWork();
    boolean isStreaming = getStreaming() != null && getStreaming();
    boolean isStopOnException = getStopOnException() != null && getStopOnException();
    boolean isParallelAggregate = getParallelAggregate() != null && getParallelAggregate();
    boolean shutdownThreadPool = ProcessorDefinitionHelper.willCreateNewThreadPool(routeContext, this, isParallelProcessing);
    ExecutorService threadPool = ProcessorDefinitionHelper.getConfiguredExecutorService(routeContext, ""Multicast"", this, isParallelProcessing);
    long timeout = getTimeout() != null ? getTimeout() : 0;
    if (timeout > 0 && !isParallelProcessing) {
        throw new IllegalArgumentException(""Timeout is used but ParallelProcessing has not been enabled."");
    }
    if (onPrepareRef != null) {
        onPrepare = CamelContextHelper.mandatoryLookup(routeContext.getCamelContext(), onPrepareRef, Processor.class);
    }
    MulticastProcessor answer = new MulticastProcessor(routeContext.getCamelContext(), list, strategy, isParallelProcessing, threadPool, shutdownThreadPool, isStreaming, isStopOnException, timeout, onPrepare, isShareUnitOfWork, isParallelAggregate);
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9444_baece126,Major,camel-core/src/main/java/org/apache/camel/model/MulticastDefinition.java,318,341,"private AggregationStrategy createAggregationStrategy(RouteContext routeContext) {
    AggregationStrategy strategy = getAggregationStrategy();
    if (strategy == null && strategyRef != null) {
        Object aggStrategy = routeContext.lookup(strategyRef, Object.class);
        if (aggStrategy instanceof AggregationStrategy) {
            strategy = (AggregationStrategy) aggStrategy;
        } else if (aggStrategy != null) {
            AggregationStrategyBeanAdapter adapter = new AggregationStrategyBeanAdapter(aggStrategy, getStrategyMethodName());
            if (getStrategyMethodAllowNull() != null) {
                adapter.setAllowNullNewExchange(getStrategyMethodAllowNull());
                adapter.setAllowNullOldExchange(getStrategyMethodAllowNull());
            }
            strategy = adapter;
        } else {
            throw new IllegalArgumentException(""Cannot find AggregationStrategy in Registry with name: "" + strategyRef);
        }
    }
    if (strategy != null && strategy instanceof CamelContextAware) {
        ((CamelContextAware) strategy).setCamelContext(routeContext.getCamelContext());
    }
    return strategy;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9444_baece126,Major,camel-core/src/main/java/org/apache/camel/model/ProcessorDefinition.java,503,555,"private Processor makeProcessorImpl(RouteContext routeContext) throws Exception {
    Processor processor = null;
    // allow any custom logic before we create the processor
    preCreateProcessor();
    // resolve properties before we create the processor
    ProcessorDefinitionHelper.resolvePropertyPlaceholders(routeContext.getCamelContext(), this);
    // resolve constant fields (eg Exchange.FILE_NAME)
    ProcessorDefinitionHelper.resolveKnownConstantFields(this);
    // also resolve properties and constant fields on embedded expressions
    ProcessorDefinition<?> me = (ProcessorDefinition<?>) this;
    if (me instanceof ExpressionNode) {
        ExpressionNode exp = (ExpressionNode) me;
        ExpressionDefinition expressionDefinition = exp.getExpression();
        if (expressionDefinition != null) {
            // resolve properties before we create the processor
            ProcessorDefinitionHelper.resolvePropertyPlaceholders(routeContext.getCamelContext(), expressionDefinition);
            // resolve constant fields (eg Exchange.FILE_NAME)
            ProcessorDefinitionHelper.resolveKnownConstantFields(expressionDefinition);
        }
    }
    // at first use custom factory
    if (routeContext.getCamelContext().getProcessorFactory() != null) {
        processor = routeContext.getCamelContext().getProcessorFactory().createProcessor(routeContext, this);
    }
    // fallback to default implementation if factory did not create the processor
    if (processor == null) {
        processor = createProcessor(routeContext);
    }
    // unwrap internal processor so we can set id on the actual processor
    Processor idProcessor = processor;
    if (processor instanceof CamelInternalProcessor) {
        idProcessor = ((CamelInternalProcessor) processor).getProcessor();
    }
    // inject id
    if (idProcessor instanceof IdAware) {
        String id = this.idOrCreate(routeContext.getCamelContext().getNodeIdFactory());
        ((IdAware) idProcessor).setId(id);
    }
    if (processor == null) {
        // no processor to make
        return null;
    }
    return wrapProcessor(routeContext, processor);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9444_baece126,Major,camel-core/src/main/java/org/apache/camel/model/RecipientListDefinition.java,178,205,"private AggregationStrategy createAggregationStrategy(RouteContext routeContext) {
    AggregationStrategy strategy = getAggregationStrategy();
    if (strategy == null && strategyRef != null) {
        Object aggStrategy = routeContext.lookup(strategyRef, Object.class);
        if (aggStrategy instanceof AggregationStrategy) {
            strategy = (AggregationStrategy) aggStrategy;
        } else if (aggStrategy != null) {
            AggregationStrategyBeanAdapter adapter = new AggregationStrategyBeanAdapter(aggStrategy, getStrategyMethodName());
            if (getStrategyMethodAllowNull() != null) {
                adapter.setAllowNullNewExchange(getStrategyMethodAllowNull());
                adapter.setAllowNullOldExchange(getStrategyMethodAllowNull());
            }
            strategy = adapter;
        } else {
            throw new IllegalArgumentException(""Cannot find AggregationStrategy in Registry with name: "" + strategyRef);
        }
    }
    if (strategy == null) {
        // fallback to use latest
        strategy = new UseLatestAggregationStrategy();
    }
    if (strategy instanceof CamelContextAware) {
        ((CamelContextAware) strategy).setCamelContext(routeContext.getCamelContext());
    }
    return strategy;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9444_baece126,Major,camel-core/src/main/java/org/apache/camel/model/SplitDefinition.java,97,123,"@Override
public Processor createProcessor(RouteContext routeContext) throws Exception {
    Processor childProcessor = this.createChildProcessor(routeContext, true);
    aggregationStrategy = createAggregationStrategy(routeContext);
    boolean isParallelProcessing = getParallelProcessing() != null && getParallelProcessing();
    boolean isStreaming = getStreaming() != null && getStreaming();
    boolean isShareUnitOfWork = getShareUnitOfWork() != null && getShareUnitOfWork();
    boolean isParallelAggregate = getParallelAggregate() != null && getParallelAggregate();
    boolean shutdownThreadPool = ProcessorDefinitionHelper.willCreateNewThreadPool(routeContext, this, isParallelProcessing);
    ExecutorService threadPool = ProcessorDefinitionHelper.getConfiguredExecutorService(routeContext, ""Split"", this, isParallelProcessing);
    long timeout = getTimeout() != null ? getTimeout() : 0;
    if (timeout > 0 && !isParallelProcessing) {
        throw new IllegalArgumentException(""Timeout is used but ParallelProcessing has not been enabled."");
    }
    if (onPrepareRef != null) {
        onPrepare = CamelContextHelper.mandatoryLookup(routeContext.getCamelContext(), onPrepareRef, Processor.class);
    }
    Expression exp = getExpression().createExpression(routeContext);
    Splitter answer = new Splitter(routeContext.getCamelContext(), exp, childProcessor, aggregationStrategy, isParallelProcessing, threadPool, shutdownThreadPool, isStreaming, isStopOnException(), timeout, onPrepare, isShareUnitOfWork, isParallelAggregate);
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9444_baece126,Major,camel-core/src/main/java/org/apache/camel/model/SplitDefinition.java,125,148,"private AggregationStrategy createAggregationStrategy(RouteContext routeContext) {
    AggregationStrategy strategy = getAggregationStrategy();
    if (strategy == null && strategyRef != null) {
        Object aggStrategy = routeContext.lookup(strategyRef, Object.class);
        if (aggStrategy instanceof AggregationStrategy) {
            strategy = (AggregationStrategy) aggStrategy;
        } else if (aggStrategy != null) {
            AggregationStrategyBeanAdapter adapter = new AggregationStrategyBeanAdapter(aggStrategy, getStrategyMethodName());
            if (getStrategyMethodAllowNull() != null) {
                adapter.setAllowNullNewExchange(getStrategyMethodAllowNull());
                adapter.setAllowNullOldExchange(getStrategyMethodAllowNull());
            }
            strategy = adapter;
        } else {
            throw new IllegalArgumentException(""Cannot find AggregationStrategy in Registry with name: "" + strategyRef);
        }
    }
    if (strategy != null && strategy instanceof CamelContextAware) {
        ((CamelContextAware) strategy).setCamelContext(routeContext.getCamelContext());
    }
    return strategy;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9444_baece126,Major,camel-core/src/main/java/org/apache/camel/processor/RecipientList.java,137,179,"/**
 * Sends the given exchange to the recipient list
 */
public boolean sendToRecipientList(Exchange exchange, Object recipientList, AsyncCallback callback) {
    Iterator<Object> iter;
    if (delimiter != null && delimiter.equalsIgnoreCase(IGNORE_DELIMITER_MARKER)) {
        iter = ObjectHelper.createIterator(recipientList, null);
    } else {
        iter = ObjectHelper.createIterator(recipientList, delimiter);
    }
    RecipientListProcessor rlp = new RecipientListProcessor(exchange.getContext(), producerCache, iter, getAggregationStrategy(), isParallelProcessing(), getExecutorService(), isShutdownExecutorService(), isStreaming(), isStopOnException(), getTimeout(), getOnPrepare(), isShareUnitOfWork(), isParallelAggregate()) {

        @Override
        protected synchronized ExecutorService createAggregateExecutorService(String name) {
            // use a shared executor service to avoid creating new thread pools
            if (aggregateExecutorService == null) {
                aggregateExecutorService = super.createAggregateExecutorService(""RecipientList-AggregateTask"");
            }
            return aggregateExecutorService;
        }
    };
    rlp.setIgnoreInvalidEndpoints(isIgnoreInvalidEndpoints());
    // start the service
    try {
        ServiceHelper.startService(rlp);
    } catch (Exception e) {
        exchange.setException(e);
        callback.done(true);
        return true;
    }
    AsyncProcessor target = rlp;
    if (isShareUnitOfWork()) {
        // wrap answer in a sub unit of work, since we share the unit of work
        CamelInternalProcessor internalProcessor = new CamelInternalProcessor(rlp);
        internalProcessor.addAdvice(new CamelInternalProcessor.SubUnitOfWorkProcessorAdvice());
        target = internalProcessor;
    }
    // now let the multicast process the exchange
    return target.process(exchange, callback);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9444_baece126,Major,camel-core/src/main/java/org/apache/camel/processor/Splitter.java,92,105,"@Override
public boolean process(Exchange exchange, final AsyncCallback callback) {
    final AggregationStrategy strategy = getAggregationStrategy();
    // to ensure it supports async routing
    if (strategy == null) {
        UseOriginalAggregationStrategy original = new UseOriginalAggregationStrategy(exchange, true);
        setAggregationStrategyOnExchange(exchange, original);
    }
    return super.process(exchange, callback);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9480_0ead2cac,Major,camel-core/src/main/java/org/apache/camel/processor/idempotent/IdempotentConsumer.java,93,143,"public boolean process(final Exchange exchange, final AsyncCallback callback) {
    final String messageId = messageIdExpression.evaluate(exchange, String.class);
    if (messageId == null) {
        exchange.setException(new NoMessageIdException(exchange, messageIdExpression));
        callback.done(true);
        return true;
    }
    boolean newKey;
    if (eager) {
        // add the key to the repository
        if (idempotentRepository instanceof ExchangeIdempotentRepository) {
            newKey = ((ExchangeIdempotentRepository<String>) idempotentRepository).add(exchange, messageId);
        } else {
            newKey = idempotentRepository.add(messageId);
        }
    } else {
        // check if we already have the key
        if (idempotentRepository instanceof ExchangeIdempotentRepository) {
            newKey = ((ExchangeIdempotentRepository<String>) idempotentRepository).contains(exchange, messageId);
        } else {
            newKey = !idempotentRepository.contains(messageId);
        }
    }
    if (!newKey) {
        // mark the exchange as duplicate
        exchange.setProperty(Exchange.DUPLICATE_MESSAGE, Boolean.TRUE);
        // we already have this key so its a duplicate message
        onDuplicate(exchange, messageId);
        if (skipDuplicate) {
            // if we should skip duplicate then we are done
            LOG.debug(""Ignoring duplicate message with id: {} for exchange: {}"", messageId, exchange);
            callback.done(true);
            return true;
        }
    }
    final Synchronization onCompletion = new IdempotentOnCompletion(idempotentRepository, messageId, eager, removeOnFailure);
    final AsyncCallback target = new IdempotentConsumerCallback(exchange, onCompletion, callback, completionEager);
    if (!completionEager) {
        // the scope is to do the idempotent completion work as an unit of work on the exchange when its done being routed
        exchange.addOnCompletion(onCompletion);
    }
    // process the exchange
    return processor.process(exchange, target);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9641_9a6e6d8a,Major,camel-core/src/main/java/org/apache/camel/language/simple/ast/SimpleFunctionExpression.java,58,247,"private Expression createSimpleExpression(String function, boolean strict) {
    // return the function directly if we can create function without analyzing the prefix
    Expression answer = createSimpleExpressionDirectly(function);
    if (answer != null) {
        return answer;
    }
    // body and headers first
    answer = createSimpleExpressionBodyOrHeader(function, strict);
    if (answer != null) {
        return answer;
    }
    // camelContext OGNL
    String remainder = ifStartsWithReturnRemainder(""camelContext"", function);
    if (remainder != null) {
        boolean invalid = OgnlHelper.isInvalidValidOgnlExpression(remainder);
        if (invalid) {
            throw new SimpleParserException(""Valid syntax: ${camelContext.OGNL} was: "" + function, token.getIndex());
        }
        return ExpressionBuilder.camelContextOgnlExpression(remainder);
    }
    // Exception OGNL
    remainder = ifStartsWithReturnRemainder(""exception"", function);
    if (remainder != null) {
        boolean invalid = OgnlHelper.isInvalidValidOgnlExpression(remainder);
        if (invalid) {
            throw new SimpleParserException(""Valid syntax: ${exception.OGNL} was: "" + function, token.getIndex());
        }
        return ExpressionBuilder.exchangeExceptionOgnlExpression(remainder);
    }
    // property
    remainder = ifStartsWithReturnRemainder(""property"", function);
    if (remainder == null) {
        remainder = ifStartsWithReturnRemainder(""exchangeProperty"", function);
    }
    if (remainder != null) {
        // remove leading character (dot or ?)
        if (remainder.startsWith(""."") || remainder.startsWith(""?"")) {
            remainder = remainder.substring(1);
        }
        // remove starting and ending brackets
        if (remainder.startsWith(""["") && remainder.endsWith(""]"")) {
            remainder = remainder.substring(1, remainder.length() - 1);
        }
        // validate syntax
        boolean invalid = OgnlHelper.isInvalidValidOgnlExpression(remainder);
        if (invalid) {
            throw new SimpleParserException(""Valid syntax: ${exchangeProperty.OGNL} was: "" + function, token.getIndex());
        }
        if (OgnlHelper.isValidOgnlExpression(remainder)) {
            // ognl based property
            return ExpressionBuilder.propertyOgnlExpression(remainder);
        } else {
            // regular property
            return ExpressionBuilder.exchangePropertyExpression(remainder);
        }
    }
    // system property
    remainder = ifStartsWithReturnRemainder(""sys."", function);
    if (remainder != null) {
        return ExpressionBuilder.systemPropertyExpression(remainder);
    }
    remainder = ifStartsWithReturnRemainder(""sysenv."", function);
    if (remainder != null) {
        return ExpressionBuilder.systemEnvironmentExpression(remainder);
    }
    // exchange OGNL
    remainder = ifStartsWithReturnRemainder(""exchange"", function);
    if (remainder != null) {
        boolean invalid = OgnlHelper.isInvalidValidOgnlExpression(remainder);
        if (invalid) {
            throw new SimpleParserException(""Valid syntax: ${exchange.OGNL} was: "" + function, token.getIndex());
        }
        return ExpressionBuilder.exchangeOgnlExpression(remainder);
    }
    // file: prefix
    remainder = ifStartsWithReturnRemainder(""file:"", function);
    if (remainder != null) {
        Expression fileExpression = createSimpleFileExpression(remainder);
        if (function != null) {
            return fileExpression;
        }
    }
    // date: prefix
    remainder = ifStartsWithReturnRemainder(""date:"", function);
    if (remainder != null) {
        String[] parts = remainder.split("":"");
        if (parts.length < 2) {
            throw new SimpleParserException(""Valid syntax: ${date:command:pattern} was: "" + function, token.getIndex());
        }
        String command = ObjectHelper.before(remainder, "":"");
        String pattern = ObjectHelper.after(remainder, "":"");
        return ExpressionBuilder.dateExpression(command, pattern);
    }
    // bean: prefix
    remainder = ifStartsWithReturnRemainder(""bean:"", function);
    if (remainder != null) {
        return ExpressionBuilder.beanExpression(remainder);
    }
    // properties: prefix
    remainder = ifStartsWithReturnRemainder(""properties:"", function);
    if (remainder != null) {
        String[] parts = remainder.split("":"");
        if (parts.length > 2) {
            throw new SimpleParserException(""Valid syntax: ${properties:key[:default]} was: "" + function, token.getIndex());
        }
        return ExpressionBuilder.propertiesComponentExpression(remainder, null);
    }
    // properties-location: prefix
    remainder = ifStartsWithReturnRemainder(""properties-location:"", function);
    if (remainder != null) {
        String[] parts = remainder.split("":"");
        if (parts.length > 3) {
            throw new SimpleParserException(""Valid syntax: ${properties-location:location:key[:default]} was: "" + function, token.getIndex());
        }
        String locations = null;
        String key = remainder;
        if (parts.length >= 2) {
            locations = ObjectHelper.before(remainder, "":"");
            key = ObjectHelper.after(remainder, "":"");
        }
        return ExpressionBuilder.propertiesComponentExpression(key, locations);
    }
    // ref: prefix
    remainder = ifStartsWithReturnRemainder(""ref:"", function);
    if (remainder != null) {
        return ExpressionBuilder.refExpression(remainder);
    }
    // const: prefix
    remainder = ifStartsWithReturnRemainder(""type:"", function);
    if (remainder != null) {
        Expression exp = ExpressionBuilder.typeExpression(remainder);
        // we want to cache this expression so we wont re-evaluate it as the type/constant wont change
        return ExpressionBuilder.cacheExpression(exp);
    }
    // random
    remainder = ifStartsWithReturnRemainder(""random"", function);
    if (remainder != null) {
        String values = ObjectHelper.between(remainder, ""("", "")"");
        if (values == null || ObjectHelper.isEmpty(values)) {
            throw new SimpleParserException(""Valid syntax: ${random(min,max)} or ${random(max)} was: "" + function, token.getIndex());
        }
        if (values.contains("","")) {
            String[] tokens = values.split("","", -1);
            if (tokens.length > 2) {
                throw new SimpleParserException(""Valid syntax: ${random(min,max)} or ${random(max)} was: "" + function, token.getIndex());
            }
            int min = Integer.parseInt(tokens[0].trim());
            int max = Integer.parseInt(tokens[1].trim());
            return ExpressionBuilder.randomExpression(min, max);
        } else {
            int max = Integer.parseInt(values.trim());
            return ExpressionBuilder.randomExpression(max);
        }
    }
    // collate function
    remainder = ifStartsWithReturnRemainder(""collate"", function);
    if (remainder != null) {
        String values = ObjectHelper.between(remainder, ""("", "")"");
        if (values == null || ObjectHelper.isEmpty(values)) {
            throw new SimpleParserException(""Valid syntax: ${collate(group)} was: "" + function, token.getIndex());
        }
        String exp = ""${body}"";
        int num = Integer.parseInt(values.trim());
        return ExpressionBuilder.collateExpression(exp, num);
    }
    if (strict) {
        throw new SimpleParserException(""Unknown function: "" + function, token.getIndex());
    } else {
        return null;
    }
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9641_9a6e6d8a,Major,camel-core/src/main/java/org/apache/camel/language/simple/ast/SimpleFunctionExpression.java,391,422,"private Expression createSimpleFileExpression(String remainder) {
    if (ObjectHelper.equal(remainder, ""name"")) {
        return ExpressionBuilder.fileNameExpression();
    } else if (ObjectHelper.equal(remainder, ""name.noext"")) {
        return ExpressionBuilder.fileNameNoExtensionExpression();
    } else if (ObjectHelper.equal(remainder, ""name.noext.single"")) {
        return ExpressionBuilder.fileNameNoExtensionSingleExpression();
    } else if (ObjectHelper.equal(remainder, ""name.ext"") || ObjectHelper.equal(remainder, ""ext"")) {
        return ExpressionBuilder.fileExtensionExpression();
    } else if (ObjectHelper.equal(remainder, ""name.ext.single"")) {
        return ExpressionBuilder.fileExtensionSingleExpression();
    } else if (ObjectHelper.equal(remainder, ""onlyname"")) {
        return ExpressionBuilder.fileOnlyNameExpression();
    } else if (ObjectHelper.equal(remainder, ""onlyname.noext"")) {
        return ExpressionBuilder.fileOnlyNameNoExtensionExpression();
    } else if (ObjectHelper.equal(remainder, ""onlyname.noext.single"")) {
        return ExpressionBuilder.fileOnlyNameNoExtensionSingleExpression();
    } else if (ObjectHelper.equal(remainder, ""parent"")) {
        return ExpressionBuilder.fileParentExpression();
    } else if (ObjectHelper.equal(remainder, ""path"")) {
        return ExpressionBuilder.filePathExpression();
    } else if (ObjectHelper.equal(remainder, ""absolute"")) {
        return ExpressionBuilder.fileAbsoluteExpression();
    } else if (ObjectHelper.equal(remainder, ""absolute.path"")) {
        return ExpressionBuilder.fileAbsolutePathExpression();
    } else if (ObjectHelper.equal(remainder, ""length"") || ObjectHelper.equal(remainder, ""size"")) {
        return ExpressionBuilder.fileSizeExpression();
    } else if (ObjectHelper.equal(remainder, ""modified"")) {
        return ExpressionBuilder.fileLastModifiedExpression();
    }
    throw new SimpleParserException(""Unknown file language syntax: "" + remainder, token.getIndex());
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9666_da035952,Minor,camel-core/src/main/java/org/apache/camel/impl/DefaultExchange.java,92,124,"public Exchange copy(boolean safeCopy) {
    DefaultExchange exchange = new DefaultExchange(this);
    if (hasProperties()) {
        exchange.setProperties(safeCopyProperties(getProperties()));
    }
    if (safeCopy) {
        exchange.getIn().setBody(getIn().getBody());
        if (getIn().hasHeaders()) {
            exchange.getIn().setHeaders(safeCopyHeaders(getIn().getHeaders()));
            // just copy the attachments here
            exchange.getIn().copyAttachments(getIn());
        }
        if (hasOut()) {
            exchange.getOut().setBody(getOut().getBody());
            if (getOut().hasHeaders()) {
                exchange.getOut().setHeaders(safeCopyHeaders(getOut().getHeaders()));
            }
            // Just copy the attachments here
            exchange.getOut().copyAttachments(getOut());
        }
    } else {
        // old way of doing copy which is @deprecated
        // TODO: remove this in Camel 3.0, and always do a safe copy
        exchange.setIn(getIn().copy());
        if (hasOut()) {
            exchange.setOut(getOut().copy());
        }
    }
    exchange.setException(getException());
    return exchange;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9672_84922699,Minor,camel-core/src/main/java/org/apache/camel/management/DefaultManagementObjectStrategy.java,269,439,"@SuppressWarnings({ ""deprecation"", ""unchecked"" })
public Object getManagedObjectForProcessor(CamelContext context, Processor processor, ProcessorDefinition<?> definition, Route route) {
    ManagedProcessor answer = null;
    if (definition instanceof RecipientListDefinition) {
        // special for RecipientListDefinition, as the processor is wrapped in a pipeline as last
        Pipeline pipeline = (Pipeline) processor;
        Iterator<Processor> it = pipeline.getProcessors().iterator();
        while (it.hasNext()) {
            processor = it.next();
        }
    } else if (definition instanceof ThreadsDefinition) {
        // special for ThreadsDefinition, as the processor is wrapped in a pipeline as first
        Pipeline pipeline = (Pipeline) processor;
        Iterator<Processor> it = pipeline.getProcessors().iterator();
        processor = it.next();
    }
    // unwrap delegates as we want the real target processor
    Processor target = processor;
    while (target != null) {
        // skip error handlers
        if (target instanceof ErrorHandler) {
            return false;
        }
        if (target instanceof ConvertBodyProcessor) {
            answer = new ManagedConvertBody(context, (ConvertBodyProcessor) target, definition);
        } else if (target instanceof ChoiceProcessor) {
            answer = new ManagedChoice(context, (ChoiceProcessor) target, definition);
        } else if (target instanceof Delayer) {
            answer = new ManagedDelayer(context, (Delayer) target, definition);
        } else if (target instanceof Throttler) {
            answer = new ManagedThrottler(context, (Throttler) target, definition);
        } else if (target instanceof DynamicRouter) {
            answer = new ManagedDynamicRouter(context, (DynamicRouter) target, (org.apache.camel.model.DynamicRouterDefinition) definition);
        } else if (target instanceof RoutingSlip) {
            answer = new ManagedRoutingSlip(context, (RoutingSlip) target, (org.apache.camel.model.RoutingSlipDefinition) definition);
        } else if (target instanceof FilterProcessor) {
            answer = new ManagedFilter(context, (FilterProcessor) target, (org.apache.camel.model.FilterDefinition) definition);
        } else if (target instanceof LogProcessor) {
            answer = new ManagedLog(context, (LogProcessor) target, definition);
        } else if (target instanceof LoopProcessor) {
            answer = new ManagedLoop(context, (LoopProcessor) target, (org.apache.camel.model.LoopDefinition) definition);
        } else if (target instanceof MarshalProcessor) {
            answer = new ManagedMarshal(context, (MarshalProcessor) target, (org.apache.camel.model.MarshalDefinition) definition);
        } else if (target instanceof UnmarshalProcessor) {
            answer = new ManagedUnmarshal(context, (UnmarshalProcessor) target, (org.apache.camel.model.UnmarshalDefinition) definition);
        } else if (target instanceof CircuitBreakerLoadBalancer) {
            answer = new ManagedCircuitBreakerLoadBalancer(context, (CircuitBreakerLoadBalancer) target, (org.apache.camel.model.LoadBalanceDefinition) definition);
        } else if (target instanceof FailOverLoadBalancer) {
            answer = new ManagedFailoverLoadBalancer(context, (FailOverLoadBalancer) target, (org.apache.camel.model.LoadBalanceDefinition) definition);
        } else if (target instanceof RandomLoadBalancer) {
            answer = new ManagedRandomLoadBalancer(context, (RandomLoadBalancer) target, (org.apache.camel.model.LoadBalanceDefinition) definition);
        } else if (target instanceof RoundRobinLoadBalancer) {
            answer = new ManagedRoundRobinLoadBalancer(context, (RoundRobinLoadBalancer) target, (org.apache.camel.model.LoadBalanceDefinition) definition);
        } else if (target instanceof StickyLoadBalancer) {
            answer = new ManagedStickyLoadBalancer(context, (StickyLoadBalancer) target, (org.apache.camel.model.LoadBalanceDefinition) definition);
        } else if (target instanceof TopicLoadBalancer) {
            answer = new ManagedTopicLoadBalancer(context, (TopicLoadBalancer) target, (org.apache.camel.model.LoadBalanceDefinition) definition);
        } else if (target instanceof WeightedLoadBalancer) {
            answer = new ManagedWeightedLoadBalancer(context, (WeightedLoadBalancer) target, (org.apache.camel.model.LoadBalanceDefinition) definition);
        } else if (target instanceof RecipientList) {
            answer = new ManagedRecipientList(context, (RecipientList) target, (RecipientListDefinition) definition);
        } else if (target instanceof Splitter) {
            answer = new ManagedSplitter(context, (Splitter) target, (org.apache.camel.model.SplitDefinition) definition);
        } else if (target instanceof MulticastProcessor) {
            answer = new ManagedMulticast(context, (MulticastProcessor) target, definition);
        } else if (target instanceof SamplingThrottler) {
            answer = new ManagedSamplingThrottler(context, (SamplingThrottler) target, definition);
        } else if (target instanceof Resequencer) {
            answer = new ManagedResequencer(context, (Resequencer) target, definition);
        } else if (target instanceof RollbackProcessor) {
            answer = new ManagedRollback(context, (RollbackProcessor) target, definition);
        } else if (target instanceof StreamResequencer) {
            answer = new ManagedResequencer(context, (StreamResequencer) target, definition);
        } else if (target instanceof SetBodyProcessor) {
            answer = new ManagedSetBody(context, (SetBodyProcessor) target, (org.apache.camel.model.SetBodyDefinition) definition);
        } else if (target instanceof RemoveHeaderProcessor) {
            answer = new ManagedRemoveHeader(context, (RemoveHeaderProcessor) target, definition);
        } else if (target instanceof RemoveHeadersProcessor) {
            answer = new ManagedRemoveHeaders(context, (RemoveHeadersProcessor) target, definition);
        } else if (target instanceof SetHeaderProcessor) {
            answer = new ManagedSetHeader(context, (SetHeaderProcessor) target, (org.apache.camel.model.SetHeaderDefinition) definition);
        } else if (target instanceof RemovePropertyProcessor) {
            answer = new ManagedRemoveProperty(context, (RemovePropertyProcessor) target, definition);
        } else if (target instanceof RemovePropertiesProcessor) {
            answer = new ManagedRemoveProperties(context, (RemovePropertiesProcessor) target, definition);
        } else if (target instanceof SetPropertyProcessor) {
            answer = new ManagedSetProperty(context, (SetPropertyProcessor) target, (org.apache.camel.model.SetPropertyDefinition) definition);
        } else if (target instanceof ExchangePatternProcessor) {
            answer = new ManagedSetExchangePattern(context, (ExchangePatternProcessor) target, definition);
        } else if (target instanceof ScriptProcessor) {
            answer = new ManagedScript(context, (ScriptProcessor) target, (org.apache.camel.model.ScriptDefinition) definition);
        } else if (target instanceof StopProcessor) {
            answer = new ManagedStop(context, (StopProcessor) target, definition);
        } else if (target instanceof ThreadsProcessor) {
            answer = new ManagedThreads(context, (ThreadsProcessor) target, definition);
        } else if (target instanceof ThrowExceptionProcessor) {
            answer = new ManagedThrowException(context, (ThrowExceptionProcessor) target, definition);
        } else if (target instanceof TransformProcessor) {
            answer = new ManagedTransformer(context, (TransformProcessor) target, (org.apache.camel.model.TransformDefinition) definition);
        } else if (target instanceof PredicateValidatingProcessor) {
            answer = new ManagedValidate(context, (PredicateValidatingProcessor) target, (org.apache.camel.model.ValidateDefinition) definition);
        } else if (target instanceof WireTapProcessor) {
            answer = new ManagedWireTapProcessor(context, (WireTapProcessor) target, definition);
        } else if (target instanceof SendDynamicProcessor) {
            answer = new ManagedSendDynamicProcessor(context, (SendDynamicProcessor) target, definition);
        } else if (target instanceof SendProcessor) {
            SendProcessor sp = (SendProcessor) target;
            // special for sending to throughput logger
            if (sp.getDestination() instanceof LogEndpoint) {
                LogEndpoint le = (LogEndpoint) sp.getDestination();
                if (le.getLogger() instanceof ThroughputLogger) {
                    ThroughputLogger tl = (ThroughputLogger) le.getLogger();
                    answer = new ManagedThroughputLogger(context, tl, definition);
                }
            }
            // regular send processor
            if (answer == null) {
                answer = new ManagedSendProcessor(context, (SendProcessor) target, definition);
            }
        } else if (target instanceof BeanProcessor) {
            answer = new ManagedBeanProcessor(context, (BeanProcessor) target, definition);
        } else if (target instanceof IdempotentConsumer) {
            answer = new ManagedIdempotentConsumer(context, (IdempotentConsumer) target, (org.apache.camel.model.IdempotentConsumerDefinition) definition);
        } else if (target instanceof AggregateProcessor) {
            answer = new ManagedAggregateProcessor(context, (AggregateProcessor) target, (org.apache.camel.model.AggregateDefinition) definition);
        } else if (target instanceof Enricher) {
            answer = new ManagedEnricher(context, (Enricher) target, (org.apache.camel.model.EnrichDefinition) definition);
        } else if (target instanceof PollEnricher) {
            answer = new ManagedPollEnricher(context, (PollEnricher) target, (org.apache.camel.model.PollEnrichDefinition) definition);
        } else if (target instanceof org.apache.camel.spi.ManagementAware) {
            return ((org.apache.camel.spi.ManagementAware<Processor>) target).getManagedObject(processor);
        }
        // special for custom load balancer
        if (definition instanceof LoadBalanceDefinition) {
            LoadBalanceDefinition lb = (LoadBalanceDefinition) definition;
            if (lb.getLoadBalancerType() instanceof CustomLoadBalancerDefinition) {
                answer = new ManagedCustomLoadBalancer(context, (LoadBalancer) target, (LoadBalanceDefinition) definition);
            }
        }
        if (answer != null) {
            // break out as we found an answer
            break;
        }
        // no answer yet, so unwrap any delegates and try again
        if (target instanceof DelegateProcessor) {
            target = ((DelegateProcessor) target).getProcessor();
        } else {
            // no delegate so we dont have any target to try next
            break;
        }
    }
    if (answer == null && definition instanceof ProcessDefinition) {
        answer = new ManagedProcess(context, target, (ProcessDefinition) definition);
    } else if (answer == null) {
        // fallback to a generic processor
        answer = new ManagedProcessor(context, target, definition);
    }
    answer.setRoute(route);
    answer.init(context.getManagementStrategy());
    return answer;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9672_84922699,Minor,camel-core/src/main/java/org/apache/camel/management/mbean/ManagedFilter.java,37,40,"@Override
public FilterDefinition getDefinition() {
    return (FilterDefinition) super.getDefinition();
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9673_7944093f,Minor,camel-core/src/main/java/org/apache/camel/processor/FinallyProcessor.java,42,75,"@Override
public boolean process(final Exchange exchange, final AsyncCallback callback) {
    // clear exception so finally block can be executed
    final Exception e = exchange.getException();
    exchange.setException(null);
    // but store the caught exception as a property
    if (e != null) {
        exchange.setProperty(Exchange.EXCEPTION_CAUGHT, e);
    }
    // store the last to endpoint as the failure endpoint
    if (exchange.getProperty(Exchange.FAILURE_ENDPOINT) == null) {
        exchange.setProperty(Exchange.FAILURE_ENDPOINT, exchange.getProperty(Exchange.TO_ENDPOINT));
    }
    boolean sync = processor.process(exchange, new AsyncCallback() {

        public void done(boolean doneSync) {
            if (e == null) {
                exchange.removeProperty(Exchange.FAILURE_ENDPOINT);
            } else {
                // set exception back on exchange
                exchange.setException(e);
                exchange.setProperty(Exchange.EXCEPTION_CAUGHT, e);
            }
            if (!doneSync) {
                // signal callback to continue routing async
                ExchangeHelper.prepareOutToIn(exchange);
                LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
            }
            callback.done(doneSync);
        }
    });
    return sync;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9673_7944093f,Minor,camel-core/src/main/java/org/apache/camel/processor/FinallyProcessor.java,57,72,"public void done(boolean doneSync) {
    if (e == null) {
        exchange.removeProperty(Exchange.FAILURE_ENDPOINT);
    } else {
        // set exception back on exchange
        exchange.setException(e);
        exchange.setProperty(Exchange.EXCEPTION_CAUGHT, e);
    }
    if (!doneSync) {
        // signal callback to continue routing async
        ExchangeHelper.prepareOutToIn(exchange);
        LOG.trace(""Processing complete for exchangeId: {} >>> {}"", exchange.getExchangeId(), exchange);
    }
    callback.done(doneSync);
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9700_4d03e9de,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaProducer.java,71,179,"@Override
public boolean process(final Exchange exchange, final AsyncCallback callback) {
    WaitForTaskToComplete wait = waitForTaskToComplete;
    if (exchange.getProperty(Exchange.ASYNC_WAIT) != null) {
        wait = exchange.getProperty(Exchange.ASYNC_WAIT, WaitForTaskToComplete.class);
    }
    if (wait == WaitForTaskToComplete.Always || (wait == WaitForTaskToComplete.IfReplyExpected && ExchangeHelper.isOutCapable(exchange))) {
        // do not handover the completion as we wait for the copy to complete, and copy its result back when it done
        Exchange copy = prepareCopy(exchange, false);
        // latch that waits until we are complete
        final CountDownLatch latch = new CountDownLatch(1);
        // we should wait for the reply so install a on completion so we know when its complete
        copy.addOnCompletion(new SynchronizationAdapter() {

            @Override
            public void onDone(Exchange response) {
                // check for timeout, which then already would have invoked the latch
                if (latch.getCount() == 0) {
                    if (log.isTraceEnabled()) {
                        log.trace(""{}. Timeout occurred so response will be ignored: {}"", this, response.hasOut() ? response.getOut() : response.getIn());
                    }
                    return;
                } else {
                    if (log.isTraceEnabled()) {
                        log.trace(""{} with response: {}"", this, response.hasOut() ? response.getOut() : response.getIn());
                    }
                    try {
                        ExchangeHelper.copyResults(exchange, response);
                    } finally {
                        // always ensure latch is triggered
                        latch.countDown();
                    }
                }
            }

            @Override
            public boolean allowHandover() {
                // at this point in the routing (at this leg), instead of at the very last (this ensure timeout is honored)
                return false;
            }

            @Override
            public String toString() {
                return ""onDone at endpoint: "" + endpoint;
            }
        });
        log.trace(""Adding Exchange to queue: {}"", copy);
        try {
            addToQueue(copy);
        } catch (SedaConsumerNotAvailableException e) {
            exchange.setException(e);
            callback.done(true);
            return true;
        }
        if (timeout > 0) {
            if (log.isTraceEnabled()) {
                log.trace(""Waiting for task to complete using timeout (ms): {} at [{}]"", timeout, endpoint.getEndpointUri());
            }
            // lets see if we can get the task done before the timeout
            boolean done = false;
            try {
                done = latch.await(timeout, TimeUnit.MILLISECONDS);
            } catch (InterruptedException e) {
            // ignore
            }
            if (!done) {
                exchange.setException(new ExchangeTimedOutException(exchange, timeout));
                // remove timed out Exchange from queue
                endpoint.getQueue().remove(copy);
                // count down to indicate timeout
                latch.countDown();
            }
        } else {
            if (log.isTraceEnabled()) {
                log.trace(""Waiting for task to complete (blocking) at [{}]"", endpoint.getEndpointUri());
            }
            // no timeout then wait until its done
            try {
                latch.await();
            } catch (InterruptedException e) {
            // ignore
            }
        }
    } else {
        // no wait, eg its a InOnly then just add to queue and return
        // handover the completion so its the copy which performs that, as we do not wait
        Exchange copy = prepareCopy(exchange, true);
        log.trace(""Adding Exchange to queue: {}"", copy);
        try {
            addToQueue(copy);
        } catch (SedaConsumerNotAvailableException e) {
            exchange.setException(e);
            callback.done(true);
            return true;
        }
    }
    // we use OnCompletion on the Exchange to callback and wait for the Exchange to be done
    // so we should just signal the callback we are done synchronously
    callback.done(true);
    return true;
}"
camel,remotes/origin/bugs-dot-jar_CAMEL-9700_4d03e9de,Major,camel-core/src/main/java/org/apache/camel/component/seda/SedaProducer.java,209,239,"/**
 * Strategy method for adding the exchange to the queue.
 * <p>
 * Will perform a blocking ""put"" if blockWhenFull is true, otherwise it will
 * simply add which will throw exception if the queue is full
 *
 * @param exchange the exchange to add to the queue
 */
protected void addToQueue(Exchange exchange) throws SedaConsumerNotAvailableException {
    BlockingQueue<Exchange> queue = null;
    QueueReference queueReference = endpoint.getQueueReference();
    if (queueReference != null) {
        queue = queueReference.getQueue();
    }
    if (queue == null) {
        throw new SedaConsumerNotAvailableException(""No queue available on endpoint: "" + endpoint, exchange);
    }
    boolean empty = !queueReference.hasConsumers();
    if (empty) {
        if (endpoint.isFailIfNoConsumers()) {
            throw new SedaConsumerNotAvailableException(""No consumers available on endpoint: "" + endpoint, exchange);
        } else if (endpoint.isDiscardIfNoConsumers()) {
            log.debug(""Discard message as no active consumers on endpoint: "" + endpoint);
            return;
        }
    }
    if (blockWhenFull) {
        try {
            queue.put(exchange);
        } catch (InterruptedException e) {
            // ignore
            log.debug(""Put interrupted, are we stopping? {}"", isStopping() || isStopped());
        }
    } else {
        queue.add(exchange);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1005_91d280b7,Major,src/main/java/org/apache/commons/math3/util/MathArrays.java,814,870,"/**
 * Compute a linear combination accurately.
 * This method computes the sum of the products
 * <code>a<sub>i</sub> b<sub>i</sub></code> to high accuracy.
 * It does so by using specific multiplication and addition algorithms to
 * preserve accuracy and reduce cancellation effects.
 * <br/>
 * It is based on the 2005 paper
 * <a href=""http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.1547"">
 * Accurate Sum and Dot Product</a> by Takeshi Ogita, Siegfried M. Rump,
 * and Shin'ichi Oishi published in SIAM J. Sci. Comput.
 *
 * @param a Factors.
 * @param b Factors.
 * @return <code>&Sigma;<sub>i</sub> a<sub>i</sub> b<sub>i</sub></code>.
 * @throws DimensionMismatchException if arrays dimensions don't match
 */
public static double linearCombination(final double[] a, final double[] b) throws DimensionMismatchException {
    final int len = a.length;
    if (len != b.length) {
        throw new DimensionMismatchException(len, b.length);
    }
    final double[] prodHigh = new double[len];
    double prodLowSum = 0;
    for (int i = 0; i < len; i++) {
        final double ai = a[i];
        final double ca = SPLIT_FACTOR * ai;
        final double aHigh = ca - (ca - ai);
        final double aLow = ai - aHigh;
        final double bi = b[i];
        final double cb = SPLIT_FACTOR * bi;
        final double bHigh = cb - (cb - bi);
        final double bLow = bi - bHigh;
        prodHigh[i] = ai * bi;
        final double prodLow = aLow * bLow - (((prodHigh[i] - aHigh * bHigh) - aLow * bHigh) - aHigh * bLow);
        prodLowSum += prodLow;
    }
    final double prodHighCur = prodHigh[0];
    double prodHighNext = prodHigh[1];
    double sHighPrev = prodHighCur + prodHighNext;
    double sPrime = sHighPrev - prodHighNext;
    double sLowSum = (prodHighNext - (sHighPrev - sPrime)) + (prodHighCur - sPrime);
    final int lenMinusOne = len - 1;
    for (int i = 1; i < lenMinusOne; i++) {
        prodHighNext = prodHigh[i + 1];
        final double sHighCur = sHighPrev + prodHighNext;
        sPrime = sHighCur - prodHighNext;
        sLowSum += (prodHighNext - (sHighCur - sPrime)) + (sHighPrev - sPrime);
        sHighPrev = sHighCur;
    }
    double result = sHighPrev + (prodLowSum + sLowSum);
    if (Double.isNaN(result)) {
        // either we have split infinite numbers or some coefficients were NaNs,
        // just rely on the naive implementation and let IEEE754 handle this
        result = 0;
        for (int i = 0; i < len; ++i) {
            result += a[i] * b[i];
        }
    }
    return result;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1045_a4ffd393,Minor,src/main/java/org/apache/commons/math3/linear/EigenDecomposition.java,515,523,"/**
 * Checks whether the decomposed matrix is non-singular.
 *
 * @return true if the decomposed matrix is non-singular.
 */
public boolean isNonSingular() {
    for (int i = 0; i < realEigenvalues.length; ++i) {
        if (realEigenvalues[i] == 0 && imagEigenvalues[i] == 0) {
            return false;
        }
    }
    return true;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1045_c979a6f0,Minor,src/main/java/org/apache/commons/math3/linear/EigenDecomposition.java,515,530,"/**
 * Checks whether the decomposed matrix is non-singular.
 *
 * @return true if the decomposed matrix is non-singular.
 */
public boolean isNonSingular() {
    // The eigenvalues are sorted by size, descending
    double largestEigenvalueNorm = eigenvalueNorm(0);
    // Corner case: zero matrix, all exactly 0 eigenvalues
    if (largestEigenvalueNorm == 0.0) {
        return false;
    }
    for (int i = 0; i < realEigenvalues.length; ++i) {
        // than the largest eigenvalue to be effectively 0.
        if (Precision.equals(eigenvalueNorm(i) / largestEigenvalueNorm, 0, EPSILON)) {
            return false;
        }
    }
    return true;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1051_bda25b40,Major,src/main/java/org/apache/commons/math3/linear/SchurTransformer.java,352,436,"/**
 * Perform a double QR step involving rows l:idx and columns m:n
 *
 * @param il the index of the small sub-diagonal element
 * @param im the start index for the QR step
 * @param iu the current eigenvalue index
 * @param shift shift information holder
 * @param hVec the initial houseHolder vector
 */
private void performDoubleQRStep(final int il, final int im, final int iu, final ShiftInfo shift, final double[] hVec) {
    final int n = matrixT.length;
    double p = hVec[0];
    double q = hVec[1];
    double r = hVec[2];
    for (int k = im; k <= iu - 1; k++) {
        boolean notlast = k != (iu - 1);
        if (k != im) {
            p = matrixT[k][k - 1];
            q = matrixT[k + 1][k - 1];
            r = notlast ? matrixT[k + 2][k - 1] : 0.0;
            shift.x = FastMath.abs(p) + FastMath.abs(q) + FastMath.abs(r);
            if (!Precision.equals(shift.x, 0.0, epsilon)) {
                p = p / shift.x;
                q = q / shift.x;
                r = r / shift.x;
            }
        }
        if (shift.x == 0.0) {
            break;
        }
        double s = FastMath.sqrt(p * p + q * q + r * r);
        if (p < 0.0) {
            s = -s;
        }
        if (s != 0.0) {
            if (k != im) {
                matrixT[k][k - 1] = -s * shift.x;
            } else if (il != im) {
                matrixT[k][k - 1] = -matrixT[k][k - 1];
            }
            p = p + s;
            shift.x = p / s;
            shift.y = q / s;
            double z = r / s;
            q = q / p;
            r = r / p;
            // Row modification
            for (int j = k; j < n; j++) {
                p = matrixT[k][j] + q * matrixT[k + 1][j];
                if (notlast) {
                    p = p + r * matrixT[k + 2][j];
                    matrixT[k + 2][j] = matrixT[k + 2][j] - p * z;
                }
                matrixT[k][j] = matrixT[k][j] - p * shift.x;
                matrixT[k + 1][j] = matrixT[k + 1][j] - p * shift.y;
            }
            // Column modification
            for (int i = 0; i <= FastMath.min(iu, k + 3); i++) {
                p = shift.x * matrixT[i][k] + shift.y * matrixT[i][k + 1];
                if (notlast) {
                    p = p + z * matrixT[i][k + 2];
                    matrixT[i][k + 2] = matrixT[i][k + 2] - p * r;
                }
                matrixT[i][k] = matrixT[i][k] - p;
                matrixT[i][k + 1] = matrixT[i][k + 1] - p * q;
            }
            // Accumulate transformations
            final int high = matrixT.length - 1;
            for (int i = 0; i <= high; i++) {
                p = shift.x * matrixP[i][k] + shift.y * matrixP[i][k + 1];
                if (notlast) {
                    p = p + z * matrixP[i][k + 2];
                    matrixP[i][k + 2] = matrixP[i][k + 2] - p * r;
                }
                matrixP[i][k] = matrixP[i][k] - p;
                matrixP[i][k + 1] = matrixP[i][k + 1] - p * q;
            }
        }
    // (s != 0)
    }
    // clean up pollution due to round-off errors
    for (int i = im + 2; i <= iu; i++) {
        matrixT[i][i - 2] = 0.0;
        if (i > im + 2) {
            matrixT[i][i - 3] = 0.0;
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1058_4ebd967c,Minor,src/main/java/org/apache/commons/math3/distribution/LogNormalDistribution.java,289,293,"/**
 * {@inheritDoc}
 *
 * For scale {@code m} and shape {@code s}, the variance is
 * {@code (exp(s^2) - 1) * exp(2 * m + s^2)}.
 */
public double getNumericalVariance() {
    final double s = shape;
    final double ss = s * s;
    return (FastMath.exp(ss) - 1) * FastMath.exp(2 * scale + ss);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1058_4ebd967c,Minor,src/main/java/org/apache/commons/math3/distribution/WeibullDistribution.java,214,227,"/**
 * {@inheritDoc}
 *
 * Returns {@code 0} when {@code p == 0} and
 * {@code Double.POSITIVE_INFINITY} when {@code p == 1}.
 */
@Override
public double inverseCumulativeProbability(double p) {
    double ret;
    if (p < 0.0 || p > 1.0) {
        throw new OutOfRangeException(p, 0.0, 1.0);
    } else if (p == 0) {
        ret = 0.0;
    } else if (p == 1) {
        ret = Double.POSITIVE_INFINITY;
    } else {
        ret = scale * FastMath.pow(-FastMath.log(1.0 - p), 1.0 / shape);
    }
    return ret;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1058_4ebd967c,Minor,src/main/java/org/apache/commons/math3/special/Beta.java,182,227,"/**
 * Returns the regularized beta function I(x, a, b).
 *
 * The implementation of this method is based on:
 * <ul>
 * <li>
 * <a href=""http://mathworld.wolfram.com/RegularizedBetaFunction.html"">
 * Regularized Beta Function</a>.</li>
 * <li>
 * <a href=""http://functions.wolfram.com/06.21.10.0001.01"">
 * Regularized Beta Function</a>.</li>
 * </ul>
 *
 * @param x the value.
 * @param a Parameter {@code a}.
 * @param b Parameter {@code b}.
 * @param epsilon When the absolute value of the nth item in the
 * series is less than epsilon the approximation ceases to calculate
 * further elements in the series.
 * @param maxIterations Maximum number of ""iterations"" to complete.
 * @return the regularized beta function I(x, a, b)
 * @throws org.apache.commons.math3.exception.MaxCountExceededException
 * if the algorithm fails to converge.
 */
public static double regularizedBeta(double x, final double a, final double b, double epsilon, int maxIterations) {
    double ret;
    if (Double.isNaN(x) || Double.isNaN(a) || Double.isNaN(b) || x < 0 || x > 1 || a <= 0.0 || b <= 0.0) {
        ret = Double.NaN;
    } else if (x > (a + 1.0) / (a + b + 2.0)) {
        ret = 1.0 - regularizedBeta(1.0 - x, b, a, epsilon, maxIterations);
    } else {
        ContinuedFraction fraction = new ContinuedFraction() {

            @Override
            protected double getB(int n, double x) {
                double ret;
                double m;
                if (n % 2 == 0) {
                    // even
                    m = n / 2.0;
                    ret = (m * (b - m) * x) / ((a + (2 * m) - 1) * (a + (2 * m)));
                } else {
                    m = (n - 1.0) / 2.0;
                    ret = -((a + m) * (a + b + m) * x) / ((a + (2 * m)) * (a + (2 * m) + 1.0));
                }
                return ret;
            }

            @Override
            protected double getA(int n, double x) {
                return 1.0;
            }
        };
        ret = FastMath.exp((a * FastMath.log(x)) + (b * FastMath.log(1.0 - x)) - FastMath.log(a) - logBeta(a, b)) * 1.0 / fraction.evaluate(x, epsilon, maxIterations);
    }
    return ret;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1067_aff82362,Major,src/main/java/org/apache/commons/math3/special/Beta.java,182,227,"/**
 * Returns the regularized beta function I(x, a, b).
 *
 * The implementation of this method is based on:
 * <ul>
 * <li>
 * <a href=""http://mathworld.wolfram.com/RegularizedBetaFunction.html"">
 * Regularized Beta Function</a>.</li>
 * <li>
 * <a href=""http://functions.wolfram.com/06.21.10.0001.01"">
 * Regularized Beta Function</a>.</li>
 * </ul>
 *
 * @param x the value.
 * @param a Parameter {@code a}.
 * @param b Parameter {@code b}.
 * @param epsilon When the absolute value of the nth item in the
 * series is less than epsilon the approximation ceases to calculate
 * further elements in the series.
 * @param maxIterations Maximum number of ""iterations"" to complete.
 * @return the regularized beta function I(x, a, b)
 * @throws org.apache.commons.math3.exception.MaxCountExceededException
 * if the algorithm fails to converge.
 */
public static double regularizedBeta(double x, final double a, final double b, double epsilon, int maxIterations) {
    double ret;
    if (Double.isNaN(x) || Double.isNaN(a) || Double.isNaN(b) || x < 0 || x > 1 || a <= 0.0 || b <= 0.0) {
        ret = Double.NaN;
    } else if (x > (a + 1.0) / (a + b + 2.0)) {
        ret = 1.0 - regularizedBeta(1.0 - x, b, a, epsilon, maxIterations);
    } else {
        ContinuedFraction fraction = new ContinuedFraction() {

            @Override
            protected double getB(int n, double x) {
                double ret;
                double m;
                if (n % 2 == 0) {
                    // even
                    m = n / 2.0;
                    ret = (m * (b - m) * x) / ((a + (2 * m) - 1) * (a + (2 * m)));
                } else {
                    m = (n - 1.0) / 2.0;
                    ret = -((a + m) * (a + b + m) * x) / ((a + (2 * m)) * (a + (2 * m) + 1.0));
                }
                return ret;
            }

            @Override
            protected double getA(int n, double x) {
                return 1.0;
            }
        };
        ret = FastMath.exp((a * FastMath.log(x)) + (b * FastMath.log1p(-x)) - FastMath.log(a) - logBeta(a, b)) * 1.0 / fraction.evaluate(x, epsilon, maxIterations);
    }
    return ret;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1068_b12610d3,Minor,src/main/java/org/apache/commons/math3/stat/correlation/KendallsCorrelation.java,155,259,"/**
 * Computes the Kendall's Tau rank correlation coefficient between the two arrays.
 *
 * @param xArray first data array
 * @param yArray second data array
 * @return Returns Kendall's Tau rank correlation coefficient for the two arrays
 * @throws DimensionMismatchException if the arrays lengths do not match
 */
public double correlation(final double[] xArray, final double[] yArray) throws DimensionMismatchException {
    if (xArray.length != yArray.length) {
        throw new DimensionMismatchException(xArray.length, yArray.length);
    }
    final int n = xArray.length;
    final int numPairs = n * (n - 1) / 2;
    @SuppressWarnings(""unchecked"")
    Pair<Double, Double>[] pairs = new Pair[n];
    for (int i = 0; i < n; i++) {
        pairs[i] = new Pair<Double, Double>(xArray[i], yArray[i]);
    }
    Arrays.sort(pairs, new Comparator<Pair<Double, Double>>() {

        public int compare(Pair<Double, Double> pair1, Pair<Double, Double> pair2) {
            int compareFirst = pair1.getFirst().compareTo(pair2.getFirst());
            return compareFirst != 0 ? compareFirst : pair1.getSecond().compareTo(pair2.getSecond());
        }
    });
    int tiedXPairs = 0;
    int tiedXYPairs = 0;
    int consecutiveXTies = 1;
    int consecutiveXYTies = 1;
    Pair<Double, Double> prev = pairs[0];
    for (int i = 1; i < n; i++) {
        final Pair<Double, Double> curr = pairs[i];
        if (curr.getFirst().equals(prev.getFirst())) {
            consecutiveXTies++;
            if (curr.getSecond().equals(prev.getSecond())) {
                consecutiveXYTies++;
            } else {
                tiedXYPairs += consecutiveXYTies * (consecutiveXYTies - 1) / 2;
                consecutiveXYTies = 1;
            }
        } else {
            tiedXPairs += consecutiveXTies * (consecutiveXTies - 1) / 2;
            consecutiveXTies = 1;
            tiedXYPairs += consecutiveXYTies * (consecutiveXYTies - 1) / 2;
            consecutiveXYTies = 1;
        }
        prev = curr;
    }
    tiedXPairs += consecutiveXTies * (consecutiveXTies - 1) / 2;
    tiedXYPairs += consecutiveXYTies * (consecutiveXYTies - 1) / 2;
    int swaps = 0;
    @SuppressWarnings(""unchecked"")
    Pair<Double, Double>[] pairsDestination = new Pair[n];
    for (int segmentSize = 1; segmentSize < n; segmentSize <<= 1) {
        for (int offset = 0; offset < n; offset += 2 * segmentSize) {
            int i = offset;
            final int iEnd = FastMath.min(i + segmentSize, n);
            int j = iEnd;
            final int jEnd = FastMath.min(j + segmentSize, n);
            int copyLocation = offset;
            while (i < iEnd || j < jEnd) {
                if (i < iEnd) {
                    if (j < jEnd) {
                        if (pairs[i].getSecond().compareTo(pairs[j].getSecond()) <= 0) {
                            pairsDestination[copyLocation] = pairs[i];
                            i++;
                        } else {
                            pairsDestination[copyLocation] = pairs[j];
                            j++;
                            swaps += iEnd - i;
                        }
                    } else {
                        pairsDestination[copyLocation] = pairs[i];
                        i++;
                    }
                } else {
                    pairsDestination[copyLocation] = pairs[j];
                    j++;
                }
                copyLocation++;
            }
        }
        final Pair<Double, Double>[] pairsTemp = pairs;
        pairs = pairsDestination;
        pairsDestination = pairsTemp;
    }
    int tiedYPairs = 0;
    int consecutiveYTies = 1;
    prev = pairs[0];
    for (int i = 1; i < n; i++) {
        final Pair<Double, Double> curr = pairs[i];
        if (curr.getSecond().equals(prev.getSecond())) {
            consecutiveYTies++;
        } else {
            tiedYPairs += consecutiveYTies * (consecutiveYTies - 1) / 2;
            consecutiveYTies = 1;
        }
        prev = curr;
    }
    tiedYPairs += consecutiveYTies * (consecutiveYTies - 1) / 2;
    int concordantMinusDiscordant = numPairs - tiedXPairs - tiedYPairs + tiedXYPairs - 2 * swaps;
    return concordantMinusDiscordant / FastMath.sqrt((numPairs - tiedXPairs) * (numPairs - tiedYPairs));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1070_8e5867ed,Critical,src/main/java/org/apache/commons/math3/util/Precision.java,454,534,"/**
 * Rounds the given non-negative value to the ""nearest"" integer. Nearest is
 * determined by the rounding method specified. Rounding methods are defined
 * in {@link BigDecimal}.
 *
 * @param unscaled Value to round.
 * @param sign Sign of the original, scaled value.
 * @param roundingMethod Rounding method, as defined in {@link BigDecimal}.
 * @return the rounded value.
 * @throws MathArithmeticException if an exact operation is required but result is not exact
 * @throws MathIllegalArgumentException if {@code roundingMethod} is not a valid rounding method.
 * @since 1.1 (previously in {@code MathUtils}, moved as of version 3.0)
 */
private static double roundUnscaled(double unscaled, double sign, int roundingMethod) throws MathArithmeticException, MathIllegalArgumentException {
    switch(roundingMethod) {
        case BigDecimal.ROUND_CEILING:
            if (sign == -1) {
                unscaled = FastMath.floor(FastMath.nextAfter(unscaled, Double.NEGATIVE_INFINITY));
            } else {
                unscaled = FastMath.ceil(FastMath.nextAfter(unscaled, Double.POSITIVE_INFINITY));
            }
            break;
        case BigDecimal.ROUND_DOWN:
            unscaled = FastMath.floor(FastMath.nextAfter(unscaled, Double.NEGATIVE_INFINITY));
            break;
        case BigDecimal.ROUND_FLOOR:
            if (sign == -1) {
                unscaled = FastMath.ceil(FastMath.nextAfter(unscaled, Double.POSITIVE_INFINITY));
            } else {
                unscaled = FastMath.floor(FastMath.nextAfter(unscaled, Double.NEGATIVE_INFINITY));
            }
            break;
        case BigDecimal.ROUND_HALF_DOWN:
            {
                unscaled = FastMath.nextAfter(unscaled, Double.NEGATIVE_INFINITY);
                double fraction = unscaled - FastMath.floor(unscaled);
                if (fraction > 0.5) {
                    unscaled = FastMath.ceil(unscaled);
                } else {
                    unscaled = FastMath.floor(unscaled);
                }
                break;
            }
        case BigDecimal.ROUND_HALF_EVEN:
            {
                double fraction = unscaled - FastMath.floor(unscaled);
                if (fraction > 0.5) {
                    unscaled = FastMath.ceil(unscaled);
                } else if (fraction < 0.5) {
                    unscaled = FastMath.floor(unscaled);
                } else {
                    // The following equality test is intentional and needed for rounding purposes
                    if (FastMath.floor(unscaled) / 2.0 == FastMath.floor(Math.floor(unscaled) / 2.0)) {
                        // even
                        unscaled = FastMath.floor(unscaled);
                    } else {
                        // odd
                        unscaled = FastMath.ceil(unscaled);
                    }
                }
                break;
            }
        case BigDecimal.ROUND_HALF_UP:
            {
                unscaled = FastMath.nextAfter(unscaled, Double.POSITIVE_INFINITY);
                double fraction = unscaled - FastMath.floor(unscaled);
                if (fraction >= 0.5) {
                    unscaled = FastMath.ceil(unscaled);
                } else {
                    unscaled = FastMath.floor(unscaled);
                }
                break;
            }
        case BigDecimal.ROUND_UNNECESSARY:
            if (unscaled != FastMath.floor(unscaled)) {
                throw new MathArithmeticException();
            }
            break;
        case BigDecimal.ROUND_UP:
            unscaled = FastMath.ceil(FastMath.nextAfter(unscaled, Double.POSITIVE_INFINITY));
            break;
        default:
            throw new MathIllegalArgumentException(LocalizedFormats.INVALID_ROUNDING_METHOD, roundingMethod, ""ROUND_CEILING"", BigDecimal.ROUND_CEILING, ""ROUND_DOWN"", BigDecimal.ROUND_DOWN, ""ROUND_FLOOR"", BigDecimal.ROUND_FLOOR, ""ROUND_HALF_DOWN"", BigDecimal.ROUND_HALF_DOWN, ""ROUND_HALF_EVEN"", BigDecimal.ROUND_HALF_EVEN, ""ROUND_HALF_UP"", BigDecimal.ROUND_HALF_UP, ""ROUND_UNNECESSARY"", BigDecimal.ROUND_UNNECESSARY, ""ROUND_UP"", BigDecimal.ROUND_UP);
    }
    return unscaled;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1088_63d88c74,Minor,src/main/java/org/apache/commons/math3/util/MultidimensionalCounter.java,92,99,"/**
 * {@inheritDoc}
 */
public boolean hasNext() {
    for (int i = 0; i < dimension; i++) {
        if (counter[i] != size[i] - 1) {
            return true;
        }
    }
    return false;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1088_63d88c74,Minor,src/main/java/org/apache/commons/math3/util/MultidimensionalCounter.java,105,116,"/**
 * @return the unidimensional count after the counter has been
 * incremented by {@code 1}.
 */
public Integer next() {
    for (int i = last; i >= 0; i--) {
        if (counter[i] == size[i] - 1) {
            counter[i] = 0;
        } else {
            ++counter[i];
            break;
        }
    }
    return ++count;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1089_e91d0f05,Major,src/main/java/org/apache/commons/math3/util/Precision.java,393,406,"/**
 * Rounds the given value to the specified number of decimal places.
 * The value is rounded using the given method which is any method defined
 * in {@link BigDecimal}.
 * If {@code x} is infinite or {@code NaN}, then the value of {@code x} is
 * returned unchanged, regardless of the other parameters.
 *
 * @param x Value to round.
 * @param scale Number of digits to the right of the decimal point.
 * @param roundingMethod Rounding method as defined in {@link BigDecimal}.
 * @return the rounded value.
 * @throws ArithmeticException if {@code roundingMethod == ROUND_UNNECESSARY}
 * and the specified scaling operation would require rounding.
 * @throws IllegalArgumentException if {@code roundingMethod} does not
 * represent a valid rounding mode.
 * @since 1.1 (previously in {@code MathUtils}, moved as of version 3.0)
 */
public static double round(double x, int scale, int roundingMethod) {
    try {
        return (new BigDecimal(Double.toString(x)).setScale(scale, roundingMethod)).doubleValue();
    } catch (NumberFormatException ex) {
        if (Double.isInfinite(x)) {
            return x;
        } else {
            return Double.NaN;
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1093_7cfbc0da,Major,src/main/java/org/apache/commons/math3/geometry/spherical/oned/ArcsSet.java,709,742,"/**
 * Compute the relative position of the instance with respect
 * to an arc.
 * <p>
 * The {@link Side#MINUS} side of the arc is the one covered by the arc.
 * </p>
 * @param arc arc to check instance against
 * @return one of {@link Side#PLUS}, {@link Side#MINUS}, {@link Side#BOTH}
 * or {@link Side#HYPER}
 */
public Side side(final Arc arc) {
    final double reference = FastMath.PI + arc.getInf();
    final double arcLength = arc.getSup() - arc.getInf();
    boolean inMinus = false;
    boolean inPlus = false;
    for (final double[] a : this) {
        final double syncedStart = MathUtils.normalizeAngle(a[0], reference) - arc.getInf();
        final double arcOffset = a[0] - syncedStart;
        final double syncedEnd = a[1] - arcOffset;
        if (syncedStart < arcLength || syncedEnd > MathUtils.TWO_PI) {
            inMinus = true;
        }
        if (syncedEnd > arcLength) {
            inPlus = true;
        }
    }
    if (inMinus) {
        if (inPlus) {
            return Side.BOTH;
        } else {
            return Side.MINUS;
        }
    } else {
        if (inPlus) {
            return Side.PLUS;
        } else {
            return Side.HYPER;
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1093_7cfbc0da,Major,src/main/java/org/apache/commons/math3/geometry/spherical/oned/ArcsSet.java,750,817,"/**
 * Split the instance in two parts by an arc.
 * @param arc splitting arc
 * @return an object containing both the part of the instance
 * on the plus side of the arc and the part of the
 * instance on the minus side of the arc
 */
public Split split(final Arc arc) {
    final BSPTree<Sphere1D> minus = new BSPTree<Sphere1D>();
    minus.setAttribute(Boolean.FALSE);
    final BSPTree<Sphere1D> plus = new BSPTree<Sphere1D>();
    plus.setAttribute(Boolean.FALSE);
    final double reference = FastMath.PI + arc.getInf();
    final double arcLength = arc.getSup() - arc.getInf();
    for (final double[] a : this) {
        final double syncedStart = MathUtils.normalizeAngle(a[0], reference) - arc.getInf();
        final double arcOffset = a[0] - syncedStart;
        final double syncedEnd = a[1] - arcOffset;
        if (syncedStart < arcLength) {
            // the start point a[0] is in the minus part of the arc
            addArcLimit(minus, a[0], true);
            if (syncedEnd > arcLength) {
                // the end point a[1] is past the end of the arc
                // so we leave the minus part and enter the plus part
                final double minusToPlus = arcLength + arcOffset;
                addArcLimit(minus, minusToPlus, false);
                addArcLimit(plus, minusToPlus, true);
                if (syncedEnd > MathUtils.TWO_PI) {
                    // in fact the end point a[1] goes far enough that we
                    // leave the plus part of the arc and enter the minus part again
                    final double plusToMinus = MathUtils.TWO_PI + arcOffset;
                    addArcLimit(plus, plusToMinus, false);
                    addArcLimit(minus, plusToMinus, true);
                    addArcLimit(minus, a[1], false);
                } else {
                    // the end point a[1] is in the plus part of the arc
                    addArcLimit(plus, a[1], false);
                }
            } else {
                // the end point a[1] is in the minus part of the arc
                addArcLimit(minus, a[1], false);
            }
        } else {
            // the start point a[0] is in the plus part of the arc
            addArcLimit(plus, a[0], true);
            if (syncedEnd > MathUtils.TWO_PI) {
                // the end point a[1] wraps around to the start of the arc
                // so we leave the plus part and enter the minus part
                final double plusToMinus = MathUtils.TWO_PI + arcOffset;
                addArcLimit(plus, plusToMinus, false);
                addArcLimit(minus, plusToMinus, true);
                if (syncedEnd > MathUtils.TWO_PI + arcLength) {
                    // in fact the end point a[1] goes far enough that we
                    // leave the minus part of the arc and enter the plus part again
                    final double minusToPlus = MathUtils.TWO_PI + arcLength + arcOffset;
                    addArcLimit(minus, minusToPlus, false);
                    addArcLimit(plus, minusToPlus, true);
                    addArcLimit(plus, a[1], false);
                } else {
                    // the end point a[1] is in the minus part of the arc
                    addArcLimit(minus, a[1], false);
                }
            } else {
                // the end point a[1] is in the plus part of the arc
                addArcLimit(plus, a[1], false);
            }
        }
    }
    return new Split(createSplitPart(plus), createSplitPart(minus));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1093_7cfbc0da,Major,src/main/java/org/apache/commons/math3/geometry/spherical/oned/ArcsSet.java,824,838,"/**
 * Add an arc limit to a BSP tree under construction.
 * @param tree BSP tree under construction
 * @param alpha arc limit
 * @param isStart if true, the limit is the start of an arc
 */
private void addArcLimit(final BSPTree<Sphere1D> tree, final double alpha, final boolean isStart) {
    final LimitAngle limit = new LimitAngle(new S1Point(alpha), !isStart, getTolerance());
    final BSPTree<Sphere1D> node = tree.getCell(limit.getLocation(), getTolerance());
    if (node.getCut() != null) {
        // we find again an already added limit,
        // this means we have done a full turn around the circle
        leafBefore(node).setAttribute(Boolean.valueOf(!isStart));
    } else {
        // it's a new node
        node.insertCut(limit);
        node.setAttribute(null);
        node.getPlus().setAttribute(Boolean.FALSE);
        node.getMinus().setAttribute(Boolean.TRUE);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1093_7cfbc0da,Major,src/main/java/org/apache/commons/math3/geometry/spherical/oned/ArcsSet.java,844,850,"/**
 * Create a split part.
 * @param tree BSP tree containing the limit angles of the split part
 * @return split part (may be null)
 */
private ArcsSet createSplitPart(final BSPTree<Sphere1D> tree) {
    if (tree.getCut() == null && !(Boolean) tree.getAttribute()) {
        return null;
    } else {
        return new ArcsSet(tree, getTolerance());
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_19c1c3bb,Blocker,src/main/java/org/apache/commons/math3/geometry/enclosing/WelzlEncloser.java,78,116,"/**
 * Compute enclosing ball using Gärtner's pivoting heuristic.
 * @param points points to be enclosed
 * @return enclosing ball
 */
private EnclosingBall<S, P> pivotingBall(final Iterable<P> points) {
    final P first = points.iterator().next();
    final List<P> extreme = new ArrayList<P>(first.getSpace().getDimension() + 1);
    final List<P> support = new ArrayList<P>(first.getSpace().getDimension() + 1);
    // start with only first point selected as a candidate support
    extreme.add(first);
    EnclosingBall<S, P> ball = moveToFrontBall(extreme, extreme.size(), support);
    while (true) {
        // select the point farthest to current ball
        final P farthest = selectFarthest(points, ball);
        if (ball.contains(farthest, tolerance)) {
            // we have found a ball containing all points
            return ball;
        }
        // recurse search, restricted to the small subset containing support and farthest point
        support.clear();
        support.add(farthest);
        EnclosingBall<S, P> savedBall = ball;
        ball = moveToFrontBall(extreme, extreme.size(), support);
        if (ball.getRadius() < savedBall.getRadius()) {
            // TODO: fix this, it should never happen but it does!
            throw new MathInternalError();
        }
        // it was an interesting point, move it to the front
        // according to Gärtner's heuristic
        extreme.add(0, farthest);
        // prune the least interesting points
        extreme.subList(ball.getSupportSize(), extreme.size()).clear();
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_19c1c3bb,Blocker,src/main/java/org/apache/commons/math3/geometry/euclidean/threed/SphereGenerator.java,36,114,"/**
 * {@inheritDoc}
 */
public EnclosingBall<Euclidean3D, Vector3D> ballOnSupport(final List<Vector3D> support) {
    if (support.size() < 1) {
        return new EnclosingBall<Euclidean3D, Vector3D>(Vector3D.ZERO, -1.0);
    } else {
        final Vector3D vA = support.get(0);
        if (support.size() < 2) {
            return new EnclosingBall<Euclidean3D, Vector3D>(vA, 0, vA);
        } else {
            final Vector3D vB = support.get(1);
            if (support.size() < 3) {
                return new EnclosingBall<Euclidean3D, Vector3D>(new Vector3D(0.5, vA, 0.5, vB), 0.5 * vA.distance(vB), vA, vB);
            } else {
                final Vector3D vC = support.get(2);
                if (support.size() < 4) {
                    // delegate to 2D disk generator
                    final Plane p = new Plane(vA, vB, vC, 1.0e-10 * (vA.getNorm1() + vB.getNorm1() + vC.getNorm1()));
                    final EnclosingBall<Euclidean2D, Vector2D> disk = new DiskGenerator().ballOnSupport(Arrays.asList(p.toSubSpace(vA), p.toSubSpace(vB), p.toSubSpace(vC)));
                    // convert back to 3D
                    return new EnclosingBall<Euclidean3D, Vector3D>(p.toSpace(disk.getCenter()), disk.getRadius(), vA, vB, vC);
                } else {
                    final Vector3D vD = support.get(3);
                    // a sphere is 3D can be defined as:
                    // (1)   (x - x_0)^2 + (y - y_0)^2 + (z - z_0)^2 = r^2
                    // which can be written:
                    // (2)   (x^2 + y^2 + z^2) - 2 x_0 x - 2 y_0 y - 2 z_0 z + (x_0^2 + y_0^2 + z_0^2 - r^2) = 0
                    // or simply:
                    // (3)   (x^2 + y^2 + z^2) + a x + b y + c z + d = 0
                    // with sphere center coordinates -a/2, -b/2, -c/2
                    // If the sphere exists, a b, c and d are a non zero solution to
                    // [ (x^2  + y^2  + z^2)    x    y   z    1 ]   [ 1 ]   [ 0 ]
                    // [ (xA^2 + yA^2 + zA^2)   xA   yA  zA   1 ]   [ a ]   [ 0 ]
                    // [ (xB^2 + yB^2 + zB^2)   xB   yB  zB   1 ] * [ b ] = [ 0 ]
                    // [ (xC^2 + yC^2 + zC^2)   xC   yC  zC   1 ]   [ c ]   [ 0 ]
                    // [ (xD^2 + yD^2 + zD^2)   xD   yD  zD   1 ]   [ d ]   [ 0 ]
                    // So the determinant of the matrix is zero. Computing this determinant
                    // by expanding it using the minors m_ij of first row leads to
                    // (4)   m_11 (x^2 + y^2 + z^2) - m_12 x + m_13 y - m_14 z + m_15 = 0
                    // So by identifying equations (2) and (4) we get the coordinates
                    // of center as:
                    // x_0 = +m_12 / (2 m_11)
                    // y_0 = -m_13 / (2 m_11)
                    // z_0 = +m_14 / (2 m_11)
                    // Note that the minors m_11, m_12, m_13 and m_14 all have the last column
                    // filled with 1.0, hence simplifying the computation
                    final double[] c1 = new double[] { vA.getNormSq(), vB.getNormSq(), vC.getNormSq(), vD.getNormSq() };
                    final double[] c2 = new double[] { vA.getX(), vB.getX(), vC.getX(), vD.getX() };
                    final double[] c3 = new double[] { vA.getY(), vB.getY(), vC.getY(), vD.getY() };
                    final double[] c4 = new double[] { vA.getZ(), vB.getZ(), vC.getZ(), vD.getZ() };
                    final double m11 = minor(c2, c3, c4);
                    final double m12 = minor(c1, c3, c4);
                    final double m13 = minor(c1, c2, c4);
                    final double m14 = minor(c1, c2, c3);
                    final Vector3D center = new Vector3D(0.5 * m12 / m11, -0.5 * m13 / m11, 0.5 * m14 / m11);
                    return new EnclosingBall<Euclidean3D, Vector3D>(center, center.distance(vA), vA, vB, vC, vD);
                }
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_19c1c3bb,Blocker,src/main/java/org/apache/commons/math3/geometry/euclidean/threed/SphereGenerator.java,127,152,"/**
 * Compute a dimension 4 minor, when 4<sup>th</sup> column is known to be filled with 1.0.
 * <p>
 * The computation is performed using {@link MathArrays#linearCombination(double[], double[])
 * high accuracy sum of products}, trying to avoid cancellations effect. This should reduce
 * risks in case of near co-planar points.
 * </p>
 * @param c1 first column
 * @param c2 second column
 * @param c3 third column
 * @return value of the minor computed to high accuracy
 */
private double minor(final double[] c1, final double[] c2, final double[] c3) {
    final double m01 = c2[0] * c3[1];
    final double m02 = c2[0] * c3[2];
    final double m03 = c2[0] * c3[3];
    final double m10 = c2[1] * c3[0];
    final double m12 = c2[1] * c3[2];
    final double m13 = c2[1] * c3[3];
    final double m20 = c2[2] * c3[0];
    final double m21 = c2[2] * c3[1];
    final double m23 = c2[2] * c3[3];
    final double m30 = c2[3] * c3[0];
    final double m31 = c2[3] * c3[1];
    final double m32 = c2[3] * c3[2];
    return MathArrays.linearCombination(new double[] { c1[2], c1[1], c1[3], -c1[1], -c1[3], -c1[2], c1[0], c1[3], c1[2], -c1[3], -c1[0], -c1[2], c1[1], c1[0], c1[3], -c1[0], -c1[3], -c1[1], c1[0], c1[2], c1[1], -c1[2], -c1[0], -c1[1] }, new double[] { m13, m32, m21, m23, m12, m31, m23, m02, m30, m20, m32, m03, m03, m31, m10, m13, m01, m30, m12, m01, m20, m10, m21, m02 });
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_19c1c3bb,Blocker,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/DiskGenerator.java,32,86,"/**
 * {@inheritDoc}
 */
public EnclosingBall<Euclidean2D, Vector2D> ballOnSupport(final List<Vector2D> support) {
    if (support.size() < 1) {
        return new EnclosingBall<Euclidean2D, Vector2D>(Vector2D.ZERO, -1.0);
    } else {
        final Vector2D vA = support.get(0);
        if (support.size() < 2) {
            return new EnclosingBall<Euclidean2D, Vector2D>(vA, 0, vA);
        } else {
            final Vector2D vB = support.get(1);
            if (support.size() < 3) {
                return new EnclosingBall<Euclidean2D, Vector2D>(new Vector2D(0.5, vA, 0.5, vB), 0.5 * vA.distance(vB), vA, vB);
            } else {
                final Vector2D vC = support.get(2);
                // a disk is 2D can be defined as:
                // (1)   (x - x_0)^2 + (y - y_0)^2 = r^2
                // which can be written:
                // (2)   (x^2 + y^2) - 2 x_0 x - 2 y_0 y + (x_0^2 + y_0^2 - r^2) = 0
                // or simply:
                // (3)   (x^2 + y^2) + a x + b y + c= 0
                // with disk center coordinates -a/2, -b/2
                // If the sphere exists, a, b and c are a non zero solution to
                // [ (x^2  + y^2 )   x    y   1 ]   [ 1 ]   [ 0 ]
                // [ (xA^2 + yA^2)   xA   yA  1 ]   [ a ]   [ 0 ]
                // [ (xB^2 + yB^2)   xB   yB  1 ] * [ b ] = [ 0 ]
                // [ (xC^2 + yC^2)   xC   yC  1 ]   [ c ]   [ 0 ]
                // So the determinant of the matrix is zero. Computing this determinant
                // by expanding it using the minors m_ij of first row leads to
                // (4)   m_11 (x^2 + y^2) - m_12 x + m_13 y - m_14 = 0
                // So by identifying equations (2) and (4) we get the coordinates
                // of center as:
                // x_0 = +m_12 / (2 m_11)
                // y_0 = -m_13 / (2 m_11)
                // Note that the minors m_11, m_12 and m_13 all have the last column
                // filled with 1.0, hence simplifying the computation
                final double[] c1 = new double[] { vA.getNormSq(), vB.getNormSq(), vC.getNormSq() };
                final double[] c2 = new double[] { vA.getX(), vB.getX(), vC.getX() };
                final double[] c3 = new double[] { vA.getY(), vB.getY(), vC.getY() };
                final double m11 = minor(c2, c3);
                final double m12 = minor(c1, c3);
                final double m13 = minor(c1, c2);
                final Vector2D center = new Vector2D(0.5 * m12 / m11, -0.5 * m13 / m11);
                return new EnclosingBall<Euclidean2D, Vector2D>(center, center.distance(vA), vA, vB, vC);
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_19c1c3bb,Blocker,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/DiskGenerator.java,98,105,"/**
 * Compute a dimension 3 minor, when 3<sup>d</sup> column is known to be filled with 1.0.
 * <p>
 * The computation is performed using {@link MathArrays#linearCombination(double[], double[])
 * high accuracy sum of products}, trying to avoid cancellations effect. This should reduce
 * risks in case of near co-planar points.
 * </p>
 * @param c1 first column
 * @param c2 second column
 * @return value of the minor computed to high accuracy
 */
private double minor(final double[] c1, final double[] c2) {
    return MathArrays.linearCombination(new double[] { c1[0], c1[2], c1[1], -c1[2], -c1[0], -c1[1] }, new double[] { c2[1], c2[0], c2[2], c2[1], c2[2], c2[0] });
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_faf99727,Blocker,src/main/java/org/apache/commons/math3/geometry/enclosing/Encloser.java,37,37,"/**
 * Find a ball enclosing a list of points.
 * @param points points to enclose
 * @return enclosing ball
 */
EnclosingBall<S, P> enclose(List<P> points);"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_faf99727,Blocker,src/main/java/org/apache/commons/math3/geometry/enclosing/WelzlEncloser.java,68,78,"/**
 * {@inheritDoc}
 */
public EnclosingBall<S, P> enclose(final List<P> points) {
    if (points == null || points.isEmpty()) {
        // return an empty ball
        return generator.ballOnSupport(new ArrayList<P>());
    }
    // Emo Welzl algorithm with Bernd Gärtner and Linus Källberg improvements
    return pivotingBall(points);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_faf99727,Blocker,src/main/java/org/apache/commons/math3/geometry/enclosing/WelzlEncloser.java,84,121,"/**
 * Compute enclosing ball using Gärtner's pivoting heuristic.
 * @param points points to be enclosed
 * @return enclosing ball
 */
private EnclosingBall<S, P> pivotingBall(final List<P> points) {
    List<P> extreme = new ArrayList<P>(max);
    List<P> support = new ArrayList<P>(max);
    // start with only first point selected as a candidate support
    extreme.add(points.get(0));
    EnclosingBall<S, P> ball = moveToFrontBall(extreme, support);
    while (true) {
        // select the point farthest to current ball
        final P farthest = selectFarthest(points, ball);
        if (ball.contains(farthest, tolerance)) {
            // we have found a ball containing all points
            return ball;
        }
        // recurse search, restricted to the small subset containing support and farthest point
        support.clear();
        support.add(farthest);
        EnclosingBall<S, P> savedBall = ball;
        ball = moveToFrontBall(extreme, support);
        if (ball.getRadius() < savedBall.getRadius()) {
            // TODO: fix this, it should never happen but it does!
            throw new MathInternalError();
        }
        // it was an interesting point, move it to the front
        // according to Gärtner's heuristic
        extreme.add(0, farthest);
        // prune the least interesting points
        extreme.subList(ball.getSupportSize(), extreme.size()).clear();
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_faf99727,Blocker,src/main/java/org/apache/commons/math3/geometry/enclosing/WelzlEncloser.java,128,158,"/**
 * Compute enclosing ball using Welzl's move to front heuristic.
 * @param extreme subset of extreme points
 * @param support points that must belong to the ball support
 * @return enclosing ball, for the extreme subset only
 */
private EnclosingBall<S, P> moveToFrontBall(final List<P> extreme, final List<P> support) {
    // create a new ball on the prescribed support
    EnclosingBall<S, P> ball = generator.ballOnSupport(support);
    if (ball.getSupportSize() < max) {
        for (int i = 0; i < extreme.size(); ++i) {
            final P pi = extreme.get(i);
            if (!ball.contains(pi, tolerance)) {
                // we have found an outside point,
                // enlarge the ball by adding it to the support
                support.add(pi);
                ball = moveToFrontBall(extreme.subList(i + 1, extreme.size()), support);
                // according to Welzl's heuristic
                for (int j = i; j > 1; --j) {
                    extreme.set(j, extreme.get(j - 1));
                }
                extreme.set(0, pi);
            }
        }
    }
    return ball;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1096_faf99727,Blocker,src/main/java/org/apache/commons/math3/geometry/enclosing/WelzlEncloser.java,165,181,"/**
 * Select the point farthest to the current ball.
 * @param points points to be enclosed
 * @param ball current ball
 * @return farthest point
 */
public P selectFarthest(final List<P> points, final EnclosingBall<S, P> ball) {
    final P center = ball.getCenter();
    P farthest = null;
    double dMax = -1.0;
    for (final P point : points) {
        final double d = point.distance(center);
        if (d > dMax) {
            farthest = point;
            dMax = d;
        }
    }
    return farthest;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1103_a6f96306,Major,src/main/java/org/apache/commons/math3/fitting/leastsquares/GaussNewtonOptimizer.java,188,234,"/**
 * {@inheritDoc}
 */
public Optimum optimize(final LeastSquaresProblem lsp) {
    // create local evaluation and iteration counts
    final Incrementor evaluationCounter = lsp.getEvaluationCounter();
    final Incrementor iterationCounter = lsp.getIterationCounter();
    final ConvergenceChecker<Evaluation> checker = lsp.getConvergenceChecker();
    // Computation will be useless without a checker (see ""for-loop"").
    if (checker == null) {
        throw new NullArgumentException();
    }
    final int nC = lsp.getParameterSize();
    final RealVector currentPoint = lsp.getStart();
    // iterate until convergence is reached
    Evaluation current = null;
    while (true) {
        iterationCounter.incrementCount();
        // evaluate the objective function and its jacobian
        Evaluation previous = current;
        // Value of the objective function at ""currentPoint"".
        evaluationCounter.incrementCount();
        current = lsp.evaluate(currentPoint);
        final RealVector currentResiduals = current.getResiduals();
        final RealMatrix weightedJacobian = current.getJacobian();
        // Check convergence.
        if (previous != null) {
            if (checker.converged(iterationCounter.getCount(), previous, current)) {
                return new OptimumImpl(current, evaluationCounter.getCount(), iterationCounter.getCount());
            }
        }
        // solve the linearized least squares problem
        final RealVector dX = this.decomposition.solve(weightedJacobian, currentResiduals);
        // update the estimated parameters
        for (int i = 0; i < nC; ++i) {
            currentPoint.setEntry(i, currentPoint.getEntry(i) + dX.getEntry(i));
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1103_a6f96306,Major,src/main/java/org/apache/commons/math3/fitting/leastsquares/LeastSquaresFactory.java,328,336,"/**
 * {@inheritDoc}
 */
public Evaluation evaluate(final RealVector point) {
    // evaluate value and jacobian in one function call
    final Pair<RealVector, RealMatrix> value = this.model.value(point);
    return new UnweightedEvaluation(value.getFirst(), value.getSecond(), this.target, point);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1103_a6f96306,Major,src/main/java/org/apache/commons/math3/fitting/leastsquares/LevenbergMarquardtOptimizer.java,297,548,"/**
 * {@inheritDoc}
 */
public Optimum optimize(final LeastSquaresProblem problem) {
    // pull in relevant data from the problem as locals
    // Number of observed data.
    final int nR = problem.getObservationSize();
    // Number of parameters.
    final int nC = problem.getParameterSize();
    final double[] currentPoint = problem.getStart().toArray();
    // counters
    final Incrementor iterationCounter = problem.getIterationCounter();
    final Incrementor evaluationCounter = problem.getEvaluationCounter();
    // convergence criterion
    final ConvergenceChecker<Evaluation> checker = problem.getConvergenceChecker();
    // arrays shared with the other private methods
    final int solvedCols = FastMath.min(nR, nC);
    /* Parameters evolution direction associated with lmPar. */
    double[] lmDir = new double[nC];
    /* Levenberg-Marquardt parameter. */
    double lmPar = 0;
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[nC];
    double[] oldX = new double[nC];
    double[] oldRes = new double[nR];
    double[] qtf = new double[nR];
    double[] work1 = new double[nC];
    double[] work2 = new double[nC];
    double[] work3 = new double[nC];
    // Evaluate the function at the starting point and calculate its norm.
    evaluationCounter.incrementCount();
    // value will be reassigned in the loop
    Evaluation current = problem.evaluate(new ArrayRealVector(currentPoint, false));
    double[] currentResiduals = current.getResiduals().toArray();
    double currentCost = current.getCost();
    // Outer loop.
    boolean firstIteration = true;
    while (true) {
        iterationCounter.incrementCount();
        final Evaluation previous = current;
        // QR decomposition of the jacobian matrix
        final InternalData internalData = qrDecomposition(current.getJacobian(), solvedCols);
        final double[][] weightedJacobian = internalData.weightedJacobian;
        final int[] permutation = internalData.permutation;
        final double[] diagR = internalData.diagR;
        final double[] jacNorm = internalData.jacNorm;
        // residuals already have weights applied
        double[] weightedResidual = currentResiduals;
        for (int i = 0; i < nR; i++) {
            qtf[i] = weightedResidual[i];
        }
        // compute Qt.res
        qTy(qtf, internalData);
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            weightedJacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < nC; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * currentPoint[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = FastMath.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (currentCost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += weightedJacobian[i][pj] * qtf[i];
                    }
                    maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // Convergence has been reached.
            return new OptimumImpl(current, evaluationCounter.getCount(), iterationCounter.getCount());
        }
        // rescale if necessary
        for (int j = 0; j < nC; ++j) {
            diag[j] = FastMath.max(diag[j], jacNorm[j]);
        }
        // Inner loop.
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = currentPoint[pj];
            }
            final double previousCost = currentCost;
            double[] tmpVec = weightedResidual;
            weightedResidual = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            lmPar = determineLMParameter(qtf, delta, diag, internalData, solvedCols, work1, work2, work3, lmDir, lmPar);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                currentPoint[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = FastMath.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = FastMath.min(delta, lmNorm);
            }
            // Evaluate the function at x + p and calculate its norm.
            evaluationCounter.incrementCount();
            current = problem.evaluate(new ArrayRealVector(currentPoint, false));
            currentResiduals = current.getResiduals().toArray();
            currentCost = current.getCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * currentCost < previousCost) {
                double r = currentCost / previousCost;
                actRed = 1.0 - r * r;
            }
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += weightedJacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 /= pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * FastMath.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < nC; ++k) {
                    double xK = diag[k] * currentPoint[k];
                    xNorm += xK * xK;
                }
                xNorm = FastMath.sqrt(xNorm);
                // tests for convergence.
                if (checker != null && checker.converged(iterationCounter.getCount(), previous, current)) {
                    return new OptimumImpl(current, iterationCounter.getCount(), evaluationCounter.getCount());
                }
            } else {
                // failed iteration, reset the previous values
                currentCost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    currentPoint[pj] = oldX[pj];
                }
                tmpVec = weightedResidual;
                weightedResidual = oldRes;
                oldRes = tmpVec;
                // Reset ""current"" to previous values.
                current = previous;
            }
            // Default convergence criteria.
            if ((FastMath.abs(actRed) <= costRelativeTolerance && preRed <= costRelativeTolerance && ratio <= 2.0) || delta <= parRelativeTolerance * xNorm) {
                return new OptimumImpl(current, iterationCounter.getCount(), evaluationCounter.getCount());
            }
            // tests for termination and stringent tolerances
            if (FastMath.abs(actRed) <= TWO_EPS && preRed <= TWO_EPS && ratio <= 2.0) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= TWO_EPS * xNorm) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= TWO_EPS) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1106_e2dc384d,Major,src/main/java/org/apache/commons/math3/fitting/leastsquares/LevenbergMarquardtOptimizer.java,297,548,"/**
 * {@inheritDoc}
 */
public Optimum optimize(final LeastSquaresProblem problem) {
    // pull in relevant data from the problem as locals
    // Number of observed data.
    final int nR = problem.getObservationSize();
    // Number of parameters.
    final int nC = problem.getParameterSize();
    final double[] currentPoint = problem.getStart().toArray();
    // counters
    final Incrementor iterationCounter = problem.getIterationCounter();
    final Incrementor evaluationCounter = problem.getEvaluationCounter();
    // convergence criterion
    final ConvergenceChecker<Evaluation> checker = problem.getConvergenceChecker();
    // arrays shared with the other private methods
    final int solvedCols = FastMath.min(nR, nC);
    /* Parameters evolution direction associated with lmPar. */
    double[] lmDir = new double[nC];
    /* Levenberg-Marquardt parameter. */
    double lmPar = 0;
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[nC];
    double[] oldX = new double[nC];
    double[] oldRes = new double[nR];
    double[] qtf = new double[nR];
    double[] work1 = new double[nC];
    double[] work2 = new double[nC];
    double[] work3 = new double[nC];
    // Evaluate the function at the starting point and calculate its norm.
    evaluationCounter.incrementCount();
    // value will be reassigned in the loop
    Evaluation current = problem.evaluate(new ArrayRealVector(currentPoint));
    double[] currentResiduals = current.getResiduals().toArray();
    double currentCost = current.getCost();
    // Outer loop.
    boolean firstIteration = true;
    while (true) {
        iterationCounter.incrementCount();
        final Evaluation previous = current;
        // QR decomposition of the jacobian matrix
        final InternalData internalData = qrDecomposition(current.getJacobian(), solvedCols);
        final double[][] weightedJacobian = internalData.weightedJacobian;
        final int[] permutation = internalData.permutation;
        final double[] diagR = internalData.diagR;
        final double[] jacNorm = internalData.jacNorm;
        // residuals already have weights applied
        double[] weightedResidual = currentResiduals;
        for (int i = 0; i < nR; i++) {
            qtf[i] = weightedResidual[i];
        }
        // compute Qt.res
        qTy(qtf, internalData);
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            weightedJacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < nC; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * currentPoint[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = FastMath.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (currentCost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += weightedJacobian[i][pj] * qtf[i];
                    }
                    maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // Convergence has been reached.
            return new OptimumImpl(current, evaluationCounter.getCount(), iterationCounter.getCount());
        }
        // rescale if necessary
        for (int j = 0; j < nC; ++j) {
            diag[j] = FastMath.max(diag[j], jacNorm[j]);
        }
        // Inner loop.
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = currentPoint[pj];
            }
            final double previousCost = currentCost;
            double[] tmpVec = weightedResidual;
            weightedResidual = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            lmPar = determineLMParameter(qtf, delta, diag, internalData, solvedCols, work1, work2, work3, lmDir, lmPar);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                currentPoint[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = FastMath.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = FastMath.min(delta, lmNorm);
            }
            // Evaluate the function at x + p and calculate its norm.
            evaluationCounter.incrementCount();
            current = problem.evaluate(new ArrayRealVector(currentPoint));
            currentResiduals = current.getResiduals().toArray();
            currentCost = current.getCost();
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * currentCost < previousCost) {
                double r = currentCost / previousCost;
                actRed = 1.0 - r * r;
            }
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += weightedJacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 /= pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * FastMath.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < nC; ++k) {
                    double xK = diag[k] * currentPoint[k];
                    xNorm += xK * xK;
                }
                xNorm = FastMath.sqrt(xNorm);
                // tests for convergence.
                if (checker != null && checker.converged(iterationCounter.getCount(), previous, current)) {
                    return new OptimumImpl(current, iterationCounter.getCount(), evaluationCounter.getCount());
                }
            } else {
                // failed iteration, reset the previous values
                currentCost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    currentPoint[pj] = oldX[pj];
                }
                tmpVec = weightedResidual;
                weightedResidual = oldRes;
                oldRes = tmpVec;
                // Reset ""current"" to previous values.
                current = previous;
            }
            // Default convergence criteria.
            if ((FastMath.abs(actRed) <= costRelativeTolerance && preRed <= costRelativeTolerance && ratio <= 2.0) || delta <= parRelativeTolerance * xNorm) {
                return new OptimumImpl(current, iterationCounter.getCount(), evaluationCounter.getCount());
            }
            // tests for termination and stringent tolerances
            if (FastMath.abs(actRed) <= TWO_EPS && preRed <= TWO_EPS && ratio <= 2.0) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= TWO_EPS * xNorm) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= TWO_EPS) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1115_2a6c6409,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/threed/PolyhedronsSet.java,189,203,"/**
 * Build a parallellepipedic box boundary.
 * @param xMin low bound along the x direction
 * @param xMax high bound along the x direction
 * @param yMin low bound along the y direction
 * @param yMax high bound along the y direction
 * @param zMin low bound along the z direction
 * @param zMax high bound along the z direction
 * @param tolerance tolerance below which points are considered identical
 * @return boundary tree
 * @since 3.3
 */
private static BSPTree<Euclidean3D> buildBoundary(final double xMin, final double xMax, final double yMin, final double yMax, final double zMin, final double zMax, final double tolerance) {
    final Plane pxMin = new Plane(new Vector3D(xMin, 0, 0), Vector3D.MINUS_I, tolerance);
    final Plane pxMax = new Plane(new Vector3D(xMax, 0, 0), Vector3D.PLUS_I, tolerance);
    final Plane pyMin = new Plane(new Vector3D(0, yMin, 0), Vector3D.MINUS_J, tolerance);
    final Plane pyMax = new Plane(new Vector3D(0, yMax, 0), Vector3D.PLUS_J, tolerance);
    final Plane pzMin = new Plane(new Vector3D(0, 0, zMin), Vector3D.MINUS_K, tolerance);
    final Plane pzMax = new Plane(new Vector3D(0, 0, zMax), Vector3D.PLUS_K, tolerance);
    @SuppressWarnings(""unchecked"")
    final Region<Euclidean3D> boundary = new RegionFactory<Euclidean3D>().buildConvex(pxMin, pxMax, pyMin, pyMax, pzMin, pzMax);
    return boundary.getTree(false);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1117_f4c926ea,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,219,232,"/**
 * Create a list of hyperplanes representing the boundary of a box.
 * @param xMin low bound along the x direction
 * @param xMax high bound along the x direction
 * @param yMin low bound along the y direction
 * @param yMax high bound along the y direction
 * @param tolerance tolerance below which points are considered identical
 * @return boundary of the box
 */
private static Line[] boxBoundary(final double xMin, final double xMax, final double yMin, final double yMax, final double tolerance) {
    final Vector2D minMin = new Vector2D(xMin, yMin);
    final Vector2D minMax = new Vector2D(xMin, yMax);
    final Vector2D maxMin = new Vector2D(xMax, yMin);
    final Vector2D maxMax = new Vector2D(xMax, yMax);
    return new Line[] { new Line(minMin, maxMin, tolerance), new Line(maxMin, maxMax, tolerance), new Line(maxMax, minMax, tolerance), new Line(minMax, minMin, tolerance) };
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1121_5a6ccd58,Major,src/main/java/org/apache/commons/math3/optim/univariate/BrentOptimizer.java,114,286,"/**
 * {@inheritDoc}
 */
@Override
protected UnivariatePointValuePair doOptimize() {
    final boolean isMinim = getGoalType() == GoalType.MINIMIZE;
    final double lo = getMin();
    final double mid = getStartValue();
    final double hi = getMax();
    // Optional additional convergence criteria.
    final ConvergenceChecker<UnivariatePointValuePair> checker = getConvergenceChecker();
    double a;
    double b;
    if (lo < hi) {
        a = lo;
        b = hi;
    } else {
        a = hi;
        b = lo;
    }
    double x = mid;
    double v = x;
    double w = x;
    double d = 0;
    double e = 0;
    double fx = computeObjectiveValue(x);
    if (!isMinim) {
        fx = -fx;
    }
    double fv = fx;
    double fw = fx;
    UnivariatePointValuePair previous = null;
    UnivariatePointValuePair current = new UnivariatePointValuePair(x, isMinim ? fx : -fx);
    // Best point encountered so far (which is the initial guess).
    UnivariatePointValuePair best = current;
    int iter = 0;
    while (true) {
        final double m = 0.5 * (a + b);
        final double tol1 = relativeThreshold * FastMath.abs(x) + absoluteThreshold;
        final double tol2 = 2 * tol1;
        // Default stopping criterion.
        final boolean stop = FastMath.abs(x - m) <= tol2 - 0.5 * (b - a);
        if (!stop) {
            double p = 0;
            double q = 0;
            double r = 0;
            double u = 0;
            if (FastMath.abs(e) > tol1) {
                // Fit parabola.
                r = (x - w) * (fx - fv);
                q = (x - v) * (fx - fw);
                p = (x - v) * q - (x - w) * r;
                q = 2 * (q - r);
                if (q > 0) {
                    p = -p;
                } else {
                    q = -q;
                }
                r = e;
                e = d;
                if (p > q * (a - x) && p < q * (b - x) && FastMath.abs(p) < FastMath.abs(0.5 * q * r)) {
                    // Parabolic interpolation step.
                    d = p / q;
                    u = x + d;
                    // f must not be evaluated too close to a or b.
                    if (u - a < tol2 || b - u < tol2) {
                        if (x <= m) {
                            d = tol1;
                        } else {
                            d = -tol1;
                        }
                    }
                } else {
                    // Golden section step.
                    if (x < m) {
                        e = b - x;
                    } else {
                        e = a - x;
                    }
                    d = GOLDEN_SECTION * e;
                }
            } else {
                // Golden section step.
                if (x < m) {
                    e = b - x;
                } else {
                    e = a - x;
                }
                d = GOLDEN_SECTION * e;
            }
            // Update by at least ""tol1"".
            if (FastMath.abs(d) < tol1) {
                if (d >= 0) {
                    u = x + tol1;
                } else {
                    u = x - tol1;
                }
            } else {
                u = x + d;
            }
            double fu = computeObjectiveValue(u);
            if (!isMinim) {
                fu = -fu;
            }
            // User-defined convergence checker.
            previous = current;
            current = new UnivariatePointValuePair(u, isMinim ? fu : -fu);
            best = best(best, best(previous, current, isMinim), isMinim);
            if (checker != null && checker.converged(iter, previous, current)) {
                return best;
            }
            // Update a, b, v, w and x.
            if (fu <= fx) {
                if (u < x) {
                    b = x;
                } else {
                    a = x;
                }
                v = w;
                fv = fw;
                w = x;
                fw = fx;
                x = u;
                fx = fu;
            } else {
                if (u < x) {
                    a = u;
                } else {
                    b = u;
                }
                if (fu <= fw || Precision.equals(w, x)) {
                    v = w;
                    fv = fw;
                    w = u;
                    fw = fu;
                } else if (fu <= fv || Precision.equals(v, x) || Precision.equals(v, w)) {
                    v = u;
                    fv = fu;
                }
            }
        } else {
            // Default termination (Brent's criterion).
            return best(best, best(previous, current, isMinim), isMinim);
        }
        ++iter;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1123_a197ba85,Major,src/main/java/org/apache/commons/math3/geometry/partitioning/BSPTree.java,295,305,"/**
 * Fit a sub-hyperplane inside the cell defined by the instance.
 * <p>Fitting is done by chopping off the parts of the
 * sub-hyperplane that lie outside of the cell using the
 * cut-hyperplanes of the parent nodes of the instance.</p>
 * @param sub sub-hyperplane to fit
 * @return a new sub-hyperplane, guaranteed to have no part outside
 * of the instance cell
 */
private SubHyperplane<S> fitToCell(final SubHyperplane<S> sub) {
    SubHyperplane<S> s = sub;
    for (BSPTree<S> tree = this; tree.parent != null; tree = tree.parent) {
        if (tree == tree.parent.plus) {
            s = s.split(tree.parent.cut.getHyperplane()).getPlus();
        } else {
            s = s.split(tree.parent.cut.getHyperplane()).getMinus();
        }
    }
    return s;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1127_ba62c59d,Major,src/main/java/org/apache/commons/math3/util/Precision.java,123,130,"/**
 * Compares two numbers given some amount of allowed error.
 * Two float numbers are considered equal if there are {@code (maxUlps - 1)}
 * (or fewer) floating point numbers between them, i.e. two adjacent floating
 * point numbers are considered equal.
 * Adapted from <a
 * href=""http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm"">
 * Bruce Dawson</a>
 *
 * @param x first value
 * @param y second value
 * @param maxUlps {@code (maxUlps - 1)} is the number of floating point
 * values between {@code x} and {@code y}.
 * @return <ul><li>0 if  {@link #equals(double, double, int) equals(x, y, maxUlps)}</li>
 *       <li>&lt; 0 if !{@link #equals(double, double, int) equals(x, y, maxUlps)} &amp;&amp; x &lt; y</li>
 *       <li>> 0 if !{@link #equals(double, double, int) equals(x, y, maxUlps)} &amp;&amp; x > y</li></ul>
 */
public static int compareTo(final double x, final double y, final int maxUlps) {
    if (equals(x, y, maxUlps)) {
        return 0;
    } else if (x < y) {
        return -1;
    }
    return 1;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1127_ba62c59d,Major,src/main/java/org/apache/commons/math3/util/Precision.java,204,219,"/**
 * Returns true if both arguments are equal or within the range of allowed
 * error (inclusive).
 * Two float numbers are considered equal if there are {@code (maxUlps - 1)}
 * (or fewer) floating point numbers between them, i.e. two adjacent floating
 * point numbers are considered equal.
 * Adapted from <a
 * href=""http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm"">
 * Bruce Dawson</a>
 *
 * @param x first value
 * @param y second value
 * @param maxUlps {@code (maxUlps - 1)} is the number of floating point
 * values between {@code x} and {@code y}.
 * @return {@code true} if there are fewer than {@code maxUlps} floating
 * point values between {@code x} and {@code y}.
 * @since 2.2
 */
public static boolean equals(float x, float y, int maxUlps) {
    int xInt = Float.floatToIntBits(x);
    int yInt = Float.floatToIntBits(y);
    // Make lexicographically ordered as a two's-complement integer.
    if (xInt < 0) {
        xInt = SGN_MASK_FLOAT - xInt;
    }
    if (yInt < 0) {
        yInt = SGN_MASK_FLOAT - yInt;
    }
    final boolean isEqual = FastMath.abs(xInt - yInt) <= maxUlps;
    return isEqual && !Float.isNaN(x) && !Float.isNaN(y);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1127_ba62c59d,Major,src/main/java/org/apache/commons/math3/util/Precision.java,332,347,"/**
 * Returns true if both arguments are equal or within the range of allowed
 * error (inclusive).
 * Two float numbers are considered equal if there are {@code (maxUlps - 1)}
 * (or fewer) floating point numbers between them, i.e. two adjacent floating
 * point numbers are considered equal.
 * Adapted from <a
 * href=""http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm"">
 * Bruce Dawson</a>
 *
 * @param x first value
 * @param y second value
 * @param maxUlps {@code (maxUlps - 1)} is the number of floating point
 * values between {@code x} and {@code y}.
 * @return {@code true} if there are fewer than {@code maxUlps} floating
 * point values between {@code x} and {@code y}.
 */
public static boolean equals(double x, double y, int maxUlps) {
    long xInt = Double.doubleToLongBits(x);
    long yInt = Double.doubleToLongBits(y);
    // Make lexicographically ordered as a two's-complement integer.
    if (xInt < 0) {
        xInt = SGN_MASK - xInt;
    }
    if (yInt < 0) {
        yInt = SGN_MASK - yInt;
    }
    final boolean isEqual = FastMath.abs(xInt - yInt) <= maxUlps;
    return isEqual && !Double.isNaN(x) && !Double.isNaN(y);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1129_d4f978dd,Major,src/main/java/org/apache/commons/math3/stat/descriptive/rank/Percentile.java,442,452,"/**
 * Sort in place a (small) array slice using insertion sort
 * @param work array to sort
 * @param begin index of the first element of the slice to sort
 * @param end index after the last element of the slice to sort
 */
private void insertionSort(final double[] work, final int begin, final int end) {
    for (int j = begin + 1; j < end; j++) {
        final double saved = work[j];
        int i = j - 1;
        while ((i >= begin) && (saved < work[i])) {
            work[i + 1] = work[i];
            i--;
        }
        work[i + 1] = saved;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1135_a7363a2a,Minor,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/MonotoneChain.java,130,174,"/**
 * Update the partial hull with the current point.
 *
 * @param point the current point
 * @param hull the partial hull
 */
private void updateHull(final Vector2D point, final List<Vector2D> hull) {
    final double tolerance = getTolerance();
    if (hull.size() == 1) {
        // ensure that we do not add an identical point
        final Vector2D p1 = hull.get(0);
        if (p1.distance(point) < tolerance) {
            return;
        }
    }
    while (hull.size() >= 2) {
        final int size = hull.size();
        final Vector2D p1 = hull.get(size - 2);
        final Vector2D p2 = hull.get(size - 1);
        final double offset = new Line(p1, p2, tolerance).getOffset(point);
        if (FastMath.abs(offset) < tolerance) {
            // the point is collinear to the line (p1, p2)
            final double distanceToCurrent = p1.distance(point);
            if (distanceToCurrent < tolerance || p2.distance(point) < tolerance) {
                // the point is assumed to be identical to either p1 or p2
                return;
            }
            final double distanceToLast = p1.distance(p2);
            if (isIncludeCollinearPoints()) {
                final int index = distanceToCurrent < distanceToLast ? size - 1 : size;
                hull.add(index, point);
            } else {
                if (distanceToCurrent > distanceToLast) {
                    hull.remove(size - 1);
                }
                hull.add(point);
            }
            return;
        } else if (offset > 0) {
            hull.remove(size - 1);
        } else {
            break;
        }
    }
    hull.add(point);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1136_cc4ab51e,Minor,src/main/java/org/apache/commons/math3/distribution/BinomialDistribution.java,107,118,"/**
 * {@inheritDoc} *
 */
@Override
public double logProbability(int x) {
    double ret;
    if (x < 0 || x > numberOfTrials) {
        ret = Double.NEGATIVE_INFINITY;
    } else {
        ret = SaddlePointExpansion.logBinomialProbability(x, numberOfTrials, probabilityOfSuccess, 1.0 - probabilityOfSuccess);
    }
    return ret;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1148_4080feff,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/ConvexHull2D.java,78,104,"/**
 * Checks whether the given hull vertices form a convex hull.
 * @param hullVertices the hull vertices
 * @return {@code true} if the vertices form a convex hull, {@code false} otherwise
 */
private boolean isConvex(final Vector2D[] hullVertices) {
    if (hullVertices.length < 3) {
        return true;
    }
    double sign = 0.0;
    for (int i = 0; i < hullVertices.length; i++) {
        final Vector2D p1 = hullVertices[i == 0 ? hullVertices.length - 1 : i - 1];
        final Vector2D p2 = hullVertices[i];
        final Vector2D p3 = hullVertices[i == hullVertices.length - 1 ? 0 : i + 1];
        final Vector2D d1 = p2.subtract(p1);
        final Vector2D d2 = p3.subtract(p2);
        final double cross = FastMath.signum(MathArrays.linearCombination(d1.getX(), d2.getY(), -d1.getY(), d2.getX()));
        // in case of collinear points the cross product will be zero
        if (cross != 0.0) {
            if (sign != 0.0 && cross != sign) {
                return false;
            }
            sign = cross;
        }
    }
    return true;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1148_4080feff,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/MonotoneChain.java,75,121,"@Override
public Collection<Vector2D> findHullVertices(final Collection<Vector2D> points) {
    final List<Vector2D> pointsSortedByXAxis = new ArrayList<Vector2D>(points);
    // sort the points in increasing order on the x-axis
    Collections.sort(pointsSortedByXAxis, new Comparator<Vector2D>() {

        public int compare(final Vector2D o1, final Vector2D o2) {
            final int diff = (int) FastMath.signum(o1.getX() - o2.getX());
            if (diff == 0) {
                return (int) FastMath.signum(o1.getY() - o2.getY());
            } else {
                return diff;
            }
        }
    });
    // build lower hull
    final List<Vector2D> lowerHull = new ArrayList<Vector2D>();
    for (Vector2D p : pointsSortedByXAxis) {
        updateHull(p, lowerHull);
    }
    // build upper hull
    final List<Vector2D> upperHull = new ArrayList<Vector2D>();
    for (int idx = pointsSortedByXAxis.size() - 1; idx >= 0; idx--) {
        final Vector2D p = pointsSortedByXAxis.get(idx);
        updateHull(p, upperHull);
    }
    // concatenate the lower and upper hulls
    // the last point of each list is omitted as it is repeated at the beginning of the other list
    final List<Vector2D> hullVertices = new ArrayList<Vector2D>(lowerHull.size() + upperHull.size() - 2);
    for (int idx = 0; idx < lowerHull.size() - 1; idx++) {
        hullVertices.add(lowerHull.get(idx));
    }
    for (int idx = 0; idx < upperHull.size() - 1; idx++) {
        hullVertices.add(upperHull.get(idx));
    }
    // special case: if the lower and upper hull may contain only 1 point if all are identical
    if (hullVertices.isEmpty() && !lowerHull.isEmpty()) {
        hullVertices.add(lowerHull.get(0));
    }
    return hullVertices;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1148_4080feff,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/hull/MonotoneChain.java,82,89,"public int compare(final Vector2D o1, final Vector2D o2) {
    final int diff = (int) FastMath.signum(o1.getX() - o2.getX());
    if (diff == 0) {
        return (int) FastMath.signum(o1.getY() - o2.getY());
    } else {
        return diff;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1165_596ccd59,Minor,src/main/java/org/apache/commons/math3/ml/clustering/FuzzyKMeansClusterer.java,346,369,"/**
 * Updates the membership matrix and assigns the points to the cluster with
 * the highest membership.
 */
private void updateMembershipMatrix() {
    for (int i = 0; i < points.size(); i++) {
        final T point = points.get(i);
        double maxMembership = 0.0;
        int newCluster = -1;
        for (int j = 0; j < clusters.size(); j++) {
            double sum = 0.0;
            final double distA = FastMath.abs(distance(point, clusters.get(j).getCenter()));
            for (final CentroidCluster<T> c : clusters) {
                final double distB = FastMath.abs(distance(point, c.getCenter()));
                sum += FastMath.pow(distA / distB, 2.0 / (fuzziness - 1.0));
            }
            membershipMatrix[i][j] = 1.0 / sum;
            if (membershipMatrix[i][j] > maxMembership) {
                maxMembership = membershipMatrix[i][j];
                newCluster = j;
            }
        }
        clusters.get(newCluster).addPoint(point);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1203_4aa4c6d3,Major,src/main/java/org/apache/commons/math4/random/EmpiricalDistribution.java,801,809,"/**
 * The within-bin smoothing kernel. Returns a Gaussian distribution
 * parameterized by {@code bStats}, unless the bin contains only one
 * observation, in which case a constant distribution is returned.
 *
 * @param bStats summary statistics for the bin
 * @return within-bin kernel parameterized by bStats
 */
protected RealDistribution getKernel(SummaryStatistics bStats) {
    if (bStats.getN() == 1) {
        return new ConstantRealDistribution(bStats.getMean());
    } else {
        return new NormalDistribution(randomData.getRandomGenerator(), bStats.getMean(), bStats.getStandardDeviation(), NormalDistribution.DEFAULT_INVERSE_ABSOLUTE_ACCURACY);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1203_b148046a,Major,src/main/java/org/apache/commons/math4/random/EmpiricalDistribution.java,600,616,"/**
 * {@inheritDoc}
 *
 * <p>Algorithm description:<ol>
 * <li>Find the bin B that x belongs to.</li>
 * <li>Compute P(B) = the mass of B and P(B-) = the combined mass of the bins below B.</li>
 * <li>Compute K(B) = the probability mass of B with respect to the within-bin kernel
 * and K(B-) = the kernel distribution evaluated at the lower endpoint of B</li>
 * <li>Return P(B-) + P(B) * [K(x) - K(B-)] / K(B) where
 * K(x) is the within-bin kernel distribution function evaluated at x.</li></ol></p>
 *
 * @since 3.1
 */
public double cumulativeProbability(double x) {
    if (x < min) {
        return 0d;
    } else if (x >= max) {
        return 1d;
    }
    final int binIndex = findBin(x);
    final double pBminus = pBminus(binIndex);
    final double pB = pB(binIndex);
    final double[] binBounds = getUpperBounds();
    final double kB = kB(binIndex);
    final double lower = binIndex == 0 ? min : binBounds[binIndex - 1];
    final RealDistribution kernel = k(x);
    final double withinBinCum = (kernel.cumulativeProbability(x) - kernel.cumulativeProbability(lower)) / kB;
    return pBminus + pB * withinBinCum;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1204_a56d4998,Major,src/main/java/org/apache/commons/math4/analysis/solvers/UnivariateSolverUtils.java,293,355,"/**
 * This method attempts to find two values a and b satisfying <ul>
 * <li> {@code lowerBound <= a < initial < b <= upperBound} </li>
 * <li> {@code f(a) * f(b) <= 0} </li>
 * </ul>
 * If {@code f} is continuous on {@code [a,b]}, this means that {@code a}
 * and {@code b} bracket a root of {@code f}.
 * <p>
 * The algorithm checks the sign of \( f(l_k) \) and \( f(u_k) \) for increasing
 * values of k, where \( l_k = max(lower, initial - \delta_k) \),
 * \( u_k = min(upper, initial + \delta_k) \), using recurrence
 * \( \delta_{k+1} = r \delta_k + q, \delta_0 = 0\) and starting search with \( k=1 \).
 * The algorithm stops when one of the following happens: <ul>
 * <li> at least one positive and one negative value have been found --  success!</li>
 * <li> both endpoints have reached their respective limites -- NoBracketingException </li>
 * <li> {@code maximumIterations} iterations elapse -- NoBracketingException </li></ul></p>
 * <p>
 * If different signs are found at first iteration ({@code k=1}), then the returned
 * interval will be \( [a, b] = [l_1, u_1] \). If different signs are found at a later
 * iteration ({code k>1}, then the returned interval will be either
 * \( [a, b] = [l_{k+1}, l_{k}] \) or \( [a, b] = [u_{k}, u_{k+1}] \). A root solver called
 * with these parameters will therefore start with the smallest bracketing interval known
 * at this step.
 * </p>
 * <p>
 * Interval expansion rate is tuned by changing the recurrence parameters {@code r} and
 * {@code q}. When the multiplicative factor {@code r} is set to 1, the sequence is a
 * simple arithmetic sequence with linear increase. When the multiplicative factor {@code r}
 * is larger than 1, the sequence has an asymtotically exponential rate. Note than the
 * additive parameter {@code q} should never be set to zero, otherwise the interval would
 * degenerate to the single initial point for all values of {@code k}.
 * </p>
 * <p>
 * As a rule of thumb, when the location of the root is expected to be approximately known
 * within some error margin, {@code r} should be set to 1 and {@code q} should be set to the
 * order of magnitude of the error margin. When the location of the root is really a wild guess,
 * then {@code r} should be set to a value larger than 1 (typically 2 to double the interval
 * length at each iteration) and {@code q} should be set according to half the initial
 * search interval length.
 * </p>
 * <p>
 * As an example, if we consider the trivial function {@code f(x) = 1 - x} and use
 * {@code initial = 4}, {@code r = 1}, {@code q = 2}, the algorithm will compute
 * {@code f(4-2) = f(2) = -1} and {@code f(4+2) = f(6) = -5} for {@code k = 1}, then
 * {@code f(4-4) = f(0) = +1} and {@code f(4+4) = f(8) = -7} for {@code k = 2}. Then it will
 * return the interval {@code [0, 2]} as the smallest one known to be bracketing the root.
 * As shown by this example, the initial value (here {@code 4}) may lie outside of the returned
 * bracketing interval.
 * </p>
 * @param function function to check
 * @param initial Initial midpoint of interval being expanded to
 * bracket a root.
 * @param lowerBound Lower bound (a is never lower than this value).
 * @param upperBound Upper bound (b never is greater than this
 * value).
 * @param q additive offset used to compute bounds sequence (must be strictly positive)
 * @param r multiplicative factor used to compute bounds sequence
 * @param maximumIterations Maximum number of iterations to perform
 * @return a two element array holding the bracketing values.
 * @exception NoBracketingException if function cannot be bracketed in the search interval
 */
public static double[] bracket(final UnivariateFunction function, final double initial, final double lowerBound, final double upperBound, final double q, final double r, final int maximumIterations) throws NoBracketingException {
    if (function == null) {
        throw new NullArgumentException(LocalizedFormats.FUNCTION);
    }
    if (q <= 0) {
        throw new NotStrictlyPositiveException(q);
    }
    if (maximumIterations <= 0) {
        throw new NotStrictlyPositiveException(LocalizedFormats.INVALID_MAX_ITERATIONS, maximumIterations);
    }
    verifySequence(lowerBound, initial, upperBound);
    // initialize the recurrence
    double a = initial;
    double b = initial;
    double fa = Double.NaN;
    double fb = Double.NaN;
    double delta = 0;
    for (int numIterations = 0; (numIterations < maximumIterations) && (a > lowerBound || b > upperBound); ++numIterations) {
        final double previousA = a;
        final double previousFa = fa;
        final double previousB = b;
        final double previousFb = fb;
        delta = r * delta + q;
        a = FastMath.max(initial - delta, lowerBound);
        b = FastMath.min(initial + delta, upperBound);
        fa = function.value(a);
        fb = function.value(b);
        if (numIterations == 0) {
            // we simply compare both sides of the initial interval
            if (fa * fb <= 0) {
                // the first interval already brackets a root
                return new double[] { a, b };
            }
        } else {
            // we expect sign changes to occur at boundaries
            if (fa * previousFa <= 0) {
                // sign change detected at near lower bound
                return new double[] { a, previousA };
            } else if (fb * previousFb <= 0) {
                // sign change detected at near upper bound
                return new double[] { previousB, b };
            }
        }
    }
    // no bracketing found
    throw new NoBracketingException(a, b, fa, fb);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1208_ce2badf0,Major,src/main/java/org/apache/commons/math4/random/EmpiricalDistribution.java,602,621,"/**
 * {@inheritDoc}
 *
 * <p>Algorithm description:<ol>
 * <li>Find the bin B that x belongs to.</li>
 * <li>Compute P(B) = the mass of B and P(B-) = the combined mass of the bins below B.</li>
 * <li>Compute K(B) = the probability mass of B with respect to the within-bin kernel
 * and K(B-) = the kernel distribution evaluated at the lower endpoint of B</li>
 * <li>Return P(B-) + P(B) * [K(x) - K(B-)] / K(B) where
 * K(x) is the within-bin kernel distribution function evaluated at x.</li></ol>
 * If K is a constant distribution, we return P(B-) + P(B) (counting the full
 * mass of B).</p>
 *
 * @since 3.1
 */
public double cumulativeProbability(double x) {
    if (x < min) {
        return 0d;
    } else if (x >= max) {
        return 1d;
    }
    final int binIndex = findBin(x);
    final double pBminus = pBminus(binIndex);
    final double pB = pB(binIndex);
    final RealDistribution kernel = k(x);
    if (kernel instanceof ConstantRealDistribution) {
        return pBminus + pB;
    }
    final double[] binBounds = getUpperBounds();
    final double kB = kB(binIndex);
    final double lower = binIndex == 0 ? min : binBounds[binIndex - 1];
    final double withinBinCum = (kernel.cumulativeProbability(x) - kernel.cumulativeProbability(lower)) / kB;
    return pBminus + pB * withinBinCum;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1211_a06a1584,Major,src/main/java/org/apache/commons/math4/geometry/euclidean/threed/PolyhedronsSet.java,247,249,"/**
 * Get the first sub-hyperplane crossed by a semi-infinite line.
 * @param point start point of the part of the line considered
 * @param line line to consider (contains point)
 * @return the first sub-hyperplaned crossed by the line after the
 * given point, or null if the line does not intersect any
 * sub-hyperplaned
 */
public SubHyperplane<Euclidean3D> firstIntersection(final Vector3D point, final Line line) {
    return recurseFirstIntersection(getTree(true), point, line);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1211_a06a1584,Major,src/main/java/org/apache/commons/math4/geometry/euclidean/threed/PolyhedronsSet.java,259,312,"/**
 * Get the first sub-hyperplane crossed by a semi-infinite line.
 * @param node current node
 * @param point start point of the part of the line considered
 * @param line line to consider (contains point)
 * @return the first sub-hyperplaned crossed by the line after the
 * given point, or null if the line does not intersect any
 * sub-hyperplaned
 */
private SubHyperplane<Euclidean3D> recurseFirstIntersection(final BSPTree<Euclidean3D> node, final Vector3D point, final Line line) {
    final SubHyperplane<Euclidean3D> cut = node.getCut();
    if (cut == null) {
        return null;
    }
    final BSPTree<Euclidean3D> minus = node.getMinus();
    final BSPTree<Euclidean3D> plus = node.getPlus();
    final Plane plane = (Plane) cut.getHyperplane();
    // establish search order
    final double offset = plane.getOffset((Point<Euclidean3D>) point);
    final boolean in = FastMath.abs(offset) < 1.0e-10;
    final BSPTree<Euclidean3D> near;
    final BSPTree<Euclidean3D> far;
    if (offset < 0) {
        near = minus;
        far = plus;
    } else {
        near = plus;
        far = minus;
    }
    if (in) {
        // search in the cut hyperplane
        final SubHyperplane<Euclidean3D> facet = boundaryFacet(point, node);
        if (facet != null) {
            return facet;
        }
    }
    // search in the near branch
    final SubHyperplane<Euclidean3D> crossed = recurseFirstIntersection(near, point, line);
    if (crossed != null) {
        return crossed;
    }
    if (!in) {
        // search in the cut hyperplane
        final Vector3D hit3D = plane.intersection(line);
        if (hit3D != null) {
            final SubHyperplane<Euclidean3D> facet = boundaryFacet(hit3D, node);
            if (facet != null) {
                return facet;
            }
        }
    }
    // search in the far branch
    return recurseFirstIntersection(far, point, line);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1226_c44bfe00,Minor,src/main/java/org/apache/commons/math4/ode/events/EventState.java,224,328,"/**
 * Evaluate the impact of the proposed step on the event handler.
 * @param interpolator step interpolator for the proposed step
 * @return true if the event handler triggers an event before
 * the end of the proposed step
 * @exception MaxCountExceededException if the interpolator throws one because
 * the number of functions evaluations is exceeded
 * @exception NoBracketingException if the event cannot be bracketed
 */
public boolean evaluateStep(final StepInterpolator interpolator) throws MaxCountExceededException, NoBracketingException {
    try {
        forward = interpolator.isForward();
        final double t1 = interpolator.getCurrentTime();
        final double dt = t1 - t0;
        if (FastMath.abs(dt) < convergence) {
            // we cannot do anything on such a small step, don't trigger any events
            return false;
        }
        final int n = FastMath.max(1, (int) FastMath.ceil(FastMath.abs(dt) / maxCheckInterval));
        final double h = dt / n;
        final UnivariateFunction f = new UnivariateFunction() {

            public double value(final double t) throws LocalMaxCountExceededException {
                try {
                    interpolator.setInterpolatedTime(t);
                    return handler.g(t, getCompleteState(interpolator));
                } catch (MaxCountExceededException mcee) {
                    throw new LocalMaxCountExceededException(mcee);
                }
            }
        };
        double ta = t0;
        double ga = g0;
        for (int i = 0; i < n; ++i) {
            // evaluate handler value at the end of the substep
            final double tb = t0 + (i + 1) * h;
            interpolator.setInterpolatedTime(tb);
            final double gb = handler.g(tb, getCompleteState(interpolator));
            // check events occurrence
            if (g0Positive ^ (gb >= 0)) {
                // there is a sign change: an event is expected during this step
                // variation direction, with respect to the integration direction
                increasing = gb >= ga;
                // find the event time making sure we select a solution just at or past the exact root
                final double root;
                if (solver instanceof BracketedUnivariateSolver<?>) {
                    @SuppressWarnings(""unchecked"")
                    BracketedUnivariateSolver<UnivariateFunction> bracketing = (BracketedUnivariateSolver<UnivariateFunction>) solver;
                    root = forward ? bracketing.solve(maxIterationCount, f, ta, tb, AllowedSolution.RIGHT_SIDE) : bracketing.solve(maxIterationCount, f, tb, ta, AllowedSolution.LEFT_SIDE);
                } else {
                    final double baseRoot = forward ? solver.solve(maxIterationCount, f, ta, tb) : solver.solve(maxIterationCount, f, tb, ta);
                    final int remainingEval = maxIterationCount - solver.getEvaluations();
                    BracketedUnivariateSolver<UnivariateFunction> bracketing = new PegasusSolver(solver.getRelativeAccuracy(), solver.getAbsoluteAccuracy());
                    root = forward ? UnivariateSolverUtils.forceSide(remainingEval, f, bracketing, baseRoot, ta, tb, AllowedSolution.RIGHT_SIDE) : UnivariateSolverUtils.forceSide(remainingEval, f, bracketing, baseRoot, tb, ta, AllowedSolution.LEFT_SIDE);
                }
                if ((!Double.isNaN(previousEventTime)) && (FastMath.abs(root - ta) <= convergence) && (FastMath.abs(root - previousEventTime) <= convergence)) {
                    // crosses the axis several times
                    do {
                        ta = forward ? ta + convergence : ta - convergence;
                        ga = f.value(ta);
                    } while ((g0Positive ^ (ga >= 0)) && (forward ^ (ta >= tb)));
                    --i;
                } else if (Double.isNaN(previousEventTime) || (FastMath.abs(previousEventTime - root) > convergence)) {
                    pendingEventTime = root;
                    pendingEvent = true;
                    return true;
                } else {
                    // no sign change: there is no event for now
                    ta = tb;
                    ga = gb;
                }
            } else {
                // no sign change: there is no event for now
                ta = tb;
                ga = gb;
            }
        }
        // no event during the whole step
        pendingEvent = false;
        pendingEventTime = Double.NaN;
        return false;
    } catch (LocalMaxCountExceededException lmcee) {
        throw lmcee.getException();
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1230_96eb80ef,Major,src/main/java/org/apache/commons/math4/optim/linear/SimplexSolver.java,150,155,"/**
 * {@inheritDoc}
 *
 * @param optData Optimization data. In addition to those documented in
 * {@link LinearOptimizer#optimize(OptimizationData...)
 * LinearOptimizer}, this method will register the following data:
 * <ul>
 *  <li>{@link SolutionCallback}</li>
 *  <li>{@link PivotSelectionRule}</li>
 * </ul>
 *
 * @return {@inheritDoc}
 * @throws TooManyIterationsException if the maximal number of iterations is exceeded.
 */
@Override
public PointValuePair optimize(OptimizationData... optData) throws TooManyIterationsException {
    // Set up base class and perform computation.
    return super.optimize(optData);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1241_471e6b07,Minor,src/main/java/org/apache/commons/math4/special/Gamma.java,444,461,"/**
 * <p>Computes the digamma function of x.</p>
 *
 * <p>This is an independently written implementation of the algorithm described in
 * Jose Bernardo, Algorithm AS 103: Psi (Digamma) Function, Applied Statistics, 1976.</p>
 *
 * <p>Some of the constants have been changed to increase accuracy at the moderate expense
 * of run-time.  The result should be accurate to within 10^-8 absolute tolerance for
 * x >= 10^-5 and within 10^-8 relative tolerance for x > 0.</p>
 *
 * <p>Performance for large negative values of x will be quite expensive (proportional to
 * |x|).  Accuracy for negative values of x should be about 10^-8 absolute for results
 * less than 10^5 and 10^-8 relative for results larger than that.</p>
 *
 * @param x Argument.
 * @return digamma(x) to within 10-8 relative or absolute error whichever is smaller.
 * @see <a href=""http://en.wikipedia.org/wiki/Digamma_function"">Digamma</a>
 * @see <a href=""http://www.uv.es/~bernardo/1976AppStatist.pdf"">Bernardo&apos;s original article </a>
 * @since 2.0
 */
public static double digamma(double x) {
    if (x > 0 && x <= S_LIMIT) {
        // accurate to O(x)
        return -GAMMA - 1 / x;
    }
    if (x >= C_LIMIT) {
        // use method 4 (accurate to O(1/x^8)
        double inv = 1 / (x * x);
        // 2 x   12 x^2   120 x^4   252 x^6
        return FastMath.log(x) - 0.5 / x - inv * ((1.0 / 12) + inv * (1.0 / 120 - inv / 252));
    }
    return digamma(x + 1) - 1 / x;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1241_471e6b07,Minor,src/main/java/org/apache/commons/math4/special/Gamma.java,474,489,"/**
 * Computes the trigamma function of x.
 * This function is derived by taking the derivative of the implementation
 * of digamma.
 *
 * @param x Argument.
 * @return trigamma(x) to within 10-8 relative or absolute error whichever is smaller
 * @see <a href=""http://en.wikipedia.org/wiki/Trigamma_function"">Trigamma</a>
 * @see Gamma#digamma(double)
 * @since 2.0
 */
public static double trigamma(double x) {
    if (x > 0 && x <= S_LIMIT) {
        return 1 / (x * x);
    }
    if (x >= C_LIMIT) {
        double inv = 1 / (x * x);
        // 2 x    6 x    30 x    42 x
        return 1 / x + inv / 2 + inv / x * (1.0 / 6 - inv * (1.0 / 30 + inv / 42));
    }
    return trigamma(x + 1) + 1 / (x * x);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1257_03178c8b,Minor,src/main/java/org/apache/commons/math4/distribution/NormalDistribution.java,190,197,"/**
 * {@inheritDoc}
 *
 * If {@code x} is more than 40 standard deviations from the mean, 0 or 1
 * is returned, as in these cases the actual value is within
 * {@code Double.MIN_VALUE} of 0 or 1.
 */
@Override
public double cumulativeProbability(double x) {
    final double dev = x - mean;
    if (FastMath.abs(dev) > 40 * standardDeviation) {
        return dev < 0 ? 0.0d : 1.0d;
    }
    return 0.5 * (1 + Erf.erf(dev / (standardDeviation * SQRT2)));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1261_4c4b3e2e,Minor,src/main/java/org/apache/commons/math4/fraction/Fraction.java,567,570,"/**
 * Multiply the fraction by an integer.
 * @param i the {@code integer} to multiply by.
 * @return this * i
 */
@Override
public Fraction multiply(final int i) {
    return new Fraction(numerator * i, denominator);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1261_4c4b3e2e,Minor,src/main/java/org/apache/commons/math4/fraction/Fraction.java,599,601,"/**
 * Divide the fraction by an integer.
 * @param i the {@code integer} to divide by.
 * @return this * i
 */
public Fraction divide(final int i) {
    return new Fraction(numerator, denominator * i);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1269_a94ff90a,Major,src/main/java/org/apache/commons/math4/util/FastMath.java,874,985,"/**
 * Internal helper method for exponential function.
 * @param x original argument of the exponential function
 * @param extra extra bits of precision on input (To Be Confirmed)
 * @param hiPrec extra bits of precision on output (To Be Confirmed)
 * @return exp(x)
 */
private static double exp(double x, double extra, double[] hiPrec) {
    double intPartA;
    double intPartB;
    int intVal = (int) x;
    /* Lookup exp(floor(x)).
         * intPartA will have the upper 22 bits, intPartB will have the lower
         * 52 bits.
         */
    if (x < 0.0) {
        // may be affected by a JIT bug. Subsequent comparisons can safely use intVal
        if (x < -746d) {
            if (hiPrec != null) {
                hiPrec[0] = 0.0;
                hiPrec[1] = 0.0;
            }
            return 0.0;
        }
        if (intVal < -709) {
            /* This will produce a subnormal output */
            final double result = exp(x + 40.19140625, extra, hiPrec) / 285040095144011776.0;
            if (hiPrec != null) {
                hiPrec[0] /= 285040095144011776.0;
                hiPrec[1] /= 285040095144011776.0;
            }
            return result;
        }
        if (intVal == -709) {
            /* exp(1.494140625) is nearly a machine number... */
            final double result = exp(x + 1.494140625, extra, hiPrec) / 4.455505956692756620;
            if (hiPrec != null) {
                hiPrec[0] /= 4.455505956692756620;
                hiPrec[1] /= 4.455505956692756620;
            }
            return result;
        }
        intVal--;
    } else {
        if (intVal > 709) {
            if (hiPrec != null) {
                hiPrec[0] = Double.POSITIVE_INFINITY;
                hiPrec[1] = 0.0;
            }
            return Double.POSITIVE_INFINITY;
        }
    }
    intPartA = ExpIntTable.EXP_INT_TABLE_A[EXP_INT_TABLE_MAX_INDEX + intVal];
    intPartB = ExpIntTable.EXP_INT_TABLE_B[EXP_INT_TABLE_MAX_INDEX + intVal];
    /* Get the fractional part of x, find the greatest multiple of 2^-10 less than
         * x and look up the exp function of it.
         * fracPartA will have the upper 22 bits, fracPartB the lower 52 bits.
         */
    final int intFrac = (int) ((x - intVal) * 1024.0);
    final double fracPartA = ExpFracTable.EXP_FRAC_TABLE_A[intFrac];
    final double fracPartB = ExpFracTable.EXP_FRAC_TABLE_B[intFrac];
    /* epsilon is the difference in x from the nearest multiple of 2^-10.  It
         * has a value in the range 0 <= epsilon < 2^-10.
         * Do the subtraction from x as the last step to avoid possible loss of precision.
         */
    final double epsilon = x - (intVal + intFrac / 1024.0);
    /* Compute z = exp(epsilon) - 1.0 via a minimax polynomial.  z has
       full double precision (52 bits).  Since z < 2^-10, we will have
       62 bits of precision when combined with the constant 1.  This will be
       used in the last addition below to get proper rounding. */
    /* Remez generated polynomial.  Converges on the interval [0, 2^-10], error
       is less than 0.5 ULP */
    double z = 0.04168701738764507;
    z = z * epsilon + 0.1666666505023083;
    z = z * epsilon + 0.5000000000042687;
    z = z * epsilon + 1.0;
    z = z * epsilon + -3.940510424527919E-20;
    /* Compute (intPartA+intPartB) * (fracPartA+fracPartB) by binomial
       expansion.
       tempA is exact since intPartA and intPartB only have 22 bits each.
       tempB will have 52 bits of precision.
         */
    double tempA = intPartA * fracPartA;
    double tempB = intPartA * fracPartB + intPartB * fracPartA + intPartB * fracPartB;
    /* Compute the result.  (1+z)(tempA+tempB).  Order of operations is
       important.  For accuracy add by increasing size.  tempA is exact and
       much larger than the others.  If there are extra bits specified from the
       pow() function, use them. */
    final double tempC = tempB + tempA;
    final double result;
    if (extra != 0.0) {
        result = tempC * extra * z + tempC * extra + tempC * z + tempB + tempA;
    } else {
        result = tempC * z + tempB + tempA;
    }
    if (hiPrec != null) {
        // If requesting high precision
        hiPrec[0] = tempA;
        hiPrec[1] = tempC * extra * z + tempC * extra + tempC * z + tempB;
    }
    return result;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1272_26e878ab,Minor,src/main/java/org/apache/commons/math4/util/FastMath.java,1718,1756,"/**
 * Computes this^e.
 * @param e exponent (beware, here it MUST be > 0)
 * @return d^e, split in high and low bits
 * @since 4.0
 */
private Split pow(final long e) {
    // prepare result
    Split result = new Split(1);
    // d^(2p)
    Split d2p = new Split(full, high, low);
    for (long p = e; p != 0; p >>= 1) {
        if ((p & 0x1) != 0) {
            // accurate multiplication result = result * d^(2p) using Veltkamp TwoProduct algorithm
            result = result.multiply(d2p);
        }
        // accurate squaring d^(2(p+1)) = d^(2p) * d^(2p) using Veltkamp TwoProduct algorithm
        d2p = d2p.multiply(d2p);
    }
    if (Double.isNaN(result.full)) {
        if (Double.isNaN(full)) {
            return Split.NAN;
        } else {
            // and the low order bits became NaN (because infinity - infinity = NaN)
            if (FastMath.abs(full) < 1) {
                return new Split(FastMath.copySign(0.0, full), 0.0);
            } else if (full < 0 && (e & 0x1) == 1) {
                return Split.NEGATIVE_INFINITY;
            } else {
                return Split.POSITIVE_INFINITY;
            }
        }
    } else {
        return result;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1277_fb007815,Minor,src/main/java/org/apache/commons/math4/stat/correlation/KendallsCorrelation.java,154,260,"/**
 * Computes the Kendall's Tau rank correlation coefficient between the two arrays.
 *
 * @param xArray first data array
 * @param yArray second data array
 * @return Returns Kendall's Tau rank correlation coefficient for the two arrays
 * @throws DimensionMismatchException if the arrays lengths do not match
 */
public double correlation(final double[] xArray, final double[] yArray) throws DimensionMismatchException {
    if (xArray.length != yArray.length) {
        throw new DimensionMismatchException(xArray.length, yArray.length);
    }
    final int n = xArray.length;
    final long numPairs = sum(n - 1);
    @SuppressWarnings(""unchecked"")
    Pair<Double, Double>[] pairs = new Pair[n];
    for (int i = 0; i < n; i++) {
        pairs[i] = new Pair<Double, Double>(xArray[i], yArray[i]);
    }
    Arrays.sort(pairs, new Comparator<Pair<Double, Double>>() {

        @Override
        public int compare(Pair<Double, Double> pair1, Pair<Double, Double> pair2) {
            int compareFirst = pair1.getFirst().compareTo(pair2.getFirst());
            return compareFirst != 0 ? compareFirst : pair1.getSecond().compareTo(pair2.getSecond());
        }
    });
    long tiedXPairs = 0;
    long tiedXYPairs = 0;
    long consecutiveXTies = 1;
    long consecutiveXYTies = 1;
    Pair<Double, Double> prev = pairs[0];
    for (int i = 1; i < n; i++) {
        final Pair<Double, Double> curr = pairs[i];
        if (curr.getFirst().equals(prev.getFirst())) {
            consecutiveXTies++;
            if (curr.getSecond().equals(prev.getSecond())) {
                consecutiveXYTies++;
            } else {
                tiedXYPairs += sum(consecutiveXYTies - 1);
                consecutiveXYTies = 1;
            }
        } else {
            tiedXPairs += sum(consecutiveXTies - 1);
            consecutiveXTies = 1;
            tiedXYPairs += sum(consecutiveXYTies - 1);
            consecutiveXYTies = 1;
        }
        prev = curr;
    }
    tiedXPairs += sum(consecutiveXTies - 1);
    tiedXYPairs += sum(consecutiveXYTies - 1);
    int swaps = 0;
    @SuppressWarnings(""unchecked"")
    Pair<Double, Double>[] pairsDestination = new Pair[n];
    for (int segmentSize = 1; segmentSize < n; segmentSize <<= 1) {
        for (int offset = 0; offset < n; offset += 2 * segmentSize) {
            int i = offset;
            final int iEnd = FastMath.min(i + segmentSize, n);
            int j = iEnd;
            final int jEnd = FastMath.min(j + segmentSize, n);
            int copyLocation = offset;
            while (i < iEnd || j < jEnd) {
                if (i < iEnd) {
                    if (j < jEnd) {
                        if (pairs[i].getSecond().compareTo(pairs[j].getSecond()) <= 0) {
                            pairsDestination[copyLocation] = pairs[i];
                            i++;
                        } else {
                            pairsDestination[copyLocation] = pairs[j];
                            j++;
                            swaps += iEnd - i;
                        }
                    } else {
                        pairsDestination[copyLocation] = pairs[i];
                        i++;
                    }
                } else {
                    pairsDestination[copyLocation] = pairs[j];
                    j++;
                }
                copyLocation++;
            }
        }
        final Pair<Double, Double>[] pairsTemp = pairs;
        pairs = pairsDestination;
        pairsDestination = pairsTemp;
    }
    long tiedYPairs = 0;
    long consecutiveYTies = 1;
    prev = pairs[0];
    for (int i = 1; i < n; i++) {
        final Pair<Double, Double> curr = pairs[i];
        if (curr.getSecond().equals(prev.getSecond())) {
            consecutiveYTies++;
        } else {
            tiedYPairs += sum(consecutiveYTies - 1);
            consecutiveYTies = 1;
        }
        prev = curr;
    }
    tiedYPairs += sum(consecutiveYTies - 1);
    final long concordantMinusDiscordant = numPairs - tiedXPairs - tiedYPairs + tiedXYPairs - 2 * swaps;
    final double nonTiedPairsMultiplied = (numPairs - tiedXPairs) * (double) (numPairs - tiedYPairs);
    return concordantMinusDiscordant / FastMath.sqrt(nonTiedPairsMultiplied);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1283_9e0c5ad4,Minor,src/main/java/org/apache/commons/math4/special/Gamma.java,655,717,"/**
 * Returns the value of Γ(x). Based on the <em>NSWC Library of
 * Mathematics Subroutines</em> double precision implementation,
 * {@code DGAMMA}.
 *
 * @param x Argument.
 * @return the value of {@code Gamma(x)}.
 * @since 3.1
 */
public static double gamma(final double x) {
    if ((x == FastMath.rint(x)) && (x <= 0.0)) {
        return Double.NaN;
    }
    final double ret;
    final double absX = FastMath.abs(x);
    if (absX <= 20.0) {
        if (x >= 1.0) {
            /*
                 * From the recurrence relation
                 * Gamma(x) = (x - 1) * ... * (x - n) * Gamma(x - n),
                 * then
                 * Gamma(t) = 1 / [1 + invGamma1pm1(t - 1)],
                 * where t = x - n. This means that t must satisfy
                 * -0.5 <= t - 1 <= 1.5.
                 */
            double prod = 1.0;
            double t = x;
            while (t > 2.5) {
                t -= 1.0;
                prod *= t;
            }
            ret = prod / (1.0 + invGamma1pm1(t - 1.0));
        } else {
            /*
                 * From the recurrence relation
                 * Gamma(x) = Gamma(x + n + 1) / [x * (x + 1) * ... * (x + n)]
                 * then
                 * Gamma(x + n + 1) = 1 / [1 + invGamma1pm1(x + n)],
                 * which requires -0.5 <= x + n <= 1.5.
                 */
            double prod = x;
            double t = x;
            while (t < -0.5) {
                t += 1.0;
                prod *= t;
            }
            ret = 1.0 / (prod * (1.0 + invGamma1pm1(t)));
        }
    } else {
        final double y = absX + LANCZOS_G + 0.5;
        final double gammaAbs = SQRT_TWO_PI / x * FastMath.pow(y, absX + 0.5) * FastMath.exp(-y) * lanczos(absX);
        if (x > 0.0) {
            ret = gammaAbs;
        } else {
            /*
                 * From the reflection formula
                 * Gamma(x) * Gamma(1 - x) * sin(pi * x) = pi,
                 * and the recurrence relation
                 * Gamma(1 - x) = -x * Gamma(-x),
                 * it is found
                 * Gamma(x) = -pi / [x * sin(pi * x) * Gamma(-x)].
                 */
            ret = -FastMath.PI / (x * FastMath.sin(FastMath.PI * x) * gammaAbs);
        }
    }
    return ret;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1297_56434517,Major,src/main/java/org/apache/commons/math4/ode/MultistepIntegrator.java,215,262,"/**
 * Start the integration.
 * <p>This method computes one step using the underlying starter integrator,
 * and initializes the Nordsieck vector at step start. The starter integrator
 * purpose is only to establish initial conditions, it does not really change
 * time by itself. The top level multistep integrator remains in charge of
 * handling time propagation and events handling as it will starts its own
 * computation right from the beginning. In a sense, the starter integrator
 * can be seen as a dummy one and so it will never trigger any user event nor
 * call any user step handler.</p>
 * @param t0 initial time
 * @param y0 initial value of the state vector at t0
 * @param t target time for the integration
 * (can be set to a value smaller than <code>t0</code> for backward integration)
 * @exception DimensionMismatchException if arrays dimension do not match equations settings
 * @exception NumberIsTooSmallException if integration step is too small
 * @exception MaxCountExceededException if the number of functions evaluations is exceeded
 * @exception NoBracketingException if the location of an event cannot be bracketed
 */
protected void start(final double t0, final double[] y0, final double t) throws DimensionMismatchException, NumberIsTooSmallException, MaxCountExceededException, NoBracketingException {
    // make sure NO user event nor user step handler is triggered,
    // this is the task of the top level integrator, not the task
    // of the starter integrator
    starter.clearEventHandlers();
    starter.clearStepHandlers();
    // set up one specific step handler to extract initial Nordsieck vector
    starter.addStepHandler(new NordsieckInitializer((nSteps + 3) / 2, y0.length));
    // start integration, expecting a InitializationCompletedMarkerException
    try {
        if (starter instanceof AbstractIntegrator) {
            ((AbstractIntegrator) starter).integrate(getExpandable(), t);
        } else {
            starter.integrate(new FirstOrderDifferentialEquations() {

                /**
                 * {@inheritDoc}
                 */
                @Override
                public int getDimension() {
                    return getExpandable().getTotalDimension();
                }

                /**
                 * {@inheritDoc}
                 */
                @Override
                public void computeDerivatives(double t, double[] y, double[] yDot) {
                    getExpandable().computeDerivatives(t, y, yDot);
                }
            }, t0, y0, t, new double[y0.length]);
        }
    } catch (InitializationCompletedMarkerException icme) {
        // NOPMD
        // this is the expected nominal interruption of the start integrator
        // count the evaluations used by the starter
        getCounter().increment(starter.getEvaluations());
    }
    // remove the specific step handler
    starter.clearStepHandlers();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1300_1d635088,Major,src/main/java/org/apache/commons/math4/random/AbstractRandomGenerator.java,108,123,"/**
 * Generates random bytes and places them into a user-supplied
 * byte array.  The number of random bytes produced is equal to
 * the length of the byte array.
 * <p>
 * The default implementation fills the array with bytes extracted from
 * random integers generated using {@link #nextInt}.</p>
 *
 * @param bytes the non-null byte array in which to put the
 * random bytes
 */
@Override
public void nextBytes(byte[] bytes) {
    int bytesOut = 0;
    while (bytesOut < bytes.length) {
        int randInt = nextInt();
        for (int i = 0; i < 3; i++) {
            if (i > 0) {
                randInt >>= 8;
            }
            bytes[bytesOut++] = (byte) randInt;
            if (bytesOut == bytes.length) {
                return;
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-1300_1d635088,Major,src/main/java/org/apache/commons/math4/random/BitsStreamGenerator.java,73,90,"/**
 * {@inheritDoc}
 */
@Override
public void nextBytes(byte[] bytes) {
    int i = 0;
    final int iEnd = bytes.length - 3;
    while (i < iEnd) {
        final int random = next(32);
        bytes[i] = (byte) (random & 0xff);
        bytes[i + 1] = (byte) ((random >> 8) & 0xff);
        bytes[i + 2] = (byte) ((random >> 16) & 0xff);
        bytes[i + 3] = (byte) ((random >> 24) & 0xff);
        i += 4;
    }
    int random = next(32);
    while (i < bytes.length) {
        bytes[i++] = (byte) (random & 0xff);
        random >>= 8;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-286_dbdff075,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,272,282,"/**
 * Checks whether the given column is basic.
 * @param col index of the column to check
 * @return the row that the variable is basic in.  null if the column is not basic
 */
private Integer getBasicRow(final int col) {
    Integer row = null;
    for (int i = getNumObjectiveFunctions(); i < getHeight(); i++) {
        if (MathUtils.equals(getEntry(i, col), 1.0, epsilon) && (row == null)) {
            row = i;
        } else if (!MathUtils.equals(getEntry(i, col), 0.0, epsilon)) {
            return null;
        }
    }
    return row;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-286_dbdff075,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,320,340,"/**
 * Get the current solution.
 *
 * @return current solution
 */
protected RealPointValuePair getSolution() {
    double[] coefficients = new double[getOriginalNumDecisionVariables()];
    Integer basicRow = getBasicRow(getNumObjectiveFunctions() + getOriginalNumDecisionVariables());
    double mostNegative = basicRow == null ? 0 : getEntry(basicRow, getRhsOffset());
    Set<Integer> basicRows = new HashSet<Integer>();
    for (int i = 0; i < coefficients.length; i++) {
        basicRow = getBasicRow(getNumObjectiveFunctions() + i);
        if (basicRows.contains(basicRow)) {
            // if multiple variables can take a given value
            // then we choose the first and set the rest equal to 0
            coefficients[i] = 0;
        } else {
            basicRows.add(basicRow);
            coefficients[i] = (basicRow == null ? 0 : getEntry(basicRow, getRhsOffset())) - (restrictToNonNegative ? 0 : mostNegative);
        }
    }
    return new RealPointValuePair(coefficients, f.getValue(coefficients));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-288_38983e82,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexSolver.java,76,90,"/**
 * Returns the row with the minimum ratio as given by the minimum ratio test (MRT).
 * @param tableau simple tableau for the problem
 * @param col the column to test the ratio of.  See {@link #getPivotColumn(SimplexTableau)}
 * @return row with the minimum ratio
 */
private Integer getPivotRow(final int col, final SimplexTableau tableau) {
    double minRatio = Double.MAX_VALUE;
    Integer minRatioPos = null;
    for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getHeight(); i++) {
        double rhs = tableau.getEntry(i, tableau.getWidth() - 1);
        if (MathUtils.compareTo(tableau.getEntry(i, col), 0, epsilon) >= 0) {
            double ratio = rhs / tableau.getEntry(i, col);
            if (ratio < minRatio) {
                minRatio = ratio;
                minRatioPos = i;
            }
        }
    }
    return minRatioPos;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-290_b01fcc31,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,123,184,"/**
 * Create the tableau by itself.
 * @param maximize if true, goal is to maximize the objective function
 * @return created tableau
 */
protected double[][] createTableau(final boolean maximize) {
    // create a matrix of the correct size
    List<LinearConstraint> constraints = getNormalizedConstraints();
    int width = numDecisionVariables + numSlackVariables + numArtificialVariables + getNumObjectiveFunctions() + // + 1 is for RHS
    1;
    int height = constraints.size() + getNumObjectiveFunctions();
    double[][] matrix = new double[height][width];
    // initialize the objective function rows
    if (getNumObjectiveFunctions() == 2) {
        matrix[0][0] = -1;
    }
    int zIndex = (getNumObjectiveFunctions() == 1) ? 0 : 1;
    matrix[zIndex][zIndex] = maximize ? 1 : -1;
    RealVector objectiveCoefficients = maximize ? f.getCoefficients().mapMultiply(-1) : f.getCoefficients();
    copyArray(objectiveCoefficients.getData(), matrix[zIndex], getNumObjectiveFunctions());
    matrix[zIndex][width - 1] = maximize ? f.getConstantTerm() : -1 * f.getConstantTerm();
    if (!restrictToNonNegative) {
        matrix[zIndex][getSlackVariableOffset() - 1] = getInvertedCoeffiecientSum(objectiveCoefficients);
    }
    // initialize the constraint rows
    int slackVar = 0;
    int artificialVar = 0;
    for (int i = 0; i < constraints.size(); i++) {
        LinearConstraint constraint = constraints.get(i);
        int row = getNumObjectiveFunctions() + i;
        // decision variable coefficients
        copyArray(constraint.getCoefficients().getData(), matrix[row], 1);
        // x-
        if (!restrictToNonNegative) {
            matrix[row][getSlackVariableOffset() - 1] = getInvertedCoeffiecientSum(constraint.getCoefficients());
        }
        // RHS
        matrix[row][width - 1] = constraint.getValue();
        // slack variables
        if (constraint.getRelationship() == Relationship.LEQ) {
            // slack
            matrix[row][getSlackVariableOffset() + slackVar++] = 1;
        } else if (constraint.getRelationship() == Relationship.GEQ) {
            // excess
            matrix[row][getSlackVariableOffset() + slackVar++] = -1;
        }
        // artificial variables
        if ((constraint.getRelationship() == Relationship.EQ) || (constraint.getRelationship() == Relationship.GEQ)) {
            matrix[0][getArtificialVariableOffset() + artificialVar] = 1;
            matrix[row][getArtificialVariableOffset() + artificialVar++] = 1;
        }
    }
    return matrix;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-290_b01fcc31,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,197,203,"/**
 * Get new versions of the constraints which have positive right hand sides.
 * @return new versions of the constraints
 */
public List<LinearConstraint> getNormalizedConstraints() {
    List<LinearConstraint> normalized = new ArrayList<LinearConstraint>();
    for (LinearConstraint constraint : constraints) {
        normalized.add(normalize(constraint));
    }
    return normalized;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-293_59a0da9c,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,271,306,"/**
 * Removes the phase 1 objective function, positive cost non-artificial variables,
 * and the non-basic artificial variables from this tableau.
 */
protected void dropPhase1Objective() {
    if (getNumObjectiveFunctions() == 1) {
        return;
    }
    List<Integer> columnsToDrop = new ArrayList<Integer>();
    columnsToDrop.add(0);
    // positive cost non-artificial variables
    for (int i = getNumObjectiveFunctions(); i < getArtificialVariableOffset(); i++) {
        if (MathUtils.compareTo(tableau.getEntry(0, i), 0, epsilon) > 0) {
            columnsToDrop.add(i);
        }
    }
    // non-basic artificial variables
    for (int i = 0; i < getNumArtificialVariables(); i++) {
        int col = i + getArtificialVariableOffset();
        if (getBasicRow(col) == null) {
            columnsToDrop.add(col);
        }
    }
    double[][] matrix = new double[getHeight() - 1][getWidth() - columnsToDrop.size()];
    for (int i = 1; i < getHeight(); i++) {
        int col = 0;
        for (int j = 0; j < getWidth(); j++) {
            if (!columnsToDrop.contains(j)) {
                matrix[i - 1][col++] = tableau.getEntry(i, j);
            }
        }
    }
    this.tableau = new Array2DRowRealMatrix(matrix);
    this.numArtificialVariables = 0;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-293_59a0da9c,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,334,353,"/**
 * Get the current solution.
 *
 * @return current solution
 */
protected RealPointValuePair getSolution() {
    double[] coefficients = new double[getOriginalNumDecisionVariables()];
    Integer negativeVarBasicRow = getBasicRow(getNegativeDecisionVariableOffset());
    double mostNegative = negativeVarBasicRow == null ? 0 : getEntry(negativeVarBasicRow, getRhsOffset());
    Set<Integer> basicRows = new HashSet<Integer>();
    for (int i = 0; i < coefficients.length; i++) {
        Integer basicRow = getBasicRow(getNumObjectiveFunctions() + i);
        if (basicRows.contains(basicRow)) {
            // if multiple variables can take a given value
            // then we choose the first and set the rest equal to 0
            coefficients[i] = 0;
        } else {
            basicRows.add(basicRow);
            coefficients[i] = (basicRow == null ? 0 : getEntry(basicRow, getRhsOffset())) - (restrictToNonNegative ? 0 : mostNegative);
        }
    }
    return new RealPointValuePair(coefficients, f.getValue(coefficients));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-293_59a0da9c,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,450,452,"/**
 * Returns the offset of the extra decision variable added when there is a
 * negative decision variable in the original problem.
 * @return the offset of x-
 */
protected final int getNegativeDecisionVariableOffset() {
    return getNumObjectiveFunctions() + getOriginalNumDecisionVariables();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-293_59a0da9c,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,473,475,"/**
 * Get the original number of decision variables.
 * @return original number of decision variables
 * @see #getNumDecisionVariables()
 */
protected final int getOriginalNumDecisionVariables() {
    return restrictToNonNegative ? numDecisionVariables : numDecisionVariables - 1;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-294_2c8a114f,Major,src/main/java/org/apache/commons/math/random/RandomDataImpl.java,351,440,"/**
 * {@inheritDoc}
 * <p>
 * <strong>Algorithm Description</strong>: For small means, uses simulation
 * of a Poisson process using Uniform deviates, as described <a
 * href=""http://irmi.epfl.ch/cmos/Pmmi/interactive/rng7.htm""> here.</a>
 * </p>
 * <p>
 * The Poisson process (and hence value returned) is bounded by 1000 * mean.
 * </p>
 *
 * <p>
 * For large means, uses a reject method as described in <a
 * href=""http://cg.scs.carleton.ca/~luc/rnbookindex.html"">Non-Uniform Random
 * Variate Generation</a>
 * </p>
 *
 * <p>
 * References:
 * <ul>
 * <li>Devroye, Luc. (1986). <i>Non-Uniform Random Variate Generation</i>.
 * New York, NY. Springer-Verlag</li>
 * </ul>
 * </p>
 *
 * @param mean
 *            mean of the Poisson distribution.
 * @return the random Poisson value.
 */
public long nextPoisson(double mean) {
    if (mean <= 0) {
        throw MathRuntimeException.createIllegalArgumentException(""the Poisson mean must be positive ({0})"", mean);
    }
    final RandomGenerator generator = getRan();
    double pivot = 6.0;
    if (mean < pivot) {
        double p = Math.exp(-mean);
        long n = 0;
        double r = 1.0d;
        double rnd = 1.0d;
        while (n < 1000 * mean) {
            rnd = generator.nextDouble();
            r = r * rnd;
            if (r >= p) {
                n++;
            } else {
                return n;
            }
        }
        return n;
    } else {
        double mu = Math.floor(mean);
        // integer
        double delta = Math.floor(pivot + (mu - pivot) / 2.0);
        // between 6
        // and mean
        double mu2delta = 2.0 * mu + delta;
        double muDeltaHalf = mu + delta / 2.0;
        double logMeanMu = Math.log(mean / mu);
        double muFactorialLog = MathUtils.factorialLog((int) mu);
        double c1 = Math.sqrt(Math.PI * mu / 2.0);
        double c2 = c1 + Math.sqrt(Math.PI * muDeltaHalf / (2.0 * Math.exp(1.0 / mu2delta)));
        double c3 = c2 + 2.0;
        double c4 = c3 + Math.exp(1.0 / 78.0);
        double c = c4 + 2.0 / delta * mu2delta * Math.exp(-delta / mu2delta * (1.0 + delta / 2.0));
        double y = 0.0;
        double x = 0.0;
        double w = Double.POSITIVE_INFINITY;
        boolean accept = false;
        while (!accept) {
            double u = nextUniform(0.0, c);
            double e = nextExponential(mean);
            if (u <= c1) {
                double z = nextGaussian(0.0, 1.0);
                y = -Math.abs(z) * Math.sqrt(mu) - 1.0;
                x = Math.floor(y);
                w = -z * z / 2.0 - e - x * logMeanMu;
                if (x < -mu) {
                    w = Double.POSITIVE_INFINITY;
                }
            } else if (c1 < u && u <= c2) {
                double z = nextGaussian(0.0, 1.0);
                y = 1.0 + Math.abs(z) * Math.sqrt(muDeltaHalf);
                x = Math.ceil(y);
                w = (-y * y + 2.0 * y) / mu2delta - e - x * logMeanMu;
                if (x > delta) {
                    w = Double.POSITIVE_INFINITY;
                }
            } else if (c2 < u && u <= c3) {
                x = 0.0;
                w = -e;
            } else if (c3 < u && u <= c4) {
                x = 1.0;
                w = -e - logMeanMu;
            } else if (c4 < u) {
                double v = nextExponential(mean);
                y = delta + v * 2.0 / delta * mu2delta;
                x = Math.ceil(y);
                w = -delta / mu2delta * (1.0 + y / 2.0) - e - x * logMeanMu;
            }
            accept = w <= x * Math.log(mu) - MathUtils.factorialLog((int) (mu + x)) / muFactorialLog;
        }
        // numbers.
        return (long) (x + mu);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-305_ef9b639a,Major,src/main/java/org/apache/commons/math/util/MathUtils.java,1623,1630,"/**
 * Calculates the L<sub>2</sub> (Euclidean) distance between two points.
 *
 * @param p1 the first point
 * @param p2 the second point
 * @return the L<sub>2</sub> distance between the two points
 */
public static double distance(int[] p1, int[] p2) {
    int sum = 0;
    for (int i = 0; i < p1.length; i++) {
        final int dp = p1[i] - p2[i];
        sum += dp * dp;
    }
    return Math.sqrt(sum);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-309_0596e314,Minor,src/main/java/org/apache/commons/math/random/RandomDataImpl.java,464,475,"/**
 * Returns a random value from an Exponential distribution with the given
 * mean.
 * <p>
 * <strong>Algorithm Description</strong>: Uses the <a
 * href=""http://www.jesus.ox.ac.uk/~clifford/a5/chap1/node5.html""> Inversion
 * Method</a> to generate exponentially distributed random values from
 * uniform deviates.
 * </p>
 *
 * @param mean
 *            the mean of the distribution
 * @return the random Exponential value
 */
public double nextExponential(double mean) {
    if (mean < 0.0) {
        throw MathRuntimeException.createIllegalArgumentException(""mean must be positive ({0})"", mean);
    }
    final RandomGenerator generator = getRan();
    double unif = generator.nextDouble();
    while (unif == 0.0d) {
        unif = generator.nextDouble();
    }
    return -mean * Math.log(unif);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-318_83f18d52,Major,src/main/java/org/apache/commons/math/linear/EigenDecompositionImpl.java,1132,1147,"/**
 * Flip qd array if warranted.
 * @param n number of rows in the block
 * @param step within the array (1 for flipping all elements, 2 for flipping
 * only every other element)
 * @return true if qd array was flipped
 */
private boolean flipIfWarranted(final int n, final int step) {
    if (1.5 * work[pingPong] < work[4 * (n - 1) + pingPong]) {
        // flip array
        int j = 4 * n - 1;
        for (int i = 0; i < j; i += 4) {
            for (int k = 0; k < 4; k += step) {
                final double tmp = work[i + k];
                work[i + k] = work[j - k];
                work[j - k] = tmp;
            }
            j -= 4;
        }
        return true;
    }
    return false;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_b2f3f6db,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,153,200,"/**
 * {@inheritDoc}
 */
public RealMatrix getU() throws InvalidMatrixException {
    if (cachedU == null) {
        final int p = singularValues.length;
        if (m >= n) {
            // the tridiagonal matrix is Bt.B, where B is upper bidiagonal
            final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, p - 1, 0, p - 1);
            final double[][] eData = e.getData();
            final double[][] wData = new double[m][p];
            double[] ei1 = eData[0];
            for (int i = 0; i < p - 1; ++i) {
                // compute W = B.E.S^(-1) where E is the eigenvectors matrix
                final double mi = mainBidiagonal[i];
                final double si = secondaryBidiagonal[i];
                final double[] ei0 = ei1;
                final double[] wi = wData[i];
                ei1 = eData[i + 1];
                for (int j = 0; j < p; ++j) {
                    wi[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j];
                }
            }
            // last row
            final double lastMain = mainBidiagonal[p - 1];
            final double[] wr1 = wData[p - 1];
            for (int j = 0; j < p; ++j) {
                wr1[j] = ei1[j] * lastMain / singularValues[j];
            }
            for (int i = p; i < m; ++i) {
                wData[i] = new double[p];
            }
            cachedU = transformer.getU().multiply(MatrixUtils.createRealMatrix(wData));
        } else {
            // the tridiagonal matrix is B.Bt, where B is lower bidiagonal
            final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, m - 1, 0, p - 1);
            cachedU = transformer.getU().multiply(e);
        }
    }
    // return the cached matrix
    return cachedU;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_b2f3f6db,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,235,282,"/**
 * {@inheritDoc}
 */
public RealMatrix getV() throws InvalidMatrixException {
    if (cachedV == null) {
        final int p = singularValues.length;
        if (m >= n) {
            // the tridiagonal matrix is Bt.B, where B is upper bidiagonal
            final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, n - 1, 0, p - 1);
            cachedV = transformer.getV().multiply(e);
        } else {
            // the tridiagonal matrix is B.Bt, where B is lower bidiagonal
            // compute W = Bt.E.S^(-1) where E is the eigenvectors matrix
            final RealMatrix e = eigenDecomposition.getV().getSubMatrix(0, p - 1, 0, p - 1);
            final double[][] eData = e.getData();
            final double[][] wData = new double[n][p];
            double[] ei1 = eData[0];
            for (int i = 0; i < p - 1; ++i) {
                final double mi = mainBidiagonal[i];
                final double si = secondaryBidiagonal[i];
                final double[] ei0 = ei1;
                final double[] wi = wData[i];
                ei1 = eData[i + 1];
                for (int j = 0; j < p; ++j) {
                    wi[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j];
                }
            }
            // last row
            final double lastMain = mainBidiagonal[p - 1];
            final double[] wr1 = wData[p - 1];
            for (int j = 0; j < p; ++j) {
                wr1[j] = ei1[j] * lastMain / singularValues[j];
            }
            for (int i = p; i < n; ++i) {
                wData[i] = new double[p];
            }
            cachedV = transformer.getV().multiply(MatrixUtils.createRealMatrix(wData));
        }
    }
    // return the cached matrix
    return cachedV;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_c06cc933,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,125,168,"/**
 * {@inheritDoc}
 */
public RealMatrix getU() throws InvalidMatrixException {
    if (cachedU == null) {
        if (m >= n) {
            // the tridiagonal matrix is Bt.B, where B is upper bidiagonal
            final double[][] eData = eigenDecomposition.getV().getData();
            final double[][] iData = new double[m][];
            double[] ei1 = eData[0];
            iData[0] = ei1;
            for (int i = 0; i < n - 1; ++i) {
                // compute B.E.S^(-1) where E is the eigenvectors matrix
                // we reuse the array from matrix E to store the result
                final double mi = mainBidiagonal[i];
                final double si = secondaryBidiagonal[i];
                final double[] ei0 = ei1;
                ei1 = eData[i + 1];
                iData[i + 1] = ei1;
                for (int j = 0; j < n; ++j) {
                    ei0[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j];
                }
            }
            // last row
            final double lastMain = mainBidiagonal[n - 1];
            for (int j = 0; j < n; ++j) {
                ei1[j] *= lastMain / singularValues[j];
            }
            for (int i = n; i < m; ++i) {
                iData[i] = new double[n];
            }
            cachedU = transformer.getU().multiply(MatrixUtils.createRealMatrix(iData));
        } else {
            // the tridiagonal matrix is B.Bt, where B is lower bidiagonal
            cachedU = transformer.getU().multiply(eigenDecomposition.getV());
        }
    }
    // return the cached matrix
    return cachedU;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_c06cc933,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,203,246,"/**
 * {@inheritDoc}
 */
public RealMatrix getV() throws InvalidMatrixException {
    if (cachedV == null) {
        if (m >= n) {
            // the tridiagonal matrix is Bt.B, where B is upper bidiagonal
            cachedV = transformer.getV().multiply(eigenDecomposition.getV());
        } else {
            // the tridiagonal matrix is B.Bt, where B is lower bidiagonal
            final double[][] eData = eigenDecomposition.getV().getData();
            final double[][] iData = new double[n][];
            double[] ei1 = eData[0];
            iData[0] = ei1;
            for (int i = 0; i < m - 1; ++i) {
                // compute Bt.E.S^(-1) where E is the eigenvectors matrix
                // we reuse the array from matrix E to store the result
                final double mi = mainBidiagonal[i];
                final double si = secondaryBidiagonal[i];
                final double[] ei0 = ei1;
                ei1 = eData[i + 1];
                iData[i + 1] = ei1;
                for (int j = 0; j < m; ++j) {
                    ei0[j] = (mi * ei0[j] + si * ei1[j]) / singularValues[j];
                }
            }
            // last row
            final double lastMain = mainBidiagonal[m - 1];
            for (int j = 0; j < m; ++j) {
                ei1[j] *= lastMain / singularValues[j];
            }
            for (int i = m; i < n; ++i) {
                iData[i] = new double[m];
            }
            cachedV = transformer.getV().multiply(MatrixUtils.createRealMatrix(iData));
        }
    }
    // return the cached matrix
    return cachedV;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_c06cc933,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,262,288,"/**
 * {@inheritDoc}
 */
public RealMatrix getCovariance(final double minSingularValue) {
    // get the number of singular values to consider
    int dimension = 0;
    while ((dimension < n) && (singularValues[dimension] >= minSingularValue)) {
        ++dimension;
    }
    if (dimension == 0) {
        throw MathRuntimeException.createIllegalArgumentException(""cutoff singular value is {0}, should be at most {1}"", minSingularValue, singularValues[0]);
    }
    final double[][] data = new double[dimension][n];
    getVT().walkInOptimizedOrder(new DefaultRealMatrixPreservingVisitor() {

        /**
         * {@inheritDoc}
         */
        @Override
        public void visit(final int row, final int column, final double value) {
            data[row][column] = value / singularValues[row];
        }
    }, 0, dimension - 1, 0, n - 1);
    RealMatrix jv = new Array2DRowRealMatrix(data, false);
    return jv.transpose().multiply(jv);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_c06cc933,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,318,321,"/**
 * {@inheritDoc}
 */
public DecompositionSolver getSolver() {
    return new Solver(singularValues, getUT(), getV(), getRank() == singularValues.length);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_c06cc933,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,361,380,"/**
 * Solve the linear equation A &times; X = B in least square sense.
 * <p>The m&times;n matrix A may not be square, the solution X is
 * such that ||A &times; X - B|| is minimal.</p>
 * @param b right-hand side of the equation A &times; X = B
 * @return a vector X that minimizes the two norm of A &times; X - B
 * @exception IllegalArgumentException if matrices dimensions don't match
 * @exception InvalidMatrixException if decomposed matrix is singular
 */
public double[] solve(final double[] b) throws IllegalArgumentException, InvalidMatrixException {
    if (b.length != uT.getColumnDimension()) {
        throw MathRuntimeException.createIllegalArgumentException(""vector length mismatch: got {0} but expected {1}"", b.length, uT.getColumnDimension());
    }
    final double[] w = uT.operate(b);
    for (int i = 0; i < singularValues.length; ++i) {
        final double si = singularValues[i];
        if (si == 0) {
            throw new SingularMatrixException();
        }
        w[i] /= si;
    }
    return v.operate(w);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_c06cc933,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,390,409,"/**
 * Solve the linear equation A &times; X = B in least square sense.
 * <p>The m&times;n matrix A may not be square, the solution X is
 * such that ||A &times; X - B|| is minimal.</p>
 * @param b right-hand side of the equation A &times; X = B
 * @return a vector X that minimizes the two norm of A &times; X - B
 * @exception IllegalArgumentException if matrices dimensions don't match
 * @exception InvalidMatrixException if decomposed matrix is singular
 */
public RealVector solve(final RealVector b) throws IllegalArgumentException, InvalidMatrixException {
    if (b.getDimension() != uT.getColumnDimension()) {
        throw MathRuntimeException.createIllegalArgumentException(""vector length mismatch: got {0} but expected {1}"", b.getDimension(), uT.getColumnDimension());
    }
    final RealVector w = uT.operate(b);
    for (int i = 0; i < singularValues.length; ++i) {
        final double si = singularValues[i];
        if (si == 0) {
            throw new SingularMatrixException();
        }
        w.setEntry(i, w.getEntry(i) / si);
    }
    return v.operate(w);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_c06cc933,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,419,442,"/**
 * Solve the linear equation A &times; X = B in least square sense.
 * <p>The m&times;n matrix A may not be square, the solution X is
 * such that ||A &times; X - B|| is minimal.</p>
 * @param b right-hand side of the equation A &times; X = B
 * @return a matrix X that minimizes the two norm of A &times; X - B
 * @exception IllegalArgumentException if matrices dimensions don't match
 * @exception InvalidMatrixException if decomposed matrix is singular
 */
public RealMatrix solve(final RealMatrix b) throws IllegalArgumentException, InvalidMatrixException {
    if (b.getRowDimension() != singularValues.length) {
        throw MathRuntimeException.createIllegalArgumentException(""dimensions mismatch: got {0}x{1} but expected {2}x{3}"", b.getRowDimension(), b.getColumnDimension(), singularValues.length, ""n"");
    }
    final RealMatrix w = uT.multiply(b);
    for (int i = 0; i < singularValues.length; ++i) {
        final double si = singularValues[i];
        if (si == 0) {
            throw new SingularMatrixException();
        }
        final double inv = 1.0 / si;
        for (int j = 0; j < b.getColumnDimension(); ++j) {
            w.multiplyEntry(i, j, inv);
        }
    }
    return v.multiply(w);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-320_c06cc933,Major,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,456,465,"/**
 * Get the pseudo-inverse of the decomposed matrix.
 * @return inverse matrix
 * @throws InvalidMatrixException if decomposed matrix is singular
 */
public RealMatrix getInverse() throws InvalidMatrixException {
    if (!isNonSingular()) {
        throw new SingularMatrixException();
    }
    return solve(MatrixUtils.createRealIdentityMatrix(singularValues.length));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-326_ce185345,Major,src/main/java/org/apache/commons/math/linear/ArrayRealVector.java,697,703,"/**
 * {@inheritDoc}
 */
public double getNorm() {
    double sum = 0;
    for (double a : data) {
        sum += a * a;
    }
    return Math.sqrt(sum);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-326_ce185345,Major,src/main/java/org/apache/commons/math/linear/ArrayRealVector.java,706,712,"/**
 * {@inheritDoc}
 */
public double getL1Norm() {
    double sum = 0;
    for (double a : data) {
        sum += Math.abs(a);
    }
    return sum;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-326_ce185345,Major,src/main/java/org/apache/commons/math/linear/ArrayRealVector.java,715,721,"/**
 * {@inheritDoc}
 */
public double getLInfNorm() {
    double max = 0;
    for (double a : data) {
        max += Math.max(max, Math.abs(a));
    }
    return max;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-326_ce185345,Major,src/main/java/org/apache/commons/math/linear/OpenMapRealVector.java,499,507,"/**
 * {@inheritDoc}
 */
public double getL1Norm() {
    double res = 0;
    Iterator iter = entries.iterator();
    while (iter.hasNext()) {
        iter.advance();
        res += Math.abs(iter.value());
    }
    return res;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-326_ce185345,Major,src/main/java/org/apache/commons/math/linear/OpenMapRealVector.java,560,568,"/**
 * {@inheritDoc}
 */
public double getLInfNorm() {
    double max = 0;
    Iterator iter = entries.iterator();
    while (iter.hasNext()) {
        iter.advance();
        max += iter.value();
    }
    return max;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-326_ce185345,Major,src/main/java/org/apache/commons/math/linear/OpenMapRealVector.java,571,579,"/**
 * {@inheritDoc}
 */
public double getNorm() {
    double res = 0;
    Iterator iter = entries.iterator();
    while (iter.hasNext()) {
        iter.advance();
        res += iter.value() * iter.value();
    }
    return Math.sqrt(res);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-327_262fe4c0,Critical,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,219,221,"/**
 * {@inheritDoc}
 */
public double getConditionNumber() {
    return singularValues[0] / singularValues[singularValues.length - 1];
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-327_262fe4c0,Critical,src/main/java/org/apache/commons/math/linear/SingularValueDecompositionImpl.java,224,233,"/**
 * {@inheritDoc}
 */
public int getRank() {
    final double threshold = FastMath.max(m, n) * FastMath.ulp(singularValues[0]);
    for (int i = singularValues.length - 1; i >= 0; --i) {
        if (singularValues[i] > threshold) {
            return i + 1;
        }
    }
    return 0;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-329_6dd3724b,Minor,src/main/java/org/apache/commons/math/stat/Frequency.java,301,304,"// -------------------------------------------------------------
/**
 * Returns the percentage of values that are equal to v
 * (as a proportion between 0 and 1).
 * <p>
 * Returns <code>Double.NaN</code> if no values have been added.</p>
 *
 * @param v the value to lookup
 * @return the proportion of values equal to v
 * @deprecated replaced by {@link #getPct(Comparable)} as of 2.0
 */
@Deprecated
public double getPct(Object v) {
    return getCumPct((Comparable<?>) v);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-338_8dd22390,Major,src/main/java/org/apache/commons/math/ode/nonstiff/EmbeddedRungeKuttaIntegrator.java,193,361,"/**
 * {@inheritDoc}
 */
@Override
public double integrate(final FirstOrderDifferentialEquations equations, final double t0, final double[] y0, final double t, final double[] y) throws DerivativeException, IntegratorException {
    sanityChecks(equations, t0, y0, t, y);
    setEquations(equations);
    resetEvaluations();
    final boolean forward = t > t0;
    // create some internal working arrays
    final int stages = c.length + 1;
    if (y != y0) {
        System.arraycopy(y0, 0, y, 0, y0.length);
    }
    final double[][] yDotK = new double[stages][y0.length];
    final double[] yTmp = new double[y0.length];
    // set up an interpolator sharing the integrator arrays
    AbstractStepInterpolator interpolator;
    if (requiresDenseOutput() || (!eventsHandlersManager.isEmpty())) {
        final RungeKuttaStepInterpolator rki = (RungeKuttaStepInterpolator) prototype.copy();
        rki.reinitialize(this, yTmp, yDotK, forward);
        interpolator = rki;
    } else {
        interpolator = new DummyStepInterpolator(yTmp, forward);
    }
    interpolator.storeTime(t0);
    // set up integration control objects
    stepStart = t0;
    double hNew = 0;
    boolean firstTime = true;
    for (StepHandler handler : stepHandlers) {
        handler.reset();
    }
    CombinedEventsManager manager = addEndTimeChecker(t0, t, eventsHandlersManager);
    boolean lastStep = false;
    // main integration loop
    while (!lastStep) {
        interpolator.shift();
        double error = 0;
        for (boolean loop = true; loop; ) {
            if (firstTime || !fsal) {
                // first stage
                computeDerivatives(stepStart, y, yDotK[0]);
            }
            if (firstTime) {
                final double[] scale;
                if (vecAbsoluteTolerance != null) {
                    scale = vecAbsoluteTolerance;
                } else {
                    scale = new double[y0.length];
                    Arrays.fill(scale, scalAbsoluteTolerance);
                }
                hNew = initializeStep(equations, forward, getOrder(), scale, stepStart, y, yDotK[0], yTmp, yDotK[1]);
                firstTime = false;
            }
            stepSize = hNew;
            // next stages
            for (int k = 1; k < stages; ++k) {
                for (int j = 0; j < y0.length; ++j) {
                    double sum = a[k - 1][0] * yDotK[0][j];
                    for (int l = 1; l < k; ++l) {
                        sum += a[k - 1][l] * yDotK[l][j];
                    }
                    yTmp[j] = y[j] + stepSize * sum;
                }
                computeDerivatives(stepStart + c[k - 1] * stepSize, yTmp, yDotK[k]);
            }
            // estimate the state at the end of the step
            for (int j = 0; j < y0.length; ++j) {
                double sum = b[0] * yDotK[0][j];
                for (int l = 1; l < stages; ++l) {
                    sum += b[l] * yDotK[l][j];
                }
                yTmp[j] = y[j] + stepSize * sum;
            }
            // estimate the error at the end of the step
            error = estimateError(yDotK, y, yTmp, stepSize);
            if (error <= 1.0) {
                // discrete events handling
                interpolator.storeTime(stepStart + stepSize);
                if (manager.evaluateStep(interpolator)) {
                    final double dt = manager.getEventTime() - stepStart;
                    if (Math.abs(dt) <= Math.ulp(stepStart)) {
                        // rejecting the step would lead to a too small next step, we accept it
                        loop = false;
                    } else {
                        // reject the step to match exactly the next switch time
                        hNew = dt;
                    }
                } else {
                    // accept the step
                    loop = false;
                }
            } else {
                // reject the step and attempt to reduce error by stepsize control
                final double factor = Math.min(maxGrowth, Math.max(minReduction, safety * Math.pow(error, exp)));
                hNew = filterStep(stepSize * factor, forward, false);
            }
        }
        // the step has been accepted
        final double nextStep = stepStart + stepSize;
        System.arraycopy(yTmp, 0, y, 0, y0.length);
        manager.stepAccepted(nextStep, y);
        lastStep = manager.stop();
        // provide the step data to the step handler
        interpolator.storeTime(nextStep);
        for (StepHandler handler : stepHandlers) {
            handler.handleStep(interpolator, lastStep);
        }
        stepStart = nextStep;
        if (fsal) {
            // save the last evaluation for the next step
            System.arraycopy(yDotK[stages - 1], 0, yDotK[0], 0, y0.length);
        }
        if (manager.reset(stepStart, y) && !lastStep) {
            // some event handler has triggered changes that
            // invalidate the derivatives, we need to recompute them
            computeDerivatives(stepStart, y, yDotK[0]);
        }
        if (!lastStep) {
            // in some rare cases we may get here with stepSize = 0, for example
            // when an event occurs at integration start, reducing the first step
            // to zero; we have to reset the step to some safe non zero value
            stepSize = filterStep(stepSize, forward, true);
            // stepsize control for next step
            final double factor = Math.min(maxGrowth, Math.max(minReduction, safety * Math.pow(error, exp)));
            final double scaledH = stepSize * factor;
            final double nextT = stepStart + scaledH;
            final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t);
            hNew = filterStep(scaledH, forward, nextIsLast);
        }
    }
    final double stopTime = stepStart;
    resetInternalState();
    return stopTime;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-343_f6dd42b4,Critical,src/main/java/org/apache/commons/math/analysis/solvers/BrentSolver.java,93,134,"/**
 * Find a zero in the given interval with an initial guess.
 * <p>Throws <code>IllegalArgumentException</code> if the values of the
 * function at the three points have the same sign (note that it is
 * allowed to have endpoints with the same sign if the initial point has
 * opposite sign function-wise).</p>
 *
 * @param f function to solve.
 * @param min the lower bound for the interval.
 * @param max the upper bound for the interval.
 * @param initial the start value to use (must be set to min if no
 * initial point is known).
 * @return the value where the function is zero
 * @throws MaxIterationsExceededException the maximum iteration count
 * is exceeded
 * @throws FunctionEvaluationException if an error occurs evaluating
 *  the function
 * @throws IllegalArgumentException if initial is not between min and max
 * (even if it <em>is</em> a root)
 */
public double solve(final UnivariateRealFunction f, final double min, final double max, final double initial) throws MaxIterationsExceededException, FunctionEvaluationException {
    clearResult();
    verifySequence(min, initial, max);
    // return the initial guess if it is good enough
    double yInitial = f.value(initial);
    if (Math.abs(yInitial) <= functionValueAccuracy) {
        setResult(initial, 0);
        return result;
    }
    // return the first endpoint if it is good enough
    double yMin = f.value(min);
    if (Math.abs(yMin) <= functionValueAccuracy) {
        setResult(yMin, 0);
        return result;
    }
    // reduce interval if min and initial bracket the root
    if (yInitial * yMin < 0) {
        return solve(f, min, yMin, initial, yInitial, min, yMin);
    }
    // return the second endpoint if it is good enough
    double yMax = f.value(max);
    if (Math.abs(yMax) <= functionValueAccuracy) {
        setResult(yMax, 0);
        return result;
    }
    // reduce interval if initial and max bracket the root
    if (yInitial * yMax < 0) {
        return solve(f, initial, yInitial, max, yMax, initial, yInitial);
    }
    // full Brent algorithm starting with provided initial guess
    return solve(f, min, yMin, max, yMax, initial, yInitial);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-343_f6dd42b4,Critical,src/main/java/org/apache/commons/math/analysis/solvers/BrentSolver.java,153,196,"/**
 * Find a zero in the given interval.
 * <p>
 * Requires that the values of the function at the endpoints have opposite
 * signs. An <code>IllegalArgumentException</code> is thrown if this is not
 * the case.</p>
 *
 * @param f the function to solve
 * @param min the lower bound for the interval.
 * @param max the upper bound for the interval.
 * @return the value where the function is zero
 * @throws MaxIterationsExceededException if the maximum iteration count is exceeded
 * @throws FunctionEvaluationException if an error occurs evaluating the
 * function
 * @throws IllegalArgumentException if min is not less than max or the
 * signs of the values of the function at the endpoints are not opposites
 */
public double solve(final UnivariateRealFunction f, final double min, final double max) throws MaxIterationsExceededException, FunctionEvaluationException {
    clearResult();
    verifyInterval(min, max);
    double ret = Double.NaN;
    double yMin = f.value(min);
    double yMax = f.value(max);
    // Verify bracketing
    double sign = yMin * yMax;
    if (sign > 0) {
        // check if either value is close to a zero
        if (Math.abs(yMin) <= functionValueAccuracy) {
            setResult(min, 0);
            ret = min;
        } else if (Math.abs(yMax) <= functionValueAccuracy) {
            setResult(max, 0);
            ret = max;
        } else {
            // neither value is close to zero and min and max do not bracket root.
            throw MathRuntimeException.createIllegalArgumentException(""function values at endpoints do not have different signs.  "" + ""Endpoints: [{0}, {1}], Values: [{2}, {3}]"", min, max, yMin, yMax);
        }
    } else if (sign < 0) {
        // solve using only the first endpoint as initial guess
        ret = solve(f, min, yMin, max, yMax, min, yMin);
    } else {
        // either min or max is a root
        if (yMin == 0.0) {
            ret = min;
        } else {
            ret = max;
        }
    }
    return ret;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-344_a0b4b4b7,Critical,src/main/java/org/apache/commons/math/analysis/solvers/BrentSolver.java,98,144,"/**
 * Find a zero in the given interval with an initial guess.
 * <p>Throws <code>IllegalArgumentException</code> if the values of the
 * function at the three points have the same sign (note that it is
 * allowed to have endpoints with the same sign if the initial point has
 * opposite sign function-wise).</p>
 *
 * @param f function to solve.
 * @param min the lower bound for the interval.
 * @param max the upper bound for the interval.
 * @param initial the start value to use (must be set to min if no
 * initial point is known).
 * @return the value where the function is zero
 * @throws MaxIterationsExceededException the maximum iteration count
 * is exceeded
 * @throws FunctionEvaluationException if an error occurs evaluating
 *  the function
 * @throws IllegalArgumentException if initial is not between min and max
 * (even if it <em>is</em> a root)
 */
public double solve(final UnivariateRealFunction f, final double min, final double max, final double initial) throws MaxIterationsExceededException, FunctionEvaluationException {
    clearResult();
    verifySequence(min, initial, max);
    // return the initial guess if it is good enough
    double yInitial = f.value(initial);
    if (Math.abs(yInitial) <= functionValueAccuracy) {
        setResult(initial, 0);
        return result;
    }
    // return the first endpoint if it is good enough
    double yMin = f.value(min);
    if (Math.abs(yMin) <= functionValueAccuracy) {
        setResult(yMin, 0);
        return result;
    }
    // reduce interval if min and initial bracket the root
    if (yInitial * yMin < 0) {
        return solve(f, min, yMin, initial, yInitial, min, yMin);
    }
    // return the second endpoint if it is good enough
    double yMax = f.value(max);
    if (Math.abs(yMax) <= functionValueAccuracy) {
        setResult(yMax, 0);
        return result;
    }
    // reduce interval if initial and max bracket the root
    if (yInitial * yMax < 0) {
        return solve(f, initial, yInitial, max, yMax, initial, yInitial);
    }
    if (yMin * yMax > 0) {
        throw MathRuntimeException.createIllegalArgumentException(NON_BRACKETING_MESSAGE, min, max, yMin, yMax);
    }
    // full Brent algorithm starting with provided initial guess
    return solve(f, min, yMin, max, yMax, initial, yInitial);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-349_4cc9a49d,Minor,src/main/java/org/apache/commons/math/distribution/PoissonDistribution.java,52,53,"/**
 * Set the mean for the distribution.
 * The parameter value must be positive; otherwise an
 * <code>IllegalArgument</code> is thrown.
 *
 * @param p the mean
 * @throws IllegalArgumentException if p &le; 0
 * @deprecated as of v2.1
 */
@Deprecated
void setMean(double p);"
commons-math,remotes/origin/bugs-dot-jar_MATH-349_4cc9a49d,Minor,src/main/java/org/apache/commons/math/distribution/PoissonDistributionImpl.java,157,160,"/**
 * Set the Poisson mean for the distribution. The mean value must be
 * positive; otherwise an <code>IllegalArgument</code> is thrown.
 *
 * @param p the Poisson mean value
 * @throws IllegalArgumentException if p &le; 0
 * @deprecated as of 2.1 (class will become immutable in 3.0)
 */
@Deprecated
public void setMean(double p) {
    setNormalAndMeanInternal(normal, p);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-349_4cc9a49d,Minor,src/main/java/org/apache/commons/math/distribution/PoissonDistributionImpl.java,169,179,"/**
 * Set the Poisson mean for the distribution. The mean value must be
 * positive; otherwise an <code>IllegalArgument</code> is thrown.
 *
 * @param z the new distribution
 * @param p the Poisson mean value
 * @throws IllegalArgumentException if p &le; 0
 */
private void setNormalAndMeanInternal(NormalDistribution z, double p) {
    if (p <= 0) {
        throw MathRuntimeException.createIllegalArgumentException(LocalizedFormats.NOT_POSITIVE_POISSON_MEAN, p);
    }
    mean = p;
    normal = z;
    normal.setMean(p);
    normal.setStandardDeviation(FastMath.sqrt(p));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-349_4cc9a49d,Minor,src/main/java/org/apache/commons/math/distribution/PoissonDistributionImpl.java,299,302,"/**
 * Modify the normal distribution used to compute normal approximations. The
 * caller is responsible for insuring the normal distribution has the proper
 * parameter settings.
 *
 * @param value the new distribution
 * @since 1.2
 * @deprecated as of 2.1 (class will become immutable in 3.0)
 */
@Deprecated
public void setNormal(NormalDistribution value) {
    setNormalAndMeanInternal(value, mean);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-358_061f5017,Critical,src/main/java/org/apache/commons/math/ode/nonstiff/AdamsBashforthIntegrator.java,184,343,"/**
 * {@inheritDoc}
 */
@Override
public double integrate(final FirstOrderDifferentialEquations equations, final double t0, final double[] y0, final double t, final double[] y) throws DerivativeException, IntegratorException {
    final int n = y0.length;
    sanityChecks(equations, t0, y0, t, y);
    setEquations(equations);
    resetEvaluations();
    final boolean forward = t > t0;
    // initialize working arrays
    if (y != y0) {
        System.arraycopy(y0, 0, y, 0, n);
    }
    final double[] yDot = new double[n];
    final double[] yTmp = new double[y0.length];
    // set up an interpolator sharing the integrator arrays
    final NordsieckStepInterpolator interpolator = new NordsieckStepInterpolator();
    interpolator.reinitialize(y, forward);
    final NordsieckStepInterpolator interpolatorTmp = new NordsieckStepInterpolator();
    interpolatorTmp.reinitialize(yTmp, forward);
    // set up integration control objects
    for (StepHandler handler : stepHandlers) {
        handler.reset();
    }
    CombinedEventsManager manager = addEndTimeChecker(t0, t, eventsHandlersManager);
    // compute the initial Nordsieck vector using the configured starter integrator
    start(t0, y, t);
    interpolator.reinitialize(stepStart, stepSize, scaled, nordsieck);
    interpolator.storeTime(stepStart);
    final int lastRow = nordsieck.getRowDimension() - 1;
    // reuse the step that was chosen by the starter integrator
    double hNew = stepSize;
    interpolator.rescale(hNew);
    boolean lastStep = false;
    while (!lastStep) {
        // shift all data
        interpolator.shift();
        double error = 0;
        for (boolean loop = true; loop; ) {
            stepSize = hNew;
            // evaluate error using the last term of the Taylor expansion
            error = 0;
            for (int i = 0; i < y0.length; ++i) {
                final double yScale = Math.abs(y[i]);
                final double tol = (vecAbsoluteTolerance == null) ? (scalAbsoluteTolerance + scalRelativeTolerance * yScale) : (vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * yScale);
                final double ratio = nordsieck.getEntry(lastRow, i) / tol;
                error += ratio * ratio;
            }
            error = Math.sqrt(error / y0.length);
            if (error <= 1.0) {
                // predict a first estimate of the state at step end
                final double stepEnd = stepStart + stepSize;
                interpolator.setInterpolatedTime(stepEnd);
                System.arraycopy(interpolator.getInterpolatedState(), 0, yTmp, 0, y0.length);
                // evaluate the derivative
                computeDerivatives(stepEnd, yTmp, yDot);
                // update Nordsieck vector
                final double[] predictedScaled = new double[y0.length];
                for (int j = 0; j < y0.length; ++j) {
                    predictedScaled[j] = stepSize * yDot[j];
                }
                final Array2DRowRealMatrix nordsieckTmp = updateHighOrderDerivativesPhase1(nordsieck);
                updateHighOrderDerivativesPhase2(scaled, predictedScaled, nordsieckTmp);
                // discrete events handling
                interpolatorTmp.reinitialize(stepEnd, stepSize, predictedScaled, nordsieckTmp);
                interpolatorTmp.storeTime(stepStart);
                interpolatorTmp.shift();
                interpolatorTmp.storeTime(stepEnd);
                if (manager.evaluateStep(interpolatorTmp)) {
                    final double dt = manager.getEventTime() - stepStart;
                    if (Math.abs(dt) <= Math.ulp(stepStart)) {
                        // rejecting the step would lead to a too small next step, we accept it
                        loop = false;
                    } else {
                        // reject the step to match exactly the next switch time
                        hNew = dt;
                        interpolator.rescale(hNew);
                    }
                } else {
                    // accept the step
                    scaled = predictedScaled;
                    nordsieck = nordsieckTmp;
                    interpolator.reinitialize(stepEnd, stepSize, scaled, nordsieck);
                    loop = false;
                }
            } else {
                // reject the step and attempt to reduce error by stepsize control
                final double factor = computeStepGrowShrinkFactor(error);
                hNew = filterStep(stepSize * factor, forward, false);
                interpolator.rescale(hNew);
            }
        }
        // the step has been accepted (may have been truncated)
        final double nextStep = stepStart + stepSize;
        System.arraycopy(yTmp, 0, y, 0, n);
        interpolator.storeTime(nextStep);
        manager.stepAccepted(nextStep, y);
        lastStep = manager.stop();
        // provide the step data to the step handler
        for (StepHandler handler : stepHandlers) {
            interpolator.setInterpolatedTime(nextStep);
            handler.handleStep(interpolator, lastStep);
        }
        stepStart = nextStep;
        if (!lastStep && manager.reset(stepStart, y)) {
            // some events handler has triggered changes that
            // invalidate the derivatives, we need to restart from scratch
            start(stepStart, y, t);
            interpolator.reinitialize(stepStart, stepSize, scaled, nordsieck);
        }
        if (!lastStep) {
            // in some rare cases we may get here with stepSize = 0, for example
            // when an event occurs at integration start, reducing the first step
            // to zero; we have to reset the step to some safe non zero value
            stepSize = filterStep(stepSize, forward, true);
            // stepsize control for next step
            final double factor = computeStepGrowShrinkFactor(error);
            final double scaledH = stepSize * factor;
            final double nextT = stepStart + scaledH;
            final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t);
            hNew = filterStep(scaledH, forward, nextIsLast);
            interpolator.rescale(hNew);
        }
    }
    final double stopTime = stepStart;
    stepStart = Double.NaN;
    stepSize = Double.NaN;
    return stopTime;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-358_061f5017,Critical,src/main/java/org/apache/commons/math/ode/nonstiff/AdamsMoultonIntegrator.java,202,361,"/**
 * {@inheritDoc}
 */
@Override
public double integrate(final FirstOrderDifferentialEquations equations, final double t0, final double[] y0, final double t, final double[] y) throws DerivativeException, IntegratorException {
    final int n = y0.length;
    sanityChecks(equations, t0, y0, t, y);
    setEquations(equations);
    resetEvaluations();
    final boolean forward = t > t0;
    // initialize working arrays
    if (y != y0) {
        System.arraycopy(y0, 0, y, 0, n);
    }
    final double[] yDot = new double[y0.length];
    final double[] yTmp = new double[y0.length];
    // set up two interpolators sharing the integrator arrays
    final NordsieckStepInterpolator interpolator = new NordsieckStepInterpolator();
    interpolator.reinitialize(y, forward);
    final NordsieckStepInterpolator interpolatorTmp = new NordsieckStepInterpolator();
    interpolatorTmp.reinitialize(yTmp, forward);
    // set up integration control objects
    for (StepHandler handler : stepHandlers) {
        handler.reset();
    }
    CombinedEventsManager manager = addEndTimeChecker(t0, t, eventsHandlersManager);
    // compute the initial Nordsieck vector using the configured starter integrator
    start(t0, y, t);
    interpolator.reinitialize(stepStart, stepSize, scaled, nordsieck);
    interpolator.storeTime(stepStart);
    double hNew = stepSize;
    interpolator.rescale(hNew);
    boolean lastStep = false;
    while (!lastStep) {
        // shift all data
        interpolator.shift();
        double error = 0;
        for (boolean loop = true; loop; ) {
            stepSize = hNew;
            // predict a first estimate of the state at step end (P in the PECE sequence)
            final double stepEnd = stepStart + stepSize;
            interpolator.setInterpolatedTime(stepEnd);
            System.arraycopy(interpolator.getInterpolatedState(), 0, yTmp, 0, y0.length);
            // evaluate a first estimate of the derivative (first E in the PECE sequence)
            computeDerivatives(stepEnd, yTmp, yDot);
            // update Nordsieck vector
            final double[] predictedScaled = new double[y0.length];
            for (int j = 0; j < y0.length; ++j) {
                predictedScaled[j] = stepSize * yDot[j];
            }
            final Array2DRowRealMatrix nordsieckTmp = updateHighOrderDerivativesPhase1(nordsieck);
            updateHighOrderDerivativesPhase2(scaled, predictedScaled, nordsieckTmp);
            // apply correction (C in the PECE sequence)
            error = nordsieckTmp.walkInOptimizedOrder(new Corrector(y, predictedScaled, yTmp));
            if (error <= 1.0) {
                // evaluate a final estimate of the derivative (second E in the PECE sequence)
                computeDerivatives(stepEnd, yTmp, yDot);
                // update Nordsieck vector
                final double[] correctedScaled = new double[y0.length];
                for (int j = 0; j < y0.length; ++j) {
                    correctedScaled[j] = stepSize * yDot[j];
                }
                updateHighOrderDerivativesPhase2(predictedScaled, correctedScaled, nordsieckTmp);
                // discrete events handling
                interpolatorTmp.reinitialize(stepEnd, stepSize, correctedScaled, nordsieckTmp);
                interpolatorTmp.storeTime(stepStart);
                interpolatorTmp.shift();
                interpolatorTmp.storeTime(stepEnd);
                if (manager.evaluateStep(interpolatorTmp)) {
                    final double dt = manager.getEventTime() - stepStart;
                    if (Math.abs(dt) <= Math.ulp(stepStart)) {
                        // rejecting the step would lead to a too small next step, we accept it
                        loop = false;
                    } else {
                        // reject the step to match exactly the next switch time
                        hNew = dt;
                        interpolator.rescale(hNew);
                    }
                } else {
                    // accept the step
                    scaled = correctedScaled;
                    nordsieck = nordsieckTmp;
                    interpolator.reinitialize(stepEnd, stepSize, scaled, nordsieck);
                    loop = false;
                }
            } else {
                // reject the step and attempt to reduce error by stepsize control
                final double factor = computeStepGrowShrinkFactor(error);
                hNew = filterStep(stepSize * factor, forward, false);
                interpolator.rescale(hNew);
            }
        }
        // the step has been accepted (may have been truncated)
        final double nextStep = stepStart + stepSize;
        System.arraycopy(yTmp, 0, y, 0, n);
        interpolator.storeTime(nextStep);
        manager.stepAccepted(nextStep, y);
        lastStep = manager.stop();
        // provide the step data to the step handler
        for (StepHandler handler : stepHandlers) {
            interpolator.setInterpolatedTime(nextStep);
            handler.handleStep(interpolator, lastStep);
        }
        stepStart = nextStep;
        if (!lastStep && manager.reset(stepStart, y)) {
            // some events handler has triggered changes that
            // invalidate the derivatives, we need to restart from scratch
            start(stepStart, y, t);
            interpolator.reinitialize(stepStart, stepSize, scaled, nordsieck);
        }
        if (!lastStep) {
            // in some rare cases we may get here with stepSize = 0, for example
            // when an event occurs at integration start, reducing the first step
            // to zero; we have to reset the step to some safe non zero value
            stepSize = filterStep(stepSize, forward, true);
            // stepsize control for next step
            final double factor = computeStepGrowShrinkFactor(error);
            final double scaledH = stepSize * factor;
            final double nextT = stepStart + scaledH;
            final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t);
            hNew = filterStep(scaledH, forward, nextIsLast);
            interpolator.rescale(hNew);
        }
    }
    final double stopTime = stepStart;
    stepStart = Double.NaN;
    stepSize = Double.NaN;
    return stopTime;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-358_061f5017,Critical,src/main/java/org/apache/commons/math/ode/nonstiff/EmbeddedRungeKuttaIntegrator.java,191,362,"/**
 * {@inheritDoc}
 */
@Override
public double integrate(final FirstOrderDifferentialEquations equations, final double t0, final double[] y0, final double t, final double[] y) throws DerivativeException, IntegratorException {
    sanityChecks(equations, t0, y0, t, y);
    setEquations(equations);
    resetEvaluations();
    final boolean forward = t > t0;
    // create some internal working arrays
    final int stages = c.length + 1;
    if (y != y0) {
        System.arraycopy(y0, 0, y, 0, y0.length);
    }
    final double[][] yDotK = new double[stages][y0.length];
    final double[] yTmp = new double[y0.length];
    // set up an interpolator sharing the integrator arrays
    AbstractStepInterpolator interpolator;
    if (requiresDenseOutput() || (!eventsHandlersManager.isEmpty())) {
        final RungeKuttaStepInterpolator rki = (RungeKuttaStepInterpolator) prototype.copy();
        rki.reinitialize(this, yTmp, yDotK, forward);
        interpolator = rki;
    } else {
        interpolator = new DummyStepInterpolator(yTmp, yDotK[stages - 1], forward);
    }
    interpolator.storeTime(t0);
    // set up integration control objects
    stepStart = t0;
    double hNew = 0;
    boolean firstTime = true;
    for (StepHandler handler : stepHandlers) {
        handler.reset();
    }
    CombinedEventsManager manager = addEndTimeChecker(t0, t, eventsHandlersManager);
    boolean lastStep = false;
    // main integration loop
    while (!lastStep) {
        interpolator.shift();
        double error = 0;
        for (boolean loop = true; loop; ) {
            if (firstTime || !fsal) {
                // first stage
                computeDerivatives(stepStart, y, yDotK[0]);
            }
            if (firstTime) {
                final double[] scale = new double[y0.length];
                if (vecAbsoluteTolerance == null) {
                    for (int i = 0; i < scale.length; ++i) {
                        scale[i] = scalAbsoluteTolerance + scalRelativeTolerance * Math.abs(y[i]);
                    }
                } else {
                    for (int i = 0; i < scale.length; ++i) {
                        scale[i] = vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * Math.abs(y[i]);
                    }
                }
                hNew = initializeStep(equations, forward, getOrder(), scale, stepStart, y, yDotK[0], yTmp, yDotK[1]);
                firstTime = false;
            }
            stepSize = hNew;
            // next stages
            for (int k = 1; k < stages; ++k) {
                for (int j = 0; j < y0.length; ++j) {
                    double sum = a[k - 1][0] * yDotK[0][j];
                    for (int l = 1; l < k; ++l) {
                        sum += a[k - 1][l] * yDotK[l][j];
                    }
                    yTmp[j] = y[j] + stepSize * sum;
                }
                computeDerivatives(stepStart + c[k - 1] * stepSize, yTmp, yDotK[k]);
            }
            // estimate the state at the end of the step
            for (int j = 0; j < y0.length; ++j) {
                double sum = b[0] * yDotK[0][j];
                for (int l = 1; l < stages; ++l) {
                    sum += b[l] * yDotK[l][j];
                }
                yTmp[j] = y[j] + stepSize * sum;
            }
            // estimate the error at the end of the step
            error = estimateError(yDotK, y, yTmp, stepSize);
            if (error <= 1.0) {
                // discrete events handling
                interpolator.storeTime(stepStart + stepSize);
                if (manager.evaluateStep(interpolator)) {
                    final double dt = manager.getEventTime() - stepStart;
                    if (Math.abs(dt) <= Math.ulp(stepStart)) {
                        // rejecting the step would lead to a too small next step, we accept it
                        loop = false;
                    } else {
                        // reject the step to match exactly the next switch time
                        hNew = dt;
                    }
                } else {
                    // accept the step
                    loop = false;
                }
            } else {
                // reject the step and attempt to reduce error by stepsize control
                final double factor = Math.min(maxGrowth, Math.max(minReduction, safety * Math.pow(error, exp)));
                hNew = filterStep(stepSize * factor, forward, false);
            }
        }
        // the step has been accepted
        final double nextStep = stepStart + stepSize;
        System.arraycopy(yTmp, 0, y, 0, y0.length);
        manager.stepAccepted(nextStep, y);
        lastStep = manager.stop();
        // provide the step data to the step handler
        interpolator.storeTime(nextStep);
        for (StepHandler handler : stepHandlers) {
            handler.handleStep(interpolator, lastStep);
        }
        stepStart = nextStep;
        if (fsal) {
            // save the last evaluation for the next step
            System.arraycopy(yDotK[stages - 1], 0, yDotK[0], 0, y0.length);
        }
        if (manager.reset(stepStart, y) && !lastStep) {
            // some event handler has triggered changes that
            // invalidate the derivatives, we need to recompute them
            computeDerivatives(stepStart, y, yDotK[0]);
        }
        if (!lastStep) {
            // in some rare cases we may get here with stepSize = 0, for example
            // when an event occurs at integration start, reducing the first step
            // to zero; we have to reset the step to some safe non zero value
            stepSize = filterStep(stepSize, forward, true);
            // stepsize control for next step
            final double factor = Math.min(maxGrowth, Math.max(minReduction, safety * Math.pow(error, exp)));
            final double scaledH = stepSize * factor;
            final double nextT = stepStart + scaledH;
            final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t);
            hNew = filterStep(scaledH, forward, nextIsLast);
        }
    }
    final double stopTime = stepStart;
    resetInternalState();
    return stopTime;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-358_061f5017,Critical,src/main/java/org/apache/commons/math/ode/nonstiff/RungeKuttaIntegrator.java,95,216,"/**
 * {@inheritDoc}
 */
public double integrate(final FirstOrderDifferentialEquations equations, final double t0, final double[] y0, final double t, final double[] y) throws DerivativeException, IntegratorException {
    sanityChecks(equations, t0, y0, t, y);
    setEquations(equations);
    resetEvaluations();
    final boolean forward = t > t0;
    // create some internal working arrays
    final int stages = c.length + 1;
    if (y != y0) {
        System.arraycopy(y0, 0, y, 0, y0.length);
    }
    final double[][] yDotK = new double[stages][];
    for (int i = 0; i < stages; ++i) {
        yDotK[i] = new double[y0.length];
    }
    final double[] yTmp = new double[y0.length];
    // set up an interpolator sharing the integrator arrays
    AbstractStepInterpolator interpolator;
    if (requiresDenseOutput() || (!eventsHandlersManager.isEmpty())) {
        final RungeKuttaStepInterpolator rki = (RungeKuttaStepInterpolator) prototype.copy();
        rki.reinitialize(this, yTmp, yDotK, forward);
        interpolator = rki;
    } else {
        interpolator = new DummyStepInterpolator(yTmp, yDotK[stages - 1], forward);
    }
    interpolator.storeTime(t0);
    // set up integration control objects
    stepStart = t0;
    stepSize = forward ? step : -step;
    for (StepHandler handler : stepHandlers) {
        handler.reset();
    }
    CombinedEventsManager manager = addEndTimeChecker(t0, t, eventsHandlersManager);
    boolean lastStep = false;
    // main integration loop
    while (!lastStep) {
        interpolator.shift();
        for (boolean loop = true; loop; ) {
            // first stage
            computeDerivatives(stepStart, y, yDotK[0]);
            // next stages
            for (int k = 1; k < stages; ++k) {
                for (int j = 0; j < y0.length; ++j) {
                    double sum = a[k - 1][0] * yDotK[0][j];
                    for (int l = 1; l < k; ++l) {
                        sum += a[k - 1][l] * yDotK[l][j];
                    }
                    yTmp[j] = y[j] + stepSize * sum;
                }
                computeDerivatives(stepStart + c[k - 1] * stepSize, yTmp, yDotK[k]);
            }
            // estimate the state at the end of the step
            for (int j = 0; j < y0.length; ++j) {
                double sum = b[0] * yDotK[0][j];
                for (int l = 1; l < stages; ++l) {
                    sum += b[l] * yDotK[l][j];
                }
                yTmp[j] = y[j] + stepSize * sum;
            }
            // discrete events handling
            interpolator.storeTime(stepStart + stepSize);
            if (manager.evaluateStep(interpolator)) {
                final double dt = manager.getEventTime() - stepStart;
                if (Math.abs(dt) <= Math.ulp(stepStart)) {
                    // rejecting the step would lead to a too small next step, we accept it
                    loop = false;
                } else {
                    // reject the step to match exactly the next switch time
                    stepSize = dt;
                }
            } else {
                loop = false;
            }
        }
        // the step has been accepted
        final double nextStep = stepStart + stepSize;
        System.arraycopy(yTmp, 0, y, 0, y0.length);
        manager.stepAccepted(nextStep, y);
        lastStep = manager.stop();
        // provide the step data to the step handler
        interpolator.storeTime(nextStep);
        for (StepHandler handler : stepHandlers) {
            handler.handleStep(interpolator, lastStep);
        }
        stepStart = nextStep;
        if (manager.reset(stepStart, y) && !lastStep) {
            // some events handler has triggered changes that
            // invalidate the derivatives, we need to recompute them
            computeDerivatives(stepStart, y, yDotK[0]);
        }
        // make sure step size is set to default before next step
        stepSize = forward ? step : -step;
    }
    final double stopTime = stepStart;
    stepStart = Double.NaN;
    stepSize = Double.NaN;
    return stopTime;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-367_3a15d8ce,Minor,src/main/java/org/apache/commons/math/linear/AbstractRealVector.java,908,918,"/**
 * Advance an entry up to the next non null one.
 * @param e entry to advance
 */
protected void advance(EntryImpl e) {
    if (e == null) {
        return;
    }
    do {
        e.setIndex(e.getIndex() + 1);
    } while (e.getIndex() < dim && e.getValue() == 0);
    if (e.getIndex() >= dim) {
        e.setIndex(-1);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-367_3a15d8ce,Minor,src/main/java/org/apache/commons/math/linear/AbstractRealVector.java,921,923,"/**
 * {@inheritDoc}
 */
public boolean hasNext() {
    return current != null;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-367_3a15d8ce,Minor,src/main/java/org/apache/commons/math/linear/AbstractRealVector.java,926,938,"/**
 * {@inheritDoc}
 */
public Entry next() {
    tmp.setIndex(current.getIndex());
    if (next != null) {
        current.setIndex(next.getIndex());
        advance(next);
        if (next.getIndex() < 0) {
            next = null;
        }
    } else {
        current = null;
    }
    return tmp;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-369_f4a4464b,Minor,src/main/java/org/apache/commons/math/analysis/solvers/BisectionSolver.java,70,73,"/**
 * {@inheritDoc}
 */
public double solve(final UnivariateRealFunction f, double min, double max, double initial) throws MaxIterationsExceededException, FunctionEvaluationException {
    return solve(min, max);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-370_495f04bc,Minor,src/main/java/org/apache/commons/math/util/MathUtils.java,422,424,"/**
 * Returns true iff they are equal as defined by
 * {@link #equals(double,double,int) this method}.
 *
 * @param x first value
 * @param y second value
 * @return {@code true} if the values are equal.
 * @deprecated This method considers that {@code NaN == NaN}. In release
 * 3.0, the semantics will change in order to comply with IEEE754 where it
 * is specified that {@code NaN != NaN}.
 * New methods have been added for those cases wher the old semantics is
 * useful (see e.g. {@link #equalsIncludingNaN(double,double)
 * equalsIncludingNaN}.
 */
public static boolean equals(double x, double y) {
    return (Double.isNaN(x) && Double.isNaN(y)) || x == y;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-370_495f04bc,Minor,src/main/java/org/apache/commons/math/util/MathUtils.java,534,547,"/**
 * Returns true iff both arguments are null or have same dimensions and all
 * their elements are equal as defined by
 * {@link #equals(double,double) this method}.
 *
 * @param x first array
 * @param y second array
 * @return true if the values are both null or have same dimension
 * and equal elements.
 * @deprecated This method considers that {@code NaN == NaN}. In release
 * 3.0, the semantics will change in order to comply with IEEE754 where it
 * is specified that {@code NaN != NaN}.
 * New methods have been added for those cases wher the old semantics is
 * useful (see e.g. {@link #equalsIncludingNaN(double[],double[])
 * equalsIncludingNaN}.
 */
public static boolean equals(double[] x, double[] y) {
    if ((x == null) || (y == null)) {
        return !((x == null) ^ (y == null));
    }
    if (x.length != y.length) {
        return false;
    }
    for (int i = 0; i < x.length; ++i) {
        if (!equals(x[i], y[i])) {
            return false;
        }
    }
    return true;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-370_495f04bc,Minor,src/main/java/org/apache/commons/math/util/MathUtils.java,1122,1125,"/**
 * Get the next machine representable number after a number, moving
 * in the direction of another number.
 * <p>
 * If <code>direction</code> is greater than or equal to<code>d</code>,
 * the smallest machine representable number strictly greater than
 * <code>d</code> is returned; otherwise the largest representable number
 * strictly less than <code>d</code> is returned.</p>
 * <p>
 * If <code>d</code> is NaN or Infinite, it is returned unchanged.</p>
 *
 * @param d base number
 * @param direction (the only important thing is whether
 * direction is greater or smaller than d)
 * @return the next machine representable number in the specified direction
 * @since 1.2
 * @deprecated as of 2.2, replaced by {@link FastMath#nextAfter(double, double)}
 */
@Deprecated
public static double nextAfter(double d, double direction) {
    return FastMath.nextAfter(d, direction);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-370_495f04bc,Minor,src/main/java/org/apache/commons/math/util/MathUtils.java,1316,1395,"/**
 * Round the given non-negative, value to the ""nearest"" integer. Nearest is
 * determined by the rounding method specified. Rounding methods are defined
 * in {@link BigDecimal}.
 *
 * @param unscaled the value to round.
 * @param sign the sign of the original, scaled value.
 * @param roundingMethod the rounding method as defined in
 *        {@link BigDecimal}.
 * @return the rounded value.
 * @since 1.1
 */
private static double roundUnscaled(double unscaled, double sign, int roundingMethod) {
    switch(roundingMethod) {
        case BigDecimal.ROUND_CEILING:
            if (sign == -1) {
                unscaled = FastMath.floor(nextAfter(unscaled, Double.NEGATIVE_INFINITY));
            } else {
                unscaled = FastMath.ceil(nextAfter(unscaled, Double.POSITIVE_INFINITY));
            }
            break;
        case BigDecimal.ROUND_DOWN:
            unscaled = FastMath.floor(nextAfter(unscaled, Double.NEGATIVE_INFINITY));
            break;
        case BigDecimal.ROUND_FLOOR:
            if (sign == -1) {
                unscaled = FastMath.ceil(nextAfter(unscaled, Double.POSITIVE_INFINITY));
            } else {
                unscaled = FastMath.floor(nextAfter(unscaled, Double.NEGATIVE_INFINITY));
            }
            break;
        case BigDecimal.ROUND_HALF_DOWN:
            {
                unscaled = nextAfter(unscaled, Double.NEGATIVE_INFINITY);
                double fraction = unscaled - FastMath.floor(unscaled);
                if (fraction > 0.5) {
                    unscaled = FastMath.ceil(unscaled);
                } else {
                    unscaled = FastMath.floor(unscaled);
                }
                break;
            }
        case BigDecimal.ROUND_HALF_EVEN:
            {
                double fraction = unscaled - FastMath.floor(unscaled);
                if (fraction > 0.5) {
                    unscaled = FastMath.ceil(unscaled);
                } else if (fraction < 0.5) {
                    unscaled = FastMath.floor(unscaled);
                } else {
                    // The following equality test is intentional and needed for rounding purposes
                    if (FastMath.floor(unscaled) / 2.0 == FastMath.floor(Math.floor(unscaled) / 2.0)) {
                        // even
                        unscaled = FastMath.floor(unscaled);
                    } else {
                        // odd
                        unscaled = FastMath.ceil(unscaled);
                    }
                }
                break;
            }
        case BigDecimal.ROUND_HALF_UP:
            {
                unscaled = nextAfter(unscaled, Double.POSITIVE_INFINITY);
                double fraction = unscaled - FastMath.floor(unscaled);
                if (fraction >= 0.5) {
                    unscaled = FastMath.ceil(unscaled);
                } else {
                    unscaled = FastMath.floor(unscaled);
                }
                break;
            }
        case BigDecimal.ROUND_UNNECESSARY:
            if (unscaled != FastMath.floor(unscaled)) {
                throw new ArithmeticException(""Inexact result from rounding"");
            }
            break;
        case BigDecimal.ROUND_UP:
            unscaled = FastMath.ceil(nextAfter(unscaled, Double.POSITIVE_INFINITY));
            break;
        default:
            throw MathRuntimeException.createIllegalArgumentException(LocalizedFormats.INVALID_ROUNDING_METHOD, roundingMethod, ""ROUND_CEILING"", BigDecimal.ROUND_CEILING, ""ROUND_DOWN"", BigDecimal.ROUND_DOWN, ""ROUND_FLOOR"", BigDecimal.ROUND_FLOOR, ""ROUND_HALF_DOWN"", BigDecimal.ROUND_HALF_DOWN, ""ROUND_HALF_EVEN"", BigDecimal.ROUND_HALF_EVEN, ""ROUND_HALF_UP"", BigDecimal.ROUND_HALF_UP, ""ROUND_UNNECESSARY"", BigDecimal.ROUND_UNNECESSARY, ""ROUND_UP"", BigDecimal.ROUND_UP);
    }
    return unscaled;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-370_495f04bc,Minor,src/main/java/org/apache/commons/math/util/MathUtils.java,1917,1923,"/**
 * Checks that the given array is sorted.
 *
 * @param val Values
 * @param dir Order direction (-1 for decreasing, 1 for increasing)
 * @param strict Whether the order should be strict
 * @throws NonMonotonousSequenceException if the array is not sorted.
 * @deprecated as of 2.2 (please use the new {@link #checkOrder(double[],OrderDirection,boolean)
 * checkOrder} method). To be removed in 3.0.
 */
public static void checkOrder(double[] val, int dir, boolean strict) {
    if (dir > 0) {
        checkOrder(val, OrderDirection.INCREASING, strict);
    } else {
        checkOrder(val, OrderDirection.DECREASING, strict);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-371_bb005b56,Major,src/main/java/org/apache/commons/math/stat/correlation/PearsonsCorrelation.java,160,176,"/**
 * Returns a matrix of p-values associated with the (two-sided) null
 * hypothesis that the corresponding correlation coefficient is zero.
 * <p><code>getCorrelationPValues().getEntry(i,j)</code> is the probability
 * that a random variable distributed as <code>t<sub>n-2</sub></code> takes
 * a value with absolute value greater than or equal to <br>
 * <code>|r|((n - 2) / (1 - r<sup>2</sup>))<sup>1/2</sup></code></p>
 * <p>The values in the matrix are sometimes referred to as the
 * <i>significance</i> of the corresponding correlation coefficients.</p>
 *
 * @return matrix of p-values
 * @throws MathException if an error occurs estimating probabilities
 */
public RealMatrix getCorrelationPValues() throws MathException {
    TDistribution tDistribution = new TDistributionImpl(nObs - 2);
    int nVars = correlationMatrix.getColumnDimension();
    double[][] out = new double[nVars][nVars];
    for (int i = 0; i < nVars; i++) {
        for (int j = 0; j < nVars; j++) {
            if (i == j) {
                out[i][j] = 0d;
            } else {
                double r = correlationMatrix.getEntry(i, j);
                double t = Math.abs(r * Math.sqrt((nObs - 2) / (1 - r * r)));
                out[i][j] = 2 * (1 - tDistribution.cumulativeProbability(t));
            }
        }
    }
    return new BlockRealMatrix(out);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/Product.java,72,80,"/**
 * {@inheritDoc}
 */
@Override
public void increment(final double d) {
    if (n == 0) {
        value = d;
    } else {
        value *= d;
    }
    n++;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/Product.java,100,104,"/**
 * {@inheritDoc}
 */
@Override
public void clear() {
    value = Double.NaN;
    n = 0;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/Product.java,120,130,"/**
 * Returns the product of the entries in the specified portion of
 * the input array, or <code>Double.NaN</code> if the designated subarray
 * is empty.
 * <p>
 * Throws <code>IllegalArgumentException</code> if the array is null.</p>
 *
 * @param values the input array
 * @param begin index of the first array element to include
 * @param length the number of elements to include
 * @return the product of the values or Double.NaN if length = 0
 * @throws IllegalArgumentException if the array is null or the array index
 *  parameters are not valid
 */
@Override
public double evaluate(final double[] values, final int begin, final int length) {
    double product = Double.NaN;
    if (test(values, begin, length)) {
        product = 1.0;
        for (int i = begin; i < begin + length; i++) {
            product *= values[i];
        }
    }
    return product;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/Product.java,160,170,"/**
 * <p>Returns the weighted product of the entries in the specified portion of
 * the input array, or <code>Double.NaN</code> if the designated subarray
 * is empty.</p>
 *
 * <p>Throws <code>IllegalArgumentException</code> if any of the following are true:
 * <ul><li>the values array is null</li>
 *     <li>the weights array is null</li>
 *     <li>the weights array does not have the same length as the values array</li>
 *     <li>the weights array contains one or more infinite values</li>
 *     <li>the weights array contains one or more NaN values</li>
 *     <li>the weights array contains negative values</li>
 *     <li>the start and length arguments do not determine a valid array</li>
 * </ul></p>
 *
 * <p>Uses the formula, <pre>
 *    weighted product = &prod;values[i]<sup>weights[i]</sup>
 * </pre>
 * that is, the weights are applied as exponents when computing the weighted product.</p>
 *
 * @param values the input array
 * @param weights the weights array
 * @param begin index of the first array element to include
 * @param length the number of elements to include
 * @return the product of the values or Double.NaN if length = 0
 * @throws IllegalArgumentException if the parameters are not valid
 * @since 2.1
 */
public double evaluate(final double[] values, final double[] weights, final int begin, final int length) {
    double product = Double.NaN;
    if (test(values, weights, begin, length)) {
        product = 1.0;
        for (int i = begin; i < begin + length; i++) {
            product *= FastMath.pow(values[i], weights[i]);
        }
    }
    return product;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/Sum.java,71,79,"/**
 * {@inheritDoc}
 */
@Override
public void increment(final double d) {
    if (n == 0) {
        value = d;
    } else {
        value += d;
    }
    n++;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/Sum.java,99,103,"/**
 * {@inheritDoc}
 */
@Override
public void clear() {
    value = Double.NaN;
    n = 0;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/Sum.java,119,129,"/**
 * The sum of the entries in the specified portion of
 * the input array, or <code>Double.NaN</code> if the designated subarray
 * is empty.
 * <p>
 * Throws <code>IllegalArgumentException</code> if the array is null.</p>
 *
 * @param values the input array
 * @param begin index of the first array element to include
 * @param length the number of elements to include
 * @return the sum of the values or Double.NaN if length = 0
 * @throws IllegalArgumentException if the array is null or the array index
 *  parameters are not valid
 */
@Override
public double evaluate(final double[] values, final int begin, final int length) {
    double sum = Double.NaN;
    if (test(values, begin, length)) {
        sum = 0.0;
        for (int i = begin; i < begin + length; i++) {
            sum += values[i];
        }
    }
    return sum;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/Sum.java,158,168,"/**
 * The weighted sum of the entries in the specified portion of
 * the input array, or <code>Double.NaN</code> if the designated subarray
 * is empty.
 * <p>
 * Throws <code>IllegalArgumentException</code> if any of the following are true:
 * <ul><li>the values array is null</li>
 *     <li>the weights array is null</li>
 *     <li>the weights array does not have the same length as the values array</li>
 *     <li>the weights array contains one or more infinite values</li>
 *     <li>the weights array contains one or more NaN values</li>
 *     <li>the weights array contains negative values</li>
 *     <li>the start and length arguments do not determine a valid array</li>
 * </ul></p>
 * <p>
 * Uses the formula, <pre>
 *    weighted sum = &Sigma;(values[i] * weights[i])
 * </pre></p>
 *
 * @param values the input array
 * @param weights the weights array
 * @param begin index of the first array element to include
 * @param length the number of elements to include
 * @return the sum of the values or Double.NaN if length = 0
 * @throws IllegalArgumentException if the parameters are not valid
 * @since 2.1
 */
public double evaluate(final double[] values, final double[] weights, final int begin, final int length) {
    double sum = Double.NaN;
    if (test(values, weights, begin, length)) {
        sum = 0.0;
        for (int i = begin; i < begin + length; i++) {
            sum += values[i] * weights[i];
        }
    }
    return sum;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/SumOfLogs.java,88,95,"/**
 * {@inheritDoc}
 */
@Override
public double getResult() {
    if (n > 0) {
        return value;
    } else {
        return Double.NaN;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/SumOfLogs.java,130,140,"/**
 * Returns the sum of the natural logs of the entries in the specified portion of
 * the input array, or <code>Double.NaN</code> if the designated subarray
 * is empty.
 * <p>
 * Throws <code>IllegalArgumentException</code> if the array is null.</p>
 * <p>
 * See {@link SumOfLogs}.</p>
 *
 * @param values the input array
 * @param begin index of the first array element to include
 * @param length the number of elements to include
 * @return the sum of the natural logs of the values or Double.NaN if
 * length = 0
 * @throws IllegalArgumentException if the array is null or the array index
 *  parameters are not valid
 */
@Override
public double evaluate(final double[] values, final int begin, final int length) {
    double sumLog = Double.NaN;
    if (test(values, begin, length)) {
        sumLog = 0.0;
        for (int i = begin; i < begin + length; i++) {
            sumLog += FastMath.log(values[i]);
        }
    }
    return sumLog;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/SumOfSquares.java,70,78,"/**
 * {@inheritDoc}
 */
@Override
public void increment(final double d) {
    if (n == 0) {
        value = d * d;
    } else {
        value += d * d;
    }
    n++;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/SumOfSquares.java,98,102,"/**
 * {@inheritDoc}
 */
@Override
public void clear() {
    value = Double.NaN;
    n = 0;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-373_bfe4623c,Major,src/main/java/org/apache/commons/math/stat/descriptive/summary/SumOfSquares.java,118,128,"/**
 * Returns the sum of the squares of the entries in the specified portion of
 * the input array, or <code>Double.NaN</code> if the designated subarray
 * is empty.
 * <p>
 * Throws <code>IllegalArgumentException</code> if the array is null.</p>
 *
 * @param values the input array
 * @param begin index of the first array element to include
 * @param length the number of elements to include
 * @return the sum of the squares of the values or Double.NaN if length = 0
 * @throws IllegalArgumentException if the array is null or the array index
 *  parameters are not valid
 */
@Override
public double evaluate(final double[] values, final int begin, final int length) {
    double sumSq = Double.NaN;
    if (test(values, begin, length)) {
        sumSq = 0.0;
        for (int i = begin; i < begin + length; i++) {
            sumSq += values[i] * values[i];
        }
    }
    return sumSq;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-377_c640932d,Major,src/main/java/org/apache/commons/math/linear/EigenDecompositionImpl.java,470,617,"/**
 * Find eigenvalues and eigenvectors (Dubrulle et al., 1971)
 * @param householderMatrix Householder matrix of the transformation
 *  to tri-diagonal form.
 */
private void findEigenVectors(double[][] householderMatrix) {
    double[][] z = householderMatrix.clone();
    final int n = main.length;
    realEigenvalues = new double[n];
    imagEigenvalues = new double[n];
    double[] e = new double[n];
    for (int i = 0; i < n - 1; i++) {
        realEigenvalues[i] = main[i];
        e[i] = secondary[i];
    }
    realEigenvalues[n - 1] = main[n - 1];
    e[n - 1] = 0.0;
    // Determine the largest main and secondary value in absolute term.
    double maxAbsoluteValue = 0.0;
    for (int i = 0; i < n; i++) {
        if (Math.abs(realEigenvalues[i]) > maxAbsoluteValue) {
            maxAbsoluteValue = Math.abs(realEigenvalues[i]);
        }
        if (Math.abs(e[i]) > maxAbsoluteValue) {
            maxAbsoluteValue = Math.abs(e[i]);
        }
    }
    // Make null any main and secondary value too small to be significant
    if (maxAbsoluteValue != 0.0) {
        for (int i = 0; i < n; i++) {
            if (Math.abs(realEigenvalues[i]) <= MathUtils.EPSILON * maxAbsoluteValue) {
                realEigenvalues[i] = 0.0;
            }
            if (Math.abs(e[i]) <= MathUtils.EPSILON * maxAbsoluteValue) {
                e[i] = 0.0;
            }
        }
    }
    for (int j = 0; j < n; j++) {
        int its = 0;
        int m;
        do {
            for (m = j; m < n - 1; m++) {
                double delta = Math.abs(realEigenvalues[m]) + Math.abs(realEigenvalues[m + 1]);
                if (Math.abs(e[m]) + delta == delta) {
                    break;
                }
            }
            if (m != j) {
                if (its == maxIter)
                    throw new InvalidMatrixException(new MaxIterationsExceededException(maxIter));
                its++;
                double q = (realEigenvalues[j + 1] - realEigenvalues[j]) / (2 * e[j]);
                double t = Math.sqrt(1 + q * q);
                if (q < 0.0) {
                    q = realEigenvalues[m] - realEigenvalues[j] + e[j] / (q - t);
                } else {
                    q = realEigenvalues[m] - realEigenvalues[j] + e[j] / (q + t);
                }
                double u = 0.0;
                double s = 1.0;
                double c = 1.0;
                int i;
                for (i = m - 1; i >= j; i--) {
                    double p = s * e[i];
                    double h = c * e[i];
                    if (Math.abs(p) >= Math.abs(q)) {
                        c = q / p;
                        t = Math.sqrt(c * c + 1.0);
                        e[i + 1] = p * t;
                        s = 1.0 / t;
                        c = c * s;
                    } else {
                        s = p / q;
                        t = Math.sqrt(s * s + 1.0);
                        e[i + 1] = q * t;
                        c = 1.0 / t;
                        s = s * c;
                    }
                    if (e[i + 1] == 0.0) {
                        realEigenvalues[i + 1] -= u;
                        e[m] = 0.0;
                        break;
                    }
                    q = realEigenvalues[i + 1] - u;
                    t = (realEigenvalues[i] - q) * s + 2.0 * c * h;
                    u = s * t;
                    realEigenvalues[i + 1] = q + u;
                    q = c * t - h;
                    for (int ia = 0; ia < n; ia++) {
                        p = z[ia][i + 1];
                        z[ia][i + 1] = s * z[ia][i] + c * p;
                        z[ia][i] = c * z[ia][i] - s * p;
                    }
                }
                if (e[i + 1] == 0.0 && i >= j)
                    continue;
                realEigenvalues[j] -= u;
                e[j] = q;
                e[m] = 0.0;
            }
        } while (m != j);
    }
    // Sort the eigen values (and vectors) in increase order
    for (int i = 0; i < n; i++) {
        int k = i;
        double p = realEigenvalues[i];
        for (int j = i + 1; j < n; j++) {
            if (realEigenvalues[j] > p) {
                k = j;
                p = realEigenvalues[j];
            }
        }
        if (k != i) {
            realEigenvalues[k] = realEigenvalues[i];
            realEigenvalues[i] = p;
            for (int j = 0; j < n; j++) {
                p = z[j][i];
                z[j][i] = z[j][k];
                z[j][k] = p;
            }
        }
    }
    // Determine the largest eigen value in absolute term.
    maxAbsoluteValue = 0.0;
    for (int i = 0; i < n; i++) {
        if (Math.abs(realEigenvalues[i]) > maxAbsoluteValue) {
            maxAbsoluteValue = Math.abs(realEigenvalues[i]);
        }
    }
    // Make null any eigen value too small to be significant
    if (maxAbsoluteValue != 0.0) {
        for (int i = 0; i < n; i++) {
            if (Math.abs(realEigenvalues[i]) < MathUtils.EPSILON * maxAbsoluteValue) {
                realEigenvalues[i] = 0.0;
            }
        }
    }
    eigenvectors = new ArrayRealVector[n];
    double[] tmp = new double[n];
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            tmp[j] = z[j][i];
        }
        eigenvectors[i] = new ArrayRealVector(tmp);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-377_c640932d,Major,src/main/java/org/apache/commons/math/optimization/general/AbstractLeastSquaresOptimizer.java,239,246,"/**
 * Get the Root Mean Square value.
 * Get the Root Mean Square value, i.e. the root of the arithmetic
 * mean of the square of all weighted residuals. This is related to the
 * criterion that is minimized by the optimizer as follows: if
 * <em>c</em> if the criterion, and <em>n</em> is the number of
 * measurements, then the RMS is <em>sqrt (c/n)</em>.
 *
 * @return RMS value
 */
public double getRMS() {
    double criterion = 0;
    for (int i = 0; i < rows; ++i) {
        final double residual = residuals[i];
        criterion += residualsWeights[i] * residual * residual;
    }
    return Math.sqrt(criterion / rows);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-377_c640932d,Major,src/main/java/org/apache/commons/math/optimization/general/AbstractLeastSquaresOptimizer.java,252,259,"/**
 * Get the Chi-Square value.
 * @return chi-square value
 */
public double getChiSquare() {
    double chiSquare = 0;
    for (int i = 0; i < rows; ++i) {
        final double residual = residuals[i];
        chiSquare += residual * residual / residualsWeights[i];
    }
    return chiSquare;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-393_d4b02f6a,Trivial,src/main/java/org/apache/commons/math/optimization/MultiStartUnivariateRealOptimizer.java,91,93,"/**
 * {@inheritDoc}
 */
public double getFunctionValue() {
    return optimizer.getFunctionValue();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-393_d4b02f6a,Trivial,src/main/java/org/apache/commons/math/optimization/MultiStartUnivariateRealOptimizer.java,96,98,"/**
 * {@inheritDoc}
 */
public double getResult() {
    return optimizer.getResult();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-393_d4b02f6a,Trivial,src/main/java/org/apache/commons/math/optimization/UnivariateRealOptimizer.java,41,41,"/**
 * Get the maximal number of functions evaluations.
 * @return maximal number of functions evaluations
 */
int getMaxEvaluations();"
commons-math,remotes/origin/bugs-dot-jar_MATH-393_d4b02f6a,Trivial,src/main/java/org/apache/commons/math/optimization/UnivariateRealOptimizer.java,51,51,"/**
 * Get the number of evaluations of the objective function.
 * <p>
 * The number of evaluations corresponds to the last call to the
 * {@link #optimize(UnivariateRealFunction, GoalType, double, double) optimize}
 * method. It is 0 if the method has not been called yet.
 * </p>
 * @return number of evaluations of the objective function
 */
int getEvaluations();"
commons-math,remotes/origin/bugs-dot-jar_MATH-393_d4b02f6a,Trivial,src/main/java/org/apache/commons/math/optimization/UnivariateRealOptimizer.java,71,73,"/**
 * Find an optimum in the given interval.
 * <p>
 * An optimizer may require that the interval brackets a single optimum.
 * </p>
 * @param f the function to optimize.
 * @param goalType type of optimization goal: either {@link GoalType#MAXIMIZE}
 * or {@link GoalType#MINIMIZE}
 * @param min the lower bound for the interval.
 * @param max the upper bound for the interval.
 * @return a value where the function is optimum
 * @throws ConvergenceException if the maximum iteration count is exceeded
 * or the optimizer detects convergence problems otherwise.
 * @throws FunctionEvaluationException if an error occurs evaluating the
 * function
 * @throws IllegalArgumentException if min > max or the endpoints do not
 * satisfy the requirements specified by the optimizer
 */
double optimize(UnivariateRealFunction f, GoalType goalType, double min, double max) throws ConvergenceException, FunctionEvaluationException;"
commons-math,remotes/origin/bugs-dot-jar_MATH-393_d4b02f6a,Trivial,src/main/java/org/apache/commons/math/optimization/UnivariateRealOptimizer.java,94,96,"/**
 * Find an optimum in the given interval, start at startValue.
 * <p>
 * An optimizer may require that the interval brackets a single optimum.
 * </p>
 * @param f the function to optimize.
 * @param goalType type of optimization goal: either {@link GoalType#MAXIMIZE}
 * or {@link GoalType#MINIMIZE}
 * @param min the lower bound for the interval.
 * @param max the upper bound for the interval.
 * @param startValue the start value to use
 * @return a value where the function is optimum
 * @throws ConvergenceException if the maximum iteration count is exceeded
 * or the optimizer detects convergence problems otherwise.
 * @throws FunctionEvaluationException if an error occurs evaluating the
 * function
 * @throws IllegalArgumentException if min > max or the arguments do not
 * satisfy the requirements specified by the optimizer
 */
double optimize(UnivariateRealFunction f, GoalType goalType, double min, double max, double startValue) throws ConvergenceException, FunctionEvaluationException;"
commons-math,remotes/origin/bugs-dot-jar_MATH-393_d4b02f6a,Trivial,src/main/java/org/apache/commons/math/optimization/UnivariateRealOptimizer.java,105,105,"/**
 * Get the result of the last run of the optimizer.
 *
 * @return the last result.
 * @throws IllegalStateException if there is no result available, either
 * because no result was yet computed or the last attempt failed.
 */
double getResult();"
commons-math,remotes/origin/bugs-dot-jar_MATH-393_d4b02f6a,Trivial,src/main/java/org/apache/commons/math/optimization/UnivariateRealOptimizer.java,114,114,"/**
 * Get the result of the last run of the optimizer.
 *
 * @return the value of the function at the last result.
 * @throws IllegalStateException if there is no result available, either
 * because no result was yet computed or the last attempt failed.
 */
double getFunctionValue();"
commons-math,remotes/origin/bugs-dot-jar_MATH-395_962315ba,Major,src/main/java/org/apache/commons/math/ConvergingAlgorithmImpl.java,146,151,"/**
 * Increment the iterations counter by 1.
 *
 * @throws OptimizationException if the maximal number
 * of iterations is exceeded.
 * @since 2.2
 */
protected void incrementIterationsCounter() throws ConvergenceException {
    if (++iterationCount > maximalIterationCount) {
        throw new ConvergenceException(new MaxIterationsExceededException(maximalIterationCount));
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-395_962315ba,Major,src/main/java/org/apache/commons/math/optimization/univariate/AbstractUnivariateRealOptimizer.java,263,263,"/**
 * Method for implementing actual optimization algorithms in derived
 * classes.
 *
 * @return the optimum.
 */
protected abstract double doOptimize();"
commons-math,remotes/origin/bugs-dot-jar_MATH-395_962315ba,Major,src/main/java/org/apache/commons/math/optimization/univariate/BrentOptimizer.java,48,54,"/**
 * {@inheritDoc}
 */
public double optimize(final UnivariateRealFunction f, final GoalType goalType, final double min, final double max, final double startValue) throws MaxIterationsExceededException, FunctionEvaluationException {
    clearResult();
    return localMin(f, goalType, min, startValue, max, getRelativeAccuracy(), getAbsoluteAccuracy());
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-395_962315ba,Major,src/main/java/org/apache/commons/math/optimization/univariate/BrentOptimizer.java,57,61,"/**
 * {@inheritDoc}
 */
public double optimize(final UnivariateRealFunction f, final GoalType goalType, final double min, final double max) throws MaxIterationsExceededException, FunctionEvaluationException {
    return optimize(f, goalType, min, max, min + GOLDEN_SECTION * (max - min));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-395_962315ba,Major,src/main/java/org/apache/commons/math/optimization/univariate/BrentOptimizer.java,88,238,"/**
 * Find the minimum of the function {@code f} within the interval {@code (a, b)}.
 *
 * If the function {@code f} is defined on the interval {@code (a, b)}, then
 * this method finds an approximation {@code x} to the point at which {@code f}
 * attains its minimum.<br/>
 * {@code t} and {@code eps} define a tolerance {@code tol = eps |x| + t} and
 * {@code f} is never evaluated at two points closer together than {@code tol}.
 * {@code eps} should be no smaller than <em>2 macheps</em> and preferable not
 * much less than <em>sqrt(macheps)</em>, where <em>macheps</em> is the relative
 * machine precision. {@code t} should be positive.
 * @param f the function to solve.
 * @param goalType type of optimization goal: either {@link GoalType#MAXIMIZE}
 * or {@link GoalType#MINIMIZE}.
 * @param lo Lower bound of the interval.
 * @param mid Point inside the interval {@code [lo, hi]}.
 * @param hi Higher bound of the interval.
 * @param eps Relative accuracy.
 * @param t Absolute accuracy.
 * @return the optimum point.
 * @throws MaxIterationsExceededException if the maximum iteration count
 * is exceeded.
 * @throws FunctionEvaluationException if an error occurs evaluating
 * the function.
 */
private double localMin(UnivariateRealFunction f, GoalType goalType, double lo, double mid, double hi, double eps, double t) throws MaxIterationsExceededException, FunctionEvaluationException {
    if (eps <= 0) {
        throw new NotStrictlyPositiveException(eps);
    }
    if (t <= 0) {
        throw new NotStrictlyPositiveException(t);
    }
    double a, b;
    if (lo < hi) {
        a = lo;
        b = hi;
    } else {
        a = hi;
        b = lo;
    }
    double x = mid;
    double v = x;
    double w = x;
    double e = 0;
    double fx = computeObjectiveValue(f, x);
    if (goalType == GoalType.MAXIMIZE) {
        fx = -fx;
    }
    double fv = fx;
    double fw = fx;
    int count = 0;
    while (count < maximalIterationCount) {
        double m = 0.5 * (a + b);
        final double tol1 = eps * Math.abs(x) + t;
        final double tol2 = 2 * tol1;
        // Check stopping criterion.
        if (Math.abs(x - m) > tol2 - 0.5 * (b - a)) {
            double p = 0;
            double q = 0;
            double r = 0;
            double d = 0;
            double u = 0;
            if (Math.abs(e) > tol1) {
                // Fit parabola.
                r = (x - w) * (fx - fv);
                q = (x - v) * (fx - fw);
                p = (x - v) * q - (x - w) * r;
                q = 2 * (q - r);
                if (q > 0) {
                    p = -p;
                } else {
                    q = -q;
                }
                r = e;
                e = d;
                if (p > q * (a - x) && p < q * (b - x) && Math.abs(p) < Math.abs(0.5 * q * r)) {
                    // Parabolic interpolation step.
                    d = p / q;
                    u = x + d;
                    // f must not be evaluated too close to a or b.
                    if (u - a < tol2 || b - u < tol2) {
                        if (x <= m) {
                            d = tol1;
                        } else {
                            d = -tol1;
                        }
                    }
                } else {
                    // Golden section step.
                    if (x < m) {
                        e = b - x;
                    } else {
                        e = a - x;
                    }
                    d = GOLDEN_SECTION * e;
                }
            } else {
                // Golden section step.
                if (x < m) {
                    e = b - x;
                } else {
                    e = a - x;
                }
                d = GOLDEN_SECTION * e;
            }
            // Update by at least ""tol1"".
            if (Math.abs(d) < tol1) {
                if (d >= 0) {
                    u = x + tol1;
                } else {
                    u = x - tol1;
                }
            } else {
                u = x + d;
            }
            double fu = computeObjectiveValue(f, u);
            if (goalType == GoalType.MAXIMIZE) {
                fu = -fu;
            }
            // Update a, b, v, w and x.
            if (fu <= fx) {
                if (u < x) {
                    b = x;
                } else {
                    a = x;
                }
                v = w;
                fv = fw;
                w = x;
                fw = fx;
                x = u;
                fx = fu;
            } else {
                if (u < x) {
                    a = u;
                } else {
                    b = u;
                }
                if (fu <= fw || w == x) {
                    v = w;
                    fv = fw;
                    w = u;
                    fw = fu;
                } else if (fu <= fv || v == x || v == w) {
                    v = u;
                    fv = fu;
                }
            }
        } else {
            // termination
            setResult(x, (goalType == GoalType.MAXIMIZE) ? -fx : fx, count);
            return x;
        }
        ++count;
    }
    throw new MaxIterationsExceededException(maximalIterationCount);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-395_962315ba,Major,src/main/java/org/apache/commons/math/optimization/univariate/BrentOptimizer.java,241,243,"/**
 * Temporary workaround.
 */
protected double doOptimize() {
    throw new UnsupportedOperationException();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-405_784e4f69,Major,src/main/java/org/apache/commons/math/optimization/general/AbstractLeastSquaresOptimizer.java,249,256,"/**
 * Get a Chi-Square-like value assuming the N residuals follow N
 * distinct normal distributions centered on 0 and whose variances are
 * the reciprocal of the weights.
 * @return chi-square value
 */
public double getChiSquare() {
    double chiSquare = 0;
    for (int i = 0; i < rows; ++i) {
        final double residual = residuals[i];
        chiSquare += residual * residual * residualsWeights[i];
    }
    return chiSquare;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-405_784e4f69,Major,src/main/java/org/apache/commons/math/optimization/general/LevenbergMarquardtOptimizer.java,240,469,"/**
 * {@inheritDoc}
 */
@Override
protected VectorialPointValuePair doOptimize() throws FunctionEvaluationException, OptimizationException, IllegalArgumentException {
    // arrays shared with the other private methods
    solvedCols = Math.min(rows, cols);
    diagR = new double[cols];
    jacNorm = new double[cols];
    beta = new double[cols];
    permutation = new int[cols];
    lmDir = new double[cols];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[cols];
    double[] oldX = new double[cols];
    double[] oldRes = new double[rows];
    double[] work1 = new double[cols];
    double[] work2 = new double[cols];
    double[] work3 = new double[cols];
    // evaluate the function at the starting point and calculate its norm
    updateResidualsAndCost();
    // outer loop
    lmPar = 0;
    boolean firstIteration = true;
    VectorialPointValuePair current = new VectorialPointValuePair(point, objective);
    while (true) {
        incrementIterationsCounter();
        // compute the Q.R. decomposition of the jacobian matrix
        VectorialPointValuePair previous = current;
        updateJacobian();
        qrDecomposition();
        // compute Qt.res
        qTy(residuals);
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            jacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < cols; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * point[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = Math.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (cost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += jacobian[i][pj] * residuals[i];
                    }
                    maxCosine = Math.max(maxCosine, Math.abs(sum) / (s * cost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // convergence has been reached
            return current;
        }
        // rescale if necessary
        for (int j = 0; j < cols; ++j) {
            diag[j] = Math.max(diag[j], jacNorm[j]);
        }
        // inner loop
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = point[pj];
            }
            double previousCost = cost;
            double[] tmpVec = residuals;
            residuals = oldRes;
            oldRes = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(oldRes, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                point[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = Math.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = Math.min(delta, lmNorm);
            }
            // evaluate the function at x + p and calculate its norm
            updateResidualsAndCost();
            current = new VectorialPointValuePair(point, objective);
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * cost < previousCost) {
                double r = cost / previousCost;
                actRed = 1.0 - r * r;
            }
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += jacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * cost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * Math.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < cols; ++k) {
                    double xK = diag[k] * point[k];
                    xNorm += xK * xK;
                }
                xNorm = Math.sqrt(xNorm);
            } else {
                // failed iteration, reset the previous values
                cost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    point[pj] = oldX[pj];
                }
                tmpVec = residuals;
                residuals = oldRes;
                oldRes = tmpVec;
            }
            // tests for convergence.
            if (checker != null) {
                // we use the vectorial convergence checker
                if (checker.converged(getIterations(), previous, current)) {
                    return current;
                }
            } else {
                // we use the Levenberg-Marquardt specific convergence parameters
                if (((Math.abs(actRed) <= costRelativeTolerance) && (preRed <= costRelativeTolerance) && (ratio <= 2.0)) || (delta <= parRelativeTolerance * xNorm)) {
                    return current;
                }
            }
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((Math.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new OptimizationException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-413_51aa6e6c,Major,src/main/java/org/apache/commons/math/optimization/univariate/MultiStartUnivariateRealOptimizer.java,142,178,"/**
 * {@inheritDoc}
 */
public UnivariateRealPointValuePair optimize(final FUNC f, final GoalType goal, final double min, final double max) throws FunctionEvaluationException {
    optima = new UnivariateRealPointValuePair[starts];
    totalEvaluations = 0;
    // Multi-start loop.
    for (int i = 0; i < starts; ++i) {
        try {
            final double bound1 = (i == 0) ? min : min + generator.nextDouble() * (max - min);
            final double bound2 = (i == 0) ? max : min + generator.nextDouble() * (max - min);
            optima[i] = optimizer.optimize(f, goal, FastMath.min(bound1, bound2), FastMath.max(bound1, bound2));
        } catch (FunctionEvaluationException fee) {
            optima[i] = null;
        } catch (ConvergenceException ce) {
            optima[i] = null;
        }
        final int usedEvaluations = optimizer.getEvaluations();
        optimizer.setMaxEvaluations(optimizer.getMaxEvaluations() - usedEvaluations);
        totalEvaluations += usedEvaluations;
    }
    sortPairs(goal);
    if (optima[0] == null) {
        throw new ConvergenceException(LocalizedFormats.NO_CONVERGENCE_WITH_ANY_START_POINT, starts);
    }
    // Return the point with the best objective function value.
    return optima[0];
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-413_51aa6e6c,Major,src/main/java/org/apache/commons/math/optimization/univariate/MultiStartUnivariateRealOptimizer.java,181,188,"/**
 * {@inheritDoc}
 */
public UnivariateRealPointValuePair optimize(final FUNC f, final GoalType goalType, final double min, final double max, final double startValue) throws FunctionEvaluationException {
    // XXX This method should set ""startValue"" to min + 0.5 * (max - min)
    return optimize(f, goalType, min, max);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-414_5fe9b36c,Minor,src/main/java/org/apache/commons/math/distribution/NormalDistributionImpl.java,124,137,"/**
 * For this distribution, {@code X}, this method returns {@code P(X < x)}.
 *
 * @param x Value at which the CDF is evaluated.
 * @return CDF evaluated at {@code x}.
 * @throws MathException if the algorithm fails to converge; unless
 * {@code x} is more than 20 standard deviations from the mean, in which
 * case the convergence exception is caught and 0 or 1 is returned.
 */
public double cumulativeProbability(double x) throws MathException {
    try {
        return 0.5 * (1.0 + Erf.erf((x - mean) / (standardDeviation * FastMath.sqrt(2.0))));
    } catch (MaxIterationsExceededException ex) {
        if (x < (mean - 20 * standardDeviation)) {
            // JDK 1.5 blows at 38
            return 0;
        } else if (x > (mean + 20 * standardDeviation)) {
            return 1;
        } else {
            throw ex;
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexSolver.java,61,71,"/**
 * Returns the column with the most negative coefficient in the objective function row.
 * @param tableau simple tableau for the problem
 * @return column with the most negative coefficient
 */
private Integer getPivotColumn(SimplexTableau tableau) {
    double minValue = 0;
    Integer minPos = null;
    for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getWidth() - 1; i++) {
        if (MathUtils.compareTo(tableau.getEntry(0, i), minValue, epsilon) < 0) {
            minValue = tableau.getEntry(0, i);
            minPos = i;
        }
    }
    return minPos;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexSolver.java,79,114,"/**
 * Returns the row with the minimum ratio as given by the minimum ratio test (MRT).
 * @param tableau simple tableau for the problem
 * @param col the column to test the ratio of.  See {@link #getPivotColumn(SimplexTableau)}
 * @return row with the minimum ratio
 */
private Integer getPivotRow(SimplexTableau tableau, final int col) {
    // create a list of all the rows that tie for the lowest score in the minimum ratio test
    List<Integer> minRatioPositions = new ArrayList<Integer>();
    double minRatio = Double.MAX_VALUE;
    for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getHeight(); i++) {
        final double rhs = tableau.getEntry(i, tableau.getWidth() - 1);
        final double entry = tableau.getEntry(i, col);
        if (MathUtils.compareTo(entry, 0, epsilon) > 0) {
            final double ratio = rhs / entry;
            if (MathUtils.equals(ratio, minRatio, epsilon)) {
                minRatioPositions.add(i);
            } else if (ratio < minRatio) {
                minRatio = ratio;
                minRatioPositions = new ArrayList<Integer>();
                minRatioPositions.add(i);
            }
        }
    }
    if (minRatioPositions.size() == 0) {
        return null;
    } else if (minRatioPositions.size() > 1) {
        // check if there's an artificial variable that can be forced out of the basis
        for (Integer row : minRatioPositions) {
            for (int i = 0; i < tableau.getNumArtificialVariables(); i++) {
                int column = i + tableau.getArtificialVariableOffset();
                if (MathUtils.equals(tableau.getEntry(row, column), 1, epsilon) && row.equals(tableau.getBasicRow(column))) {
                    return row;
                }
            }
        }
    }
    return minRatioPositions.get(0);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexSolver.java,153,168,"/**
 * Solves Phase 1 of the Simplex method.
 * @param tableau simple tableau for the problem
 * @exception OptimizationException if the maximal number of iterations is
 * exceeded, or if the problem is found not to have a bounded solution, or
 * if there is no feasible solution
 */
protected void solvePhase1(final SimplexTableau tableau) throws OptimizationException {
    // make sure we're in Phase 1
    if (tableau.getNumArtificialVariables() == 0) {
        return;
    }
    while (!tableau.isOptimal()) {
        doIteration(tableau);
    }
    // if W is not zero then we have no feasible solution
    if (!MathUtils.equals(tableau.getEntry(0, tableau.getRhsOffset()), 0, epsilon)) {
        throw new NoFeasibleSolutionException();
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexSolver.java,171,183,"/**
 * {@inheritDoc}
 */
@Override
public RealPointValuePair doOptimize() throws OptimizationException {
    final SimplexTableau tableau = new SimplexTableau(function, linearConstraints, goal, nonNegative, epsilon);
    solvePhase1(tableau);
    tableau.dropPhase1Objective();
    while (!tableau.isOptimal()) {
        doIteration(tableau);
    }
    return tableau.getSolution();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,153,214,"/**
 * Create the tableau by itself.
 * @param maximize if true, goal is to maximize the objective function
 * @return created tableau
 */
protected RealMatrix createTableau(final boolean maximize) {
    // create a matrix of the correct size
    int width = numDecisionVariables + numSlackVariables + numArtificialVariables + getNumObjectiveFunctions() + // + 1 is for RHS
    1;
    int height = constraints.size() + getNumObjectiveFunctions();
    Array2DRowRealMatrix matrix = new Array2DRowRealMatrix(height, width);
    // initialize the objective function rows
    if (getNumObjectiveFunctions() == 2) {
        matrix.setEntry(0, 0, -1);
    }
    int zIndex = (getNumObjectiveFunctions() == 1) ? 0 : 1;
    matrix.setEntry(zIndex, zIndex, maximize ? 1 : -1);
    RealVector objectiveCoefficients = maximize ? f.getCoefficients().mapMultiply(-1) : f.getCoefficients();
    copyArray(objectiveCoefficients.getData(), matrix.getDataRef()[zIndex]);
    matrix.setEntry(zIndex, width - 1, maximize ? f.getConstantTerm() : -1 * f.getConstantTerm());
    if (!restrictToNonNegative) {
        matrix.setEntry(zIndex, getSlackVariableOffset() - 1, getInvertedCoeffiecientSum(objectiveCoefficients));
    }
    // initialize the constraint rows
    int slackVar = 0;
    int artificialVar = 0;
    for (int i = 0; i < constraints.size(); i++) {
        LinearConstraint constraint = constraints.get(i);
        int row = getNumObjectiveFunctions() + i;
        // decision variable coefficients
        copyArray(constraint.getCoefficients().getData(), matrix.getDataRef()[row]);
        // x-
        if (!restrictToNonNegative) {
            matrix.setEntry(row, getSlackVariableOffset() - 1, getInvertedCoeffiecientSum(constraint.getCoefficients()));
        }
        // RHS
        matrix.setEntry(row, width - 1, constraint.getValue());
        // slack variables
        if (constraint.getRelationship() == Relationship.LEQ) {
            // slack
            matrix.setEntry(row, getSlackVariableOffset() + slackVar++, 1);
        } else if (constraint.getRelationship() == Relationship.GEQ) {
            // excess
            matrix.setEntry(row, getSlackVariableOffset() + slackVar++, -1);
        }
        // artificial variables
        if ((constraint.getRelationship() == Relationship.EQ) || (constraint.getRelationship() == Relationship.GEQ)) {
            matrix.setEntry(0, getArtificialVariableOffset() + artificialVar, 1);
            matrix.setEntry(row, getArtificialVariableOffset() + artificialVar++, 1);
            matrix.setRowVector(0, matrix.getRowVector(0).subtract(matrix.getRowVector(row)));
        }
    }
    return matrix;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,272,278,"/**
 * Get the -1 times the sum of all coefficients in the given array.
 * @param coefficients coefficients to sum
 * @return the -1 times the sum of all coefficients in the given array.
 */
protected static double getInvertedCoeffiecientSum(final RealVector coefficients) {
    double sum = 0;
    for (double coefficient : coefficients.getData()) {
        sum -= coefficient;
    }
    return sum;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,285,295,"/**
 * Checks whether the given column is basic.
 * @param col index of the column to check
 * @return the row that the variable is basic in.  null if the column is not basic
 */
protected Integer getBasicRow(final int col) {
    Integer row = null;
    for (int i = 0; i < getHeight(); i++) {
        if (MathUtils.equals(getEntry(i, col), 1.0, epsilon) && (row == null)) {
            row = i;
        } else if (!MathUtils.equals(getEntry(i, col), 0.0, epsilon)) {
            return null;
        }
    }
    return row;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,301,340,"/**
 * Removes the phase 1 objective function, positive cost non-artificial variables,
 * and the non-basic artificial variables from this tableau.
 */
protected void dropPhase1Objective() {
    if (getNumObjectiveFunctions() == 1) {
        return;
    }
    List<Integer> columnsToDrop = new ArrayList<Integer>();
    columnsToDrop.add(0);
    // positive cost non-artificial variables
    for (int i = getNumObjectiveFunctions(); i < getArtificialVariableOffset(); i++) {
        if (MathUtils.compareTo(tableau.getEntry(0, i), 0, epsilon) > 0) {
            columnsToDrop.add(i);
        }
    }
    // non-basic artificial variables
    for (int i = 0; i < getNumArtificialVariables(); i++) {
        int col = i + getArtificialVariableOffset();
        if (getBasicRow(col) == null) {
            columnsToDrop.add(col);
        }
    }
    double[][] matrix = new double[getHeight() - 1][getWidth() - columnsToDrop.size()];
    for (int i = 1; i < getHeight(); i++) {
        int col = 0;
        for (int j = 0; j < getWidth(); j++) {
            if (!columnsToDrop.contains(j)) {
                matrix[i - 1][col++] = tableau.getEntry(i, j);
            }
        }
    }
    for (int i = columnsToDrop.size() - 1; i >= 0; i--) {
        columnLabels.remove((int) columnsToDrop.get(i));
    }
    this.tableau = new Array2DRowRealMatrix(matrix);
    this.numArtificialVariables = 0;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,354,361,"/**
 * Returns whether the problem is at an optimal state.
 * @return whether the model has been solved
 */
boolean isOptimal() {
    for (int i = getNumObjectiveFunctions(); i < getWidth() - 1; i++) {
        if (MathUtils.compareTo(tableau.getEntry(0, i), 0, epsilon) < 0) {
            return false;
        }
    }
    return true;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,368,394,"/**
 * Get the current solution.
 *
 * @return current solution
 */
protected RealPointValuePair getSolution() {
    int negativeVarColumn = columnLabels.indexOf(NEGATIVE_VAR_COLUMN_LABEL);
    Integer negativeVarBasicRow = negativeVarColumn > 0 ? getBasicRow(negativeVarColumn) : null;
    double mostNegative = negativeVarBasicRow == null ? 0 : getEntry(negativeVarBasicRow, getRhsOffset());
    Set<Integer> basicRows = new HashSet<Integer>();
    double[] coefficients = new double[getOriginalNumDecisionVariables()];
    for (int i = 0; i < coefficients.length; i++) {
        int colIndex = columnLabels.indexOf(""x"" + i);
        if (colIndex < 0) {
            coefficients[i] = 0;
            continue;
        }
        Integer basicRow = getBasicRow(colIndex);
        if (basicRows.contains(basicRow)) {
            // if multiple variables can take a given value
            // then we choose the first and set the rest equal to 0
            coefficients[i] = 0;
        } else {
            basicRows.add(basicRow);
            coefficients[i] = (basicRow == null ? 0 : getEntry(basicRow, getRhsOffset())) - (restrictToNonNegative ? 0 : mostNegative);
        }
    }
    return new RealPointValuePair(coefficients, f.getValue(coefficients));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,534,553,"/**
 * {@inheritDoc}
 */
@Override
public boolean equals(Object other) {
    if (this == other) {
        return true;
    }
    if (other instanceof SimplexTableau) {
        SimplexTableau rhs = (SimplexTableau) other;
        return (restrictToNonNegative == rhs.restrictToNonNegative) && (numDecisionVariables == rhs.numDecisionVariables) && (numSlackVariables == rhs.numSlackVariables) && (numArtificialVariables == rhs.numArtificialVariables) && (epsilon == rhs.epsilon) && f.equals(rhs.f) && constraints.equals(rhs.constraints) && tableau.equals(rhs.tableau);
    }
    return false;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-434_133cbc2d,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,556,566,"/**
 * {@inheritDoc}
 */
@Override
public int hashCode() {
    return Boolean.valueOf(restrictToNonNegative).hashCode() ^ numDecisionVariables ^ numSlackVariables ^ numArtificialVariables ^ Double.valueOf(epsilon).hashCode() ^ f.hashCode() ^ constraints.hashCode() ^ tableau.hashCode();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-482_6d6649ef,Major,src/main/java/org/apache/commons/math/util/FastMath.java,3481,3483,"/**
 * Compute the maximum of two values
 * @param a first value
 * @param b second value
 * @return b if a is lesser or equal to b, a otherwise
 */
public static float max(final float a, final float b) {
    return (a <= b) ? b : (Float.isNaN(a + b) ? Float.NaN : b);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-519_26a61077,Major,src/main/java/org/apache/commons/math/optimization/fitting/GaussianFitter.java,80,83,"/**
 * Fits Gaussian function to the observed points.
 * It will call the base class
 * {@link CurveFitter#fit(
 * org.apache.commons.math.analysis.ParametricUnivariateRealFunction,
 * double[]) fit} method.
 *
 * @return the Gaussian function that best fits the observed points.
 */
public double[] fit() {
    return fit(new Gaussian.Parametric(), (new ParameterGuesser(getObservations())).guess());
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-519_26a61077,Major,src/main/java/org/apache/commons/math/optimization/fitting/GaussianFitter.java,117,122,"/**
 * Guesses the parameters based on the observed points.
 *
 * @return guessed parameters array <code>{norm, mean, sigma}</code>
 */
public double[] guess() {
    if (parameters == null) {
        parameters = basicGuess(observations);
    }
    return parameters.clone();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-519_26a61077,Major,src/main/java/org/apache/commons/math/optimization/fitting/GaussianFitter.java,131,152,"/**
 * Guesses the parameters based on the specified observed points.
 *
 * @param points observed points upon which should base guess
 *
 * @return guessed parameters array <code>{norm, mean, sigma}</code>
 */
private double[] basicGuess(WeightedObservedPoint[] points) {
    Arrays.sort(points, createWeightedObservedPointComparator());
    double[] params = new double[3];
    int maxYIdx = findMaxY(points);
    params[0] = points[maxYIdx].getY();
    params[1] = points[maxYIdx].getX();
    double fwhmApprox;
    try {
        double halfY = params[0] + ((params[1] - params[0]) / 2.0);
        double fwhmX1 = interpolateXAtY(points, maxYIdx, -1, halfY);
        double fwhmX2 = interpolateXAtY(points, maxYIdx, +1, halfY);
        fwhmApprox = fwhmX2 - fwhmX1;
    } catch (OutOfRangeException e) {
        fwhmApprox = points[points.length - 1].getX() - points[0].getX();
    }
    params[2] = fwhmApprox / (2.0 * Math.sqrt(2.0 * Math.log(2.0)));
    return params;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-519_26a61077,Major,src/main/java/org/apache/commons/math/optimization/fitting/GaussianFitter.java,161,169,"/**
 * Finds index of point in specified points with the largest Y.
 *
 * @param points points to search
 *
 * @return index in specified points array
 */
private int findMaxY(WeightedObservedPoint[] points) {
    int maxYIdx = 0;
    for (int i = 1; i < points.length; i++) {
        if (points[i].getY() > points[maxYIdx].getY()) {
            maxYIdx = i;
        }
    }
    return maxYIdx;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-519_26a61077,Major,src/main/java/org/apache/commons/math/optimization/fitting/GaussianFitter.java,187,205,"/**
 * Interpolates using the specified points to determine X at the specified
 * Y.
 *
 * @param points points to use for interpolation
 * @param startIdx index within points from which to start search for
 *        interpolation bounds points
 * @param idxStep index step for search for interpolation bounds points
 * @param y Y value for which X should be determined
 *
 * @return value of X at the specified Y
 *
 * @throws IllegalArgumentException if idxStep is 0
 * @throws OutOfRangeException if specified <code>y</code> is not within the
 *         range of the specified <code>points</code>
 */
private double interpolateXAtY(WeightedObservedPoint[] points, int startIdx, int idxStep, double y) throws OutOfRangeException {
    if (idxStep == 0) {
        throw new ZeroException();
    }
    WeightedObservedPoint[] twoPoints = getInterpolationPointsForY(points, startIdx, idxStep, y);
    WeightedObservedPoint pointA = twoPoints[0];
    WeightedObservedPoint pointB = twoPoints[1];
    if (pointA.getY() == y) {
        return pointA.getX();
    }
    if (pointB.getY() == y) {
        return pointB.getX();
    }
    return pointA.getX() + (((y - pointA.getY()) * (pointB.getX() - pointA.getX())) / (pointB.getY() - pointA.getY()));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-519_26a61077,Major,src/main/java/org/apache/commons/math/optimization/fitting/GaussianFitter.java,224,248,"/**
 * Gets the two bounding interpolation points from the specified points
 * suitable for determining X at the specified Y.
 *
 * @param points points to use for interpolation
 * @param startIdx index within points from which to start search for
 *        interpolation bounds points
 * @param idxStep index step for search for interpolation bounds points
 * @param y Y value for which X should be determined
 *
 * @return array containing two points suitable for determining X at the
 *         specified Y
 *
 * @throws IllegalArgumentException if idxStep is 0
 * @throws OutOfRangeException if specified <code>y</code> is not within the
 *         range of the specified <code>points</code>
 */
private WeightedObservedPoint[] getInterpolationPointsForY(WeightedObservedPoint[] points, int startIdx, int idxStep, double y) throws OutOfRangeException {
    if (idxStep == 0) {
        throw new ZeroException();
    }
    for (int i = startIdx; (idxStep < 0) ? (i + idxStep >= 0) : (i + idxStep < points.length); i += idxStep) {
        if (isBetween(y, points[i].getY(), points[i + idxStep].getY())) {
            return (idxStep < 0) ? new WeightedObservedPoint[] { points[i + idxStep], points[i] } : new WeightedObservedPoint[] { points[i], points[i + idxStep] };
        }
    }
    double minY = Double.POSITIVE_INFINITY;
    double maxY = Double.NEGATIVE_INFINITY;
    for (final WeightedObservedPoint point : points) {
        minY = Math.min(minY, point.getY());
        maxY = Math.max(maxY, point.getY());
    }
    throw new OutOfRangeException(y, minY, maxY);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-519_26a61077,Major,src/main/java/org/apache/commons/math/optimization/fitting/GaussianFitter.java,261,264,"/**
 * Determines whether a value is between two other values.
 *
 * @param value value to determine whether is between <code>boundary1</code>
 *        and <code>boundary2</code>
 * @param boundary1 one end of the range
 * @param boundary2 other end of the range
 *
 * @return true if <code>value</code> is between <code>boundary1</code> and
 *         <code>boundary2</code> (inclusive); false otherwise
 */
private boolean isBetween(double value, double boundary1, double boundary2) {
    return (value >= boundary1 && value <= boundary2) || (value >= boundary2 && value <= boundary1);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-519_26a61077,Major,src/main/java/org/apache/commons/math/optimization/fitting/GaussianFitter.java,272,305,"/**
 * Factory method creating <code>Comparator</code> for comparing
 * <code>WeightedObservedPoint</code> instances.
 *
 * @return new <code>Comparator</code> instance
 */
private Comparator<WeightedObservedPoint> createWeightedObservedPointComparator() {
    return new Comparator<WeightedObservedPoint>() {

        public int compare(WeightedObservedPoint p1, WeightedObservedPoint p2) {
            if (p1 == null && p2 == null) {
                return 0;
            }
            if (p1 == null) {
                return -1;
            }
            if (p2 == null) {
                return 1;
            }
            if (p1.getX() < p2.getX()) {
                return -1;
            }
            if (p1.getX() > p2.getX()) {
                return 1;
            }
            if (p1.getY() < p2.getY()) {
                return -1;
            }
            if (p1.getY() > p2.getY()) {
                return 1;
            }
            if (p1.getWeight() < p2.getWeight()) {
                return -1;
            }
            if (p1.getWeight() > p2.getWeight()) {
                return 1;
            }
            return 0;
        }
    };
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-546_b6bf8f41,Minor,src/main/java/org/apache/commons/math/stat/clustering/KMeansPlusPlusClusterer.java,161,198,"/**
 * Use K-means++ to choose the initial centers.
 *
 * @param <T> type of the points to cluster
 * @param points the points to choose the initial centers from
 * @param k the number of centers to choose
 * @param random random generator to use
 * @return the initial centers
 */
private static <T extends Clusterable<T>> List<Cluster<T>> chooseInitialCenters(final Collection<T> points, final int k, final Random random) {
    final List<T> pointSet = new ArrayList<T>(points);
    final List<Cluster<T>> resultSet = new ArrayList<Cluster<T>>();
    // Choose one center uniformly at random from among the data points.
    final T firstPoint = pointSet.remove(random.nextInt(pointSet.size()));
    resultSet.add(new Cluster<T>(firstPoint));
    final double[] dx2 = new double[pointSet.size()];
    while (resultSet.size() < k) {
        // For each data point x, compute D(x), the distance between x and
        // the nearest center that has already been chosen.
        int sum = 0;
        for (int i = 0; i < pointSet.size(); i++) {
            final T p = pointSet.get(i);
            final Cluster<T> nearest = getNearestCluster(resultSet, p);
            final double d = p.distanceFrom(nearest.getCenter());
            sum += d * d;
            dx2[i] = sum;
        }
        // Add one new data point as a center. Each point x is chosen with
        // probability proportional to D(x)2
        final double r = random.nextDouble() * sum;
        for (int i = 0; i < dx2.length; i++) {
            if (dx2[i] >= r) {
                final T p = pointSet.remove(i);
                resultSet.add(new Cluster<T>(p));
                break;
            }
        }
    }
    return resultSet;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-554_fbbb96eb,Major,src/main/java/org/apache/commons/math/geometry/Vector3D.java,457,461,"/**
 * Compute the cross-product of two vectors.
 * @param v1 first vector
 * @param v2 second vector
 * @return the cross product v1 ^ v2 as a new Vector
 */
public static Vector3D crossProduct(Vector3D v1, Vector3D v2) {
    return new Vector3D(v1.y * v2.z - v1.z * v2.y, v1.z * v2.x - v1.x * v2.z, v1.x * v2.y - v1.y * v2.x);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-555_328513f3,Minor,src/main/java/org/apache/commons/math/util/MathUtils.java,1347,1362,"/**
 * Round the given value to the specified number of decimal places. The
 * value is rounded using the given method which is any method defined in
 * {@link BigDecimal}.
 *
 * @param x the value to round.
 * @param scale the number of digits to the right of the decimal point.
 * @param roundingMethod the rounding method as defined in
 *        {@link BigDecimal}.
 * @return the rounded value.
 * @since 1.1
 */
public static double round(double x, int scale, int roundingMethod) {
    try {
        return (new BigDecimal(Double.toString(x)).setScale(scale, roundingMethod)).doubleValue();
    } catch (NumberFormatException ex) {
        if (Double.isInfinite(x)) {
            return x;
        } else {
            return Double.NaN;
        }
    } catch (RuntimeException ex) {
        throw new MathRuntimeException(ex);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-559_fc409e88,Trivial,src/main/java/org/apache/commons/math/util/MathUtils.java,517,536,"/**
 * Returns true if both arguments are equal or within the range of allowed
 * error (inclusive).
 * Two float numbers are considered equal if there are {@code (maxUlps - 1)}
 * (or fewer) floating point numbers between them, i.e. two adjacent floating
 * point numbers are considered equal.
 * Adapted from <a
 * href=""http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm"">
 * Bruce Dawson</a>
 *
 * @param x first value
 * @param y second value
 * @param maxUlps {@code (maxUlps - 1)} is the number of floating point
 * values between {@code x} and {@code y}.
 * @return {@code true} if there are fewer than {@code maxUlps} floating
 * point values between {@code x} and {@code y}.
 * @since 2.2
 */
public static boolean equals(float x, float y, int maxUlps) {
    // NaN won't compare as equal to anything (except another NaN).
    assert maxUlps > 0 && maxUlps < NAN_GAP;
    int xInt = Float.floatToIntBits(x);
    int yInt = Float.floatToIntBits(y);
    // Make lexicographically ordered as a two's-complement integer.
    if (xInt < 0) {
        xInt = SGN_MASK_FLOAT - xInt;
    }
    if (yInt < 0) {
        yInt = SGN_MASK_FLOAT - yInt;
    }
    final boolean isEqual = FastMath.abs(xInt - yInt) <= maxUlps;
    return isEqual && !Float.isNaN(x) && !Float.isNaN(y);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-559_fc409e88,Trivial,src/main/java/org/apache/commons/math/util/MathUtils.java,677,696,"/**
 * Returns true if both arguments are equal or within the range of allowed
 * error (inclusive).
 * Two float numbers are considered equal if there are {@code (maxUlps - 1)}
 * (or fewer) floating point numbers between them, i.e. two adjacent floating
 * point numbers are considered equal.
 * Adapted from <a
 * href=""http://www.cygnus-software.com/papers/comparingfloats/comparingfloats.htm"">
 * Bruce Dawson</a>
 *
 * @param x first value
 * @param y second value
 * @param maxUlps {@code (maxUlps - 1)} is the number of floating point
 * values between {@code x} and {@code y}.
 * @return {@code true} if there are fewer than {@code maxUlps} floating
 * point values between {@code x} and {@code y}.
 */
public static boolean equals(double x, double y, int maxUlps) {
    // NaN won't compare as equal to anything (except another NaN).
    assert maxUlps > 0 && maxUlps < NAN_GAP;
    long xInt = Double.doubleToLongBits(x);
    long yInt = Double.doubleToLongBits(y);
    // Make lexicographically ordered as a two's-complement integer.
    if (xInt < 0) {
        xInt = SGN_MASK - xInt;
    }
    if (yInt < 0) {
        yInt = SGN_MASK - yInt;
    }
    final boolean isEqual = FastMath.abs(xInt - yInt) <= maxUlps;
    return isEqual && !Double.isNaN(x) && !Double.isNaN(y);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-618_2123f780,Major,src/main/java/org/apache/commons/math/complex/Complex.java,150,155,"/**
 * Return the sum of this complex number and the given complex number.
 * <p>
 * Uses the definitional formula
 * <pre>
 * (a + bi) + (c + di) = (a+c) + (b+d)i
 * </pre></p>
 * <p>
 * If either this or <code>rhs</code> has a NaN value in either part,
 * {@link #NaN} is returned; otherwise Infinite and NaN values are
 * returned in the parts of the result according to the rules for
 * {@link java.lang.Double} arithmetic.</p>
 *
 * @param rhs the other complex number
 * @return the complex number sum
 * @throws NullArgumentException if <code>rhs</code> is null
 */
public Complex add(Complex rhs) throws NullArgumentException {
    MathUtils.checkNotNull(rhs);
    return createComplex(real + rhs.getReal(), imaginary + rhs.getImaginary());
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-631_334c01e6,Major,src/main/java/org/apache/commons/math/analysis/solvers/BaseSecantSolver.java,128,244,"/**
 * {@inheritDoc}
 */
protected final double doSolve() {
    // Get initial solution
    double x0 = getMin();
    double x1 = getMax();
    double f0 = computeObjectiveValue(x0);
    double f1 = computeObjectiveValue(x1);
    // regardless of the allowed solutions.
    if (f0 == 0.0) {
        return x0;
    }
    if (f1 == 0.0) {
        return x1;
    }
    // Verify bracketing of initial solution.
    verifyBracketing(x0, x1);
    // Get accuracies.
    final double ftol = getFunctionValueAccuracy();
    final double atol = getAbsoluteAccuracy();
    final double rtol = getRelativeAccuracy();
    // Keep track of inverted intervals, meaning that the left bound is
    // larger than the right bound.
    boolean inverted = false;
    // Keep finding better approximations.
    while (true) {
        // Calculate the next approximation.
        final double x = x1 - ((f1 * (x1 - x0)) / (f1 - f0));
        final double fx = computeObjectiveValue(x);
        // we can return it regardless of the allowed solutions.
        if (fx == 0.0) {
            return x;
        }
        // Update the bounds with the new approximation.
        if (f1 * fx < 0) {
            // We had [x0..x1]. We update it to [x1, x]. Note that the
            // value of x1 has switched to the other bound, thus inverting
            // the interval.
            x0 = x1;
            f0 = f1;
            x1 = x;
            f1 = fx;
            inverted = !inverted;
        } else {
            // We had [x0..x1]. We update it to [x0, x].
            if (method == Method.ILLINOIS) {
                f0 *= 0.5;
            }
            if (method == Method.PEGASUS) {
                f0 *= f1 / (f1 + fx);
            }
            x1 = x;
            f1 = fx;
        }
        // the root than we already are.
        if (FastMath.abs(f1) <= ftol) {
            switch(allowed) {
                case ANY_SIDE:
                    return x1;
                case LEFT_SIDE:
                    if (inverted) {
                        return x1;
                    }
                    break;
                case RIGHT_SIDE:
                    if (!inverted) {
                        return x1;
                    }
                    break;
                case BELOW_SIDE:
                    if (f1 <= 0) {
                        return x1;
                    }
                    break;
                case ABOVE_SIDE:
                    if (f1 >= 0) {
                        return x1;
                    }
                    break;
                default:
                    throw new MathInternalError();
            }
        }
        // are satisfied with the current approximation.
        if (FastMath.abs(x1 - x0) < FastMath.max(rtol * FastMath.abs(x1), atol)) {
            switch(allowed) {
                case ANY_SIDE:
                    return x1;
                case LEFT_SIDE:
                    return inverted ? x1 : x0;
                case RIGHT_SIDE:
                    return inverted ? x0 : x1;
                case BELOW_SIDE:
                    return (f1 <= 0) ? x1 : x0;
                case ABOVE_SIDE:
                    return (f1 >= 0) ? x1 : x0;
                default:
                    throw new MathInternalError();
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-631_c0b49542,Major,src/main/java/org/apache/commons/math/analysis/solvers/BaseSecantSolver.java,128,249,"/**
 * {@inheritDoc}
 */
protected final double doSolve() {
    // Get initial solution
    double x0 = getMin();
    double x1 = getMax();
    double f0 = computeObjectiveValue(x0);
    double f1 = computeObjectiveValue(x1);
    // regardless of the allowed solutions.
    if (f0 == 0.0) {
        return x0;
    }
    if (f1 == 0.0) {
        return x1;
    }
    // Verify bracketing of initial solution.
    verifyBracketing(x0, x1);
    // Get accuracies.
    final double ftol = getFunctionValueAccuracy();
    final double atol = getAbsoluteAccuracy();
    final double rtol = getRelativeAccuracy();
    // Keep track of inverted intervals, meaning that the left bound is
    // larger than the right bound.
    boolean inverted = false;
    // Keep finding better approximations.
    while (true) {
        // Calculate the next approximation.
        final double x = x1 - ((f1 * (x1 - x0)) / (f1 - f0));
        final double fx = computeObjectiveValue(x);
        // we can return it regardless of the allowed solutions.
        if (fx == 0.0) {
            return x;
        }
        // Update the bounds with the new approximation.
        if (f1 * fx < 0) {
            // The value of x1 has switched to the other bound, thus inverting
            // the interval.
            x0 = x1;
            f0 = f1;
            inverted = !inverted;
        } else {
            switch(method) {
                case ILLINOIS:
                    f0 *= 0.5;
                    break;
                case PEGASUS:
                    f0 *= f1 / (f1 + fx);
                    break;
                case REGULA_FALSI:
                    // Nothing.
                    break;
                default:
                    // Should never happen.
                    throw new MathInternalError();
            }
        }
        // Update from [x0, x1] to [x0, x].
        x1 = x;
        f1 = fx;
        // the root than we already are.
        if (FastMath.abs(f1) <= ftol) {
            switch(allowed) {
                case ANY_SIDE:
                    return x1;
                case LEFT_SIDE:
                    if (inverted) {
                        return x1;
                    }
                    break;
                case RIGHT_SIDE:
                    if (!inverted) {
                        return x1;
                    }
                    break;
                case BELOW_SIDE:
                    if (f1 <= 0) {
                        return x1;
                    }
                    break;
                case ABOVE_SIDE:
                    if (f1 >= 0) {
                        return x1;
                    }
                    break;
                default:
                    throw new MathInternalError();
            }
        }
        // are satisfied with the current approximation.
        if (FastMath.abs(x1 - x0) < FastMath.max(rtol * FastMath.abs(x1), atol)) {
            switch(allowed) {
                case ANY_SIDE:
                    return x1;
                case LEFT_SIDE:
                    return inverted ? x1 : x0;
                case RIGHT_SIDE:
                    return inverted ? x0 : x1;
                case BELOW_SIDE:
                    return (f1 <= 0) ? x1 : x0;
                case ABOVE_SIDE:
                    return (f1 >= 0) ? x1 : x0;
                default:
                    throw new MathInternalError();
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-631_ebc61de9,Major,src/main/java/org/apache/commons/math/analysis/solvers/BaseSecantSolver.java,128,256,"/**
 * {@inheritDoc}
 */
protected final double doSolve() {
    // Get initial solution
    double x0 = getMin();
    double x1 = getMax();
    double f0 = computeObjectiveValue(x0);
    double f1 = computeObjectiveValue(x1);
    // regardless of the allowed solutions.
    if (f0 == 0.0) {
        return x0;
    }
    if (f1 == 0.0) {
        return x1;
    }
    // Verify bracketing of initial solution.
    verifyBracketing(x0, x1);
    // Get accuracies.
    final double ftol = getFunctionValueAccuracy();
    final double atol = getAbsoluteAccuracy();
    final double rtol = getRelativeAccuracy();
    // Keep track of inverted intervals, meaning that the left bound is
    // larger than the right bound.
    boolean inverted = false;
    // Keep finding better approximations.
    while (true) {
        // Calculate the next approximation.
        final double x = x1 - ((f1 * (x1 - x0)) / (f1 - f0));
        final double fx = computeObjectiveValue(x);
        // we can return it regardless of the allowed solutions.
        if (fx == 0.0) {
            return x;
        }
        // Update the bounds with the new approximation.
        if (f1 * fx < 0) {
            // The value of x1 has switched to the other bound, thus inverting
            // the interval.
            x0 = x1;
            f0 = f1;
            inverted = !inverted;
        } else {
            switch(method) {
                case ILLINOIS:
                    f0 *= 0.5;
                    break;
                case PEGASUS:
                    f0 *= f1 / (f1 + fx);
                    break;
                case REGULA_FALSI:
                    if (x == x1) {
                        final double delta = FastMath.max(rtol * FastMath.abs(x1), atol);
                        // Update formula cannot make any progress: Update the
                        // search interval.
                        x0 = 0.5 * (x0 + x1 - delta);
                        f0 = computeObjectiveValue(x0);
                    }
                    break;
                default:
                    // Should never happen.
                    throw new MathInternalError();
            }
        }
        // Update from [x0, x1] to [x0, x].
        x1 = x;
        f1 = fx;
        // the root than we already are.
        if (FastMath.abs(f1) <= ftol) {
            switch(allowed) {
                case ANY_SIDE:
                    return x1;
                case LEFT_SIDE:
                    if (inverted) {
                        return x1;
                    }
                    break;
                case RIGHT_SIDE:
                    if (!inverted) {
                        return x1;
                    }
                    break;
                case BELOW_SIDE:
                    if (f1 <= 0) {
                        return x1;
                    }
                    break;
                case ABOVE_SIDE:
                    if (f1 >= 0) {
                        return x1;
                    }
                    break;
                default:
                    throw new MathInternalError();
            }
        }
        // are satisfied with the current approximation.
        if (FastMath.abs(x1 - x0) < FastMath.max(rtol * FastMath.abs(x1), atol)) {
            switch(allowed) {
                case ANY_SIDE:
                    return x1;
                case LEFT_SIDE:
                    return inverted ? x1 : x0;
                case RIGHT_SIDE:
                    return inverted ? x0 : x1;
                case BELOW_SIDE:
                    return (f1 <= 0) ? x1 : x0;
                case ABOVE_SIDE:
                    return (f1 >= 0) ? x1 : x0;
                default:
                    throw new MathInternalError();
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-640_98556fed,Major,src/main/java/org/apache/commons/math/random/AbstractRandomGenerator.java,136,138,"/**
 * Returns the next pseudorandom, uniformly distributed {@code int}
 * value from this random number generator's sequence.
 * All 2<font size=""-1""><sup>32</sup></font> possible {@code int} values
 * should be produced with  (approximately) equal probability.
 * <p>
 * The default implementation provided here returns
 * <pre>
 * <code>(int) (nextDouble() * Integer.MAX_VALUE)</code>
 * </pre></p>
 *
 * @return the next pseudorandom, uniformly distributed {@code int}
 *  value from this random number generator's sequence
 */
public int nextInt() {
    return (int) (nextDouble() * Integer.MAX_VALUE);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-640_98556fed,Major,src/main/java/org/apache/commons/math/random/AbstractRandomGenerator.java,178,180,"/**
 * Returns the next pseudorandom, uniformly distributed {@code long}
 * value from this random number generator's sequence.  All
 * 2<font size=""-1""><sup>64</sup></font> possible {@code long} values
 * should be produced with (approximately) equal probability.
 * <p>
 * The default implementation returns
 * <pre>
 * <code>(long) (nextDouble() * Long.MAX_VALUE)</code>
 * </pre></p>
 *
 * @return  the next pseudorandom, uniformly distributed {@code long}
 *value from this random number generator's sequence
 */
public long nextLong() {
    return (long) (nextDouble() * Long.MAX_VALUE);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-657_32b0f733,Minor,src/main/java/org/apache/commons/math/complex/Complex.java,245,273,"/**
 * Returns a {@code Complex} whose value is
 * {@code (this / divisor)}.
 * Implements the definitional formula
 * <pre>
 *  <code>
 *    a + bi          ac + bd + (bc - ad)i
 *    ----------- = -------------------------
 *    c + di         c<sup>2</sup> + d<sup>2</sup>
 *  </code>
 * </pre>
 * but uses
 * <a href=""http://doi.acm.org/10.1145/1039813.1039814"">
 * prescaling of operands</a> to limit the effects of overflows and
 * underflows in the computation.
 * <br/>
 * {@code Infinite} and {@code NaN} values are handled according to the
 * following rules, applied in the order presented:
 * <ul>
 *  <li>If either {@code this} or {@code divisor} has a {@code NaN} value
 *   in either part, {@link #NaN} is returned.
 *  </li>
 *  <li>If {@code divisor} equals {@link #ZERO}, {@link #NaN} is returned.
 *  </li>
 *  <li>If {@code this} and {@code divisor} are both infinite,
 *   {@link #NaN} is returned.
 *  </li>
 *  <li>If {@code this} is finite (i.e., has no {@code Infinite} or
 *   {@code NaN} parts) and {@code divisor} is infinite (one or both parts
 *   infinite), {@link #ZERO} is returned.
 *  </li>
 *  <li>If {@code this} is infinite and {@code divisor} is finite,
 *   {@code NaN} values are returned in the parts of the result if the
 *   {@link java.lang.Double} rules applied to the definitional formula
 *   force {@code NaN} results.
 *  </li>
 * </ul>
 *
 * @param divisor Value by which this {@code Complex} is to be divided.
 * @return {@code this / divisor}.
 * @throws NullArgumentException if {@code divisor} is {@code null}.
 */
public Complex divide(Complex divisor) throws NullArgumentException {
    MathUtils.checkNotNull(divisor);
    if (isNaN || divisor.isNaN) {
        return NaN;
    }
    final double c = divisor.getReal();
    final double d = divisor.getImaginary();
    if (c == 0.0 && d == 0.0) {
        return NaN;
    }
    if (divisor.isInfinite() && !isInfinite()) {
        return ZERO;
    }
    if (FastMath.abs(c) < FastMath.abs(d)) {
        double q = c / d;
        double denominator = c * q + d;
        return createComplex((real * q + imaginary) / denominator, (imaginary * q - real) / denominator);
    } else {
        double q = d / c;
        double denominator = d * q + c;
        return createComplex((imaginary * q + real) / denominator, (imaginary - real * q) / denominator);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-657_32b0f733,Minor,src/main/java/org/apache/commons/math/complex/Complex.java,283,295,"/**
 * Returns a {@code Complex} whose value is {@code (this / divisor)},
 * with {@code divisor} interpreted as a real number.
 *
 * @param  divisor Value by which this {@code Complex} is to be divided.
 * @return {@code this / divisor}.
 * @see #divide(Complex)
 */
public Complex divide(double divisor) {
    if (isNaN || Double.isNaN(divisor)) {
        return NaN;
    }
    if (divisor == 0d) {
        return NaN;
    }
    if (Double.isInfinite(divisor)) {
        return !isInfinite() ? ZERO : NaN;
    }
    return createComplex(real / divisor, imaginary / divisor);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-657_97b440fc,Minor,src/main/java/org/apache/commons/math/complex/Complex.java,251,280,"/**
 * Returns a {@code Complex} whose value is
 * {@code (this / divisor)}.
 * Implements the definitional formula
 * <pre>
 *  <code>
 *    a + bi          ac + bd + (bc - ad)i
 *    ----------- = -------------------------
 *    c + di         c<sup>2</sup> + d<sup>2</sup>
 *  </code>
 * </pre>
 * but uses
 * <a href=""http://doi.acm.org/10.1145/1039813.1039814"">
 * prescaling of operands</a> to limit the effects of overflows and
 * underflows in the computation.
 * <br/>
 * {@code Infinite} and {@code NaN} values are handled according to the
 * following rules, applied in the order presented:
 * <ul>
 *  <li>If either {@code this} or {@code divisor} has a {@code NaN} value
 *   in either part, {@link #NaN} is returned.
 *  </li>
 *  <li>If {@code this} and {@code divisor} are both {@link #ZERO},
 *   {@link #NaN} is returned.
 *  </li>
 *  <li>If {@code divisor} equals {@link #ZERO}, {@link #INF} is returned.
 *  </li>
 *  <li>If {@code this} and {@code divisor} are both infinite,
 *   {@link #NaN} is returned.
 *  </li>
 *  <li>If {@code this} is finite (i.e., has no {@code Infinite} or
 *   {@code NaN} parts) and {@code divisor} is infinite (one or both parts
 *   infinite), {@link #ZERO} is returned.
 *  </li>
 *  <li>If {@code this} is infinite and {@code divisor} is finite,
 *   {@code NaN} values are returned in the parts of the result if the
 *   {@link java.lang.Double} rules applied to the definitional formula
 *   force {@code NaN} results.
 *  </li>
 * </ul>
 *
 * @param divisor Value by which this {@code Complex} is to be divided.
 * @return {@code this / divisor}.
 * @throws NullArgumentException if {@code divisor} is {@code null}.
 */
public Complex divide(Complex divisor) throws NullArgumentException {
    MathUtils.checkNotNull(divisor);
    if (isNaN || divisor.isNaN) {
        return NaN;
    }
    if (divisor.isZero) {
        return isZero ? NaN : INF;
    }
    if (divisor.isInfinite() && !isInfinite()) {
        return ZERO;
    }
    final double c = divisor.getReal();
    final double d = divisor.getImaginary();
    if (FastMath.abs(c) < FastMath.abs(d)) {
        double q = c / d;
        double denominator = c * q + d;
        return createComplex((real * q + imaginary) / denominator, (imaginary * q - real) / denominator);
    } else {
        double q = d / c;
        double denominator = d * q + c;
        return createComplex((imaginary * q + real) / denominator, (imaginary - real * q) / denominator);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-657_97b440fc,Minor,src/main/java/org/apache/commons/math/complex/Complex.java,290,302,"/**
 * Returns a {@code Complex} whose value is {@code (this / divisor)},
 * with {@code divisor} interpreted as a real number.
 *
 * @param  divisor Value by which this {@code Complex} is to be divided.
 * @return {@code this / divisor}.
 * @see #divide(Complex)
 */
public Complex divide(double divisor) {
    if (isNaN || Double.isNaN(divisor)) {
        return NaN;
    }
    if (divisor == 0d) {
        return isZero ? NaN : INF;
    }
    if (Double.isInfinite(divisor)) {
        return !isInfinite() ? ZERO : NaN;
    }
    return createComplex(real / divisor, imaginary / divisor);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-691_118f0cc0,Minor,src/main/java/org/apache/commons/math/stat/descriptive/SummaryStatistics.java,149,168,"/**
 * Add a value to the data
 * @param value the value to add
 */
public void addValue(double value) {
    sumImpl.increment(value);
    sumsqImpl.increment(value);
    minImpl.increment(value);
    maxImpl.increment(value);
    sumLogImpl.increment(value);
    secondMoment.increment(value);
    // need to increment these
    if (!(meanImpl instanceof Mean)) {
        meanImpl.increment(value);
    }
    if (!(varianceImpl instanceof Variance)) {
        varianceImpl.increment(value);
    }
    if (!(geoMeanImpl instanceof GeometricMean)) {
        geoMeanImpl.increment(value);
    }
    n++;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-695_7980a242,Major,src/main/java/org/apache/commons/math/ode/AbstractIntegrator.java,275,375,"/**
 * Accept a step, triggering events and step handlers.
 * @param interpolator step interpolator
 * @param y state vector at step end time, must be reset if an event
 * asks for resetting or if an events stops integration during the step
 * @param yDot placeholder array where to put the time derivative of the state vector
 * @param tEnd final integration time
 * @return time at end of step
 * @exception MathIllegalStateException if the value of one event state cannot be evaluated
 * @since 2.2
 */
protected double acceptStep(final AbstractStepInterpolator interpolator, final double[] y, final double[] yDot, final double tEnd) throws MathIllegalStateException {
    double previousT = interpolator.getGlobalPreviousTime();
    final double currentT = interpolator.getGlobalCurrentTime();
    resetOccurred = false;
    // initialize the events states if needed
    if (!statesInitialized) {
        for (EventState state : eventsStates) {
            state.reinitializeBegin(interpolator);
        }
        statesInitialized = true;
    }
    // search for next events that may occur during the step
    final int orderingSign = interpolator.isForward() ? +1 : -1;
    SortedSet<EventState> occuringEvents = new TreeSet<EventState>(new Comparator<EventState>() {

        /**
         * {@inheritDoc}
         */
        public int compare(EventState es0, EventState es1) {
            return orderingSign * Double.compare(es0.getEventTime(), es1.getEventTime());
        }
    });
    for (final EventState state : eventsStates) {
        if (state.evaluateStep(interpolator)) {
            // the event occurs during the current step
            occuringEvents.add(state);
        }
    }
    while (!occuringEvents.isEmpty()) {
        // handle the chronologically first event
        final Iterator<EventState> iterator = occuringEvents.iterator();
        final EventState currentEvent = iterator.next();
        iterator.remove();
        // restrict the interpolator to the first part of the step, up to the event
        final double eventT = currentEvent.getEventTime();
        interpolator.setSoftPreviousTime(previousT);
        interpolator.setSoftCurrentTime(eventT);
        // trigger the event
        interpolator.setInterpolatedTime(eventT);
        final double[] eventY = interpolator.getInterpolatedState();
        currentEvent.stepAccepted(eventT, eventY);
        isLastStep = currentEvent.stop();
        // handle the first part of the step, up to the event
        for (final StepHandler handler : stepHandlers) {
            handler.handleStep(interpolator, isLastStep);
        }
        if (isLastStep) {
            // the event asked to stop integration
            System.arraycopy(eventY, 0, y, 0, y.length);
            return eventT;
        }
        if (currentEvent.reset(eventT, eventY)) {
            // some event handler has triggered changes that
            // invalidate the derivatives, we need to recompute them
            System.arraycopy(eventY, 0, y, 0, y.length);
            computeDerivatives(eventT, y, yDot);
            resetOccurred = true;
            return eventT;
        }
        // prepare handling of the remaining part of the step
        previousT = eventT;
        interpolator.setSoftPreviousTime(eventT);
        interpolator.setSoftCurrentTime(currentT);
        // check if the same event occurs again in the remaining part of the step
        if (currentEvent.evaluateStep(interpolator)) {
            // the event occurs during the current step
            occuringEvents.add(currentEvent);
        }
    }
    interpolator.setInterpolatedTime(currentT);
    final double[] currentY = interpolator.getInterpolatedState();
    for (final EventState state : eventsStates) {
        state.stepAccepted(currentT, currentY);
        isLastStep = isLastStep || state.stop();
    }
    isLastStep = isLastStep || Precision.equals(currentT, tEnd, 1);
    // handle the remaining part of the step, after all events if any
    for (StepHandler handler : stepHandlers) {
        handler.handleStep(interpolator, isLastStep);
    }
    return currentT;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-699_b2e24119,Minor,src/main/java/org/apache/commons/math/distribution/AbstractRealDistribution.java,71,116,"/**
 * {@inheritDoc}
 */
public double inverseCumulativeProbability(final double p) throws OutOfRangeException {
    if (p < 0.0 || p > 1.0) {
        throw new OutOfRangeException(p, 0, 1);
    }
    // by default, do simple root finding using bracketing and default solver.
    // subclasses can override if there is a better method.
    UnivariateFunction rootFindingFunction = new UnivariateFunction() {

        public double value(double x) {
            return cumulativeProbability(x) - p;
        }
    };
    // Try to bracket root, test domain endpoints if this fails
    double lowerBound = getDomainLowerBound(p);
    double upperBound = getDomainUpperBound(p);
    double[] bracket = null;
    try {
        bracket = UnivariateRealSolverUtils.bracket(rootFindingFunction, getInitialDomain(p), lowerBound, upperBound);
    } catch (NumberIsTooLargeException ex) {
        /*
             * Check domain endpoints to see if one gives value that is within
             * the default solver's defaultAbsoluteAccuracy of 0 (will be the
             * case if density has bounded support and p is 0 or 1).
             */
        if (FastMath.abs(rootFindingFunction.value(lowerBound)) < getSolverAbsoluteAccuracy()) {
            return lowerBound;
        }
        if (FastMath.abs(rootFindingFunction.value(upperBound)) < getSolverAbsoluteAccuracy()) {
            return upperBound;
        }
        // Failed bracket convergence was not because of corner solution
        throw new MathInternalError(ex);
    }
    // find root
    double root = UnivariateRealSolverUtils.solve(rootFindingFunction, // absolute accuracy different from the default.
    bracket[0], bracket[1], getSolverAbsoluteAccuracy());
    return root;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-699_b2e24119,Minor,src/main/java/org/apache/commons/math/distribution/AbstractRealDistribution.java,81,83,"public double value(double x) {
    return cumulativeProbability(x) - p;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-704_3f645310,Major,src/main/java/org/apache/commons/math/stat/descriptive/moment/Variance.java,501,532,"/**
 * Returns the weighted variance of the entries in the specified portion of
 * the input array, using the precomputed weighted mean value.  Returns
 * <code>Double.NaN</code> if the designated subarray is empty.
 * <p>
 * Uses the formula <pre>
 *   &Sigma;(weights[i]*(values[i] - mean)<sup>2</sup>)/(&Sigma;(weights[i]) - 1)
 * </pre></p>
 * <p>
 * The formula used assumes that the supplied mean value is the weighted arithmetic
 * mean of the sample data, not a known population parameter. This method
 * is supplied only to save computation when the mean has already been
 * computed.</p>
 * <p>
 * This formula will not return the same result as the unweighted variance when all
 * weights are equal, unless all weights are equal to 1. The formula assumes that
 * weights are to be treated as ""expansion values,"" as will be the case if for example
 * the weights represent frequency counts. To normalize weights so that the denominator
 * in the variance computation equals the length of the input vector minus one, use <pre>
 *   <code>evaluate(values, MathArrays.normalizeArray(weights, values.length), mean); </code>
 * </pre>
 * <p>
 * Returns 0 for a single-value (i.e. length = 1) sample.</p>
 * <p>
 * Throws <code>IllegalArgumentException</code> if any of the following are true:
 * <ul><li>the values array is null</li>
 *     <li>the weights array is null</li>
 *     <li>the weights array does not have the same length as the values array</li>
 *     <li>the weights array contains one or more infinite values</li>
 *     <li>the weights array contains one or more NaN values</li>
 *     <li>the weights array contains negative values</li>
 *     <li>the start and length arguments do not determine a valid array</li>
 * </ul></p>
 * <p>
 * Does not change the internal state of the statistic.</p>
 *
 * @param values the input array
 * @param weights the weights array
 * @param mean the precomputed weighted mean value
 * @param begin index of the first array element to include
 * @param length the number of elements to include
 * @return the variance of the values or Double.NaN if length = 0
 * @throws IllegalArgumentException if the parameters are not valid
 * @since 2.1
 */
public double evaluate(final double[] values, final double[] weights, final double mean, final int begin, final int length) {
    double var = Double.NaN;
    if (test(values, weights, begin, length)) {
        if (length == 1) {
            var = 0.0;
        } else if (length > 1) {
            double accum = 0.0;
            double dev = 0.0;
            double accum2 = 0.0;
            for (int i = begin; i < begin + length; i++) {
                dev = values[i] - mean;
                accum += weights[i] * (dev * dev);
                accum2 += weights[i] * dev;
            }
            double sumWts = 0;
            for (int i = 0; i < weights.length; i++) {
                sumWts += weights[i];
            }
            if (isBiasCorrected) {
                var = (accum - (accum2 * accum2 / sumWts)) / (sumWts - 1.0);
            } else {
                var = (accum - (accum2 * accum2 / sumWts)) / sumWts;
            }
        }
    }
    return var;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-705_645d642b,Major,src/main/java/org/apache/commons/math/ode/nonstiff/DormandPrince853StepInterpolator.java,314,385,"/**
 * {@inheritDoc}
 */
@Override
protected void computeInterpolatedStateAndDerivatives(final double theta, final double oneMinusThetaH) {
    if (!vectorsInitialized) {
        if (v == null) {
            v = new double[7][];
            for (int k = 0; k < 7; ++k) {
                v[k] = new double[interpolatedState.length];
            }
        }
        // perform the last evaluations if they have not been done yet
        finalizeStep();
        // compute the interpolation vectors for this time step
        for (int i = 0; i < interpolatedState.length; ++i) {
            final double yDot1 = yDotK[0][i];
            final double yDot6 = yDotK[5][i];
            final double yDot7 = yDotK[6][i];
            final double yDot8 = yDotK[7][i];
            final double yDot9 = yDotK[8][i];
            final double yDot10 = yDotK[9][i];
            final double yDot11 = yDotK[10][i];
            final double yDot12 = yDotK[11][i];
            final double yDot13 = yDotK[12][i];
            final double yDot14 = yDotKLast[0][i];
            final double yDot15 = yDotKLast[1][i];
            final double yDot16 = yDotKLast[2][i];
            v[0][i] = B_01 * yDot1 + B_06 * yDot6 + B_07 * yDot7 + B_08 * yDot8 + B_09 * yDot9 + B_10 * yDot10 + B_11 * yDot11 + B_12 * yDot12;
            v[1][i] = yDot1 - v[0][i];
            v[2][i] = v[0][i] - v[1][i] - yDotK[12][i];
            for (int k = 0; k < D.length; ++k) {
                v[k + 3][i] = D[k][0] * yDot1 + D[k][1] * yDot6 + D[k][2] * yDot7 + D[k][3] * yDot8 + D[k][4] * yDot9 + D[k][5] * yDot10 + D[k][6] * yDot11 + D[k][7] * yDot12 + D[k][8] * yDot13 + D[k][9] * yDot14 + D[k][10] * yDot15 + D[k][11] * yDot16;
            }
        }
        vectorsInitialized = true;
    }
    final double eta = 1 - theta;
    final double twoTheta = 2 * theta;
    final double theta2 = theta * theta;
    final double dot1 = 1 - twoTheta;
    final double dot2 = theta * (2 - 3 * theta);
    final double dot3 = twoTheta * (1 + theta * (twoTheta - 3));
    final double dot4 = theta2 * (3 + theta * (5 * theta - 8));
    final double dot5 = theta2 * (3 + theta * (-12 + theta * (15 - 6 * theta)));
    final double dot6 = theta2 * theta * (4 + theta * (-15 + theta * (18 - 7 * theta)));
    for (int i = 0; i < interpolatedState.length; ++i) {
        interpolatedState[i] = currentState[i] - oneMinusThetaH * (v[0][i] - theta * (v[1][i] + theta * (v[2][i] + eta * (v[3][i] + theta * (v[4][i] + eta * (v[5][i] + theta * (v[6][i])))))));
        interpolatedDerivatives[i] = v[0][i] + dot1 * v[1][i] + dot2 * v[2][i] + dot3 * v[3][i] + dot4 * v[4][i] + dot5 * v[5][i] + dot6 * v[6][i];
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-705_645d642b,Major,src/main/java/org/apache/commons/math/ode/nonstiff/EmbeddedRungeKuttaIntegrator.java,191,332,"/**
 * {@inheritDoc}
 */
@Override
public void integrate(final ExpandableStatefulODE equations, final double t) throws MathIllegalStateException, MathIllegalArgumentException {
    sanityChecks(equations, t);
    setEquations(equations);
    resetEvaluations();
    final boolean forward = t > equations.getTime();
    // create some internal working arrays
    final double[] y0 = equations.getCompleteState();
    final double[] y = y0.clone();
    final int stages = c.length + 1;
    final double[][] yDotK = new double[stages][y.length];
    final double[] yTmp = new double[y.length];
    final double[] yDotTmp = new double[y.length];
    // set up an interpolator sharing the integrator arrays
    final RungeKuttaStepInterpolator interpolator = (RungeKuttaStepInterpolator) prototype.copy();
    interpolator.reinitialize(this, yTmp, yDotK, forward, equations.getPrimaryMapper(), equations.getSecondaryMappers());
    interpolator.storeTime(equations.getTime());
    // set up integration control objects
    stepStart = equations.getTime();
    double hNew = 0;
    boolean firstTime = true;
    for (StepHandler handler : stepHandlers) {
        handler.reset();
    }
    setStateInitialized(false);
    // main integration loop
    isLastStep = false;
    do {
        interpolator.shift();
        // iterate over step size, ensuring local normalized error is smaller than 1
        double error = 10;
        while (error >= 1.0) {
            if (firstTime || !fsal) {
                // first stage
                computeDerivatives(stepStart, y, yDotK[0]);
            }
            if (firstTime) {
                final double[] scale = new double[mainSetDimension];
                if (vecAbsoluteTolerance == null) {
                    for (int i = 0; i < scale.length; ++i) {
                        scale[i] = scalAbsoluteTolerance + scalRelativeTolerance * FastMath.abs(y[i]);
                    }
                } else {
                    for (int i = 0; i < scale.length; ++i) {
                        scale[i] = vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * FastMath.abs(y[i]);
                    }
                }
                hNew = initializeStep(forward, getOrder(), scale, stepStart, y, yDotK[0], yTmp, yDotK[1]);
                firstTime = false;
            }
            stepSize = hNew;
            // next stages
            for (int k = 1; k < stages; ++k) {
                for (int j = 0; j < y0.length; ++j) {
                    double sum = a[k - 1][0] * yDotK[0][j];
                    for (int l = 1; l < k; ++l) {
                        sum += a[k - 1][l] * yDotK[l][j];
                    }
                    yTmp[j] = y[j] + stepSize * sum;
                }
                computeDerivatives(stepStart + c[k - 1] * stepSize, yTmp, yDotK[k]);
            }
            // estimate the state at the end of the step
            for (int j = 0; j < y0.length; ++j) {
                double sum = b[0] * yDotK[0][j];
                for (int l = 1; l < stages; ++l) {
                    sum += b[l] * yDotK[l][j];
                }
                yTmp[j] = y[j] + stepSize * sum;
            }
            // estimate the error at the end of the step
            error = estimateError(yDotK, y, yTmp, stepSize);
            if (error >= 1.0) {
                // reject the step and attempt to reduce error by stepsize control
                final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp)));
                hNew = filterStep(stepSize * factor, forward, false);
            }
        }
        // local error is small enough: accept the step, trigger events and step handlers
        interpolator.storeTime(stepStart + stepSize);
        System.arraycopy(yTmp, 0, y, 0, y0.length);
        System.arraycopy(yDotK[stages - 1], 0, yDotTmp, 0, y0.length);
        stepStart = acceptStep(interpolator, y, yDotTmp, t);
        if (!isLastStep) {
            // prepare next step
            interpolator.storeTime(stepStart);
            if (fsal) {
                // save the last evaluation for the next step
                System.arraycopy(yDotTmp, 0, yDotK[0], 0, y0.length);
            }
            // stepsize control for next step
            final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp)));
            final double scaledH = stepSize * factor;
            final double nextT = stepStart + scaledH;
            final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t);
            hNew = filterStep(scaledH, forward, nextIsLast);
            final double filteredNextT = stepStart + hNew;
            final boolean filteredNextIsLast = forward ? (filteredNextT >= t) : (filteredNextT <= t);
            if (filteredNextIsLast) {
                hNew = t - stepStart;
            }
        }
    } while (!isLastStep);
    // dispatch results
    equations.setTime(stepStart);
    equations.setCompleteState(y);
    resetInternalState();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-705_645d642b,Major,src/main/java/org/apache/commons/math/ode/nonstiff/RungeKuttaIntegrator.java,93,188,"/**
 * {@inheritDoc}
 */
@Override
public void integrate(final ExpandableStatefulODE equations, final double t) throws MathIllegalStateException, MathIllegalArgumentException {
    sanityChecks(equations, t);
    setEquations(equations);
    resetEvaluations();
    final boolean forward = t > equations.getTime();
    // create some internal working arrays
    final double[] y0 = equations.getCompleteState();
    final double[] y = y0.clone();
    final int stages = c.length + 1;
    final double[][] yDotK = new double[stages][];
    for (int i = 0; i < stages; ++i) {
        yDotK[i] = new double[y0.length];
    }
    final double[] yTmp = new double[y0.length];
    final double[] yDotTmp = new double[y0.length];
    // set up an interpolator sharing the integrator arrays
    final RungeKuttaStepInterpolator interpolator = (RungeKuttaStepInterpolator) prototype.copy();
    interpolator.reinitialize(this, yTmp, yDotK, forward, equations.getPrimaryMapper(), equations.getSecondaryMappers());
    interpolator.storeTime(equations.getTime());
    // set up integration control objects
    stepStart = equations.getTime();
    stepSize = forward ? step : -step;
    for (StepHandler handler : stepHandlers) {
        handler.reset();
    }
    setStateInitialized(false);
    // main integration loop
    isLastStep = false;
    do {
        interpolator.shift();
        // first stage
        computeDerivatives(stepStart, y, yDotK[0]);
        // next stages
        for (int k = 1; k < stages; ++k) {
            for (int j = 0; j < y0.length; ++j) {
                double sum = a[k - 1][0] * yDotK[0][j];
                for (int l = 1; l < k; ++l) {
                    sum += a[k - 1][l] * yDotK[l][j];
                }
                yTmp[j] = y[j] + stepSize * sum;
            }
            computeDerivatives(stepStart + c[k - 1] * stepSize, yTmp, yDotK[k]);
        }
        // estimate the state at the end of the step
        for (int j = 0; j < y0.length; ++j) {
            double sum = b[0] * yDotK[0][j];
            for (int l = 1; l < stages; ++l) {
                sum += b[l] * yDotK[l][j];
            }
            yTmp[j] = y[j] + stepSize * sum;
        }
        // discrete events handling
        interpolator.storeTime(stepStart + stepSize);
        System.arraycopy(yTmp, 0, y, 0, y0.length);
        System.arraycopy(yDotK[stages - 1], 0, yDotTmp, 0, y0.length);
        stepStart = acceptStep(interpolator, y, yDotTmp, t);
        if (!isLastStep) {
            // prepare next step
            interpolator.storeTime(stepStart);
            // stepsize control for next step
            final double nextT = stepStart + stepSize;
            final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t);
            if (nextIsLast) {
                stepSize = t - stepStart;
            }
        }
    } while (!isLastStep);
    // dispatch results
    equations.setTime(stepStart);
    equations.setCompleteState(y);
    stepStart = Double.NaN;
    stepSize = Double.NaN;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-705_645d642b,Major,src/main/java/org/apache/commons/math/ode/nonstiff/RungeKuttaStepInterpolator.java,127,134,"/**
 * Reinitialize the instance
 * <p>Some Runge-Kutta integrators need fewer functions evaluations
 * than their counterpart step interpolators. So the interpolator
 * should perform the last evaluations they need by themselves. The
 * {@link RungeKuttaIntegrator RungeKuttaIntegrator} and {@link
 * EmbeddedRungeKuttaIntegrator EmbeddedRungeKuttaIntegrator}
 * abstract classes call this method in order to let the step
 * interpolator perform the evaluations it needs. These evaluations
 * will be performed during the call to <code>doFinalize</code> if
 * any, i.e. only if the step handler either calls the {@link
 * AbstractStepInterpolator#finalizeStep finalizeStep} method or the
 * {@link AbstractStepInterpolator#getInterpolatedState
 * getInterpolatedState} method (for an interpolator which needs a
 * finalization) or if it clones the step interpolator.</p>
 * @param rkIntegrator integrator being used
 * @param y reference to the integrator array holding the state at
 * the end of the step
 * @param yDotArray reference to the integrator array holding all the
 * intermediate slopes
 * @param forward integration direction indicator
 * @param primaryMapper equations mapper for the primary equations set
 * @param secondaryMappers equations mappers for the secondary equations sets
 */
public void reinitialize(final AbstractIntegrator rkIntegrator, final double[] y, final double[][] yDotArray, final boolean forward, final EquationsMapper primaryMapper, final EquationsMapper[] secondaryMappers) {
    reinitialize(y, forward, primaryMapper, secondaryMappers);
    this.yDotK = yDotArray;
    this.integrator = rkIntegrator;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-705_645d642b,Major,src/main/java/org/apache/commons/math/ode/nonstiff/RungeKuttaStepInterpolator.java,137,156,"/**
 * {@inheritDoc}
 */
@Override
public void writeExternal(final ObjectOutput out) throws IOException {
    // save the state of the base class
    writeBaseExternal(out);
    // save the local attributes
    final int n = (currentState == null) ? -1 : currentState.length;
    final int kMax = (yDotK == null) ? -1 : yDotK.length;
    out.writeInt(kMax);
    for (int k = 0; k < kMax; ++k) {
        for (int i = 0; i < n; ++i) {
            out.writeDouble(yDotK[k][i]);
        }
    }
// we do not save any reference to the equations
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-705_645d642b,Major,src/main/java/org/apache/commons/math/ode/nonstiff/RungeKuttaStepInterpolator.java,159,186,"/**
 * {@inheritDoc}
 */
@Override
public void readExternal(final ObjectInput in) throws IOException, ClassNotFoundException {
    // read the base class
    final double t = readBaseExternal(in);
    // read the local attributes
    final int n = (currentState == null) ? -1 : currentState.length;
    final int kMax = in.readInt();
    yDotK = (kMax < 0) ? null : new double[kMax][];
    for (int k = 0; k < kMax; ++k) {
        yDotK[k] = (n < 0) ? null : new double[n];
        for (int i = 0; i < n; ++i) {
            yDotK[k][i] = in.readDouble();
        }
    }
    integrator = null;
    if (currentState != null) {
        // we can now set the interpolated time and state
        setInterpolatedTime(t);
    } else {
        interpolatedTime = t;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-713_f656676e,Major,src/main/java/org/apache/commons/math/optimization/linear/SimplexTableau.java,396,422,"/**
 * Get the current solution.
 *
 * @return current solution
 */
protected RealPointValuePair getSolution() {
    int negativeVarColumn = columnLabels.indexOf(NEGATIVE_VAR_COLUMN_LABEL);
    Integer negativeVarBasicRow = negativeVarColumn > 0 ? getBasicRow(negativeVarColumn) : null;
    double mostNegative = negativeVarBasicRow == null ? 0 : getEntry(negativeVarBasicRow, getRhsOffset());
    Set<Integer> basicRows = new HashSet<Integer>();
    double[] coefficients = new double[getOriginalNumDecisionVariables()];
    for (int i = 0; i < coefficients.length; i++) {
        int colIndex = columnLabels.indexOf(""x"" + i);
        if (colIndex < 0) {
            coefficients[i] = 0;
            continue;
        }
        Integer basicRow = getBasicRow(colIndex);
        if (basicRows.contains(basicRow)) {
            // if multiple variables can take a given value
            // then we choose the first and set the rest equal to 0
            coefficients[i] = 0 - (restrictToNonNegative ? 0 : mostNegative);
        } else {
            basicRows.add(basicRow);
            coefficients[i] = (basicRow == null ? 0 : getEntry(basicRow, getRhsOffset())) - (restrictToNonNegative ? 0 : mostNegative);
        }
    }
    return new RealPointValuePair(coefficients, f.getValue(coefficients));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-716_faa77857,Minor,src/main/java/org/apache/commons/math/analysis/solvers/BracketingNthOrderBrentSolver.java,142,345,"/**
 * {@inheritDoc}
 */
@Override
protected double doSolve() {
    // prepare arrays with the first points
    final double[] x = new double[maximalOrder + 1];
    final double[] y = new double[maximalOrder + 1];
    x[0] = getMin();
    x[1] = getStartValue();
    x[2] = getMax();
    verifySequence(x[0], x[1], x[2]);
    // evaluate initial guess
    y[1] = computeObjectiveValue(x[1]);
    if (Precision.equals(y[1], 0.0, 1)) {
        // return the initial guess if it is a perfect root.
        return x[1];
    }
    // evaluate first  endpoint
    y[0] = computeObjectiveValue(x[0]);
    if (Precision.equals(y[0], 0.0, 1)) {
        // return the first endpoint if it is a perfect root.
        return x[0];
    }
    int nbPoints;
    int signChangeIndex;
    if (y[0] * y[1] < 0) {
        // reduce interval if it brackets the root
        nbPoints = 2;
        signChangeIndex = 1;
    } else {
        // evaluate second endpoint
        y[2] = computeObjectiveValue(x[2]);
        if (Precision.equals(y[2], 0.0, 1)) {
            // return the second endpoint if it is a perfect root.
            return x[2];
        }
        if (y[1] * y[2] < 0) {
            // use all computed point as a start sampling array for solving
            nbPoints = 3;
            signChangeIndex = 2;
        } else {
            throw new NoBracketingException(x[0], x[2], y[0], y[2]);
        }
    }
    // prepare a work array for inverse polynomial interpolation
    final double[] tmpX = new double[x.length];
    // current tightest bracketing of the root
    double xA = x[signChangeIndex - 1];
    double yA = y[signChangeIndex - 1];
    double absYA = FastMath.abs(yA);
    int agingA = 0;
    double xB = x[signChangeIndex];
    double yB = y[signChangeIndex];
    double absYB = FastMath.abs(yB);
    int agingB = 0;
    // search loop
    while (true) {
        // check convergence of bracketing interval
        final double xTol = getAbsoluteAccuracy() + getRelativeAccuracy() * FastMath.max(FastMath.abs(xA), FastMath.abs(xB));
        if (((xB - xA) <= xTol) || (FastMath.max(absYA, absYB) < getFunctionValueAccuracy())) {
            switch(allowed) {
                case ANY_SIDE:
                    return absYA < absYB ? xA : xB;
                case LEFT_SIDE:
                    return xA;
                case RIGHT_SIDE:
                    return xB;
                case BELOW_SIDE:
                    return (yA <= 0) ? xA : xB;
                case ABOVE_SIDE:
                    return (yA < 0) ? xB : xA;
                default:
                    // this should never happen
                    throw new MathInternalError(null);
            }
        }
        // target for the next evaluation point
        double targetY;
        if (agingA >= MAXIMAL_AGING) {
            // we keep updating the high bracket, try to compensate this
            targetY = -REDUCTION_FACTOR * yB;
        } else if (agingB >= MAXIMAL_AGING) {
            // we keep updating the low bracket, try to compensate this
            targetY = -REDUCTION_FACTOR * yA;
        } else {
            // bracketing is balanced, try to find the root itself
            targetY = 0;
        }
        // make a few attempts to guess a root,
        double nextX;
        int start = 0;
        int end = nbPoints;
        do {
            // guess a value for current target, using inverse polynomial interpolation
            System.arraycopy(x, start, tmpX, start, end - start);
            nextX = guessX(targetY, tmpX, y, start, end);
            if (!((nextX > xA) && (nextX < xB))) {
                // we try again with a lower interpolation order
                if (signChangeIndex - start >= end - signChangeIndex) {
                    // we have more points before the sign change, drop the lowest point
                    ++start;
                } else {
                    // we have more points after sign change, drop the highest point
                    --end;
                }
                // we need to do one more attempt
                nextX = Double.NaN;
            }
        } while (Double.isNaN(nextX) && (end - start > 1));
        if (Double.isNaN(nextX)) {
            // fall back to bisection
            nextX = xA + 0.5 * (xB - xA);
            start = signChangeIndex - 1;
            end = signChangeIndex;
        }
        // evaluate the function at the guessed root
        final double nextY = computeObjectiveValue(nextX);
        if (Precision.equals(nextY, 0.0, 1)) {
            // we don't need to bother about the allowed solutions setting
            return nextX;
        }
        if ((nbPoints > 2) && (end - start != nbPoints)) {
            // we have been forced to ignore some points to keep bracketing,
            // they are probably too far from the root, drop them from now on
            nbPoints = end - start;
            System.arraycopy(x, start, x, 0, nbPoints);
            System.arraycopy(y, start, y, 0, nbPoints);
            signChangeIndex -= start;
        } else if (nbPoints == x.length) {
            // we have to drop one point in order to insert the new one
            nbPoints--;
            // keep the tightest bracketing interval as centered as possible
            if (signChangeIndex >= (x.length + 1) / 2) {
                // we drop the lowest point, we have to shift the arrays and the index
                System.arraycopy(x, 1, x, 0, nbPoints);
                System.arraycopy(y, 1, y, 0, nbPoints);
                --signChangeIndex;
            }
        }
        // insert the last computed point
        // (by construction, we know it lies inside the tightest bracketing interval)
        System.arraycopy(x, signChangeIndex, x, signChangeIndex + 1, nbPoints - signChangeIndex);
        x[signChangeIndex] = nextX;
        System.arraycopy(y, signChangeIndex, y, signChangeIndex + 1, nbPoints - signChangeIndex);
        y[signChangeIndex] = nextY;
        ++nbPoints;
        // update the bracketing interval
        if (nextY * yA <= 0) {
            // the sign change occurs before the inserted point
            xB = nextX;
            yB = nextY;
            absYB = FastMath.abs(yB);
            ++agingA;
            agingB = 0;
        } else {
            // the sign change occurs after the inserted point
            xA = nextX;
            yA = nextY;
            absYA = FastMath.abs(yA);
            agingA = 0;
            ++agingB;
            // update the sign change index
            signChangeIndex++;
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-718_3a08bfa6,Major,src/main/java/org/apache/commons/math3/util/ContinuedFraction.java,124,199,"/**
 * <p>
 * Evaluates the continued fraction at the value x.
 * </p>
 *
 * <p>
 * The implementation of this method is based on equations 14-17 of:
 * <ul>
 * <li>
 *   Eric W. Weisstein. ""Continued Fraction."" From MathWorld--A Wolfram Web
 *   Resource. <a target=""_blank""
 *   href=""http://mathworld.wolfram.com/ContinuedFraction.html"">
 *   http://mathworld.wolfram.com/ContinuedFraction.html</a>
 * </li>
 * </ul>
 * The recurrence relationship defined in those equations can result in
 * very large intermediate results which can result in numerical overflow.
 * As a means to combat these overflow conditions, the intermediate results
 * are scaled whenever they threaten to become numerically unstable.</p>
 *
 * @param x the evaluation point.
 * @param epsilon maximum error allowed.
 * @param maxIterations maximum number of convergents
 * @return the value of the continued fraction evaluated at x.
 * @throws ConvergenceException if the algorithm fails to converge.
 */
public double evaluate(double x, double epsilon, int maxIterations) {
    double p0 = 1.0;
    double p1 = getA(0, x);
    double q0 = 0.0;
    double q1 = 1.0;
    double c = p1 / q1;
    int n = 0;
    double relativeError = Double.MAX_VALUE;
    while (n < maxIterations && relativeError > epsilon) {
        ++n;
        double a = getA(n, x);
        double b = getB(n, x);
        double p2 = a * p1 + b * p0;
        double q2 = a * q1 + b * q0;
        boolean infinite = false;
        if (Double.isInfinite(p2) || Double.isInfinite(q2)) {
            /*
                 * Need to scale. Try successive powers of the larger of a or b
                 * up to 5th power. Throw ConvergenceException if one or both
                 * of p2, q2 still overflow.
                 */
            double scaleFactor = 1d;
            double lastScaleFactor = 1d;
            final int maxPower = 5;
            final double scale = FastMath.max(a, b);
            if (scale <= 0) {
                // Can't scale
                throw new ConvergenceException(LocalizedFormats.CONTINUED_FRACTION_INFINITY_DIVERGENCE, x);
            }
            infinite = true;
            for (int i = 0; i < maxPower; i++) {
                lastScaleFactor = scaleFactor;
                scaleFactor *= scale;
                if (a != 0.0 && a > b) {
                    p2 = p1 / lastScaleFactor + (b / scaleFactor * p0);
                    q2 = q1 / lastScaleFactor + (b / scaleFactor * q0);
                } else if (b != 0) {
                    p2 = (a / scaleFactor * p1) + p0 / lastScaleFactor;
                    q2 = (a / scaleFactor * q1) + q0 / lastScaleFactor;
                }
                infinite = Double.isInfinite(p2) || Double.isInfinite(q2);
                if (!infinite) {
                    break;
                }
            }
        }
        if (infinite) {
            // Scaling failed
            throw new ConvergenceException(LocalizedFormats.CONTINUED_FRACTION_INFINITY_DIVERGENCE, x);
        }
        double r = p2 / q2;
        if (Double.isNaN(r)) {
            throw new ConvergenceException(LocalizedFormats.CONTINUED_FRACTION_NAN_DIVERGENCE, x);
        }
        relativeError = FastMath.abs(r / c - 1.0);
        // prepare for next iteration
        c = p2 / q2;
        p0 = p1;
        p1 = p2;
        q0 = q1;
        q1 = q2;
    }
    if (n >= maxIterations) {
        throw new MaxCountExceededException(LocalizedFormats.NON_CONVERGENT_CONTINUED_FRACTION, maxIterations, x);
    }
    return c;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-722_95d15eff,Minor,src/main/java/org/apache/commons/math/complex/Complex.java,1017,1028,"/**
 * Compute the
 * <a href=""http://mathworld.wolfram.com/Tangent.html"" TARGET=""_top"">
 * tangent</a> of this complex number.
 * Implements the formula:
 * <pre>
 *  <code>
 *   tan(a + bi) = sin(2a)/(cos(2a)+cosh(2b)) + [sinh(2b)/(cos(2a)+cosh(2b))]i
 *  </code>
 * </pre>
 * where the (real) functions on the right-hand side are
 * {@link java.lang.Math#sin}, {@link java.lang.Math#cos},
 * {@link FastMath#cosh} and {@link FastMath#sinh}.
 * <br/>
 * Returns {@link Complex#NaN} if either real or imaginary part of the
 * input argument is {@code NaN}.
 * <br/>
 * Infinite (or critical) values in real or imaginary parts of the input may
 * result in infinite or NaN values returned in parts of the result.
 * <pre>
 *  Examples:
 *  <code>
 *   tan(1 &plusmn; INFINITY i) = 0 + NaN i
 *   tan(&plusmn;INFINITY + i) = NaN + NaN i
 *   tan(&plusmn;INFINITY &plusmn; INFINITY i) = NaN + NaN i
 *   tan(&plusmn;&pi;/2 + 0 i) = &plusmn;INFINITY + NaN i
 *  </code>
 * </pre>
 *
 * @return the tangent of {@code this}.
 * @since 1.2
 */
public Complex tan() {
    if (isNaN) {
        return NaN;
    }
    double real2 = 2.0 * real;
    double imaginary2 = 2.0 * imaginary;
    double d = FastMath.cos(real2) + FastMath.cosh(imaginary2);
    return createComplex(FastMath.sin(real2) / d, FastMath.sinh(imaginary2) / d);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-722_95d15eff,Minor,src/main/java/org/apache/commons/math/complex/Complex.java,1062,1073,"/**
 * Compute the
 * <a href=""http://mathworld.wolfram.com/HyperbolicTangent.html"" TARGET=""_top"">
 * hyperbolic tangent</a> of this complex number.
 * Implements the formula:
 * <pre>
 *  <code>
 *   tan(a + bi) = sinh(2a)/(cosh(2a)+cos(2b)) + [sin(2b)/(cosh(2a)+cos(2b))]i
 *  </code>
 * </pre>
 * where the (real) functions on the right-hand side are
 * {@link java.lang.Math#sin}, {@link java.lang.Math#cos},
 * {@link FastMath#cosh} and {@link FastMath#sinh}.
 * <br/>
 * Returns {@link Complex#NaN} if either real or imaginary part of the
 * input argument is {@code NaN}.
 * <br/>
 * Infinite values in real or imaginary parts of the input may result in
 * infinite or NaN values returned in parts of the result.
 * <pre>
 *  Examples:
 *  <code>
 *   tanh(1 &plusmn; INFINITY i) = NaN + NaN i
 *   tanh(&plusmn;INFINITY + i) = NaN + 0 i
 *   tanh(&plusmn;INFINITY &plusmn; INFINITY i) = NaN + NaN i
 *   tanh(0 + (&pi;/2)i) = NaN + INFINITY i
 *  </code>
 * </pre>
 *
 * @return the hyperbolic tangent of {@code this}.
 * @since 1.2
 */
public Complex tanh() {
    if (isNaN) {
        return NaN;
    }
    double real2 = 2.0 * real;
    double imaginary2 = 2.0 * imaginary;
    double d = FastMath.cosh(real2) + FastMath.cos(imaginary2);
    return createComplex(FastMath.sinh(real2) / d, FastMath.sin(imaginary2) / d);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-723_1352a70f,Major,src/main/java/org/apache/commons/math/random/ISAACRandom.java,202,238,"/**
 * Initialize, or reinitialize, this instance of rand.
 */
private void initState() {
    a = b = c = 0;
    for (i = 0; i < arr.length; i++) {
        arr[i] = GLD_RATIO;
    }
    for (i = 0; i < 4; i++) {
        shuffle();
    }
    // fill in mem[] with messy stuff
    for (i = 0; i < SIZE; i += 8) {
        arr[0] += rsl[i];
        arr[1] += rsl[i + 1];
        arr[2] += rsl[i + 2];
        arr[3] += rsl[i + 3];
        arr[4] += rsl[i + 4];
        arr[5] += rsl[i + 5];
        arr[6] += rsl[i + 6];
        arr[7] += rsl[i + 7];
        shuffle();
        setState();
    }
    // second pass makes all of seed affect all of mem
    for (i = 0; i < SIZE; i += 8) {
        arr[0] += mem[i];
        arr[1] += mem[i + 1];
        arr[2] += mem[i + 2];
        arr[3] += mem[i + 3];
        arr[4] += mem[i + 4];
        arr[5] += mem[i + 5];
        arr[6] += mem[i + 6];
        arr[7] += mem[i + 7];
        shuffle();
        setState();
    }
    isaac();
    count = SIZE - 1;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-724_9c8bb934,Major,src/main/java/org/apache/commons/math/random/RandomDataImpl.java,247,254,"/**
 * Generate a random int value uniformly distributed between
 * <code>lower</code> and <code>upper</code>, inclusive.
 *
 * @param lower
 *            the lower bound.
 * @param upper
 *            the upper bound.
 * @return the random integer.
 * @throws NumberIsTooLargeException if {@code lower >= upper}.
 */
public int nextInt(int lower, int upper) {
    if (lower >= upper) {
        throw new NumberIsTooLargeException(LocalizedFormats.LOWER_BOUND_NOT_BELOW_UPPER_BOUND, lower, upper, false);
    }
    double r = getRan().nextDouble();
    return (int) ((r * upper) + ((1.0 - r) * lower) + r);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-724_9c8bb934,Major,src/main/java/org/apache/commons/math/random/RandomDataImpl.java,267,274,"/**
 * Generate a random long value uniformly distributed between
 * <code>lower</code> and <code>upper</code>, inclusive.
 *
 * @param lower
 *            the lower bound.
 * @param upper
 *            the upper bound.
 * @return the random integer.
 * @throws NumberIsTooLargeException if {@code lower >= upper}.
 */
public long nextLong(long lower, long upper) {
    if (lower >= upper) {
        throw new NumberIsTooLargeException(LocalizedFormats.LOWER_BOUND_NOT_BELOW_UPPER_BOUND, lower, upper, false);
    }
    double r = getRan().nextDouble();
    return (long) ((r * upper) + ((1.0 - r) * lower) + r);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-724_9c8bb934,Major,src/main/java/org/apache/commons/math/random/RandomDataImpl.java,358,365,"/**
 * Generate a random int value uniformly distributed between
 * <code>lower</code> and <code>upper</code>, inclusive. This algorithm uses
 * a secure random number generator.
 *
 * @param lower
 *            the lower bound.
 * @param upper
 *            the upper bound.
 * @return the random integer.
 * @throws NumberIsTooLargeException if {@code lower >= upper}.
 */
public int nextSecureInt(int lower, int upper) {
    if (lower >= upper) {
        throw new NumberIsTooLargeException(LocalizedFormats.LOWER_BOUND_NOT_BELOW_UPPER_BOUND, lower, upper, false);
    }
    SecureRandom sec = getSecRan();
    return lower + (int) (sec.nextDouble() * (upper - lower + 1));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-724_9c8bb934,Major,src/main/java/org/apache/commons/math/random/RandomDataImpl.java,379,386,"/**
 * Generate a random long value uniformly distributed between
 * <code>lower</code> and <code>upper</code>, inclusive. This algorithm uses
 * a secure random number generator.
 *
 * @param lower
 *            the lower bound.
 * @param upper
 *            the upper bound.
 * @return the random integer.
 * @throws NumberIsTooLargeException if {@code lower >= upper}.
 */
public long nextSecureLong(long lower, long upper) {
    if (lower >= upper) {
        throw new NumberIsTooLargeException(LocalizedFormats.LOWER_BOUND_NOT_BELOW_UPPER_BOUND, lower, upper, false);
    }
    SecureRandom sec = getSecRan();
    return lower + (long) (sec.nextDouble() * (upper - lower + 1));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-724_9c8bb934,Major,src/main/java/org/apache/commons/math/random/RandomDataImpl.java,590,604,"/**
 * {@inheritDoc}
 * <p>
 * <strong>Algorithm Description</strong>: scales the output of
 * Random.nextDouble(), but rejects 0 values (i.e., will generate another
 * random double if Random.nextDouble() returns 0). This is necessary to
 * provide a symmetric output interval (both endpoints excluded).
 * </p>
 *
 * @param lower
 *            the lower bound.
 * @param upper
 *            the upper bound.
 * @return a uniformly distributed random value from the interval (lower,
 *         upper)
 * @throws NumberIsTooLargeException if {@code lower >= upper}.
 */
public double nextUniform(double lower, double upper) {
    if (lower >= upper) {
        throw new NumberIsTooLargeException(LocalizedFormats.LOWER_BOUND_NOT_BELOW_UPPER_BOUND, lower, upper, false);
    }
    final RandomGenerator generator = getRan();
    // ensure nextDouble() isn't 0.0
    double u = generator.nextDouble();
    while (u <= 0.0) {
        u = generator.nextDouble();
    }
    return lower + u * (upper - lower);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-727_69273dca,Major,src/main/java/org/apache/commons/math3/ode/nonstiff/RungeKuttaIntegrator.java,94,186,"/**
 * {@inheritDoc}
 */
@Override
public void integrate(final ExpandableStatefulODE equations, final double t) throws NumberIsTooSmallException, DimensionMismatchException, MaxCountExceededException, NoBracketingException {
    sanityChecks(equations, t);
    setEquations(equations);
    final boolean forward = t > equations.getTime();
    // create some internal working arrays
    final double[] y0 = equations.getCompleteState();
    final double[] y = y0.clone();
    final int stages = c.length + 1;
    final double[][] yDotK = new double[stages][];
    for (int i = 0; i < stages; ++i) {
        yDotK[i] = new double[y0.length];
    }
    final double[] yTmp = y0.clone();
    final double[] yDotTmp = new double[y0.length];
    // set up an interpolator sharing the integrator arrays
    final RungeKuttaStepInterpolator interpolator = (RungeKuttaStepInterpolator) prototype.copy();
    interpolator.reinitialize(this, yTmp, yDotK, forward, equations.getPrimaryMapper(), equations.getSecondaryMappers());
    interpolator.storeTime(equations.getTime());
    // set up integration control objects
    stepStart = equations.getTime();
    stepSize = forward ? step : -step;
    initIntegration(equations.getTime(), y0, t);
    // main integration loop
    isLastStep = false;
    do {
        interpolator.shift();
        // first stage
        computeDerivatives(stepStart, y, yDotK[0]);
        // next stages
        for (int k = 1; k < stages; ++k) {
            for (int j = 0; j < y0.length; ++j) {
                double sum = a[k - 1][0] * yDotK[0][j];
                for (int l = 1; l < k; ++l) {
                    sum += a[k - 1][l] * yDotK[l][j];
                }
                yTmp[j] = y[j] + stepSize * sum;
            }
            computeDerivatives(stepStart + c[k - 1] * stepSize, yTmp, yDotK[k]);
        }
        // estimate the state at the end of the step
        for (int j = 0; j < y0.length; ++j) {
            double sum = b[0] * yDotK[0][j];
            for (int l = 1; l < stages; ++l) {
                sum += b[l] * yDotK[l][j];
            }
            yTmp[j] = y[j] + stepSize * sum;
        }
        // discrete events handling
        interpolator.storeTime(stepStart + stepSize);
        System.arraycopy(yTmp, 0, y, 0, y0.length);
        System.arraycopy(yDotK[stages - 1], 0, yDotTmp, 0, y0.length);
        stepStart = acceptStep(interpolator, y, yDotTmp, t);
        if (!isLastStep) {
            // prepare next step
            interpolator.storeTime(stepStart);
            // stepsize control for next step
            final double nextT = stepStart + stepSize;
            final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t);
            if (nextIsLast) {
                stepSize = t - stepStart;
            }
        }
    } while (!isLastStep);
    // dispatch results
    equations.setTime(stepStart);
    equations.setCompleteState(y);
    stepStart = Double.NaN;
    stepSize = Double.NaN;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-727_d2777388,Major,src/main/java/org/apache/commons/math/ode/nonstiff/EmbeddedRungeKuttaIntegrator.java,190,328,"/**
 * {@inheritDoc}
 */
@Override
public void integrate(final ExpandableStatefulODE equations, final double t) throws MathIllegalStateException, MathIllegalArgumentException {
    sanityChecks(equations, t);
    setEquations(equations);
    final boolean forward = t > equations.getTime();
    // create some internal working arrays
    final double[] y0 = equations.getCompleteState();
    final double[] y = y0.clone();
    final int stages = c.length + 1;
    final double[][] yDotK = new double[stages][y.length];
    final double[] yTmp = y0.clone();
    final double[] yDotTmp = new double[y.length];
    // set up an interpolator sharing the integrator arrays
    final RungeKuttaStepInterpolator interpolator = (RungeKuttaStepInterpolator) prototype.copy();
    interpolator.reinitialize(this, yTmp, yDotK, forward, equations.getPrimaryMapper(), equations.getSecondaryMappers());
    interpolator.storeTime(equations.getTime());
    // set up integration control objects
    stepStart = equations.getTime();
    double hNew = 0;
    boolean firstTime = true;
    initIntegration(equations.getTime(), y0, t);
    // main integration loop
    isLastStep = false;
    do {
        interpolator.shift();
        // iterate over step size, ensuring local normalized error is smaller than 1
        double error = 10;
        while (error >= 1.0) {
            if (firstTime || !fsal) {
                // first stage
                computeDerivatives(stepStart, y, yDotK[0]);
            }
            if (firstTime) {
                final double[] scale = new double[mainSetDimension];
                if (vecAbsoluteTolerance == null) {
                    for (int i = 0; i < scale.length; ++i) {
                        scale[i] = scalAbsoluteTolerance + scalRelativeTolerance * FastMath.abs(y[i]);
                    }
                } else {
                    for (int i = 0; i < scale.length; ++i) {
                        scale[i] = vecAbsoluteTolerance[i] + vecRelativeTolerance[i] * FastMath.abs(y[i]);
                    }
                }
                hNew = initializeStep(forward, getOrder(), scale, stepStart, y, yDotK[0], yTmp, yDotK[1]);
                firstTime = false;
            }
            stepSize = hNew;
            // next stages
            for (int k = 1; k < stages; ++k) {
                for (int j = 0; j < y0.length; ++j) {
                    double sum = a[k - 1][0] * yDotK[0][j];
                    for (int l = 1; l < k; ++l) {
                        sum += a[k - 1][l] * yDotK[l][j];
                    }
                    yTmp[j] = y[j] + stepSize * sum;
                }
                computeDerivatives(stepStart + c[k - 1] * stepSize, yTmp, yDotK[k]);
            }
            // estimate the state at the end of the step
            for (int j = 0; j < y0.length; ++j) {
                double sum = b[0] * yDotK[0][j];
                for (int l = 1; l < stages; ++l) {
                    sum += b[l] * yDotK[l][j];
                }
                yTmp[j] = y[j] + stepSize * sum;
            }
            // estimate the error at the end of the step
            error = estimateError(yDotK, y, yTmp, stepSize);
            if (error >= 1.0) {
                // reject the step and attempt to reduce error by stepsize control
                final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp)));
                hNew = filterStep(stepSize * factor, forward, false);
            }
        }
        // local error is small enough: accept the step, trigger events and step handlers
        interpolator.storeTime(stepStart + stepSize);
        System.arraycopy(yTmp, 0, y, 0, y0.length);
        System.arraycopy(yDotK[stages - 1], 0, yDotTmp, 0, y0.length);
        stepStart = acceptStep(interpolator, y, yDotTmp, t);
        System.arraycopy(y, 0, yTmp, 0, y.length);
        if (!isLastStep) {
            // prepare next step
            interpolator.storeTime(stepStart);
            if (fsal) {
                // save the last evaluation for the next step
                System.arraycopy(yDotTmp, 0, yDotK[0], 0, y0.length);
            }
            // stepsize control for next step
            final double factor = FastMath.min(maxGrowth, FastMath.max(minReduction, safety * FastMath.pow(error, exp)));
            final double scaledH = stepSize * factor;
            final double nextT = stepStart + scaledH;
            final boolean nextIsLast = forward ? (nextT >= t) : (nextT <= t);
            hNew = filterStep(scaledH, forward, nextIsLast);
            final double filteredNextT = stepStart + hNew;
            final boolean filteredNextIsLast = forward ? (filteredNextT >= t) : (filteredNextT <= t);
            if (filteredNextIsLast) {
                hNew = t - stepStart;
            }
        }
    } while (!isLastStep);
    // dispatch results
    equations.setTime(stepStart);
    equations.setCompleteState(y);
    resetInternalState();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-738_f64b6a90,Major,src/main/java/org/apache/commons/math3/special/Beta.java,169,171,"/**
 * Returns the natural logarithm of the beta function B(a, b).
 *
 * @param a Parameter {@code a}.
 * @param b Parameter {@code b}.
 * @return log(B(a, b)).
 */
public static double logBeta(double a, double b) {
    return logBeta(a, b, DEFAULT_EPSILON, Integer.MAX_VALUE);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-738_f64b6a90,Major,src/main/java/org/apache/commons/math3/special/Beta.java,190,206,"/**
 * Returns the natural logarithm of the beta function B(a, b).
 *
 * The implementation of this method is based on:
 * <ul>
 * <li><a href=""http://mathworld.wolfram.com/BetaFunction.html"">
 * Beta Function</a>, equation (1).</li>
 * </ul>
 *
 * @param a Parameter {@code a}.
 * @param b Parameter {@code b}.
 * @param epsilon When the absolute value of the nth item in the
 * series is less than epsilon the approximation ceases to calculate
 * further elements in the series.
 * @param maxIterations Maximum number of ""iterations"" to complete.
 * @return log(B(a, b)).
 */
public static double logBeta(double a, double b, double epsilon, int maxIterations) {
    double ret;
    if (Double.isNaN(a) || Double.isNaN(b) || a <= 0.0 || b <= 0.0) {
        ret = Double.NaN;
    } else {
        ret = Gamma.logGamma(a) + Gamma.logGamma(b) - Gamma.logGamma(a + b);
    }
    return ret;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-744_8a83581e,Major,src/main/java/org/apache/commons/math/fraction/BigFraction.java,683,686,"/**
 * <p>
 * Gets the fraction as a <tt>double</tt>. This calculates the fraction as
 * the numerator divided by denominator.
 * </p>
 *
 * @return the fraction as a <tt>double</tt>
 * @see java.lang.Number#doubleValue()
 */
@Override
public double doubleValue() {
    return numerator.doubleValue() / denominator.doubleValue();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-744_8a83581e,Major,src/main/java/org/apache/commons/math/fraction/BigFraction.java,727,730,"/**
 * <p>
 * Gets the fraction as a <tt>float</tt>. This calculates the fraction as
 * the numerator divided by denominator.
 * </p>
 *
 * @return the fraction as a <tt>float</tt>.
 * @see java.lang.Number#floatValue()
 */
@Override
public float floatValue() {
    return numerator.floatValue() / denominator.floatValue();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,440,446,"/**
 * Adds an element to the end of this expandable array.
 *
 * @param value Value to be added to end of array.
 */
@Override
public synchronized void addElement(double value) {
    if (internalArray.length <= startIndex + numElements) {
        expand();
    }
    internalArray[startIndex + numElements++] = value;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,454,462,"/**
 * Adds several element to the end of this expandable array.
 *
 * @param values Values to be added to end of array.
 * @since 2.2
 */
@Override
public synchronized void addElements(double[] values) {
    final double[] tempArray = new double[numElements + values.length + 1];
    System.arraycopy(internalArray, startIndex, tempArray, 0, numElements);
    System.arraycopy(values, 0, tempArray, numElements, values.length);
    internalArray = tempArray;
    startIndex = 0;
    numElements += values.length;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,480,498,"/**
 * <p>
 * Adds an element to the end of the array and removes the first
 * element in the array.  Returns the discarded first element.
 * The effect is similar to a push operation in a FIFO queue.
 * </p>
 * <p>
 * Example: If the array contains the elements 1, 2, 3, 4 (in that order)
 * and addElementRolling(5) is invoked, the result is an array containing
 * the entries 2, 3, 4, 5 and the value returned is 1.
 * </p>
 *
 * @param value Value to be added to the array.
 * @return the value which has been discarded or ""pushed"" out of the array
 * by this rolling insert.
 */
@Override
public synchronized double addElementRolling(double value) {
    double discarded = internalArray[startIndex];
    if ((startIndex + (numElements + 1)) > internalArray.length) {
        expand();
    }
    // Increment the start index
    startIndex += 1;
    // Add the new value
    internalArray[startIndex + (numElements - 1)] = value;
    // Check the contraction criterion.
    if (shouldContract()) {
        contract();
    }
    return discarded;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,510,523,"/**
 * Substitutes <code>value</code> for the most recently added value.
 * Returns the value that has been replaced. If the array is empty (i.e.
 * if {@link #numElements} is zero), an IllegalStateException is thrown.
 *
 * @param value New value to substitute for the most recently added value
 * @return the value that has been replaced in the array.
 * @throws MathIllegalStateException if the array is empty
 * @since 2.0
 */
public synchronized double substituteMostRecentElement(double value) throws MathIllegalStateException {
    if (numElements < 1) {
        throw new MathIllegalStateException(LocalizedFormats.CANNOT_SUBSTITUTE_ELEMENT_FROM_EMPTY_ARRAY);
    }
    final int substIndex = startIndex + (numElements - 1);
    final double discarded = internalArray[substIndex];
    internalArray[substIndex] = value;
    return discarded;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,537,542,"/**
 * Checks the expansion factor and the contraction criterion and throws an
 * IllegalArgumentException if the contractionCriteria is less than the
 * expansionCriteria
 *
 * @param expansion factor to be checked
 * @param contraction criteria to be checked
 * @throws MathIllegalArgumentException if the contractionCriteria is less than
 * the expansionCriteria.
 * @deprecated As of 3.1. Please use
 * {@link #checkContractExpand(double,double)} instead.
 */
@Deprecated
protected void checkContractExpand(float contraction, float expansion) throws MathIllegalArgumentException {
    checkContractExpand((double) contraction, (double) expansion);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,584,588,"/**
 * Clear the array contents, resetting the number of elements to zero.
 */
@Override
public synchronized void clear() {
    numElements = 0;
    startIndex = 0;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,595,604,"/**
 * Contracts the storage array to the (size of the element set) + 1 - to
 * avoid a zero length array. This function also resets the startIndex to
 * zero.
 */
public synchronized void contract() {
    final double[] tempArray = new double[numElements + 1];
    // Copy and swap - copy only the element array from the src array.
    System.arraycopy(internalArray, startIndex, tempArray, 0, numElements);
    internalArray = tempArray;
    // Reset the start index to zero
    startIndex = 0;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,617,620,"/**
 * Discards the <code>i</code> initial elements of the array.  For example,
 * if the array contains the elements 1,2,3,4, invoking
 * <code>discardFrontElements(2)</code> will cause the first two elements
 * to be discarded, leaving 3,4 in the array.  Throws illegalArgumentException
 * if i exceeds numElements.
 *
 * @param i  the number of elements to discard from the front of the array
 * @throws MathIllegalArgumentException if i is greater than numElements.
 * @since 2.0
 */
public synchronized void discardFrontElements(int i) throws MathIllegalArgumentException {
    discardExtremeElements(i, true);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,633,636,"/**
 * Discards the <code>i</code> last elements of the array.  For example,
 * if the array contains the elements 1,2,3,4, invoking
 * <code>discardMostRecentElements(2)</code> will cause the last two elements
 * to be discarded, leaving 1,2 in the array.  Throws illegalArgumentException
 * if i exceeds numElements.
 *
 * @param i  the number of elements to discard from the end of the array
 * @throws MathIllegalArgumentException if i is greater than numElements.
 * @since 2.0
 */
public synchronized void discardMostRecentElements(int i) throws MathIllegalArgumentException {
    discardExtremeElements(i, false);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,657,678,"/**
 * Discards the <code>i</code> first or last elements of the array,
 * depending on the value of <code>front</code>.
 * For example, if the array contains the elements 1,2,3,4, invoking
 * <code>discardExtremeElements(2,false)</code> will cause the last two elements
 * to be discarded, leaving 1,2 in the array.
 * For example, if the array contains the elements 1,2,3,4, invoking
 * <code>discardExtremeElements(2,true)</code> will cause the first two elements
 * to be discarded, leaving 3,4 in the array.
 * Throws illegalArgumentException
 * if i exceeds numElements.
 *
 * @param i  the number of elements to discard from the front/end of the array
 * @param front true if elements are to be discarded from the front
 * of the array, false if elements are to be discarded from the end
 * of the array
 * @throws MathIllegalArgumentException if i is greater than numElements.
 * @since 2.0
 */
private synchronized void discardExtremeElements(int i, boolean front) throws MathIllegalArgumentException {
    if (i > numElements) {
        throw new MathIllegalArgumentException(LocalizedFormats.TOO_MANY_ELEMENTS_TO_DISCARD_FROM_ARRAY, i, numElements);
    } else if (i < 0) {
        throw new MathIllegalArgumentException(LocalizedFormats.CANNOT_DISCARD_NEGATIVE_NUMBER_OF_ELEMENTS, i);
    } else {
        // ""Subtract"" this number of discarded from numElements
        numElements -= i;
        if (front) {
            startIndex += i;
        }
    }
    if (shouldContract()) {
        contract();
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,689,706,"/**
 * Expands the internal storage array using the expansion factor.
 * <p>
 * if <code>expansionMode</code> is set to MULTIPLICATIVE_MODE,
 * the new array size will be <code>internalArray.length * expansionFactor.</code>
 * If <code>expansionMode</code> is set to ADDITIVE_MODE,  the length
 * after expansion will be <code>internalArray.length + expansionFactor</code>
 * </p>
 */
protected synchronized void expand() {
    // notice the use of FastMath.ceil(), this guarantees that we will always
    // have an array of at least currentSize + 1.   Assume that the
    // current initial capacity is 1 and the expansion factor
    // is 1.000000000000000001.  The newly calculated size will be
    // rounded up to 2 after the multiplication is performed.
    int newSize = 0;
    if (expansionMode == ExpansionMode.MULTIPLICATIVE) {
        newSize = (int) FastMath.ceil(internalArray.length * expansionFactor);
    } else {
        newSize = (int) (internalArray.length + FastMath.round(expansionFactor));
    }
    final double[] tempArray = new double[newSize];
    // Copy and swap
    System.arraycopy(internalArray, 0, tempArray, 0, internalArray.length);
    internalArray = tempArray;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,713,718,"/**
 * Expands the internal storage array to the specified size.
 *
 * @param size Size of the new internal storage array.
 */
private synchronized void expandTo(int size) {
    final double[] tempArray = new double[size];
    // Copy and swap
    System.arraycopy(internalArray, 0, tempArray, 0, internalArray.length);
    internalArray = tempArray;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,734,737,"/**
 * The contraction criteria defines when the internal array will contract
 * to store only the number of elements in the element array.
 * If  the <code>expansionMode</code> is <code>MULTIPLICATIVE_MODE</code>,
 * contraction is triggered when the ratio between storage array length
 * and <code>numElements</code> exceeds <code>contractionFactor</code>.
 * If the <code>expansionMode</code> is <code>ADDITIVE_MODE</code>, the
 * number of excess storage locations is compared to
 * <code>contractionFactor.</code>
 *
 * @return the contraction criteria used to reclaim memory.
 * @deprecated As of 3.1. Please use {@link #getContractionCriterion()}
 * instead.
 */
@Deprecated
public float getContractionCriteria() {
    return (float) getContractionCriterion();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,752,754,"/**
 * The contraction criterion defines when the internal array will contract
 * to store only the number of elements in the element array.
 * If  the <code>expansionMode</code> is <code>MULTIPLICATIVE_MODE</code>,
 * contraction is triggered when the ratio between storage array length
 * and <code>numElements</code> exceeds <code>contractionFactor</code>.
 * If the <code>expansionMode</code> is <code>ADDITIVE_MODE</code>, the
 * number of excess storage locations is compared to
 * <code>contractionFactor.</code>
 *
 * @return the contraction criterion used to reclaim memory.
 * @since 3.1
 */
public double getContractionCriterion() {
    return contractionCriterion;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,764,773,"/**
 * Returns the element at the specified index
 *
 * @param index index to fetch a value from
 * @return value stored at the specified index
 * @throws ArrayIndexOutOfBoundsException if <code>index</code> is less than
 * zero or is greater than <code>getNumElements() - 1</code>.
 */
@Override
public synchronized double getElement(int index) {
    if (index >= numElements) {
        throw new ArrayIndexOutOfBoundsException(index);
    } else if (index >= 0) {
        return internalArray[startIndex + index];
    } else {
        throw new ArrayIndexOutOfBoundsException(index);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,782,787,"/**
 * Returns a double array containing the elements of this
 * <code>ResizableArray</code>.  This method returns a copy, not a
 * reference to the underlying array, so that changes made to the returned
 *  array have no effect on this <code>ResizableArray.</code>
 * @return the double array.
 */
@Override
public synchronized double[] getElements() {
    final double[] elementArray = new double[numElements];
    System.arraycopy(internalArray, startIndex, elementArray, 0, numElements);
    return elementArray;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,802,805,"/**
 * The expansion factor controls the size of a new array when an array
 * needs to be expanded.  The <code>expansionMode</code>
 * determines whether the size of the array is multiplied by the
 * <code>expansionFactor</code> (MULTIPLICATIVE_MODE) or if
 * the expansion is additive (ADDITIVE_MODE -- <code>expansionFactor</code>
 * storage locations added).  The default <code>expansionMode</code> is
 * MULTIPLICATIVE_MODE and the default <code>expansionFactor</code>
 * is 2.0.
 *
 * @return the expansion factor of this expandable double array
 * @deprecated As of 3.1. Return type will be changed to ""double"" in 4.0.
 */
@Deprecated
public float getExpansionFactor() {
    return (float) expansionFactor;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,815,825,"/**
 * The expansion mode determines whether the internal storage
 * array grows additively or multiplicatively when it is expanded.
 *
 * @return the expansion mode.
 * @deprecated As of 3.1. Return value to be changed to
 * {@link ExpansionMode} in 4.0.
 */
@Deprecated
public int getExpansionMode() {
    switch(expansionMode) {
        case MULTIPLICATIVE:
            return MULTIPLICATIVE_MODE;
        case ADDITIVE:
            return ADDITIVE_MODE;
        default:
            // Should never happen.
            throw new MathInternalError();
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,836,839,"/**
 * Notice the package scope on this method.   This method is simply here
 * for the JUnit test, it allows us check if the expansion is working
 * properly after a number of expansions.  This is not meant to be a part
 * of the public interface of this class.
 *
 * @return the length of the internal storage array.
 * @deprecated As of 3.1. Please use {@link #getCapacity()} instead.
 */
@Deprecated
synchronized int getInternalLength() {
    return internalArray.length;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,860,863,"/**
 * Returns the number of elements currently in the array.  Please note
 * that this is different from the length of the internal storage array.
 *
 * @return the number of elements.
 */
@Override
public synchronized int getNumElements() {
    return numElements;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,878,881,"/**
 * Returns the internal storage array.  Note that this method returns
 * a reference to the internal storage array, not a copy, and to correctly
 * address elements of the array, the <code>startIndex</code> is
 * required (available via the {@link #start} method).  This method should
 * only be used in cases where copying the internal array is not practical.
 * The {@link #getElements} method should be used in all other cases.
 *
 * @return the internal storage array used by this object
 * @since 2.0
 * @deprecated As of 3.1.
 */
@Deprecated
public synchronized double[] getInternalValues() {
    return internalArray;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,902,904,"/**
 * Provides <em>direct</em> access to the internal storage array.
 * Please note that this method returns a reference to this object's
 * storage array, not a copy.
 * <br/>
 * To correctly address elements of the array, the ""start index"" is
 * required (available via the {@link #getStartIndex() getStartIndex}
 * method.
 * <br/>
 * This method should only be used to avoid copying the internal array.
 * The returned value <em>must</em> be used for reading only; other
 * uses could lead to this object becoming inconsistent.
 * <br/>
 * The {@link #getElements} method has no such limitation since it
 * returns a copy of this array's addressable elements.
 *
 * @return the internal storage array used by this object.
 * @since 3.1
 */
protected double[] getArrayRef() {
    return internalArray;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,917,919,"/**
 * Returns the ""start index"" of the internal array.
 * This index is the position of the first addressable element in the
 * internal storage array.
 * The addressable elements in the array are at indices contained in
 * the interval [{@link #getStartIndex()},
 *               {@link #getStartIndex()} + {@link #getNumElements()} - 1].
 *
 * @return the start index.
 * @since 3.1
 */
protected int getStartIndex() {
    return startIndex;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,929,936,"/**
 * Sets the contraction criteria.
 *
 * @param contractionCriteria contraction criteria
 * @throws MathIllegalArgumentException if the contractionCriteria is less than
 *         the expansionCriteria.
 * @deprecated As of 3.1 (to be removed in 4.0 as field will become ""final"").
 */
@Deprecated
public void setContractionCriteria(float contractionCriteria) throws MathIllegalArgumentException {
    checkContractExpand(contractionCriteria, getExpansionFactor());
    synchronized (this) {
        this.contractionCriterion = contractionCriteria;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,945,955,"/**
 * Performs an operation on the addressable elements of the array.
 *
 * @param f Function to be applied on this array.
 * @return the result.
 * @since 3.1
 */
public double compute(MathArrays.Function f) {
    final double[] array;
    final int start;
    final int num;
    synchronized (this) {
        array = internalArray;
        start = startIndex;
        num = numElements;
    }
    return f.evaluate(array, start, num);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,968,980,"/**
 * Sets the element at the specified index.  If the specified index is greater than
 * <code>getNumElements() - 1</code>, the <code>numElements</code> property
 * is increased to <code>index +1</code> and additional storage is allocated
 * (if necessary) for the new element and all  (uninitialized) elements
 * between the new element and the previous end of the array).
 *
 * @param index index to store a value in
 * @param value value to store at the specified index
 * @throws ArrayIndexOutOfBoundsException if {@code index < 0}.
 */
@Override
public synchronized void setElement(int index, double value) {
    if (index < 0) {
        throw new ArrayIndexOutOfBoundsException(index);
    }
    if (index + 1 > numElements) {
        numElements = index + 1;
    }
    if ((startIndex + index) >= internalArray.length) {
        expandTo(startIndex + (index + 1));
    }
    internalArray[startIndex + index] = value;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,994,1001,"/**
 * Sets the expansionFactor.  Throws IllegalArgumentException if the
 * the following conditions are not met:
 * <ul>
 * <li><code>expansionFactor > 1</code></li>
 * <li><code>contractionFactor >= expansionFactor</code></li>
 * </ul>
 * @param expansionFactor the new expansion factor value.
 * @throws MathIllegalArgumentException if expansionFactor is <= 1 or greater
 * than contractionFactor
 * @deprecated As of 3.1 (to be removed in 4.0 as field will become ""final"").
 */
@Deprecated
public void setExpansionFactor(float expansionFactor) throws MathIllegalArgumentException {
    checkContractExpand(getContractionCriterion(), expansionFactor);
    // The check above verifies that the expansion factor is > 1.0;
    synchronized (this) {
        this.expansionFactor = expansionFactor;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1011,1027,"/**
 * Sets the <code>expansionMode</code>. The specified value must be one of
 * ADDITIVE_MODE, MULTIPLICATIVE_MODE.
 *
 * @param expansionMode The expansionMode to set.
 * @throws MathIllegalArgumentException if the specified mode value is not valid.
 * @deprecated As of 3.1. Please use {@link #setExpansionMode(ExpansionMode)} instead.
 */
@Deprecated
public void setExpansionMode(int expansionMode) throws MathIllegalArgumentException {
    if (expansionMode != MULTIPLICATIVE_MODE && expansionMode != ADDITIVE_MODE) {
        throw new MathIllegalArgumentException(LocalizedFormats.UNSUPPORTED_EXPANSION_MODE, expansionMode, MULTIPLICATIVE_MODE, ""MULTIPLICATIVE_MODE"", ADDITIVE_MODE, ""ADDITIVE_MODE"");
    }
    synchronized (this) {
        if (expansionMode == MULTIPLICATIVE_MODE) {
            setExpansionMode(ExpansionMode.MULTIPLICATIVE);
        } else if (expansionMode == ADDITIVE_MODE) {
            setExpansionMode(ExpansionMode.ADDITIVE);
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1035,1038,"/**
 * Sets the {@link ExpansionMode expansion mode}.
 *
 * @param expansionMode Expansion mode to use for resizing the array.
 * @deprecated As of 3.1 (to be removed in 4.0 as field will become ""final"").
 */
@Deprecated
public void setExpansionMode(ExpansionMode expansionMode) {
    this.expansionMode = expansionMode;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1048,1052,"/**
 * Sets the initial capacity.  Should only be invoked by constructors.
 *
 * @param initialCapacity of the array
 * @throws MathIllegalArgumentException if <code>initialCapacity</code> is not
 * positive.
 * @deprecated As of 3.1, this is a no-op.
 */
@Deprecated
protected void setInitialCapacity(int initialCapacity) throws MathIllegalArgumentException {
// Body removed in 3.1.
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1062,1080,"/**
 * This function allows you to control the number of elements contained
 * in this array, and can be used to ""throw out"" the last n values in an
 * array. This function will also expand the internal array as needed.
 *
 * @param i a new number of elements
 * @throws MathIllegalArgumentException if <code>i</code> is negative.
 */
public synchronized void setNumElements(int i) throws MathIllegalArgumentException {
    // If index is negative thrown an error.
    if (i < 0) {
        throw new MathIllegalArgumentException(LocalizedFormats.INDEX_NOT_POSITIVE, i);
    }
    // Test the new num elements, check to see if the array needs to be
    // expanded to accommodate this new number of elements.
    final int newSize = startIndex + i;
    if (newSize > internalArray.length) {
        expandTo(newSize);
    }
    // Set the new number of elements to new value.
    numElements = i;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1088,1094,"/**
 * Returns true if the internal storage array has too many unused
 * storage positions.
 *
 * @return true if array satisfies the contraction criteria
 */
private synchronized boolean shouldContract() {
    if (expansionMode == ExpansionMode.MULTIPLICATIVE) {
        return (internalArray.length / ((float) numElements)) > contractionCriterion;
    } else {
        return (internalArray.length - numElements) > contractionCriterion;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1106,1109,"/**
 * Returns the starting index of the internal array.  The starting index is
 * the position of the first addressable element in the internal storage
 * array.  The addressable elements in the array are <code>
 * internalArray[startIndex],...,internalArray[startIndex + numElements -1]
 * </code>
 *
 * @return the starting index.
 * @deprecated As of 3.1.
 */
@Deprecated
public synchronized int start() {
    return startIndex;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1128,1145,"/**
 * <p>Copies source to dest, copying the underlying data, so dest is
 * a new, independent copy of source.  Does not contract before
 * the copy.</p>
 *
 * <p>Obtains synchronization locks on both source and dest
 * (in that order) before performing the copy.</p>
 *
 * <p>Neither source nor dest may be null; otherwise a {@link NullArgumentException}
 * is thrown</p>
 *
 * @param source ResizableDoubleArray to copy
 * @param dest ResizableArray to replace with a copy of the source array
 * @exception NullArgumentException if either source or dest is null
 * @since 2.0
 */
public static void copy(ResizableDoubleArray source, ResizableDoubleArray dest) throws NullArgumentException {
    MathUtils.checkNotNull(source);
    MathUtils.checkNotNull(dest);
    synchronized (source) {
        synchronized (dest) {
            dest.contractionCriterion = source.contractionCriterion;
            dest.expansionFactor = source.expansionFactor;
            dest.expansionMode = source.expansionMode;
            dest.internalArray = new double[source.internalArray.length];
            System.arraycopy(source.internalArray, 0, dest.internalArray, 0, dest.internalArray.length);
            dest.numElements = source.numElements;
            dest.startIndex = source.startIndex;
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1155,1159,"/**
 * Returns a copy of the ResizableDoubleArray.  Does not contract before
 * the copy, so the returned object is an exact copy of this.
 *
 * @return a new ResizableDoubleArray with the same data and configuration
 * properties as this
 * @since 2.0
 */
public synchronized ResizableDoubleArray copy() {
    final ResizableDoubleArray result = new ResizableDoubleArray();
    copy(this, result);
    return result;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1170,1194,"/**
 * Returns true iff object is a ResizableDoubleArray with the same properties
 * as this and an identical internal storage array.
 *
 * @param object object to be compared for equality with this
 * @return true iff object is a ResizableDoubleArray with the same data and
 * properties as this
 * @since 2.0
 */
@Override
public boolean equals(Object object) {
    if (object == this) {
        return true;
    }
    if (object instanceof ResizableDoubleArray == false) {
        return false;
    }
    synchronized (this) {
        synchronized (object) {
            boolean result = true;
            final ResizableDoubleArray other = (ResizableDoubleArray) object;
            result = result && (other.contractionCriterion == contractionCriterion);
            result = result && (other.expansionFactor == expansionFactor);
            result = result && (other.expansionMode == expansionMode);
            result = result && (other.numElements == numElements);
            result = result && (other.startIndex == startIndex);
            if (!result) {
                return false;
            } else {
                return Arrays.equals(internalArray, other.internalArray);
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-757_76b7413d,Major,src/main/java/org/apache/commons/math4/util/ResizableDoubleArray.java,1202,1212,"/**
 * Returns a hash code consistent with equals.
 *
 * @return the hash code representing this {@code ResizableDoubleArray}.
 * @since 2.0
 */
@Override
public synchronized int hashCode() {
    final int[] hashData = new int[6];
    hashData[0] = Double.valueOf(expansionFactor).hashCode();
    hashData[1] = Double.valueOf(contractionCriterion).hashCode();
    hashData[2] = expansionMode.hashCode();
    hashData[3] = Arrays.hashCode(internalArray);
    hashData[4] = numElements;
    hashData[5] = startIndex;
    return Arrays.hashCode(hashData);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-778_5b9302d5,Major,src/main/java/org/apache/commons/math3/dfp/Dfp.java,1603,1659,"/**
 * Multiply this by a single digit 0&lt;=x&lt;radix.
 * There are speed advantages in this special case
 * @param x multiplicand
 * @return product of this and x
 */
public Dfp multiply(final int x) {
    Dfp result = newInstance(this);
    /* handle special cases */
    if (nans != FINITE) {
        if (isNaN()) {
            return this;
        }
        if (nans == INFINITE && x != 0) {
            result = newInstance(this);
            return result;
        }
        if (nans == INFINITE && x == 0) {
            field.setIEEEFlagsBits(DfpField.FLAG_INVALID);
            result = newInstance(getZero());
            result.nans = QNAN;
            result = dotrap(DfpField.FLAG_INVALID, MULTIPLY_TRAP, newInstance(getZero()), result);
            return result;
        }
    }
    /* range check x */
    if (x < 0 || x >= RADIX) {
        field.setIEEEFlagsBits(DfpField.FLAG_INVALID);
        result = newInstance(getZero());
        result.nans = QNAN;
        result = dotrap(DfpField.FLAG_INVALID, MULTIPLY_TRAP, result, result);
        return result;
    }
    int rh = 0;
    for (int i = 0; i < mant.length; i++) {
        final int r = mant[i] * x + rh;
        rh = r / RADIX;
        result.mant[i] = r - rh * RADIX;
    }
    int lostdigit = 0;
    if (rh != 0) {
        lostdigit = result.mant[0];
        result.shiftRight();
        result.mant[mant.length - 1] = rh;
    }
    if (result.mant[mant.length - 1] == 0) {
        // if result is zero, set exp to zero
        result.exp = 0;
    }
    final int excp = result.round(lostdigit);
    if (excp != 0) {
        result = dotrap(excp, MULTIPLY_TRAP, result, result);
    }
    return result;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-779_ebadb558,Major,src/main/java/org/apache/commons/math3/genetics/ListPopulation.java,207,209,"/**
 * Chromosome list iterator
 *
 * @return chromosome iterator
 */
public Iterator<Chromosome> iterator() {
    return chromosomes.iterator();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-780_dd6cefb0,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,129,179,"/**
 * {@inheritDoc}
 */
@Override
protected void computeGeometricalProperties() {
    final Vector2D[][] v = getVertices();
    if (v.length == 0) {
        if ((Boolean) getTree(false).getAttribute()) {
            setSize(Double.POSITIVE_INFINITY);
            setBarycenter(Vector2D.NaN);
        } else {
            setSize(0);
            setBarycenter(new Vector2D(0, 0));
        }
    } else if (v[0][0] == null) {
        // there is at least one open-loop: the polygon is infinite
        setSize(Double.POSITIVE_INFINITY);
        setBarycenter(Vector2D.NaN);
    } else {
        // all loops are closed, we compute some integrals around the shape
        double sum = 0;
        double sumX = 0;
        double sumY = 0;
        for (Vector2D[] loop : v) {
            double x1 = loop[loop.length - 1].getX();
            double y1 = loop[loop.length - 1].getY();
            for (final Vector2D point : loop) {
                final double x0 = x1;
                final double y0 = y1;
                x1 = point.getX();
                y1 = point.getY();
                final double factor = x0 * y1 - y0 * x1;
                sum += factor;
                sumX += factor * (x0 + x1);
                sumY += factor * (y0 + y1);
            }
        }
        if (sum < 0) {
            // the polygon as a finite outside surrounded by an infinite inside
            setSize(Double.POSITIVE_INFINITY);
            setBarycenter(Vector2D.NaN);
        } else {
            setSize(sum / 2);
            setBarycenter(new Vector2D(sumX / (3 * sum), sumY / (3 * sum)));
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-781_3c4cb189,Major,src/main/java/org/apache/commons/math3/optimization/linear/SimplexTableau.java,327,367,"/**
 * Removes the phase 1 objective function, positive cost non-artificial variables,
 * and the non-basic artificial variables from this tableau.
 */
protected void dropPhase1Objective() {
    if (getNumObjectiveFunctions() == 1) {
        return;
    }
    List<Integer> columnsToDrop = new ArrayList<Integer>();
    columnsToDrop.add(0);
    // positive cost non-artificial variables
    for (int i = getNumObjectiveFunctions(); i < getArtificialVariableOffset(); i++) {
        final double entry = tableau.getEntry(0, i);
        if (Precision.compareTo(entry, 0d, maxUlps) > 0) {
            columnsToDrop.add(i);
        }
    }
    // non-basic artificial variables
    for (int i = 0; i < getNumArtificialVariables(); i++) {
        int col = i + getArtificialVariableOffset();
        if (getBasicRow(col) == null) {
            columnsToDrop.add(col);
        }
    }
    double[][] matrix = new double[getHeight() - 1][getWidth() - columnsToDrop.size()];
    for (int i = 1; i < getHeight(); i++) {
        int col = 0;
        for (int j = 0; j < getWidth(); j++) {
            if (!columnsToDrop.contains(j)) {
                matrix[i - 1][col++] = tableau.getEntry(i, j);
            }
        }
    }
    for (int i = columnsToDrop.size() - 1; i >= 0; i--) {
        columnLabels.remove((int) columnsToDrop.get(i));
    }
    this.tableau = new Array2DRowRealMatrix(matrix);
    this.numArtificialVariables = 0;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-812_607c9ec6,Major,src/main/java/org/apache/commons/math3/linear/RealVector.java,644,666,"/**
 * Compute the outer product.
 *
 * @param v Vector with which outer product should be computed.
 * @return the matrix outer product between this instance and {@code v}.
 */
public RealMatrix outerProduct(RealVector v) {
    RealMatrix product;
    if (v instanceof SparseRealVector || this instanceof SparseRealVector) {
        product = new OpenMapRealMatrix(this.getDimension(), v.getDimension());
    } else {
        product = new Array2DRowRealMatrix(this.getDimension(), v.getDimension());
    }
    Iterator<Entry> thisIt = sparseIterator();
    while (thisIt.hasNext()) {
        final Entry thisE = thisIt.next();
        Iterator<Entry> otherIt = v.sparseIterator();
        while (otherIt.hasNext()) {
            final Entry otherE = otherIt.next();
            product.setEntry(thisE.getIndex(), otherE.getIndex(), thisE.getValue() * otherE.getValue());
        }
    }
    return product;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-812_6eb46555,Major,src/main/java/org/apache/commons/math3/linear/ArrayRealVector.java,448,468,"/**
 * {@inheritDoc}
 */
@Override
public double dotProduct(RealVector v) {
    if (v instanceof ArrayRealVector) {
        final double[] vData = ((ArrayRealVector) v).data;
        checkVectorDimensions(vData.length);
        double dot = 0;
        for (int i = 0; i < data.length; i++) {
            dot += data[i] * vData[i];
        }
        return dot;
    } else {
        checkVectorDimensions(v);
        double dot = 0;
        Iterator<Entry> it = v.sparseIterator();
        while (it.hasNext()) {
            final Entry e = it.next();
            dot += data[e.getIndex()] * e.getValue();
        }
        return dot;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-812_6eb46555,Major,src/main/java/org/apache/commons/math3/linear/OpenMapRealVector.java,316,327,"/**
 * Optimized method to compute the dot product with an OpenMapRealVector.
 * It iterates over the smallest of the two.
 *
 * @param v Cector to compute the dot product with.
 * @return the dot product of {@code this} and {@code v}.
 * @throws org.apache.commons.math3.exception.DimensionMismatchException
 * if the dimensions do not match.
 */
public double dotProduct(OpenMapRealVector v) {
    checkVectorDimensions(v.getDimension());
    boolean thisIsSmaller = entries.size() < v.entries.size();
    Iterator iter = thisIsSmaller ? entries.iterator() : v.entries.iterator();
    OpenIntToDoubleHashMap larger = thisIsSmaller ? v.entries : entries;
    double d = 0;
    while (iter.hasNext()) {
        iter.advance();
        d += iter.value() * larger.get(iter.key());
    }
    return d;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-812_6eb46555,Major,src/main/java/org/apache/commons/math3/linear/OpenMapRealVector.java,330,337,"/**
 * {@inheritDoc}
 */
@Override
public double dotProduct(RealVector v) {
    if (v instanceof OpenMapRealVector) {
        return dotProduct((OpenMapRealVector) v);
    } else {
        return super.dotProduct(v);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-812_6eb46555,Major,src/main/java/org/apache/commons/math3/linear/RealVector.java,303,312,"/**
 * Compute the dot product of this vector with {@code v}.
 *
 * @param v Vector with which dot product should be computed
 * @return the scalar dot product between this instance and {@code v}.
 * @throws org.apache.commons.math3.exception.DimensionMismatchException
 * if {@code v} is not the same size as this vector.
 */
public double dotProduct(RealVector v) {
    checkVectorDimensions(v);
    double d = 0;
    Iterator<Entry> it = sparseIterator();
    while (it.hasNext()) {
        final Entry e = it.next();
        d += e.getValue() * v.getEntry(e.getIndex());
    }
    return d;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-828_a49e443c,Major,src/main/java/org/apache/commons/math3/optimization/linear/SimplexSolver.java,90,150,"/**
 * Returns the row with the minimum ratio as given by the minimum ratio test (MRT).
 * @param tableau simple tableau for the problem
 * @param col the column to test the ratio of.  See {@link #getPivotColumn(SimplexTableau)}
 * @return row with the minimum ratio
 */
private Integer getPivotRow(SimplexTableau tableau, final int col) {
    // create a list of all the rows that tie for the lowest score in the minimum ratio test
    List<Integer> minRatioPositions = new ArrayList<Integer>();
    double minRatio = Double.MAX_VALUE;
    for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getHeight(); i++) {
        final double rhs = tableau.getEntry(i, tableau.getWidth() - 1);
        final double entry = tableau.getEntry(i, col);
        if (Precision.compareTo(entry, 0d, maxUlps) > 0) {
            final double ratio = rhs / entry;
            // check if the entry is strictly equal to the current min ratio
            // do not use a ulp/epsilon check
            final int cmp = Double.compare(ratio, minRatio);
            if (cmp == 0) {
                minRatioPositions.add(i);
            } else if (cmp < 0) {
                minRatio = ratio;
                minRatioPositions = new ArrayList<Integer>();
                minRatioPositions.add(i);
            }
        }
    }
    if (minRatioPositions.size() == 0) {
        return null;
    } else if (minRatioPositions.size() > 1) {
        // 1. check if there's an artificial variable that can be forced out of the basis
        for (Integer row : minRatioPositions) {
            for (int i = 0; i < tableau.getNumArtificialVariables(); i++) {
                int column = i + tableau.getArtificialVariableOffset();
                final double entry = tableau.getEntry(row, column);
                if (Precision.equals(entry, 1d, maxUlps) && row.equals(tableau.getBasicRow(column))) {
                    return row;
                }
            }
        }
        // 2. apply Bland's rule to prevent cycling:
        // take the row for which the corresponding basic variable has the smallest index
        // 
        // see http://www.stanford.edu/class/msande310/blandrule.pdf
        // see http://en.wikipedia.org/wiki/Bland%27s_rule (not equivalent to the above paper)
        Integer minRow = null;
        int minIndex = tableau.getWidth();
        for (Integer row : minRatioPositions) {
            for (int i = tableau.getNumObjectiveFunctions(); i < tableau.getWidth() - 1 && minRow != row; i++) {
                if (row == tableau.getBasicRow(i)) {
                    if (i < minIndex) {
                        minIndex = i;
                        minRow = row;
                    }
                }
            }
        }
        return minRow;
    }
    return minRatioPositions.get(0);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-835_63a48705,Minor,src/main/java/org/apache/commons/math3/fraction/Fraction.java,596,598,"/**
 * <p>
 * Gets the fraction percentage as a <tt>double</tt>. This calculates the
 * fraction as the numerator divided by denominator multiplied by 100.
 * </p>
 *
 * @return the fraction percentage as a <tt>double</tt>.
 */
public double percentageValue() {
    return multiply(100).doubleValue();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-844_7994d3ee,Minor,src/main/java/org/apache/commons/math3/optimization/fitting/HarmonicFitter.java,254,323,"/**
 * Estimate a first guess of the amplitude and angular frequency.
 * This method assumes that the {@link #sortObservations()} method
 * has been called previously.
 *
 * @throws ZeroException if the abscissa range is zero.
 */
private void guessAOmega() {
    // initialize the sums for the linear model between the two integrals
    double sx2 = 0;
    double sy2 = 0;
    double sxy = 0;
    double sxz = 0;
    double syz = 0;
    double currentX = observations[0].getX();
    double currentY = observations[0].getY();
    double f2Integral = 0;
    double fPrime2Integral = 0;
    final double startX = currentX;
    for (int i = 1; i < observations.length; ++i) {
        // one step forward
        final double previousX = currentX;
        final double previousY = currentY;
        currentX = observations[i].getX();
        currentY = observations[i].getY();
        // update the integrals of f<sup>2</sup> and f'<sup>2</sup>
        // considering a linear model for f (and therefore constant f')
        final double dx = currentX - previousX;
        final double dy = currentY - previousY;
        final double f2StepIntegral = dx * (previousY * previousY + previousY * currentY + currentY * currentY) / 3;
        final double fPrime2StepIntegral = dy * dy / dx;
        final double x = currentX - startX;
        f2Integral += f2StepIntegral;
        fPrime2Integral += fPrime2StepIntegral;
        sx2 += x * x;
        sy2 += f2Integral * f2Integral;
        sxy += x * f2Integral;
        sxz += x * fPrime2Integral;
        syz += f2Integral * fPrime2Integral;
    }
    // compute the amplitude and pulsation coefficients
    double c1 = sy2 * sxz - sxy * syz;
    double c2 = sxy * sxz - sx2 * syz;
    double c3 = sx2 * sy2 - sxy * sxy;
    if ((c1 / c2 < 0) || (c2 / c3 < 0)) {
        final int last = observations.length - 1;
        // Range of the observations, assuming that the
        // observations are sorted.
        final double xRange = observations[last].getX() - observations[0].getX();
        if (xRange == 0) {
            throw new ZeroException();
        }
        omega = 2 * Math.PI / xRange;
        double yMin = Double.POSITIVE_INFINITY;
        double yMax = Double.NEGATIVE_INFINITY;
        for (int i = 1; i < observations.length; ++i) {
            final double y = observations[i].getY();
            if (y < yMin) {
                yMin = y;
            }
            if (y > yMax) {
                yMax = y;
            }
        }
        a = 0.5 * (yMax - yMin);
    } else {
        a = FastMath.sqrt(c1 / c2);
        omega = FastMath.sqrt(c2 / c3);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-848_ad252a8c,Major,src/main/java/org/apache/commons/math3/linear/SchurTransformer.java,132,252,"/**
 * Transform original matrix to Schur form.
 * @throws MaxCountExceededException if the transformation does not converge
 */
private void transform() {
    final int n = matrixT.length;
    // compute matrix norm
    final double norm = getNorm();
    // shift information
    final ShiftInfo shift = new ShiftInfo();
    // Outer loop over eigenvalue index
    int iteration = 0;
    int idx = n - 1;
    while (idx >= 0) {
        // Look for single small sub-diagonal element
        final int l = findSmallSubDiagonalElement(idx, norm);
        // Check for convergence
        if (l == idx) {
            // One root found
            matrixT[idx][idx] = matrixT[idx][idx] + shift.exShift;
            idx--;
            iteration = 0;
        } else if (l == idx - 1) {
            // Two roots found
            shift.w = matrixT[idx][idx - 1] * matrixT[idx - 1][idx];
            double p = (matrixT[idx - 1][idx - 1] - matrixT[idx][idx]) / 2.0;
            double q = p * p + shift.w;
            double z = FastMath.sqrt(FastMath.abs(q));
            matrixT[idx][idx] = matrixT[idx][idx] + shift.exShift;
            matrixT[idx - 1][idx - 1] = matrixT[idx - 1][idx - 1] + shift.exShift;
            shift.x = matrixT[idx][idx];
            if (q >= 0) {
                if (p >= 0) {
                    z = p + z;
                } else {
                    z = p - z;
                }
                shift.x = matrixT[idx][idx - 1];
                double s = FastMath.abs(shift.x) + FastMath.abs(z);
                p = shift.x / s;
                q = z / s;
                double r = FastMath.sqrt(p * p + q * q);
                p = p / r;
                q = q / r;
                // Row modification
                for (int j = idx - 1; j < n; j++) {
                    z = matrixT[idx - 1][j];
                    matrixT[idx - 1][j] = q * z + p * matrixT[idx][j];
                    matrixT[idx][j] = q * matrixT[idx][j] - p * z;
                }
                // Column modification
                for (int i = 0; i <= idx; i++) {
                    z = matrixT[i][idx - 1];
                    matrixT[i][idx - 1] = q * z + p * matrixT[i][idx];
                    matrixT[i][idx] = q * matrixT[i][idx] - p * z;
                }
                // Accumulate transformations
                for (int i = 0; i <= n - 1; i++) {
                    z = matrixP[i][idx - 1];
                    matrixP[i][idx - 1] = q * z + p * matrixP[i][idx];
                    matrixP[i][idx] = q * matrixP[i][idx] - p * z;
                }
            }
            idx -= 2;
            iteration = 0;
        } else {
            // No convergence yet
            computeShift(l, idx, iteration, shift);
            // stop transformation after too many iterations
            if (++iteration > MAX_ITERATIONS) {
                throw new MaxCountExceededException(LocalizedFormats.CONVERGENCE_FAILED, MAX_ITERATIONS);
            }
            // Look for two consecutive small sub-diagonal elements
            int m = idx - 2;
            // the initial houseHolder vector for the QR step
            final double[] hVec = new double[3];
            while (m >= l) {
                double z = matrixT[m][m];
                hVec[2] = shift.x - z;
                double s = shift.y - z;
                hVec[0] = (hVec[2] * s - shift.w) / matrixT[m + 1][m] + matrixT[m][m + 1];
                hVec[1] = matrixT[m + 1][m + 1] - z - hVec[2] - s;
                hVec[2] = matrixT[m + 2][m + 1];
                s = FastMath.abs(hVec[0]) + FastMath.abs(hVec[1]) + FastMath.abs(hVec[2]);
                if (m == l) {
                    break;
                }
                for (int i = 0; i < hVec.length; i++) {
                    hVec[i] /= s;
                }
                final double lhs = FastMath.abs(matrixT[m][m - 1]) * (FastMath.abs(hVec[1]) + FastMath.abs(hVec[2]));
                final double rhs = FastMath.abs(hVec[0]) * (FastMath.abs(matrixT[m - 1][m - 1]) + FastMath.abs(z) + FastMath.abs(matrixT[m + 1][m + 1]));
                if (lhs < epsilon * rhs) {
                    break;
                }
                m--;
            }
            performDoubleQRStep(l, m, idx, shift, hVec);
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-848_ad252a8c,Major,src/main/java/org/apache/commons/math3/linear/SchurTransformer.java,277,290,"/**
 * Find the first small sub-diagonal element and returns its index.
 *
 * @param startIdx the starting index for the search
 * @param norm the L1 norm of the matrix
 * @return the index of the first small sub-diagonal element
 */
private int findSmallSubDiagonalElement(final int startIdx, final double norm) {
    int l = startIdx;
    while (l > 0) {
        double s = FastMath.abs(matrixT[l - 1][l - 1]) + FastMath.abs(matrixT[l][l]);
        if (Precision.equals(s, 0.0, epsilon)) {
            s = norm;
        }
        if (FastMath.abs(matrixT[l][l - 1]) < epsilon * s) {
            break;
        }
        l--;
    }
    return l;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-848_ad252a8c,Major,src/main/java/org/apache/commons/math3/linear/SchurTransformer.java,300,337,"/**
 * Compute the shift for the current iteration.
 *
 * @param l the index of the small sub-diagonal element
 * @param idx the current eigenvalue index
 * @param iteration the current iteration
 * @param shift holder for shift information
 */
private void computeShift(final int l, final int idx, final int iteration, final ShiftInfo shift) {
    // Form shift
    shift.x = matrixT[idx][idx];
    shift.y = shift.w = 0.0;
    if (l < idx) {
        shift.y = matrixT[idx - 1][idx - 1];
        shift.w = matrixT[idx][idx - 1] * matrixT[idx - 1][idx];
    }
    // Wilkinson's original ad hoc shift
    if (iteration == 10) {
        shift.exShift += shift.x;
        for (int i = 0; i <= idx; i++) {
            matrixT[i][i] -= shift.x;
        }
        double s = FastMath.abs(matrixT[idx][idx - 1]) + FastMath.abs(matrixT[idx - 1][idx - 2]);
        shift.x = shift.y = 0.75 * s;
        shift.w = -0.4375 * s * s;
    }
    // MATLAB's new ad hoc shift
    if (iteration == 30) {
        double s = (shift.y - shift.x) / 2.0;
        s = s * s + shift.w;
        if (Precision.compareTo(s, 0.0d, epsilon) > 0) {
            s = FastMath.sqrt(s);
            if (shift.y < shift.x) {
                s = -s;
            }
            s = shift.x - shift.w / ((shift.y - shift.x) / 2.0 + s);
            for (int i = 0; i <= idx; i++) {
                matrixT[i][i] -= s;
            }
            shift.exShift += s;
            shift.x = shift.y = shift.w = 0.964;
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-848_ad252a8c,Major,src/main/java/org/apache/commons/math3/linear/SchurTransformer.java,348,432,"/**
 * Perform a double QR step involving rows l:idx and columns m:n
 *
 * @param l the index of the small sub-diagonal element
 * @param m the start index for the QR step
 * @param idx the current eigenvalue index
 * @param shift shift information holder
 * @param hVec the initial houseHolder vector
 */
private void performDoubleQRStep(final int l, final int m, final int idx, final ShiftInfo shift, final double[] hVec) {
    final int n = matrixT.length;
    double p = hVec[0];
    double q = hVec[1];
    double r = hVec[2];
    for (int k = m; k <= idx - 1; k++) {
        boolean notlast = k != idx - 1;
        if (k != m) {
            p = matrixT[k][k - 1];
            q = matrixT[k + 1][k - 1];
            r = notlast ? matrixT[k + 2][k - 1] : 0.0;
            shift.x = FastMath.abs(p) + FastMath.abs(q) + FastMath.abs(r);
            if (!Precision.equals(shift.x, 0.0, epsilon)) {
                p = p / shift.x;
                q = q / shift.x;
                r = r / shift.x;
            }
        }
        if (Precision.equals(shift.x, 0.0, epsilon)) {
            break;
        }
        double s = FastMath.sqrt(p * p + q * q + r * r);
        if (p < 0.0) {
            s = -s;
        }
        if (!Precision.equals(s, 0.0, epsilon)) {
            if (k != m) {
                matrixT[k][k - 1] = -s * shift.x;
            } else if (l != m) {
                matrixT[k][k - 1] = -matrixT[k][k - 1];
            }
            p = p + s;
            shift.x = p / s;
            shift.y = q / s;
            double z = r / s;
            q = q / p;
            r = r / p;
            // Row modification
            for (int j = k; j < n; j++) {
                p = matrixT[k][j] + q * matrixT[k + 1][j];
                if (notlast) {
                    p = p + r * matrixT[k + 2][j];
                    matrixT[k + 2][j] = matrixT[k + 2][j] - p * z;
                }
                matrixT[k][j] = matrixT[k][j] - p * shift.x;
                matrixT[k + 1][j] = matrixT[k + 1][j] - p * shift.y;
            }
            // Column modification
            for (int i = 0; i <= FastMath.min(idx, k + 3); i++) {
                p = shift.x * matrixT[i][k] + shift.y * matrixT[i][k + 1];
                if (notlast) {
                    p = p + z * matrixT[i][k + 2];
                    matrixT[i][k + 2] = matrixT[i][k + 2] - p * r;
                }
                matrixT[i][k] = matrixT[i][k] - p;
                matrixT[i][k + 1] = matrixT[i][k + 1] - p * q;
            }
            // Accumulate transformations
            final int high = matrixT.length - 1;
            for (int i = 0; i <= high; i++) {
                p = shift.x * matrixP[i][k] + shift.y * matrixP[i][k + 1];
                if (notlast) {
                    p = p + z * matrixP[i][k + 2];
                    matrixP[i][k + 2] = matrixP[i][k + 2] - p * r;
                }
                matrixP[i][k] = matrixP[i][k] - p;
                matrixP[i][k + 1] = matrixP[i][k + 1] - p * q;
            }
        }
    // (s != 0)
    }
    // clean up pollution due to round-off errors
    for (int i = m + 2; i <= idx; i++) {
        matrixT[i][i - 2] = 0.0;
        if (i > m + 2) {
            matrixT[i][i - 3] = 0.0;
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-855_350f726c,Minor,src/main/java/org/apache/commons/math3/optimization/univariate/BrentOptimizer.java,107,270,"/**
 * {@inheritDoc}
 */
@Override
protected UnivariatePointValuePair doOptimize() {
    final boolean isMinim = getGoalType() == GoalType.MINIMIZE;
    final double lo = getMin();
    final double mid = getStartValue();
    final double hi = getMax();
    // Optional additional convergence criteria.
    final ConvergenceChecker<UnivariatePointValuePair> checker = getConvergenceChecker();
    double a;
    double b;
    if (lo < hi) {
        a = lo;
        b = hi;
    } else {
        a = hi;
        b = lo;
    }
    double x = mid;
    double v = x;
    double w = x;
    double d = 0;
    double e = 0;
    double fx = computeObjectiveValue(x);
    if (!isMinim) {
        fx = -fx;
    }
    double fv = fx;
    double fw = fx;
    UnivariatePointValuePair previous = null;
    UnivariatePointValuePair current = new UnivariatePointValuePair(x, isMinim ? fx : -fx);
    int iter = 0;
    while (true) {
        final double m = 0.5 * (a + b);
        final double tol1 = relativeThreshold * FastMath.abs(x) + absoluteThreshold;
        final double tol2 = 2 * tol1;
        // Default stopping criterion.
        final boolean stop = FastMath.abs(x - m) <= tol2 - 0.5 * (b - a);
        if (!stop) {
            double p = 0;
            double q = 0;
            double r = 0;
            double u = 0;
            if (FastMath.abs(e) > tol1) {
                // Fit parabola.
                r = (x - w) * (fx - fv);
                q = (x - v) * (fx - fw);
                p = (x - v) * q - (x - w) * r;
                q = 2 * (q - r);
                if (q > 0) {
                    p = -p;
                } else {
                    q = -q;
                }
                r = e;
                e = d;
                if (p > q * (a - x) && p < q * (b - x) && FastMath.abs(p) < FastMath.abs(0.5 * q * r)) {
                    // Parabolic interpolation step.
                    d = p / q;
                    u = x + d;
                    // f must not be evaluated too close to a or b.
                    if (u - a < tol2 || b - u < tol2) {
                        if (x <= m) {
                            d = tol1;
                        } else {
                            d = -tol1;
                        }
                    }
                } else {
                    // Golden section step.
                    if (x < m) {
                        e = b - x;
                    } else {
                        e = a - x;
                    }
                    d = GOLDEN_SECTION * e;
                }
            } else {
                // Golden section step.
                if (x < m) {
                    e = b - x;
                } else {
                    e = a - x;
                }
                d = GOLDEN_SECTION * e;
            }
            // Update by at least ""tol1"".
            if (FastMath.abs(d) < tol1) {
                if (d >= 0) {
                    u = x + tol1;
                } else {
                    u = x - tol1;
                }
            } else {
                u = x + d;
            }
            double fu = computeObjectiveValue(u);
            if (!isMinim) {
                fu = -fu;
            }
            // User-defined convergence checker.
            previous = current;
            current = new UnivariatePointValuePair(u, isMinim ? fu : -fu);
            if (checker != null) {
                if (checker.converged(iter, previous, current)) {
                    return current;
                }
            }
            // Update a, b, v, w and x.
            if (fu <= fx) {
                if (u < x) {
                    b = x;
                } else {
                    a = x;
                }
                v = w;
                fv = fw;
                w = x;
                fw = fx;
                x = u;
                fx = fu;
            } else {
                if (u < x) {
                    a = u;
                } else {
                    b = u;
                }
                if (fu <= fw || Precision.equals(w, x)) {
                    v = w;
                    fv = fw;
                    w = u;
                    fw = fu;
                } else if (fu <= fv || Precision.equals(v, x) || Precision.equals(v, w)) {
                    v = u;
                    fv = fu;
                }
            }
        } else {
            // Default termination (Brent's criterion).
            return current;
        }
        ++iter;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-855_ac597cc1,Minor,src/main/java/org/apache/commons/math3/optimization/univariate/BrentOptimizer.java,108,271,"/**
 * {@inheritDoc}
 */
@Override
protected UnivariatePointValuePair doOptimize() {
    final boolean isMinim = getGoalType() == GoalType.MINIMIZE;
    final double lo = getMin();
    final double mid = getStartValue();
    final double hi = getMax();
    // Optional additional convergence criteria.
    final ConvergenceChecker<UnivariatePointValuePair> checker = getConvergenceChecker();
    double a;
    double b;
    if (lo < hi) {
        a = lo;
        b = hi;
    } else {
        a = hi;
        b = lo;
    }
    double x = mid;
    double v = x;
    double w = x;
    double d = 0;
    double e = 0;
    double fx = computeObjectiveValue(x);
    if (!isMinim) {
        fx = -fx;
    }
    double fv = fx;
    double fw = fx;
    UnivariatePointValuePair previous = null;
    UnivariatePointValuePair current = new UnivariatePointValuePair(x, isMinim ? fx : -fx);
    int iter = 0;
    while (true) {
        final double m = 0.5 * (a + b);
        final double tol1 = relativeThreshold * FastMath.abs(x) + absoluteThreshold;
        final double tol2 = 2 * tol1;
        // Default stopping criterion.
        final boolean stop = FastMath.abs(x - m) <= tol2 - 0.5 * (b - a);
        if (!stop) {
            double p = 0;
            double q = 0;
            double r = 0;
            double u = 0;
            if (FastMath.abs(e) > tol1) {
                // Fit parabola.
                r = (x - w) * (fx - fv);
                q = (x - v) * (fx - fw);
                p = (x - v) * q - (x - w) * r;
                q = 2 * (q - r);
                if (q > 0) {
                    p = -p;
                } else {
                    q = -q;
                }
                r = e;
                e = d;
                if (p > q * (a - x) && p < q * (b - x) && FastMath.abs(p) < FastMath.abs(0.5 * q * r)) {
                    // Parabolic interpolation step.
                    d = p / q;
                    u = x + d;
                    // f must not be evaluated too close to a or b.
                    if (u - a < tol2 || b - u < tol2) {
                        if (x <= m) {
                            d = tol1;
                        } else {
                            d = -tol1;
                        }
                    }
                } else {
                    // Golden section step.
                    if (x < m) {
                        e = b - x;
                    } else {
                        e = a - x;
                    }
                    d = GOLDEN_SECTION * e;
                }
            } else {
                // Golden section step.
                if (x < m) {
                    e = b - x;
                } else {
                    e = a - x;
                }
                d = GOLDEN_SECTION * e;
            }
            // Update by at least ""tol1"".
            if (FastMath.abs(d) < tol1) {
                if (d >= 0) {
                    u = x + tol1;
                } else {
                    u = x - tol1;
                }
            } else {
                u = x + d;
            }
            double fu = computeObjectiveValue(u);
            if (!isMinim) {
                fu = -fu;
            }
            // User-defined convergence checker.
            previous = current;
            current = new UnivariatePointValuePair(u, isMinim ? fu : -fu);
            if (checker != null) {
                if (checker.converged(iter, previous, current)) {
                    return best(current, previous, isMinim);
                }
            }
            // Update a, b, v, w and x.
            if (fu <= fx) {
                if (u < x) {
                    b = x;
                } else {
                    a = x;
                }
                v = w;
                fv = fw;
                w = x;
                fw = fx;
                x = u;
                fx = fu;
            } else {
                if (u < x) {
                    a = u;
                } else {
                    b = u;
                }
                if (fu <= fw || Precision.equals(w, x)) {
                    v = w;
                    fv = fw;
                    w = u;
                    fw = fu;
                } else if (fu <= fv || Precision.equals(v, x) || Precision.equals(v, w)) {
                    v = u;
                    fv = fu;
                }
            }
        } else {
            // Default termination (Brent's criterion).
            return best(current, previous, isMinim);
        }
        ++iter;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-855_ac597cc1,Minor,src/main/java/org/apache/commons/math3/optimization/univariate/BrentOptimizer.java,283,298,"/**
 * Selects the best of two points.
 *
 * @param a Point and value.
 * @param b Point and value.
 * @param isMinim {@code true} if the selected point must be the one with
 * the lowest value.
 * @return the best point, or {@code null} if {@code a} and {@code b} are
 * both {@code null}.
 */
private UnivariatePointValuePair best(UnivariatePointValuePair a, UnivariatePointValuePair b, boolean isMinim) {
    if (a == null) {
        return b;
    }
    if (b == null) {
        return a;
    }
    if (isMinim) {
        return a.getValue() < b.getValue() ? a : b;
    } else {
        return a.getValue() > b.getValue() ? a : b;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-859_66dece12,Major,src/main/java/org/apache/commons/math3/distribution/FDistribution.java,274,276,"/**
 * {@inheritDoc}
 */
public boolean isSupportLowerBoundInclusive() {
    return true;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-859_66dece12,Major,src/main/java/org/apache/commons/math3/distribution/RealDistribution.java,145,145,"/**
 * Use this method to get information about whether the lower bound
 * of the support is inclusive or not.
 *
 * @return whether the lower bound of the support is inclusive or not
 */
boolean isSupportLowerBoundInclusive();"
commons-math,remotes/origin/bugs-dot-jar_MATH-859_66dece12,Major,src/main/java/org/apache/commons/math3/distribution/RealDistribution.java,153,153,"/**
 * Use this method to get information about whether the upper bound
 * of the support is inclusive or not.
 *
 * @return whether the upper bound of the support is inclusive or not
 */
boolean isSupportUpperBoundInclusive();"
commons-math,remotes/origin/bugs-dot-jar_MATH-859_66dece12,Major,src/main/java/org/apache/commons/math3/distribution/UniformRealDistribution.java,183,185,"/**
 * {@inheritDoc}
 */
public boolean isSupportUpperBoundInclusive() {
    return false;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-864_abe53a53,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,346,491,"/**
 * {@inheritDoc}
 */
@Override
protected PointValuePair doOptimize() {
    checkParameters();
    // -------------------- Initialization --------------------------------
    isMinimize = getGoalType().equals(GoalType.MINIMIZE);
    final FitnessFunction fitfun = new FitnessFunction();
    final double[] guess = fitfun.encode(getStartPoint());
    // number of objective variables/problem dimension
    dimension = guess.length;
    initializeCMA(guess);
    iterations = 0;
    double bestValue = fitfun.value(guess);
    push(fitnessHistory, bestValue);
    PointValuePair optimum = new PointValuePair(getStartPoint(), isMinimize ? bestValue : -bestValue);
    PointValuePair lastResult = null;
    generationLoop: for (iterations = 1; iterations <= maxIterations; iterations++) {
        // Generate and evaluate lambda offspring
        RealMatrix arz = randn1(dimension, lambda);
        RealMatrix arx = zeros(dimension, lambda);
        double[] fitness = new double[lambda];
        // generate random offspring
        for (int k = 0; k < lambda; k++) {
            RealMatrix arxk = null;
            for (int i = 0; i < checkFeasableCount + 1; i++) {
                if (diagonalOnly <= 0) {
                    arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k)).scalarMultiply(// m + sig * Normal(0,C)
                    sigma));
                } else {
                    arxk = xmean.add(times(diagD, arz.getColumnMatrix(k)).scalarMultiply(sigma));
                }
                if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {
                    break;
                }
                // regenerate random arguments for row
                arz.setColumn(k, randn(dimension));
            }
            copyColumn(arxk, 0, arx, k);
            try {
                // compute fitness
                fitness[k] = fitfun.value(arx.getColumn(k));
            } catch (TooManyEvaluationsException e) {
                break generationLoop;
            }
        }
        // Sort by fitness and compute weighted mean into xmean
        int[] arindex = sortedIndices(fitness);
        // Calculate new xmean, this is selection and recombination
        // for speed up of Eq. (2) and (3)
        RealMatrix xold = xmean;
        RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));
        xmean = bestArx.multiply(weights);
        RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));
        RealMatrix zmean = bestArz.multiply(weights);
        boolean hsig = updateEvolutionPaths(zmean, xold);
        if (diagonalOnly <= 0) {
            updateCovariance(hsig, bestArx, arz, arindex, xold);
        } else {
            updateCovarianceDiagonalOnly(hsig, bestArz, xold);
        }
        // Adapt step size sigma - Eq. (5)
        sigma *= Math.exp(Math.min(1.0, (normps / chiN - 1.) * cs / damps));
        double bestFitness = fitness[arindex[0]];
        double worstFitness = fitness[arindex[arindex.length - 1]];
        if (bestValue > bestFitness) {
            bestValue = bestFitness;
            lastResult = optimum;
            optimum = new PointValuePair(fitfun.decode(bestArx.getColumn(0)), isMinimize ? bestFitness : -bestFitness);
            if (getConvergenceChecker() != null && lastResult != null) {
                if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {
                    break generationLoop;
                }
            }
        }
        // Break, if fitness is good enough
        if (stopFitness != 0) {
            // only if stopFitness is defined
            if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {
                break generationLoop;
            }
        }
        double[] sqrtDiagC = sqrt(diagC).getColumn(0);
        double[] pcCol = pc.getColumn(0);
        for (int i = 0; i < dimension; i++) {
            if (sigma * (Math.max(Math.abs(pcCol[i]), sqrtDiagC[i])) > stopTolX) {
                break;
            }
            if (i >= dimension - 1) {
                break generationLoop;
            }
        }
        for (int i = 0; i < dimension; i++) {
            if (sigma * sqrtDiagC[i] > stopTolUpX) {
                break generationLoop;
            }
        }
        double historyBest = min(fitnessHistory);
        double historyWorst = max(fitnessHistory);
        if (iterations > 2 && Math.max(historyWorst, worstFitness) - Math.min(historyBest, bestFitness) < stopTolFun) {
            break generationLoop;
        }
        if (iterations > fitnessHistory.length && historyWorst - historyBest < stopTolHistFun) {
            break generationLoop;
        }
        // condition number of the covariance matrix exceeds 1e14
        if (max(diagD) / min(diagD) > 1e7) {
            break generationLoop;
        }
        // user defined termination
        if (getConvergenceChecker() != null) {
            PointValuePair current = new PointValuePair(bestArx.getColumn(0), isMinimize ? bestFitness : -bestFitness);
            if (lastResult != null && getConvergenceChecker().converged(iterations, current, lastResult)) {
                break generationLoop;
            }
            lastResult = current;
        }
        // Adjust step size in case of equal function values (flat fitness)
        if (bestValue == fitness[arindex[(int) (0.1 + lambda / 4.)]]) {
            sigma = sigma * Math.exp(0.2 + cs / damps);
        }
        if (iterations > 2 && Math.max(historyWorst, bestFitness) - Math.min(historyBest, bestFitness) == 0) {
            sigma = sigma * Math.exp(0.2 + cs / damps);
        }
        // store best in history
        push(fitnessHistory, bestFitness);
        fitfun.setValueRange(worstFitness - bestFitness);
        if (generateStatistics) {
            statisticsSigmaHistory.add(sigma);
            statisticsFitnessHistory.add(bestFitness);
            statisticsMeanHistory.add(xmean.transpose());
            statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));
        }
    }
    return optimum;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-865_b55e0206,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,498,553,"/**
 * Checks dimensions and values of boundaries and inputSigma if defined.
 */
private void checkParameters() {
    final double[] init = getStartPoint();
    final double[] lB = getLowerBound();
    final double[] uB = getUpperBound();
    // Checks whether there is at least one finite bound value.
    boolean hasFiniteBounds = false;
    for (int i = 0; i < lB.length; i++) {
        if (!Double.isInfinite(lB[i]) || !Double.isInfinite(uB[i])) {
            hasFiniteBounds = true;
            break;
        }
    }
    // Checks whether there is at least one infinite bound value.
    boolean hasInfiniteBounds = false;
    if (hasFiniteBounds) {
        for (int i = 0; i < lB.length; i++) {
            if (Double.isInfinite(lB[i]) || Double.isInfinite(uB[i])) {
                hasInfiniteBounds = true;
                break;
            }
        }
        if (hasInfiniteBounds) {
            // because mixed cases are not supported by the current code.
            throw new MathUnsupportedOperationException();
        } else {
            // Convert API to internal handling of boundaries.
            boundaries = new double[2][];
            boundaries[0] = lB;
            boundaries[1] = uB;
        }
    } else {
        // Convert API to internal handling of boundaries.
        boundaries = null;
    }
    if (inputSigma != null) {
        if (inputSigma.length != init.length) {
            throw new DimensionMismatchException(inputSigma.length, init.length);
        }
        for (int i = 0; i < init.length; i++) {
            if (inputSigma[i] < 0) {
                throw new NotPositiveException(inputSigma[i]);
            }
            if (boundaries != null) {
                if (inputSigma[i] > boundaries[1][i] - boundaries[0][i]) {
                    throw new OutOfRangeException(inputSigma[i], 0, boundaries[1][i] - boundaries[0][i]);
                }
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-867_bfbb156d,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,354,499,"/**
 * {@inheritDoc}
 */
@Override
protected PointValuePair doOptimize() {
    checkParameters();
    // -------------------- Initialization --------------------------------
    isMinimize = getGoalType().equals(GoalType.MINIMIZE);
    final FitnessFunction fitfun = new FitnessFunction();
    final double[] guess = fitfun.encode(getStartPoint());
    // number of objective variables/problem dimension
    dimension = guess.length;
    initializeCMA(guess);
    iterations = 0;
    double bestValue = fitfun.value(guess);
    push(fitnessHistory, bestValue);
    PointValuePair optimum = new PointValuePair(getStartPoint(), isMinimize ? bestValue : -bestValue);
    PointValuePair lastResult = null;
    generationLoop: for (iterations = 1; iterations <= maxIterations; iterations++) {
        // Generate and evaluate lambda offspring
        RealMatrix arz = randn1(dimension, lambda);
        RealMatrix arx = zeros(dimension, lambda);
        double[] fitness = new double[lambda];
        // generate random offspring
        for (int k = 0; k < lambda; k++) {
            RealMatrix arxk = null;
            for (int i = 0; i < checkFeasableCount + 1; i++) {
                if (diagonalOnly <= 0) {
                    arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k)).scalarMultiply(// m + sig * Normal(0,C)
                    sigma));
                } else {
                    arxk = xmean.add(times(diagD, arz.getColumnMatrix(k)).scalarMultiply(sigma));
                }
                if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {
                    break;
                }
                // regenerate random arguments for row
                arz.setColumn(k, randn(dimension));
            }
            copyColumn(arxk, 0, arx, k);
            try {
                // compute fitness
                fitness[k] = fitfun.value(arx.getColumn(k));
            } catch (TooManyEvaluationsException e) {
                break generationLoop;
            }
        }
        // Sort by fitness and compute weighted mean into xmean
        int[] arindex = sortedIndices(fitness);
        // Calculate new xmean, this is selection and recombination
        // for speed up of Eq. (2) and (3)
        RealMatrix xold = xmean;
        RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));
        xmean = bestArx.multiply(weights);
        RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));
        RealMatrix zmean = bestArz.multiply(weights);
        boolean hsig = updateEvolutionPaths(zmean, xold);
        if (diagonalOnly <= 0) {
            updateCovariance(hsig, bestArx, arz, arindex, xold);
        } else {
            updateCovarianceDiagonalOnly(hsig, bestArz, xold);
        }
        // Adapt step size sigma - Eq. (5)
        sigma *= Math.exp(Math.min(1.0, (normps / chiN - 1.) * cs / damps));
        double bestFitness = fitness[arindex[0]];
        double worstFitness = fitness[arindex[arindex.length - 1]];
        if (bestValue > bestFitness) {
            bestValue = bestFitness;
            lastResult = optimum;
            optimum = new PointValuePair(fitfun.repairAndDecode(bestArx.getColumn(0)), isMinimize ? bestFitness : -bestFitness);
            if (getConvergenceChecker() != null && lastResult != null) {
                if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {
                    break generationLoop;
                }
            }
        }
        // Break, if fitness is good enough
        if (stopFitness != 0) {
            // only if stopFitness is defined
            if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {
                break generationLoop;
            }
        }
        double[] sqrtDiagC = sqrt(diagC).getColumn(0);
        double[] pcCol = pc.getColumn(0);
        for (int i = 0; i < dimension; i++) {
            if (sigma * (Math.max(Math.abs(pcCol[i]), sqrtDiagC[i])) > stopTolX) {
                break;
            }
            if (i >= dimension - 1) {
                break generationLoop;
            }
        }
        for (int i = 0; i < dimension; i++) {
            if (sigma * sqrtDiagC[i] > stopTolUpX) {
                break generationLoop;
            }
        }
        double historyBest = min(fitnessHistory);
        double historyWorst = max(fitnessHistory);
        if (iterations > 2 && Math.max(historyWorst, worstFitness) - Math.min(historyBest, bestFitness) < stopTolFun) {
            break generationLoop;
        }
        if (iterations > fitnessHistory.length && historyWorst - historyBest < stopTolHistFun) {
            break generationLoop;
        }
        // condition number of the covariance matrix exceeds 1e14
        if (max(diagD) / min(diagD) > 1e7) {
            break generationLoop;
        }
        // user defined termination
        if (getConvergenceChecker() != null) {
            PointValuePair current = new PointValuePair(bestArx.getColumn(0), isMinimize ? bestFitness : -bestFitness);
            if (lastResult != null && getConvergenceChecker().converged(iterations, current, lastResult)) {
                break generationLoop;
            }
            lastResult = current;
        }
        // Adjust step size in case of equal function values (flat fitness)
        if (bestValue == fitness[arindex[(int) (0.1 + lambda / 4.)]]) {
            sigma = sigma * Math.exp(0.2 + cs / damps);
        }
        if (iterations > 2 && Math.max(historyWorst, bestFitness) - Math.min(historyBest, bestFitness) == 0) {
            sigma = sigma * Math.exp(0.2 + cs / damps);
        }
        // store best in history
        push(fitnessHistory, bestFitness);
        fitfun.setValueRange(worstFitness - bestFitness);
        if (generateStatistics) {
            statisticsSigmaHistory.add(sigma);
            statisticsFitnessHistory.add(bestFitness);
            statisticsMeanHistory.add(xmean.transpose());
            statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));
        }
    }
    return optimum;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-867_bfbb156d,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,504,574,"/**
 * Checks dimensions and values of boundaries and inputSigma if defined.
 */
private void checkParameters() {
    final double[] init = getStartPoint();
    final double[] lB = getLowerBound();
    final double[] uB = getUpperBound();
    // Checks whether there is at least one finite bound value.
    boolean hasFiniteBounds = false;
    for (int i = 0; i < lB.length; i++) {
        if (!Double.isInfinite(lB[i]) || !Double.isInfinite(uB[i])) {
            hasFiniteBounds = true;
            break;
        }
    }
    // Checks whether there is at least one infinite bound value.
    boolean hasInfiniteBounds = false;
    if (hasFiniteBounds) {
        for (int i = 0; i < lB.length; i++) {
            if (Double.isInfinite(lB[i]) || Double.isInfinite(uB[i])) {
                hasInfiniteBounds = true;
                break;
            }
        }
        if (hasInfiniteBounds) {
            // because mixed cases are not supported by the current code.
            throw new MathUnsupportedOperationException();
        } else {
            // Convert API to internal handling of boundaries.
            boundaries = new double[2][];
            boundaries[0] = lB;
            boundaries[1] = uB;
            // Abort early if the normalization will overflow (cf. ""encode"" method).
            for (int i = 0; i < lB.length; i++) {
                if (Double.isInfinite(boundaries[1][i] - boundaries[0][i])) {
                    final double max = Double.MAX_VALUE + boundaries[0][i];
                    final NumberIsTooLargeException e = new NumberIsTooLargeException(boundaries[1][i], max, true);
                    e.getContext().addMessage(LocalizedFormats.OVERFLOW);
                    e.getContext().addMessage(LocalizedFormats.INDEX, i);
                    throw e;
                }
            }
        }
    } else {
        // Convert API to internal handling of boundaries.
        boundaries = null;
    }
    if (inputSigma != null) {
        if (inputSigma.length != init.length) {
            throw new DimensionMismatchException(inputSigma.length, init.length);
        }
        for (int i = 0; i < init.length; i++) {
            if (inputSigma[i] < 0) {
                throw new NotPositiveException(inputSigma[i]);
            }
            if (boundaries != null) {
                if (inputSigma[i] > boundaries[1][i] - boundaries[0][i]) {
                    throw new OutOfRangeException(inputSigma[i], 0, boundaries[1][i] - boundaries[0][i]);
                }
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-867_bfbb156d,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,581,648,"/**
 * Initialization of the dynamic search parameters
 *
 * @param guess Initial guess for the arguments of the fitness function.
 */
private void initializeCMA(double[] guess) {
    if (lambda <= 0) {
        lambda = 4 + (int) (3. * Math.log(dimension));
    }
    // initialize sigma
    double[][] sigmaArray = new double[guess.length][1];
    for (int i = 0; i < guess.length; i++) {
        final double range = (boundaries == null) ? 1.0 : boundaries[1][i] - boundaries[0][i];
        sigmaArray[i][0] = ((inputSigma == null) ? 0.3 : inputSigma[i]) / range;
    }
    RealMatrix insigma = new Array2DRowRealMatrix(sigmaArray, false);
    // overall standard deviation
    sigma = max(insigma);
    // initialize termination criteria
    stopTolUpX = 1e3 * max(insigma);
    stopTolX = 1e-11 * max(insigma);
    stopTolFun = 1e-12;
    stopTolHistFun = 1e-13;
    // initialize selection strategy parameters
    // number of parents/points for recombination
    mu = lambda / 2;
    logMu2 = Math.log(mu + 0.5);
    weights = log(sequence(1, mu, 1)).scalarMultiply(-1.).scalarAdd(logMu2);
    double sumw = 0;
    double sumwq = 0;
    for (int i = 0; i < mu; i++) {
        double w = weights.getEntry(i, 0);
        sumw += w;
        sumwq += w * w;
    }
    weights = weights.scalarMultiply(1. / sumw);
    // variance-effectiveness of sum w_i x_i
    mueff = sumw * sumw / sumwq;
    // initialize dynamic strategy parameters and constants
    cc = (4. + mueff / dimension) / (dimension + 4. + 2. * mueff / dimension);
    cs = (mueff + 2.) / (dimension + mueff + 3.);
    damps = (1. + 2. * Math.max(0, Math.sqrt((mueff - 1.) / (dimension + 1.)) - 1.)) * Math.max(0.3, 1. - dimension / (1e-6 + Math.min(maxIterations, getMaxEvaluations() / lambda))) + // minor increment
    cs;
    ccov1 = 2. / ((dimension + 1.3) * (dimension + 1.3) + mueff);
    ccovmu = Math.min(1 - ccov1, 2. * (mueff - 2. + 1. / mueff) / ((dimension + 2.) * (dimension + 2.) + mueff));
    ccov1Sep = Math.min(1, ccov1 * (dimension + 1.5) / 3.);
    ccovmuSep = Math.min(1 - ccov1, ccovmu * (dimension + 1.5) / 3.);
    chiN = Math.sqrt(dimension) * (1. - 1. / (4. * dimension) + 1 / (21. * dimension * dimension));
    // intialize CMA internal values - updated each generation
    // objective
    xmean = MatrixUtils.createColumnRealMatrix(guess);
    // variables
    diagD = insigma.scalarMultiply(1. / sigma);
    diagC = square(diagD);
    // evolution paths for C and sigma
    pc = zeros(dimension, 1);
    // B defines the coordinate system
    ps = zeros(dimension, 1);
    normps = ps.getFrobeniusNorm();
    B = eye(dimension, dimension);
    // diagonal D defines the scaling
    D = ones(dimension, 1);
    BD = times(B, repmat(diagD.transpose(), dimension, 1));
    // covariance
    C = B.multiply(diag(square(D)).multiply(B.transpose()));
    historySize = 10 + (int) (3. * 10. * dimension / lambda);
    // history of fitness values
    fitnessHistory = new double[historySize];
    for (int i = 0; i < historySize; i++) {
        fitnessHistory[i] = Double.MAX_VALUE;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-867_bfbb156d,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,925,935,"/**
 * @param x Original objective variables.
 * @return the normalized objective variables.
 */
public double[] encode(final double[] x) {
    if (boundaries == null) {
        return x;
    }
    double[] res = new double[x.length];
    for (int i = 0; i < x.length; i++) {
        double diff = boundaries[1][i] - boundaries[0][i];
        res[i] = x[i] / diff;
    }
    return res;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-867_bfbb156d,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,941,945,"/**
 * @param x Normalized objective variables.
 * @return the original objective variables, possibly repaired.
 */
public double[] repairAndDecode(final double[] x) {
    return boundaries != null && isRepairMode ? decode(repair(x)) : decode(x);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-867_bfbb156d,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,951,961,"/**
 * @param x Normalized objective variables.
 * @return the original objective variables.
 */
public double[] decode(final double[] x) {
    if (boundaries == null) {
        return x;
    }
    double[] res = new double[x.length];
    for (int i = 0; i < x.length; i++) {
        double diff = boundaries[1][i] - boundaries[0][i];
        res[i] = diff * x[i];
    }
    return res;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-867_bfbb156d,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,967,979,"/**
 * @param point Normalized objective variables.
 * @return the objective value + penalty for violated bounds.
 */
public double value(final double[] point) {
    double value;
    if (boundaries != null && isRepairMode) {
        double[] repaired = repair(point);
        value = CMAESOptimizer.this.computeObjectiveValue(decode(repaired)) + penalty(point, repaired);
    } else {
        value = CMAESOptimizer.this.computeObjectiveValue(decode(point));
    }
    return isMinimize ? value : -value;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-867_bfbb156d,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,985,1002,"/**
 * @param x Normalized objective variables.
 * @return {@code true} if in bounds.
 */
public boolean isFeasible(final double[] x) {
    if (boundaries == null) {
        return true;
    }
    final double[] bLoEnc = encode(boundaries[0]);
    final double[] bHiEnc = encode(boundaries[1]);
    for (int i = 0; i < x.length; i++) {
        if (x[i] < bLoEnc[i]) {
            return false;
        }
        if (x[i] > bHiEnc[i]) {
            return false;
        }
    }
    return true;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-867_bfbb156d,Major,src/main/java/org/apache/commons/math3/optimization/direct/CMAESOptimizer.java,1015,1027,"/**
 * @param x Normalized objective variables.
 * @return the repaired objective variables - all in bounds.
 */
private double[] repair(final double[] x) {
    double[] repaired = new double[x.length];
    for (int i = 0; i < x.length; i++) {
        if (x[i] < 0) {
            repaired[i] = 0;
        } else if (x[i] > 1.0) {
            repaired[i] = 1.0;
        } else {
            repaired[i] = x[i];
        }
    }
    return repaired;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-880_2a9cbbab,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,157,177,"/**
 * Build the BSP tree of a polygons set from a simple list of vertices.
 * <p>The boundary is provided as a list of points considering to
 * represent the vertices of a simple loop. The interior part of the
 * region is on the left side of this path and the exterior is on its
 * right side.</p>
 * <p>This constructor does not handle polygons with a boundary
 * forming several disconnected paths (such as polygons with holes).</p>
 * <p>For cases where this simple constructor applies, it is expected to
 * be numerically more robust than the {@link #PolygonsSet(Collection) general
 * constructor} using {@link SubHyperplane subhyperplanes}.</p>
 * @param hyperplaneThickness tolerance below which points are consider to
 * belong to the hyperplane (which is therefore more a slab)
 * @param vertices vertices of the simple loop boundary
 */
private static BSPTree<Euclidean2D> verticesToTree(final double hyperplaneThickness, final Vector2D... vertices) {
    if (vertices.length == 0) {
        // the tree represents the whole space
        return new BSPTree<Euclidean2D>(Boolean.TRUE);
    }
    // at start, none of the edges have been processed
    final BSPTree<Euclidean2D> tree = new BSPTree<Euclidean2D>();
    List<Vertex> list = new ArrayList<PolygonsSet.Vertex>(vertices.length);
    for (final Vector2D vertex : vertices) {
        list.add(new Vertex(vertex));
    }
    // build the tree top-down
    insertVertices(hyperplaneThickness, tree, list);
    return tree;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-880_2a9cbbab,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,187,297,"/**
 * Recursively build a tree by inserting cut sub-hyperplanes.
 * @param hyperplaneThickness tolerance below which points are consider to
 * belong to the hyperplane (which is therefore more a slab)
 * @param node current tree node (it is a leaf node at the beginning
 * of the call)
 * @param vertices list of vertices belonging to the boundary of the
 * cell defined by the node
 */
private static void insertVertices(final double hyperplaneThickness, final BSPTree<Euclidean2D> node, final List<Vertex> vertices) {
    Vertex current = vertices.get(vertices.size() - 1);
    int index = 0;
    Line inserted = null;
    while (inserted == null && index < vertices.size()) {
        final Vertex previous = current;
        current = vertices.get(index++);
        if (previous.outgoingNeedsProcessing() && current.incomingNeedsProcessing()) {
            if (previous.shareNodeWith(current)) {
                // both vertices are already handled by an existing node,
                // closer to the tree root, they were probably created
                // when split points were introduced
                inserted = null;
            } else {
                inserted = new Line(previous.getLocation(), current.getLocation());
                if (node.insertCut(inserted)) {
                    previous.addNode(node);
                    previous.outgoingProcessed();
                    current.addNode(node);
                    current.incomingProcessed();
                } else {
                    inserted = null;
                }
            }
        }
    }
    if (node.getCut() == null) {
        final BSPTree<Euclidean2D> parent = node.getParent();
        if (parent == null || node == parent.getMinus()) {
            node.setAttribute(Boolean.TRUE);
        } else {
            node.setAttribute(Boolean.FALSE);
        }
        return;
    }
    // distribute the remaining vertices in the two sub-trees
    Side currentSide = Side.HYPER;
    final List<Vertex> plusList = new ArrayList<Vertex>();
    plusList.add(current);
    int plusCount = 0;
    final List<Vertex> minusList = new ArrayList<Vertex>();
    minusList.add(current);
    int minusCount = 0;
    while (index < vertices.size()) {
        final Vertex previous = current;
        final Side previousSide = currentSide;
        current = vertices.get(index++);
        final double currentOffset = inserted.getOffset(current.getLocation());
        currentSide = (FastMath.abs(currentOffset) <= hyperplaneThickness) ? Side.HYPER : ((currentOffset < 0) ? Side.MINUS : Side.PLUS);
        switch(currentSide) {
            case PLUS:
                if (previousSide == Side.MINUS) {
                    // we need to insert a split point on the hyperplane
                    final Line line = new Line(previous.getLocation(), current.getLocation());
                    final Vertex splitPoint = new Vertex(inserted.intersection(line));
                    splitPoint.addNode(node);
                    minusList.add(splitPoint);
                    plusList.add(splitPoint);
                }
                plusList.add(current);
                if (current.incomingNeedsProcessing() || current.outgoingNeedsProcessing()) {
                    ++plusCount;
                }
                break;
            case MINUS:
                if (previousSide == Side.PLUS) {
                    // we need to insert a split point on the hyperplane
                    final Line line = new Line(previous.getLocation(), current.getLocation());
                    final Vertex splitPoint = new Vertex(inserted.intersection(line));
                    splitPoint.addNode(node);
                    minusList.add(splitPoint);
                    plusList.add(splitPoint);
                }
                minusList.add(current);
                if (current.incomingNeedsProcessing() || current.outgoingNeedsProcessing()) {
                    ++minusCount;
                }
                break;
            default:
                current.addNode(node);
                plusList.add(current);
                minusList.add(current);
                break;
        }
    }
    // recurse through lower levels
    if (plusCount > 0) {
        insertVertices(hyperplaneThickness, node.getPlus(), plusList);
    } else {
        node.getPlus().setAttribute(Boolean.FALSE);
    }
    if (minusCount > 0) {
        insertVertices(hyperplaneThickness, node.getMinus(), minusList);
    } else {
        node.getMinus().setAttribute(Boolean.TRUE);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-880_2a9cbbab,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,340,349,"/**
 * Check if the instance and another vertex share a node.
 * <p>
 * When two vertices share a node, this means they are already handled
 * by the hyperplane of this node, so there is no need to create a cut
 * hyperplane for them.
 * </p>
 * @param vertex other vertex to check instance against
 * @return true if the instance and another vertex share a node
 */
public boolean shareNodeWith(final Vertex vertex) {
    for (final BSPTree<Euclidean2D> node1 : nodes) {
        for (final BSPTree<Euclidean2D> node2 : vertex.nodes) {
            if (node1 == node2) {
                return true;
            }
        }
    }
    return false;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-880_2a9cbbab,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,354,356,"/**
 * Add a node whose hyperplane contains this vertex.
 * @param node node whose hyperplane contains this vertex
 */
public void addNode(final BSPTree<Euclidean2D> node) {
    nodes.add(node);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-880_2a9cbbab,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,361,363,"/**
 * Check incoming edge processed indicator.
 * @return true if incoming edge needs processing
 */
public boolean incomingNeedsProcessing() {
    return incomingNeedsProcessing;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-880_2a9cbbab,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,368,370,"/**
 * Check outgoing edge processed indicator.
 * @return true if outgoing edge needs processing
 */
public boolean outgoingNeedsProcessing() {
    return outgoingNeedsProcessing;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-880_2a9cbbab,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,374,376,"/**
 * Mark the incoming edge as processed.
 */
public void incomingProcessed() {
    incomingNeedsProcessing = false;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-880_2a9cbbab,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/PolygonsSet.java,380,382,"/**
 * Mark the outgoing edge as processed.
 */
public void outgoingProcessed() {
    outgoingNeedsProcessing = false;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-891_2b852d79,Major,src/main/java/org/apache/commons/math3/stat/correlation/SpearmansCorrelation.java,128,132,"/**
 * Computes the Spearman's rank correlation matrix for the columns of the
 * input matrix.
 *
 * @param matrix matrix with columns representing variables to correlate
 * @return correlation matrix
 */
public RealMatrix computeCorrelationMatrix(RealMatrix matrix) {
    RealMatrix matrixCopy = matrix.copy();
    rankTransform(matrixCopy);
    return new PearsonsCorrelation().computeCorrelationMatrix(matrixCopy);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-891_2b852d79,Major,src/main/java/org/apache/commons/math3/stat/correlation/SpearmansCorrelation.java,142,144,"/**
 * Computes the Spearman's rank correlation matrix for the columns of the
 * input rectangular array.  The columns of the array represent values
 * of variables to be correlated.
 *
 * @param matrix matrix with columns representing variables to correlate
 * @return correlation matrix
 */
public RealMatrix computeCorrelationMatrix(double[][] matrix) {
    return computeCorrelationMatrix(new BlockRealMatrix(matrix));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-891_2b852d79,Major,src/main/java/org/apache/commons/math3/stat/correlation/SpearmansCorrelation.java,155,165,"/**
 * Computes the Spearman's rank correlation coefficient between the two arrays.
 *
 * @param xArray first data array
 * @param yArray second data array
 * @return Returns Spearman's rank correlation coefficient for the two arrays
 * @throws DimensionMismatchException if the arrays lengths do not match
 * @throws MathIllegalArgumentException if the array length is less than 2
 */
public double correlation(final double[] xArray, final double[] yArray) {
    if (xArray.length != yArray.length) {
        throw new DimensionMismatchException(xArray.length, yArray.length);
    } else if (xArray.length < 2) {
        throw new MathIllegalArgumentException(LocalizedFormats.INSUFFICIENT_DIMENSION, xArray.length, 2);
    } else {
        return new PearsonsCorrelation().correlation(rankingAlgorithm.rank(xArray), rankingAlgorithm.rank(yArray));
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-891_2b852d79,Major,src/main/java/org/apache/commons/math3/stat/correlation/SpearmansCorrelation.java,173,177,"/**
 * Applies rank transform to each of the columns of <code>matrix</code>
 * using the current <code>rankingAlgorithm</code>
 *
 * @param matrix matrix to transform
 */
private void rankTransform(RealMatrix matrix) {
    for (int i = 0; i < matrix.getColumnDimension(); i++) {
        matrix.setColumn(i, rankingAlgorithm.rank(matrix.getColumn(i)));
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-899_ce126bdb,Minor,src/main/java/org/apache/commons/math3/random/SynchronizedRandomGenerator.java,84,86,"/**
 * {@inheritDoc}
 */
public synchronized int nextInt(int n) {
    return wrapped.nextInt();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-904_6844aba9,Major,src/main/java/org/apache/commons/math3/util/FastMath.java,1440,1598,"/**
 * Power function.  Compute x^y.
 *
 * @param x   a double
 * @param y   a double
 * @return double
 */
public static double pow(double x, double y) {
    final double[] lns = new double[2];
    if (y == 0.0) {
        return 1.0;
    }
    if (x != x) {
        // X is NaN
        return x;
    }
    if (x == 0) {
        long bits = Double.doubleToLongBits(x);
        if ((bits & 0x8000000000000000L) != 0) {
            // -zero
            long yi = (long) y;
            if (y < 0 && y == yi && (yi & 1) == 1) {
                return Double.NEGATIVE_INFINITY;
            }
            if (y > 0 && y == yi && (yi & 1) == 1) {
                return -0.0;
            }
        }
        if (y < 0) {
            return Double.POSITIVE_INFINITY;
        }
        if (y > 0) {
            return 0.0;
        }
        return Double.NaN;
    }
    if (x == Double.POSITIVE_INFINITY) {
        if (y != y) {
            // y is NaN
            return y;
        }
        if (y < 0.0) {
            return 0.0;
        } else {
            return Double.POSITIVE_INFINITY;
        }
    }
    if (y == Double.POSITIVE_INFINITY) {
        if (x * x == 1.0) {
            return Double.NaN;
        }
        if (x * x > 1.0) {
            return Double.POSITIVE_INFINITY;
        } else {
            return 0.0;
        }
    }
    if (x == Double.NEGATIVE_INFINITY) {
        if (y != y) {
            // y is NaN
            return y;
        }
        if (y < 0) {
            long yi = (long) y;
            if (y == yi && (yi & 1) == 1) {
                return -0.0;
            }
            return 0.0;
        }
        if (y > 0) {
            long yi = (long) y;
            if (y == yi && (yi & 1) == 1) {
                return Double.NEGATIVE_INFINITY;
            }
            return Double.POSITIVE_INFINITY;
        }
    }
    if (y == Double.NEGATIVE_INFINITY) {
        if (x * x == 1.0) {
            return Double.NaN;
        }
        if (x * x < 1.0) {
            return Double.POSITIVE_INFINITY;
        } else {
            return 0.0;
        }
    }
    /* Handle special case x<0 */
    if (x < 0) {
        // y is an even integer in this case
        if (y >= TWO_POWER_52 || y <= -TWO_POWER_52) {
            return pow(-x, y);
        }
        if (y == (long) y) {
            // If y is an integer
            return ((long) y & 1) == 0 ? pow(-x, y) : -pow(-x, y);
        } else {
            return Double.NaN;
        }
    }
    /* Split y into ya and yb such that y = ya+yb */
    double ya;
    double yb;
    if (y < 8e298 && y > -8e298) {
        double tmp1 = y * HEX_40000000;
        ya = y + tmp1 - tmp1;
        yb = y - ya;
    } else {
        double tmp1 = y * 9.31322574615478515625E-10;
        double tmp2 = tmp1 * 9.31322574615478515625E-10;
        ya = (tmp1 + tmp2 - tmp1) * HEX_40000000 * HEX_40000000;
        yb = y - ya;
    }
    /* Compute ln(x) */
    final double lores = log(x, lns);
    if (Double.isInfinite(lores)) {
        // don't allow this to be converted to NaN
        return lores;
    }
    double lna = lns[0];
    double lnb = lns[1];
    /* resplit lns */
    double tmp1 = lna * HEX_40000000;
    double tmp2 = lna + tmp1 - tmp1;
    lnb += lna - tmp2;
    lna = tmp2;
    // y*ln(x) = (aa+ab)
    final double aa = lna * ya;
    final double ab = lna * yb + lnb * ya + lnb * yb;
    lna = aa + ab;
    lnb = -(lna - aa - ab);
    double z = 1.0 / 120.0;
    z = z * lnb + (1.0 / 24.0);
    z = z * lnb + (1.0 / 6.0);
    z = z * lnb + 0.5;
    z = z * lnb + 1.0;
    z = z * lnb;
    final double result = exp(lna, z, null);
    // result = result + result * z;
    return result;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-924_2836a6f9,Critical,src/main/java/org/apache/commons/math3/optimization/general/AbstractLeastSquaresOptimizer.java,560,563,"/**
 * Computes the square-root of the weight matrix.
 *
 * @param m Symmetric, positive-definite (weight) matrix.
 * @return the square-root of the weight matrix.
 */
private RealMatrix squareRoot(RealMatrix m) {
    final EigenDecomposition dec = new EigenDecomposition(m);
    return dec.getSquareRoot();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-924_b07ecae3,Critical,src/main/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/AbstractLeastSquaresOptimizer.java,265,268,"/**
 * Computes the square-root of the weight matrix.
 *
 * @param m Symmetric, positive-definite (weight) matrix.
 * @return the square-root of the weight matrix.
 */
private RealMatrix squareRoot(RealMatrix m) {
    final EigenDecomposition dec = new EigenDecomposition(m);
    return dec.getSquareRoot();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-929_cedf0d27,Critical,src/main/java/org/apache/commons/math3/distribution/MultivariateNormalDistribution.java,177,186,"/**
 * {@inheritDoc}
 */
public double density(final double[] vals) throws DimensionMismatchException {
    final int dim = getDimension();
    if (vals.length != dim) {
        throw new DimensionMismatchException(vals.length, dim);
    }
    return FastMath.pow(2 * FastMath.PI, -dim / 2) * FastMath.pow(covarianceMatrixDeterminant, -0.5) * getExponentTerm(vals);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-934_724795b5,Minor,src/main/java/org/apache/commons/math3/complex/Complex.java,299,321,"/**
 * {@inheritDoc}
 */
public Complex reciprocal() {
    if (isNaN) {
        return NaN;
    }
    if (real == 0.0 && imaginary == 0.0) {
        return NaN;
    }
    if (isInfinite) {
        return ZERO;
    }
    if (FastMath.abs(real) < FastMath.abs(imaginary)) {
        double q = real / imaginary;
        double scale = 1. / (real * q + imaginary);
        return createComplex(scale * q, -scale);
    } else {
        double q = imaginary / real;
        double scale = 1. / (imaginary * q + real);
        return createComplex(scale, -scale * q);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-935_48dde378,Minor,src/main/java/org/apache/commons/math3/analysis/differentiation/DSCompiler.java,1382,1418,"/**
 * Compute two arguments arc tangent of a derivative structure.
 * @param y array holding the first operand
 * @param yOffset offset of the first operand in its array
 * @param x array holding the second operand
 * @param xOffset offset of the second operand in its array
 * @param result array where result must be stored (for
 * two arguments arc tangent the result array <em>cannot</em>
 * be the input array)
 * @param resultOffset offset of the result in its array
 */
public void atan2(final double[] y, final int yOffset, final double[] x, final int xOffset, final double[] result, final int resultOffset) {
    // compute r = sqrt(x^2+y^2)
    double[] tmp1 = new double[getSize()];
    // x^2
    multiply(x, xOffset, x, xOffset, tmp1, 0);
    double[] tmp2 = new double[getSize()];
    // y^2
    multiply(y, yOffset, y, yOffset, tmp2, 0);
    // x^2 + y^2
    add(tmp1, 0, tmp2, 0, tmp2, 0);
    // r = sqrt(x^2 + y^2)
    rootN(tmp2, 0, 2, tmp1, 0);
    if (x[xOffset] >= 0) {
        // compute atan2(y, x) = 2 atan(y / (r + x))
        // r + x
        add(tmp1, 0, x, xOffset, tmp2, 0);
        // y /(r + x)
        divide(y, yOffset, tmp2, 0, tmp1, 0);
        // atan(y / (r + x))
        atan(tmp1, 0, tmp2, 0);
        for (int i = 0; i < tmp2.length; ++i) {
            // 2 * atan(y / (r + x))
            result[resultOffset + i] = 2 * tmp2[i];
        }
    } else {
        // compute atan2(y, x) = +/- pi - 2 atan(y / (r - x))
        // r - x
        subtract(tmp1, 0, x, xOffset, tmp2, 0);
        // y /(r - x)
        divide(y, yOffset, tmp2, 0, tmp1, 0);
        // atan(y / (r - x))
        atan(tmp1, 0, tmp2, 0);
        result[resultOffset] = // +/-pi - 2 * atan(y / (r - x))
        ((tmp2[0] <= 0) ? -FastMath.PI : FastMath.PI) - 2 * tmp2[0];
        for (int i = 1; i < tmp2.length; ++i) {
            // +/-pi - 2 * atan(y / (r - x))
            result[resultOffset + i] = -2 * tmp2[i];
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-938_73605560,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/threed/Line.java,86,88,"/**
 * Get a line with reversed direction.
 * @return a new instance, with reversed direction
 */
public Line revert() {
    return new Line(zero, zero.subtract(direction));
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-939_49444ee6,Major,src/main/java/org/apache/commons/math3/stat/correlation/Covariance.java,162,176,"/**
 * Compute a covariance matrix from a matrix whose columns represent
 * covariates.
 * @param matrix input matrix (must have at least two columns and two rows)
 * @param biasCorrected determines whether or not covariance estimates are bias-corrected
 * @return covariance matrix
 * @throws MathIllegalArgumentException if the matrix does not contain sufficient data
 */
protected RealMatrix computeCovarianceMatrix(RealMatrix matrix, boolean biasCorrected) throws MathIllegalArgumentException {
    int dimension = matrix.getColumnDimension();
    Variance variance = new Variance(biasCorrected);
    RealMatrix outMatrix = new BlockRealMatrix(dimension, dimension);
    for (int i = 0; i < dimension; i++) {
        for (int j = 0; j < i; j++) {
            double cov = covariance(matrix.getColumn(i), matrix.getColumn(j), biasCorrected);
            outMatrix.setEntry(i, j, cov);
            outMatrix.setEntry(j, i, cov);
        }
        outMatrix.setEntry(i, i, variance.evaluate(matrix.getColumn(i)));
    }
    return outMatrix;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-939_49444ee6,Major,src/main/java/org/apache/commons/math3/stat/correlation/Covariance.java,186,189,"/**
 * Create a covariance matrix from a matrix whose columns represent
 * covariates. Covariances are computed using the bias-corrected formula.
 * @param matrix input matrix (must have at least two columns and two rows)
 * @return covariance matrix
 * @throws MathIllegalArgumentException if matrix does not contain sufficient data
 * @see #Covariance
 */
protected RealMatrix computeCovarianceMatrix(RealMatrix matrix) throws MathIllegalArgumentException {
    return computeCovarianceMatrix(matrix, true);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-939_49444ee6,Major,src/main/java/org/apache/commons/math3/stat/correlation/Covariance.java,200,203,"/**
 * Compute a covariance matrix from a rectangular array whose columns represent
 * covariates.
 * @param data input array (must have at least two columns and two rows)
 * @param biasCorrected determines whether or not covariance estimates are bias-corrected
 * @return covariance matrix
 * @throws MathIllegalArgumentException if the data array does not contain sufficient
 * data
 */
protected RealMatrix computeCovarianceMatrix(double[][] data, boolean biasCorrected) throws MathIllegalArgumentException {
    return computeCovarianceMatrix(new BlockRealMatrix(data), biasCorrected);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-939_49444ee6,Major,src/main/java/org/apache/commons/math3/stat/correlation/Covariance.java,213,215,"/**
 * Create a covariance matrix from a rectangular array whose columns represent
 * covariates. Covariances are computed using the bias-corrected formula.
 * @param data input array (must have at least two columns and two rows)
 * @return covariance matrix
 * @throws MathIllegalArgumentException if the data array does not contain sufficient data
 * @see #Covariance
 */
protected RealMatrix computeCovarianceMatrix(double[][] data) throws MathIllegalArgumentException {
    return computeCovarianceMatrix(data, true);
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-939_49444ee6,Major,src/main/java/org/apache/commons/math3/stat/correlation/Covariance.java,276,284,"/**
 * Throws MathIllegalArgumentException if the matrix does not have at least
 * two columns and two rows.
 * @param matrix matrix to check
 * @throws MathIllegalArgumentException if the matrix does not contain sufficient data
 * to compute covariance
 */
private void checkSufficientData(final RealMatrix matrix) throws MathIllegalArgumentException {
    int nRows = matrix.getRowDimension();
    int nCols = matrix.getColumnDimension();
    if (nRows < 2 || nCols < 2) {
        throw new MathIllegalArgumentException(LocalizedFormats.INSUFFICIENT_ROWS_AND_COLUMNS, nRows, nCols);
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-942_0d057fc6,Major,src/main/java/org/apache/commons/math3/distribution/DiscreteDistribution.java,181,195,"/**
 * Generate a random sample from the distribution.
 *
 * @param sampleSize the number of random values to generate.
 * @return an array representing the random sample.
 * @throws NotStrictlyPositiveException if {@code sampleSize} is not
 * positive.
 */
public T[] sample(int sampleSize) throws NotStrictlyPositiveException {
    if (sampleSize <= 0) {
        throw new NotStrictlyPositiveException(LocalizedFormats.NUMBER_OF_SAMPLES, sampleSize);
    }
    @SuppressWarnings(""unchecked"")
    final T[] out = (T[]) Array.newInstance(singletons.get(0).getClass(), sampleSize);
    for (int i = 0; i < sampleSize; i++) {
        out[i] = sample();
    }
    return out;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-949_f83bbc1d,Major,src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/gradient/NonLinearConjugateGradientOptimizer.java,191,288,"/**
 * {@inheritDoc}
 */
@Override
protected PointValuePair doOptimize() {
    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();
    final double[] point = getStartPoint();
    final GoalType goal = getGoalType();
    final int n = point.length;
    double[] r = computeObjectiveGradient(point);
    if (goal == GoalType.MINIMIZE) {
        for (int i = 0; i < n; i++) {
            r[i] = -r[i];
        }
    }
    // Initial search direction.
    double[] steepestDescent = preconditioner.precondition(point, r);
    double[] searchDirection = steepestDescent.clone();
    double delta = 0;
    for (int i = 0; i < n; ++i) {
        delta += r[i] * searchDirection[i];
    }
    PointValuePair current = null;
    int iter = 0;
    int maxEval = getMaxEvaluations();
    while (true) {
        ++iter;
        final double objective = computeObjectiveValue(point);
        PointValuePair previous = current;
        current = new PointValuePair(point, objective);
        if (previous != null) {
            if (checker.converged(iter, previous, current)) {
                // We have found an optimum.
                return current;
            }
        }
        // Find the optimal step in the search direction.
        final UnivariateFunction lsf = new LineSearchFunction(point, searchDirection);
        final double uB = findUpperBound(lsf, 0, initialStep);
        // XXX Last parameters is set to a value close to zero in order to
        // work around the divergence problem in the ""testCircleFitting""
        // unit test (see MATH-439).
        final double step = solver.solve(maxEval, lsf, 0, uB, 1e-15);
        // Subtract used up evaluations.
        maxEval -= solver.getEvaluations();
        // Validate new point.
        for (int i = 0; i < point.length; ++i) {
            point[i] += step * searchDirection[i];
        }
        r = computeObjectiveGradient(point);
        if (goal == GoalType.MINIMIZE) {
            for (int i = 0; i < n; ++i) {
                r[i] = -r[i];
            }
        }
        // Compute beta.
        final double deltaOld = delta;
        final double[] newSteepestDescent = preconditioner.precondition(point, r);
        delta = 0;
        for (int i = 0; i < n; ++i) {
            delta += r[i] * newSteepestDescent[i];
        }
        final double beta;
        switch(updateFormula) {
            case FLETCHER_REEVES:
                beta = delta / deltaOld;
                break;
            case POLAK_RIBIERE:
                double deltaMid = 0;
                for (int i = 0; i < r.length; ++i) {
                    deltaMid += r[i] * steepestDescent[i];
                }
                beta = (delta - deltaMid) / deltaOld;
                break;
            default:
                // Should never happen.
                throw new MathInternalError();
        }
        steepestDescent = newSteepestDescent;
        // Compute conjugate search direction.
        if (iter % n == 0 || beta < 0) {
            // Break conjugation: reset search direction.
            searchDirection = steepestDescent.clone();
        } else {
            // Compute new conjugate search direction.
            for (int i = 0; i < n; ++i) {
                searchDirection[i] = steepestDescent[i] + beta * searchDirection[i];
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-949_f83bbc1d,Major,src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/CMAESOptimizer.java,367,514,"/**
 * {@inheritDoc}
 */
@Override
protected PointValuePair doOptimize() {
    // -------------------- Initialization --------------------------------
    isMinimize = getGoalType().equals(GoalType.MINIMIZE);
    final FitnessFunction fitfun = new FitnessFunction();
    final double[] guess = getStartPoint();
    // number of objective variables/problem dimension
    dimension = guess.length;
    initializeCMA(guess);
    iterations = 0;
    double bestValue = fitfun.value(guess);
    push(fitnessHistory, bestValue);
    PointValuePair optimum = new PointValuePair(getStartPoint(), isMinimize ? bestValue : -bestValue);
    PointValuePair lastResult = null;
    generationLoop: for (iterations = 1; iterations <= maxIterations; iterations++) {
        // Generate and evaluate lambda offspring
        final RealMatrix arz = randn1(dimension, lambda);
        final RealMatrix arx = zeros(dimension, lambda);
        final double[] fitness = new double[lambda];
        // generate random offspring
        for (int k = 0; k < lambda; k++) {
            RealMatrix arxk = null;
            for (int i = 0; i < checkFeasableCount + 1; i++) {
                if (diagonalOnly <= 0) {
                    arxk = xmean.add(BD.multiply(arz.getColumnMatrix(k)).scalarMultiply(// m + sig * Normal(0,C)
                    sigma));
                } else {
                    arxk = xmean.add(times(diagD, arz.getColumnMatrix(k)).scalarMultiply(sigma));
                }
                if (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {
                    break;
                }
                // regenerate random arguments for row
                arz.setColumn(k, randn(dimension));
            }
            copyColumn(arxk, 0, arx, k);
            try {
                // compute fitness
                fitness[k] = fitfun.value(arx.getColumn(k));
            } catch (TooManyEvaluationsException e) {
                break generationLoop;
            }
        }
        // Sort by fitness and compute weighted mean into xmean
        final int[] arindex = sortedIndices(fitness);
        // Calculate new xmean, this is selection and recombination
        // for speed up of Eq. (2) and (3)
        final RealMatrix xold = xmean;
        final RealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));
        xmean = bestArx.multiply(weights);
        final RealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));
        final RealMatrix zmean = bestArz.multiply(weights);
        final boolean hsig = updateEvolutionPaths(zmean, xold);
        if (diagonalOnly <= 0) {
            updateCovariance(hsig, bestArx, arz, arindex, xold);
        } else {
            updateCovarianceDiagonalOnly(hsig, bestArz);
        }
        // Adapt step size sigma - Eq. (5)
        sigma *= Math.exp(Math.min(1, (normps / chiN - 1) * cs / damps));
        final double bestFitness = fitness[arindex[0]];
        final double worstFitness = fitness[arindex[arindex.length - 1]];
        if (bestValue > bestFitness) {
            bestValue = bestFitness;
            lastResult = optimum;
            optimum = new PointValuePair(fitfun.repair(bestArx.getColumn(0)), isMinimize ? bestFitness : -bestFitness);
            if (getConvergenceChecker() != null && lastResult != null) {
                if (getConvergenceChecker().converged(iterations, optimum, lastResult)) {
                    break generationLoop;
                }
            }
        }
        // Break, if fitness is good enough
        if (stopFitness != 0) {
            // only if stopFitness is defined
            if (bestFitness < (isMinimize ? stopFitness : -stopFitness)) {
                break generationLoop;
            }
        }
        final double[] sqrtDiagC = sqrt(diagC).getColumn(0);
        final double[] pcCol = pc.getColumn(0);
        for (int i = 0; i < dimension; i++) {
            if (sigma * Math.max(Math.abs(pcCol[i]), sqrtDiagC[i]) > stopTolX) {
                break;
            }
            if (i >= dimension - 1) {
                break generationLoop;
            }
        }
        for (int i = 0; i < dimension; i++) {
            if (sigma * sqrtDiagC[i] > stopTolUpX) {
                break generationLoop;
            }
        }
        final double historyBest = min(fitnessHistory);
        final double historyWorst = max(fitnessHistory);
        if (iterations > 2 && Math.max(historyWorst, worstFitness) - Math.min(historyBest, bestFitness) < stopTolFun) {
            break generationLoop;
        }
        if (iterations > fitnessHistory.length && historyWorst - historyBest < stopTolHistFun) {
            break generationLoop;
        }
        // condition number of the covariance matrix exceeds 1e14
        if (max(diagD) / min(diagD) > 1e7) {
            break generationLoop;
        }
        // user defined termination
        if (getConvergenceChecker() != null) {
            final PointValuePair current = new PointValuePair(bestArx.getColumn(0), isMinimize ? bestFitness : -bestFitness);
            if (lastResult != null && getConvergenceChecker().converged(iterations, current, lastResult)) {
                break generationLoop;
            }
            lastResult = current;
        }
        // Adjust step size in case of equal function values (flat fitness)
        if (bestValue == fitness[arindex[(int) (0.1 + lambda / 4.)]]) {
            sigma = sigma * Math.exp(0.2 + cs / damps);
        }
        if (iterations > 2 && Math.max(historyWorst, bestFitness) - Math.min(historyBest, bestFitness) == 0) {
            sigma = sigma * Math.exp(0.2 + cs / damps);
        }
        // store best in history
        push(fitnessHistory, bestFitness);
        fitfun.setValueRange(worstFitness - bestFitness);
        if (generateStatistics) {
            statisticsSigmaHistory.add(sigma);
            statisticsFitnessHistory.add(bestFitness);
            statisticsMeanHistory.add(xmean.transpose());
            statisticsDHistory.add(diagD.transpose().scalarMultiply(1E5));
        }
    }
    return optimum;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-949_f83bbc1d,Major,src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/PowellOptimizer.java,172,268,"/**
 * {@inheritDoc}
 */
@Override
protected PointValuePair doOptimize() {
    checkParameters();
    final GoalType goal = getGoalType();
    final double[] guess = getStartPoint();
    final int n = guess.length;
    final double[][] direc = new double[n][n];
    for (int i = 0; i < n; i++) {
        direc[i][i] = 1;
    }
    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();
    double[] x = guess;
    double fVal = computeObjectiveValue(x);
    double[] x1 = x.clone();
    int iter = 0;
    while (true) {
        ++iter;
        double fX = fVal;
        double fX2 = 0;
        double delta = 0;
        int bigInd = 0;
        double alphaMin = 0;
        for (int i = 0; i < n; i++) {
            final double[] d = MathArrays.copyOf(direc[i]);
            fX2 = fVal;
            final UnivariatePointValuePair optimum = line.search(x, d);
            fVal = optimum.getValue();
            alphaMin = optimum.getPoint();
            final double[][] result = newPointAndDirection(x, d, alphaMin);
            x = result[0];
            if ((fX2 - fVal) > delta) {
                delta = fX2 - fVal;
                bigInd = i;
            }
        }
        // Default convergence check.
        boolean stop = 2 * (fX - fVal) <= (relativeThreshold * (FastMath.abs(fX) + FastMath.abs(fVal)) + absoluteThreshold);
        final PointValuePair previous = new PointValuePair(x1, fX);
        final PointValuePair current = new PointValuePair(x, fVal);
        if (!stop) {
            // User-defined stopping criteria.
            if (checker != null) {
                stop = checker.converged(iter, previous, current);
            }
        }
        if (stop) {
            if (goal == GoalType.MINIMIZE) {
                return (fVal < fX) ? current : previous;
            } else {
                return (fVal > fX) ? current : previous;
            }
        }
        final double[] d = new double[n];
        final double[] x2 = new double[n];
        for (int i = 0; i < n; i++) {
            d[i] = x[i] - x1[i];
            x2[i] = 2 * x[i] - x1[i];
        }
        x1 = x.clone();
        fX2 = computeObjectiveValue(x2);
        if (fX > fX2) {
            double t = 2 * (fX + fX2 - 2 * fVal);
            double temp = fX - fVal - delta;
            t *= temp * temp;
            temp = fX - fX2;
            t -= delta * temp * temp;
            if (t < 0.0) {
                final UnivariatePointValuePair optimum = line.search(x, d);
                fVal = optimum.getValue();
                alphaMin = optimum.getPoint();
                final double[][] result = newPointAndDirection(x, d, alphaMin);
                x = result[0];
                final int lastInd = n - 1;
                direc[bigInd] = direc[lastInd];
                direc[lastInd] = result[1];
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-949_f83bbc1d,Major,src/main/java/org/apache/commons/math3/optim/nonlinear/scalar/noderiv/SimplexOptimizer.java,126,176,"/**
 * {@inheritDoc}
 */
@Override
protected PointValuePair doOptimize() {
    checkParameters();
    // Indirect call to ""computeObjectiveValue"" in order to update the
    // evaluations counter.
    final MultivariateFunction evalFunc = new MultivariateFunction() {

        public double value(double[] point) {
            return computeObjectiveValue(point);
        }
    };
    final boolean isMinim = getGoalType() == GoalType.MINIMIZE;
    final Comparator<PointValuePair> comparator = new Comparator<PointValuePair>() {

        public int compare(final PointValuePair o1, final PointValuePair o2) {
            final double v1 = o1.getValue();
            final double v2 = o2.getValue();
            return isMinim ? Double.compare(v1, v2) : Double.compare(v2, v1);
        }
    };
    // Initialize search.
    simplex.build(getStartPoint());
    simplex.evaluate(evalFunc, comparator);
    PointValuePair[] previous = null;
    int iteration = 0;
    final ConvergenceChecker<PointValuePair> checker = getConvergenceChecker();
    while (true) {
        if (iteration > 0) {
            boolean converged = true;
            for (int i = 0; i < simplex.getSize(); i++) {
                PointValuePair prev = previous[i];
                converged = converged && checker.converged(iteration, prev, simplex.getPoint(i));
            }
            if (converged) {
                // We have found an optimum.
                return simplex.getPoint(0);
            }
        }
        // We still need to search.
        previous = simplex.getPoints();
        simplex.iterate(evalFunc, comparator);
        ++iteration;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-949_f83bbc1d,Major,src/main/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/GaussNewtonOptimizer.java,79,169,"/**
 * {@inheritDoc}
 */
@Override
public PointVectorValuePair doOptimize() {
    checkParameters();
    final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();
    // Computation will be useless without a checker (see ""for-loop"").
    if (checker == null) {
        throw new NullArgumentException();
    }
    final double[] targetValues = getTarget();
    // Number of observed data.
    final int nR = targetValues.length;
    final RealMatrix weightMatrix = getWeight();
    // Diagonal of the weight matrix.
    final double[] residualsWeights = new double[nR];
    for (int i = 0; i < nR; i++) {
        residualsWeights[i] = weightMatrix.getEntry(i, i);
    }
    final double[] currentPoint = getStartPoint();
    final int nC = currentPoint.length;
    // iterate until convergence is reached
    PointVectorValuePair current = null;
    int iter = 0;
    for (boolean converged = false; !converged; ) {
        ++iter;
        // evaluate the objective function and its jacobian
        PointVectorValuePair previous = current;
        // Value of the objective function at ""currentPoint"".
        final double[] currentObjective = computeObjectiveValue(currentPoint);
        final double[] currentResiduals = computeResiduals(currentObjective);
        final RealMatrix weightedJacobian = computeWeightedJacobian(currentPoint);
        current = new PointVectorValuePair(currentPoint, currentObjective);
        // build the linear problem
        final double[] b = new double[nC];
        final double[][] a = new double[nC][nC];
        for (int i = 0; i < nR; ++i) {
            final double[] grad = weightedJacobian.getRow(i);
            final double weight = residualsWeights[i];
            final double residual = currentResiduals[i];
            // compute the normal equation
            final double wr = weight * residual;
            for (int j = 0; j < nC; ++j) {
                b[j] += wr * grad[j];
            }
            // build the contribution matrix for measurement i
            for (int k = 0; k < nC; ++k) {
                double[] ak = a[k];
                double wgk = weight * grad[k];
                for (int l = 0; l < nC; ++l) {
                    ak[l] += wgk * grad[l];
                }
            }
        }
        try {
            // solve the linearized least squares problem
            RealMatrix mA = new BlockRealMatrix(a);
            DecompositionSolver solver = useLU ? new LUDecomposition(mA).getSolver() : new QRDecomposition(mA).getSolver();
            final double[] dX = solver.solve(new ArrayRealVector(b, false)).toArray();
            // update the estimated parameters
            for (int i = 0; i < nC; ++i) {
                currentPoint[i] += dX[i];
            }
        } catch (SingularMatrixException e) {
            throw new ConvergenceException(LocalizedFormats.UNABLE_TO_SOLVE_SINGULAR_PROBLEM);
        }
        // Check convergence.
        if (previous != null) {
            converged = checker.converged(iter, previous, current);
            if (converged) {
                setCost(computeCost(currentResiduals));
                return current;
            }
        }
    }
    // Must never happen.
    throw new MathInternalError();
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-949_f83bbc1d,Major,src/main/java/org/apache/commons/math3/optim/nonlinear/vector/jacobian/LevenbergMarquardtOptimizer.java,283,534,"/**
 * {@inheritDoc}
 */
@Override
protected PointVectorValuePair doOptimize() {
    checkParameters();
    // Number of observed data.
    final int nR = getTarget().length;
    final double[] currentPoint = getStartPoint();
    // Number of parameters.
    final int nC = currentPoint.length;
    // arrays shared with the other private methods
    solvedCols = FastMath.min(nR, nC);
    diagR = new double[nC];
    jacNorm = new double[nC];
    beta = new double[nC];
    permutation = new int[nC];
    lmDir = new double[nC];
    // local point
    double delta = 0;
    double xNorm = 0;
    double[] diag = new double[nC];
    double[] oldX = new double[nC];
    double[] oldRes = new double[nR];
    double[] oldObj = new double[nR];
    double[] qtf = new double[nR];
    double[] work1 = new double[nC];
    double[] work2 = new double[nC];
    double[] work3 = new double[nC];
    final RealMatrix weightMatrixSqrt = getWeightSquareRoot();
    // Evaluate the function at the starting point and calculate its norm.
    double[] currentObjective = computeObjectiveValue(currentPoint);
    double[] currentResiduals = computeResiduals(currentObjective);
    PointVectorValuePair current = new PointVectorValuePair(currentPoint, currentObjective);
    double currentCost = computeCost(currentResiduals);
    // Outer loop.
    lmPar = 0;
    boolean firstIteration = true;
    int iter = 0;
    final ConvergenceChecker<PointVectorValuePair> checker = getConvergenceChecker();
    while (true) {
        ++iter;
        final PointVectorValuePair previous = current;
        // QR decomposition of the jacobian matrix
        qrDecomposition(computeWeightedJacobian(currentPoint));
        weightedResidual = weightMatrixSqrt.operate(currentResiduals);
        for (int i = 0; i < nR; i++) {
            qtf[i] = weightedResidual[i];
        }
        // compute Qt.res
        qTy(qtf);
        // so let jacobian contain the R matrix with its diagonal elements
        for (int k = 0; k < solvedCols; ++k) {
            int pk = permutation[k];
            weightedJacobian[k][pk] = diagR[pk];
        }
        if (firstIteration) {
            // scale the point according to the norms of the columns
            // of the initial jacobian
            xNorm = 0;
            for (int k = 0; k < nC; ++k) {
                double dk = jacNorm[k];
                if (dk == 0) {
                    dk = 1.0;
                }
                double xk = dk * currentPoint[k];
                xNorm += xk * xk;
                diag[k] = dk;
            }
            xNorm = FastMath.sqrt(xNorm);
            // initialize the step bound delta
            delta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);
        }
        // check orthogonality between function vector and jacobian columns
        double maxCosine = 0;
        if (currentCost != 0) {
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double s = jacNorm[pj];
                if (s != 0) {
                    double sum = 0;
                    for (int i = 0; i <= j; ++i) {
                        sum += weightedJacobian[i][pj] * qtf[i];
                    }
                    maxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * currentCost));
                }
            }
        }
        if (maxCosine <= orthoTolerance) {
            // Convergence has been reached.
            setCost(currentCost);
            return current;
        }
        // rescale if necessary
        for (int j = 0; j < nC; ++j) {
            diag[j] = FastMath.max(diag[j], jacNorm[j]);
        }
        // Inner loop.
        for (double ratio = 0; ratio < 1.0e-4; ) {
            // save the state
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                oldX[pj] = currentPoint[pj];
            }
            final double previousCost = currentCost;
            double[] tmpVec = weightedResidual;
            weightedResidual = oldRes;
            oldRes = tmpVec;
            tmpVec = currentObjective;
            currentObjective = oldObj;
            oldObj = tmpVec;
            // determine the Levenberg-Marquardt parameter
            determineLMParameter(qtf, delta, diag, work1, work2, work3);
            // compute the new point and the norm of the evolution direction
            double lmNorm = 0;
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                lmDir[pj] = -lmDir[pj];
                currentPoint[pj] = oldX[pj] + lmDir[pj];
                double s = diag[pj] * lmDir[pj];
                lmNorm += s * s;
            }
            lmNorm = FastMath.sqrt(lmNorm);
            // on the first iteration, adjust the initial step bound.
            if (firstIteration) {
                delta = FastMath.min(delta, lmNorm);
            }
            // Evaluate the function at x + p and calculate its norm.
            currentObjective = computeObjectiveValue(currentPoint);
            currentResiduals = computeResiduals(currentObjective);
            current = new PointVectorValuePair(currentPoint, currentObjective);
            currentCost = computeCost(currentResiduals);
            // compute the scaled actual reduction
            double actRed = -1.0;
            if (0.1 * currentCost < previousCost) {
                double r = currentCost / previousCost;
                actRed = 1.0 - r * r;
            }
            // and the scaled directional derivative
            for (int j = 0; j < solvedCols; ++j) {
                int pj = permutation[j];
                double dirJ = lmDir[pj];
                work1[j] = 0;
                for (int i = 0; i <= j; ++i) {
                    work1[i] += weightedJacobian[i][pj] * dirJ;
                }
            }
            double coeff1 = 0;
            for (int j = 0; j < solvedCols; ++j) {
                coeff1 += work1[j] * work1[j];
            }
            double pc2 = previousCost * previousCost;
            coeff1 = coeff1 / pc2;
            double coeff2 = lmPar * lmNorm * lmNorm / pc2;
            double preRed = coeff1 + 2 * coeff2;
            double dirDer = -(coeff1 + coeff2);
            // ratio of the actual to the predicted reduction
            ratio = (preRed == 0) ? 0 : (actRed / preRed);
            // update the step bound
            if (ratio <= 0.25) {
                double tmp = (actRed < 0) ? (0.5 * dirDer / (dirDer + 0.5 * actRed)) : 0.5;
                if ((0.1 * currentCost >= previousCost) || (tmp < 0.1)) {
                    tmp = 0.1;
                }
                delta = tmp * FastMath.min(delta, 10.0 * lmNorm);
                lmPar /= tmp;
            } else if ((lmPar == 0) || (ratio >= 0.75)) {
                delta = 2 * lmNorm;
                lmPar *= 0.5;
            }
            // test for successful iteration.
            if (ratio >= 1.0e-4) {
                // successful iteration, update the norm
                firstIteration = false;
                xNorm = 0;
                for (int k = 0; k < nC; ++k) {
                    double xK = diag[k] * currentPoint[k];
                    xNorm += xK * xK;
                }
                xNorm = FastMath.sqrt(xNorm);
                // tests for convergence.
                if (checker != null) {
                    // we use the vectorial convergence checker
                    if (checker.converged(iter, previous, current)) {
                        setCost(currentCost);
                        return current;
                    }
                }
            } else {
                // failed iteration, reset the previous values
                currentCost = previousCost;
                for (int j = 0; j < solvedCols; ++j) {
                    int pj = permutation[j];
                    currentPoint[pj] = oldX[pj];
                }
                tmpVec = weightedResidual;
                weightedResidual = oldRes;
                oldRes = tmpVec;
                tmpVec = currentObjective;
                currentObjective = oldObj;
                oldObj = tmpVec;
                // Reset ""current"" to previous values.
                current = new PointVectorValuePair(currentPoint, currentObjective);
            }
            // Default convergence criteria.
            if ((FastMath.abs(actRed) <= costRelativeTolerance && preRed <= costRelativeTolerance && ratio <= 2.0) || delta <= parRelativeTolerance * xNorm) {
                setCost(currentCost);
                return current;
            }
            // (2.2204e-16 is the machine epsilon for IEEE754)
            if ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_COST_RELATIVE_TOLERANCE, costRelativeTolerance);
            } else if (delta <= 2.2204e-16 * xNorm) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_PARAMETERS_RELATIVE_TOLERANCE, parRelativeTolerance);
            } else if (maxCosine <= 2.2204e-16) {
                throw new ConvergenceException(LocalizedFormats.TOO_SMALL_ORTHOGONALITY_TOLERANCE, orthoTolerance);
            }
        }
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-950_424cbd20,Critical,src/main/java/org/apache/commons/math3/ode/AbstractIntegrator.java,296,401,"/**
 * Accept a step, triggering events and step handlers.
 * @param interpolator step interpolator
 * @param y state vector at step end time, must be reset if an event
 * asks for resetting or if an events stops integration during the step
 * @param yDot placeholder array where to put the time derivative of the state vector
 * @param tEnd final integration time
 * @return time at end of step
 * @exception MaxCountExceededException if the interpolator throws one because
 * the number of functions evaluations is exceeded
 * @exception NoBracketingException if the location of an event cannot be bracketed
 * @exception DimensionMismatchException if arrays dimensions do not match equations settings
 * @since 2.2
 */
protected double acceptStep(final AbstractStepInterpolator interpolator, final double[] y, final double[] yDot, final double tEnd) throws MaxCountExceededException, DimensionMismatchException, NoBracketingException {
    double previousT = interpolator.getGlobalPreviousTime();
    final double currentT = interpolator.getGlobalCurrentTime();
    // initialize the events states if needed
    if (!statesInitialized) {
        for (EventState state : eventsStates) {
            state.reinitializeBegin(interpolator);
        }
        statesInitialized = true;
    }
    // search for next events that may occur during the step
    final int orderingSign = interpolator.isForward() ? +1 : -1;
    SortedSet<EventState> occuringEvents = new TreeSet<EventState>(new Comparator<EventState>() {

        /**
         * {@inheritDoc}
         */
        public int compare(EventState es0, EventState es1) {
            return orderingSign * Double.compare(es0.getEventTime(), es1.getEventTime());
        }
    });
    for (final EventState state : eventsStates) {
        if (state.evaluateStep(interpolator)) {
            // the event occurs during the current step
            occuringEvents.add(state);
        }
    }
    while (!occuringEvents.isEmpty()) {
        // handle the chronologically first event
        final Iterator<EventState> iterator = occuringEvents.iterator();
        final EventState currentEvent = iterator.next();
        iterator.remove();
        // restrict the interpolator to the first part of the step, up to the event
        final double eventT = currentEvent.getEventTime();
        interpolator.setSoftPreviousTime(previousT);
        interpolator.setSoftCurrentTime(eventT);
        // trigger the event
        interpolator.setInterpolatedTime(eventT);
        final double[] eventY = interpolator.getInterpolatedState().clone();
        currentEvent.stepAccepted(eventT, eventY);
        isLastStep = currentEvent.stop();
        // handle the first part of the step, up to the event
        for (final StepHandler handler : stepHandlers) {
            handler.handleStep(interpolator, isLastStep);
        }
        if (isLastStep) {
            // the event asked to stop integration
            System.arraycopy(eventY, 0, y, 0, y.length);
            for (final EventState remaining : occuringEvents) {
                remaining.stepAccepted(eventT, eventY);
            }
            return eventT;
        }
        if (currentEvent.reset(eventT, eventY)) {
            // some event handler has triggered changes that
            // invalidate the derivatives, we need to recompute them
            System.arraycopy(eventY, 0, y, 0, y.length);
            computeDerivatives(eventT, y, yDot);
            resetOccurred = true;
            for (final EventState remaining : occuringEvents) {
                remaining.stepAccepted(eventT, eventY);
            }
            return eventT;
        }
        // prepare handling of the remaining part of the step
        previousT = eventT;
        interpolator.setSoftPreviousTime(eventT);
        interpolator.setSoftCurrentTime(currentT);
        // check if the same event occurs again in the remaining part of the step
        if (currentEvent.evaluateStep(interpolator)) {
            // the event occurs during the current step
            occuringEvents.add(currentEvent);
        }
    }
    interpolator.setInterpolatedTime(currentT);
    final double[] currentY = interpolator.getInterpolatedState();
    for (final EventState state : eventsStates) {
        state.stepAccepted(currentT, currentY);
        isLastStep = isLastStep || state.stop();
    }
    isLastStep = isLastStep || Precision.equals(currentT, tEnd, 1);
    // handle the remaining part of the step, after all events if any
    for (StepHandler handler : stepHandlers) {
        handler.handleStep(interpolator, isLastStep);
    }
    return currentT;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-957_9aabf587,Major,src/main/java/org/apache/commons/math3/distribution/UniformRealDistribution.java,127,130,"/**
 * {@inheritDoc}
 */
@Override
protected double getSolverAbsoluteAccuracy() {
    return solverAbsoluteAccuracy;
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-988_d270055e,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/threed/SubLine.java,110,127,"/**
 * Get the intersection of the instance and another sub-line.
 * <p>
 * This method is related to the {@link Line#intersection(Line)
 * intersection} method in the {@link Line Line} class, but in addition
 * to compute the point along infinite lines, it also checks the point
 * lies on both sub-line ranges.
 * </p>
 * @param subLine other sub-line which may intersect instance
 * @param includeEndPoints if true, endpoints are considered to belong to
 * instance (i.e. they are closed sets) and may be returned, otherwise endpoints
 * are considered to not belong to instance (i.e. they are open sets) and intersection
 * occurring on endpoints lead to null being returned
 * @return the intersection point if there is one, null if the sub-lines don't intersect
 */
public Vector3D intersection(final SubLine subLine, final boolean includeEndPoints) {
    // compute the intersection on infinite line
    Vector3D v1D = line.intersection(subLine.line);
    // check location of point with respect to first sub-line
    Location loc1 = remainingRegion.checkPoint(line.toSubSpace(v1D));
    // check location of point with respect to second sub-line
    Location loc2 = subLine.remainingRegion.checkPoint(subLine.line.toSubSpace(v1D));
    if (includeEndPoints) {
        return ((loc1 != Location.OUTSIDE) && (loc2 != Location.OUTSIDE)) ? v1D : null;
    } else {
        return ((loc1 == Location.INSIDE) && (loc2 == Location.INSIDE)) ? v1D : null;
    }
}"
commons-math,remotes/origin/bugs-dot-jar_MATH-988_d270055e,Major,src/main/java/org/apache/commons/math3/geometry/euclidean/twod/SubLine.java,110,131,"/**
 * Get the intersection of the instance and another sub-line.
 * <p>
 * This method is related to the {@link Line#intersection(Line)
 * intersection} method in the {@link Line Line} class, but in addition
 * to compute the point along infinite lines, it also checks the point
 * lies on both sub-line ranges.
 * </p>
 * @param subLine other sub-line which may intersect instance
 * @param includeEndPoints if true, endpoints are considered to belong to
 * instance (i.e. they are closed sets) and may be returned, otherwise endpoints
 * are considered to not belong to instance (i.e. they are open sets) and intersection
 * occurring on endpoints lead to null being returned
 * @return the intersection point if there is one, null if the sub-lines don't intersect
 */
public Vector2D intersection(final SubLine subLine, final boolean includeEndPoints) {
    // retrieve the underlying lines
    Line line1 = (Line) getHyperplane();
    Line line2 = (Line) subLine.getHyperplane();
    // compute the intersection on infinite line
    Vector2D v2D = line1.intersection(line2);
    // check location of point with respect to first sub-line
    Location loc1 = getRemainingRegion().checkPoint(line1.toSubSpace(v2D));
    // check location of point with respect to second sub-line
    Location loc2 = subLine.getRemainingRegion().checkPoint(line2.toSubSpace(v2D));
    if (includeEndPoints) {
        return ((loc1 != Location.OUTSIDE) && (loc2 != Location.OUTSIDE)) ? v2D : null;
    } else {
        return ((loc1 == Location.INSIDE) && (loc2 == Location.INSIDE)) ? v2D : null;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1133_02c08456,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,411,434,"private <IN1> TypeInformation<?> createTypeInfoFromInput(TypeVariable<?> returnTypeVar, ArrayList<Type> returnTypeHierarchy, Type inType, TypeInformation<IN1> inTypeInfo) {
    TypeInformation<?> info = null;
    // the input is a type variable
    if (inType instanceof TypeVariable) {
        inType = materializeTypeVariable(returnTypeHierarchy, (TypeVariable<?>) inType);
        info = findCorrespondingInfo(returnTypeVar, inType, inTypeInfo);
    } else // the input is a tuple that may contains type variables
    if (inType instanceof ParameterizedType && Tuple.class.isAssignableFrom(((Class<?>) ((ParameterizedType) inType).getRawType()))) {
        Type[] tupleElements = ((ParameterizedType) inType).getActualTypeArguments();
        // go thru all tuple elements and search for type variables
        for (int i = 0; i < tupleElements.length; i++) {
            if (tupleElements[i] instanceof TypeVariable) {
                inType = materializeTypeVariable(returnTypeHierarchy, (TypeVariable<?>) tupleElements[i]);
                info = findCorrespondingInfo(returnTypeVar, inType, ((TupleTypeInfo<?>) inTypeInfo).getTypeAt(i));
                if (info != null) {
                    break;
                }
            }
        }
    }
    return info;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1133_27e40205,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,194,213,"// for (Rich)Functions
@SuppressWarnings(""unchecked"")
private <IN1, IN2, OUT> TypeInformation<OUT> privateCreateTypeInfo(Class<?> baseClass, Class<?> clazz, int returnParamPos, TypeInformation<IN1> in1Type, TypeInformation<IN2> in2Type) {
    ArrayList<Type> typeHierarchy = new ArrayList<Type>();
    Type returnType = getParameterType(baseClass, typeHierarchy, clazz, returnParamPos);
    TypeInformation<OUT> typeInfo = null;
    // return type is a variable -> try to get the type info from the input directly
    if (returnType instanceof TypeVariable<?>) {
        typeInfo = (TypeInformation<OUT>) createTypeInfoFromInput((TypeVariable<?>) returnType, typeHierarchy, in1Type, in2Type);
        if (typeInfo != null) {
            return typeInfo;
        }
    }
    // get info from hierarchy
    return (TypeInformation<OUT>) createTypeInfoWithTypeHierarchy(typeHierarchy, returnType, in1Type, in2Type);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1133_27e40205,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,224,372,"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
private <IN1, IN2, OUT> TypeInformation<OUT> createTypeInfoWithTypeHierarchy(ArrayList<Type> typeHierarchy, Type t, TypeInformation<IN1> in1Type, TypeInformation<IN2> in2Type) {
    // check if type is a subclass of tuple
    if ((t instanceof Class<?> && Tuple.class.isAssignableFrom((Class<?>) t)) || (t instanceof ParameterizedType && Tuple.class.isAssignableFrom((Class<?>) ((ParameterizedType) t).getRawType()))) {
        Type curT = t;
        // do not allow usage of Tuple as type
        if (curT instanceof Class<?> && ((Class<?>) curT).equals(Tuple.class)) {
            throw new InvalidTypesException(""Usage of class Tuple as a type is not allowed. Use a concrete subclass (e.g. Tuple1, Tuple2, etc.) instead."");
        }
        // collect the types while moving up for a later top-down
        while (!(curT instanceof ParameterizedType && ((Class<?>) ((ParameterizedType) curT).getRawType()).getSuperclass().equals(Tuple.class)) && !(curT instanceof Class<?> && ((Class<?>) curT).getSuperclass().equals(Tuple.class))) {
            typeHierarchy.add(curT);
            // parameterized type
            if (curT instanceof ParameterizedType) {
                curT = ((Class<?>) ((ParameterizedType) curT).getRawType()).getGenericSuperclass();
            } else // class
            {
                curT = ((Class<?>) curT).getGenericSuperclass();
            }
        }
        // check if immediate child of Tuple has generics
        if (curT instanceof Class<?>) {
            throw new InvalidTypesException(""Tuple needs to be parameterized by using generics."");
        }
        ParameterizedType tupleChild = (ParameterizedType) curT;
        Type[] subtypes = new Type[tupleChild.getActualTypeArguments().length];
        // materialize possible type variables
        for (int i = 0; i < subtypes.length; i++) {
            // materialize immediate TypeVariables
            if (tupleChild.getActualTypeArguments()[i] instanceof TypeVariable<?>) {
                subtypes[i] = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) tupleChild.getActualTypeArguments()[i]);
            } else // class or parameterized type
            {
                subtypes[i] = tupleChild.getActualTypeArguments()[i];
            }
        }
        TypeInformation<?>[] tupleSubTypes = new TypeInformation<?>[subtypes.length];
        for (int i = 0; i < subtypes.length; i++) {
            // try to derive the type info of the TypeVariable from the immediate base child input as a last attempt
            if (subtypes[i] instanceof TypeVariable<?>) {
                tupleSubTypes[i] = createTypeInfoFromInput((TypeVariable<?>) subtypes[i], typeHierarchy, in1Type, in2Type);
                // variable could not be determined
                if (tupleSubTypes[i] == null) {
                    throw new InvalidTypesException(""Type of TypeVariable '"" + ((TypeVariable<?>) subtypes[i]).getName() + ""' in '"" + ((TypeVariable<?>) subtypes[i]).getGenericDeclaration() + ""' could not be determined. This is most likely a type erasure problem. "" + ""The type extraction currently supports types with generic variables only in cases where "" + ""all variables in the return type can be deduced from the input type(s)."");
                }
            } else {
                tupleSubTypes[i] = createTypeInfoWithTypeHierarchy(new ArrayList<Type>(typeHierarchy), subtypes[i], in1Type, in2Type);
            }
        }
        if (t instanceof Class<?>) {
            return new TupleTypeInfo(((Class<? extends Tuple>) t), tupleSubTypes);
        } else if (t instanceof ParameterizedType) {
            return new TupleTypeInfo(((Class<? extends Tuple>) ((ParameterizedType) t).getRawType()), tupleSubTypes);
        }
    } else // e.g. class MyMapper<E> extends MapFunction<String, E>
    if (t instanceof TypeVariable) {
        Type typeVar = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) t);
        if (!(typeVar instanceof TypeVariable)) {
            return createTypeInfoWithTypeHierarchy(typeHierarchy, typeVar, in1Type, in2Type);
        } else // try to derive the type info of the TypeVariable from the immediate base child input as a last attempt
        {
            TypeInformation<OUT> typeInfo = (TypeInformation<OUT>) createTypeInfoFromInput((TypeVariable<?>) t, typeHierarchy, in1Type, in2Type);
            if (typeInfo != null) {
                return typeInfo;
            } else {
                throw new InvalidTypesException(""Type of TypeVariable '"" + ((TypeVariable<?>) t).getName() + ""' in '"" + ((TypeVariable<?>) t).getGenericDeclaration() + ""' could not be determined. This is most likely a type erasure problem. "" + ""The type extraction currently supports types with generic variables only in cases where "" + ""all variables in the return type can be deduced from the input type(s)."");
            }
        }
    } else // arrays with generics
    if (t instanceof GenericArrayType) {
        GenericArrayType genericArray = (GenericArrayType) t;
        Type componentType = genericArray.getGenericComponentType();
        // due to a Java 6 bug, it is possible that the JVM classifies e.g. String[] or int[] as GenericArrayType instead of Class
        if (componentType instanceof Class) {
            Class<?> componentClass = (Class<?>) componentType;
            String className;
            // for int[], double[] etc.
            if (componentClass.isPrimitive()) {
                className = encodePrimitiveClass(componentClass);
            } else // for String[], Integer[] etc.
            {
                className = ""L"" + componentClass.getName() + "";"";
            }
            Class<OUT> classArray = null;
            try {
                classArray = (Class<OUT>) Class.forName(""["" + className);
            } catch (ClassNotFoundException e) {
                throw new InvalidTypesException(""Could not convert GenericArrayType to Class."");
            }
            return getForClass(classArray);
        }
        TypeInformation<?> componentInfo = createTypeInfoWithTypeHierarchy(typeHierarchy, genericArray.getGenericComponentType(), in1Type, in2Type);
        return ObjectArrayTypeInfo.getInfoFor(t, componentInfo);
    } else // objects with generics are treated as raw type
    if (t instanceof ParameterizedType) {
        return privateGetForClass((Class<OUT>) ((ParameterizedType) t).getRawType());
    } else // no tuple, no TypeVariable, no generic type
    if (t instanceof Class) {
        return privateGetForClass((Class<OUT>) t);
    }
    throw new InvalidTypesException(""Type Information could not be created."");
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1133_27e40205,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,374,413,"private <IN1, IN2> TypeInformation<?> createTypeInfoFromInput(TypeVariable<?> returnTypeVar, ArrayList<Type> returnTypeHierarchy, TypeInformation<IN1> in1TypeInfo, TypeInformation<IN2> in2TypeInfo) {
    Type matReturnTypeVar = materializeTypeVariable(returnTypeHierarchy, returnTypeVar);
    // variable could be resolved
    if (!(matReturnTypeVar instanceof TypeVariable)) {
        return createTypeInfoWithTypeHierarchy(returnTypeHierarchy, matReturnTypeVar, in1TypeInfo, in2TypeInfo);
    } else {
        returnTypeVar = (TypeVariable<?>) matReturnTypeVar;
    }
    TypeInformation<?> info = null;
    if (in1TypeInfo != null) {
        // find the deepest type variable that describes the type of input 1
        ParameterizedType baseClass = (ParameterizedType) returnTypeHierarchy.get(returnTypeHierarchy.size() - 1);
        Type in1Type = baseClass.getActualTypeArguments()[0];
        if (in1Type instanceof TypeVariable) {
            in1Type = materializeTypeVariable(returnTypeHierarchy, (TypeVariable<?>) in1Type);
            info = findCorrespondingInfo(returnTypeVar, in1Type, in1TypeInfo);
        }
    }
    if (info == null && in2TypeInfo != null) {
        // find the deepest type variable that describes the type of input 2
        ParameterizedType baseClass = (ParameterizedType) returnTypeHierarchy.get(returnTypeHierarchy.size() - 1);
        Type in2Type = baseClass.getActualTypeArguments()[1];
        if (in2Type instanceof TypeVariable) {
            in2Type = materializeTypeVariable(returnTypeHierarchy, (TypeVariable<?>) in2Type);
            info = findCorrespondingInfo(returnTypeVar, in2Type, in2TypeInfo);
        }
    }
    if (info != null) {
        return info;
    }
    return null;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1145_22c370d9,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,957,1010,"/**
 *  Checks if the given field is a valid pojo field:
 *  - it is public
 *  OR
 *   - there are getter and setter methods for the field.
 *
 *  @param f field to check
 *  @param clazz class of field
 *  @param typeHierarchy type hierarchy for materializing generic types
 *  @return
 */
private boolean isValidPojoField(Field f, Class<?> clazz, ArrayList<Type> typeHierarchy) {
    if (Modifier.isPublic(f.getModifiers())) {
        return true;
    } else {
        boolean hasGetter = false, hasSetter = false;
        final String fieldNameLow = f.getName().toLowerCase();
        Type fieldType = f.getGenericType();
        TypeVariable<?> fieldTypeGeneric = null;
        if (fieldType instanceof TypeVariable) {
            fieldTypeGeneric = (TypeVariable<?>) fieldType;
            fieldType = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) fieldType);
        }
        for (Method m : clazz.getMethods()) {
            if (// The name should be ""get<FieldName>"" or ""<fieldName>"" (for scala).
            (m.getName().toLowerCase().equals(""get"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow)) && // no arguments for the getter
            m.getParameterTypes().length == 0 && // return type is same as field type (or the generic variant of it)
            m.getReturnType().equals(fieldType) || (fieldTypeGeneric != null && m.getGenericReturnType().equals(fieldTypeGeneric))) {
                if (hasGetter) {
                    throw new IllegalStateException(""Detected more than one getters"");
                }
                hasGetter = true;
            }
            // check for setters (<FieldName>_$eq for scala)
            if ((m.getName().toLowerCase().equals(""set"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow + ""_$eq"")) && // one parameter of the field's type
            m.getParameterTypes().length == 1 && (m.getParameterTypes()[0].equals(fieldType) || (fieldTypeGeneric != null && m.getGenericParameterTypes()[0].equals(fieldTypeGeneric))) && // return type is void.
            m.getReturnType().equals(Void.TYPE)) {
                if (hasSetter) {
                    throw new IllegalStateException(""Detected more than one getters"");
                }
                hasSetter = true;
            }
        }
        if (hasGetter && hasSetter) {
            return true;
        } else {
            if (!hasGetter) {
                LOG.warn(""Class "" + clazz + "" does not contain a getter for field "" + f.getName());
            }
            if (!hasSetter) {
                LOG.warn(""Class "" + clazz + "" does not contain a setter for field "" + f.getName());
            }
            return false;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1167_259f10c0,Minor,flink-compiler/src/main/java/org/apache/flink/compiler/dag/BulkIterationNode.java,130,170,"/**
 *  Sets the nextPartialSolution for this BulkIterationNode.
 *
 *  @param nextPartialSolution The nextPartialSolution to set.
 */
public void setNextPartialSolution(OptimizerNode nextPartialSolution, OptimizerNode terminationCriterion) {
    // or if the steo function has any operator at all
    if (nextPartialSolution.getDegreeOfParallelism() != getDegreeOfParallelism() || nextPartialSolution == partialSolution) {
        // add a no-op to the root to express the re-partitioning
        NoOpNode noop = new NoOpNode();
        noop.setDegreeOfParallelism(getDegreeOfParallelism());
        PactConnection noOpConn = new PactConnection(nextPartialSolution, noop);
        noop.setIncomingConnection(noOpConn);
        nextPartialSolution.addOutgoingConnection(noOpConn);
        nextPartialSolution = noop;
    }
    this.nextPartialSolution = nextPartialSolution;
    this.terminationCriterion = terminationCriterion;
    if (terminationCriterion == null) {
        this.singleRoot = nextPartialSolution;
        this.rootConnection = new PactConnection(nextPartialSolution);
    } else {
        // we have a termination criterion
        SingleRootJoiner singleRootJoiner = new SingleRootJoiner();
        this.rootConnection = new PactConnection(nextPartialSolution, singleRootJoiner);
        this.terminationCriterionRootConnection = new PactConnection(terminationCriterion, singleRootJoiner);
        singleRootJoiner.setInputs(this.rootConnection, this.terminationCriterionRootConnection);
        this.singleRoot = singleRootJoiner;
        // add connection to terminationCriterion for interesting properties visitor
        terminationCriterion.addOutgoingConnection(terminationCriterionRootConnection);
    }
    nextPartialSolution.addOutgoingConnection(rootConnection);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1167_259f10c0,Minor,flink-compiler/src/main/java/org/apache/flink/compiler/dag/WorksetIterationNode.java,149,193,"public void setNextPartialSolution(OptimizerNode solutionSetDelta, OptimizerNode nextWorkset) {
    // the partial solution (so we can potentially do direct updates)
    if (solutionSetDelta instanceof TwoInputNode) {
        TwoInputNode solutionDeltaTwoInput = (TwoInputNode) solutionSetDelta;
        if (solutionDeltaTwoInput.getFirstPredecessorNode() == this.solutionSetNode || solutionDeltaTwoInput.getSecondPredecessorNode() == this.solutionSetNode) {
            this.solutionDeltaImmediatelyAfterSolutionJoin = true;
        }
    }
    // if the next workset is equal to the workset, we need to inject a no-op node
    if (nextWorkset == worksetNode) {
        NoOpNode noop = new NoOpNode();
        noop.setDegreeOfParallelism(getDegreeOfParallelism());
        PactConnection noOpConn = new PactConnection(nextWorkset, noop);
        noop.setIncomingConnection(noOpConn);
        nextWorkset.addOutgoingConnection(noOpConn);
        nextWorkset = noop;
    }
    // attach an extra node to the solution set delta for the cases where we need to repartition
    UnaryOperatorNode solutionSetDeltaUpdateAux = new UnaryOperatorNode(""Solution-Set Delta"", getSolutionSetKeyFields(), new SolutionSetDeltaOperator(getSolutionSetKeyFields()));
    solutionSetDeltaUpdateAux.setDegreeOfParallelism(getDegreeOfParallelism());
    PactConnection conn = new PactConnection(solutionSetDelta, solutionSetDeltaUpdateAux);
    solutionSetDeltaUpdateAux.setIncomingConnection(conn);
    solutionSetDelta.addOutgoingConnection(conn);
    this.solutionSetDelta = solutionSetDeltaUpdateAux;
    this.nextWorkset = nextWorkset;
    this.singleRoot = new SingleRootJoiner();
    this.solutionSetDeltaRootConnection = new PactConnection(solutionSetDeltaUpdateAux, this.singleRoot);
    this.nextWorksetRootConnection = new PactConnection(nextWorkset, this.singleRoot);
    this.singleRoot.setInputs(this.solutionSetDeltaRootConnection, this.nextWorksetRootConnection);
    solutionSetDeltaUpdateAux.addOutgoingConnection(this.solutionSetDeltaRootConnection);
    nextWorkset.addOutgoingConnection(this.nextWorksetRootConnection);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1167_259f10c0,Minor,flink-compiler/src/main/java/org/apache/flink/compiler/plandump/PlanJSONDumpGenerator.java,141,606,"private boolean visit(DumpableNode<?> node, PrintWriter writer, boolean first) {
    // check for duplicate traversal
    if (this.nodeIds.containsKey(node)) {
        return false;
    }
    // assign an id first
    this.nodeIds.put(node, this.nodeCnt++);
    // then recurse
    for (DumpableNode<?> child : node.getPredecessors()) {
        // to set first to false!
        if (visit(child, writer, first)) {
            first = false;
        }
        ;
    }
    // check if this node should be skipped from the dump
    final OptimizerNode n = node.getOptimizerNode();
    // start a new node and output node id
    if (!first) {
        writer.print("",\n"");
    }
    // open the node
    writer.print(""\t{\n"");
    // recurse, it is is an iteration node
    if (node instanceof BulkIterationNode || node instanceof BulkIterationPlanNode) {
        DumpableNode<?> innerChild = node instanceof BulkIterationNode ? ((BulkIterationNode) node).getNextPartialSolution() : ((BulkIterationPlanNode) node).getRootOfStepFunction();
        DumpableNode<?> begin = node instanceof BulkIterationNode ? ((BulkIterationNode) node).getPartialSolution() : ((BulkIterationPlanNode) node).getPartialSolutionPlanNode();
        writer.print(""\t\t\""step_function\"": [\n"");
        visit(innerChild, writer, true);
        writer.print(""\n\t\t],\n"");
        writer.print(""\t\t\""partial_solution\"": "" + this.nodeIds.get(begin) + "",\n"");
        writer.print(""\t\t\""next_partial_solution\"": "" + this.nodeIds.get(innerChild) + "",\n"");
    } else if (node instanceof WorksetIterationNode || node instanceof WorksetIterationPlanNode) {
        DumpableNode<?> worksetRoot = node instanceof WorksetIterationNode ? ((WorksetIterationNode) node).getNextWorkset() : ((WorksetIterationPlanNode) node).getNextWorkSetPlanNode();
        DumpableNode<?> solutionDelta = node instanceof WorksetIterationNode ? ((WorksetIterationNode) node).getSolutionSetDelta() : ((WorksetIterationPlanNode) node).getSolutionSetDeltaPlanNode();
        DumpableNode<?> workset = node instanceof WorksetIterationNode ? ((WorksetIterationNode) node).getWorksetNode() : ((WorksetIterationPlanNode) node).getWorksetPlanNode();
        DumpableNode<?> solutionSet = node instanceof WorksetIterationNode ? ((WorksetIterationNode) node).getSolutionSetNode() : ((WorksetIterationPlanNode) node).getSolutionSetPlanNode();
        writer.print(""\t\t\""step_function\"": [\n"");
        visit(worksetRoot, writer, true);
        visit(solutionDelta, writer, false);
        writer.print(""\n\t\t],\n"");
        writer.print(""\t\t\""workset\"": "" + this.nodeIds.get(workset) + "",\n"");
        writer.print(""\t\t\""solution_set\"": "" + this.nodeIds.get(solutionSet) + "",\n"");
        writer.print(""\t\t\""next_workset\"": "" + this.nodeIds.get(worksetRoot) + "",\n"");
        writer.print(""\t\t\""solution_delta\"": "" + this.nodeIds.get(solutionDelta) + "",\n"");
    }
    // print the id
    writer.print(""\t\t\""id\"": "" + this.nodeIds.get(node));
    final String type;
    final String contents;
    if (n instanceof DataSinkNode) {
        type = ""sink"";
        contents = n.getPactContract().toString();
    } else if (n instanceof DataSourceNode) {
        type = ""source"";
        contents = n.getPactContract().toString();
    } else if (n instanceof BulkIterationNode) {
        type = ""bulk_iteration"";
        contents = n.getPactContract().getName();
    } else if (n instanceof WorksetIterationNode) {
        type = ""workset_iteration"";
        contents = n.getPactContract().getName();
    } else if (n instanceof BinaryUnionNode) {
        type = ""pact"";
        contents = """";
    } else {
        type = ""pact"";
        contents = n.getPactContract().getName();
    }
    String name = n.getName();
    if (name.equals(""Reduce"") && (node instanceof SingleInputPlanNode) && ((SingleInputPlanNode) node).getDriverStrategy() == DriverStrategy.SORTED_GROUP_COMBINE) {
        name = ""Combine"";
    }
    // output the type identifier
    writer.print("",\n\t\t\""type\"": \"""" + type + ""\"""");
    // output node name
    writer.print("",\n\t\t\""pact\"": \"""" + name + ""\"""");
    // output node contents
    writer.print("",\n\t\t\""contents\"": \"""" + contents + ""\"""");
    // degree of parallelism
    writer.print("",\n\t\t\""parallelism\"": \"""" + (n.getDegreeOfParallelism() >= 1 ? n.getDegreeOfParallelism() : ""default"") + ""\"""");
    // output node predecessors
    Iterator<? extends DumpableConnection<?>> inConns = node.getDumpableInputs().iterator();
    String child1name = """", child2name = """";
    if (inConns != null && inConns.hasNext()) {
        // start predecessor list
        writer.print("",\n\t\t\""predecessors\"": ["");
        int connNum = 0;
        int inputNum = 0;
        while (inConns.hasNext()) {
            final DumpableConnection<?> conn = inConns.next();
            final Collection<DumpableConnection<?>> inConnsForInput;
            if (conn.getSource() instanceof NAryUnionPlanNode) {
                inConnsForInput = new ArrayList<DumpableConnection<?>>();
                for (DumpableConnection<?> inputOfUnion : conn.getSource().getDumpableInputs()) {
                    inConnsForInput.add(inputOfUnion);
                }
            } else {
                inConnsForInput = Collections.<DumpableConnection<?>>singleton(conn);
            }
            for (DumpableConnection<?> inConn : inConnsForInput) {
                final DumpableNode<?> source = inConn.getSource();
                writer.print(connNum == 0 ? ""\n"" : "",\n"");
                if (connNum == 0) {
                    child1name += child1name.length() > 0 ? "", "" : """";
                    child1name += source.getOptimizerNode().getPactContract().getName();
                } else if (connNum == 1) {
                    child2name += child2name.length() > 0 ? "", "" : """";
                    child2name = source.getOptimizerNode().getPactContract().getName();
                }
                // output predecessor id
                writer.print(""\t\t\t{\""id\"": "" + this.nodeIds.get(source));
                // output connection side
                if (inConns.hasNext() || inputNum > 0) {
                    writer.print("", \""side\"": \"""" + (inputNum == 0 ? ""first"" : ""second"") + ""\"""");
                }
                // output shipping strategy and channel type
                final Channel channel = (inConn instanceof Channel) ? (Channel) inConn : null;
                final ShipStrategyType shipType = channel != null ? channel.getShipStrategy() : ((PactConnection) inConn).getShipStrategy();
                String shipStrategy = null;
                if (shipType != null) {
                    switch(shipType) {
                        case NONE:
                            // nothing
                            break;
                        case FORWARD:
                            shipStrategy = ""Forward"";
                            break;
                        case BROADCAST:
                            shipStrategy = ""Broadcast"";
                            break;
                        case PARTITION_HASH:
                            shipStrategy = ""Hash Partition"";
                            break;
                        case PARTITION_RANGE:
                            shipStrategy = ""Range Partition"";
                            break;
                        case PARTITION_RANDOM:
                            shipStrategy = ""Redistribute"";
                            break;
                        case PARTITION_FORCED_REBALANCE:
                            shipStrategy = ""Rebalance"";
                            break;
                        default:
                            throw new CompilerException(""Unknown ship strategy '"" + conn.getShipStrategy().name() + ""' in JSON generator."");
                    }
                }
                if (channel != null && channel.getShipStrategyKeys() != null && channel.getShipStrategyKeys().size() > 0) {
                    shipStrategy += "" on "" + (channel.getShipStrategySortOrder() == null ? channel.getShipStrategyKeys().toString() : Utils.createOrdering(channel.getShipStrategyKeys(), channel.getShipStrategySortOrder()).toString());
                }
                if (shipStrategy != null) {
                    writer.print("", \""ship_strategy\"": \"""" + shipStrategy + ""\"""");
                }
                if (channel != null) {
                    String localStrategy = null;
                    switch(channel.getLocalStrategy()) {
                        case NONE:
                            break;
                        case SORT:
                            localStrategy = ""Sort"";
                            break;
                        case COMBININGSORT:
                            localStrategy = ""Sort (combining)"";
                            break;
                        default:
                            throw new CompilerException(""Unknown local strategy "" + channel.getLocalStrategy().name());
                    }
                    if (channel != null && channel.getLocalStrategyKeys() != null && channel.getLocalStrategyKeys().size() > 0) {
                        localStrategy += "" on "" + (channel.getLocalStrategySortOrder() == null ? channel.getLocalStrategyKeys().toString() : Utils.createOrdering(channel.getLocalStrategyKeys(), channel.getLocalStrategySortOrder()).toString());
                    }
                    if (localStrategy != null) {
                        writer.print("", \""local_strategy\"": \"""" + localStrategy + ""\"""");
                    }
                    if (channel != null && channel.getTempMode() != TempMode.NONE) {
                        String tempMode = channel.getTempMode().toString();
                        writer.print("", \""temp_mode\"": \"""" + tempMode + ""\"""");
                    }
                }
                writer.print('}');
                connNum++;
            }
            inputNum++;
        }
        // finish predecessors
        writer.print(""\n\t\t]"");
    }
    // ---------------------------------------------------------------------------------------
    // the part below here is relevant only to plan nodes with concrete strategies, etc
    // ---------------------------------------------------------------------------------------
    final PlanNode p = node.getPlanNode();
    if (p == null) {
        // finish node
        writer.print(""\n\t}"");
        return true;
    }
    // local strategy
    String locString = null;
    if (p.getDriverStrategy() != null) {
        switch(p.getDriverStrategy()) {
            case NONE:
            case BINARY_NO_OP:
                break;
            case UNARY_NO_OP:
                locString = ""No-Op"";
                break;
            case COLLECTOR_MAP:
            case MAP:
                locString = ""Map"";
                break;
            case FLAT_MAP:
                locString = ""FlatMap"";
                break;
            case MAP_PARTITION:
                locString = ""Map Partition"";
                break;
            case ALL_REDUCE:
                locString = ""Reduce All"";
                break;
            case ALL_GROUP_REDUCE:
            case ALL_GROUP_COMBINE:
                locString = ""Group Reduce All"";
                break;
            case SORTED_REDUCE:
                locString = ""Sorted Reduce"";
                break;
            case SORTED_PARTIAL_REDUCE:
                locString = ""Sorted Combine/Reduce"";
                break;
            case SORTED_GROUP_REDUCE:
                locString = ""Sorted Group Reduce"";
                break;
            case SORTED_GROUP_COMBINE:
                locString = ""Sorted Combine"";
                break;
            case HYBRIDHASH_BUILD_FIRST:
                locString = ""Hybrid Hash (build: "" + child1name + "")"";
                break;
            case HYBRIDHASH_BUILD_SECOND:
                locString = ""Hybrid Hash (build: "" + child2name + "")"";
                break;
            case HYBRIDHASH_BUILD_FIRST_CACHED:
                locString = ""Hybrid Hash (CACHED) (build: "" + child1name + "")"";
                break;
            case HYBRIDHASH_BUILD_SECOND_CACHED:
                locString = ""Hybrid Hash (CACHED) (build: "" + child2name + "")"";
                break;
            case NESTEDLOOP_BLOCKED_OUTER_FIRST:
                locString = ""Nested Loops (Blocked Outer: "" + child1name + "")"";
                break;
            case NESTEDLOOP_BLOCKED_OUTER_SECOND:
                locString = ""Nested Loops (Blocked Outer: "" + child2name + "")"";
                break;
            case NESTEDLOOP_STREAMED_OUTER_FIRST:
                locString = ""Nested Loops (Streamed Outer: "" + child1name + "")"";
                break;
            case NESTEDLOOP_STREAMED_OUTER_SECOND:
                locString = ""Nested Loops (Streamed Outer: "" + child2name + "")"";
                break;
            case MERGE:
                locString = ""Merge"";
                break;
            case CO_GROUP:
                locString = ""Co-Group"";
                break;
            default:
                locString = p.getDriverStrategy().name();
                break;
        }
        if (locString != null) {
            writer.print("",\n\t\t\""driver_strategy\"": \"""");
            writer.print(locString);
            writer.print(""\"""");
        }
    }
    {
        // output node global properties
        final GlobalProperties gp = p.getGlobalProperties();
        writer.print("",\n\t\t\""global_properties\"": [\n"");
        addProperty(writer, ""Partitioning"", gp.getPartitioning().name(), true);
        if (gp.getPartitioningFields() != null) {
            addProperty(writer, ""Partitioned on"", gp.getPartitioningFields().toString(), false);
        }
        if (gp.getPartitioningOrdering() != null) {
            addProperty(writer, ""Partitioning Order"", gp.getPartitioningOrdering().toString(), false);
        } else {
            addProperty(writer, ""Partitioning Order"", ""(none)"", false);
        }
        if (n.getUniqueFields() == null || n.getUniqueFields().size() == 0) {
            addProperty(writer, ""Uniqueness"", ""not unique"", false);
        } else {
            addProperty(writer, ""Uniqueness"", n.getUniqueFields().toString(), false);
        }
        writer.print(""\n\t\t]"");
    }
    {
        // output node local properties
        LocalProperties lp = p.getLocalProperties();
        writer.print("",\n\t\t\""local_properties\"": [\n"");
        if (lp.getOrdering() != null) {
            addProperty(writer, ""Order"", lp.getOrdering().toString(), true);
        } else {
            addProperty(writer, ""Order"", ""(none)"", true);
        }
        if (lp.getGroupedFields() != null && lp.getGroupedFields().size() > 0) {
            addProperty(writer, ""Grouped on"", lp.getGroupedFields().toString(), false);
        } else {
            addProperty(writer, ""Grouping"", ""not grouped"", false);
        }
        if (n.getUniqueFields() == null || n.getUniqueFields().size() == 0) {
            addProperty(writer, ""Uniqueness"", ""not unique"", false);
        } else {
            addProperty(writer, ""Uniqueness"", n.getUniqueFields().toString(), false);
        }
        writer.print(""\n\t\t]"");
    }
    // output node size estimates
    writer.print("",\n\t\t\""estimates\"": [\n"");
    addProperty(writer, ""Est. Output Size"", n.getEstimatedOutputSize() == -1 ? ""(unknown)"" : formatNumber(n.getEstimatedOutputSize(), ""B""), true);
    addProperty(writer, ""Est. Cardinality"", n.getEstimatedNumRecords() == -1 ? ""(unknown)"" : formatNumber(n.getEstimatedNumRecords()), false);
    writer.print(""\t\t]"");
    // output node cost
    if (p.getNodeCosts() != null) {
        writer.print("",\n\t\t\""costs\"": [\n"");
        addProperty(writer, ""Network"", p.getNodeCosts().getNetworkCost() == -1 ? ""(unknown)"" : formatNumber(p.getNodeCosts().getNetworkCost(), ""B""), true);
        addProperty(writer, ""Disk I/O"", p.getNodeCosts().getDiskCost() == -1 ? ""(unknown)"" : formatNumber(p.getNodeCosts().getDiskCost(), ""B""), false);
        addProperty(writer, ""CPU"", p.getNodeCosts().getCpuCost() == -1 ? ""(unknown)"" : formatNumber(p.getNodeCosts().getCpuCost(), """"), false);
        addProperty(writer, ""Cumulative Network"", p.getCumulativeCosts().getNetworkCost() == -1 ? ""(unknown)"" : formatNumber(p.getCumulativeCosts().getNetworkCost(), ""B""), false);
        addProperty(writer, ""Cumulative Disk I/O"", p.getCumulativeCosts().getDiskCost() == -1 ? ""(unknown)"" : formatNumber(p.getCumulativeCosts().getDiskCost(), ""B""), false);
        addProperty(writer, ""Cumulative CPU"", p.getCumulativeCosts().getCpuCost() == -1 ? ""(unknown)"" : formatNumber(p.getCumulativeCosts().getCpuCost(), """"), false);
        writer.print(""\n\t\t]"");
    }
    // output the node compiler hints
    if (n.getPactContract().getCompilerHints() != null) {
        CompilerHints hints = n.getPactContract().getCompilerHints();
        CompilerHints defaults = new CompilerHints();
        String size = hints.getOutputSize() == defaults.getOutputSize() ? ""(none)"" : String.valueOf(hints.getOutputSize());
        String card = hints.getOutputCardinality() == defaults.getOutputCardinality() ? ""(none)"" : String.valueOf(hints.getOutputCardinality());
        String width = hints.getAvgOutputRecordSize() == defaults.getAvgOutputRecordSize() ? ""(none)"" : String.valueOf(hints.getAvgOutputRecordSize());
        String filter = hints.getFilterFactor() == defaults.getFilterFactor() ? ""(none)"" : String.valueOf(hints.getFilterFactor());
        writer.print("",\n\t\t\""compiler_hints\"": [\n"");
        addProperty(writer, ""Output Size (bytes)"", size, true);
        addProperty(writer, ""Output Cardinality"", card, false);
        addProperty(writer, ""Avg. Output Record Size (bytes)"", width, false);
        addProperty(writer, ""Filter Factor"", filter, false);
        writer.print(""\t\t]"");
    }
    // finish node
    writer.print(""\n\t}"");
    return true;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1214_6ecd0f82,Major,flink-compiler/src/main/java/org/apache/flink/compiler/dag/SingleInputNode.java,215,234,"@Override
public void computeInterestingPropertiesForInputs(CostEstimator estimator) {
    // get what we inherit and what is preserved by our user code
    final InterestingProperties props = getInterestingProperties().filterByCodeAnnotations(this, 0);
    // add all properties relevant to this node
    for (OperatorDescriptorSingle dps : getPossibleProperties()) {
        for (RequestedGlobalProperties gp : dps.getPossibleGlobalProperties()) {
            props.addGlobalProperties(gp);
        }
        for (RequestedLocalProperties lp : dps.getPossibleLocalProperties()) {
            props.addLocalProperties(lp);
        }
    }
    this.inConn.setInterestingProperties(props);
    for (PactConnection conn : getBroadcastConnections()) {
        conn.setInterestingProperties(new InterestingProperties());
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1290_45fb6d82,Major,flink-compiler/src/main/java/org/apache/flink/compiler/operators/AbstractJoinDescriptor.java,59,98,"@Override
protected List<GlobalPropertiesPair> createPossibleGlobalProperties() {
    ArrayList<GlobalPropertiesPair> pairs = new ArrayList<GlobalPropertiesPair>();
    if (repartitionAllowed) {
        // partition both (hash or custom)
        RequestedGlobalProperties partitioned1 = new RequestedGlobalProperties();
        if (customPartitioner == null) {
            partitioned1.setAnyPartitioning(this.keys1);
        } else {
            partitioned1.setCustomPartitioned(this.keys1, this.customPartitioner);
        }
        RequestedGlobalProperties partitioned2 = new RequestedGlobalProperties();
        if (customPartitioner == null) {
            partitioned2.setAnyPartitioning(this.keys2);
        } else {
            partitioned2.setCustomPartitioned(this.keys2, this.customPartitioner);
        }
        pairs.add(new GlobalPropertiesPair(partitioned1, partitioned2));
    }
    if (broadcastSecondAllowed) {
        // replicate second
        RequestedGlobalProperties any1 = new RequestedGlobalProperties();
        RequestedGlobalProperties replicated2 = new RequestedGlobalProperties();
        replicated2.setFullyReplicated();
        pairs.add(new GlobalPropertiesPair(any1, replicated2));
    }
    if (broadcastFirstAllowed) {
        // replicate first
        RequestedGlobalProperties replicated1 = new RequestedGlobalProperties();
        replicated1.setFullyReplicated();
        RequestedGlobalProperties any2 = new RequestedGlobalProperties();
        pairs.add(new GlobalPropertiesPair(replicated1, any2));
    }
    return pairs;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1290_45fb6d82,Major,flink-compiler/src/main/java/org/apache/flink/compiler/operators/CoGroupDescriptor.java,99,116,"@Override
protected List<GlobalPropertiesPair> createPossibleGlobalProperties() {
    RequestedGlobalProperties partitioned1 = new RequestedGlobalProperties();
    if (this.customPartitioner == null) {
        partitioned1.setAnyPartitioning(this.keys1);
    } else {
        partitioned1.setCustomPartitioned(this.keys1, this.customPartitioner);
    }
    RequestedGlobalProperties partitioned2 = new RequestedGlobalProperties();
    if (this.customPartitioner == null) {
        partitioned2.setAnyPartitioning(this.keys2);
    } else {
        partitioned2.setCustomPartitioned(this.keys2, this.customPartitioner);
    }
    return Collections.singletonList(new GlobalPropertiesPair(partitioned1, partitioned2));
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1311_94c8e3fa,Major,flink-compiler/src/main/java/org/apache/flink/compiler/PactCompiler.java,790,925,"@Override
public void postVisit(Operator<?> c) {
    OptimizerNode n = this.con2node.get(c);
    // first connect to the predecessors
    n.setInput(this.con2node);
    n.setBroadcastInputs(this.con2node);
    // if the node represents a bulk iteration, we recursively translate the data flow now
    if (n instanceof BulkIterationNode) {
        final BulkIterationNode iterNode = (BulkIterationNode) n;
        final BulkIterationBase<?> iter = iterNode.getIterationContract();
        // pass a copy of the no iterative part into the iteration translation,
        // in case the iteration references its closure
        HashMap<Operator<?>, OptimizerNode> closure = new HashMap<Operator<?>, OptimizerNode>(con2node);
        // first, recursively build the data flow for the step function
        final GraphCreatingVisitor recursiveCreator = new GraphCreatingVisitor(this, true, iterNode.getDegreeOfParallelism(), closure);
        BulkPartialSolutionNode partialSolution = null;
        iter.getNextPartialSolution().accept(recursiveCreator);
        partialSolution = (BulkPartialSolutionNode) recursiveCreator.con2node.get(iter.getPartialSolution());
        OptimizerNode rootOfStepFunction = recursiveCreator.con2node.get(iter.getNextPartialSolution());
        if (partialSolution == null) {
            throw new CompilerException(""Error: The step functions result does not depend on the partial solution."");
        }
        OptimizerNode terminationCriterion = null;
        if (iter.getTerminationCriterion() != null) {
            terminationCriterion = recursiveCreator.con2node.get(iter.getTerminationCriterion());
            // no intermediate node yet, traverse from the termination criterion to build the missing parts
            if (terminationCriterion == null) {
                iter.getTerminationCriterion().accept(recursiveCreator);
                terminationCriterion = recursiveCreator.con2node.get(iter.getTerminationCriterion());
            }
        }
        iterNode.setPartialSolution(partialSolution);
        iterNode.setNextPartialSolution(rootOfStepFunction, terminationCriterion);
        // go over the contained data flow and mark the dynamic path nodes
        StaticDynamicPathIdentifier identifier = new StaticDynamicPathIdentifier(iterNode.getCostWeight());
        rootOfStepFunction.accept(identifier);
        if (terminationCriterion != null) {
            terminationCriterion.accept(identifier);
        }
    } else if (n instanceof WorksetIterationNode) {
        final WorksetIterationNode iterNode = (WorksetIterationNode) n;
        final DeltaIterationBase<?, ?> iter = iterNode.getIterationContract();
        // we need to ensure that both the next-workset and the solution-set-delta depend on the workset. One check is for free
        // during the translation, we do the other check here as a pre-condition
        {
            StepFunctionValidator wsf = new StepFunctionValidator();
            iter.getNextWorkset().accept(wsf);
            if (!wsf.foundWorkset) {
                throw new CompilerException(""In the given program, the next workset does not depend on the workset. This is a prerequisite in delta iterations."");
            }
        }
        // calculate the closure of the anonymous function
        HashMap<Operator<?>, OptimizerNode> closure = new HashMap<Operator<?>, OptimizerNode>(con2node);
        // first, recursively build the data flow for the step function
        final GraphCreatingVisitor recursiveCreator = new GraphCreatingVisitor(this, true, iterNode.getDegreeOfParallelism(), closure);
        // descend from the solution set delta. check that it depends on both the workset
        // and the solution set. If it does depend on both, this descend should create both nodes
        iter.getSolutionSetDelta().accept(recursiveCreator);
        final WorksetNode worksetNode = (WorksetNode) recursiveCreator.con2node.get(iter.getWorkset());
        if (worksetNode == null) {
            throw new CompilerException(""In the given program, the solution set delta does not depend on the workset. This is a prerequisite in delta iterations."");
        }
        iter.getNextWorkset().accept(recursiveCreator);
        SolutionSetNode solutionSetNode = (SolutionSetNode) recursiveCreator.con2node.get(iter.getSolutionSet());
        if (solutionSetNode == null || solutionSetNode.getOutgoingConnections() == null || solutionSetNode.getOutgoingConnections().isEmpty()) {
            solutionSetNode = new SolutionSetNode((SolutionSetPlaceHolder<?>) iter.getSolutionSet(), iterNode);
        } else {
            for (PactConnection conn : solutionSetNode.getOutgoingConnections()) {
                OptimizerNode successor = conn.getTarget();
                if (successor.getClass() == JoinNode.class) {
                    // find out which input to the match the solution set is
                    JoinNode mn = (JoinNode) successor;
                    if (mn.getFirstPredecessorNode() == solutionSetNode) {
                        mn.makeJoinWithSolutionSet(0);
                    } else if (mn.getSecondPredecessorNode() == solutionSetNode) {
                        mn.makeJoinWithSolutionSet(1);
                    } else {
                        throw new CompilerException();
                    }
                } else if (successor.getClass() == CoGroupNode.class) {
                    CoGroupNode cg = (CoGroupNode) successor;
                    if (cg.getFirstPredecessorNode() == solutionSetNode) {
                        cg.makeCoGroupWithSolutionSet(0);
                    } else if (cg.getSecondPredecessorNode() == solutionSetNode) {
                        cg.makeCoGroupWithSolutionSet(1);
                    } else {
                        throw new CompilerException();
                    }
                } else {
                    throw new InvalidProgramException(""Error: The only operations allowed on the solution set are Join and CoGroup."");
                }
            }
        }
        final OptimizerNode nextWorksetNode = recursiveCreator.con2node.get(iter.getNextWorkset());
        final OptimizerNode solutionSetDeltaNode = recursiveCreator.con2node.get(iter.getSolutionSetDelta());
        // set the step function nodes to the iteration node
        iterNode.setPartialSolution(solutionSetNode, worksetNode);
        iterNode.setNextPartialSolution(solutionSetDeltaNode, nextWorksetNode);
        // go over the contained data flow and mark the dynamic path nodes
        StaticDynamicPathIdentifier pathIdentifier = new StaticDynamicPathIdentifier(iterNode.getCostWeight());
        nextWorksetNode.accept(pathIdentifier);
        iterNode.getSolutionSetDelta().accept(pathIdentifier);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1333_63ef8e86,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,977,1029,"/**
 *  Checks if the given field is a valid pojo field:
 *  - it is public
 *  OR
 *   - there are getter and setter methods for the field.
 *
 *  @param f field to check
 *  @param clazz class of field
 *  @param typeHierarchy type hierarchy for materializing generic types
 *  @return
 */
private boolean isValidPojoField(Field f, Class<?> clazz, ArrayList<Type> typeHierarchy) {
    if (Modifier.isPublic(f.getModifiers())) {
        return true;
    } else {
        boolean hasGetter = false, hasSetter = false;
        final String fieldNameLow = f.getName().toLowerCase();
        Type fieldType = f.getGenericType();
        TypeVariable<?> fieldTypeGeneric = null;
        if (fieldType instanceof TypeVariable) {
            fieldTypeGeneric = (TypeVariable<?>) fieldType;
            fieldType = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) fieldType);
        }
        for (Method m : clazz.getMethods()) {
            // check for getter
            if (// The name should be ""get<FieldName>"" or ""<fieldName>"" (for scala).
            (m.getName().toLowerCase().equals(""get"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow)) && // no arguments for the getter
            m.getParameterTypes().length == 0 && // return type is same as field type (or the generic variant of it)
            (m.getReturnType().equals(fieldType) || (fieldTypeGeneric != null && m.getGenericReturnType().equals(fieldTypeGeneric)))) {
                if (hasGetter) {
                    throw new IllegalStateException(""Detected more than one getter"");
                }
                hasGetter = true;
            }
            // check for setters (<FieldName>_$eq for scala)
            if ((m.getName().toLowerCase().equals(""set"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow + ""_$eq"")) && // one parameter of the field's type
            m.getParameterTypes().length == 1 && (m.getParameterTypes()[0].equals(fieldType) || (fieldTypeGeneric != null && m.getGenericParameterTypes()[0].equals(fieldTypeGeneric))) && // return type is void.
            m.getReturnType().equals(Void.TYPE)) {
                if (hasSetter) {
                    throw new IllegalStateException(""Detected more than one setter"");
                }
                hasSetter = true;
            }
        }
        if (hasGetter && hasSetter) {
            return true;
        } else {
            if (!hasGetter) {
                LOG.warn(""Class "" + clazz + "" does not contain a getter for field "" + f.getName());
            }
            if (!hasSetter) {
                LOG.warn(""Class "" + clazz + "" does not contain a setter for field "" + f.getName());
            }
            return false;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1382_9cd96df7,Minor,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeInfoParser.java,99,324,"@SuppressWarnings({ ""rawtypes"", ""unchecked"" })
private static TypeInformation<?> parse(StringBuilder sb) throws ClassNotFoundException {
    String infoString = sb.toString();
    final Matcher tupleMatcher = tuplePattern.matcher(infoString);
    final Matcher writableMatcher = writablePattern.matcher(infoString);
    final Matcher enumMatcher = enumPattern.matcher(infoString);
    final Matcher basicTypeMatcher = basicTypePattern.matcher(infoString);
    final Matcher basicType2Matcher = basicType2Pattern.matcher(infoString);
    final Matcher valueTypeMatcher = valueTypePattern.matcher(infoString);
    final Matcher basicArrayTypeMatcher = basicArrayTypePattern.matcher(infoString);
    final Matcher basicArrayType2Matcher = basicArrayType2Pattern.matcher(infoString);
    final Matcher pojoGenericMatcher = pojoGenericObjectPattern.matcher(infoString);
    if (infoString.length() == 0) {
        return null;
    }
    TypeInformation<?> returnType = null;
    // tuples
    if (tupleMatcher.find()) {
        String className = tupleMatcher.group(1);
        sb.delete(0, className.length() + 1);
        int arity = Integer.parseInt(className.replaceAll(""\\D"", """"));
        Class<?> clazz;
        // check if fully qualified
        if (className.startsWith(TUPLE_PACKAGE)) {
            clazz = Class.forName(className);
        } else {
            clazz = Class.forName(TUPLE_PACKAGE + ""."" + className);
        }
        TypeInformation<?>[] types = new TypeInformation<?>[arity];
        for (int i = 0; i < arity; i++) {
            types[i] = parse(sb);
            if (types[i] == null) {
                throw new IllegalArgumentException(""Tuple arity does not match given parameters."");
            }
        }
        if (sb.charAt(0) != '>') {
            throw new IllegalArgumentException(""Tuple arity does not match given parameters."");
        }
        // remove '>'
        sb.deleteCharAt(0);
        // tuple arrays
        if (sb.length() > 0) {
            if (sb.length() >= 2 && sb.charAt(0) == '[' && sb.charAt(1) == ']') {
                Class<?> arrayClazz;
                // check if fully qualified
                if (className.startsWith(TUPLE_PACKAGE)) {
                    arrayClazz = Class.forName(""[L"" + className + "";"");
                } else {
                    arrayClazz = Class.forName(""[L"" + TUPLE_PACKAGE + ""."" + className + "";"");
                }
                returnType = ObjectArrayTypeInfo.getInfoFor(arrayClazz, new TupleTypeInfo(clazz, types));
            } else if (sb.length() < 1 || sb.charAt(0) != '[') {
                returnType = new TupleTypeInfo(clazz, types);
            }
        } else {
            returnType = new TupleTypeInfo(clazz, types);
        }
    } else // writable types
    if (writableMatcher.find()) {
        String className = writableMatcher.group(1);
        String fullyQualifiedName = writableMatcher.group(3);
        sb.delete(0, className.length() + 1 + fullyQualifiedName.length() + 1);
        Class<?> clazz = loadClass(fullyQualifiedName);
        returnType = WritableTypeInfo.getWritableTypeInfo((Class) clazz);
    } else // enum types
    if (enumMatcher.find()) {
        String className = enumMatcher.group(1);
        String fullyQualifiedName = enumMatcher.group(3);
        sb.delete(0, className.length() + 1 + fullyQualifiedName.length() + 1);
        Class<?> clazz = loadClass(fullyQualifiedName);
        returnType = new EnumTypeInfo(clazz);
    } else // basic types of classes
    if (basicTypeMatcher.find()) {
        String className = basicTypeMatcher.group(1);
        sb.delete(0, className.length());
        Class<?> clazz;
        // check if fully qualified
        if (className.startsWith(""java.lang"")) {
            clazz = Class.forName(className);
        } else {
            clazz = Class.forName(""java.lang."" + className);
        }
        returnType = BasicTypeInfo.getInfoFor(clazz);
    } else // basic type of primitives
    if (basicType2Matcher.find()) {
        String className = basicType2Matcher.group(1);
        sb.delete(0, className.length());
        Class<?> clazz = null;
        if (className.equals(""int"")) {
            clazz = Integer.class;
        } else if (className.equals(""byte"")) {
            clazz = Byte.class;
        } else if (className.equals(""short"")) {
            clazz = Short.class;
        } else if (className.equals(""char"")) {
            clazz = Character.class;
        } else if (className.equals(""double"")) {
            clazz = Double.class;
        } else if (className.equals(""float"")) {
            clazz = Float.class;
        } else if (className.equals(""long"")) {
            clazz = Long.class;
        } else if (className.equals(""boolean"")) {
            clazz = Boolean.class;
        }
        returnType = BasicTypeInfo.getInfoFor(clazz);
    } else // values
    if (valueTypeMatcher.find()) {
        String className = valueTypeMatcher.group(1);
        sb.delete(0, className.length() + 5);
        Class<?> clazz;
        // check if fully qualified
        if (className.startsWith(VALUE_PACKAGE)) {
            clazz = Class.forName(className + ""Value"");
        } else {
            clazz = Class.forName(VALUE_PACKAGE + ""."" + className + ""Value"");
        }
        returnType = ValueTypeInfo.getValueTypeInfo((Class<Value>) clazz);
    } else // array of basic classes
    if (basicArrayTypeMatcher.find()) {
        String className = basicArrayTypeMatcher.group(1);
        sb.delete(0, className.length() + 2);
        Class<?> clazz;
        if (className.startsWith(""java.lang"")) {
            clazz = Class.forName(""[L"" + className + "";"");
        } else {
            clazz = Class.forName(""[Ljava.lang."" + className + "";"");
        }
        returnType = BasicArrayTypeInfo.getInfoFor(clazz);
    } else // array of primitives
    if (basicArrayType2Matcher.find()) {
        String className = basicArrayType2Matcher.group(1);
        sb.delete(0, className.length() + 2);
        Class<?> clazz = null;
        if (className.equals(""int"")) {
            clazz = int[].class;
        } else if (className.equals(""byte"")) {
            clazz = byte[].class;
        } else if (className.equals(""short"")) {
            clazz = short[].class;
        } else if (className.equals(""char"")) {
            clazz = char[].class;
        } else if (className.equals(""double"")) {
            clazz = double[].class;
        } else if (className.equals(""float"")) {
            clazz = float[].class;
        } else if (className.equals(""long"")) {
            clazz = long[].class;
        } else if (className.equals(""boolean"")) {
            clazz = boolean[].class;
        }
        returnType = PrimitiveArrayTypeInfo.getInfoFor(clazz);
    } else // pojo objects or generic types
    if (pojoGenericMatcher.find()) {
        String fullyQualifiedName = pojoGenericMatcher.group(1);
        sb.delete(0, fullyQualifiedName.length());
        boolean isPojo = pojoGenericMatcher.group(2) != null;
        if (isPojo) {
            sb.deleteCharAt(0);
            Class<?> clazz = loadClass(fullyQualifiedName);
            ArrayList<PojoField> fields = new ArrayList<PojoField>();
            while (sb.charAt(0) != '>') {
                final Matcher fieldMatcher = fieldPattern.matcher(sb);
                if (!fieldMatcher.find()) {
                    throw new IllegalArgumentException(""Field name missing."");
                }
                String fieldName = fieldMatcher.group(1);
                sb.delete(0, fieldName.length() + 1);
                Field field = null;
                try {
                    field = clazz.getDeclaredField(fieldName);
                } catch (Exception e) {
                    throw new IllegalArgumentException(""Field '"" + fieldName + ""'could not be accessed."");
                }
                fields.add(new PojoField(field, parse(sb)));
            }
            returnType = new PojoTypeInfo(clazz, fields);
        } else {
            // custom object array
            if (fullyQualifiedName.endsWith(""[]"")) {
                fullyQualifiedName = fullyQualifiedName.substring(0, fullyQualifiedName.length() - 2);
                returnType = ObjectArrayTypeInfo.getInfoFor(loadClass(""[L"" + fullyQualifiedName + "";""));
            } else {
                returnType = new GenericTypeInfo(loadClass(fullyQualifiedName));
            }
        }
    }
    if (returnType == null) {
        throw new IllegalArgumentException(""Error at '"" + infoString + ""'"");
    } else {
        // remove possible ','
        if (sb.length() > 0 && sb.charAt(0) == ',') {
            sb.deleteCharAt(0);
        }
        return returnType;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1437_fb7ce0e3,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java,133,153,"@Override
public T copy(T from) {
    T target;
    try {
        target = clazz.newInstance();
    } catch (Throwable t) {
        throw new RuntimeException(""Cannot instantiate class."", t);
    }
    try {
        for (int i = 0; i < numFields; i++) {
            Object copy = fieldSerializers[i].copy(fields[i].get(from));
            fields[i].set(target, copy);
        }
    } catch (IllegalAccessException e) {
        throw new RuntimeException(""Error during POJO copy, this should not happen since we check the fields before."");
    }
    return target;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1437_fb7ce0e3,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java,155,167,"@Override
public T copy(T from, T reuse) {
    try {
        for (int i = 0; i < numFields; i++) {
            Object copy = fieldSerializers[i].copy(fields[i].get(from), fields[i].get(reuse));
            fields[i].set(reuse, copy);
        }
    } catch (IllegalAccessException e) {
        throw new RuntimeException(""Error during POJO copy, this should not happen since we check the fields"" + ""before."");
    }
    return reuse;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1437_fb7ce0e3,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java,255,263,"@Override
public void copy(DataInputView source, DataOutputView target) throws IOException {
    // copy the Non-Null/Null tag
    target.writeBoolean(source.readBoolean());
    for (int i = 0; i < numFields; i++) {
        target.writeBoolean(source.readBoolean());
        fieldSerializers[i].copy(source, target);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1458_91f9bfc7,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,888,898,"// --------------------------------------------------------------------------------------------
// Utility methods
// --------------------------------------------------------------------------------------------
/**
 *  @param curT : start type
 *  @return Type The immediate child of the top class
 */
private static Type getTypeHierarchy(ArrayList<Type> typeHierarchy, Type curT, Class<?> stopAtClass) {
    // skip first one
    if (typeHierarchy.size() > 0 && typeHierarchy.get(0) == curT && isClassType(curT)) {
        curT = typeToClass(curT).getGenericSuperclass();
    }
    while (!(isClassType(curT) && typeToClass(curT).equals(stopAtClass))) {
        typeHierarchy.add(curT);
        curT = typeToClass(curT).getGenericSuperclass();
    }
    return curT;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1458_91f9bfc7,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,1088,1175,"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
private <OUT, IN1, IN2> TypeInformation<OUT> privateGetForClass(Class<OUT> clazz, ArrayList<Type> typeHierarchy, ParameterizedType parameterizedType, TypeInformation<IN1> in1Type, TypeInformation<IN2> in2Type) {
    Validate.notNull(clazz);
    // check for abstract classes or interfaces
    if (!clazz.isPrimitive() && (Modifier.isInterface(clazz.getModifiers()) || (Modifier.isAbstract(clazz.getModifiers()) && !clazz.isArray()))) {
        throw new InvalidTypesException(""Interfaces and abstract classes are not valid types: "" + clazz);
    }
    if (clazz.equals(Object.class)) {
        return new GenericTypeInfo<OUT>(clazz);
    }
    // check for arrays
    if (clazz.isArray()) {
        // primitive arrays: int[], byte[], ...
        PrimitiveArrayTypeInfo<OUT> primitiveArrayInfo = PrimitiveArrayTypeInfo.getInfoFor(clazz);
        if (primitiveArrayInfo != null) {
            return primitiveArrayInfo;
        }
        // basic type arrays: String[], Integer[], Double[]
        BasicArrayTypeInfo<OUT, ?> basicArrayInfo = BasicArrayTypeInfo.getInfoFor(clazz);
        if (basicArrayInfo != null) {
            return basicArrayInfo;
        } else // object arrays
        {
            return ObjectArrayTypeInfo.getInfoFor(clazz);
        }
    }
    // check for writable types
    if (Writable.class.isAssignableFrom(clazz)) {
        return (TypeInformation<OUT>) WritableTypeInfo.getWritableTypeInfo((Class<? extends Writable>) clazz);
    }
    // check for basic types
    TypeInformation<OUT> basicTypeInfo = BasicTypeInfo.getInfoFor(clazz);
    if (basicTypeInfo != null) {
        return basicTypeInfo;
    }
    // check for subclasses of Value
    if (Value.class.isAssignableFrom(clazz)) {
        Class<? extends Value> valueClass = clazz.asSubclass(Value.class);
        return (TypeInformation<OUT>) ValueTypeInfo.getValueTypeInfo(valueClass);
    }
    // check for subclasses of Tuple
    if (Tuple.class.isAssignableFrom(clazz)) {
        throw new InvalidTypesException(""Type information extraction for tuples cannot be done based on the class."");
    }
    // check for Enums
    if (Enum.class.isAssignableFrom(clazz)) {
        return (TypeInformation<OUT>) new EnumTypeInfo(clazz);
    }
    if (alreadySeen.contains(clazz)) {
        return new GenericTypeInfo<OUT>(clazz);
    }
    alreadySeen.add(clazz);
    if (clazz.equals(Class.class)) {
        // special case handling for Class, this should not be handled by the POJO logic
        return new GenericTypeInfo<OUT>(clazz);
    }
    try {
        TypeInformation<OUT> pojoType = analyzePojo(clazz, new ArrayList<Type>(typeHierarchy), parameterizedType, in1Type, in2Type);
        if (pojoType != null) {
            return pojoType;
        }
    } catch (InvalidTypesException e) {
        if (LOG.isDebugEnabled()) {
            LOG.debug(""Unable to handle type "" + clazz + "" as POJO. Message: "" + e.getMessage(), e);
        }
    // ignore and create generic type info
    }
    // return a generic type
    return new GenericTypeInfo<OUT>(clazz);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1458_91f9bfc7,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,1187,1239,"/**
 *  Checks if the given field is a valid pojo field:
 *  - it is public
 *  OR
 *   - there are getter and setter methods for the field.
 *
 *  @param f field to check
 *  @param clazz class of field
 *  @param typeHierarchy type hierarchy for materializing generic types
 */
private boolean isValidPojoField(Field f, Class<?> clazz, ArrayList<Type> typeHierarchy) {
    if (Modifier.isPublic(f.getModifiers())) {
        return true;
    } else {
        boolean hasGetter = false, hasSetter = false;
        final String fieldNameLow = f.getName().toLowerCase();
        Type fieldType = f.getGenericType();
        TypeVariable<?> fieldTypeGeneric = null;
        if (fieldType instanceof TypeVariable) {
            fieldTypeGeneric = (TypeVariable<?>) fieldType;
            fieldType = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) fieldType);
        }
        for (Method m : clazz.getMethods()) {
            // check for getter
            if (// The name should be ""get<FieldName>"" or ""<fieldName>"" (for scala) or ""is<fieldName>"" for boolean fields.
            (m.getName().toLowerCase().equals(""get"" + fieldNameLow) || m.getName().toLowerCase().equals(""is"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow)) && // no arguments for the getter
            m.getParameterTypes().length == 0 && // return type is same as field type (or the generic variant of it)
            (m.getGenericReturnType().equals(fieldType) || (fieldTypeGeneric != null && m.getGenericReturnType().equals(fieldTypeGeneric)))) {
                if (hasGetter) {
                    throw new IllegalStateException(""Detected more than one getter"");
                }
                hasGetter = true;
            }
            // check for setters (<FieldName>_$eq for scala)
            if ((m.getName().toLowerCase().equals(""set"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow + ""_$eq"")) && // one parameter of the field's type
            m.getParameterTypes().length == 1 && (m.getGenericParameterTypes()[0].equals(fieldType) || (fieldTypeGeneric != null && m.getGenericParameterTypes()[0].equals(fieldTypeGeneric))) && // return type is void.
            m.getReturnType().equals(Void.TYPE)) {
                if (hasSetter) {
                    throw new IllegalStateException(""Detected more than one setter"");
                }
                hasSetter = true;
            }
        }
        if (hasGetter && hasSetter) {
            return true;
        } else {
            if (!hasGetter) {
                LOG.warn(""Class "" + clazz + "" does not contain a getter for field "" + f.getName());
            }
            if (!hasSetter) {
                LOG.warn(""Class "" + clazz + "" does not contain a setter for field "" + f.getName());
            }
            return false;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1458_91f9bfc7,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,1241,1300,"@SuppressWarnings(""unchecked"")
private <OUT, IN1, IN2> TypeInformation<OUT> analyzePojo(Class<OUT> clazz, ArrayList<Type> typeHierarchy, ParameterizedType parameterizedType, TypeInformation<IN1> in1Type, TypeInformation<IN2> in2Type) {
    // add the hierarchy of the POJO itself if it is generic
    if (parameterizedType != null) {
        getTypeHierarchy(typeHierarchy, parameterizedType, Object.class);
    } else // create a type hierarchy, if the incoming only contains the most bottom one or none.
    if (typeHierarchy.size() <= 1) {
        getTypeHierarchy(typeHierarchy, clazz, Object.class);
    }
    List<Field> fields = getAllDeclaredFields(clazz);
    List<PojoField> pojoFields = new ArrayList<PojoField>();
    for (Field field : fields) {
        Type fieldType = field.getGenericType();
        if (!isValidPojoField(field, clazz, typeHierarchy)) {
            LOG.warn(""Class "" + clazz + "" is not a valid POJO type"");
            return null;
        }
        try {
            ArrayList<Type> fieldTypeHierarchy = new ArrayList<Type>(typeHierarchy);
            fieldTypeHierarchy.add(fieldType);
            TypeInformation<?> ti = createTypeInfoWithTypeHierarchy(fieldTypeHierarchy, fieldType, in1Type, in2Type);
            pojoFields.add(new PojoField(field, ti));
        } catch (InvalidTypesException e) {
            Class<?> genericClass = Object.class;
            if (isClassType(fieldType)) {
                genericClass = typeToClass(fieldType);
            }
            pojoFields.add(new PojoField(field, new GenericTypeInfo<OUT>((Class<OUT>) genericClass)));
        }
    }
    CompositeType<OUT> pojoType = new PojoTypeInfo<OUT>(clazz, pojoFields);
    // 
    // Validate the correctness of the pojo.
    // returning ""null"" will result create a generic type information.
    // 
    List<Method> methods = getAllDeclaredMethods(clazz);
    for (Method method : methods) {
        if (method.getName().equals(""readObject"") || method.getName().equals(""writeObject"")) {
            LOG.warn(""Class "" + clazz + "" contains custom serialization methods we do not call."");
            return null;
        }
    }
    // we cannot use this because the serializer uses it.
    try {
        clazz.getDeclaredConstructor();
    } catch (NoSuchMethodException e) {
        LOG.warn(""Class "" + clazz + "" must have a default constructor to be used as a POJO."");
        return null;
    }
    // everything is checked, we return the pojo
    return pojoType;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1471_d033fa8f,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,683,691,"private static void validateInputType(Class<?> baseClass, Class<?> clazz, int inputParamPos, TypeInformation<?> inType) {
    ArrayList<Type> typeHierarchy = new ArrayList<Type>();
    try {
        validateInfo(typeHierarchy, getParameterType(baseClass, typeHierarchy, clazz, inputParamPos), inType);
    } catch (InvalidTypesException e) {
        throw new InvalidTypesException(""Input mismatch: "" + e.getMessage());
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1496_0a4c7694,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/BufferReader.java,153,155,"// TODO This is a work-around for the union reader
boolean hasInputChannelWithData() {
    return !inputChannelsWithData.isEmpty();
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1496_0a4c7694,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/BufferReader.java,163,165,"/**
 *  Returns the total number of input channels for this reader.
 *  <p>
 *  Note: This number might be smaller the current number of input channels
 *  of the reader as channels are possibly updated during runtime.
 */
public int getNumberOfInputChannels() {
    return totalNumberOfInputChannels;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1496_0a4c7694,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/BufferReader.java,171,175,"public void setInputChannel(IntermediateResultPartitionID partitionId, InputChannel inputChannel) {
    synchronized (requestLock) {
        inputChannels.put(checkNotNull(partitionId), checkNotNull(inputChannel));
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1496_0a4c7694,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/BufferReader.java,177,208,"public void updateInputChannel(PartitionInfo partitionInfo) throws IOException {
    synchronized (requestLock) {
        if (isReleased) {
            // There was a race with a task failure/cancel
            return;
        }
        final IntermediateResultPartitionID partitionId = partitionInfo.getPartitionId();
        InputChannel current = inputChannels.get(partitionId);
        if (current.getClass() == UnknownInputChannel.class) {
            UnknownInputChannel unknownChannel = (UnknownInputChannel) current;
            InputChannel newChannel;
            if (partitionInfo.getProducerLocation() == PartitionLocation.REMOTE) {
                newChannel = unknownChannel.toRemoteInputChannel(partitionInfo.getProducerAddress());
            } else if (partitionInfo.getProducerLocation() == PartitionLocation.LOCAL) {
                newChannel = unknownChannel.toLocalInputChannel();
            } else {
                throw new IllegalStateException(""Tried to update unknown channel with unknown channel."");
            }
            inputChannels.put(partitionId, newChannel);
            newChannel.requestIntermediateResultPartition(queueToRequest);
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1496_0a4c7694,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/api/reader/BufferReader.java,382,391,"// ------------------------------------------------------------------------
// Task events
// ------------------------------------------------------------------------
@Override
public void sendTaskEvent(TaskEvent event) throws IOException, InterruptedException {
    // remote input channels.
    synchronized (requestLock) {
        for (InputChannel inputChannel : inputChannels.values()) {
            inputChannel.sendTaskEvent(event);
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1531_21f47d9c,Minor,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/KryoSerializer.java,189,199,"@SuppressWarnings(""unchecked"")
@Override
public T deserialize(DataInputView source) throws IOException {
    checkKryoInitialized();
    if (source != previousIn) {
        DataInputViewStream inputStream = new DataInputViewStream(source);
        input = new NoFetchingInput(inputStream);
        previousIn = source;
    }
    return (T) kryo.readClassAndObject(input);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1531_21f47d9c,Minor,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/NoFetchingInput.java,62,86,"/**
 *  Require makes sure that at least required number of bytes are kept in the buffer. If not, then
 *  it will load exactly the difference between required and currently available number of bytes.
 *  Thus, it will only load the data which is required and never prefetch data.
 *
 *  @param required the number of bytes being available in the buffer
 *  @return the number of bytes remaining, which is equal to required
 *  @throws KryoException
 */
@Override
protected int require(int required) throws KryoException {
    if (required > capacity) {
        throw new KryoException(""Buffer too small: capacity: "" + capacity + "", "" + ""required: "" + required);
    }
    position = 0;
    int bytesRead = 0;
    int count;
    while (true) {
        count = fill(buffer, bytesRead, required - bytesRead);
        if (count == -1) {
            throw new KryoException(""Buffer underflow"");
        }
        bytesRead += count;
        if (bytesRead == required) {
            break;
        }
    }
    limit = required;
    return required;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1531_21f47d9c,Minor,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/NoFetchingInput.java,110,136,"@Override
public void readBytes(byte[] bytes, int offset, int count) throws KryoException {
    if (bytes == null) {
        throw new IllegalArgumentException(""bytes cannot be null."");
    }
    try {
        int bytesRead = 0;
        int c;
        while (true) {
            c = inputStream.read(bytes, offset + bytesRead, count - bytesRead);
            if (c == -1) {
                throw new KryoException(""Buffer underflow"");
            }
            bytesRead += c;
            if (bytesRead == count) {
                break;
            }
        }
    } catch (IOException ex) {
        throw new KryoException(ex);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1640_8f321c72,Major,flink-core/src/main/java/org/apache/flink/core/fs/Path.java,152,160,"/**
 *  Checks if the provided path string is either null or has zero length and throws
 *  a {@link IllegalArgumentException} if any of the two conditions apply.
 *
 *  @param path
 *         the path string to be checked
 */
private void checkPathArg(String path) {
    // disallow construction of a Path from an empty string
    if (path == null) {
        throw new IllegalArgumentException(""Can not create a Path from a null string"");
    }
    if (path.length() == 0) {
        throw new IllegalArgumentException(""Can not create a Path from an empty string"");
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1640_8f321c72,Major,flink-core/src/main/java/org/apache/flink/core/fs/Path.java,249,255,"/**
 *  Normalizes a path string.
 *
 *  @param path
 *         the path string to normalize
 *  @return the normalized path string
 */
private String normalizePath(String path) {
    // remove double slashes & backslashes
    path = path.replace(""//"", ""/"");
    path = path.replace(""\\"", ""/"");
    return path;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1640_8f321c72,Major,flink-core/src/main/java/org/apache/flink/core/fs/Path.java,313,322,"/**
 *  Returns the final component of this path.
 *
 *  @return the final component of the path
 */
public String getName() {
    final String path = uri.getPath();
    if (path.endsWith(SEPARATOR)) {
        final int slash = path.lastIndexOf(SEPARATOR, path.length() - SEPARATOR.length() - 1);
        return path.substring(slash + 1, path.length() - SEPARATOR.length());
    } else {
        final int slash = path.lastIndexOf(SEPARATOR);
        return path.substring(slash + 1);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1640_8f321c72,Major,flink-core/src/main/java/org/apache/flink/core/fs/Path.java,329,345,"/**
 *  Returns the parent of a path or <code>null</code> if at root.
 *
 *  @return the parent of a path or <code>null</code> if at root.
 */
public Path getParent() {
    final String path = uri.getPath();
    final int lastSlash = path.lastIndexOf('/');
    final int start = hasWindowsDrive(path, true) ? 3 : 0;
    if (// empty path
    (path.length() == start) || (lastSlash == start && path.length() == start + 1)) {
        // at root
        return null;
    }
    String parent;
    if (lastSlash == -1) {
        parent = CUR_DIR;
    } else {
        final int end = hasWindowsDrive(path, true) ? 3 : 0;
        parent = path.substring(0, lastSlash == end ? end + 1 : lastSlash);
    }
    return new Path(uri.getScheme(), uri.getAuthority(), parent);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1686_1f726e48,Critical,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/streamvertex/StreamIterationTail.java,44,58,"@Override
public void setInputsOutputs() {
    try {
        inputHandler = new InputHandler<IN>(this);
        iterationId = configuration.getIterationId();
        iterationWaitTime = configuration.getIterationWaitTime();
        shouldWait = iterationWaitTime > 0;
        BlockingQueueBroker.instance().get(iterationId.toString() + ""-"" + getEnvironment().getIndexInSubtaskGroup());
    } catch (Exception e) {
        throw new StreamVertexException(String.format(""Cannot register inputs of StreamIterationSink %s"", iterationId), e);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1705_5308ac83,Major,flink-runtime/src/main/java/org/apache/flink/runtime/instance/InstanceConnectionInfo.java,134,136,"/**
 *  Returns the host name of the instance. If the host name could not be determined, the return value will be a
 *  textual representation of the instance's IP address.
 *
 *  @return the host name of the instance
 */
public String getFQDNHostname() {
    return this.fqdnHostName;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1705_5308ac83,Major,flink-runtime/src/main/java/org/apache/flink/runtime/instance/InstanceConnectionInfo.java,138,148,"public String getHostname() {
    if (hostName == null) {
        String fqdn = getFQDNHostname();
        if (this.fqdnHostNameIsIP) {
            // fqdn to hostname translation is pointless if FQDN is an ip address.
            hostName = fqdn;
        } else {
            hostName = NetUtils.getHostnameFromFQDN(fqdn);
        }
    }
    return hostName;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1705_5308ac83,Major,flink-runtime/src/main/java/org/apache/flink/runtime/instance/InstanceConnectionInfo.java,150,152,"public String getInetAdress() {
    return this.inetAddress.toString();
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1705_5308ac83,Major,flink-runtime/src/main/java/org/apache/flink/runtime/instance/InstanceConnectionInfo.java,158,176,"// --------------------------------------------------------------------------------------------
// Serialization
// --------------------------------------------------------------------------------------------
@Override
public void read(DataInputView in) throws IOException {
    final int addr_length = in.readInt();
    byte[] address = new byte[addr_length];
    in.readFully(address);
    this.dataPort = in.readInt();
    this.fqdnHostName = StringUtils.readNullableString(in);
    this.hostName = StringUtils.readNullableString(in);
    this.fqdnHostNameIsIP = in.readBoolean();
    try {
        this.inetAddress = InetAddress.getByAddress(address);
    } catch (UnknownHostException e) {
        throw new IOException(""This lookup should never fail."", e);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1705_5308ac83,Major,flink-runtime/src/main/java/org/apache/flink/runtime/instance/InstanceConnectionInfo.java,179,189,"@Override
public void write(final DataOutputView out) throws IOException {
    out.writeInt(this.inetAddress.getAddress().length);
    out.write(this.inetAddress.getAddress());
    out.writeInt(this.dataPort);
    StringUtils.writeNullableString(fqdnHostName, out);
    StringUtils.writeNullableString(hostName, out);
    out.writeBoolean(fqdnHostNameIsIP);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1761_380ef878,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestClientHandler.java,129,138,"private void notifyAllChannelsOfErrorAndClose(Throwable cause) {
    if (channelError.compareAndSet(false, true)) {
        for (RemoteInputChannel inputChannel : inputChannels.values()) {
            inputChannel.onError(cause);
        }
        inputChannels.clear();
        ctx.close();
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1761_380ef878,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/netty/PartitionRequestClientHandler.java,184,236,"private boolean decodeBufferOrEvent(RemoteInputChannel inputChannel, NettyMessage.BufferResponse bufferOrEvent) throws Throwable {
    boolean releaseNettyBuffer = true;
    try {
        if (bufferOrEvent.isBuffer()) {
            // ---- Buffer ------------------------------------------------
            BufferProvider bufferProvider = inputChannel.getBufferProvider();
            if (bufferProvider == null) {
                // receiver has been cancelled/failed
                return false;
            }
            while (true) {
                Buffer buffer = bufferProvider.requestBuffer();
                if (buffer != null) {
                    buffer.setSize(bufferOrEvent.getSize());
                    bufferOrEvent.getNettyBuffer().readBytes(buffer.getNioBuffer());
                    inputChannel.onBuffer(buffer, bufferOrEvent.sequenceNumber);
                    return true;
                } else if (bufferListener.waitForBuffer(bufferProvider, bufferOrEvent)) {
                    releaseNettyBuffer = false;
                    return false;
                } else if (bufferProvider.isDestroyed()) {
                    return false;
                }
            }
        } else {
            // ---- Event -------------------------------------------------
            // TODO We can just keep the serialized data in the Netty buffer and release it later at the reader
            byte[] byteArray = new byte[bufferOrEvent.getSize()];
            bufferOrEvent.getNettyBuffer().readBytes(byteArray);
            Buffer buffer = new Buffer(new MemorySegment(byteArray), EventSerializer.RECYCLER, false);
            inputChannel.onBuffer(buffer, bufferOrEvent.sequenceNumber);
            return true;
        }
    } finally {
        if (releaseNettyBuffer) {
            bufferOrEvent.releaseBuffer();
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/ByteParser.java,27,65,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, Byte reusable) {
    int val = 0;
    boolean neg = false;
    final int delimLimit = limit - delimiter.length + 1;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        // check for empty field with only the sign
        if (startPos == limit || (startPos < delimLimit && delimiterNext(bytes, startPos, delimiter))) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ORPHAN_SIGN);
            return -1;
        }
    }
    for (int i = startPos; i < limit; i++) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            this.result = (byte) (neg ? -val : val);
            return i + delimiter.length;
        }
        if (bytes[i] < 48 || bytes[i] > 57) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ILLEGAL_CHARACTER);
            return -1;
        }
        val *= 10;
        val += bytes[i] - 48;
        if (val > Byte.MAX_VALUE && (!neg || val > -Byte.MIN_VALUE)) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
            return -1;
        }
    }
    this.result = (byte) (neg ? -val : val);
    return limit;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/ByteParser.java,89,91,"/**
 *  Static utility to parse a field of type byte from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final byte parseField(byte[] bytes, int startPos, int length) {
    return parseField(bytes, startPos, length, (char) 0xffff);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/ByteParser.java,106,137,"/**
 *  Static utility to parse a field of type byte from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *  @param delimiter The delimiter that terminates the field.
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final byte parseField(byte[] bytes, int startPos, int length, char delimiter) {
    if (length <= 0) {
        throw new NumberFormatException(""Invalid input: Empty string"");
    }
    long val = 0;
    boolean neg = false;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        length--;
        if (length == 0 || bytes[startPos] == delimiter) {
            throw new NumberFormatException(""Orphaned minus sign."");
        }
    }
    for (; length > 0; startPos++, length--) {
        if (bytes[startPos] == delimiter) {
            return (byte) (neg ? -val : val);
        }
        if (bytes[startPos] < 48 || bytes[startPos] > 57) {
            throw new NumberFormatException(""Invalid character."");
        }
        val *= 10;
        val += bytes[startPos] - 48;
        if (val > Byte.MAX_VALUE && (!neg || val > -Byte.MIN_VALUE)) {
            throw new NumberFormatException(""Value overflow/underflow"");
        }
    }
    return (byte) (neg ? -val : val);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/ByteValueParser.java,32,73,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, ByteValue reusable) {
    int val = 0;
    boolean neg = false;
    this.result = reusable;
    final int delimLimit = limit - delimiter.length + 1;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        // check for empty field with only the sign
        if (startPos == limit || (startPos < delimLimit && delimiterNext(bytes, startPos, delimiter))) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ORPHAN_SIGN);
            return -1;
        }
    }
    for (int i = startPos; i < limit; i++) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            reusable.setValue((byte) (neg ? -val : val));
            return i + delimiter.length;
        }
        if (bytes[i] < 48 || bytes[i] > 57) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ILLEGAL_CHARACTER);
            return -1;
        }
        val *= 10;
        val += bytes[i] - 48;
        if (val > Byte.MAX_VALUE && (!neg || val > -Byte.MIN_VALUE)) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
            return -1;
        }
    }
    reusable.setValue((byte) (neg ? -val : val));
    return limit;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/DoubleParser.java,31,53,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, Double reusable) {
    int i = startPos;
    final int delimLimit = limit - delimiter.length + 1;
    while (i < limit) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            break;
        }
        i++;
    }
    String str = new String(bytes, startPos, i - startPos);
    try {
        this.result = Double.parseDouble(str);
        return (i == limit) ? limit : i + delimiter.length;
    } catch (NumberFormatException e) {
        setErrorState(ParseErrorState.NUMERIC_VALUE_FORMAT_ERROR);
        return -1;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/DoubleParser.java,77,79,"/**
 *  Static utility to parse a field of type double from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final double parseField(byte[] bytes, int startPos, int length) {
    return parseField(bytes, startPos, length, (char) 0xffff);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/DoubleParser.java,94,107,"/**
 *  Static utility to parse a field of type double from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *  @param delimiter The delimiter that terminates the field.
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final double parseField(byte[] bytes, int startPos, int length, char delimiter) {
    if (length <= 0) {
        throw new NumberFormatException(""Invalid input: Empty string"");
    }
    int i = 0;
    final byte delByte = (byte) delimiter;
    while (i < length && bytes[i] != delByte) {
        i++;
    }
    String str = new String(bytes, startPos, i);
    return Double.parseDouble(str);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/DoubleValueParser.java,31,56,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, DoubleValue reusable) {
    int i = startPos;
    final int delimLimit = limit - delimiter.length + 1;
    while (i < limit) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            break;
        }
        i++;
    }
    String str = new String(bytes, startPos, i - startPos);
    try {
        double value = Double.parseDouble(str);
        reusable.setValue(value);
        this.result = reusable;
        return (i == limit) ? limit : i + delimiter.length;
    } catch (NumberFormatException e) {
        setErrorState(ParseErrorState.NUMERIC_VALUE_FORMAT_ERROR);
        return -1;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/FloatParser.java,29,52,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, Float reusable) {
    int i = startPos;
    final int delimLimit = limit - delimiter.length + 1;
    while (i < limit) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            break;
        }
        i++;
    }
    String str = new String(bytes, startPos, i - startPos);
    try {
        this.result = Float.parseFloat(str);
        return (i == limit) ? limit : i + delimiter.length;
    } catch (NumberFormatException e) {
        setErrorState(ParseErrorState.NUMERIC_VALUE_FORMAT_ERROR);
        return -1;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/FloatParser.java,76,78,"/**
 *  Static utility to parse a field of type float from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final float parseField(byte[] bytes, int startPos, int length) {
    return parseField(bytes, startPos, length, (char) 0xffff);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/FloatParser.java,93,106,"/**
 *  Static utility to parse a field of type float from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *  @param delimiter The delimiter that terminates the field.
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final float parseField(byte[] bytes, int startPos, int length, char delimiter) {
    if (length <= 0) {
        throw new NumberFormatException(""Invalid input: Empty string"");
    }
    int i = 0;
    final byte delByte = (byte) delimiter;
    while (i < length && bytes[i] != delByte) {
        i++;
    }
    String str = new String(bytes, startPos, i);
    return Float.parseFloat(str);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/FloatValueParser.java,31,56,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, FloatValue reusable) {
    int i = startPos;
    final int delimLimit = limit - delimiter.length + 1;
    while (i < limit) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            break;
        }
        i++;
    }
    String str = new String(bytes, startPos, i - startPos);
    try {
        float value = Float.parseFloat(str);
        reusable.setValue(value);
        this.result = reusable;
        return (i == limit) ? limit : i + delimiter.length;
    } catch (NumberFormatException e) {
        setErrorState(ParseErrorState.NUMERIC_VALUE_FORMAT_ERROR);
        return -1;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/IntParser.java,34,72,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, Integer reusable) {
    long val = 0;
    boolean neg = false;
    final int delimLimit = limit - delimiter.length + 1;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        // check for empty field with only the sign
        if (startPos == limit || (startPos < delimLimit && delimiterNext(bytes, startPos, delimiter))) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ORPHAN_SIGN);
            return -1;
        }
    }
    for (int i = startPos; i < limit; i++) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            this.result = (int) (neg ? -val : val);
            return i + delimiter.length;
        }
        if (bytes[i] < 48 || bytes[i] > 57) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ILLEGAL_CHARACTER);
            return -1;
        }
        val *= 10;
        val += bytes[i] - 48;
        if (val > OVERFLOW_BOUND && (!neg || val > UNDERFLOW_BOUND)) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
            return -1;
        }
    }
    this.result = (int) (neg ? -val : val);
    return limit;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/IntParser.java,96,98,"/**
 *  Static utility to parse a field of type int from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final int parseField(byte[] bytes, int startPos, int length) {
    return parseField(bytes, startPos, length, (char) 0xffff);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/IntParser.java,113,144,"/**
 *  Static utility to parse a field of type int from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *  @param delimiter The delimiter that terminates the field.
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final int parseField(byte[] bytes, int startPos, int length, char delimiter) {
    if (length <= 0) {
        throw new NumberFormatException(""Invalid input: Empty string"");
    }
    long val = 0;
    boolean neg = false;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        length--;
        if (length == 0 || bytes[startPos] == delimiter) {
            throw new NumberFormatException(""Orphaned minus sign."");
        }
    }
    for (; length > 0; startPos++, length--) {
        if (bytes[startPos] == delimiter) {
            return (int) (neg ? -val : val);
        }
        if (bytes[startPos] < 48 || bytes[startPos] > 57) {
            throw new NumberFormatException(""Invalid character."");
        }
        val *= 10;
        val += bytes[startPos] - 48;
        if (val > OVERFLOW_BOUND && (!neg || val > UNDERFLOW_BOUND)) {
            throw new NumberFormatException(""Value overflow/underflow"");
        }
    }
    return (int) (neg ? -val : val);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/IntValueParser.java,35,75,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, IntValue reusable) {
    long val = 0;
    boolean neg = false;
    final int delimLimit = limit - delimiter.length + 1;
    this.result = reusable;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        // check for empty field with only the sign
        if (startPos == limit || (startPos < delimLimit && delimiterNext(bytes, startPos, delimiter))) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ORPHAN_SIGN);
            return -1;
        }
    }
    for (int i = startPos; i < limit; i++) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            reusable.setValue((int) (neg ? -val : val));
            return i + delimiter.length;
        }
        if (bytes[i] < 48 || bytes[i] > 57) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ILLEGAL_CHARACTER);
            return -1;
        }
        val *= 10;
        val += bytes[i] - 48;
        if (val > OVERFLOW_BOUND && (!neg || val > UNDERFLOW_BOUND)) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
            return -1;
        }
    }
    reusable.setValue((int) (neg ? -val : val));
    return limit;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/LongParser.java,30,84,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, Long reusable) {
    long val = 0;
    boolean neg = false;
    final int delimLimit = limit - delimiter.length + 1;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        // check for empty field with only the sign
        if (startPos == limit || (startPos < delimLimit && delimiterNext(bytes, startPos, delimiter))) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ORPHAN_SIGN);
            return -1;
        }
    }
    for (int i = startPos; i < limit; i++) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            this.result = neg ? -val : val;
            return i + delimiter.length;
        }
        if (bytes[i] < 48 || bytes[i] > 57) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ILLEGAL_CHARACTER);
            return -1;
        }
        val *= 10;
        val += bytes[i] - 48;
        // check for overflow / underflow
        if (val < 0) {
            // this is an overflow/underflow, unless we hit exactly the Long.MIN_VALUE
            if (neg && val == Long.MIN_VALUE) {
                this.result = Long.MIN_VALUE;
                if (i + 1 >= limit) {
                    return limit;
                } else if (i + 1 < delimLimit && delimiterNext(bytes, i + 1, delimiter)) {
                    return i + 1 + delimiter.length;
                } else {
                    setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
                    return -1;
                }
            } else {
                setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
                return -1;
            }
        }
    }
    this.result = neg ? -val : val;
    return limit;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/LongParser.java,108,110,"/**
 *  Static utility to parse a field of type long from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final long parseField(byte[] bytes, int startPos, int length) {
    return parseField(bytes, startPos, length, (char) 0xffff);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/LongParser.java,125,167,"/**
 *  Static utility to parse a field of type long from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *  @param delimiter The delimiter that terminates the field.
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final long parseField(byte[] bytes, int startPos, int length, char delimiter) {
    if (length <= 0) {
        throw new NumberFormatException(""Invalid input: Empty string"");
    }
    long val = 0;
    boolean neg = false;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        length--;
        if (length == 0 || bytes[startPos] == delimiter) {
            throw new NumberFormatException(""Orphaned minus sign."");
        }
    }
    for (; length > 0; startPos++, length--) {
        if (bytes[startPos] == delimiter) {
            return neg ? -val : val;
        }
        if (bytes[startPos] < 48 || bytes[startPos] > 57) {
            throw new NumberFormatException(""Invalid character."");
        }
        val *= 10;
        val += bytes[startPos] - 48;
        // check for overflow / underflow
        if (val < 0) {
            // this is an overflow/underflow, unless we hit exactly the Long.MIN_VALUE
            if (neg && val == Long.MIN_VALUE) {
                if (length == 1 || bytes[startPos + 1] == delimiter) {
                    return Long.MIN_VALUE;
                } else {
                    throw new NumberFormatException(""value overflow"");
                }
            } else {
                throw new NumberFormatException(""value overflow"");
            }
        }
    }
    return neg ? -val : val;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/LongValueParser.java,32,88,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, LongValue reusable) {
    long val = 0;
    boolean neg = false;
    final int delimLimit = limit - delimiter.length + 1;
    this.result = reusable;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        // check for empty field with only the sign
        if (startPos == limit || (startPos < delimLimit && delimiterNext(bytes, startPos, delimiter))) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ORPHAN_SIGN);
            return -1;
        }
    }
    for (int i = startPos; i < limit; i++) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            reusable.setValue(neg ? -val : val);
            return i + delimiter.length;
        }
        if (bytes[i] < 48 || bytes[i] > 57) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ILLEGAL_CHARACTER);
            return -1;
        }
        val *= 10;
        val += bytes[i] - 48;
        // check for overflow / underflow
        if (val < 0) {
            // this is an overflow/underflow, unless we hit exactly the Long.MIN_VALUE
            if (neg && val == Long.MIN_VALUE) {
                reusable.setValue(Long.MIN_VALUE);
                if (i + 1 >= limit) {
                    return limit;
                } else if (i + 1 < delimLimit && delimiterNext(bytes, i + 1, delimiter)) {
                    return i + 1 + delimiter.length;
                } else {
                    setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
                    return -1;
                }
            } else {
                setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
                return -1;
            }
        }
    }
    reusable.setValue(neg ? -val : val);
    return limit;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/ShortParser.java,34,72,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, Short reusable) {
    int val = 0;
    boolean neg = false;
    final int delimLimit = limit - delimiter.length + 1;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        // check for empty field with only the sign
        if (startPos == limit || (startPos < delimLimit && delimiterNext(bytes, startPos, delimiter))) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ORPHAN_SIGN);
            return -1;
        }
    }
    for (int i = startPos; i < limit; i++) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            this.result = (short) (neg ? -val : val);
            return i + delimiter.length;
        }
        if (bytes[i] < 48 || bytes[i] > 57) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ILLEGAL_CHARACTER);
            return -1;
        }
        val *= 10;
        val += bytes[i] - 48;
        if (val > OVERFLOW_BOUND && (!neg || val > UNDERFLOW_BOUND)) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
            return -1;
        }
    }
    this.result = (short) (neg ? -val : val);
    return limit;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/ShortParser.java,96,98,"/**
 *  Static utility to parse a field of type short from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final short parseField(byte[] bytes, int startPos, int length) {
    return parseField(bytes, startPos, length, (char) 0xffff);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/ShortParser.java,113,144,"/**
 *  Static utility to parse a field of type short from a byte sequence that represents text characters
 *  (such as when read from a file stream).
 *
 *  @param bytes The bytes containing the text data that should be parsed.
 *  @param startPos The offset to start the parsing.
 *  @param length The length of the byte sequence (counting from the offset).
 *  @param delimiter The delimiter that terminates the field.
 *
 *  @return The parsed value.
 *
 *  @throws NumberFormatException Thrown when the value cannot be parsed because the text represents not a correct number.
 */
public static final short parseField(byte[] bytes, int startPos, int length, char delimiter) {
    if (length <= 0) {
        throw new NumberFormatException(""Invalid input: Empty string"");
    }
    long val = 0;
    boolean neg = false;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        length--;
        if (length == 0 || bytes[startPos] == delimiter) {
            throw new NumberFormatException(""Orphaned minus sign."");
        }
    }
    for (; length > 0; startPos++, length--) {
        if (bytes[startPos] == delimiter) {
            return (short) (neg ? -val : val);
        }
        if (bytes[startPos] < 48 || bytes[startPos] > 57) {
            throw new NumberFormatException(""Invalid character."");
        }
        val *= 10;
        val += bytes[startPos] - 48;
        if (val > OVERFLOW_BOUND && (!neg || val > UNDERFLOW_BOUND)) {
            throw new NumberFormatException(""Value overflow/underflow"");
        }
    }
    return (short) (neg ? -val : val);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1820_39d526e6,Critical,flink-core/src/main/java/org/apache/flink/types/parser/ShortValueParser.java,35,75,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, ShortValue reusable) {
    int val = 0;
    boolean neg = false;
    final int delimLimit = limit - delimiter.length + 1;
    this.result = reusable;
    if (bytes[startPos] == '-') {
        neg = true;
        startPos++;
        // check for empty field with only the sign
        if (startPos == limit || (startPos < delimLimit && delimiterNext(bytes, startPos, delimiter))) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ORPHAN_SIGN);
            return -1;
        }
    }
    for (int i = startPos; i < limit; i++) {
        if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
            reusable.setValue((short) (neg ? -val : val));
            return i + delimiter.length;
        }
        if (bytes[i] < 48 || bytes[i] > 57) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_ILLEGAL_CHARACTER);
            return -1;
        }
        val *= 10;
        val += bytes[i] - 48;
        if (val > OVERFLOW_BOUND && (!neg || val > UNDERFLOW_BOUND)) {
            setErrorState(ParseErrorState.NUMERIC_VALUE_OVERFLOW_UNDERFLOW);
            return -1;
        }
    }
    reusable.setValue((short) (neg ? -val : val));
    return limit;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1848_7164b2b6,Critical,flink-core/src/main/java/org/apache/flink/core/fs/Path.java,253,268,"/**
 *  Normalizes a path string.
 *
 *  @param path
 *         the path string to normalize
 *  @return the normalized path string
 */
private String normalizePath(String path) {
    // remove leading and tailing whitespaces
    path = path.trim();
    // remove consecutive slashes & backslashes
    path = path.replace(""\\"", ""/"");
    path = path.replaceAll(""/+"", ""/"");
    // remove tailing separator
    if (!path.equals(SEPARATOR) && path.endsWith(SEPARATOR)) {
        path = path.substring(0, path.length() - SEPARATOR.length());
    }
    return path;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1848_7164b2b6,Critical,flink-core/src/main/java/org/apache/flink/core/fs/local/LocalFileSystem.java,229,234,"/**
 *  Recursively creates the directory specified by the provided path.
 *
 *  @return <code>true</code>if the directories either already existed or have been created successfully,
 *          <code>false</code> otherwise
 *  @throws IOException
 *          thrown if an error occurred while creating the directory/directories
 */
public boolean mkdirs(final Path f) throws IOException {
    final Path parent = f.getParent();
    final File p2f = pathToFile(f);
    return (parent == null || mkdirs(parent)) && (p2f.mkdir() || p2f.isDirectory());
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1922_ccd574a4,Major,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java,283,377,"public void deployToSlot(final SimpleSlot slot) throws JobException {
    // sanity checks
    if (slot == null) {
        throw new NullPointerException();
    }
    if (!slot.isAlive()) {
        throw new JobException(""Target slot for deployment is not alive."");
    }
    // make sure exactly one deployment call happens from the correct state
    // note: the transition from CREATED to DEPLOYING is for testing purposes only
    ExecutionState previous = this.state;
    if (previous == SCHEDULED || previous == CREATED) {
        if (!transitionState(previous, DEPLOYING)) {
            // this should actually not happen and indicates a race somewhere else
            throw new IllegalStateException(""Cannot deploy task: Concurrent deployment call race."");
        }
    } else {
        // vertex may have been cancelled, or it was already scheduled
        throw new IllegalStateException(""The vertex must be in CREATED or SCHEDULED state to be deployed. Found state "" + previous);
    }
    try {
        // good, we are allowed to deploy
        if (!slot.setExecutedVertex(this)) {
            throw new JobException(""Could not assign the ExecutionVertex to the slot "" + slot);
        }
        this.assignedResource = slot;
        this.assignedResourceLocation = slot.getInstance().getInstanceConnectionInfo();
        // race double check, did we fail/cancel and do we need to release the slot?
        if (this.state != DEPLOYING) {
            slot.releaseSlot();
            return;
        }
        if (LOG.isInfoEnabled()) {
            LOG.info(String.format(""Deploying %s (attempt #%d) to %s"", vertex.getSimpleName(), attemptNumber, slot.getInstance().getInstanceConnectionInfo().getHostname()));
        }
        final TaskDeploymentDescriptor deployment = vertex.createDeploymentDescriptor(attemptId, slot);
        // register this execution at the execution graph, to receive call backs
        vertex.getExecutionGraph().registerExecution(this);
        Instance instance = slot.getInstance();
        Future<Object> deployAction = Patterns.ask(instance.getTaskManager(), new SubmitTask(deployment), new Timeout(timeout));
        deployAction.onComplete(new OnComplete<Object>() {

            @Override
            public void onComplete(Throwable failure, Object success) throws Throwable {
                if (failure != null) {
                    if (failure instanceof TimeoutException) {
                        markFailed(new Exception(""Cannot deploy task - TaskManager not responding."", failure));
                    } else {
                        markFailed(failure);
                    }
                } else {
                    if (success == null) {
                        markFailed(new Exception(""Failed to deploy the task to slot "" + slot + "": TaskOperationResult was null""));
                    }
                    if (success instanceof TaskOperationResult) {
                        TaskOperationResult result = (TaskOperationResult) success;
                        if (!result.executionID().equals(attemptId)) {
                            markFailed(new Exception(""Answer execution id does not match the request execution id.""));
                        } else if (result.success()) {
                            switchToRunning();
                        } else {
                            // deployment failed :(
                            markFailed(new Exception(""Failed to deploy the task "" + getVertexWithAttempt() + "" to slot "" + slot + "": "" + result.description()));
                        }
                    } else {
                        markFailed(new Exception(""Failed to deploy the task to slot "" + slot + "": Response was not of type TaskOperationResult""));
                    }
                }
            }
        }, AkkaUtils.globalExecutionContext());
    } catch (Throwable t) {
        markFailed(t);
        ExceptionUtils.rethrow(t);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1922_ccd574a4,Major,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java,337,370,"@Override
public void onComplete(Throwable failure, Object success) throws Throwable {
    if (failure != null) {
        if (failure instanceof TimeoutException) {
            markFailed(new Exception(""Cannot deploy task - TaskManager not responding."", failure));
        } else {
            markFailed(failure);
        }
    } else {
        if (success == null) {
            markFailed(new Exception(""Failed to deploy the task to slot "" + slot + "": TaskOperationResult was null""));
        }
        if (success instanceof TaskOperationResult) {
            TaskOperationResult result = (TaskOperationResult) success;
            if (!result.executionID().equals(attemptId)) {
                markFailed(new Exception(""Answer execution id does not match the request execution id.""));
            } else if (result.success()) {
                switchToRunning();
            } else {
                // deployment failed :(
                markFailed(new Exception(""Failed to deploy the task "" + getVertexWithAttempt() + "" to slot "" + slot + "": "" + result.description()));
            }
        } else {
            markFailed(new Exception(""Failed to deploy the task to slot "" + slot + "": Response was not of type TaskOperationResult""));
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1922_ccd574a4,Major,flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/TaskInputSplitProvider.java,62,90,"@Override
public InputSplit getNextInputSplit() {
    try {
        final Future<Object> response = Patterns.ask(jobManager, new JobManagerMessages.RequestNextInputSplit(jobId, vertexId, executionID), timeout);
        final Object result = Await.result(response, timeout.duration());
        if (result == null) {
            return null;
        }
        if (!(result instanceof JobManagerMessages.NextInputSplit)) {
            throw new RuntimeException(""RequestNextInputSplit requires a response of type "" + ""NextInputSplit. Instead response is of type "" + result.getClass() + ""."");
        } else {
            final JobManagerMessages.NextInputSplit nextInputSplit = (JobManagerMessages.NextInputSplit) result;
            byte[] serializedData = nextInputSplit.splitData();
            Object deserialized = InstantiationUtil.deserializeObject(serializedData, usercodeClassLoader);
            return (InputSplit) deserialized;
        }
    } catch (Exception e) {
        throw new RuntimeException(""Requesting the next InputSplit failed."", e);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1930_4dbf030a,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/buffer/LocalBufferPool.java,136,172,"private Buffer requestBuffer(boolean isBlocking) throws InterruptedException, IOException {
    synchronized (availableMemorySegments) {
        returnExcessMemorySegments();
        boolean askToRecycle = owner != null;
        while (availableMemorySegments.isEmpty()) {
            if (isDestroyed) {
                return null;
            }
            if (numberOfRequestedMemorySegments < currentPoolSize) {
                final MemorySegment segment = networkBufferPool.requestMemorySegment();
                if (segment != null) {
                    numberOfRequestedMemorySegments++;
                    availableMemorySegments.add(segment);
                    continue;
                }
            }
            if (askToRecycle) {
                owner.releaseMemory(1);
            }
            if (isBlocking) {
                availableMemorySegments.wait(2000);
            } else {
                return null;
            }
        }
        return new Buffer(availableMemorySegments.poll(), this);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1951_adb321d6,Critical,flink-optimizer/src/main/java/org/apache/flink/optimizer/plantranslate/JobGraphGenerator.java,1137,1184,"private void addLocalInfoFromChannelToConfig(Channel channel, TaskConfig config, int inputNum, boolean isBroadcastChannel) {
    // serializer
    if (isBroadcastChannel) {
        config.setBroadcastInputSerializer(channel.getSerializer(), inputNum);
        if (channel.getLocalStrategy() != LocalStrategy.NONE || (channel.getTempMode() != null && channel.getTempMode() != TempMode.NONE)) {
            throw new CompilerException(""Found local strategy or temp mode on a broadcast variable channel."");
        } else {
            return;
        }
    } else {
        config.setInputSerializer(channel.getSerializer(), inputNum);
    }
    // local strategy
    if (channel.getLocalStrategy() != LocalStrategy.NONE) {
        config.setInputLocalStrategy(inputNum, channel.getLocalStrategy());
        if (channel.getLocalStrategyComparator() != null) {
            config.setInputComparator(channel.getLocalStrategyComparator(), inputNum);
        }
    }
    assignLocalStrategyResources(channel, config, inputNum);
    // materialization / caching
    if (channel.getTempMode() != null) {
        final TempMode tm = channel.getTempMode();
        boolean needsMemory = false;
        // Don't add a pipeline breaker if the data exchange is already blocking.
        if (tm.breaksPipeline() && channel.getDataExchangeMode() != DataExchangeMode.BATCH) {
            config.setInputAsynchronouslyMaterialized(inputNum, true);
            needsMemory = true;
        }
        if (tm.isCached()) {
            config.setInputCached(inputNum, true);
            needsMemory = true;
        }
        if (needsMemory) {
            // sanity check
            if (tm == null || tm == TempMode.NONE || channel.getRelativeTempMemory() <= 0) {
                throw new CompilerException(""Bug in compiler: Inconsistent description of input materialization."");
            }
            config.setRelativeInputMaterializationMemory(inputNum, channel.getRelativeTempMemory());
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1978_0078c44e,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java,278,312,"@Override
@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
public T copy(T from, T reuse) {
    if (from == null) {
        return null;
    }
    Class<?> actualType = from.getClass();
    if (reuse == null || actualType != reuse.getClass()) {
        // cannot reuse, do a non-reuse copy
        return copy(from);
    }
    if (actualType == clazz) {
        try {
            for (int i = 0; i < numFields; i++) {
                Object value = fields[i].get(from);
                if (value != null) {
                    Object copy = fieldSerializers[i].copy(fields[i].get(from), fields[i].get(reuse));
                    fields[i].set(reuse, copy);
                } else {
                    fields[i].set(reuse, null);
                }
            }
        } catch (IllegalAccessException e) {
            throw new RuntimeException(""Error during POJO copy, this should not happen since we check the fields"" + ""before."");
        }
    } else {
        TypeSerializer subclassSerializer = getSubclassSerializer(actualType);
        reuse = (T) subclassSerializer.copy(from, reuse);
    }
    return reuse;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1978_0078c44e,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/PojoSerializer.java,437,503,"@Override
@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
public T deserialize(T reuse, DataInputView source) throws IOException {
    // handle null values
    int flags = source.readByte();
    if ((flags & IS_NULL) != 0) {
        return null;
    }
    Class<?> subclass = null;
    TypeSerializer subclassSerializer = null;
    if ((flags & IS_SUBCLASS) != 0) {
        String subclassName = source.readUTF();
        try {
            subclass = Class.forName(subclassName, true, cl);
        } catch (ClassNotFoundException e) {
            throw new RuntimeException(""Cannot instantiate class."", e);
        }
        subclassSerializer = getSubclassSerializer(subclass);
        if (reuse == null || subclass != reuse.getClass()) {
            // cannot reuse
            reuse = (T) subclassSerializer.createInstance();
            // also initialize fields for which the subclass serializer is not responsible
            initializeFields(reuse);
        }
    } else if ((flags & IS_TAGGED_SUBCLASS) != 0) {
        int subclassTag = source.readByte();
        subclassSerializer = registeredSerializers[subclassTag];
        if (reuse == null || ((PojoSerializer) subclassSerializer).clazz != reuse.getClass()) {
            // cannot reuse
            reuse = (T) subclassSerializer.createInstance();
            // also initialize fields for which the subclass serializer is not responsible
            initializeFields(reuse);
        }
    } else {
        if (reuse == null || clazz != reuse.getClass()) {
            reuse = createInstance();
        }
    }
    if ((flags & NO_SUBCLASS) != 0) {
        try {
            for (int i = 0; i < numFields; i++) {
                boolean isNull = source.readBoolean();
                if (isNull) {
                    fields[i].set(reuse, null);
                } else {
                    Object field = fieldSerializers[i].deserialize(fields[i].get(reuse), source);
                    fields[i].set(reuse, field);
                }
            }
        } catch (IllegalAccessException e) {
            throw new RuntimeException(""Error during POJO copy, this should not happen since we check the fields before."");
        }
    } else {
        if (subclassSerializer != null) {
            reuse = (T) subclassSerializer.deserialize(reuse, source);
        }
    }
    return reuse;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-1985_495a5c3c,Blocker,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java,79,97,"public JobGraph createJobGraph(String jobName) {
    jobGraph = new JobGraph(jobName);
    // make sure that all vertices start immediately
    jobGraph.setScheduleMode(ScheduleMode.ALL);
    init();
    setChaining();
    setPhysicalEdges();
    setSlotSharing();
    configureCheckpointing();
    return jobGraph;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2074_6bc6dbec,Blocker,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/windowing/windowbuffer/SlidingGroupedPreReducer.java,143,146,"@Override
protected void resetCurrent() {
    currentReducedMap = null;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2074_6bc6dbec,Blocker,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/windowing/windowbuffer/SlidingTimePreReducer.java,79,94,"@Override
public void evict(int n) {
    toRemove += n;
    Integer lastPreAggregateSize = elementsPerPreAggregate.peek();
    while (lastPreAggregateSize != null && lastPreAggregateSize <= toRemove) {
        toRemove = max(toRemove - elementsPerPreAggregate.removeFirst(), 0);
        reduced.removeFirst();
        lastPreAggregateSize = elementsPerPreAggregate.peek();
    }
    if (toRemove > 0 && lastPreAggregateSize == null) {
        currentReduced = null;
        toRemove = 0;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2082_0cfa43d7,Minor,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/OutputHandler.java,118,159,"/**
 *  This method builds up a nested output which encapsulates all the
 *  chained operators and their network output. The result of this recursive
 *  call will be passed as output to the first operator in the chain.
 *
 *  @param chainedTaskConfig
 *  		The configuration of the starting operator of the chain, we
 *  		use this paramater to recursively build the whole chain
 *  @return Returns the output for the chain starting from the given
 *  config
 */
@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
private <X> Output<X> createChainedCollector(StreamConfig chainedTaskConfig) {
    // We create a wrapper that will encapsulate the chained operators and
    // network outputs
    OutputSelectorWrapper<?> outputSelectorWrapper = chainedTaskConfig.getOutputSelectorWrapper(cl);
    CollectorWrapper wrapper = new CollectorWrapper(outputSelectorWrapper);
    // Create collectors for the network outputs
    for (StreamEdge outputEdge : chainedTaskConfig.getNonChainedOutputs(cl)) {
        Collector<?> outCollector = outputMap.get(outputEdge);
        wrapper.addCollector(outCollector, outputEdge);
    }
    // Create collectors for the chained outputs
    for (StreamEdge outputEdge : chainedTaskConfig.getChainedOutputs(cl)) {
        Integer output = outputEdge.getTargetID();
        Collector<?> outCollector = createChainedCollector(chainedConfigs.get(output));
        wrapper.addCollector(outCollector, outputEdge);
    }
    if (chainedTaskConfig.isChainStart()) {
        // return the wrapper
        return (Output<X>) wrapper;
    } else {
        // The current task is a part of the chain so we get the chainable
        // operator which will be returned and set it up using the wrapper
        OneInputStreamOperator chainableOperator = chainedTaskConfig.getStreamOperator(vertex.getUserCodeClassLoader());
        chainableOperator.setup(wrapper, vertex.context);
        chainedOperators.add(chainableOperator);
        return new OperatorCollector<X>(chainableOperator);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2082_0cfa43d7,Minor,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java,78,94,"@Override
public void registerInputOutput() {
    this.userClassLoader = getUserCodeClassLoader();
    this.configuration = new StreamConfig(getTaskConfiguration());
    this.context = createRuntimeContext(getEnvironment().getTaskName());
    this.stateHandleProvider = getStateHandleProvider();
    outputHandler = new OutputHandler<OUT>(this);
    streamOperator = configuration.getStreamOperator(userClassLoader);
    if (streamOperator != null) {
        // IterationHead and IterationTail don't have an Operator...
        streamOperator.setup(outputHandler.getOutput(), this.context);
    }
    hasChainedOperators = !outputHandler.getChainedOperators().isEmpty();
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2082_0cfa43d7,Minor,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java,100,104,"public StreamingRuntimeContext createRuntimeContext(String taskName) {
    Environment env = getEnvironment();
    return new StreamingRuntimeContext(taskName, env, getUserCodeClassLoader(), getExecutionConfig());
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2109_d594d024,Major,flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java,402,668,"/**
 *  The core work method that bootstraps the task and executes it code
 */
@Override
public void run() {
    // ----------------------------
    while (true) {
        ExecutionState current = this.executionState;
        if (current == ExecutionState.CREATED) {
            if (STATE_UPDATER.compareAndSet(this, ExecutionState.CREATED, ExecutionState.DEPLOYING)) {
                // success, we can start our work
                break;
            }
        } else if (current == ExecutionState.FAILED) {
            // we were immediately failed. tell the TaskManager that we reached our final state
            notifyFinalState();
            return;
        } else if (current == ExecutionState.CANCELING) {
            if (STATE_UPDATER.compareAndSet(this, ExecutionState.CANCELING, ExecutionState.CANCELED)) {
                // we were immediately canceled. tell the TaskManager that we reached our final state
                notifyFinalState();
                return;
            }
        } else {
            throw new IllegalStateException(""Invalid state for beginning of task operation"");
        }
    }
    // all resource acquisitions and registrations from here on
    // need to be undone in the end
    Map<String, Future<Path>> distributedCacheEntries = new HashMap<String, Future<Path>>();
    AbstractInvokable invokable = null;
    try {
        // ----------------------------
        // Task Bootstrap - We periodically
        // check for canceling as a shortcut
        // ----------------------------
        // first of all, get a user-code classloader
        // this may involve downloading the job's JAR files and/or classes
        LOG.info(""Loading JAR files for task "" + taskNameWithSubtask);
        final ClassLoader userCodeClassLoader = createUserCodeClassloader(libraryCache);
        // now load the task's invokable code
        invokable = loadAndInstantiateInvokable(userCodeClassLoader, nameOfInvokableClass);
        if (isCanceledOrFailed()) {
            throw new CancelTaskException();
        }
        // ----------------------------------------------------------------
        // register the task with the network stack
        // this operation may fail if the system does not have enough
        // memory to run the necessary data exchanges
        // the registration must also strictly be undone
        // ----------------------------------------------------------------
        LOG.info(""Registering task at network: "" + this);
        network.registerTask(this);
        // next, kick off the background copying of files for the distributed cache
        try {
            for (Map.Entry<String, DistributedCache.DistributedCacheEntry> entry : DistributedCache.readFileInfoFromConfig(jobConfiguration)) {
                LOG.info(""Obtaining local cache file for '"" + entry.getKey() + '\'');
                Future<Path> cp = fileCache.createTmpFile(entry.getKey(), entry.getValue(), jobId);
                distributedCacheEntries.put(entry.getKey(), cp);
            }
        } catch (Exception e) {
            throw new Exception(""Exception while adding files to distributed cache."", e);
        }
        if (isCanceledOrFailed()) {
            throw new CancelTaskException();
        }
        // ----------------------------------------------------------------
        // call the user code initialization methods
        // ----------------------------------------------------------------
        TaskInputSplitProvider splitProvider = new TaskInputSplitProvider(jobManager, jobId, vertexId, executionId, userCodeClassLoader, actorAskTimeout);
        Environment env = new RuntimeEnvironment(jobId, vertexId, executionId, taskName, taskNameWithSubtask, subtaskIndex, parallelism, jobConfiguration, taskConfiguration, userCodeClassLoader, memoryManager, ioManager, broadcastVariableManager, splitProvider, distributedCacheEntries, writers, inputGates, jobManager);
        // let the task code create its readers and writers
        invokable.setEnvironment(env);
        try {
            invokable.registerInputOutput();
        } catch (Exception e) {
            throw new Exception(""Call to registerInputOutput() of invokable failed"", e);
        }
        // the very last thing before the actual execution starts running is to inject
        // the state into the task. the state is non-empty if this is an execution
        // of a task that failed but had backuped state from a checkpoint
        // get our private reference onto the stack (be safe against concurrent changes)
        SerializedValue<StateHandle<?>> operatorState = this.operatorState;
        if (operatorState != null) {
            if (invokable instanceof OperatorStateCarrier) {
                try {
                    StateHandle<?> state = operatorState.deserializeValue(userCodeClassLoader);
                    OperatorStateCarrier<?> op = (OperatorStateCarrier<?>) invokable;
                    StateUtils.setOperatorState(op, state);
                } catch (Exception e) {
                    throw new RuntimeException(""Failed to deserialize state handle and setup initial operator state."", e);
                }
            } else {
                throw new IllegalStateException(""Found operator state for a non-stateful task invokable"");
            }
        }
        // be memory and GC friendly - since the code stays in invoke() for a potentially long time,
        // we clear the reference to the state handle
        // noinspection UnusedAssignment
        operatorState = null;
        this.operatorState = null;
        // ----------------------------------------------------------------
        // actual task core work
        // ----------------------------------------------------------------
        // we must make strictly sure that the invokable is accessible to teh cancel() call
        // by the time we switched to running.
        this.invokable = invokable;
        // switch to the RUNNING state, if that fails, we have been canceled/failed in the meantime
        if (!STATE_UPDATER.compareAndSet(this, ExecutionState.DEPLOYING, ExecutionState.RUNNING)) {
            throw new CancelTaskException();
        }
        // notify everyone that we switched to running. especially the TaskManager needs
        // to know this!
        notifyObservers(ExecutionState.RUNNING, null);
        taskManager.tell(new TaskMessages.UpdateTaskExecutionState(new TaskExecutionState(jobId, executionId, ExecutionState.RUNNING)), ActorRef.noSender());
        // make sure the user code classloader is accessible thread-locally
        executingThread.setContextClassLoader(userCodeClassLoader);
        // run the invokable
        invokable.invoke();
        // to the fact that it has been canceled
        if (isCanceledOrFailed()) {
            throw new CancelTaskException();
        }
        // finish the produced partitions. if this fails, we consider the execution failed.
        for (ResultPartition partition : producedPartitions) {
            if (partition != null) {
                partition.finish();
            }
        }
        // if that fails, the task was canceled/failed in the meantime
        if (STATE_UPDATER.compareAndSet(this, ExecutionState.RUNNING, ExecutionState.FINISHED)) {
            notifyObservers(ExecutionState.FINISHED, null);
        } else {
            throw new CancelTaskException();
        }
    } catch (Throwable t) {
        try {
            // to failExternally()
            while (true) {
                ExecutionState current = this.executionState;
                if (current == ExecutionState.RUNNING || current == ExecutionState.DEPLOYING) {
                    if (STATE_UPDATER.compareAndSet(this, current, ExecutionState.FAILED)) {
                        // proper failure of the task. record the exception as the root cause
                        failureCause = t;
                        notifyObservers(ExecutionState.FAILED, t);
                        // in case of an exception during execution, we still call ""cancel()"" on the task
                        if (invokable != null && this.invokable != null && invokableHasBeenCanceled.compareAndSet(false, true)) {
                            try {
                                invokable.cancel();
                            } catch (Throwable t2) {
                                LOG.error(""Error while canceling task "" + taskNameWithSubtask, t2);
                            }
                        }
                        break;
                    }
                } else if (current == ExecutionState.CANCELING) {
                    if (STATE_UPDATER.compareAndSet(this, current, ExecutionState.CANCELED)) {
                        notifyObservers(ExecutionState.CANCELED, null);
                        break;
                    }
                } else if (current == ExecutionState.FAILED) {
                    // in state failed already, no transition necessary any more
                    break;
                } else // unexpected state, go to failed
                if (STATE_UPDATER.compareAndSet(this, current, ExecutionState.FAILED)) {
                    LOG.error(""Unexpected state in Task during an exception: "" + current);
                    break;
                }
            // else fall through the loop and
            }
        } catch (Throwable tt) {
            String message = ""FATAL - exception in task exception handler"";
            LOG.error(message, tt);
            notifyFatalError(message, tt);
        }
    } finally {
        try {
            LOG.info(""Freeing task resources for "" + taskNameWithSubtask);
            // free the network resources
            network.unregisterTask(this);
            if (invokable != null) {
                memoryManager.releaseAll(invokable);
            }
            // remove all of the tasks library resources
            libraryCache.unregisterTask(jobId, executionId);
            // remove all files in the distributed cache
            removeCachedFiles(distributedCacheEntries, fileCache);
            notifyFinalState();
        } catch (Throwable t) {
            // an error in the resource cleanup is fatal
            String message = ""FATAL - exception in task resource cleanup"";
            LOG.error(message, t);
            notifyFatalError(message, t);
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2109_d594d024,Major,flink-runtime/src/main/java/org/apache/flink/runtime/taskmanager/Task.java,757,760,"/**
 *  Marks task execution failed for an external reason (a reason other than th task code itself
 *  throwing an exception). If the task is already in a terminal state
 *  (such as FINISHED, CANCELED, FAILED), or if the task is already canceling this does nothing.
 *  Otherwise it sets the state to FAILED, and, if the invokable code is running,
 *  starts an asynchronous thread that aborts that code.
 *
 *  <p>This method never blocks.</p>
 */
public void failExternally(Throwable cause) {
    LOG.info(""Attempting to fail task externally "" + taskNameWithSubtask);
    cancelOrFailAndCancelInvokable(ExecutionState.FAILED, cause);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2121_03340919,Minor,flink-core/src/main/java/org/apache/flink/api/common/io/FileInputFormat.java,324,356,"protected FileBaseStatistics getFileStats(FileBaseStatistics cachedStats, Path filePath, FileSystem fs, ArrayList<FileStatus> files) throws IOException {
    // get the file info and check whether the cached statistics are still valid.
    final FileStatus file = fs.getFileStatus(filePath);
    long totalLength = 0;
    // enumerate all files
    if (file.isDir()) {
        totalLength += addFilesInDir(file.getPath(), files, totalLength, false);
    } else {
        files.add(file);
        testForUnsplittable(file);
        totalLength += file.getLen();
    }
    // check the modification time stamp
    long latestModTime = 0;
    for (FileStatus f : files) {
        latestModTime = Math.max(f.getModificationTime(), latestModTime);
    }
    // check whether the cached statistics are still valid, if we have any
    if (cachedStats != null && latestModTime <= cachedStats.getLastModificationTime()) {
        return cachedStats;
    }
    // sanity check
    if (totalLength <= 0) {
        totalLength = BaseStatistics.SIZE_UNKNOWN;
    }
    return new FileBaseStatistics(latestModTime, totalLength, BaseStatistics.AVG_RECORD_BYTES_UNKNOWN);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2121_03340919,Minor,flink-core/src/main/java/org/apache/flink/api/common/io/FileInputFormat.java,373,494,"/**
 *  Computes the input splits for the file. By default, one file block is one split. If more splits
 *  are requested than blocks are available, then a split may be a fraction of a block and splits may cross
 *  block boundaries.
 *
 *  @param minNumSplits The minimum desired number of file splits.
 *  @return The computed file splits.
 *
 *  @see org.apache.flink.api.common.io.InputFormat#createInputSplits(int)
 */
@Override
public FileInputSplit[] createInputSplits(int minNumSplits) throws IOException {
    if (minNumSplits < 1) {
        throw new IllegalArgumentException(""Number of input splits has to be at least 1."");
    }
    // take the desired number of splits into account
    minNumSplits = Math.max(minNumSplits, this.numSplits);
    final Path path = this.filePath;
    final List<FileInputSplit> inputSplits = new ArrayList<FileInputSplit>(minNumSplits);
    // get all the files that are involved in the splits
    List<FileStatus> files = new ArrayList<FileStatus>();
    long totalLength = 0;
    final FileSystem fs = path.getFileSystem();
    final FileStatus pathFile = fs.getFileStatus(path);
    if (pathFile.isDir()) {
        totalLength += addFilesInDir(path, files, totalLength, true);
    } else {
        testForUnsplittable(pathFile);
        files.add(pathFile);
        totalLength += pathFile.getLen();
    }
    // returns if unsplittable
    if (unsplittable) {
        int splitNum = 0;
        for (final FileStatus file : files) {
            final BlockLocation[] blocks = fs.getFileBlockLocations(file, 0, file.getLen());
            Set<String> hosts = new HashSet<String>();
            for (BlockLocation block : blocks) {
                hosts.addAll(Arrays.asList(block.getHosts()));
            }
            long len = file.getLen();
            if (testForUnsplittable(file)) {
                len = READ_WHOLE_SPLIT_FLAG;
            }
            FileInputSplit fis = new FileInputSplit(splitNum++, file.getPath(), 0, len, hosts.toArray(new String[hosts.size()]));
            inputSplits.add(fis);
        }
        return inputSplits.toArray(new FileInputSplit[inputSplits.size()]);
    }
    final long maxSplitSize = (minNumSplits < 1) ? Long.MAX_VALUE : (totalLength / minNumSplits + (totalLength % minNumSplits == 0 ? 0 : 1));
    // now that we have the files, generate the splits
    int splitNum = 0;
    for (final FileStatus file : files) {
        final long len = file.getLen();
        final long blockSize = file.getBlockSize();
        final long minSplitSize;
        if (this.minSplitSize <= blockSize) {
            minSplitSize = this.minSplitSize;
        } else {
            if (LOG.isWarnEnabled()) {
                LOG.warn(""Minimal split size of "" + this.minSplitSize + "" is larger than the block size of "" + blockSize + "". Decreasing minimal split size to block size."");
            }
            minSplitSize = blockSize;
        }
        final long splitSize = Math.max(minSplitSize, Math.min(maxSplitSize, blockSize));
        final long halfSplit = splitSize >>> 1;
        final long maxBytesForLastSplit = (long) (splitSize * MAX_SPLIT_SIZE_DISCREPANCY);
        if (len > 0) {
            // get the block locations and make sure they are in order with respect to their offset
            final BlockLocation[] blocks = fs.getFileBlockLocations(file, 0, len);
            Arrays.sort(blocks);
            long bytesUnassigned = len;
            long position = 0;
            int blockIndex = 0;
            while (bytesUnassigned > maxBytesForLastSplit) {
                // get the block containing the majority of the data
                blockIndex = getBlockIndexForPosition(blocks, position, halfSplit, blockIndex);
                // create a new split
                FileInputSplit fis = new FileInputSplit(splitNum++, file.getPath(), position, splitSize, blocks[blockIndex].getHosts());
                inputSplits.add(fis);
                // adjust the positions
                position += splitSize;
                bytesUnassigned -= splitSize;
            }
            // assign the last split
            if (bytesUnassigned > 0) {
                blockIndex = getBlockIndexForPosition(blocks, position, halfSplit, blockIndex);
                final FileInputSplit fis = new FileInputSplit(splitNum++, file.getPath(), position, bytesUnassigned, blocks[blockIndex].getHosts());
                inputSplits.add(fis);
            }
        } else {
            // special case with a file of zero bytes size
            final BlockLocation[] blocks = fs.getFileBlockLocations(file, 0, 0);
            String[] hosts;
            if (blocks.length > 0) {
                hosts = blocks[0].getHosts();
            } else {
                hosts = new String[0];
            }
            final FileInputSplit fis = new FileInputSplit(splitNum++, file.getPath(), 0, 0, hosts);
            inputSplits.add(fis);
        }
    }
    return inputSplits.toArray(new FileInputSplit[inputSplits.size()]);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2121_03340919,Minor,flink-core/src/main/java/org/apache/flink/api/common/io/FileInputFormat.java,500,527,"/**
 *  Enumerate all files in the directory and recursive if enumerateNestedFiles is true.
 *  @return the total length of accepted files.
 */
private long addFilesInDir(Path path, List<FileStatus> files, long length, boolean logExcludedFiles) throws IOException {
    final FileSystem fs = path.getFileSystem();
    for (FileStatus dir : fs.listStatus(path)) {
        if (dir.isDir()) {
            if (acceptFile(dir) && enumerateNestedFiles) {
                length += addFilesInDir(dir.getPath(), files, length, logExcludedFiles);
            } else {
                if (logExcludedFiles && LOG.isDebugEnabled()) {
                    LOG.debug(""Directory "" + dir.getPath().toString() + "" did not pass the file-filter and is excluded."");
                }
            }
        } else {
            if (acceptFile(dir)) {
                files.add(dir);
                length += dir.getLen();
                testForUnsplittable(dir);
            } else {
                if (logExcludedFiles && LOG.isDebugEnabled()) {
                    LOG.debug(""Directory "" + dir.getPath().toString() + "" did not pass the file-filter and is excluded."");
                }
            }
        }
    }
    return length;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2294_fef9f115,Blocker,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/OutputHandler.java,274,284,"@Override
public void collect(T record) {
    try {
        operator.processElement(serializer.copy(record));
    } catch (Exception e) {
        if (LOG.isErrorEnabled()) {
            LOG.error(""Could not forward element to operator."", e);
        }
        throw new RuntimeException(e);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2412_a56aad74,Critical,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/SpillableSubpartitionView.java,67,122,"@Override
public Buffer getNextBuffer() throws IOException, InterruptedException {
    if (isReleased.get()) {
        return null;
    }
    // 1) In-memory
    synchronized (parent.buffers) {
        if (parent.spillWriter == null) {
            if (currentQueuePosition < numberOfBuffers) {
                Buffer buffer = parent.buffers.get(currentQueuePosition);
                buffer.retain();
                // TODO Fix hard coding of 8 bytes for the header
                currentBytesRead += buffer.getSize() + 8;
                currentQueuePosition++;
                return buffer;
            }
            return null;
        }
    }
    // 2) Spilled
    if (spilledView != null) {
        return spilledView.getNextBuffer();
    }
    // because this might be called from an network I/O thread.
    if (parent.spillWriter.getNumberOfOutstandingRequests() > 0) {
        return null;
    }
    if (ioMode.isSynchronous()) {
        spilledView = new SpilledSubpartitionViewSyncIO(parent, bufferProvider.getMemorySegmentSize(), parent.spillWriter.getChannelID(), currentBytesRead);
    } else {
        spilledView = new SpilledSubpartitionViewAsyncIO(parent, bufferProvider, parent.ioManager, parent.spillWriter.getChannelID(), currentBytesRead);
    }
    return spilledView.getNextBuffer();
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2437_a41bc8cc,Minor,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,1257,1309,"/**
 *  Checks if the given field is a valid pojo field:
 *  - it is public
 *  OR
 *   - there are getter and setter methods for the field.
 *
 *  @param f field to check
 *  @param clazz class of field
 *  @param typeHierarchy type hierarchy for materializing generic types
 */
private boolean isValidPojoField(Field f, Class<?> clazz, ArrayList<Type> typeHierarchy) {
    if (Modifier.isPublic(f.getModifiers())) {
        return true;
    } else {
        boolean hasGetter = false, hasSetter = false;
        final String fieldNameLow = f.getName().toLowerCase();
        Type fieldType = f.getGenericType();
        TypeVariable<?> fieldTypeGeneric = null;
        if (fieldType instanceof TypeVariable) {
            fieldTypeGeneric = (TypeVariable<?>) fieldType;
            fieldType = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) fieldType);
        }
        for (Method m : clazz.getMethods()) {
            // check for getter
            if (// The name should be ""get<FieldName>"" or ""<fieldName>"" (for scala) or ""is<fieldName>"" for boolean fields.
            (m.getName().toLowerCase().equals(""get"" + fieldNameLow) || m.getName().toLowerCase().equals(""is"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow)) && // no arguments for the getter
            m.getParameterTypes().length == 0 && // return type is same as field type (or the generic variant of it)
            (m.getGenericReturnType().equals(fieldType) || (fieldTypeGeneric != null && m.getGenericReturnType().equals(fieldTypeGeneric)))) {
                if (hasGetter) {
                    throw new IllegalStateException(""Detected more than one getter"");
                }
                hasGetter = true;
            }
            // check for setters (<FieldName>_$eq for scala)
            if ((m.getName().toLowerCase().equals(""set"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow + ""_$eq"")) && // one parameter of the field's type
            m.getParameterTypes().length == 1 && (m.getGenericParameterTypes()[0].equals(fieldType) || (fieldTypeGeneric != null && m.getGenericParameterTypes()[0].equals(fieldTypeGeneric))) && // return type is void.
            m.getReturnType().equals(Void.TYPE)) {
                if (hasSetter) {
                    throw new IllegalStateException(""Detected more than one setter"");
                }
                hasSetter = true;
            }
        }
        if (hasGetter && hasSetter) {
            return true;
        } else {
            if (!hasGetter) {
                LOG.debug(""Class "" + clazz + "" does not contain a getter for field "" + f.getName());
            }
            if (!hasSetter) {
                LOG.debug(""Class "" + clazz + "" does not contain a setter for field "" + f.getName());
            }
            return false;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2437_a41bc8cc,Minor,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,1311,1381,"@SuppressWarnings(""unchecked"")
protected <OUT, IN1, IN2> TypeInformation<OUT> analyzePojo(Class<OUT> clazz, ArrayList<Type> typeHierarchy, ParameterizedType parameterizedType, TypeInformation<IN1> in1Type, TypeInformation<IN2> in2Type) {
    // add the hierarchy of the POJO itself if it is generic
    if (parameterizedType != null) {
        getTypeHierarchy(typeHierarchy, parameterizedType, Object.class);
    } else // create a type hierarchy, if the incoming only contains the most bottom one or none.
    if (typeHierarchy.size() <= 1) {
        getTypeHierarchy(typeHierarchy, clazz, Object.class);
    }
    List<Field> fields = getAllDeclaredFields(clazz);
    if (fields.size() == 0) {
        LOG.info(""No fields detected for class "" + clazz + "". Cannot be used as a PojoType. Will be handled as GenericType"");
        return new GenericTypeInfo<OUT>(clazz);
    }
    List<PojoField> pojoFields = new ArrayList<PojoField>();
    for (Field field : fields) {
        Type fieldType = field.getGenericType();
        if (!isValidPojoField(field, clazz, typeHierarchy)) {
            LOG.info(""Class "" + clazz + "" is not a valid POJO type"");
            return null;
        }
        try {
            ArrayList<Type> fieldTypeHierarchy = new ArrayList<Type>(typeHierarchy);
            fieldTypeHierarchy.add(fieldType);
            TypeInformation<?> ti = createTypeInfoWithTypeHierarchy(fieldTypeHierarchy, fieldType, in1Type, in2Type);
            pojoFields.add(new PojoField(field, ti));
        } catch (InvalidTypesException e) {
            Class<?> genericClass = Object.class;
            if (isClassType(fieldType)) {
                genericClass = typeToClass(fieldType);
            }
            pojoFields.add(new PojoField(field, new GenericTypeInfo<OUT>((Class<OUT>) genericClass)));
        }
    }
    CompositeType<OUT> pojoType = new PojoTypeInfo<OUT>(clazz, pojoFields);
    // 
    // Validate the correctness of the pojo.
    // returning ""null"" will result create a generic type information.
    // 
    List<Method> methods = getAllDeclaredMethods(clazz);
    for (Method method : methods) {
        if (method.getName().equals(""readObject"") || method.getName().equals(""writeObject"")) {
            LOG.info(""Class "" + clazz + "" contains custom serialization methods we do not call."");
            return null;
        }
    }
    // we cannot use this because the serializer uses it.
    try {
        clazz.getDeclaredConstructor();
    } catch (NoSuchMethodException e) {
        if (clazz.isInterface() || Modifier.isAbstract(clazz.getModifiers())) {
            LOG.info(""Class "" + clazz + "" is abstract or an interface, having a concrete "" + ""type can increase performance."");
        } else {
            LOG.info(""Class "" + clazz + "" must have a default constructor to be used as a POJO."");
            return null;
        }
    }
    // everything is checked, we return the pojo
    return pojoType;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2437_a41bc8cc,Minor,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,1388,1405,"/**
 *  recursively determine all declared fields
 *  This is required because class.getFields() is not returning fields defined
 *  in parent classes.
 */
public static List<Field> getAllDeclaredFields(Class<?> clazz) {
    List<Field> result = new ArrayList<Field>();
    while (clazz != null) {
        Field[] fields = clazz.getDeclaredFields();
        for (Field field : fields) {
            if (Modifier.isTransient(field.getModifiers()) || Modifier.isStatic(field.getModifiers())) {
                // we have no use for transient or static fields
                continue;
            }
            if (hasFieldWithSameName(field.getName(), result)) {
                throw new RuntimeException(""The field "" + field + "" is already contained in the hierarchy of the class "" + clazz + ""."" + ""Please use unique field names through your classes hierarchy"");
            }
            result.add(field);
        }
        clazz = clazz.getSuperclass();
    }
    return result;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2442_30761572,Critical,flink-java/src/main/java/org/apache/flink/api/java/operators/Keys.java,251,261,"private static int countNestedElementsBefore(CompositeType<?> compositeType, int pos) {
    if (pos == 0) {
        return 0;
    }
    int ret = 0;
    for (int i = 0; i < pos; i++) {
        TypeInformation<?> fieldType = compositeType.getTypeAt(i);
        ret += fieldType.getTotalFields() - 1;
    }
    return ret;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2442_30761572,Critical,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TupleTypeInfoBase.java,97,108,"/**
 *  Recursively add all fields in this tuple type. We need this in particular to get all
 *  the types.
 *  @param startKeyId
 *  @param keyFields
 */
public void addAllFields(int startKeyId, List<FlatFieldDescriptor> keyFields) {
    for (int i = 0; i < this.getArity(); i++) {
        TypeInformation<?> type = this.types[i];
        if (type instanceof AtomicType) {
            keyFields.add(new FlatFieldDescriptor(startKeyId, type));
        } else if (type instanceof TupleTypeInfoBase<?>) {
            TupleTypeInfoBase<?> ttb = (TupleTypeInfoBase<?>) type;
            ttb.addAllFields(startKeyId, keyFields);
        }
        startKeyId += type.getTotalFields();
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2447_5546a1ef,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,373,522,"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
private <IN1, IN2, OUT> TypeInformation<OUT> createTypeInfoWithTypeHierarchy(ArrayList<Type> typeHierarchy, Type t, TypeInformation<IN1> in1Type, TypeInformation<IN2> in2Type) {
    // check if type is a subclass of tuple
    if (isClassType(t) && Tuple.class.isAssignableFrom(typeToClass(t))) {
        Type curT = t;
        // do not allow usage of Tuple as type
        if (typeToClass(t).equals(Tuple.class)) {
            throw new InvalidTypesException(""Usage of class Tuple as a type is not allowed. Use a concrete subclass (e.g. Tuple1, Tuple2, etc.) instead."");
        }
        // collect the types while moving up for a later top-down
        while (!(isClassType(curT) && typeToClass(curT).getSuperclass().equals(Tuple.class))) {
            typeHierarchy.add(curT);
            curT = typeToClass(curT).getGenericSuperclass();
        }
        // check if immediate child of Tuple has generics
        if (curT instanceof Class<?>) {
            throw new InvalidTypesException(""Tuple needs to be parameterized by using generics."");
        }
        typeHierarchy.add(curT);
        ParameterizedType tupleChild = (ParameterizedType) curT;
        Type[] subtypes = new Type[tupleChild.getActualTypeArguments().length];
        // materialize possible type variables
        for (int i = 0; i < subtypes.length; i++) {
            // materialize immediate TypeVariables
            if (tupleChild.getActualTypeArguments()[i] instanceof TypeVariable<?>) {
                subtypes[i] = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) tupleChild.getActualTypeArguments()[i]);
            } else // class or parameterized type
            {
                subtypes[i] = tupleChild.getActualTypeArguments()[i];
            }
        }
        TypeInformation<?>[] tupleSubTypes = new TypeInformation<?>[subtypes.length];
        for (int i = 0; i < subtypes.length; i++) {
            // try to derive the type info of the TypeVariable from the immediate base child input as a last attempt
            if (subtypes[i] instanceof TypeVariable<?>) {
                tupleSubTypes[i] = createTypeInfoFromInputs((TypeVariable<?>) subtypes[i], typeHierarchy, in1Type, in2Type);
                // variable could not be determined
                if (tupleSubTypes[i] == null) {
                    throw new InvalidTypesException(""Type of TypeVariable '"" + ((TypeVariable<?>) subtypes[i]).getName() + ""' in '"" + ((TypeVariable<?>) subtypes[i]).getGenericDeclaration() + ""' could not be determined. This is most likely a type erasure problem. "" + ""The type extraction currently supports types with generic variables only in cases where "" + ""all variables in the return type can be deduced from the input type(s)."");
                }
            } else {
                tupleSubTypes[i] = createTypeInfoWithTypeHierarchy(new ArrayList<Type>(typeHierarchy), subtypes[i], in1Type, in2Type);
            }
        }
        Class<?> tAsClass = null;
        if (isClassType(t)) {
            tAsClass = typeToClass(t);
        }
        Preconditions.checkNotNull(tAsClass, ""t has a unexpected type"");
        // check if the class we assumed to be a Tuple so far is actually a pojo because it contains additional fields.
        // check for additional fields.
        int fieldCount = countFieldsInClass(tAsClass);
        if (fieldCount != tupleSubTypes.length) {
            // the class is not a real tuple because it contains additional fields. treat as a pojo
            if (t instanceof ParameterizedType) {
                return (TypeInformation<OUT>) analyzePojo(tAsClass, new ArrayList<Type>(typeHierarchy), (ParameterizedType) t, in1Type, in2Type);
            } else {
                return (TypeInformation<OUT>) analyzePojo(tAsClass, new ArrayList<Type>(typeHierarchy), null, in1Type, in2Type);
            }
        }
        return new TupleTypeInfo(tAsClass, tupleSubTypes);
    } else // e.g. class MyMapper<E> extends MapFunction<String, E>
    if (t instanceof TypeVariable) {
        Type typeVar = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) t);
        if (!(typeVar instanceof TypeVariable)) {
            return createTypeInfoWithTypeHierarchy(typeHierarchy, typeVar, in1Type, in2Type);
        } else // try to derive the type info of the TypeVariable from the immediate base child input as a last attempt
        {
            TypeInformation<OUT> typeInfo = (TypeInformation<OUT>) createTypeInfoFromInputs((TypeVariable<?>) t, typeHierarchy, in1Type, in2Type);
            if (typeInfo != null) {
                return typeInfo;
            } else {
                throw new InvalidTypesException(""Type of TypeVariable '"" + ((TypeVariable<?>) t).getName() + ""' in '"" + ((TypeVariable<?>) t).getGenericDeclaration() + ""' could not be determined. This is most likely a type erasure problem. "" + ""The type extraction currently supports types with generic variables only in cases where "" + ""all variables in the return type can be deduced from the input type(s)."");
            }
        }
    } else // arrays with generics
    if (t instanceof GenericArrayType) {
        GenericArrayType genericArray = (GenericArrayType) t;
        Type componentType = genericArray.getGenericComponentType();
        // due to a Java 6 bug, it is possible that the JVM classifies e.g. String[] or int[] as GenericArrayType instead of Class
        if (componentType instanceof Class) {
            Class<?> componentClass = (Class<?>) componentType;
            String className;
            // for int[], double[] etc.
            if (componentClass.isPrimitive()) {
                className = encodePrimitiveClass(componentClass);
            } else // for String[], Integer[] etc.
            {
                className = ""L"" + componentClass.getName() + "";"";
            }
            Class<OUT> classArray;
            try {
                classArray = (Class<OUT>) Class.forName(""["" + className);
            } catch (ClassNotFoundException e) {
                throw new InvalidTypesException(""Could not convert GenericArrayType to Class."");
            }
            return getForClass(classArray);
        }
        TypeInformation<?> componentInfo = createTypeInfoWithTypeHierarchy(typeHierarchy, genericArray.getGenericComponentType(), in1Type, in2Type);
        return ObjectArrayTypeInfo.getInfoFor(t, componentInfo);
    } else // objects with generics are treated as Class first
    if (t instanceof ParameterizedType) {
        return (TypeInformation<OUT>) privateGetForClass(typeToClass(t), typeHierarchy, (ParameterizedType) t, in1Type, in2Type);
    } else // no tuple, no TypeVariable, no generic type
    if (t instanceof Class) {
        return privateGetForClass((Class<OUT>) t, typeHierarchy);
    }
    throw new InvalidTypesException(""Type Information could not be created."");
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2447_5546a1ef,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,1124,1216,"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
private <OUT, IN1, IN2> TypeInformation<OUT> privateGetForClass(Class<OUT> clazz, ArrayList<Type> typeHierarchy, ParameterizedType parameterizedType, TypeInformation<IN1> in1Type, TypeInformation<IN2> in2Type) {
    Preconditions.checkNotNull(clazz);
    if (clazz.equals(Object.class)) {
        return new GenericTypeInfo<OUT>(clazz);
    }
    // check for arrays
    if (clazz.isArray()) {
        // primitive arrays: int[], byte[], ...
        PrimitiveArrayTypeInfo<OUT> primitiveArrayInfo = PrimitiveArrayTypeInfo.getInfoFor(clazz);
        if (primitiveArrayInfo != null) {
            return primitiveArrayInfo;
        }
        // basic type arrays: String[], Integer[], Double[]
        BasicArrayTypeInfo<OUT, ?> basicArrayInfo = BasicArrayTypeInfo.getInfoFor(clazz);
        if (basicArrayInfo != null) {
            return basicArrayInfo;
        } else // object arrays
        {
            return ObjectArrayTypeInfo.getInfoFor(clazz);
        }
    }
    // check for writable types
    if (Writable.class.isAssignableFrom(clazz) && !Writable.class.equals(clazz)) {
        return (TypeInformation<OUT>) WritableTypeInfo.getWritableTypeInfo((Class<? extends Writable>) clazz);
    }
    // check for basic types
    TypeInformation<OUT> basicTypeInfo = BasicTypeInfo.getInfoFor(clazz);
    if (basicTypeInfo != null) {
        return basicTypeInfo;
    }
    // check for subclasses of Value
    if (Value.class.isAssignableFrom(clazz)) {
        Class<? extends Value> valueClass = clazz.asSubclass(Value.class);
        return (TypeInformation<OUT>) ValueTypeInfo.getValueTypeInfo(valueClass);
    }
    // check for subclasses of Tuple
    if (Tuple.class.isAssignableFrom(clazz)) {
        throw new InvalidTypesException(""Type information extraction for tuples cannot be done based on the class."");
    }
    // check for Enums
    if (Enum.class.isAssignableFrom(clazz)) {
        return (TypeInformation<OUT>) new EnumTypeInfo(clazz);
    }
    // special case for POJOs generated by Avro.
    if (SpecificRecordBase.class.isAssignableFrom(clazz)) {
        return (TypeInformation<OUT>) new AvroTypeInfo(clazz);
    }
    if (alreadySeen.contains(clazz)) {
        return new GenericTypeInfo<OUT>(clazz);
    }
    alreadySeen.add(clazz);
    if (Modifier.isInterface(clazz.getModifiers())) {
        // Interface has no members and is therefore not handled as POJO
        return new GenericTypeInfo<OUT>(clazz);
    }
    if (clazz.equals(Class.class)) {
        // special case handling for Class, this should not be handled by the POJO logic
        return new GenericTypeInfo<OUT>(clazz);
    }
    try {
        TypeInformation<OUT> pojoType = analyzePojo(clazz, new ArrayList<Type>(typeHierarchy), parameterizedType, in1Type, in2Type);
        if (pojoType != null) {
            return pojoType;
        }
    } catch (InvalidTypesException e) {
        if (LOG.isDebugEnabled()) {
            LOG.debug(""Unable to handle type "" + clazz + "" as POJO. Message: "" + e.getMessage(), e);
        }
    // ignore and create generic type info
    }
    // return a generic type
    return new GenericTypeInfo<OUT>(clazz);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2460_a17d4e82,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/SpillableSubpartitionView.java,67,126,"@Override
public Buffer getNextBuffer() throws IOException, InterruptedException {
    if (isReleased.get()) {
        return null;
    }
    // 1) In-memory
    synchronized (parent.buffers) {
        if (parent.isReleased) {
            return null;
        }
        if (parent.spillWriter == null) {
            if (currentQueuePosition < numberOfBuffers) {
                Buffer buffer = parent.buffers.get(currentQueuePosition);
                buffer.retain();
                // TODO Fix hard coding of 8 bytes for the header
                currentBytesRead += buffer.getSize() + 8;
                currentQueuePosition++;
                return buffer;
            }
            return null;
        }
    }
    // 2) Spilled
    if (spilledView != null) {
        return spilledView.getNextBuffer();
    }
    // because this might be called from an network I/O thread.
    if (parent.spillWriter.getNumberOfOutstandingRequests() > 0) {
        return null;
    }
    if (ioMode.isSynchronous()) {
        spilledView = new SpilledSubpartitionViewSyncIO(parent, bufferProvider.getMemorySegmentSize(), parent.spillWriter.getChannelID(), currentBytesRead);
    } else {
        spilledView = new SpilledSubpartitionViewAsyncIO(parent, bufferProvider, parent.ioManager, parent.spillWriter.getChannelID(), currentBytesRead);
    }
    return spilledView.getNextBuffer();
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2460_a17d4e82,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/SpillableSubpartitionView.java,163,166,"@Override
public boolean isReleased() {
    return isReleased.get();
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2460_a17d4e82,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/SpilledSubpartitionViewAsyncIO.java,188,191,"@Override
public boolean isReleased() {
    return isReleased;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2460_a17d4e82,Major,flink-runtime/src/main/java/org/apache/flink/runtime/io/network/partition/SpilledSubpartitionViewSyncIO.java,109,112,"@Override
public boolean isReleased() {
    return isReleased.get();
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2484_d738430c,Blocker,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/io/BarrierBuffer.java,97,139,"// ------------------------------------------------------------------------
// Buffer and barrier handling
// ------------------------------------------------------------------------
@Override
public BufferOrEvent getNextNonBlocked() throws IOException, InterruptedException {
    while (true) {
        // process buffered BufferOrEvents before grabbing new ones
        BufferOrEvent next;
        if (currentBuffered != null) {
            next = currentBuffered.getNext();
            if (next == null) {
                currentBuffered = queuedBuffered.pollFirst();
                if (currentBuffered != null) {
                    currentBuffered.open();
                }
                return getNextNonBlocked();
            }
        } else {
            next = inputGate.getNextBufferOrEvent();
        }
        if (next != null) {
            if (isBlocked(next.getChannelIndex())) {
                // if the channel is blocked we, we just store the BufferOrEvent
                bufferSpiller.add(next);
            } else if (next.isBuffer() || next.getEvent().getClass() != CheckpointBarrier.class) {
                return next;
            } else if (!endOfStream) {
                // process barriers only if there is a chance of the checkpoint completing
                processBarrier((CheckpointBarrier) next.getEvent(), next.getChannelIndex());
            }
        } else if (!endOfStream) {
            // end of stream. we feed the data that is still buffered
            endOfStream = true;
            releaseBlocks();
            return getNextNonBlocked();
        } else {
            return null;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2515_06e2da35,Blocker,flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/CheckpointCoordinator.java,212,310,"/**
 *  Triggers a new checkpoint and uses the given timestamp as the checkpoint
 *  timestamp.
 *
 *  @param timestamp The timestamp for the checkpoint.
 */
public boolean triggerCheckpoint(final long timestamp) {
    if (shutdown) {
        LOG.error(""Cannot trigger checkpoint, checkpoint coordinator has been shutdown."");
        return false;
    }
    final long checkpointID = checkpointIdCounter.getAndIncrement();
    LOG.info(""Triggering checkpoint "" + checkpointID + "" @ "" + timestamp);
    try {
        // first check if all tasks that we need to trigger are running.
        // if not, abort the checkpoint
        ExecutionAttemptID[] triggerIDs = new ExecutionAttemptID[tasksToTrigger.length];
        for (int i = 0; i < tasksToTrigger.length; i++) {
            Execution ee = tasksToTrigger[i].getCurrentExecutionAttempt();
            if (ee != null) {
                triggerIDs[i] = ee.getAttemptId();
            } else {
                LOG.info(""Checkpoint triggering task {} is not being executed at the moment. Aborting checkpoint."", tasksToTrigger[i].getSimpleName());
                return false;
            }
        }
        // next, check if all tasks that need to acknowledge the checkpoint are running.
        // if not, abort the checkpoint
        Map<ExecutionAttemptID, ExecutionVertex> ackTasks = new HashMap<ExecutionAttemptID, ExecutionVertex>(tasksToWaitFor.length);
        for (ExecutionVertex ev : tasksToWaitFor) {
            Execution ee = ev.getCurrentExecutionAttempt();
            if (ee != null) {
                ackTasks.put(ee.getAttemptId(), ev);
            } else {
                LOG.info(""Checkpoint acknowledging task {} is not being executed at the moment. Aborting checkpoint."", ev.getSimpleName());
                return false;
            }
        }
        // register a new pending checkpoint. this makes sure we can properly receive acknowledgements
        final PendingCheckpoint checkpoint = new PendingCheckpoint(job, checkpointID, timestamp, ackTasks);
        // schedule the timer that will clean up the expired checkpoints
        TimerTask canceller = new TimerTask() {

            @Override
            public void run() {
                try {
                    synchronized (lock) {
                        // note that checkpoint completion discards the pending checkpoint object
                        if (!checkpoint.isDiscarded()) {
                            LOG.info(""Checkpoint "" + checkpointID + "" expired before completing."");
                            checkpoint.discard(userClassLoader, true);
                            pendingCheckpoints.remove(checkpointID);
                            rememberRecentCheckpointId(checkpointID);
                        }
                    }
                } catch (Throwable t) {
                    LOG.error(""Exception while handling checkpoint timeout"", t);
                }
            }
        };
        synchronized (lock) {
            if (shutdown) {
                throw new IllegalStateException(""Checkpoint coordinator has been shutdown."");
            }
            pendingCheckpoints.put(checkpointID, checkpoint);
            timer.schedule(canceller, checkpointTimeout);
        }
        // send the messages to the tasks that trigger their checkpoint
        for (int i = 0; i < tasksToTrigger.length; i++) {
            ExecutionAttemptID id = triggerIDs[i];
            TriggerCheckpoint message = new TriggerCheckpoint(job, id, checkpointID, timestamp);
            tasksToTrigger[i].sendMessageToCurrentExecution(message, id);
        }
        numUnsuccessfulCheckpointsTriggers.set(0);
        return true;
    } catch (Throwable t) {
        int numUnsuccessful = numUnsuccessfulCheckpointsTriggers.incrementAndGet();
        LOG.warn(""Failed to trigger checkpoint ("" + numUnsuccessful + "" consecutive failed attempts so far)"", t);
        synchronized (lock) {
            PendingCheckpoint checkpoint = pendingCheckpoints.remove(checkpointID);
            if (checkpoint != null && !checkpoint.isDiscarded()) {
                checkpoint.discard(userClassLoader, true);
            }
        }
        return false;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2567_948b6e05,Minor,flink-core/src/main/java/org/apache/flink/api/common/io/GenericCsvInputFormat.java,437,477,"protected int skipFields(byte[] bytes, int startPos, int limit, byte[] delim) {
    int i = startPos;
    final int delimLimit = limit - delim.length + 1;
    if (quotedStringParsing == true && bytes[i] == quoteCharacter) {
        // quoted string parsing enabled and field is quoted
        // search for ending quote character
        i++;
        while (i < limit && bytes[i] != quoteCharacter) {
            i++;
        }
        i++;
        if (i == limit) {
            // we are at the end of the record
            return limit;
        } else if (i < delimLimit && FieldParser.delimiterNext(bytes, i, delim)) {
            // we are not at the end, check if delimiter comes next
            return i + delim.length;
        } else {
            // delimiter did not follow end quote. Error...
            return -1;
        }
    } else {
        // field is not quoted
        while (i < delimLimit && !FieldParser.delimiterNext(bytes, i, delim)) {
            i++;
        }
        if (i >= delimLimit) {
            // no delimiter found. We are at the end of the record
            return limit;
        } else {
            // delimiter found.
            return i + delim.length;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2567_948b6e05,Minor,flink-core/src/main/java/org/apache/flink/types/parser/StringParser.java,38,91,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, String reusable) {
    int i = startPos;
    final int delimLimit = limit - delimiter.length + 1;
    if (quotedStringParsing && bytes[i] == quoteCharacter) {
        // quoted string parsing enabled and first character Vis a quote
        i++;
        // search for ending quote character
        while (i < limit && bytes[i] != quoteCharacter) {
            i++;
        }
        if (i == limit) {
            setErrorState(ParseErrorState.UNTERMINATED_QUOTED_STRING);
            return -1;
        } else {
            i++;
            // check for proper termination
            if (i == limit) {
                // either by end of line
                this.result = new String(bytes, startPos + 1, i - startPos - 2);
                return limit;
            } else if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
                // or following field delimiter
                this.result = new String(bytes, startPos + 1, i - startPos - 2);
                return i + delimiter.length;
            } else {
                // no proper termination
                setErrorState(ParseErrorState.UNQUOTED_CHARS_AFTER_QUOTED_STRING);
                return -1;
            }
        }
    } else {
        // look for delimiter
        while (i < delimLimit && !delimiterNext(bytes, i, delimiter)) {
            i++;
        }
        if (i >= delimLimit) {
            // no delimiter found. Take the full string
            this.result = new String(bytes, startPos, limit - startPos);
            return limit;
        } else {
            // delimiter found.
            this.result = new String(bytes, startPos, i - startPos);
            return i + delimiter.length;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2567_948b6e05,Minor,flink-core/src/main/java/org/apache/flink/types/parser/StringValueParser.java,42,98,"@Override
public int parseField(byte[] bytes, int startPos, int limit, byte[] delimiter, StringValue reusable) {
    this.result = reusable;
    int i = startPos;
    final int delimLimit = limit - delimiter.length + 1;
    if (quotedStringParsing == true && bytes[i] == quoteCharacter) {
        // quoted string parsing enabled and first character is a quote
        i++;
        // search for ending quote character
        while (i < limit && bytes[i] != quoteCharacter) {
            i++;
        }
        if (i == limit) {
            setErrorState(ParseErrorState.UNTERMINATED_QUOTED_STRING);
            return -1;
        } else {
            i++;
            // check for proper termination
            if (i == limit) {
                // either by end of line
                reusable.setValueAscii(bytes, startPos + 1, i - startPos - 2);
                return limit;
            } else if (i < delimLimit && delimiterNext(bytes, i, delimiter)) {
                // or following field delimiter
                reusable.setValueAscii(bytes, startPos + 1, i - startPos - 2);
                return i + delimiter.length;
            } else {
                // no proper termination
                setErrorState(ParseErrorState.UNQUOTED_CHARS_AFTER_QUOTED_STRING);
                return -1;
            }
        }
    } else {
        // look for delimiter
        while (i < delimLimit && !delimiterNext(bytes, i, delimiter)) {
            i++;
        }
        if (i >= delimLimit) {
            // no delimiter found. Take the full string
            reusable.setValueAscii(bytes, startPos, limit - startPos);
            return limit;
        } else {
            // delimiter found.
            reusable.setValueAscii(bytes, startPos, i - startPos);
            return i + delimiter.length;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2658_ce68cbd9,Major,flink-contrib/flink-storm-compatibility/flink-storm-compatibility-core/src/main/java/org/apache/flink/stormcompatibility/api/FlinkTopologyBuilder.java,79,273,"/**
 *  Creates a Flink program that uses the specified spouts and bolts.
 */
@SuppressWarnings({ ""rawtypes"", ""unchecked"" })
public FlinkTopology createTopology() {
    final StormTopology stormTopolgoy = this.stormBuilder.createTopology();
    final FlinkTopology env = new FlinkTopology(stormTopolgoy);
    env.setParallelism(1);
    final HashMap<String, HashMap<String, DataStream>> availableInputs = new HashMap<String, HashMap<String, DataStream>>();
    for (final Entry<String, IRichSpout> spout : this.spouts.entrySet()) {
        final String spoutId = spout.getKey();
        final IRichSpout userSpout = spout.getValue();
        final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();
        userSpout.declareOutputFields(declarer);
        final HashMap<String, Fields> sourceStreams = declarer.outputStreams;
        this.outputStreams.put(spoutId, sourceStreams);
        declarers.put(spoutId, declarer);
        AbstractStormSpoutWrapper spoutWrapper;
        if (userSpout instanceof FiniteStormSpout) {
            spoutWrapper = new FiniteStormSpoutWrapper((FiniteStormSpout) userSpout);
        } else {
            spoutWrapper = new StormSpoutWrapper(userSpout);
        }
        DataStreamSource source;
        HashMap<String, DataStream> outputStreams = new HashMap<String, DataStream>();
        if (sourceStreams.size() == 1) {
            final String outputStreamId = (String) sourceStreams.keySet().toArray()[0];
            source = env.addSource(spoutWrapper, spoutId, declarer.getOutputType(outputStreamId));
            outputStreams.put(outputStreamId, source);
        } else {
            source = env.addSource(spoutWrapper, spoutId, TypeExtractor.getForClass(SplitStreamType.class));
            SplitDataStream splitSource = source.split(new FlinkStormStreamSelector());
            for (String streamId : sourceStreams.keySet()) {
                outputStreams.put(streamId, splitSource.select(streamId));
            }
        }
        availableInputs.put(spoutId, outputStreams);
        int dop = 1;
        final ComponentCommon common = stormTopolgoy.get_spouts().get(spoutId).get_common();
        if (common.is_set_parallelism_hint()) {
            dop = common.get_parallelism_hint();
            source.setParallelism(dop);
        }
        env.increaseNumberOfTasks(dop);
    }
    final HashMap<String, IRichBolt> unprocessedBolts = new HashMap<String, IRichBolt>();
    unprocessedBolts.putAll(this.bolts);
    final HashMap<String, Set<Entry<GlobalStreamId, Grouping>>> unprocessdInputsPerBolt = new HashMap<String, Set<Entry<GlobalStreamId, Grouping>>>();
    /* Because we do not know the order in which an iterator steps over a set, we might process a consumer before
		 * its producer
		 * ->thus, we might need to repeat multiple times
		 */
    boolean makeProgress = true;
    while (unprocessedBolts.size() > 0) {
        if (!makeProgress) {
            throw new RuntimeException(""Unable to build Topology. Could not connect the following bolts: "" + unprocessedBolts.keySet());
        }
        makeProgress = false;
        final Iterator<Entry<String, IRichBolt>> boltsIterator = unprocessedBolts.entrySet().iterator();
        while (boltsIterator.hasNext()) {
            final Entry<String, IRichBolt> bolt = boltsIterator.next();
            final String boltId = bolt.getKey();
            final IRichBolt userBolt = bolt.getValue();
            final ComponentCommon common = stormTopolgoy.get_bolts().get(boltId).get_common();
            Set<Entry<GlobalStreamId, Grouping>> unprocessedInputs = unprocessdInputsPerBolt.get(boltId);
            if (unprocessedInputs == null) {
                unprocessedInputs = new HashSet<Entry<GlobalStreamId, Grouping>>();
                unprocessedInputs.addAll(common.get_inputs().entrySet());
                unprocessdInputsPerBolt.put(boltId, unprocessedInputs);
            }
            // connect each available producer to the current bolt
            final Iterator<Entry<GlobalStreamId, Grouping>> inputStreamsIterator = unprocessedInputs.iterator();
            while (inputStreamsIterator.hasNext()) {
                final Entry<GlobalStreamId, Grouping> stormInputStream = inputStreamsIterator.next();
                final String producerId = stormInputStream.getKey().get_componentId();
                final String inputStreamId = stormInputStream.getKey().get_streamId();
                HashMap<String, DataStream> producer = availableInputs.get(producerId);
                if (producer != null) {
                    makeProgress = true;
                    DataStream inputStream = producer.get(inputStreamId);
                    if (inputStream != null) {
                        final FlinkOutputFieldsDeclarer declarer = new FlinkOutputFieldsDeclarer();
                        userBolt.declareOutputFields(declarer);
                        final HashMap<String, Fields> boltOutputStreams = declarer.outputStreams;
                        this.outputStreams.put(boltId, boltOutputStreams);
                        this.declarers.put(boltId, declarer);
                        // if producer was processed already
                        final Grouping grouping = stormInputStream.getValue();
                        if (grouping.is_set_shuffle()) {
                            // Storm uses a round-robin shuffle strategy
                            inputStream = inputStream.rebalance();
                        } else if (grouping.is_set_fields()) {
                            // global grouping is emulated in Storm via an empty fields grouping list
                            final List<String> fields = grouping.get_fields();
                            if (fields.size() > 0) {
                                FlinkOutputFieldsDeclarer prodDeclarer = this.declarers.get(producerId);
                                inputStream = inputStream.groupBy(prodDeclarer.getGroupingFieldIndexes(inputStreamId, grouping.get_fields()));
                            } else {
                                inputStream = inputStream.global();
                            }
                        } else if (grouping.is_set_all()) {
                            inputStream = inputStream.broadcast();
                        } else if (!grouping.is_set_local_or_shuffle()) {
                            throw new UnsupportedOperationException(""Flink only supports (local-or-)shuffle, fields, all, and global grouping"");
                        }
                        SingleOutputStreamOperator outputStream;
                        if (boltOutputStreams.size() < 2) {
                            // single output stream or sink
                            String outputStreamId = null;
                            if (boltOutputStreams.size() == 1) {
                                outputStreamId = (String) boltOutputStreams.keySet().toArray()[0];
                            }
                            final TypeInformation<?> outType = declarer.getOutputType(outputStreamId);
                            outputStream = inputStream.transform(boltId, outType, new StormBoltWrapper(userBolt, this.outputStreams.get(producerId).get(inputStreamId)));
                            if (outType != null) {
                                // only for non-sink nodes
                                HashMap<String, DataStream> op = new HashMap<String, DataStream>();
                                op.put(outputStreamId, outputStream);
                                availableInputs.put(boltId, op);
                            }
                        } else {
                            final TypeInformation<?> outType = TypeExtractor.getForClass(SplitStreamType.class);
                            outputStream = inputStream.transform(boltId, outType, new StormBoltWrapper(userBolt, this.outputStreams.get(producerId).get(inputStreamId)));
                            SplitDataStream splitStreams = outputStream.split(new FlinkStormStreamSelector());
                            HashMap<String, DataStream> op = new HashMap<String, DataStream>();
                            for (String outputStreamId : boltOutputStreams.keySet()) {
                                op.put(outputStreamId, splitStreams.select(outputStreamId));
                            }
                            availableInputs.put(boltId, op);
                        }
                        int dop = 1;
                        if (common.is_set_parallelism_hint()) {
                            dop = common.get_parallelism_hint();
                            outputStream.setParallelism(dop);
                        }
                        env.increaseNumberOfTasks(dop);
                        inputStreamsIterator.remove();
                    } else {
                        throw new RuntimeException(""Cannot connect '"" + boltId + ""' to '"" + producerId + ""'. Stream '"" + inputStreamId + ""' not found."");
                    }
                }
            }
            if (unprocessedInputs.size() == 0) {
                // all inputs are connected; processing bolt completed
                boltsIterator.remove();
            }
        }
    }
    return env;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2707_3e233a38,Major,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamingRuntimeContext.java,99,111,"@SuppressWarnings(""unchecked"")
@Override
public <S, C extends Serializable> OperatorState<S> getOperatorState(String name, S defaultState, boolean partitioned, StateCheckpointer<S, C> checkpointer) throws IOException {
    if (defaultState == null) {
        throw new RuntimeException(""Cannot set default state to null."");
    }
    StreamOperatorState<S, C> state = (StreamOperatorState<S, C>) getState(name, partitioned);
    state.setDefaultState(defaultState);
    state.setCheckpointer(checkpointer);
    return (OperatorState<S>) state;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2713_63d9800e,Major,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/state/PartitionedStreamOperatorState.java,73,96,"@SuppressWarnings(""unchecked"")
@Override
public S value() throws IOException {
    if (currentInput == null) {
        throw new IllegalStateException(""Need a valid input for accessing the state."");
    } else {
        Serializable key;
        try {
            key = keySelector.getKey(currentInput);
        } catch (Exception e) {
            throw new RuntimeException(""User-defined key selector threw an exception."", e);
        }
        if (stateStore.containsKey(key)) {
            return stateStore.getStateForKey(key);
        } else {
            try {
                return (S) checkpointer.restoreState((C) InstantiationUtil.deserializeObject(defaultState, cl));
            } catch (ClassNotFoundException e) {
                throw new RuntimeException(""Could not deserialize default state value."", e);
            }
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2713_63d9800e,Major,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/state/PartitionedStreamOperatorState.java,98,117,"@Override
public void update(S state) throws IOException {
    if (currentInput == null) {
        throw new IllegalStateException(""Need a valid input for updating a state."");
    } else {
        Serializable key;
        try {
            key = keySelector.getKey(currentInput);
        } catch (Exception e) {
            throw new RuntimeException(""User-defined key selector threw an exception."");
        }
        if (state == null) {
            // Remove state if set to null
            stateStore.removeStateForKey(key);
        } else {
            stateStore.setStateForKey(key, state);
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2713_63d9800e,Major,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/state/PartitionedStreamOperatorState.java,132,135,"@Override
public StateHandle<Serializable> snapshotState(long checkpointId, long checkpointTimestamp) throws Exception {
    return stateStore.snapshotStates(checkpointId, checkpointTimestamp);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2713_63d9800e,Major,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/state/PartitionedStreamOperatorState.java,137,140,"@Override
public void restoreState(StateHandle<Serializable> snapshots, ClassLoader userCodeClassLoader) throws Exception {
    stateStore.restoreStates(snapshots, userCodeClassLoader);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2713_63d9800e,Major,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/state/StreamOperatorState.java,60,63,"@Override
public S value() throws IOException {
    return state;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2713_63d9800e,Major,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/state/StreamOperatorState.java,65,71,"@Override
public void update(S state) throws IOException {
    if (state == null) {
        throw new RuntimeException(""Cannot set state to null."");
    }
    this.state = state;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2713_63d9800e,Major,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/state/StreamOperatorState.java,91,96,"public StateHandle<Serializable> snapshotState(long checkpointId, long checkpointTimestamp) throws Exception {
    return provider.createStateHandle(checkpointer.snapshotState(value(), checkpointId, checkpointTimestamp));
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2713_63d9800e,Major,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/state/StreamOperatorState.java,98,101,"@SuppressWarnings(""unchecked"")
public void restoreState(StateHandle<Serializable> snapshot, ClassLoader userCodeClassLoader) throws Exception {
    update(checkpointer.restoreState((C) snapshot.getState(userCodeClassLoader)));
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2734_8b40bb7a,Critical,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/environment/StreamExecutionEnvironment.java,1229,1233,"// TODO:fix cluster default parallelism
/**
 *  Creates a {@link RemoteStreamEnvironment}. The remote environment sends
 *  (parts of) the program to a cluster for execution. Note that all file
 *  paths used in the program must be accessible from the cluster. The
 *  execution will use no parallelism, unless the parallelism is set
 *  explicitly via {@link #setParallelism}.
 *
 *  @param host
 *  		The host name or address of the master (JobManager), where the
 *  		program should be executed.
 *  @param port
 *  		The port of the master (JobManager), where the program should
 *  		be executed.
 *  @param jarFiles
 *  		The JAR files with code that needs to be shipped to the
 *  		cluster. If the program uses user-defined functions,
 *  		user-defined input formats, or any libraries, those must be
 *  		provided in the JAR files.
 *  @return A remote environment that executes the program on a cluster.
 */
public static StreamExecutionEnvironment createRemoteEnvironment(String host, int port, String... jarFiles) {
    RemoteStreamEnvironment env = new RemoteStreamEnvironment(host, port, jarFiles);
    return env;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2734_8b40bb7a,Critical,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/environment/StreamExecutionEnvironment.java,1297,1303,"/**
 *  Getter of the {@link org.apache.flink.streaming.api.graph.StreamGraph} of the streaming job.
 *
 *  @return The streamgraph representing the transformations
 */
public StreamGraph getStreamGraph() {
    if (transformations.size() <= 0) {
        throw new IllegalStateException(""No operators defined in streaming topology. Cannot execute."");
    }
    StreamGraph result = StreamGraphGenerator.generate(this, transformations);
    return result;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2734_8b40bb7a,Critical,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/util/keys/KeySelectorUtil.java,130,138,"@Override
public Tuple getKey(IN value) throws Exception {
    key = (Tuple) tupleClasses[keyLength - 1].newInstance();
    comparator.extractKeys(value, keyArray, 0);
    for (int i = 0; i < keyLength; i++) {
        key.setField(keyArray[i], i);
    }
    return key;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2734_8b40bb7a,Critical,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/util/keys/KeySelectorUtil.java,153,161,"@Override
public Tuple getKey(IN value) throws Exception {
    key = (Tuple) tupleClasses[fields.length - 1].newInstance();
    for (int i = 0; i < fields.length; i++) {
        int pos = fields[i];
        key.setField(Array.get(value, fields[pos]), i);
    }
    return key;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2754_68912126,Major,flink-runtime/src/main/java/org/apache/flink/runtime/operators/sort/FixedLengthRecordSorter.java,424,456,"/**
 *  Writes a subset of the records in this buffer in their logical order to the given output.
 *
 *  @param output The output view to write the records to.
 *  @param start The logical start position of the subset.
 *  @param num The number of elements to write.
 *  @throws IOException Thrown, if an I/O exception occurred writing to the output view.
 */
@Override
public void writeToOutput(final ChannelWriterOutputView output, final int start, int num) throws IOException {
    final TypeComparator<T> comparator = this.comparator;
    final TypeSerializer<T> serializer = this.serializer;
    T record = this.recordInstance;
    final SingleSegmentInputView inView = this.inView;
    final int recordsPerSegment = this.recordsPerSegment;
    int currentMemSeg = start / recordsPerSegment;
    int offset = (start % recordsPerSegment) * this.recordSize;
    while (num > 0) {
        final MemorySegment currentIndexSegment = this.sortBuffer.get(currentMemSeg++);
        inView.set(currentIndexSegment, offset);
        // check whether we have a full or partially full segment
        if (num >= recordsPerSegment && offset == 0) {
            // full segment
            for (int numInMemSeg = 0; numInMemSeg < recordsPerSegment; numInMemSeg++) {
                record = comparator.readWithKeyDenormalization(record, inView);
                serializer.serialize(record, output);
            }
            num -= recordsPerSegment;
        } else {
            // partially filled segment
            for (; num > 0; num--) {
                record = comparator.readWithKeyDenormalization(record, inView);
                serializer.serialize(record, output);
            }
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2763_af477563,Major,flink-runtime/src/main/java/org/apache/flink/runtime/operators/hash/HashPartition.java,278,305,"/**
 *  Spills this partition to disk and sets it up such that it continues spilling records that are added to
 *  it. The spilling process must free at least one buffer, either in the partition's record buffers, or in
 *  the memory segments for overflow buckets.
 *  The partition immediately takes back one buffer to use it for further spilling.
 *
 *  @param target The list to which memory segments from overflow buckets are added.
 *  @param ioAccess The I/O manager to be used to create a writer to disk.
 *  @param targetChannel The id of the target channel for this partition.
 *  @return The number of buffers that were freed by spilling this partition.
 *  @throws IOException Thrown, if the writing failed.
 */
public int spillPartition(List<MemorySegment> target, IOManager ioAccess, FileIOChannel.ID targetChannel, LinkedBlockingQueue<MemorySegment> bufferReturnQueue) throws IOException {
    // sanity checks
    if (!isInMemory()) {
        throw new RuntimeException(""Bug in Hybrid Hash Join: "" + ""Request to spill a partition that has already been spilled."");
    }
    if (getBuildSideBlockCount() + this.numOverflowSegments < 2) {
        throw new RuntimeException(""Bug in Hybrid Hash Join: "" + ""Request to spill a partition with less than two buffers."");
    }
    // return the memory from the overflow segments
    for (int i = 0; i < this.numOverflowSegments; i++) {
        target.add(this.overflowSegments[i]);
    }
    this.overflowSegments = null;
    this.numOverflowSegments = 0;
    this.nextOverflowBucket = 0;
    // create the channel block writer and spill the current buffers
    // that keep the build side buffers current block, as it is most likely not full, yet
    // we return the number of blocks that become available
    this.buildSideChannel = ioAccess.createBlockChannelWriter(targetChannel, bufferReturnQueue);
    return this.buildSideWriteBuffer.spill(this.buildSideChannel);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2763_af477563,Major,flink-runtime/src/main/java/org/apache/flink/runtime/operators/hash/MutableHashTable.java,1088,1118,"// --------------------------------------------------------------------------------------------
// Memory Handling
// --------------------------------------------------------------------------------------------
/**
 *  Selects a partition and spills it. The number of the spilled partition is returned.
 *
 *  @return The number of the spilled partition.
 */
protected int spillPartition() throws IOException {
    // find the largest partition
    ArrayList<HashPartition<BT, PT>> partitions = this.partitionsBeingBuilt;
    int largestNumBlocks = 0;
    int largestPartNum = -1;
    for (int i = 0; i < partitions.size(); i++) {
        HashPartition<BT, PT> p = partitions.get(i);
        if (p.isInMemory() && p.getBuildSideBlockCount() > largestNumBlocks) {
            largestNumBlocks = p.getBuildSideBlockCount();
            largestPartNum = i;
        }
    }
    final HashPartition<BT, PT> p = partitions.get(largestPartNum);
    if (useBloomFilters) {
        buildBloomFilterForBucketsInPartition(largestPartNum, p);
    }
    // spill the partition
    int numBuffersFreed = p.spillPartition(this.availableMemory, this.ioManager, this.currentEnumerator.next(), this.writeBehindBuffers);
    this.writeBehindBuffersAvailable += numBuffersFreed;
    // grab as many buffers as are available directly
    MemorySegment currBuff;
    while (this.writeBehindBuffersAvailable > 0 && (currBuff = this.writeBehindBuffers.poll()) != null) {
        this.availableMemory.add(currBuff);
        this.writeBehindBuffersAvailable--;
    }
    return largestPartNum;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2800_b654e989,Major,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/kryo/KryoSerializer.java,176,198,"@Override
public void serialize(T record, DataOutputView target) throws IOException {
    checkKryoInitialized();
    if (target != previousOut) {
        DataOutputViewStream outputStream = new DataOutputViewStream(target);
        output = new Output(outputStream);
        previousOut = target;
    }
    try {
        kryo.writeClassAndObject(output, record);
        output.flush();
    } catch (KryoException ke) {
        Throwable cause = ke.getCause();
        if (cause instanceof EOFException) {
            throw (EOFException) cause;
        } else {
            throw ke;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2802_88a97768,Blocker,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/io/StreamInputProcessor.java,128,200,"@SuppressWarnings(""unchecked"")
public boolean processInput(OneInputStreamOperator<IN, ?> streamOperator, Object lock) throws Exception {
    if (isFinished) {
        return false;
    }
    while (true) {
        if (currentRecordDeserializer != null) {
            DeserializationResult result = currentRecordDeserializer.getNextRecord(deserializationDelegate);
            if (result.isBufferConsumed()) {
                currentRecordDeserializer.getCurrentBuffer().recycle();
                currentRecordDeserializer = null;
            }
            if (result.isFullRecord()) {
                StreamElement recordOrWatermark = deserializationDelegate.getInstance();
                if (recordOrWatermark.isWatermark()) {
                    long watermarkMillis = recordOrWatermark.asWatermark().getTimestamp();
                    if (watermarkMillis > watermarks[currentChannel]) {
                        watermarks[currentChannel] = watermarkMillis;
                        long newMinWatermark = Long.MAX_VALUE;
                        for (long watermark : watermarks) {
                            newMinWatermark = Math.min(watermark, newMinWatermark);
                        }
                        if (newMinWatermark > lastEmittedWatermark) {
                            lastEmittedWatermark = newMinWatermark;
                            synchronized (lock) {
                                streamOperator.processWatermark(new Watermark(lastEmittedWatermark));
                            }
                        }
                    }
                    continue;
                } else {
                    // now we can do the actual processing
                    StreamRecord<IN> record = recordOrWatermark.asRecord();
                    StreamingRuntimeContext ctx = streamOperator.getRuntimeContext();
                    synchronized (lock) {
                        if (ctx != null) {
                            ctx.setNextInput(record);
                        }
                        streamOperator.processElement(record);
                    }
                    return true;
                }
            }
        }
        final BufferOrEvent bufferOrEvent = barrierHandler.getNextNonBlocked();
        if (bufferOrEvent != null) {
            if (bufferOrEvent.isBuffer()) {
                currentChannel = bufferOrEvent.getChannelIndex();
                currentRecordDeserializer = recordDeserializers[currentChannel];
                currentRecordDeserializer.setNextBuffer(bufferOrEvent.getBuffer());
            } else {
                // Event received
                final AbstractEvent event = bufferOrEvent.getEvent();
                if (event.getClass() != EndOfPartitionEvent.class) {
                    throw new IOException(""Unexpected event: "" + event);
                }
            }
        } else {
            isFinished = true;
            if (!barrierHandler.isEmpty()) {
                throw new IllegalStateException(""Trailing data in checkpoint barrier handler."");
            }
            return false;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2802_88a97768,Blocker,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamIterationHead.java,41,88,"// ------------------------------------------------------------------------
@Override
protected void run() throws Exception {
    final String iterationId = configuration.getIterationId();
    if (iterationId == null || iterationId.length() == 0) {
        throw new Exception(""Missing iteration ID in the task configuration"");
    }
    final String brokerID = createBrokerIdString(getEnvironment().getJobID(), iterationId, getEnvironment().getIndexInSubtaskGroup());
    final long iterationWaitTime = configuration.getIterationWaitTime();
    final boolean shouldWait = iterationWaitTime > 0;
    final BlockingQueue<StreamRecord<OUT>> dataChannel = new ArrayBlockingQueue<StreamRecord<OUT>>(1);
    // offer the queue for the tail
    BlockingQueueBroker.INSTANCE.handIn(brokerID, dataChannel);
    LOG.info(""Iteration head {} added feedback queue under {}"", getName(), brokerID);
    // do the work
    try {
        @SuppressWarnings(""unchecked"")
        Collection<RecordWriterOutput<OUT>> outputs = (Collection<RecordWriterOutput<OUT>>) (Collection<?>) outputHandler.getOutputs();
        while (running) {
            StreamRecord<OUT> nextRecord = shouldWait ? dataChannel.poll(iterationWaitTime, TimeUnit.MILLISECONDS) : dataChannel.take();
            if (nextRecord != null) {
                for (RecordWriterOutput<OUT> output : outputs) {
                    output.collect(nextRecord);
                }
            } else {
                // done
                break;
            }
        }
    } finally {
        // make sure that we remove the queue from the broker, to prevent a resource leak
        BlockingQueueBroker.INSTANCE.remove(brokerID);
        LOG.info(""Iteration head {} removed feedback queue under {}"", getName(), brokerID);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2812_e494c279,Minor,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/util/keys/KeySelectorUtil.java,37,56,"public static <X> KeySelector<X, Tuple> getSelectorForKeys(Keys<X> keys, TypeInformation<X> typeInfo, ExecutionConfig executionConfig) {
    if (!(typeInfo instanceof CompositeType)) {
        throw new InvalidTypesException(""This key operation requires a composite type such as Tuples, POJOs, or Case Classes."");
    }
    CompositeType<X> compositeType = (CompositeType<X>) typeInfo;
    int[] logicalKeyPositions = keys.computeLogicalKeyPositions();
    int numKeyFields = logicalKeyPositions.length;
    // use ascending order here, the code paths for that are usually a slight bit faster
    boolean[] orders = new boolean[numKeyFields];
    for (int i = 0; i < numKeyFields; i++) {
        orders[i] = true;
    }
    TypeComparator<X> comparator = compositeType.createComparator(logicalKeyPositions, orders, 0, executionConfig);
    return new ComparableKeySelector<X>(comparator, numKeyFields);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2812_e494c279,Minor,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/util/keys/KeySelectorUtil.java,59,74,"public static <X, K> KeySelector<X, K> getSelectorForOneKey(Keys<X> keys, Partitioner<K> partitioner, TypeInformation<X> typeInfo, ExecutionConfig executionConfig) {
    if (partitioner != null) {
        keys.validateCustomPartitioner(partitioner, null);
    }
    int[] logicalKeyPositions = keys.computeLogicalKeyPositions();
    if (logicalKeyPositions.length != 1) {
        throw new IllegalArgumentException(""There must be exactly 1 key specified"");
    }
    TypeComparator<X> comparator = ((CompositeType<X>) typeInfo).createComparator(logicalKeyPositions, new boolean[1], 0, executionConfig);
    return new OneKeySelector<X, K>(comparator);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2817_5dfc897b,Minor,flink-staging/flink-streaming/flink-streaming-core/src/main/java/org/apache/flink/streaming/api/functions/source/FileMonitoringFunction.java,93,109,"private List<String> listNewFiles(FileSystem fileSystem) throws IOException {
    List<String> files = new ArrayList<String>();
    FileStatus[] statuses = fileSystem.listStatus(new Path(path));
    for (FileStatus status : statuses) {
        Path filePath = status.getPath();
        String fileName = filePath.getName();
        long modificationTime = status.getModificationTime();
        if (!isFiltered(fileName, modificationTime)) {
            files.add(filePath.toString());
            modificationTimes.put(fileName, modificationTime);
        }
    }
    return files;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2874_17e7b423,Minor,flink-java/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,1297,1349,"/**
 *  Checks if the given field is a valid pojo field:
 *  - it is public
 *  OR
 *   - there are getter and setter methods for the field.
 *
 *  @param f field to check
 *  @param clazz class of field
 *  @param typeHierarchy type hierarchy for materializing generic types
 */
private boolean isValidPojoField(Field f, Class<?> clazz, ArrayList<Type> typeHierarchy) {
    if (Modifier.isPublic(f.getModifiers())) {
        return true;
    } else {
        boolean hasGetter = false, hasSetter = false;
        final String fieldNameLow = f.getName().toLowerCase();
        Type fieldType = f.getGenericType();
        TypeVariable<?> fieldTypeGeneric = null;
        if (fieldType instanceof TypeVariable) {
            fieldTypeGeneric = (TypeVariable<?>) fieldType;
            fieldType = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) fieldType);
        }
        for (Method m : clazz.getMethods()) {
            // check for getter
            if (// The name should be ""get<FieldName>"" or ""<fieldName>"" (for scala) or ""is<fieldName>"" for boolean fields.
            (m.getName().toLowerCase().equals(""get"" + fieldNameLow) || m.getName().toLowerCase().equals(""is"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow)) && // no arguments for the getter
            m.getParameterTypes().length == 0 && // return type is same as field type (or the generic variant of it)
            (m.getGenericReturnType().equals(fieldType) || (fieldTypeGeneric != null && m.getGenericReturnType().equals(fieldTypeGeneric)))) {
                if (hasGetter) {
                    throw new IllegalStateException(""Detected more than one getter"");
                }
                hasGetter = true;
            }
            // check for setters (<FieldName>_$eq for scala)
            if ((m.getName().toLowerCase().equals(""set"" + fieldNameLow) || m.getName().toLowerCase().equals(fieldNameLow + ""_$eq"")) && // one parameter of the field's type
            m.getParameterTypes().length == 1 && (m.getGenericParameterTypes()[0].equals(fieldType) || (fieldTypeGeneric != null && m.getGenericParameterTypes()[0].equals(fieldTypeGeneric))) && // return type is void.
            m.getReturnType().equals(Void.TYPE)) {
                if (hasSetter) {
                    throw new IllegalStateException(""Detected more than one setter"");
                }
                hasSetter = true;
            }
        }
        if (hasGetter && hasSetter) {
            return true;
        } else {
            if (!hasGetter) {
                LOG.debug(clazz + "" does not contain a getter for field "" + f.getName());
            }
            if (!hasSetter) {
                LOG.debug(clazz + "" does not contain a setter for field "" + f.getName());
            }
            return false;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2964_76bebd42,Critical,flink-runtime/src/main/java/org/apache/flink/runtime/operators/hash/HashPartition.java,208,212,"/**
 *  Gets the number of memory segments used by this partition, which includes build side
 *  memory buffers and overflow memory segments.
 *
 *  @return The number of occupied memory segments.
 */
public int getNumOccupiedMemorySegments() {
    // either the number of memory segments, or one for spilling
    final int numPartitionBuffers = this.partitionBuffers != null ? this.partitionBuffers.length : 1;
    return numPartitionBuffers + numOverflowSegments;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2968_59685903,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/NonKeyedWindowOperator.java,513,520,"@Override
public final void setOutputType(TypeInformation<OUT> outTypeInfo, ExecutionConfig executionConfig) {
    if (userFunction instanceof OutputTypeConfigurable) {
        @SuppressWarnings(""unchecked"")
        OutputTypeConfigurable<OUT> typeConfigurable = (OutputTypeConfigurable<OUT>) userFunction;
        typeConfigurable.setOutputType(outTypeInfo, executionConfig);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-2968_59685903,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java,582,589,"@Override
public final void setOutputType(TypeInformation<OUT> outTypeInfo, ExecutionConfig executionConfig) {
    if (userFunction instanceof OutputTypeConfigurable) {
        @SuppressWarnings(""unchecked"")
        OutputTypeConfigurable<OUT> typeConfigurable = (OutputTypeConfigurable<OUT>) userFunction;
        typeConfigurable.setOutputType(outTypeInfo, executionConfig);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3011_5a86a0a1,Critical,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java,702,719,"public void cancel() {
    while (true) {
        JobStatus current = state;
        if (current == JobStatus.RUNNING || current == JobStatus.CREATED) {
            if (transitionState(current, JobStatus.CANCELLING)) {
                for (ExecutionJobVertex ejv : verticesInCreationOrder) {
                    ejv.cancel();
                }
                return;
            }
        } else {
            // no need to treat other states
            return;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3011_5a86a0a1,Critical,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java,747,780,"public void restart() {
    try {
        synchronized (progressLock) {
            if (state != JobStatus.RESTARTING) {
                throw new IllegalStateException(""Can only restart job from state restarting."");
            }
            if (scheduler == null) {
                throw new IllegalStateException(""The execution graph has not been scheduled before - scheduler is null."");
            }
            this.currentExecutions.clear();
            for (ExecutionJobVertex jv : this.verticesInCreationOrder) {
                jv.resetForNewExecution();
            }
            for (int i = 0; i < stateTimestamps.length; i++) {
                stateTimestamps[i] = 0;
            }
            numFinishedJobVertices = 0;
            transitionState(JobStatus.RESTARTING, JobStatus.CREATED);
            // if we have checkpointed state, reload it into the executions
            if (checkpointCoordinator != null) {
                checkpointCoordinator.restoreLatestCheckpointedState(getAllVertices(), false, false);
            }
        }
        scheduleForExecution(scheduler);
    } catch (Throwable t) {
        fail(t);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3011_a402002d,Critical,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java,747,786,"public void restart() {
    try {
        if (state == JobStatus.FAILED) {
            if (!transitionState(JobStatus.FAILED, JobStatus.RESTARTING)) {
                throw new IllegalStateException(""Execution Graph left the state FAILED while trying to restart."");
            }
        }
        synchronized (progressLock) {
            if (state != JobStatus.RESTARTING) {
                throw new IllegalStateException(""Can only restart job from state restarting."");
            }
            if (scheduler == null) {
                throw new IllegalStateException(""The execution graph has not been scheduled before - scheduler is null."");
            }
            this.currentExecutions.clear();
            for (ExecutionJobVertex jv : this.verticesInCreationOrder) {
                jv.resetForNewExecution();
            }
            for (int i = 0; i < stateTimestamps.length; i++) {
                stateTimestamps[i] = 0;
            }
            numFinishedJobVertices = 0;
            transitionState(JobStatus.RESTARTING, JobStatus.CREATED);
            // if we have checkpointed state, reload it into the executions
            if (checkpointCoordinator != null) {
                checkpointCoordinator.restoreLatestCheckpointedState(getAllVertices(), false, false);
            }
        }
        scheduleForExecution(scheduler);
    } catch (Throwable t) {
        fail(t);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3052_8dc70f2e,Major,flink-optimizer/src/main/java/org/apache/flink/optimizer/dag/BulkIterationNode.java,277,381,"@Override
protected void instantiateCandidate(OperatorDescriptorSingle dps, Channel in, List<Set<? extends NamedChannel>> broadcastPlanChannels, List<PlanNode> target, CostEstimator estimator, RequestedGlobalProperties globPropsReq, RequestedLocalProperties locPropsReq) {
    // NOTES ON THE ENUMERATION OF THE STEP FUNCTION PLANS:
    // Whenever we instantiate the iteration, we enumerate new candidates for the step function.
    // That way, we make sure we have an appropriate plan for each candidate for the initial partial solution,
    // we have a fitting candidate for the step function (often, work is pushed out of the step function).
    // Among the candidates of the step function, we keep only those that meet the requested properties of the
    // current candidate initial partial solution. That makes sure these properties exist at the beginning of
    // the successive iteration.
    // 1) Because we enumerate multiple times, we may need to clean the cached plans
    // before starting another enumeration
    this.nextPartialSolution.accept(PlanCacheCleaner.INSTANCE);
    if (this.terminationCriterion != null) {
        this.terminationCriterion.accept(PlanCacheCleaner.INSTANCE);
    }
    // 2) Give the partial solution the properties of the current candidate for the initial partial solution
    this.partialSolution.setCandidateProperties(in.getGlobalProperties(), in.getLocalProperties(), in);
    final BulkPartialSolutionPlanNode pspn = this.partialSolution.getCurrentPartialSolutionPlanNode();
    // 3) Get the alternative plans
    List<PlanNode> candidates = this.nextPartialSolution.getAlternativePlans(estimator);
    // 4) Make sure that the beginning of the step function does not assume properties that
    // are not also produced by the end of the step function.
    {
        List<PlanNode> newCandidates = new ArrayList<PlanNode>();
        for (Iterator<PlanNode> planDeleter = candidates.iterator(); planDeleter.hasNext(); ) {
            PlanNode candidate = planDeleter.next();
            GlobalProperties atEndGlobal = candidate.getGlobalProperties();
            LocalProperties atEndLocal = candidate.getLocalProperties();
            FeedbackPropertiesMeetRequirementsReport report = candidate.checkPartialSolutionPropertiesMet(pspn, atEndGlobal, atEndLocal);
            if (report == FeedbackPropertiesMeetRequirementsReport.NO_PARTIAL_SOLUTION) {
                // depends only through broadcast variable on the partial solution
                ;
            } else if (report == FeedbackPropertiesMeetRequirementsReport.NOT_MET) {
                // attach a no-op node through which we create the properties of the original input
                Channel toNoOp = new Channel(candidate);
                globPropsReq.parameterizeChannel(toNoOp, false, rootConnection.getDataExchangeMode(), false);
                locPropsReq.parameterizeChannel(toNoOp);
                UnaryOperatorNode rebuildPropertiesNode = new UnaryOperatorNode(""Rebuild Partial Solution Properties"", FieldList.EMPTY_LIST);
                rebuildPropertiesNode.setParallelism(candidate.getParallelism());
                SingleInputPlanNode rebuildPropertiesPlanNode = new SingleInputPlanNode(rebuildPropertiesNode, ""Rebuild Partial Solution Properties"", toNoOp, DriverStrategy.UNARY_NO_OP);
                rebuildPropertiesPlanNode.initProperties(toNoOp.getGlobalProperties(), toNoOp.getLocalProperties());
                estimator.costOperator(rebuildPropertiesPlanNode);
                GlobalProperties atEndGlobalModified = rebuildPropertiesPlanNode.getGlobalProperties();
                LocalProperties atEndLocalModified = rebuildPropertiesPlanNode.getLocalProperties();
                if (!(atEndGlobalModified.equals(atEndGlobal) && atEndLocalModified.equals(atEndLocal))) {
                    FeedbackPropertiesMeetRequirementsReport report2 = candidate.checkPartialSolutionPropertiesMet(pspn, atEndGlobalModified, atEndLocalModified);
                    if (report2 != FeedbackPropertiesMeetRequirementsReport.NOT_MET) {
                        newCandidates.add(rebuildPropertiesPlanNode);
                    }
                }
                planDeleter.remove();
            }
        }
    }
    if (candidates.isEmpty()) {
        return;
    }
    // 5) Create a candidate for the Iteration Node for every remaining plan of the step function.
    if (terminationCriterion == null) {
        for (PlanNode candidate : candidates) {
            BulkIterationPlanNode node = new BulkIterationPlanNode(this, this.getOperator().getName(), in, pspn, candidate);
            GlobalProperties gProps = candidate.getGlobalProperties().clone();
            LocalProperties lProps = candidate.getLocalProperties().clone();
            node.initProperties(gProps, lProps);
            target.add(node);
        }
    } else if (candidates.size() > 0) {
        List<PlanNode> terminationCriterionCandidates = this.terminationCriterion.getAlternativePlans(estimator);
        SingleRootJoiner singleRoot = (SingleRootJoiner) this.singleRoot;
        for (PlanNode candidate : candidates) {
            for (PlanNode terminationCandidate : terminationCriterionCandidates) {
                if (singleRoot.areBranchCompatible(candidate, terminationCandidate)) {
                    BulkIterationPlanNode node = new BulkIterationPlanNode(this, ""BulkIteration ("" + this.getOperator().getName() + "")"", in, pspn, candidate, terminationCandidate);
                    GlobalProperties gProps = candidate.getGlobalProperties().clone();
                    LocalProperties lProps = candidate.getLocalProperties().clone();
                    node.initProperties(gProps, lProps);
                    target.add(node);
                }
            }
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3052_8dc70f2e,Major,flink-optimizer/src/main/java/org/apache/flink/optimizer/dag/UnaryOperatorNode.java,50,53,"@Override
protected List<OperatorDescriptorSingle> getPossibleProperties() {
    return this.operator;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3052_8dc70f2e,Major,flink-optimizer/src/main/java/org/apache/flink/optimizer/dag/WorksetIterationNode.java,311,465,"@Override
protected void instantiate(OperatorDescriptorDual operator, Channel solutionSetIn, Channel worksetIn, List<Set<? extends NamedChannel>> broadcastPlanChannels, List<PlanNode> target, CostEstimator estimator, RequestedGlobalProperties globPropsReqSolutionSet, RequestedGlobalProperties globPropsReqWorkset, RequestedLocalProperties locPropsReqSolutionSet, RequestedLocalProperties locPropsReqWorkset) {
    // check for pipeline breaking using hash join with build on the solution set side
    placePipelineBreakersIfNecessary(DriverStrategy.HYBRIDHASH_BUILD_FIRST, solutionSetIn, worksetIn);
    // NOTES ON THE ENUMERATION OF THE STEP FUNCTION PLANS:
    // Whenever we instantiate the iteration, we enumerate new candidates for the step function.
    // That way, we make sure we have an appropriate plan for each candidate for the initial partial solution,
    // we have a fitting candidate for the step function (often, work is pushed out of the step function).
    // Among the candidates of the step function, we keep only those that meet the requested properties of the
    // current candidate initial partial solution. That makes sure these properties exist at the beginning of
    // every iteration.
    // 1) Because we enumerate multiple times, we may need to clean the cached plans
    // before starting another enumeration
    this.nextWorkset.accept(PlanCacheCleaner.INSTANCE);
    this.solutionSetDelta.accept(PlanCacheCleaner.INSTANCE);
    // 2) Give the partial solution the properties of the current candidate for the initial partial solution
    // This concerns currently only the workset.
    this.worksetNode.setCandidateProperties(worksetIn.getGlobalProperties(), worksetIn.getLocalProperties(), worksetIn);
    this.solutionSetNode.setCandidateProperties(this.partitionedProperties, new LocalProperties(), solutionSetIn);
    final SolutionSetPlanNode sspn = this.solutionSetNode.getCurrentSolutionSetPlanNode();
    final WorksetPlanNode wspn = this.worksetNode.getCurrentWorksetPlanNode();
    // 3) Get the alternative plans
    List<PlanNode> solutionSetDeltaCandidates = this.solutionSetDelta.getAlternativePlans(estimator);
    List<PlanNode> worksetCandidates = this.nextWorkset.getAlternativePlans(estimator);
    // 4) Throw away all that are not compatible with the properties currently requested to the
    // initial partial solution
    // Make sure that the workset candidates fulfill the input requirements
    {
        List<PlanNode> newCandidates = new ArrayList<PlanNode>();
        for (Iterator<PlanNode> planDeleter = worksetCandidates.iterator(); planDeleter.hasNext(); ) {
            PlanNode candidate = planDeleter.next();
            GlobalProperties atEndGlobal = candidate.getGlobalProperties();
            LocalProperties atEndLocal = candidate.getLocalProperties();
            FeedbackPropertiesMeetRequirementsReport report = candidate.checkPartialSolutionPropertiesMet(wspn, atEndGlobal, atEndLocal);
            if (report == FeedbackPropertiesMeetRequirementsReport.NO_PARTIAL_SOLUTION) {
                // depends only through broadcast variable on the workset solution
                ;
            } else if (report == FeedbackPropertiesMeetRequirementsReport.NOT_MET) {
                // attach a no-op node through which we create the properties of the original input
                Channel toNoOp = new Channel(candidate);
                globPropsReqWorkset.parameterizeChannel(toNoOp, false, nextWorksetRootConnection.getDataExchangeMode(), false);
                locPropsReqWorkset.parameterizeChannel(toNoOp);
                UnaryOperatorNode rebuildWorksetPropertiesNode = new UnaryOperatorNode(""Rebuild Workset Properties"", FieldList.EMPTY_LIST);
                rebuildWorksetPropertiesNode.setParallelism(candidate.getParallelism());
                SingleInputPlanNode rebuildWorksetPropertiesPlanNode = new SingleInputPlanNode(rebuildWorksetPropertiesNode, ""Rebuild Workset Properties"", toNoOp, DriverStrategy.UNARY_NO_OP);
                rebuildWorksetPropertiesPlanNode.initProperties(toNoOp.getGlobalProperties(), toNoOp.getLocalProperties());
                estimator.costOperator(rebuildWorksetPropertiesPlanNode);
                GlobalProperties atEndGlobalModified = rebuildWorksetPropertiesPlanNode.getGlobalProperties();
                LocalProperties atEndLocalModified = rebuildWorksetPropertiesPlanNode.getLocalProperties();
                if (!(atEndGlobalModified.equals(atEndGlobal) && atEndLocalModified.equals(atEndLocal))) {
                    FeedbackPropertiesMeetRequirementsReport report2 = candidate.checkPartialSolutionPropertiesMet(wspn, atEndGlobalModified, atEndLocalModified);
                    if (report2 != FeedbackPropertiesMeetRequirementsReport.NOT_MET) {
                        newCandidates.add(rebuildWorksetPropertiesPlanNode);
                    }
                }
                // remove the original operator and add the modified candidate
                planDeleter.remove();
            }
        }
        worksetCandidates.addAll(newCandidates);
    }
    if (worksetCandidates.isEmpty()) {
        return;
    }
    // sanity check the solution set delta
    for (PlanNode solutionSetDeltaCandidate : solutionSetDeltaCandidates) {
        SingleInputPlanNode candidate = (SingleInputPlanNode) solutionSetDeltaCandidate;
        GlobalProperties gp = candidate.getGlobalProperties();
        if (gp.getPartitioning() != PartitioningProperty.HASH_PARTITIONED || gp.getPartitioningFields() == null || !gp.getPartitioningFields().equals(this.solutionSetKeyFields)) {
            throw new CompilerException(""Bug: The solution set delta is not partitioned."");
        }
    }
    // 5) Create a candidate for the Iteration Node for every remaining plan of the step function.
    final GlobalProperties gp = new GlobalProperties();
    gp.setHashPartitioned(this.solutionSetKeyFields);
    gp.addUniqueFieldCombination(this.solutionSetKeyFields);
    LocalProperties lp = LocalProperties.EMPTY.addUniqueFields(this.solutionSetKeyFields);
    // take all combinations of solution set delta and workset plans
    for (PlanNode solutionSetCandidate : solutionSetDeltaCandidates) {
        for (PlanNode worksetCandidate : worksetCandidates) {
            // check whether they have the same operator at their latest branching point
            if (this.singleRoot.areBranchCompatible(solutionSetCandidate, worksetCandidate)) {
                SingleInputPlanNode siSolutionDeltaCandidate = (SingleInputPlanNode) solutionSetCandidate;
                boolean immediateDeltaUpdate;
                // check whether we need a dedicated solution set delta operator, or whether we can update on the fly
                if (siSolutionDeltaCandidate.getInput().getShipStrategy() == ShipStrategyType.FORWARD && this.solutionDeltaImmediatelyAfterSolutionJoin) {
                    // sanity check the node and connection
                    if (siSolutionDeltaCandidate.getDriverStrategy() != DriverStrategy.UNARY_NO_OP || siSolutionDeltaCandidate.getInput().getLocalStrategy() != LocalStrategy.NONE) {
                        throw new CompilerException(""Invalid Solution set delta node."");
                    }
                    solutionSetCandidate = siSolutionDeltaCandidate.getInput().getSource();
                    immediateDeltaUpdate = true;
                } else {
                    // was not partitioned, we need to keep this node.
                    // mark that we materialize the input
                    siSolutionDeltaCandidate.getInput().setTempMode(TempMode.PIPELINE_BREAKER);
                    immediateDeltaUpdate = false;
                }
                WorksetIterationPlanNode wsNode = new WorksetIterationPlanNode(this, this.getOperator().getName(), solutionSetIn, worksetIn, sspn, wspn, worksetCandidate, solutionSetCandidate);
                wsNode.setImmediateSolutionSetUpdate(immediateDeltaUpdate);
                wsNode.initProperties(gp, lp);
                target.add(wsNode);
            }
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3107_937963e3,Major,flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/SavepointCoordinator.java,177,241,"/**
 *  Resets the state of {@link Execution} instances back to the state of a savepoint.
 *
 *  <p>The execution vertices need to be in state {@link ExecutionState#CREATED} when calling
 *  this method. The operation might block. Make sure that calls don't block the job manager
 *  actor.
 *
 *  @param tasks         Tasks that will possibly be reset
 *  @param savepointPath The path of the savepoint to rollback to
 *  @return The application ID of the rolled back savepoint
 *  @throws IllegalStateException If coordinator is shut down
 *  @throws IllegalStateException If mismatch between program and savepoint state
 *  @throws Exception             If savepoint store failure
 */
public ApplicationID restoreSavepoint(Map<JobVertexID, ExecutionJobVertex> tasks, String savepointPath) throws Exception {
    checkNotNull(savepointPath, ""Savepoint path"");
    synchronized (lock) {
        if (isShutdown()) {
            throw new IllegalStateException(""CheckpointCoordinator is shut down"");
        }
        long recoveryTimestamp = System.currentTimeMillis();
        LOG.info(""Rolling back to savepoint '{}'."", savepointPath);
        Savepoint savepoint = savepointStore.getState(savepointPath);
        CompletedCheckpoint checkpoint = savepoint.getCompletedCheckpoint();
        LOG.info(""Savepoint: {}@{}"", checkpoint.getCheckpointID(), checkpoint.getTimestamp());
        // Set the initial state of all tasks
        LOG.debug(""Rolling back individual operators."");
        for (StateForTask state : checkpoint.getStates()) {
            LOG.debug(""Rolling back subtask {} of operator {}."", state.getSubtask(), state.getOperatorId());
            ExecutionJobVertex vertex = tasks.get(state.getOperatorId());
            if (vertex == null) {
                String msg = String.format(""Failed to rollback to savepoint %s. "" + ""Cannot map old state for task %s to the new program. "" + ""This indicates that the program has been changed in a "" + ""non-compatible way  after the savepoint."", savepoint, state.getOperatorId());
                throw new IllegalStateException(msg);
            }
            if (state.getSubtask() >= vertex.getParallelism()) {
                String msg = String.format(""Failed to rollback to savepoint %s. "" + ""Parallelism mismatch between savepoint state and new program. "" + ""Cannot map subtask %d of operator %s to new program with "" + ""parallelism %d. This indicates that the program has been changed "" + ""in a non-compatible way after the savepoint."", savepoint, state.getSubtask(), state.getOperatorId(), vertex.getParallelism());
                throw new IllegalStateException(msg);
            }
            Execution exec = vertex.getTaskVertices()[state.getSubtask()].getCurrentExecutionAttempt();
            exec.setInitialState(state.getState(), recoveryTimestamp);
        }
        // Reset the checkpoint ID counter
        long nextCheckpointId = checkpoint.getCheckpointID();
        checkpointIdCounter.setCount(nextCheckpointId + 1);
        LOG.info(""Reset the checkpoint ID to {}"", nextCheckpointId);
        this.appId = savepoint.getApplicationId();
        LOG.info(""Reset the application ID to {}"", appId);
        return appId;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3189_a5b05566,Minor,flink-clients/src/main/java/org/apache/flink/client/cli/CliFrontendParser.java,339,348,"public static InfoOptions parseInfoCommand(String[] args) throws CliArgsException {
    try {
        PosixParser parser = new PosixParser();
        CommandLine line = parser.parse(INFO_OPTIONS, args, false);
        return new InfoOptions(line);
    } catch (ParseException e) {
        throw new CliArgsException(e.getMessage());
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3251_117ba95f,Major,flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/stats/SimpleCheckpointStatsTracker.java,290,332,"@Override
public Option<OperatorCheckpointStats> getOperatorStats(JobVertexID operatorId) {
    synchronized (statsLock) {
        OperatorCheckpointStats stats = operatorStatsCache.get(operatorId);
        if (stats != null) {
            return Option.apply(stats);
        } else if (latestCompletedCheckpoint != null && subTaskStats != null) {
            long[][] subTaskStats = this.subTaskStats.get(operatorId);
            if (subTaskStats == null) {
                throw new IllegalArgumentException(""Unknown operator ID."");
            }
            long maxDuration = Long.MIN_VALUE;
            long stateSize = 0;
            for (long[] subTaskStat : subTaskStats) {
                if (subTaskStat[0] > maxDuration) {
                    maxDuration = subTaskStat[0];
                }
                stateSize += subTaskStat[1];
            }
            stats = new OperatorCheckpointStats(latestCompletedCheckpoint.getCheckpointID(), latestCompletedCheckpoint.getTimestamp(), maxDuration, stateSize, subTaskStats);
            // Remember this and don't recompute if requested again
            operatorStatsCache.put(operatorId, stats);
            return Option.apply(stats);
        } else {
            return Option.empty();
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3256_44061882,Blocker,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java,833,873,"public void restart() {
    try {
        synchronized (progressLock) {
            JobStatus current = state;
            if (current == JobStatus.CANCELED) {
                LOG.info(""Canceled job during restart. Aborting restart."");
                return;
            } else if (current != JobStatus.RESTARTING) {
                throw new IllegalStateException(""Can only restart job from state restarting."");
            }
            if (scheduler == null) {
                throw new IllegalStateException(""The execution graph has not been scheduled before - scheduler is null."");
            }
            this.currentExecutions.clear();
            for (ExecutionJobVertex jv : this.verticesInCreationOrder) {
                jv.resetForNewExecution();
            }
            for (int i = 0; i < stateTimestamps.length; i++) {
                stateTimestamps[i] = 0;
            }
            numFinishedJobVertices = 0;
            transitionState(JobStatus.RESTARTING, JobStatus.CREATED);
            // if we have checkpointed state, reload it into the executions
            if (checkpointCoordinator != null) {
                checkpointCoordinator.restoreLatestCheckpointedState(getAllVertices(), false, false);
            }
        }
        scheduleForExecution(scheduler);
    } catch (Throwable t) {
        fail(t);
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3256_44061882,Blocker,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionJobVertex.java,355,408,"public void resetForNewExecution() {
    if (!(numSubtasksInFinalState == 0 || numSubtasksInFinalState == parallelism)) {
        throw new IllegalStateException(""Cannot reset vertex that is not in final state"");
    }
    synchronized (stateMonitor) {
        // check and reset the sharing groups with scheduler hints
        if (slotSharingGroup != null) {
            slotSharingGroup.clearTaskAssignment();
        }
        if (coLocationGroup != null) {
            coLocationGroup.resetConstraints();
        }
        // fields will be consistent to handle triggered cancel calls
        for (int i = 0; i < parallelism; i++) {
            taskVertices[i].resetForNewExecution();
            if (finishedSubtasks[i]) {
                finishedSubtasks[i] = false;
                numSubtasksInFinalState--;
            }
        }
        if (numSubtasksInFinalState != 0) {
            throw new RuntimeException(""Bug: resetting the execution job vertex failed."");
        }
        // set up the input splits again
        try {
            if (this.inputSplits != null) {
                if (inputSplitsPerSubtask == null) {
                    // lazy assignment
                    @SuppressWarnings(""unchecked"")
                    InputSplitSource<InputSplit> splitSource = (InputSplitSource<InputSplit>) jobVertex.getInputSplitSource();
                    this.splitAssigner = splitSource.getInputSplitAssigner(this.inputSplits);
                } else {
                // eager assignment
                // TODO: this.splitAssigner = new AssignBasedOnPreAssignment();
                }
            }
        } catch (Throwable t) {
            throw new RuntimeException(""Re-creating the input split assigner failed: "" + t.getMessage(), t);
        }
        // Reset intermediate results
        for (IntermediateResult result : producedDataSets) {
            result.resetForNewExecution();
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3260_6968a57a,Blocker,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java,405,461,"public void cancel() {
    // successful atomic state transition
    while (true) {
        ExecutionState current = this.state;
        if (current == CANCELING || current == CANCELED) {
            // already taken care of, no need to cancel again
            return;
        } else // these two are the common cases where we need to send a cancel call
        if (current == RUNNING || current == DEPLOYING) {
            // try to transition to canceling, if successful, send the cancel call
            if (transitionState(current, CANCELING)) {
                sendCancelRpcCall();
                return;
            }
        // else: fall through the loop
        } else if (current == FINISHED || current == FAILED) {
            // nothing to do any more. finished failed before it could be cancelled.
            // in any case, the task is removed from the TaskManager already
            sendFailIntermediateResultPartitionsRpcCall();
            return;
        } else if (current == CREATED || current == SCHEDULED) {
            // from here, we can directly switch to cancelled, because the no task has been deployed
            if (transitionState(current, CANCELED)) {
                // we skip the canceling state. set the timestamp, for a consistent appearance
                markTimestamp(CANCELING, getStateTimestamp(CANCELED));
                try {
                    vertex.getExecutionGraph().deregisterExecution(this);
                    if (assignedResource != null) {
                        assignedResource.releaseSlot();
                    }
                } finally {
                    vertex.executionCanceled();
                }
                return;
            }
        // else: fall through the loop
        } else {
            throw new IllegalStateException(current.name());
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3260_6968a57a,Blocker,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java,742,799,"// --------------------------------------------------------------------------------------------
// Internal Actions
// --------------------------------------------------------------------------------------------
private boolean processFail(Throwable t, boolean isCallback) {
    // atomically switch to failed
    while (true) {
        ExecutionState current = this.state;
        if (current == FAILED) {
            // already failed. It is enough to remember once that we failed (its sad enough)
            return false;
        }
        if (current == CANCELED) {
            // we are already aborting or are already aborted
            if (LOG.isDebugEnabled()) {
                LOG.debug(String.format(""Ignoring transition of vertex %s to %s while being %s"", getVertexWithAttempt(), FAILED, CANCELED));
            }
            return false;
        }
        if (transitionState(current, FAILED, t)) {
            // success (in a manner of speaking)
            this.failureCause = t;
            try {
                if (assignedResource != null) {
                    assignedResource.releaseSlot();
                }
                vertex.getExecutionGraph().deregisterExecution(this);
            } finally {
                vertex.executionFailed(t);
            }
            if (!isCallback && (current == RUNNING || current == DEPLOYING)) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Sending out cancel request, to remove task execution from TaskManager."");
                }
                try {
                    if (assignedResource != null) {
                        sendCancelRpcCall();
                    }
                } catch (Throwable tt) {
                    // no reason this should ever happen, but log it to be safe
                    LOG.error(""Error triggering cancel call while marking task as failed."", tt);
                }
            }
            // leave the loop
            return true;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3260_6968a57a,Blocker,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java,930,949,"private boolean transitionState(ExecutionState currentState, ExecutionState targetState, Throwable error) {
    if (STATE_UPDATER.compareAndSet(this, currentState, targetState)) {
        markTimestamp(targetState);
        LOG.info(getVertex().getTaskNameWithSubtaskIndex() + "" ("" + getAttemptId() + "") switched from "" + currentState + "" to "" + targetState);
        // potential errors (in listeners may not affect the main logic)
        try {
            vertex.notifyStateTransition(attemptId, targetState, error);
        } catch (Throwable t) {
            LOG.error(""Error while notifying execution graph of execution state transition."", t);
        }
        return true;
    } else {
        return false;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3267_ed3810b1,Blocker,flink-java/src/main/java/org/apache/flink/api/java/typeutils/runtime/kryo/KryoSerializer.java,322,368,"private void checkKryoInitialized() {
    if (this.kryo == null) {
        this.kryo = getKryoInstance();
        // Throwable and all subclasses should be serialized via java serialization
        kryo.addDefaultSerializer(Throwable.class, new JavaSerializer());
        // are registered with a default serializer
        for (Map.Entry<Class<?>, ExecutionConfig.SerializableSerializer<?>> entry : defaultSerializers.entrySet()) {
            kryo.addDefaultSerializer(entry.getKey(), entry.getValue().getSerializer());
        }
        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> entry : defaultSerializerClasses.entrySet()) {
            kryo.addDefaultSerializer(entry.getKey(), entry.getValue());
        }
        // register the type of our class
        kryo.register(type);
        // more specific serializer overrides this
        for (Class<?> type : registeredTypes) {
            kryo.register(type);
        }
        // register given serializer classes
        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> e : registeredTypesWithSerializerClasses.entrySet()) {
            Class<?> typeClass = e.getKey();
            Class<? extends Serializer<?>> serializerClass = e.getValue();
            Serializer<?> serializer = ReflectionSerializerFactory.makeSerializer(kryo, serializerClass, typeClass);
            kryo.register(typeClass, serializer);
        }
        // register given serializers
        for (Map.Entry<Class<?>, ExecutionConfig.SerializableSerializer<?>> e : registeredTypesWithSerializers.entrySet()) {
            kryo.register(e.getKey(), e.getValue().getSerializer());
        }
        // this is needed for Avro but can not be added on demand.
        kryo.register(GenericData.Array.class, new SpecificInstanceCollectionSerializerForArrayList());
        kryo.setRegistrationRequired(false);
        kryo.setClassLoader(Thread.currentThread().getContextClassLoader());
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3314_8fc7e7af,Blocker,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java,168,288,"// ------------------------------------------------------------------------
// Core work methods of the Stream Task
// ------------------------------------------------------------------------
@Override
public final void invoke() throws Exception {
    boolean disposed = false;
    try {
        // -------- Initialize ---------
        LOG.debug(""Initializing {}"", getName());
        userClassLoader = getUserCodeClassLoader();
        configuration = new StreamConfig(getTaskConfiguration());
        accumulatorMap = getEnvironment().getAccumulatorRegistry().getUserMap();
        headOperator = configuration.getStreamOperator(userClassLoader);
        operatorChain = new OperatorChain<>(this, headOperator, getEnvironment().getAccumulatorRegistry().getReadWriteReporter());
        if (headOperator != null) {
            headOperator.setup(this, configuration, operatorChain.getChainEntryPoint());
        }
        timerService = Executors.newSingleThreadScheduledExecutor(new DispatcherThreadFactory(TRIGGER_THREAD_GROUP, ""Time Trigger for "" + getName()));
        // task specific initialization
        init();
        // -------- Invoke --------
        LOG.debug(""Invoking {}"", getName());
        // first order of business is to give operators back their state
        stateBackend = createStateBackend();
        stateBackend.initializeForJob(getEnvironment());
        restoreState();
        // executed before all operators are opened
        synchronized (lock) {
            openAllOperators();
        }
        // let the task do its work
        isRunning = true;
        run();
        isRunning = false;
        if (LOG.isDebugEnabled()) {
            LOG.debug(""Finished task {}"", getName());
        }
        // we also need to make sure that no triggers fire concurrently with the close logic
        synchronized (lock) {
            // this is part of the main logic, so if this fails, the task is considered failed
            closeAllOperators();
        }
        // make sure all buffered data is flushed
        operatorChain.flushOutputs();
        // make an attempt to dispose the operators such that failures in the dispose call
        // still let the computation fail
        tryDisposeAllOperators();
        disposed = true;
    } finally {
        // clean up everything we initialized
        isRunning = false;
        // stop all timers and threads
        if (timerService != null) {
            try {
                timerService.shutdownNow();
            } catch (Throwable t) {
                // catch and log the exception to not replace the original exception
                LOG.error(""Could not shut down timer service"", t);
            }
        }
        // stop all asynchronous checkpoint threads
        try {
            for (Thread checkpointThread : asyncCheckpointThreads) {
                checkpointThread.interrupt();
            }
            asyncCheckpointThreads.clear();
        } catch (Throwable t) {
            // catch and log the exception to not replace the original exception
            LOG.error(""Could not shut down async checkpoint threads"", t);
        }
        // release the output resources. this method should never fail.
        if (operatorChain != null) {
            operatorChain.releaseOutputs();
        }
        // we must! perform this cleanup
        try {
            cleanup();
        } catch (Throwable t) {
            // catch and log the exception to not replace the original exception
            LOG.error(""Error during cleanup of stream task"", t);
        }
        // if the operators were not disposed before, do a hard dispose
        if (!disposed) {
            disposeAllOperators();
        }
        try {
            if (stateBackend != null) {
                stateBackend.close();
            }
        } catch (Throwable t) {
            LOG.error(""Error while closing the state backend"", t);
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3314_8fc7e7af,Blocker,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/tasks/StreamTask.java,290,294,"@Override
public final void cancel() throws Exception {
    isRunning = false;
    cancelTask();
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3342_8e3e2f8f,Major,flink-runtime/src/main/java/org/apache/flink/runtime/checkpoint/stats/SimpleCheckpointStatsTracker.java,131,252,"@Override
public void onCompletedCheckpoint(CompletedCheckpoint checkpoint) {
    // Sanity check
    if (taskParallelism.isEmpty()) {
        return;
    }
    synchronized (statsLock) {
        int overallStateSize = 0;
        // Operator stats
        Map<JobVertexID, long[][]> statsForSubTasks = new HashMap<>();
        for (StateForTask state : checkpoint.getStates()) {
            // Job-level checkpoint size is sum of all state sizes
            overallStateSize += state.getStateSize();
            // Subtask stats
            JobVertexID opId = state.getOperatorId();
            long[][] statsPerSubtask = statsForSubTasks.get(opId);
            if (statsPerSubtask == null) {
                int parallelism = taskParallelism.get(opId);
                statsPerSubtask = new long[parallelism][2];
                statsForSubTasks.put(opId, statsPerSubtask);
            }
            int subTaskIndex = state.getSubtask();
            if (subTaskIndex < statsPerSubtask.length) {
                statsPerSubtask[subTaskIndex][0] = state.getDuration();
                statsPerSubtask[subTaskIndex][1] = state.getStateSize();
            }
        }
        // It is possible that completed checkpoints are added out of
        // order. Make sure that in this case the last completed
        // checkpoint is not updated.
        boolean isInOrder = latestCompletedCheckpoint != null && checkpoint.getCheckpointID() > latestCompletedCheckpoint.getCheckpointID();
        // Clear this in each case
        lastJobStats = null;
        if (overallCount == 0 || isInOrder) {
            latestCompletedCheckpoint = checkpoint;
            // Clear cached stats
            operatorStatsCache.clear();
            // Update the stats per sub task
            subTaskStats = statsForSubTasks;
        }
        long checkpointId = checkpoint.getCheckpointID();
        long checkpointTriggerTimestamp = checkpoint.getTimestamp();
        long checkpointDuration = checkpoint.getDuration();
        overallCount++;
        // Duration stats
        if (checkpointDuration > overallMaxDuration) {
            overallMaxDuration = checkpointDuration;
        }
        if (checkpointDuration < overallMinDuration) {
            overallMinDuration = checkpointDuration;
        }
        overallTotalDuration += checkpointDuration;
        // State size stats
        if (overallStateSize < overallMinStateSize) {
            overallMinStateSize = overallStateSize;
        }
        if (overallStateSize > overallMaxStateSize) {
            overallMaxStateSize = overallStateSize;
        }
        this.overallTotalStateSize += overallStateSize;
        // Recent history
        if (historySize > 0) {
            CheckpointStats stats = new CheckpointStats(checkpointId, checkpointTriggerTimestamp, checkpointDuration, overallStateSize);
            if (isInOrder) {
                if (history.size() == historySize) {
                    history.remove(0);
                }
                history.add(stats);
            } else {
                final int size = history.size();
                // Only remove it if it the new checkpoint is not too old
                if (size == historySize) {
                    if (checkpointId > history.get(0).getCheckpointId()) {
                        history.remove(0);
                    }
                }
                int pos = 0;
                // Find position
                for (int i = 0; i < size; i++) {
                    pos = i;
                    if (checkpointId < history.get(i).getCheckpointId()) {
                        break;
                    }
                }
                history.add(pos, stats);
            }
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3513_d90672fd,Blocker,flink-streaming-java/src/main/java/org/apache/flink/streaming/api/graph/StreamingJobGraphGenerator.java,731,747,"/**
 *  Applies the {@link Hasher} to the {@link StreamNode} (only node local
 *  attributes are taken into account). The hasher encapsulates the current
 *  state of the hash.
 *
 *  <p>The specified ID is local to this node. We cannot use the
 *  {@link StreamNode#id}, because it is incremented in a static counter.
 *  Therefore, the IDs for identical jobs will otherwise be different.
 */
private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {
    // This resolves conflicts for otherwise identical source nodes. BUT
    // the generated hash codes depend on the ordering of the nodes in the
    // stream graph.
    hasher.putInt(id);
    hasher.putInt(node.getParallelism());
    hasher.putString(node.getOperatorName(), Charset.forName(""UTF-8""));
    if (node.getOperator() instanceof AbstractUdfStreamOperator) {
        String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator()).getUserFunction().getClass().getName();
        hasher.putString(udfClassName, Charset.forName(""UTF-8""));
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3534_734ba01d,Critical,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/Execution.java,777,833,"// --------------------------------------------------------------------------------------------
// Internal Actions
// --------------------------------------------------------------------------------------------
private boolean processFail(Throwable t, boolean isCallback) {
    // atomically switch to failed
    while (true) {
        ExecutionState current = this.state;
        if (current == FAILED) {
            // already failed. It is enough to remember once that we failed (its sad enough)
            return false;
        }
        if (current == CANCELED || current == FINISHED) {
            // we are already aborting or are already aborted or we are already finished
            if (LOG.isDebugEnabled()) {
                LOG.debug(""Ignoring transition of vertex {} to {} while being {}."", getVertexWithAttempt(), FAILED, current);
            }
            return false;
        }
        if (transitionState(current, FAILED, t)) {
            // success (in a manner of speaking)
            this.failureCause = t;
            try {
                if (assignedResource != null) {
                    assignedResource.releaseSlot();
                }
                vertex.getExecutionGraph().deregisterExecution(this);
            } finally {
                vertex.executionFailed(t);
            }
            if (!isCallback && (current == RUNNING || current == DEPLOYING)) {
                if (LOG.isDebugEnabled()) {
                    LOG.debug(""Sending out cancel request, to remove task execution from TaskManager."");
                }
                try {
                    if (assignedResource != null) {
                        sendCancelRpcCall();
                    }
                } catch (Throwable tt) {
                    // no reason this should ever happen, but log it to be safe
                    LOG.error(""Error triggering cancel call while marking task as failed."", tt);
                }
            }
            // leave the loop
            return true;
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3534_734ba01d,Critical,flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java,809,833,"public void fail(Throwable t) {
    while (true) {
        JobStatus current = state;
        if (current == JobStatus.FAILED || current == JobStatus.FAILING) {
            return;
        } else if (transitionState(current, JobStatus.FAILING, t)) {
            this.failureCause = t;
            if (!verticesInCreationOrder.isEmpty()) {
                // cancel all. what is failed will not cancel but stay failed
                for (ExecutionJobVertex ejv : verticesInCreationOrder) {
                    ejv.cancel();
                }
            } else {
                // set the state of the job to failed
                transitionState(JobStatus.FAILING, JobStatus.FAILED, t);
            }
            return;
        }
    // no need to treat other states
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3566_434e88fd,Major,flink-core/src/main/java/org/apache/flink/api/java/typeutils/TypeExtractor.java,882,1094,"@SuppressWarnings(""unchecked"")
private static void validateInfo(ArrayList<Type> typeHierarchy, Type type, TypeInformation<?> typeInfo) {
    if (type == null) {
        throw new InvalidTypesException(""Unknown Error. Type is null."");
    }
    if (typeInfo == null) {
        throw new InvalidTypesException(""Unknown Error. TypeInformation is null."");
    }
    if (!(type instanceof TypeVariable<?>)) {
        // check for basic type
        if (typeInfo.isBasicType()) {
            TypeInformation<?> actual;
            // check if basic type at all
            if (!(type instanceof Class<?>) || (actual = BasicTypeInfo.getInfoFor((Class<?>) type)) == null) {
                throw new InvalidTypesException(""Basic type expected."");
            }
            // check if correct basic type
            if (!typeInfo.equals(actual)) {
                throw new InvalidTypesException(""Basic type '"" + typeInfo + ""' expected but was '"" + actual + ""'."");
            }
        } else // check for tuple
        if (typeInfo.isTupleType()) {
            // check if tuple at all
            if (!(isClassType(type) && Tuple.class.isAssignableFrom(typeToClass(type)))) {
                throw new InvalidTypesException(""Tuple type expected."");
            }
            // do not allow usage of Tuple as type
            if (isClassType(type) && typeToClass(type).equals(Tuple.class)) {
                throw new InvalidTypesException(""Concrete subclass of Tuple expected."");
            }
            // go up the hierarchy until we reach immediate child of Tuple (with or without generics)
            while (!(isClassType(type) && typeToClass(type).getSuperclass().equals(Tuple.class))) {
                typeHierarchy.add(type);
                type = typeToClass(type).getGenericSuperclass();
            }
            if (type == Tuple0.class) {
                return;
            }
            // check if immediate child of Tuple has generics
            if (type instanceof Class<?>) {
                throw new InvalidTypesException(""Parameterized Tuple type expected."");
            }
            TupleTypeInfo<?> tti = (TupleTypeInfo<?>) typeInfo;
            Type[] subTypes = ((ParameterizedType) type).getActualTypeArguments();
            if (subTypes.length != tti.getArity()) {
                throw new InvalidTypesException(""Tuple arity '"" + tti.getArity() + ""' expected but was '"" + subTypes.length + ""'."");
            }
            for (int i = 0; i < subTypes.length; i++) {
                validateInfo(new ArrayList<Type>(typeHierarchy), subTypes[i], tti.getTypeAt(i));
            }
        } else // check for Either
        if (typeInfo instanceof EitherTypeInfo) {
            // check if Either at all
            if (!(isClassType(type) && Either.class.isAssignableFrom(typeToClass(type)))) {
                throw new InvalidTypesException(""Either type expected."");
            }
            // go up the hierarchy until we reach Either (with or without generics)
            while (!(isClassType(type) && typeToClass(type).equals(Either.class))) {
                typeHierarchy.add(type);
                type = typeToClass(type).getGenericSuperclass();
            }
            // check if Either has generics
            if (type instanceof Class<?>) {
                throw new InvalidTypesException(""Parameterized Either type expected."");
            }
            EitherTypeInfo<?, ?> eti = (EitherTypeInfo<?, ?>) typeInfo;
            Type[] subTypes = ((ParameterizedType) type).getActualTypeArguments();
            validateInfo(new ArrayList<Type>(typeHierarchy), subTypes[0], eti.getLeftType());
            validateInfo(new ArrayList<Type>(typeHierarchy), subTypes[1], eti.getRightType());
        } else // check for Writable
        if (typeInfo instanceof WritableTypeInfo<?>) {
            // check if writable at all
            if (!(type instanceof Class<?> && Writable.class.isAssignableFrom((Class<?>) type))) {
                throw new InvalidTypesException(""Writable type expected."");
            }
            // check writable type contents
            Class<?> clazz;
            if (((WritableTypeInfo<?>) typeInfo).getTypeClass() != (clazz = (Class<?>) type)) {
                throw new InvalidTypesException(""Writable type '"" + ((WritableTypeInfo<?>) typeInfo).getTypeClass().getCanonicalName() + ""' expected but was '"" + clazz.getCanonicalName() + ""'."");
            }
        } else // check for primitive array
        if (typeInfo instanceof PrimitiveArrayTypeInfo) {
            Type component;
            // check if array at all
            if (!(type instanceof Class<?> && ((Class<?>) type).isArray() && (component = ((Class<?>) type).getComponentType()) != null) && !(type instanceof GenericArrayType && (component = ((GenericArrayType) type).getGenericComponentType()) != null)) {
                throw new InvalidTypesException(""Array type expected."");
            }
            if (component instanceof TypeVariable<?>) {
                component = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) component);
                if (component instanceof TypeVariable) {
                    return;
                }
            }
            if (!(component instanceof Class<?> && ((Class<?>) component).isPrimitive())) {
                throw new InvalidTypesException(""Primitive component expected."");
            }
        } else // check for basic array
        if (typeInfo instanceof BasicArrayTypeInfo<?, ?>) {
            Type component;
            // check if array at all
            if (!(type instanceof Class<?> && ((Class<?>) type).isArray() && (component = ((Class<?>) type).getComponentType()) != null) && !(type instanceof GenericArrayType && (component = ((GenericArrayType) type).getGenericComponentType()) != null)) {
                throw new InvalidTypesException(""Array type expected."");
            }
            if (component instanceof TypeVariable<?>) {
                component = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) component);
                if (component instanceof TypeVariable) {
                    return;
                }
            }
            validateInfo(typeHierarchy, component, ((BasicArrayTypeInfo<?, ?>) typeInfo).getComponentInfo());
        } else // check for object array
        if (typeInfo instanceof ObjectArrayTypeInfo<?, ?>) {
            // check if array at all
            if (!(type instanceof Class<?> && ((Class<?>) type).isArray()) && !(type instanceof GenericArrayType)) {
                throw new InvalidTypesException(""Object array type expected."");
            }
            // check component
            Type component;
            if (type instanceof Class<?>) {
                component = ((Class<?>) type).getComponentType();
            } else {
                component = ((GenericArrayType) type).getGenericComponentType();
            }
            if (component instanceof TypeVariable<?>) {
                component = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) component);
                if (component instanceof TypeVariable) {
                    return;
                }
            }
            validateInfo(typeHierarchy, component, ((ObjectArrayTypeInfo<?, ?>) typeInfo).getComponentInfo());
        } else // check for value
        if (typeInfo instanceof ValueTypeInfo<?>) {
            // check if value at all
            if (!(type instanceof Class<?> && Value.class.isAssignableFrom((Class<?>) type))) {
                throw new InvalidTypesException(""Value type expected."");
            }
            TypeInformation<?> actual;
            // check value type contents
            if (!((ValueTypeInfo<?>) typeInfo).equals(actual = ValueTypeInfo.getValueTypeInfo((Class<? extends Value>) type))) {
                throw new InvalidTypesException(""Value type '"" + typeInfo + ""' expected but was '"" + actual + ""'."");
            }
        } else // check for POJO
        if (typeInfo instanceof PojoTypeInfo) {
            Class<?> clazz = null;
            if (!(isClassType(type) && ((PojoTypeInfo<?>) typeInfo).getTypeClass() == (clazz = typeToClass(type)))) {
                throw new InvalidTypesException(""POJO type '"" + ((PojoTypeInfo<?>) typeInfo).getTypeClass().getCanonicalName() + ""' expected but was '"" + clazz.getCanonicalName() + ""'."");
            }
        } else // check for Enum
        if (typeInfo instanceof EnumTypeInfo) {
            if (!(type instanceof Class<?> && Enum.class.isAssignableFrom((Class<?>) type))) {
                throw new InvalidTypesException(""Enum type expected."");
            }
            // check enum type contents
            if (!(typeInfo.getTypeClass() == type)) {
                throw new InvalidTypesException(""Enum type '"" + typeInfo.getTypeClass().getCanonicalName() + ""' expected but was '"" + typeToClass(type).getCanonicalName() + ""'."");
            }
        } else // check for generic object
        if (typeInfo instanceof GenericTypeInfo<?>) {
            Class<?> clazz = null;
            if (!(isClassType(type) && ((GenericTypeInfo<?>) typeInfo).getTypeClass() == (clazz = typeToClass(type)))) {
                throw new InvalidTypesException(""Generic object type '"" + ((GenericTypeInfo<?>) typeInfo).getTypeClass().getCanonicalName() + ""' expected but was '"" + clazz.getCanonicalName() + ""'."");
            }
        }
    } else {
        type = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) type);
        if (!(type instanceof TypeVariable)) {
            validateInfo(typeHierarchy, type, typeInfo);
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3684_e3759a5e,Major,flink-libraries/flink-cep/src/main/java/org/apache/flink/cep/operator/CEPPatternOperator.java,83,90,"@Override
public void processWatermark(Watermark mark) throws Exception {
    while (!priorityQueue.isEmpty() && priorityQueue.peek().getTimestamp() <= mark.getTimestamp()) {
        StreamRecord<IN> streamRecord = priorityQueue.poll();
        processEvent(nfa, streamRecord.getValue(), streamRecord.getTimestamp());
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3684_e3759a5e,Major,flink-libraries/flink-cep/src/main/java/org/apache/flink/cep/operator/KeyedCEPPatternOperator.java,150,166,"@Override
public void processWatermark(Watermark mark) throws Exception {
    // iterate over all keys to trigger the execution of the buffered elements
    for (KEY key : keys) {
        setKeyContext(key);
        PriorityQueue<StreamRecord<IN>> priorityQueue = getPriorityQueue();
        NFA<IN> nfa = getNFA();
        while (!priorityQueue.isEmpty() && priorityQueue.peek().getTimestamp() <= mark.getTimestamp()) {
            StreamRecord<IN> streamRecord = priorityQueue.poll();
            processEvent(nfa, streamRecord.getValue(), streamRecord.getTimestamp());
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperator.java,79,163,"@Override
@SuppressWarnings(""unchecked"")
public void processElement(StreamRecord<IN> element) throws Exception {
    Collection<W> elementWindows = windowAssigner.assignWindows(element.getValue(), element.getTimestamp());
    K key = (K) getStateBackend().getCurrentKey();
    if (windowAssigner instanceof MergingWindowAssigner) {
        MergingWindowSet<W> mergingWindows = mergingWindowsByKey.get(getStateBackend().getCurrentKey());
        if (mergingWindows == null) {
            mergingWindows = new MergingWindowSet<>((MergingWindowAssigner<? super IN, W>) windowAssigner);
            mergingWindowsByKey.put(key, mergingWindows);
        }
        for (W window : elementWindows) {
            // If there is a merge, it can only result in a window that contains our new
            // element because we always eagerly merge
            final Tuple1<TriggerResult> mergeTriggerResult = new Tuple1<>(TriggerResult.CONTINUE);
            // adding the new window might result in a merge, in that case the actualWindow
            // is the merged window and we work with that. If we don't merge then
            // actualWindow == window
            W actualWindow = mergingWindows.addWindow(window, new MergingWindowSet.MergeFunction<W>() {

                @Override
                public void merge(W mergeResult, Collection<W> mergedWindows, W stateWindowResult, Collection<W> mergedStateWindows) throws Exception {
                    context.window = mergeResult;
                    // store for later use
                    mergeTriggerResult.f0 = context.onMerge(mergedWindows);
                    for (W m : mergedWindows) {
                        context.window = m;
                        context.clear();
                    }
                    // merge the merged state windows into the newly resulting state window
                    getStateBackend().mergePartitionedStates(stateWindowResult, mergedStateWindows, windowSerializer, (StateDescriptor<? extends MergingState<?, ?>, ?>) windowStateDescriptor);
                }
            });
            W stateWindow = mergingWindows.getStateWindow(actualWindow);
            ListState<StreamRecord<IN>> windowState = getPartitionedState(stateWindow, windowSerializer, windowStateDescriptor);
            windowState.add(element);
            context.key = key;
            context.window = actualWindow;
            // we might have already fired because of a merge but still call onElement
            // on the (possibly merged) window
            TriggerResult triggerResult = context.onElement(element);
            TriggerResult combinedTriggerResult = TriggerResult.merge(triggerResult, mergeTriggerResult.f0);
            processTriggerResult(combinedTriggerResult, key, actualWindow);
        }
    } else {
        for (W window : elementWindows) {
            ListState<StreamRecord<IN>> windowState = getPartitionedState(window, windowSerializer, windowStateDescriptor);
            windowState.add(element);
            context.key = key;
            context.window = window;
            TriggerResult triggerResult = context.onElement(element);
            processTriggerResult(triggerResult, key, window);
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperator.java,106,125,"@Override
public void merge(W mergeResult, Collection<W> mergedWindows, W stateWindowResult, Collection<W> mergedStateWindows) throws Exception {
    context.window = mergeResult;
    // store for later use
    mergeTriggerResult.f0 = context.onMerge(mergedWindows);
    for (W m : mergedWindows) {
        context.window = m;
        context.clear();
    }
    // merge the merged state windows into the newly resulting state window
    getStateBackend().mergePartitionedStates(stateWindowResult, mergedStateWindows, windowSerializer, (StateDescriptor<? extends MergingState<?, ?>, ?>) windowStateDescriptor);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/EvictingWindowOperator.java,165,211,"@Override
@SuppressWarnings(""unchecked,rawtypes"")
protected void processTriggerResult(TriggerResult triggerResult, K key, W window) throws Exception {
    if (!triggerResult.isFire() && !triggerResult.isPurge()) {
        // do nothing
        return;
    }
    ListState<StreamRecord<IN>> windowState;
    MergingWindowSet<W> mergingWindows = null;
    if (windowAssigner instanceof MergingWindowAssigner) {
        mergingWindows = mergingWindowsByKey.get(key);
        W stateWindow = mergingWindows.getStateWindow(window);
        windowState = getPartitionedState(stateWindow, windowSerializer, windowStateDescriptor);
    } else {
        windowState = getPartitionedState(window, windowSerializer, windowStateDescriptor);
    }
    if (triggerResult.isFire()) {
        timestampedCollector.setAbsoluteTimestamp(window.maxTimestamp());
        Iterable<StreamRecord<IN>> contents = windowState.get();
        // Work around type system restrictions...
        int toEvict = evictor.evict((Iterable) contents, Iterables.size(contents), context.window);
        FluentIterable<IN> projectedContents = FluentIterable.from(contents).skip(toEvict).transform(new Function<StreamRecord<IN>, IN>() {

            @Override
            public IN apply(StreamRecord<IN> input) {
                return input.getValue();
            }
        });
        userFunction.apply(context.key, context.window, projectedContents, timestampedCollector);
    }
    if (triggerResult.isPurge()) {
        windowState.clear();
        if (mergingWindows != null) {
            mergingWindows.retireWindow(window);
        }
        context.clear();
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java,224,227,"@Override
public final void close() throws Exception {
    super.close();
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java,229,307,"@Override
@SuppressWarnings(""unchecked"")
public void processElement(StreamRecord<IN> element) throws Exception {
    Collection<W> elementWindows = windowAssigner.assignWindows(element.getValue(), element.getTimestamp());
    K key = (K) getStateBackend().getCurrentKey();
    if (windowAssigner instanceof MergingWindowAssigner) {
        MergingWindowSet<W> mergingWindows = mergingWindowsByKey.get(getStateBackend().getCurrentKey());
        if (mergingWindows == null) {
            mergingWindows = new MergingWindowSet<>((MergingWindowAssigner<? super IN, W>) windowAssigner);
            mergingWindowsByKey.put(key, mergingWindows);
        }
        for (W window : elementWindows) {
            // If there is a merge, it can only result in a window that contains our new
            // element because we always eagerly merge
            final Tuple1<TriggerResult> mergeTriggerResult = new Tuple1<>(TriggerResult.CONTINUE);
            // adding the new window might result in a merge, in that case the actualWindow
            // is the merged window and we work with that. If we don't merge then
            // actualWindow == window
            W actualWindow = mergingWindows.addWindow(window, new MergingWindowSet.MergeFunction<W>() {

                @Override
                public void merge(W mergeResult, Collection<W> mergedWindows, W stateWindowResult, Collection<W> mergedStateWindows) throws Exception {
                    context.window = mergeResult;
                    // store for later use
                    mergeTriggerResult.f0 = context.onMerge(mergedWindows);
                    for (W m : mergedWindows) {
                        context.window = m;
                        context.clear();
                    }
                    // merge the merged state windows into the newly resulting state window
                    getStateBackend().mergePartitionedStates(stateWindowResult, mergedStateWindows, windowSerializer, (StateDescriptor<? extends MergingState<?, ?>, ?>) windowStateDescriptor);
                }
            });
            W stateWindow = mergingWindows.getStateWindow(actualWindow);
            AppendingState<IN, ACC> windowState = getPartitionedState(stateWindow, windowSerializer, windowStateDescriptor);
            windowState.add(element.getValue());
            context.key = key;
            context.window = actualWindow;
            // we might have already fired because of a merge but still call onElement
            // on the (possibly merged) window
            TriggerResult triggerResult = context.onElement(element);
            TriggerResult combinedTriggerResult = TriggerResult.merge(triggerResult, mergeTriggerResult.f0);
            processTriggerResult(combinedTriggerResult, key, actualWindow);
        }
    } else {
        for (W window : elementWindows) {
            AppendingState<IN, ACC> windowState = getPartitionedState(window, windowSerializer, windowStateDescriptor);
            windowState.add(element.getValue());
            context.key = key;
            context.window = window;
            TriggerResult triggerResult = context.onElement(element);
            processTriggerResult(triggerResult, key, window);
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java,254,273,"@Override
public void merge(W mergeResult, Collection<W> mergedWindows, W stateWindowResult, Collection<W> mergedStateWindows) throws Exception {
    context.window = mergeResult;
    // store for later use
    mergeTriggerResult.f0 = context.onMerge(mergedWindows);
    for (W m : mergedWindows) {
        context.window = m;
        context.clear();
    }
    // merge the merged state windows into the newly resulting state window
    getStateBackend().mergePartitionedStates(stateWindowResult, mergedStateWindows, windowSerializer, (StateDescriptor<? extends MergingState<?, ?>, ?>) windowStateDescriptor);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java,309,343,"@SuppressWarnings(""unchecked"")
protected void processTriggerResult(TriggerResult triggerResult, K key, W window) throws Exception {
    if (!triggerResult.isFire() && !triggerResult.isPurge()) {
        // do nothing
        return;
    }
    AppendingState<IN, ACC> windowState;
    MergingWindowSet<W> mergingWindows = null;
    if (windowAssigner instanceof MergingWindowAssigner) {
        mergingWindows = mergingWindowsByKey.get(key);
        W stateWindow = mergingWindows.getStateWindow(window);
        windowState = getPartitionedState(stateWindow, windowSerializer, windowStateDescriptor);
    } else {
        windowState = getPartitionedState(window, windowSerializer, windowStateDescriptor);
    }
    if (triggerResult.isFire()) {
        timestampedCollector.setAbsoluteTimestamp(window.maxTimestamp());
        ACC contents = windowState.get();
        userFunction.apply(context.key, context.window, contents, timestampedCollector);
    }
    if (triggerResult.isPurge()) {
        windowState.clear();
        if (mergingWindows != null) {
            mergingWindows.retireWindow(window);
        }
        context.clear();
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java,354,374,"private void processTriggersFor(Watermark mark) throws Exception {
    boolean fire;
    do {
        Timer<K, W> timer = watermarkTimersQueue.peek();
        if (timer != null && timer.timestamp <= mark.getTimestamp()) {
            fire = true;
            watermarkTimers.remove(timer);
            watermarkTimersQueue.remove();
            context.key = timer.key;
            context.window = timer.window;
            setKeyContext(timer.key);
            TriggerResult triggerResult = context.onEventTime(timer.timestamp);
            processTriggerResult(triggerResult, context.key, context.window);
        } else {
            fire = false;
        }
    } while (fire);
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java,376,402,"@Override
public final void trigger(long time) throws Exception {
    boolean fire;
    do {
        Timer<K, W> timer = processingTimeTimersQueue.peek();
        if (timer != null && timer.timestamp <= time) {
            fire = true;
            processingTimeTimers.remove(timer);
            processingTimeTimersQueue.remove();
            context.key = timer.key;
            context.window = timer.window;
            setKeyContext(timer.key);
            TriggerResult triggerResult = context.onProcessingTime(timer.timestamp);
            processTriggerResult(triggerResult, context.key, context.window);
        } else {
            fire = false;
        }
    } while (fire);
    // Also check any watermark timers. We might have some in here since
    // Context.registerEventTimeTimer sets a trigger if an event-time trigger is registered
    // that is already behind the watermark.
    processTriggersFor(new Watermark(currentWatermark));
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3740_f2f5bd5b,Major,flink-streaming-java/src/main/java/org/apache/flink/streaming/runtime/operators/windowing/WindowOperator.java,606,630,"// ------------------------------------------------------------------------
// Checkpointing
// ------------------------------------------------------------------------
@Override
public StreamTaskState snapshotOperatorState(long checkpointId, long timestamp) throws Exception {
    StreamTaskState taskState = super.snapshotOperatorState(checkpointId, timestamp);
    AbstractStateBackend.CheckpointStateOutputView out = getStateBackend().createCheckpointStateOutputView(checkpointId, timestamp);
    out.writeInt(watermarkTimersQueue.size());
    for (Timer<K, W> timer : watermarkTimersQueue) {
        keySerializer.serialize(timer.key, out);
        windowSerializer.serialize(timer.window, out);
        out.writeLong(timer.timestamp);
    }
    out.writeInt(processingTimeTimers.size());
    for (Timer<K, W> timer : processingTimeTimersQueue) {
        keySerializer.serialize(timer.key, out);
        windowSerializer.serialize(timer.window, out);
        out.writeLong(timer.timestamp);
    }
    taskState.setOperatorState(out.closeAndGetHandle());
    return taskState;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3760_494212b3,Critical,flink-core/src/main/java/org/apache/flink/api/common/state/StateDescriptor.java,172,174,"// ------------------------------------------------------------------------
/**
 *  Checks whether the serializer has been initialized. Serializer initialization is lazy,
 *  to allow parametrization of serializers with an {@link ExecutionConfig} via
 *  {@link #initializeSerializerUnlessSet(ExecutionConfig)}.
 *
 *  @return True if the serializers have been initialized, false otherwise.
 */
public boolean isSerializerInitialized() {
    return serializer != null;
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3760_494212b3,Critical,flink-core/src/main/java/org/apache/flink/api/common/state/StateDescriptor.java,181,190,"/**
 *  Initializes the serializer, unless it has been initialized before.
 *
 *  @param executionConfig The execution config to use when creating the serializer.
 */
public void initializeSerializerUnlessSet(ExecutionConfig executionConfig) {
    if (serializer == null) {
        if (typeInfo != null) {
            serializer = typeInfo.createSerializer(executionConfig);
        } else {
            throw new IllegalStateException(""Cannot initialize serializer after TypeInformation was dropped during serialization"");
        }
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3760_494212b3,Critical,flink-core/src/main/java/org/apache/flink/api/common/state/StateDescriptor.java,279,305,"private void readObject(final ObjectInputStream in) throws IOException, ClassNotFoundException {
    // read the non-transient fields
    in.defaultReadObject();
    // read the default value field
    boolean hasDefaultValue = in.readBoolean();
    if (hasDefaultValue) {
        int size = in.readInt();
        byte[] buffer = new byte[size];
        int bytesRead = in.read(buffer);
        if (bytesRead != size) {
            throw new RuntimeException(""Read size does not match expected size."");
        }
        try (ByteArrayInputStream bais = new ByteArrayInputStream(buffer);
            DataInputViewStreamWrapper inView = new DataInputViewStreamWrapper(bais)) {
            defaultValue = serializer.deserialize(inView);
        } catch (Exception e) {
            throw new IOException(""Unable to deserialize default value."", e);
        }
    } else {
        defaultValue = null;
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-3762_dc78a747,Major,flink-core/src/main/java/org/apache/flink/api/java/typeutils/runtime/kryo/KryoSerializer.java,326,376,"private void checkKryoInitialized() {
    if (this.kryo == null) {
        this.kryo = getKryoInstance();
        // disable reference tracking. reference tracking is costly, usually unnecessary, and
        // inconsistent with Flink's own serialization (which does not do reference tracking)
        kryo.setReferences(false);
        // Throwable and all subclasses should be serialized via java serialization
        kryo.addDefaultSerializer(Throwable.class, new JavaSerializer());
        // are registered with a default serializer
        for (Map.Entry<Class<?>, ExecutionConfig.SerializableSerializer<?>> entry : defaultSerializers.entrySet()) {
            kryo.addDefaultSerializer(entry.getKey(), entry.getValue().getSerializer());
        }
        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> entry : defaultSerializerClasses.entrySet()) {
            kryo.addDefaultSerializer(entry.getKey(), entry.getValue());
        }
        // register the type of our class
        kryo.register(type);
        // more specific serializer overrides this
        for (Class<?> type : registeredTypes) {
            kryo.register(type);
        }
        // register given serializer classes
        for (Map.Entry<Class<?>, Class<? extends Serializer<?>>> e : registeredTypesWithSerializerClasses.entrySet()) {
            Class<?> typeClass = e.getKey();
            Class<? extends Serializer<?>> serializerClass = e.getValue();
            Serializer<?> serializer = ReflectionSerializerFactory.makeSerializer(kryo, serializerClass, typeClass);
            kryo.register(typeClass, serializer);
        }
        // register given serializers
        for (Map.Entry<Class<?>, ExecutionConfig.SerializableSerializer<?>> e : registeredTypesWithSerializers.entrySet()) {
            kryo.register(e.getKey(), e.getValue().getSerializer());
        }
        // this is needed for Avro but can not be added on demand.
        kryo.register(GenericData.Array.class, new SpecificInstanceCollectionSerializerForArrayList());
        kryo.setRegistrationRequired(false);
        kryo.setClassLoader(Thread.currentThread().getContextClassLoader());
    }
}"
flink,remotes/origin/bugs-dot-jar_FLINK-996_32a003d5,Major,stratosphere-compiler/src/main/java/eu/stratosphere/compiler/PactCompiler.java,1211,1258,"@Override
public void postVisit(PlanNode visitable) {
    if (visitable instanceof BinaryUnionPlanNode) {
        final BinaryUnionPlanNode unionNode = (BinaryUnionPlanNode) visitable;
        final Channel in1 = unionNode.getInput1();
        final Channel in2 = unionNode.getInput2();
        PlanNode newUnionNode;
        // if any input is cached, we keep this as a binary union and do not collapse it into a
        // n-ary union
        // if (in1.getTempMode().isCached() || in2.getTempMode().isCached()) {
        // // replace this node by an explicit operator
        // Channel cached, pipelined;
        // if (in1.getTempMode().isCached()) {
        // cached = in1;
        // pipelined = in2;
        // } else {
        // cached = in2;
        // pipelined = in1;
        // }
        // 
        // newUnionNode = new DualInputPlanNode(unionNode.getOriginalOptimizerNode(), cached, pipelined,
        // DriverStrategy.UNION_WITH_CACHED);
        // newUnionNode.initProperties(unionNode.getGlobalProperties(), new LocalProperties());
        // 
        // in1.setTarget(newUnionNode);
        // in2.setTarget(newUnionNode);
        // } else {
        // collect the union inputs to collapse this operator with
        // its collapsed predecessors. check whether an input is materialized to prevent
        // collapsing
        List<Channel> inputs = new ArrayList<Channel>();
        collect(in1, inputs);
        collect(in2, inputs);
        newUnionNode = new NAryUnionPlanNode(unionNode.getOptimizerNode(), inputs, unionNode.getGlobalProperties());
        // adjust the input channels to have their target point to the new union node
        for (Channel c : inputs) {
            c.setTarget(newUnionNode);
        }
        // }
        unionNode.getOutgoingChannels().get(0).swapUnionNodes(newUnionNode);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1020_83427028,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/delegate/NodeDelegate.java,567,631,"private Tree findMatchingPropertyDefinition(List<Tree> types, String propertyName, Type<?> propertyType, boolean exactTypeMatch) {
    // Escape the property name for looking up a matching definition
    String escapedName;
    if (JCR_PRIMARYTYPE.equals(propertyName)) {
        escapedName = ""oak:primaryType"";
    } else if (JCR_MIXINTYPES.equals(propertyName)) {
        escapedName = ""oak:mixinTypes"";
    } else if (JCR_UUID.equals(propertyName)) {
        escapedName = ""oak:uuid"";
    } else {
        escapedName = propertyName;
    }
    String definedType = propertyType.toString();
    String undefinedType = UNDEFINED.toString();
    if (propertyType.isArray()) {
        undefinedType = UNDEFINEDS.toString();
    }
    // First look for a matching named property definition
    for (Tree type : types) {
        Tree definitions = type.getChild(OAK_NAMED_PROPERTY_DEFINITIONS).getChild(escapedName);
        Tree definition = definitions.getChild(definedType);
        if (definition.exists()) {
            return definition;
        }
        definition = definitions.getChild(undefinedType);
        if (definition.exists()) {
            return definition;
        }
        if (!exactTypeMatch) {
            for (Tree def : definitions.getChildren()) {
                if (propertyType.isArray() == TreeUtil.getBoolean(def, JCR_MULTIPLE)) {
                    return def;
                }
            }
        }
    }
    // Then look through any residual property definitions
    for (Tree type : types) {
        Tree definitions = type.getChild(OAK_RESIDUAL_PROPERTY_DEFINITIONS);
        Tree definition = definitions.getChild(definedType);
        if (definition.exists()) {
            return definition;
        }
        definition = definitions.getChild(undefinedType);
        if (definition.exists()) {
            return definition;
        }
        if (!exactTypeMatch) {
            for (Tree def : definitions.getChildren()) {
                if (propertyType.isArray() == TreeUtil.getBoolean(def, JCR_MULTIPLE)) {
                    return def;
                }
            }
        }
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1024_ecc5bdfd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/FullTextSearchImpl.java,159,209,"@Override
public boolean evaluate() {
    // such as index aggregation
    if (selector.index instanceof FulltextQueryIndex) {
        // aggregation bits
        if (relativePath == null && propertyName != null) {
            PropertyValue p = selector.currentProperty(propertyName);
            if (p == null) {
                return false;
            }
        }
        return true;
    }
    StringBuilder buff = new StringBuilder();
    if (relativePath == null && propertyName != null) {
        PropertyValue p = selector.currentProperty(propertyName);
        if (p == null) {
            return false;
        }
        appendString(buff, p);
    } else {
        String path = selector.currentPath();
        if (relativePath != null) {
            path = PathUtils.concat(path, relativePath);
        }
        Tree tree = getTree(path);
        if (tree == null || !tree.exists()) {
            return false;
        }
        if (propertyName != null) {
            PropertyState p = tree.getProperty(propertyName);
            if (p == null) {
                return false;
            }
            appendString(buff, PropertyValues.create(p));
        } else {
            for (PropertyState p : tree.getProperties()) {
                appendString(buff, PropertyValues.create(p));
            }
        }
    }
    return getFullTextConstraint(selector).evaluate(buff.toString());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1035_b2ca8baa,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/ContentMirrorStoreStrategy.java,144,180,"@Override
public long count(NodeState indexMeta, Set<String> values, int max) {
    NodeState index = indexMeta.getChildNode(INDEX_CONTENT_NODE_NAME);
    int count = 0;
    if (values == null) {
        PropertyState ec = indexMeta.getProperty(ENTRY_COUNT_PROPERTY_NAME);
        if (ec != null) {
            return ec.getValue(Type.LONG);
        }
        CountingNodeVisitor v = new CountingNodeVisitor(max);
        v.visit(index);
        count = v.getEstimatedCount();
        // ""is not null"" queries typically read more data
        count *= 10;
    } else {
        int size = values.size();
        if (size == 0) {
            return 0;
        }
        max = Math.max(10, max / size);
        int i = 0;
        for (String p : values) {
            if (count > max && i > 3) {
                count = count / size / i;
                break;
            }
            NodeState s = index.getChildNode(p);
            if (s.exists()) {
                CountingNodeVisitor v = new CountingNodeVisitor(max);
                v.visit(s);
                count += v.getEstimatedCount();
            }
            i++;
        }
    }
    return count;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1054_0adf3a6e,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/user/UserValidator.java,150,158,"@Override
public Validator childNodeDeleted(String name, NodeState before) throws CommitFailedException {
    Tree node = parentBefore.getChild(name);
    if (isAdminUser(node)) {
        String msg = ""The admin user cannot be removed."";
        throw constraintViolation(27, msg);
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1075_79467350,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/ComparisonImpl.java,116,134,"/**
 * ""operand2 always evaluates to a scalar value""
 *
 * for multi-valued properties: if any of the value matches, then return true
 *
 * @param p1
 * @param p2
 * @return
 */
private boolean evaluate(PropertyValue p1, PropertyValue p2) {
    switch(operator) {
        case EQUAL:
            return PropertyValues.match(p1, p2);
        case NOT_EQUAL:
            return !PropertyValues.match(p1, p2);
        case GREATER_OR_EQUAL:
            return p1.compareTo(p2) >= 0;
        case GREATER_THAN:
            return p1.compareTo(p2) > 0;
        case LESS_OR_EQUAL:
            return p1.compareTo(p2) <= 0;
        case LESS_THAN:
            return p1.compareTo(p2) < 0;
        case LIKE:
            return evaluateLike(p1, p2);
    }
    throw new IllegalArgumentException(""Unknown operator: "" + operator);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1075_79467350,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/index/FilterImpl.java,248,302,"public void restrictProperty(String propertyName, Operator op, PropertyValue v) {
    PropertyRestriction x = addRestricition(propertyName);
    PropertyValue oldFirst = x.first;
    PropertyValue oldLast = x.last;
    switch(op) {
        case EQUAL:
            if (x.first != null && x.last == x.first && x.firstIncluding && x.lastIncluding) {
                // if x is a multi-valued property with value ""{1, 2}"")
                return;
            }
            x.first = maxValue(oldFirst, v);
            x.firstIncluding = x.first == oldFirst ? x.firstIncluding : true;
            x.last = minValue(oldLast, v);
            x.lastIncluding = x.last == oldLast ? x.lastIncluding : true;
            break;
        case NOT_EQUAL:
            if (v != null) {
                throw new IllegalArgumentException(""NOT_EQUAL only supported for NOT_EQUAL NULL"");
            }
            break;
        case GREATER_THAN:
            x.first = maxValue(oldFirst, v);
            x.firstIncluding = false;
            break;
        case GREATER_OR_EQUAL:
            x.first = maxValue(oldFirst, v);
            x.firstIncluding = x.first == oldFirst ? x.firstIncluding : true;
            break;
        case LESS_THAN:
            x.last = minValue(oldLast, v);
            x.lastIncluding = false;
            break;
        case LESS_OR_EQUAL:
            x.last = minValue(oldLast, v);
            x.lastIncluding = x.last == oldLast ? x.lastIncluding : true;
            break;
        case LIKE:
            // LIKE is handled in the fulltext index
            x.isLike = true;
            x.first = v;
            break;
        case IN:
    }
    if (x.first != null && x.last != null) {
        if (x.first.compareTo(x.last) > 0) {
            setAlwaysFalse();
        } else if (x.first.compareTo(x.last) == 0 && (!x.firstIncluding || !x.lastIncluding)) {
            setAlwaysFalse();
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1075_79467350,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/query/PropertyValues.java,157,186,"public static boolean match(PropertyValue p1, PropertyValue p2) {
    if (p1.getType().tag() != p2.getType().tag()) {
        return false;
    }
    switch(p1.getType().tag()) {
        case PropertyType.BINARY:
            if (p1.isArray() && !p2.isArray()) {
                return contains(p1.getValue(Type.BINARIES), p2.getValue(Type.BINARY));
            }
            if (!p1.isArray() && p2.isArray()) {
                return contains(p2.getValue(Type.BINARIES), p2.getValue(Type.BINARY));
            }
            break;
        default:
            if (p1.isArray() && !p2.isArray()) {
                return contains(p1.getValue(Type.STRINGS), p2.getValue(Type.STRING));
            }
            if (!p1.isArray() && p2.isArray()) {
                return contains(p2.getValue(Type.STRINGS), p1.getValue(Type.STRING));
            }
    }
    // both arrays or both single values
    return p1.compareTo(p2) == 0;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1076_9238264d,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SelectorImpl.java,528,561,"private PropertyValue currentOakProperty(String oakPropertyName, Integer propertyType) {
    boolean asterisk = oakPropertyName.indexOf('*') >= 0;
    if (asterisk) {
        Tree t = currentTree();
        ArrayList<PropertyValue> list = new ArrayList<PropertyValue>();
        readOakProperties(list, t, oakPropertyName, propertyType);
        if (list.size() == 0) {
            return null;
        }
        ArrayList<String> strings = new ArrayList<String>();
        for (PropertyValue p : list) {
            Iterables.addAll(strings, p.getValue(Type.STRINGS));
        }
        return PropertyValues.newString(strings);
    }
    boolean relative = oakPropertyName.indexOf('/') >= 0;
    Tree t = currentTree();
    if (relative) {
        for (String p : PathUtils.elements(PathUtils.getParentPath(oakPropertyName))) {
            if (t == null) {
                return null;
            }
            if (p.equals("".."")) {
                t = t.isRoot() ? null : t.getParent();
            } else if (p.equals(""."")) {
            // same node
            } else {
                t = t.getChild(p);
            }
        }
        oakPropertyName = PathUtils.getName(oakPropertyName);
    }
    return currentOakProperty(t, oakPropertyName, propertyType);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1076_9238264d,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SelectorImpl.java,592,628,"private void readOakProperties(ArrayList<PropertyValue> target, Tree t, String oakPropertyName, Integer propertyType) {
    while (true) {
        if (t == null || !t.exists()) {
            return;
        }
        int slash = oakPropertyName.indexOf('/');
        if (slash < 0) {
            break;
        }
        String parent = oakPropertyName.substring(0, slash);
        oakPropertyName = oakPropertyName.substring(slash + 1);
        if (parent.equals("".."")) {
            t = t.isRoot() ? null : t.getParent();
        } else if (parent.equals(""."")) {
        // same node
        } else if (parent.equals(""*"")) {
            for (Tree child : t.getChildren()) {
                readOakProperties(target, child, oakPropertyName, propertyType);
            }
        } else {
            t = t.getChild(parent);
        }
    }
    if (!""*"".equals(oakPropertyName)) {
        PropertyValue value = currentOakProperty(t, oakPropertyName, propertyType);
        if (value != null) {
            target.add(value);
        }
        return;
    }
    for (PropertyState p : t.getProperties()) {
        if (propertyType == null || p.getType().tag() == propertyType) {
            PropertyValue v = PropertyValues.create(p);
            target.add(v);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1081_4ce4e3c9,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/delegate/NodeDelegate.java,334,350,"/**
 * Returns an iterator for traversing all the children of this node.
 * If the node is orderable then the iterator will return child nodes in the
 * specified order. Otherwise the ordering of the iterator is undefined.
 *
 * @return child nodes of the node
 */
@Nonnull
public Iterator<NodeDelegate> getChildren() throws InvalidItemStateException {
    Iterator<Tree> iterator = getTree().getChildren().iterator();
    return transform(filter(iterator, new Predicate<Tree>() {

        @Override
        public boolean apply(Tree tree) {
            return !tree.getName().startsWith("":"");
        }
    }), new Function<Tree, NodeDelegate>() {

        @Override
        public NodeDelegate apply(Tree tree) {
            return new NodeDelegate(sessionDelegate, tree);
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1081_4ce4e3c9,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/delegate/NodeDelegate.java,339,342,"@Override
public boolean apply(Tree tree) {
    return !tree.getName().startsWith("":"");
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1081_4ce4e3c9,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/delegate/NodeDelegate.java,453,493,"/**
 * Set a property
 *
 * @param propertyState
 * @return the set property
 */
@Nonnull
public PropertyDelegate setProperty(PropertyState propertyState, boolean exactTypeMatch, boolean setProtected) throws RepositoryException {
    Tree tree = getTree();
    String name = propertyState.getName();
    Type<?> type = propertyState.getType();
    PropertyState old = tree.getProperty(name);
    if (old != null && old.isArray() && !propertyState.isArray()) {
        throw new ValueFormatException(""Can not assign a single value to multi-valued property: "" + propertyState);
    }
    if (old != null && !old.isArray() && propertyState.isArray()) {
        throw new ValueFormatException(""Can not assign multiple values to single valued property: "" + propertyState);
    }
    Tree definition = findMatchingPropertyDefinition(getNodeTypes(tree), name, type, exactTypeMatch);
    if (definition == null) {
        throw new ConstraintViolationException(""No matching property definition: "" + propertyState);
    } else if (!setProtected && TreeUtil.getBoolean(definition, JCR_PROTECTED)) {
        throw new ConstraintViolationException(""Property is protected: "" + propertyState);
    }
    Type<?> requiredType = Type.fromString(TreeUtil.getString(definition, JCR_REQUIREDTYPE));
    if (requiredType != Type.UNDEFINED) {
        if (TreeUtil.getBoolean(definition, JCR_MULTIPLE)) {
            requiredType = requiredType.getArrayType();
        }
        propertyState = PropertyStates.convert(propertyState, requiredType);
    }
    tree.setProperty(propertyState);
    return new PropertyDelegate(sessionDelegate, tree, name);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1081_4ce4e3c9,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/delegate/NodeDelegate.java,824,830,"// FIXME this should be package private. OAK-672
@Nonnull
public Tree getTree() throws InvalidItemStateException {
    if (!tree.exists()) {
        throw new InvalidItemStateException(""Item is stale"");
    }
    return tree;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1093_531aca78,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/query/RowImpl.java,97,110,"@Override
public Value[] getValues() throws RepositoryException {
    PropertyValue[] values = row.getValues();
    int len = values.length;
    Value[] v2 = new Value[values.length];
    for (int i = 0; i < len; i++) {
        if (values[i].isArray()) {
            v2[i] = result.createValue(mvpToString(values[i]));
        } else {
            v2[i] = result.createValue(values[i]);
        }
    }
    return v2;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1093_d7f0f180,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/query/RowImpl.java,93,102,"@Override
public Value[] getValues() throws RepositoryException {
    PropertyValue[] values = row.getValues();
    int len = values.length;
    Value[] v2 = new Value[values.length];
    for (int i = 0; i < len; i++) {
        v2[i] = result.createValue(values[i]);
    }
    return v2;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1094_2e20589f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,920,936,"synchronized void refresh(K key, int hash, CacheLoader<K, V> loader) throws ExecutionException {
    V value;
    V old = get(key, hash);
    long start = System.nanoTime();
    try {
        ListenableFuture<V> future = loader.reload(key, old);
        value = future.get();
        loadSuccessCount++;
    } catch (Exception e) {
        loadExceptionCount++;
        throw new ExecutionException(e);
    } finally {
        long time = System.nanoTime() - start;
        totalLoadTime += time;
    }
    put(key, hash, value, cache.sizeOf(key, value));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1096_be44b816,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/query/QueryImpl.java,87,90,"@Override
public QueryResult execute() throws RepositoryException {
    return manager.executeQuery(statement, language, limit, offset, bindVariableMap);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1104_7ae92779,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/MapEntry.java,87,94,"// --------------------------------------------------------< Comparable >--
@Override
public int compareTo(MapEntry that) {
    return ComparisonChain.start().compare(getHash(), that.getHash()).compare(name, that.name).compare(value, that.value).result();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1104_7ae92779,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/MapRecord.java,138,185,"MapEntry getEntry(String key) {
    checkNotNull(key);
    Segment segment = getSegment();
    int head = segment.readInt(getOffset(0));
    int size = getSize(head);
    if (size == 0) {
        // shortcut
        return null;
    }
    int hash = getHash(key);
    int level = getLevel(head);
    if (isBranch(size, level)) {
        // this is an intermediate branch record
        // check if a matching bucket exists, and recurse
        int bitmap = segment.readInt(getOffset(4));
        int mask = BUCKETS_PER_LEVEL - 1;
        int shift = 32 - (level + 1) * LEVEL_BITS;
        int index = (hash >> shift) & mask;
        int bit = 1 << index;
        if ((bitmap & bit) != 0) {
            int ids = bitCount(bitmap & (bit - 1));
            RecordId id = segment.readRecordId(getOffset(8, ids));
            return new MapRecord(segment, id).getEntry(key);
        } else {
            return null;
        }
    }
    // this is a leaf record; scan the list to find a matching entry
    int d = -1;
    for (int i = 0; i < size && d < 0; i++) {
        d = Integer.valueOf(segment.readInt(getOffset(4 + i * 4))).compareTo(Integer.valueOf(hash));
        if (d == 0) {
            RecordId keyId = segment.readRecordId(getOffset(4 + size * 4, i));
            d = segment.readString(keyId).compareTo(key);
            if (d == 0) {
                RecordId valueId = segment.readRecordId(getOffset(4 + size * 4, size + i));
                return new MapEntry(segment, key, keyId, valueId);
            }
        }
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1104_7ae92779,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/MapRecord.java,371,386,"private static int compare(MapEntry before, MapEntry after) {
    if (before == null) {
        // sentinel value appear greater than any normal value.
        return 1;
    } else if (after == null) {
        // see above
        return -1;
    } else {
        return ComparisonChain.start().compare(before.getHash(), after.getHash()).compare(before.getName(), after.getName()).result();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1108_a8c925e0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/index/FilterImpl.java,248,295,"public void restrictProperty(String propertyName, Operator op, PropertyValue v) {
    PropertyRestriction x = addRestricition(propertyName);
    PropertyValue oldFirst = x.first;
    PropertyValue oldLast = x.last;
    switch(op) {
        case EQUAL:
            x.first = maxValue(oldFirst, v);
            x.firstIncluding = x.first == oldFirst ? x.firstIncluding : true;
            x.last = minValue(oldLast, v);
            x.lastIncluding = x.last == oldLast ? x.lastIncluding : true;
            break;
        case NOT_EQUAL:
            if (v != null) {
                throw new IllegalArgumentException(""NOT_EQUAL only supported for NOT_EQUAL NULL"");
            }
            break;
        case GREATER_THAN:
            x.first = maxValue(oldFirst, v);
            x.firstIncluding = false;
            break;
        case GREATER_OR_EQUAL:
            x.first = maxValue(oldFirst, v);
            x.firstIncluding = x.first == oldFirst ? x.firstIncluding : true;
            break;
        case LESS_THAN:
            x.last = minValue(oldLast, v);
            x.lastIncluding = false;
            break;
        case LESS_OR_EQUAL:
            x.last = minValue(oldLast, v);
            x.lastIncluding = x.last == oldLast ? x.lastIncluding : true;
            break;
        case LIKE:
            // LIKE is handled in the fulltext index
            x.isLike = true;
            x.first = v;
            break;
        case IN:
    }
    if (x.first != null && x.last != null) {
        if (x.first.compareTo(x.last) > 0) {
            setAlwaysFalse();
        } else if (x.first.compareTo(x.last) == 0 && (!x.firstIncluding || !x.lastIncluding)) {
            setAlwaysFalse();
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1111_459bd065,Critical,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/PersistenceCopier.java,283,326,"private org.apache.jackrabbit.oak.api.PropertyState getProperty(String name, InternalValue value, int type) throws RepositoryException, IOException {
    switch(type) {
        case PropertyType.BINARY:
            return PropertyStates.createProperty(name, store.createBlob(value.getStream()), Type.BINARY);
        case PropertyType.BOOLEAN:
            return PropertyStates.createProperty(name, value.getBoolean(), Type.BOOLEAN);
        case PropertyType.DATE:
            return PropertyStates.createProperty(name, value.getCalendar().getTimeInMillis(), Type.DATE);
        case PropertyType.DECIMAL:
            return PropertyStates.createProperty(name, value.getDecimal(), Type.DECIMAL);
        case PropertyType.DOUBLE:
            return PropertyStates.createProperty(name, value.getDouble(), Type.DOUBLE);
        case PropertyType.LONG:
            return PropertyStates.createProperty(name, value.getLong(), Type.LONG);
        case PropertyType.NAME:
            return PropertyStates.createProperty(name, getOakName(value.getName()), Type.NAME);
        case PropertyType.PATH:
            return PropertyStates.createProperty(name, getOakPath(value.getPath()), Type.PATH);
        case PropertyType.REFERENCE:
            return PropertyStates.createProperty(name, value.getNodeId().toString(), Type.REFERENCE);
        case PropertyType.STRING:
            return PropertyStates.createProperty(name, value.getString(), Type.STRING);
        case PropertyType.URI:
            return PropertyStates.createProperty(name, value.getURI().toString(), Type.URI);
        case PropertyType.WEAKREFERENCE:
            return PropertyStates.createProperty(name, value.getNodeId().toString(), Type.WEAKREFERENCE);
        default:
            throw new RepositoryException(""Unknown value type: "" + type);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1122_5286861d,Minor,oak-mk/src/main/java/org/apache/jackrabbit/mk/core/MicroKernelImpl.java,406,526,"public String commit(String path, String jsonDiff, String revisionId, String message) throws MicroKernelException {
    if (rep == null) {
        throw new IllegalStateException(""this instance has already been disposed"");
    }
    if (path.length() > 0 && !PathUtils.isAbsolute(path)) {
        throw new IllegalArgumentException(""absolute path expected: "" + path);
    }
    if (jsonDiff == null || jsonDiff.length() == 0) {
        return getHeadRevision();
    }
    Id revId = revisionId == null ? getHeadRevisionId() : Id.fromString(revisionId);
    try {
        JsopTokenizer t = new JsopTokenizer(jsonDiff);
        CommitBuilder cb = rep.getCommitBuilder(revId, message);
        while (true) {
            int r = t.read();
            if (r == JsopReader.END) {
                break;
            }
            // used for error reporting
            int pos;
            switch(r) {
                case '+':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        t.read(':');
                        t.read('{');
                        String nodePath = PathUtils.concat(path, subPath);
                        if (!PathUtils.isAbsolute(nodePath)) {
                            throw new Exception(""absolute path expected: "" + nodePath + "", pos: "" + pos);
                        }
                        String parentPath = PathUtils.getParentPath(nodePath);
                        String nodeName = PathUtils.getName(nodePath);
                        cb.addNode(parentPath, nodeName, JsonObject.create(t));
                        break;
                    }
                case '-':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        String targetPath = PathUtils.concat(path, subPath);
                        if (!PathUtils.isAbsolute(targetPath)) {
                            throw new Exception(""absolute path expected: "" + targetPath + "", pos: "" + pos);
                        }
                        cb.removeNode(targetPath);
                        break;
                    }
                case '^':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        t.read(':');
                        String value;
                        if (t.matches(JsopReader.NULL)) {
                            value = null;
                        } else {
                            value = t.readRawValue().trim();
                        }
                        String targetPath = PathUtils.concat(path, subPath);
                        if (!PathUtils.isAbsolute(targetPath)) {
                            throw new Exception(""absolute path expected: "" + targetPath + "", pos: "" + pos);
                        }
                        String parentPath = PathUtils.getParentPath(targetPath);
                        String propName = PathUtils.getName(targetPath);
                        cb.setProperty(parentPath, propName, value);
                        break;
                    }
                case '>':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        String srcPath = PathUtils.concat(path, subPath);
                        if (!PathUtils.isAbsolute(srcPath)) {
                            throw new Exception(""absolute path expected: "" + srcPath + "", pos: "" + pos);
                        }
                        t.read(':');
                        pos = t.getLastPos();
                        String targetPath = t.readString();
                        if (!PathUtils.isAbsolute(targetPath)) {
                            targetPath = PathUtils.concat(path, targetPath);
                            if (!PathUtils.isAbsolute(targetPath)) {
                                throw new Exception(""absolute path expected: "" + targetPath + "", pos: "" + pos);
                            }
                        }
                        cb.moveNode(srcPath, targetPath);
                        break;
                    }
                case '*':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        String srcPath = PathUtils.concat(path, subPath);
                        if (!PathUtils.isAbsolute(srcPath)) {
                            throw new Exception(""absolute path expected: "" + srcPath + "", pos: "" + pos);
                        }
                        t.read(':');
                        pos = t.getLastPos();
                        String targetPath = t.readString();
                        if (!PathUtils.isAbsolute(targetPath)) {
                            targetPath = PathUtils.concat(path, targetPath);
                            if (!PathUtils.isAbsolute(targetPath)) {
                                throw new Exception(""absolute path expected: "" + targetPath + "", pos: "" + pos);
                            }
                        }
                        cb.copyNode(srcPath, targetPath);
                        break;
                    }
                default:
                    throw new IllegalArgumentException(""jsonDiff: illegal token '"" + t.getToken() + ""' at pos: "" + t.getLastPos());
            }
        }
        Id newHead = cb.doCommit();
        if (!newHead.equals(revId)) {
            // non-empty commit
            if (rep.getCommit(newHead).getBranchRootId() == null) {
                // OAK-265: only trigger commit gate for non-branch commits
                gate.commit(newHead.toString());
            }
        }
        return newHead.toString();
    } catch (Exception e) {
        throw new MicroKernelException(e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1129_2f95b81f,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/MongoNodeStore.java,740,758,"@Nonnull
Revision rebase(@Nonnull Revision branchHead, @Nonnull Revision base) {
    checkNotNull(branchHead);
    checkNotNull(base);
    // TODO conflict handling
    Branch b = getBranches().getBranch(branchHead);
    if (b == null) {
        // empty branch
        return base.asBranchRevision();
    }
    if (b.getBase().equals(base)) {
        return branchHead;
    }
    // add a pseudo commit to make sure current head of branch
    // has a higher revision than base of branch
    Revision head = newRevision().asBranchRevision();
    b.rebase(head, base);
    return head;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1155_f64e8adc,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/ContentMirrorStoreStrategy.java,370,394,"@Override
public void visit(NodeState state) {
    if (state.hasProperty(""match"")) {
        count++;
        depthTotal += depth;
    }
    if (count < maxCount) {
        depth++;
        int width = 0;
        boolean finished = true;
        for (ChildNodeEntry entry : state.getChildNodeEntries()) {
            if (count >= maxCount) {
                finished = false;
                break;
            }
            width++;
            visit(entry.getNodeState());
        }
        if (finished && width > 0) {
            widthTotal += width;
            widthCount++;
        }
        depth--;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1155_f64e8adc,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/ContentMirrorStoreStrategy.java,413,429,"/**
 * The number of estimated matches. This value might be higher than the
 * number of counted matches, if the maximum number of matches has been
 * reached. It is based on the average depth of matches, and the average
 * number of child nodes.
 *
 * @return the estimated matches
 */
int getEstimatedCount() {
    if (count < maxCount) {
        return count;
    }
    double averageDepth = (int) (depthTotal / count);
    double averageWidth = 2;
    if (widthCount > 0) {
        averageWidth = (int) (widthTotal / widthCount);
    }
    // calculate with an average width of at least 2
    averageWidth = Math.max(2, averageWidth);
    // the number of estimated matches is calculated as the
    // of a estimated
    long estimatedNodes = (long) Math.pow(averageWidth, 2 * averageDepth);
    estimatedNodes = Math.min(estimatedNodes, Integer.MAX_VALUE);
    return Math.max(count, (int) estimatedNodes);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1168_c05cec12,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/NamePathMapperImpl.java,232,286,"/**
 * Checks if the given path needs to be fully parsed to apply namespace
 * mappings or to validate its syntax. If the given path is ""simple"", i.e.
 * it doesn't contain any complex constructs, and there are no local
 * namespace remappings, it's possible to skip the full path parsing
 * and simply use the JCR path string as-is as an Oak path.
 *
 * @param path JCR path
 * @return {@code true} if the path needs to be fully parsed,
 *         {@code false} if not
 */
private boolean needsFullMapping(String path) {
    int length = path.length();
    if (length == 0) {
        return true;
    }
    // index of the last slash in the path
    int slash = -1;
    // index of the last colon in the path
    int colon = -1;
    switch(path.charAt(0)) {
        // possibly an expanded name
        case '{':
        // starts with an identifier
        case '[':
        // possibly ""."" or ""..""
        case '.':
        case // colon as the first character
        ':':
            return true;
        case '/':
            if (length == 1) {
                // the root path
                return false;
            }
            slash = 0;
            break;
    }
    for (int i = 1; i < length; i++) {
        switch(path.charAt(i)) {
            // possibly an expanded name
            case '{':
            case // possibly an index
            '[':
                return true;
            case '.':
                if (i == slash + 1) {
                    // possibly ""."" or ""..""
                    return true;
                }
                break;
            case ':':
                if (// ""x/:y""
                i == slash + 1 || // ""x::y""
                i == colon + i || // ""x:y:z""
                colon > slash || i + 1 == length) {
                    // ""x:""
                    return true;
                }
                colon = i;
                break;
            case '/':
                if (// ""x//y""
                i == slash + 1 || // ""x:/y""
                i == colon + i || i + 1 == length) {
                    // ""x/""
                    return true;
                }
                slash = i;
                break;
        }
    }
    return colon != -1 && !nameMapper.getSessionLocalMappings().isEmpty();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1173_61c877d8,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/CompiledPermissionImpl.java,149,185,"@Override
public TreePermission getTreePermission(@Nonnull ImmutableTree tree, @Nonnull TreePermission parentPermission) {
    if (tree.isRoot()) {
        return new TreePermissionImpl(tree, TreeTypeProvider.TYPE_DEFAULT, TreePermission.EMPTY);
    }
    int type = tree.getType();
    switch(type) {
        case TreeTypeProvider.TYPE_HIDDEN:
            // TODO: OAK-753 decide on where to filter out hidden items.
            return TreePermission.ALL;
        case TreeTypeProvider.TYPE_VERSION:
            String ntName = checkNotNull(TreeUtil.getPrimaryTypeName(tree));
            if (VersionConstants.VERSION_STORE_NT_NAMES.contains(ntName) || VersionConstants.NT_ACTIVITY.equals(ntName)) {
                return new TreePermissionImpl(tree, TreeTypeProvider.TYPE_VERSION, parentPermission);
            } else {
                ImmutableTree versionableTree = getVersionableTree(tree);
                if (versionableTree == null) {
                    log.warn(""Cannot retrieve versionable node for "" + tree.getPath());
                    return TreePermission.EMPTY;
                } else {
                    // TODO -> evaluation by path would be more accurate (-> see #isGranted)
                    while (!versionableTree.exists()) {
                        versionableTree = versionableTree.getParent();
                    }
                    TreePermission pp = getParentPermission(versionableTree, TreeTypeProvider.TYPE_VERSION);
                    return new TreePermissionImpl(versionableTree, TreeTypeProvider.TYPE_VERSION, pp);
                }
            }
        case TreeTypeProvider.TYPE_PERMISSION_STORE:
            return TreePermission.EMPTY;
        default:
            return new TreePermissionImpl(tree, type, parentPermission);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1174_342809f7,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/JcrNameParser.java,79,212,"/**
 * Parse the specified jcr name and inform the specified {@code listener}
 * about the result or any error that may occur during parsing.
 *
 * @param jcrName The jcr name to be parsed.
 * @param listener The listener to be informed about success or failure.
 * @param index index, or {@code 0} when not specified
 * @return whether parsing was successful
 */
public static boolean parse(String jcrName, Listener listener, int index) {
    // trivial check
    int len = jcrName == null ? 0 : jcrName.length();
    if (len == 0) {
        listener.error(""Empty name"");
        return false;
    }
    if (""."".equals(jcrName) || "".."".equals(jcrName)) {
        listener.error(""Illegal name:"" + jcrName);
        return false;
    }
    // parse the name
    String prefix;
    int nameStart = 0;
    int state = STATE_PREFIX_START;
    boolean trailingSpaces = false;
    for (int i = 0; i < len; i++) {
        char c = jcrName.charAt(i);
        if (c == ':') {
            if (state == STATE_PREFIX_START) {
                listener.error(""Prefix must not be empty"");
                return false;
            } else if (state == STATE_PREFIX) {
                if (trailingSpaces) {
                    listener.error(""Trailing spaces not allowed"");
                    return false;
                }
                prefix = jcrName.substring(0, i);
                if (!XMLChar.isValidNCName(prefix)) {
                    listener.error(""Invalid name prefix: "" + prefix);
                    return false;
                }
                state = STATE_NAME_START;
            } else if (state == STATE_URI) {
            // ignore -> validation of uri later on.
            } else {
                listener.error(""'"" + c + ""' not allowed in name"");
                return false;
            }
            trailingSpaces = false;
        } else if (c == ' ') {
            if (state == STATE_PREFIX_START || state == STATE_NAME_START) {
                listener.error(""'"" + c + ""' not valid name start"");
                return false;
            }
            trailingSpaces = true;
        } else if (Character.isWhitespace(c) || c == '[' || c == ']' || c == '*' || c == '|') {
            listener.error(""'"" + c + ""' not allowed in name"");
            return false;
        } else if (c == '/') {
            if (state == STATE_URI_START) {
                state = STATE_URI;
            } else if (state != STATE_URI) {
                listener.error(""'"" + c + ""' not allowed in name"");
                return false;
            }
            trailingSpaces = false;
        } else if (c == '{') {
            if (state == STATE_PREFIX_START) {
                state = STATE_URI_START;
            } else if (state == STATE_URI_START || state == STATE_URI) {
                // second '{' in the uri-part -> no valid expanded jcr-name.
                // therefore reset the nameStart and change state.
                state = STATE_NAME;
                nameStart = 0;
            } else if (state == STATE_NAME_START) {
                state = STATE_NAME;
                nameStart = i;
            }
            trailingSpaces = false;
        } else if (c == '}') {
            if (state == STATE_URI_START || state == STATE_URI) {
                String tmp = jcrName.substring(1, i);
                if (tmp.isEmpty() || tmp.indexOf(':') != -1) {
                    // The leading ""{...}"" part is empty or contains
                    // a colon, so we treat it as a valid namespace URI.
                    // More detailed validity checks (is it well formed,
                    // registered, etc.) are not needed here.
                    state = STATE_NAME_START;
                } else if (tmp.equals(""internal"")) {
                    // As a special Jackrabbit backwards compatibility
                    // feature, support {internal} as a valid URI prefix
                    state = STATE_NAME_START;
                } else if (tmp.indexOf('/') == -1) {
                    // The leading ""{...}"" contains neither a colon nor
                    // a slash, so we can interpret it as a a part of a
                    // normal local name.
                    state = STATE_NAME;
                    nameStart = 0;
                } else {
                    listener.error(""The URI prefix of the name "" + jcrName + "" is "" + ""neither a valid URI nor a valid part of a local name."");
                    return false;
                }
            } else if (state == STATE_PREFIX_START) {
                // prefix start -> validation later on will fail.
                state = STATE_PREFIX;
            } else if (state == STATE_NAME_START) {
                state = STATE_NAME;
                nameStart = i;
            }
            trailingSpaces = false;
        } else {
            if (state == STATE_PREFIX_START) {
                // prefix start
                state = STATE_PREFIX;
            } else if (state == STATE_NAME_START) {
                state = STATE_NAME;
                nameStart = i;
            } else if (state == STATE_URI_START) {
                state = STATE_URI;
            }
            trailingSpaces = false;
        }
    }
    // a terminating '}' -> make sure there are no illegal characters present.
    if (state == STATE_URI && (jcrName.indexOf(':') > -1 || jcrName.indexOf('/') > -1)) {
        listener.error(""Local name may not contain ':' nor '/'"");
        return false;
    }
    if (nameStart == len || state == STATE_NAME_START) {
        listener.error(""Local name must not be empty"");
        return false;
    }
    if (trailingSpaces) {
        listener.error(""Trailing spaces not allowed"");
        return false;
    }
    return listener.name(jcrName, index);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1174_342809f7,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/JcrPathParser.java,47,263,"public static boolean parse(String jcrPath, Listener listener) {
    // check for length
    int len = jcrPath == null ? 0 : jcrPath.length();
    // shortcut for root path
    if (len == 1 && jcrPath.charAt(0) == '/') {
        listener.root();
        return true;
    }
    // short cut for empty path
    if (len == 0) {
        return true;
    }
    // check if absolute path
    int pos = 0;
    if (jcrPath.charAt(0) == '/') {
        if (!listener.root()) {
            return false;
        }
        pos++;
    }
    // parse the path
    int state = STATE_PREFIX_START;
    int lastPos = pos;
    String name = null;
    int index = 0;
    boolean wasSlash = false;
    while (pos <= len) {
        char c = pos == len ? EOF : jcrPath.charAt(pos);
        pos++;
        // special check for whitespace
        if (c != ' ' && Character.isWhitespace(c)) {
            c = '\t';
        }
        switch(c) {
            case '/':
            case EOF:
                if (state == STATE_PREFIX_START && c != EOF) {
                    listener.error('\'' + jcrPath + ""' is not a valid path. "" + ""double slash '//' not allowed."");
                    return false;
                }
                if (state == STATE_PREFIX || state == STATE_NAME || state == STATE_INDEX_END || state == STATE_URI_END) {
                    // eof path element
                    if (name == null) {
                        if (wasSlash) {
                            listener.error('\'' + jcrPath + ""' is not a valid path: "" + ""Trailing slashes not allowed in prefixes and names."");
                            return false;
                        }
                        name = jcrPath.substring(lastPos, pos - 1);
                    }
                    if (!JcrNameParser.parse(name, listener, index)) {
                        return false;
                    }
                    state = STATE_PREFIX_START;
                    lastPos = pos;
                    name = null;
                    index = 0;
                } else if (state == STATE_DOT) {
                    if (!listener.current()) {
                        return false;
                    }
                    lastPos = pos;
                    state = STATE_PREFIX_START;
                } else if (state == STATE_DOTDOT) {
                    if (!listener.parent()) {
                        return false;
                    }
                    lastPos = pos;
                    state = STATE_PREFIX_START;
                } else if (state != STATE_URI && !(state == STATE_PREFIX_START && c == EOF)) {
                    // ignore trailing slash
                    listener.error('\'' + jcrPath + ""' is not a valid path. '"" + c + ""' not a valid name character."");
                    return false;
                }
                break;
            case '.':
                if (state == STATE_PREFIX_START) {
                    state = STATE_DOT;
                } else if (state == STATE_DOT) {
                    state = STATE_DOTDOT;
                } else if (state == STATE_DOTDOT) {
                    state = STATE_PREFIX;
                } else if (state == STATE_INDEX_END) {
                    listener.error('\'' + jcrPath + ""' is not a valid path. '"" + c + ""' not valid after index. '/' expected."");
                    return false;
                }
                break;
            case ':':
                if (state == STATE_PREFIX_START) {
                    listener.error('\'' + jcrPath + ""' is not a valid path. Prefix "" + ""must not be empty"");
                    return false;
                } else if (state == STATE_PREFIX) {
                    if (wasSlash) {
                        listener.error('\'' + jcrPath + ""' is not a valid path: "" + ""Trailing slashes not allowed in prefixes and names."");
                        return false;
                    }
                    state = STATE_NAME_START;
                // don't reset the lastPos/pos since prefix+name are passed together to the NameResolver
                } else if (state != STATE_URI) {
                    listener.error('\'' + jcrPath + ""' is not a valid path. '"" + c + ""' not valid name character"");
                    return false;
                }
                break;
            case '[':
                if (state == STATE_PREFIX || state == STATE_NAME) {
                    if (wasSlash) {
                        listener.error('\'' + jcrPath + ""' is not a valid path: "" + ""Trailing slashes not allowed in prefixes and names."");
                        return false;
                    }
                    state = STATE_INDEX;
                    name = jcrPath.substring(lastPos, pos - 1);
                    lastPos = pos;
                }
                break;
            case ']':
                if (state == STATE_INDEX) {
                    try {
                        index = Integer.parseInt(jcrPath.substring(lastPos, pos - 1));
                    } catch (NumberFormatException e) {
                        listener.error('\'' + jcrPath + ""' is not a valid path. "" + ""NumberFormatException in index: "" + jcrPath.substring(lastPos, pos - 1));
                        return false;
                    }
                    if (index < 0) {
                        listener.error('\'' + jcrPath + ""' is not a valid path. "" + ""Index number invalid: "" + index);
                        return false;
                    }
                    state = STATE_INDEX_END;
                } else {
                    listener.error('\'' + jcrPath + ""' is not a valid path. '"" + c + ""' not a valid name character."");
                    return false;
                }
                break;
            case ' ':
                if (state == STATE_PREFIX_START || state == STATE_NAME_START) {
                    listener.error('\'' + jcrPath + ""' is not a valid path. '"" + c + ""' not valid name start"");
                    return false;
                } else if (state == STATE_INDEX_END) {
                    listener.error('\'' + jcrPath + ""' is not a valid path. '"" + c + ""' not valid after index. '/' expected."");
                    return false;
                } else if (state == STATE_DOT || state == STATE_DOTDOT) {
                    state = STATE_PREFIX;
                }
                break;
            case '\t':
                listener.error('\'' + jcrPath + ""' is not a valid path. "" + ""Whitespace not a allowed in name."");
                return false;
            case '*':
            case '|':
                listener.error('\'' + jcrPath + ""' is not a valid path. '"" + c + ""' not a valid name character."");
                return false;
            case '{':
                if (state == STATE_PREFIX_START && lastPos == pos - 1) {
                    // '{' marks the start of a uri enclosed in an expanded name
                    // instead of the usual namespace prefix, if it is
                    // located at the beginning of a new segment.
                    state = STATE_URI;
                } else if (state == STATE_NAME_START || state == STATE_DOT || state == STATE_DOTDOT) {
                    // otherwise it's part of the local name
                    state = STATE_NAME;
                }
                break;
            case '}':
                if (state == STATE_URI) {
                    state = STATE_URI_END;
                }
                break;
            default:
                if (state == STATE_PREFIX_START || state == STATE_DOT || state == STATE_DOTDOT) {
                    state = STATE_PREFIX;
                } else if (state == STATE_NAME_START) {
                    state = STATE_NAME;
                } else if (state == STATE_INDEX_END) {
                    listener.error('\'' + jcrPath + ""' is not a valid path. '"" + c + ""' not valid after index. '/' expected."");
                    return false;
                }
        }
        wasSlash = c == ' ';
    }
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1174_342809f7,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/name/Namespaces.java,240,258,"public static boolean isValidLocalName(String local) {
    if (local.isEmpty() || ""."".equals(local) || "".."".equals(local)) {
        return false;
    }
    for (int i = 0; i < local.length(); i++) {
        char ch = local.charAt(i);
        if (i == 0 && Character.isWhitespace(ch)) {
            // leading whitespace
            return false;
        } else if (i == local.length() - 1 && Character.isWhitespace(ch)) {
            // trailing whitespace
            return false;
        } else if (""/:[]|*"".indexOf(ch) != -1) {
            // invalid name character
            return false;
        }
    }
    // TODO: Other name rules?
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1178_84fb6b29,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,261,264,"@Override
public boolean isNew() {
    return !isRoot() && !parent.base().hasChildNode(name) && parent.hasChildNode(name);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1178_f2bb1a17,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/MutableTree.java,87,90,"@Override
protected boolean isNew() {
    return !getBase().exists();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1178_f2bb1a17,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/MutableTree.java,339,345,"// ---------------------------------------------------------< internal >---
private NodeState getBase() {
    if (parent == null) {
        return root.getBaseState();
    } else {
        return parent.getBase().getChildNode(name);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1178_f2bb1a17,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/MutableTree.java,485,487,"/**
 * Internal method for checking whether this node exists and is visible
 * (i.e. not hidden).
 *
 * @return {@true} if the node is visible, {@code false} if not
 */
private boolean isVisible() {
    return !isHidden(name) && nodeBuilder.exists();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1178_f2bb1a17,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelRootBuilder.java,116,122,"// ------------------------------------------------------------< internal >---
/**
 * Rebase this builder on top of the head of the underlying store
 */
NodeState rebase() {
    purge();
    branch.rebase();
    NodeState head = branch.getHead();
    reset(head);
    return head;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1178_f2bb1a17,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,261,264,"@Override
public boolean isNew() {
    return exists() && !base.exists();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1178_f2bb1a17,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/MongoRootBuilder.java,97,103,"// ------------------------------------------------------------< internal >---
/**
 * Rebase this builder on top of the head of the underlying store
 */
NodeState rebase() {
    purge();
    branch.rebase();
    NodeState head = branch.getHead();
    reset(head);
    return head;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1186_52372042,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/MongoNodeStore.java,781,819,"@Nonnull
Revision reset(@Nonnull Revision branchHead, @Nonnull Revision ancestor) {
    checkNotNull(branchHead);
    checkNotNull(ancestor);
    Branch b = getBranches().getBranch(branchHead);
    if (b == null) {
        throw new MicroKernelException(""Empty branch cannot be reset"");
    }
    if (!b.containsCommit(ancestor)) {
        throw new MicroKernelException(ancestor + "" is not "" + ""an ancestor revision of "" + branchHead);
    }
    Revision rev;
    boolean success = false;
    Commit commit = newCommit(branchHead);
    try {
        // apply reverse diff
        getRoot(ancestor).compareAgainstBaseState(getRoot(branchHead), new CommitDiff(commit, getBlobSerializer()));
        UpdateOp rootOp = commit.getUpdateOperationForNode(""/"");
        // clear collisions
        Iterator<Revision> it = b.getCommits().tailSet(ancestor).iterator();
        // first revision is the ancestor (tailSet is inclusive)
        // do not clear collision for this revision
        it.next();
        while (it.hasNext()) {
            NodeDocument.removeCollision(rootOp, it.next());
        }
        rev = apply(commit);
        success = true;
    } finally {
        if (!success) {
            canceled(commit);
        } else {
            done(commit, true, null);
        }
    }
    return rev;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1208_cb3ac20d,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,437,548,"private static void addNonFullTextConstraints(List<Query> qs, Filter filter, IndexReader reader) {
    if (!filter.matchesAllTypes()) {
        addNodeTypeConstraints(qs, filter);
    }
    String path = filter.getPath();
    switch(filter.getPathRestriction()) {
        case ALL_CHILDREN:
            if (""/"".equals(path)) {
                break;
            }
            if (!path.endsWith(""/"")) {
                path += ""/"";
            }
            qs.add(new PrefixQuery(newPathTerm(path)));
            break;
        case DIRECT_CHILDREN:
            if (!path.endsWith(""/"")) {
                path += ""/"";
            }
            qs.add(new PrefixQuery(newPathTerm(path)));
            break;
        case EXACT:
            qs.add(new TermQuery(newPathTerm(path)));
            break;
        case PARENT:
            if (PathUtils.denotesRoot(path)) {
                // there's no parent of the root node
                // we add a path that can not possibly occur because there
                // is no way to say ""match no documents"" in Lucene
                qs.add(new TermQuery(new Term(FieldNames.PATH, ""///"")));
            } else {
                qs.add(new TermQuery(newPathTerm(PathUtils.getParentPath(path))));
            }
            break;
        case NO_RESTRICTION:
            break;
    }
    for (PropertyRestriction pr : filter.getPropertyRestrictions()) {
        String name = pr.propertyName;
        if (name.contains(""/"")) {
            // lucene cannot handle child-level property restrictions
            continue;
        }
        if (""rep:excerpt"".equals(name)) {
            continue;
        }
        // TODO OAK-985
        if (JcrConstants.JCR_PRIMARYTYPE.equals(name)) {
            continue;
        }
        String first = null;
        String last = null;
        boolean isLike = pr.isLike;
        // TODO what to do with escaped tokens?
        if (pr.first != null) {
            first = pr.first.getValue(Type.STRING);
            first = first.replace(""\\"", """");
        }
        if (pr.last != null) {
            last = pr.last.getValue(Type.STRING);
            last = last.replace(""\\"", """");
        }
        if (isLike) {
            first = first.replace('%', WildcardQuery.WILDCARD_STRING);
            first = first.replace('_', WildcardQuery.WILDCARD_CHAR);
            int indexOfWS = first.indexOf(WildcardQuery.WILDCARD_STRING);
            int indexOfWC = first.indexOf(WildcardQuery.WILDCARD_CHAR);
            int len = first.length();
            if (indexOfWS == len || indexOfWC == len) {
                // remove trailing ""*"" for prefixquery
                first = first.substring(0, first.length() - 1);
                if (JCR_PATH.equals(name)) {
                    qs.add(new PrefixQuery(newPathTerm(first)));
                } else {
                    qs.add(new PrefixQuery(new Term(name, first)));
                }
            } else {
                if (JCR_PATH.equals(name)) {
                    qs.add(new WildcardQuery(newPathTerm(first)));
                } else {
                    qs.add(new WildcardQuery(new Term(name, first)));
                }
            }
            continue;
        }
        if (first != null && first.equals(last) && pr.firstIncluding && pr.lastIncluding) {
            if (JCR_PATH.equals(name)) {
                qs.add(new TermQuery(newPathTerm(first)));
            } else {
                if (""*"".equals(name)) {
                    addReferenceConstraint(first, qs, reader);
                } else {
                    qs.add(new TermQuery(new Term(name, first)));
                }
            }
            continue;
        }
        qs.add(TermRangeQuery.newStringRange(name, first, last, pr.firstIncluding, pr.lastIncluding));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1215_a9efe3c4,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/AstElement.java,59,78,"/**
 * Normalize the property name (including namespace remapping).
 *
 * @param propertyName the property name to normalize
 * @return the normalized property name
 */
protected String normalizePropertyName(String propertyName) {
    // where possible)
    if (query == null) {
        return propertyName;
    }
    if (propertyName == null) {
        return null;
    }
    int slash = propertyName.indexOf('/');
    if (slash < 0) {
        return normalizeNonRelativePropertyName(propertyName);
    }
    // relative properties
    String relativePath = PathUtils.getParentPath(propertyName);
    relativePath = query.getOakPath(relativePath);
    propertyName = PathUtils.getName(propertyName);
    propertyName = normalizeNonRelativePropertyName(propertyName);
    return PathUtils.concat(relativePath, propertyName);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1215_a9efe3c4,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/PropertyValueImpl.java,108,142,"@Override
public PropertyValue currentProperty() {
    boolean asterisk = PathUtils.getName(propertyName).equals(""*"");
    if (!asterisk) {
        PropertyValue p = selector.currentProperty(propertyName);
        return matchesPropertyType(p) ? p : null;
    }
    Tree tree = selector.currentTree();
    if (tree == null || !tree.exists()) {
        return null;
    }
    if (!asterisk) {
        String name = PathUtils.getName(propertyName);
        name = normalizePropertyName(name);
        PropertyState p = tree.getProperty(name);
        if (p == null) {
            return null;
        }
        return matchesPropertyType(p) ? PropertyValues.create(p) : null;
    }
    // asterisk - create a multi-value property
    // warning: the returned property state may have a mixed type
    // (not all values may have the same type)
    // TODO currently all property values are converted to strings -
    // this doesn't play well with the idea that the types may be different
    List<String> values = new ArrayList<String>();
    for (PropertyState p : tree.getProperties()) {
        if (matchesPropertyType(p)) {
            Iterables.addAll(values, p.getValue(Type.STRINGS));
        }
    }
    // ""*""
    return PropertyValues.newString(values);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1215_a9efe3c4,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/PropertyValueImpl.java,144,152,"private boolean matchesPropertyType(PropertyValue value) {
    if (value == null) {
        return false;
    }
    if (propertyType == PropertyType.UNDEFINED) {
        return true;
    }
    return value.getType().tag() == propertyType;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1215_a9efe3c4,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/PropertyValueImpl.java,154,162,"private boolean matchesPropertyType(PropertyState state) {
    if (state == null) {
        return false;
    }
    if (propertyType == PropertyType.UNDEFINED) {
        return true;
    }
    return state.getType().tag() == propertyType;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1215_a9efe3c4,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SelectorImpl.java,395,430,"/**
 * Get the property value. The property name may be relative. The special
 * property names ""jcr:path"", ""jcr:score"" and ""rep:excerpt"" are supported.
 *
 * @param oakPropertyName (must already be normalized)
 * @return the property value or null if not found
 */
public PropertyValue currentOakProperty(String oakPropertyName) {
    boolean relative = oakPropertyName.indexOf('/') >= 0;
    Tree t = currentTree();
    if (relative) {
        for (String p : PathUtils.elements(PathUtils.getParentPath(oakPropertyName))) {
            if (t == null) {
                return null;
            }
            if (p.equals("".."")) {
                t = t.isRoot() ? null : t.getParent();
            } else if (p.equals(""."")) {
            // same node
            } else {
                t = t.getChild(p);
            }
        }
        oakPropertyName = PathUtils.getName(oakPropertyName);
    }
    if (t == null || !t.exists()) {
        return null;
    }
    if (oakPropertyName.equals(QueryImpl.JCR_PATH)) {
        String path = currentPath();
        String local = getLocalPath(path);
        if (local == null) {
            // not a local path
            return null;
        }
        return PropertyValues.newString(local);
    } else if (oakPropertyName.equals(QueryImpl.JCR_SCORE)) {
        return currentRow.getValue(QueryImpl.JCR_SCORE);
    } else if (oakPropertyName.equals(QueryImpl.REP_EXCERPT)) {
        return currentRow.getValue(QueryImpl.REP_EXCERPT);
    }
    return PropertyValues.create(t.getProperty(oakPropertyName));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1215_a9efe3c4,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SourceImpl.java,180,180,"/**
 * <b>!Test purpose only! <b>
 *
 * this creates a filter for the given query
 */
public abstract Filter createFilter(boolean preparing);"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1216_e403e003,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/SessionContext.java,325,333,"/**
 * Returns the Oak path for the given JCR path, or throws a
 * {@link javax.jcr.RepositoryException} if the path can not be mapped.
 *
 * @param jcrPath JCR path
 * @return Oak path
 * @throws javax.jcr.RepositoryException if the path can not be mapped
 */
@Nonnull
public String getOakPathOrThrow(String jcrPath) throws RepositoryException {
    String oakPath = getOakPath(jcrPath);
    if (oakPath != null) {
        return oakPath;
    } else {
        throw new RepositoryException(""Invalid name or path: "" + jcrPath);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1225_3535afe2,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/SessionImpl.java,159,167,"/**
 * Returns the node at the specified absolute path in the workspace or
 * {@code null} if no such node exists.
 *
 * @param absPath An absolute path.
 * @return the specified {@code Node} or {@code null}.
 * @throws RepositoryException If another error occurs.
 */
@CheckForNull
public Node getNodeOrNull(final String absPath) throws RepositoryException {
    return perform(new ReadOperation<Node>() {

        @Override
        public Node perform() throws RepositoryException {
            return NodeImpl.createNodeOrNull(sd.getNode(getOakPathOrThrow(absPath)), sessionContext);
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1225_3535afe2,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/SessionImpl.java,162,165,"@Override
public Node perform() throws RepositoryException {
    return NodeImpl.createNodeOrNull(sd.getNode(getOakPathOrThrow(absPath)), sessionContext);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1225_3535afe2,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/SessionImpl.java,177,195,"/**
 * Returns the property at the specified absolute path in the workspace or
 * {@code null} if no such node exists.
 *
 * @param absPath An absolute path.
 * @return the specified {@code Property} or {@code null}.
 * @throws RepositoryException if another error occurs.
 */
@CheckForNull
public Property getPropertyOrNull(final String absPath) throws RepositoryException {
    if (absPath.equals(""/"")) {
        return null;
    } else {
        final String oakPath = getOakPathOrThrow(absPath);
        return perform(new ReadOperation<Property>() {

            @Override
            public Property perform() throws RepositoryException {
                PropertyDelegate pd = sd.getProperty(oakPath);
                if (pd != null) {
                    return new PropertyImpl(pd, sessionContext);
                } else {
                    return null;
                }
            }
        });
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1227_117b0a3d,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/NodeImpl.java,798,807,"@Override
public boolean hasNode(String relPath) throws RepositoryException {
    final String oakPath = getOakPathOrThrow(relPath);
    return perform(new NodeOperation<Boolean>(dlg) {

        @Override
        public Boolean perform() throws RepositoryException {
            return node.getChild(oakPath) != null;
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1227_117b0a3d,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/NodeImpl.java,809,818,"@Override
public boolean hasProperty(String relPath) throws RepositoryException {
    final String oakPath = getOakPathOrThrow(relPath);
    return perform(new NodeOperation<Boolean>(dlg) {

        @Override
        public Boolean perform() throws RepositoryException {
            return node.getPropertyOrNull(oakPath) != null;
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1235_1beb2a50,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,179,201,"/**
 * Copies the full content from the source to the target repository.
 * <p>
 * The source repository <strong>must not be modified</strong> while
 * the copy operation is running to avoid an inconsistent copy.
 * <p>
 * This method leaves the search indexes of the target repository in
 * an
 * Note that both the source and the target repository must be closed
 * during the copy operation as this method requires exclusive access
 * to the repositories.
 *
 * @throws RepositoryException if the copy operation fails
 */
public void copy() throws RepositoryException {
    logger.info(""Copying repository content from {} to Oak"", source.getRepositoryConfig().getHomeDir());
    try {
        NodeBuilder builder = target.getRoot().builder();
        Map<Integer, String> idxToPrefix = copyNamespaces(builder);
        copyNodeTypes(builder);
        copyVersionStore(builder, idxToPrefix);
        copyWorkspaces(builder, idxToPrefix);
        // TODO: default hooks?
        CommitHook hook = new CompositeHook(new EditorHook(new RegistrationEditorProvider()), new EditorHook(new ReferenceEditorProvider()), new EditorHook(new GroupEditorProvider()));
        target.merge(builder, hook, null);
    } catch (Exception e) {
        throw new RepositoryException(""Failed to copy content"", e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1235_1beb2a50,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,221,264,"/**
 * Copies the registered namespaces to the target repository, and returns
 * the internal namespace index mapping used in bundle serialization.
 *
 * @param root root builder
 * @return index to prefix mapping
 * @throws RepositoryException
 */
private Map<Integer, String> copyNamespaces(NodeBuilder root) throws RepositoryException {
    Map<Integer, String> idxToPrefix = newHashMap();
    NodeBuilder system = root.child(JCR_SYSTEM);
    NodeBuilder namespaces = Namespaces.createStandardMappings(system);
    Properties registry = loadProperties(""/namespaces/ns_reg.properties"");
    Properties indexes = loadProperties(""/namespaces/ns_idx.properties"");
    for (String prefixHint : registry.stringPropertyNames()) {
        String uri = registry.getProperty(prefixHint);
        if ("".empty.key"".equals(prefixHint)) {
            prefixHint = """";
        }
        String prefix = Namespaces.addCustomMapping(namespaces, uri, prefixHint);
        String index = null;
        if (uri.isEmpty()) {
            index = indexes.getProperty("".empty.key"");
        }
        if (index == null) {
            index = indexes.getProperty(uri);
        }
        Integer idx;
        if (index != null) {
            idx = Integer.decode(index);
        } else {
            int i = 0;
            do {
                idx = (uri.hashCode() + i++) & 0x00ffffff;
            } while (idxToPrefix.containsKey(idx));
        }
        checkState(idxToPrefix.put(idx, prefix) == null);
    }
    Namespaces.buildIndexNode(namespaces);
    return idxToPrefix;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1235_1beb2a50,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,288,299,"private void copyNodeTypes(NodeBuilder root) throws RepositoryException {
    NodeTypeRegistry sourceRegistry = source.getNodeTypeRegistry();
    NodeBuilder system = root.child(JCR_SYSTEM);
    NodeBuilder types = system.child(JCR_NODE_TYPES);
    logger.info(""Copying registered node types"");
    for (Name name : sourceRegistry.getRegisteredNodeTypes()) {
        QNodeTypeDefinition def = sourceRegistry.getNodeTypeDef(name);
        NodeBuilder type = types.child(getOakName(name));
        copyNodeType(def, type);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1244_b4a93c81,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/xml/ImporterImpl.java,288,450,"@Override
public void startNode(NodeInfo nodeInfo, List<PropInfo> propInfos) throws RepositoryException {
    Tree parent = parents.peek();
    Tree tree = null;
    String id = nodeInfo.getUUID();
    String nodeName = nodeInfo.getName();
    String ntName = nodeInfo.getPrimaryTypeName();
    if (parent == null) {
        log.debug(""Skipping node: "" + nodeName);
        // parent node was skipped, skip this child node too
        // push null onto stack for skipped node
        parents.push(null);
        // notify the p-i-importer
        if (pnImporter != null) {
            pnImporter.startChildInfo(nodeInfo, propInfos);
        }
        return;
    }
    NodeDefinition parentDef = getDefinition(parent);
    if (parentDef.isProtected()) {
        // skip protected node
        parents.push(null);
        log.debug(""Skipping protected node: "" + nodeName);
        if (pnImporter != null) {
            // pnImporter was already started (current nodeInfo is a sibling)
            // notify it about this child node.
            pnImporter.startChildInfo(nodeInfo, propInfos);
        } else {
            // potentially is able to deal with it, notify it about the child node.
            for (ProtectedItemImporter pni : pItemImporters) {
                if (pni instanceof ProtectedNodeImporter && ((ProtectedNodeImporter) pni).start(parent)) {
                    log.debug(""Protected node -> delegated to ProtectedNodeImporter"");
                    pnImporter = (ProtectedNodeImporter) pni;
                    pnImporter.startChildInfo(nodeInfo, propInfos);
                    break;
                }
            /* else: p-i-Importer isn't able to deal with the protected tree.
                     try next. and if none can handle the passed parent the
                     tree below will be skipped */
            }
        }
        return;
    }
    if (parent.hasChild(nodeName)) {
        // a node with that name already exists...
        Tree existing = parent.getChild(nodeName);
        NodeDefinition def = getDefinition(existing);
        if (!def.allowsSameNameSiblings()) {
            // check for potential conflicts
            if (def.isProtected() && isNodeType(existing, ntName)) {
                /*
                     use the existing node as parent for the possible subsequent
                     import of a protected tree, that the protected node importer
                     may or may not be able to deal with.
                     -> upon the next 'startNode' the check for the parent being
                        protected will notify the protected node importer.
                     -> if the importer is able to deal with that node it needs
                        to care of the complete subtree until it is notified
                        during the 'endNode' call.
                     -> if the import can't deal with that node or if that node
                        is the a leaf in the tree to be imported 'end' will
                        not have an effect on the importer, that was never started.
                    */
                log.debug(""Skipping protected node: "" + existing);
                parents.push(existing);
                return;
            }
            if (def.isAutoCreated() && isNodeType(existing, ntName)) {
                // this node has already been auto-created, no need to create it
                tree = existing;
            } else {
                // edge case: colliding node does have same uuid
                // (see http://issues.apache.org/jira/browse/JCR-1128)
                String existingIdentifier = IdentifierManager.getIdentifier(existing);
                if (!(existingIdentifier.equals(id) && (uuidBehavior == ImportUUIDBehavior.IMPORT_UUID_COLLISION_REMOVE_EXISTING || uuidBehavior == ImportUUIDBehavior.IMPORT_UUID_COLLISION_REPLACE_EXISTING))) {
                    throw new ItemExistsException(""Node with the same UUID exists:"" + existing);
                }
            // fall through
            }
        }
    }
    if (tree == null) {
        // create node
        if (id == null) {
            // no potential uuid conflict, always add new node
            tree = createTree(parent, nodeInfo, id);
        } else {
            // 1. First check from base state that tree corresponding to
            // this id exist
            Tree conflicting = baseStateIdManager.getTree(id);
            if (conflicting == null) {
                // 1.a. Check if id is found in newly created nodes
                if (uuids.contains(id)) {
                    conflicting = currentStateIdManager.getTree(id);
                }
            } else {
                // 1.b Re obtain the conflicting tree from Id Manager
                // associated with current root. Such that any operation
                // on it gets reflected in later operations
                // In case a tree with same id was removed earlier then it
                // would return null
                conflicting = currentStateIdManager.getTree(id);
            }
            if (conflicting != null && conflicting.exists()) {
                // resolve uuid conflict
                tree = resolveUUIDConflict(parent, conflicting, id, nodeInfo);
                if (tree == null) {
                    // no new node has been created, so skip this node
                    // push null onto stack for skipped node
                    parents.push(null);
                    log.debug(""Skipping existing node "" + nodeInfo.getName());
                    return;
                }
            } else {
                // create new with given uuid
                tree = createTree(parent, nodeInfo, id);
            }
        }
    }
    // process properties
    for (PropInfo pi : propInfos) {
        // find applicable definition
        // TODO find better heuristics?
        PropertyDefinition def = pi.getPropertyDef(effectiveNodeTypeProvider.getEffectiveNodeType(tree));
        if (def.isProtected()) {
            // skip protected property
            log.debug(""Skipping protected property "" + pi.getName());
            // notify the ProtectedPropertyImporter.
            for (ProtectedItemImporter ppi : pItemImporters) {
                if (ppi instanceof ProtectedPropertyImporter && ((ProtectedPropertyImporter) ppi).handlePropInfo(tree, pi, def)) {
                    log.debug(""Protected property -> delegated to ProtectedPropertyImporter"");
                    break;
                }
            /* else: p-i-Importer isn't able to deal with this property.
                             try next pp-importer */
            }
        } else {
            // regular property -> create the property
            createProperty(tree, pi, def);
        }
    }
    parents.push(tree);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1250_0c3b3306,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeStore.java,178,183,"@Override
@Nonnull
public synchronized String checkpoint(long lifetime) {
    checkArgument(lifetime > 0);
    // TODO: Guard the checkpoint from garbage collection
    return head.getRecordId().toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1250_0c3b3306,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeStore.java,185,192,"@Override
@CheckForNull
public synchronized NodeState retrieve(@Nonnull String checkpoint) {
    // TODO: Verify validity of the checkpoint
    RecordId id = RecordId.fromString(checkNotNull(checkpoint));
    SegmentNodeState root = new SegmentNodeState(store.getWriter().getDummySegment(), id);
    return root.getChildNode(ROOT);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1254_25a70439,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/MongoNodeStore.java,1116,1156,"void backgroundRead() {
    String id = Utils.getIdFromPath(""/"");
    NodeDocument doc = store.find(Collection.NODES, id, asyncDelay);
    if (doc == null) {
        return;
    }
    Map<Integer, Revision> lastRevMap = doc.getLastRev();
    Revision.RevisionComparator revisionComparator = getRevisionComparator();
    boolean hasNewRevisions = false;
    // the (old) head occurred first
    Revision headSeen = Revision.newRevision(0);
    // then we saw this new revision (from another cluster node)
    Revision otherSeen = Revision.newRevision(0);
    for (Map.Entry<Integer, Revision> e : lastRevMap.entrySet()) {
        int machineId = e.getKey();
        if (machineId == clusterId) {
            continue;
        }
        Revision r = e.getValue();
        Revision last = lastKnownRevision.get(machineId);
        if (last == null || r.compareRevisionTime(last) > 0) {
            lastKnownRevision.put(machineId, r);
            hasNewRevisions = true;
            revisionComparator.add(r, otherSeen);
        }
    }
    if (hasNewRevisions) {
        store.invalidateCache();
        // TODO only invalidate affected items
        docChildrenCache.invalidateAll();
        // add a new revision, so that changes are visible
        Revision r = Revision.newRevision(clusterId);
        // the latest revisions of the current cluster node
        // happened before the latest revisions of other cluster nodes
        revisionComparator.add(r, headSeen);
        // the head revision is after other revisions
        setHeadRevision(Revision.newRevision(clusterId));
    }
    revisionComparator.purge(Revision.getCurrentTimestamp() - REMEMBER_REVISION_ORDER_MILLIS);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1269_b8fe2ded,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/nodetype/NodeTypeIndex.java,38,56,"@Override
public double getCost(Filter filter, NodeState root) {
    // TODO don't call getCost for such queries
    if (filter.getFullTextConstraint() != null) {
        // not an appropriate index for full-text search
        return Double.POSITIVE_INFINITY;
    }
    if (!hasNodeTypeRestriction(filter)) {
        // doesn't have a node type restriction
        return Double.POSITIVE_INFINITY;
    }
    NodeTypeIndexLookup lookup = new NodeTypeIndexLookup(root);
    if (lookup.isIndexed(filter.getPath())) {
        return lookup.getCost(filter);
    } else {
        return Double.POSITIVE_INFINITY;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1269_b8fe2ded,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/nodetype/NodeTypeIndex.java,58,66,"@Override
public Cursor query(Filter filter, NodeState root) {
    NodeTypeIndexLookup lookup = new NodeTypeIndexLookup(root);
    if (!hasNodeTypeRestriction(filter) || !lookup.isIndexed(filter.getPath())) {
        throw new IllegalStateException(""NodeType index is used even when no index is available for filter "" + filter);
    }
    return Cursors.newPathCursorDistinct(lookup.query(filter));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1269_b8fe2ded,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/nodetype/NodeTypeIndexLookup.java,48,66,"/**
 * Returns <code>true</code> if a node type index lookup exists at the given
 * <code>path</code> or further up the tree.
 *
 * @param path the path to check.
 * @return <code>true</code> if a node type index exists; <code>false</code>
 *         otherwise.
 */
public boolean isIndexed(String path) {
    PropertyIndexLookup lookup = new PropertyIndexLookup(root);
    if (lookup.isIndexed(JCR_PRIMARYTYPE, path, null) && lookup.isIndexed(JCR_MIXINTYPES, path, null)) {
        return true;
    }
    if (path.startsWith(""/"")) {
        path = path.substring(1);
    }
    int slash = path.indexOf('/');
    if (slash == -1) {
        return false;
    }
    NodeState child = root.getChildNode(path.substring(0, slash));
    return new NodeTypeIndexLookup(child).isIndexed(path.substring(slash));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1269_b8fe2ded,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/nodetype/NodeTypeIndexLookup.java,68,72,"public double getCost(Filter filter) {
    PropertyIndexLookup lookup = new PropertyIndexLookup(root);
    return lookup.getCost(null, JCR_PRIMARYTYPE, newName(filter.getPrimaryTypes())) + lookup.getCost(null, JCR_MIXINTYPES, newName(filter.getMixinTypes()));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1270_70564c7c,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,410,435,"/**
 * Get the Lucene query for the given filter.
 *
 * @param filter the filter, including full-text constraint
 * @param reader the Lucene reader
 * @param nonFullTextConstraints whether non-full-text constraints (such a
 *            path, node type, and so on) should be added to the Lucene
 *            query
 * @param analyzer the Lucene analyzer used for building the fulltext query
 * @return the Lucene query
 */
private static Query getQuery(Filter filter, IndexReader reader, boolean nonFullTextConstraints, Analyzer analyzer) {
    List<Query> qs = new ArrayList<Query>();
    FullTextExpression ft = filter.getFullTextConstraint();
    if (ft == null) {
    // there might be no full-text constraint
    // when using the LowCostLuceneIndexProvider
    // which is used for testing
    } else {
        qs.add(getFullTextQuery(ft, analyzer));
    }
    if (nonFullTextConstraints) {
        addNonFullTextConstraints(qs, filter, reader);
    }
    if (qs.size() == 0) {
        return new MatchAllDocsQuery();
    }
    if (qs.size() == 1) {
        return qs.get(0);
    }
    BooleanQuery bq = new BooleanQuery();
    for (Query q : qs) {
        bq.add(q, MUST);
    }
    return bq;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1270_70564c7c,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,585,647,"static Query getFullTextQuery(FullTextExpression ft, final Analyzer analyzer) {
    // a reference to the query, so it can be set in the visitor
    // (a ""non-local return"")
    final AtomicReference<Query> result = new AtomicReference<Query>();
    ft.accept(new FullTextVisitor() {

        @Override
        public boolean visit(FullTextOr or) {
            BooleanQuery q = new BooleanQuery();
            for (FullTextExpression e : or.list) {
                Query x = getFullTextQuery(e, analyzer);
                q.add(x, SHOULD);
            }
            result.set(q);
            return true;
        }

        @Override
        public boolean visit(FullTextAnd and) {
            BooleanQuery q = new BooleanQuery();
            for (FullTextExpression e : and.list) {
                Query x = getFullTextQuery(e, analyzer);
                // Lucene can't deal with ""must(must_not(x))""
                if (x instanceof BooleanQuery) {
                    BooleanQuery bq = (BooleanQuery) x;
                    for (BooleanClause c : bq.clauses()) {
                        q.add(c);
                    }
                } else {
                    q.add(x, MUST);
                }
            }
            result.set(q);
            return true;
        }

        @Override
        public boolean visit(FullTextTerm term) {
            String p = term.getPropertyName();
            if (p != null && p.indexOf('/') >= 0) {
                // do not add constraints on child nodes properties
                p = ""*"";
            }
            Query q = tokenToQuery(term.getText(), analyzer);
            if (q == null) {
                return false;
            }
            String boost = term.getBoost();
            if (boost != null) {
                q.setBoost(Float.parseFloat(boost));
            }
            if (term.isNot()) {
                BooleanQuery bq = new BooleanQuery();
                bq.add(q, MUST_NOT);
                result.set(bq);
            } else {
                result.set(q);
            }
            return true;
        }
    });
    return result.get();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1270_70564c7c,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,591,600,"@Override
public boolean visit(FullTextOr or) {
    BooleanQuery q = new BooleanQuery();
    for (FullTextExpression e : or.list) {
        Query x = getFullTextQuery(e, analyzer);
        q.add(x, SHOULD);
    }
    result.set(q);
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1270_70564c7c,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,602,619,"@Override
public boolean visit(FullTextAnd and) {
    BooleanQuery q = new BooleanQuery();
    for (FullTextExpression e : and.list) {
        Query x = getFullTextQuery(e, analyzer);
        // Lucene can't deal with ""must(must_not(x))""
        if (x instanceof BooleanQuery) {
            BooleanQuery bq = (BooleanQuery) x;
            for (BooleanClause c : bq.clauses()) {
                q.add(c);
            }
        } else {
            q.add(x, MUST);
        }
    }
    result.set(q);
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1270_70564c7c,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,621,644,"@Override
public boolean visit(FullTextTerm term) {
    String p = term.getPropertyName();
    if (p != null && p.indexOf('/') >= 0) {
        // do not add constraints on child nodes properties
        p = ""*"";
    }
    Query q = tokenToQuery(term.getText(), analyzer);
    if (q == null) {
        return false;
    }
    String boost = term.getBoost();
    if (boost != null) {
        q.setBoost(Float.parseFloat(boost));
    }
    if (term.isNot()) {
        BooleanQuery bq = new BooleanQuery();
        bq.add(q, MUST_NOT);
        result.set(bq);
    } else {
        result.set(q);
    }
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1270_70564c7c,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,649,683,"static Query tokenToQuery(String text, Analyzer analyzer) {
    if (analyzer == null) {
        return null;
    }
    List<String> tokens = new ArrayList<String>();
    tokens = tokenize(text, analyzer);
    if (tokens.isEmpty()) {
        // TODO what should be returned in the case there are no tokens?
        return new BooleanQuery();
    }
    if (tokens.size() == 1) {
        text = tokens.iterator().next();
        boolean hasFulltextToken = false;
        for (char c : fulltextTokens) {
            if (text.indexOf(c) != -1) {
                hasFulltextToken = true;
                break;
            }
        }
        if (hasFulltextToken) {
            return new WildcardQuery(newFulltextTerm(text));
        } else {
            return new TermQuery(newFulltextTerm(text));
        }
    } else {
        PhraseQuery pq = new PhraseQuery();
        for (String t : tokens) {
            pq.add(newFulltextTerm(t));
        }
        return pq;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1270_70564c7c,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,696,765,"/**
 * Tries to merge back tokens that are split on relevant fulltext query
 * wildcards ('*' or '?')
 *
 * @param text
 * @param analyzer
 * @return
 */
static List<String> tokenize(String text, Analyzer analyzer) {
    List<String> tokens = new ArrayList<String>();
    TokenStream stream = null;
    try {
        stream = analyzer.tokenStream(FieldNames.FULLTEXT, new StringReader(text));
        CharTermAttribute termAtt = stream.addAttribute(CharTermAttribute.class);
        OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);
        // TypeAttribute type = stream.addAttribute(TypeAttribute.class);
        stream.reset();
        int poz = 0;
        boolean hasFulltextToken = false;
        StringBuilder token = new StringBuilder();
        while (stream.incrementToken()) {
            String term = termAtt.toString();
            int start = offsetAtt.startOffset();
            int end = offsetAtt.endOffset();
            if (start > poz) {
                for (int i = poz; i < start; i++) {
                    for (char c : fulltextTokens) {
                        if (c == text.charAt(i)) {
                            token.append(c);
                            hasFulltextToken = true;
                        }
                    }
                }
            }
            poz = end;
            if (hasFulltextToken) {
                token.append(term);
            } else {
                if (token.length() > 0) {
                    tokens.add(token.toString());
                }
                token = new StringBuilder();
                token.append(term);
            }
        }
        // consume to the end of the string
        if (poz < text.length()) {
            for (int i = poz; i < text.length(); i++) {
                for (char c : fulltextTokens) {
                    if (c == text.charAt(i)) {
                        token.append(c);
                    }
                }
            }
        }
        if (token.length() > 0) {
            tokens.add(token.toString());
        }
        stream.end();
    } catch (IOException e) {
        LOG.error(""Building fulltext query failed"", e.getMessage());
        return null;
    } finally {
        try {
            if (stream != null) {
                stream.close();
            }
        } catch (IOException e) {
        // ignore
        }
    }
    return tokens;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1287_14849e22,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/ListRecord.java,51,64,"public RecordId getEntry(int index) {
    checkElementIndex(index, size);
    if (size == 1) {
        return getRecordId();
    } else {
        int bucketIndex = index / bucketSize;
        int bucketOffset = index % bucketSize;
        Segment segment = getSegment();
        RecordId bucketId = segment.readRecordId(getOffset(0, bucketIndex));
        ListRecord bucket = new ListRecord(segment, bucketId, bucketSize);
        return bucket.getEntry(bucketOffset);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1287_14849e22,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/ListRecord.java,66,88,"public List<RecordId> getEntries() {
    if (size == 0) {
        return emptyList();
    } else if (size == 1) {
        return singletonList(getRecordId());
    } else {
        List<RecordId> list = newArrayListWithCapacity(size);
        Segment segment = getSegment();
        int offset = getOffset();
        for (int i = 0; i < size; i += bucketSize) {
            RecordId id = segment.readRecordId(offset);
            if (bucketSize == 1) {
                list.add(id);
            } else {
                ListRecord bucket = new ListRecord(segment, id, Math.min(bucketSize, size - offset));
                list.addAll(bucket.getEntries());
            }
            offset += Segment.RECORD_ID_BYTES;
        }
        return list;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1287_14849e22,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentWriter.java,342,348,"private synchronized RecordId writeListBucket(List<RecordId> bucket) {
    RecordId bucketId = prepare(RecordType.BUCKET, 0, bucket);
    for (RecordId id : bucket) {
        writeRecordId(id);
    }
    return bucketId;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1287_14849e22,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentWriter.java,510,524,"/**
 * Writes a list record containing the given list of record identifiers.
 *
 * @param list list of record identifiers
 * @return list record identifier
 */
public RecordId writeList(List<RecordId> list) {
    checkNotNull(list);
    checkArgument(list.size() > 0);
    List<RecordId> thisLevel = list;
    while (thisLevel.size() > 1) {
        List<RecordId> nextLevel = Lists.newArrayList();
        for (List<RecordId> bucket : Lists.partition(thisLevel, ListRecord.LEVEL_SIZE)) {
            nextLevel.add(writeListBucket(bucket));
        }
        thisLevel = nextLevel;
    }
    return thisLevel.iterator().next();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1289_0c3e3d70,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/Range.java,54,57,"/**
 * Returns <code>true</code> if the given revision is within this range.
 *
 * @param r the revision to check.
 * @return <code>true</code> if within this range; <code>false</code>
 * otherwise.
 */
boolean includes(Revision r) {
    return high.compareRevisionTime(r) >= 0 && low.compareRevisionTime(r) <= 0;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1297_73cc2442,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,373,381,"protected static void annotateSourcePath(NodeBuilder builder, String path) {
    PropertyState base = builder.getBaseState().getProperty(MoveDetector.SOURCE_PATH);
    PropertyState head = builder.getNodeState().getProperty(MoveDetector.SOURCE_PATH);
    if (Objects.equal(base, head)) {
        if (!builder.hasProperty(MoveDetector.SOURCE_PATH)) {
            builder.setProperty(MoveDetector.SOURCE_PATH, path);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1308_69ba2a54,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/XPathToSQL2Converter.java,514,562,"private Expression parsePropertyOrFunction() throws ParseException {
    StringBuilder buff = new StringBuilder();
    boolean isPath = false;
    while (true) {
        if (currentTokenType == IDENTIFIER) {
            String name = readIdentifier();
            buff.append(name);
        } else if (readIf(""*"")) {
            // any node
            buff.append('*');
            isPath = true;
        } else if (readIf(""."")) {
            buff.append('.');
            if (readIf(""."")) {
                buff.append('.');
            }
            isPath = true;
        } else if (readIf(""@"")) {
            if (readIf(""*"")) {
                // xpath supports @*, even thought jackrabbit may not
                buff.append('*');
            } else {
                buff.append(readIdentifier());
            }
            return new Expression.Property(currentSelector, buff.toString());
        } else {
            break;
        }
        if (readIf(""/"")) {
            isPath = true;
            buff.append('/');
        } else {
            break;
        }
    }
    if (!isPath && readIf(""("")) {
        return parseFunction(buff.toString());
    } else if (buff.length() > 0) {
        // jcr:contains(jcr:content, 'x')
        if (buff.toString().equals(""."")) {
            buff = new StringBuilder(""*"");
        } else {
            buff.append(""/*"");
        }
        return new Expression.Property(currentSelector, buff.toString());
    }
    throw getSyntaxError();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1308_69ba2a54,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/XPathToSQL2Converter.java,648,653,"private Expression.Property readProperty() throws ParseException {
    if (readIf(""*"")) {
        return new Expression.Property(currentSelector, ""*"");
    }
    return new Expression.Property(currentSelector, readIdentifier());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1320_64045631,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelRootBuilder.java,146,150,"/**
 * Merge all changes tracked in this builder into the underlying store.
 */
NodeState merge(CommitHook hook, CommitInfo info) throws CommitFailedException {
    purge();
    branch.merge(hook, info);
    return reset();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1320_64045631,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/MongoRootBuilder.java,143,147,"/**
 * Merge all changes tracked in this builder into the underlying store.
 */
NodeState merge(CommitHook hook, CommitInfo info) throws CommitFailedException {
    purge();
    branch.merge(hook, info);
    return reset();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1348_bc7b7e8c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/accesscontrol/ACL.java,188,232,"private boolean internalAddEntry(@Nonnull ACE entry) throws RepositoryException {
    final Principal principal = entry.getPrincipal();
    List<ACE> subList = Lists.newArrayList(Iterables.filter(entries, new Predicate<ACE>() {

        @Override
        public boolean apply(@Nullable ACE ace) {
            return (ace != null) && ace.getPrincipal().equals(principal);
        }
    }));
    for (ACE existing : subList) {
        PrivilegeBits existingBits = PrivilegeBits.getInstance(existing.getPrivilegeBits());
        PrivilegeBits entryBits = entry.getPrivilegeBits();
        if (entry.getRestrictions().equals(existing.getRestrictions())) {
            if (entry.isAllow() == existing.isAllow()) {
                if (existingBits.includes(entryBits)) {
                    // no changes
                    return false;
                } else {
                    // merge existing and new ace
                    existingBits.add(entryBits);
                    int index = entries.indexOf(existing);
                    entries.remove(existing);
                    entries.add(index, createACE(existing, existingBits));
                    return true;
                }
            } else {
                // existing is complementary entry -> clean up redundant
                // privileges defined by the existing entry
                PrivilegeBits updated = PrivilegeBits.getInstance(existingBits).diff(entryBits);
                if (updated.isEmpty()) {
                    // remove the existing entry as the new entry covers all privileges
                    entries.remove(existing);
                } else if (!updated.includes(existingBits)) {
                    // replace the existing entry having it's privileges adjusted
                    int index = entries.indexOf(existing);
                    entries.remove(existing);
                    entries.add(index, createACE(existing, updated));
                }
            /* else: no collision that requires adjusting the existing entry.*/
            }
        }
    }
    // finally add the new entry at the end of the list
    entries.add(entry);
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1348_bc7b7e8c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/accesscontrol/ACL.java,191,194,"@Override
public boolean apply(@Nullable ACE ace) {
    return (ace != null) && ace.getPrincipal().equals(principal);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-135_438e31a7,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,438,445,"@Override
@Nonnull
public NodeIterator getNodes() throws RepositoryException {
    checkStatus();
    Iterator<NodeDelegate> children = dlg.getChildren();
    return new NodeIteratorAdapter(nodeIterator(children));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-135_438e31a7,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,502,509,"@Override
@Nonnull
public PropertyIterator getProperties() throws RepositoryException {
    checkStatus();
    Iterator<PropertyDelegate> properties = dlg.getProperties();
    return new PropertyIteratorAdapter(propertyIterator(properties));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1363_69b68890,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authentication/token/TokenLoginModule.java,152,185,"@Override
public boolean commit() throws LoginException {
    if (tokenCredentials != null) {
        updateSubject(tokenCredentials, getAuthInfo(tokenInfo), principals);
        return true;
    }
    if (tokenProvider != null && sharedState.containsKey(SHARED_KEY_CREDENTIALS)) {
        Credentials shared = getSharedCredentials();
        if (shared != null && tokenProvider.doCreateToken(shared)) {
            TokenInfo ti = tokenProvider.createToken(shared);
            if (ti != null) {
                TokenCredentials tc = new TokenCredentials(ti.getToken());
                Map<String, String> attributes = ti.getPrivateAttributes();
                for (String name : attributes.keySet()) {
                    tc.setAttribute(name, attributes.get(name));
                }
                attributes = ti.getPublicAttributes();
                for (String name : attributes.keySet()) {
                    tc.setAttribute(name, attributes.get(name));
                }
                updateSubject(tc, getAuthInfo(ti), null);
            } else {
                // failed to create token -> fail commit()
                log.debug(""TokenProvider failed to create a login token for user "" + userId);
                throw new LoginException(""Failed to create login token for user "" + userId);
            }
        }
    }
    // the login attempt on this module did not succeed: clear state
    clearState();
    return false;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1363_69b68890,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authentication/token/TokenLoginModule.java,239,249,"/**
 * Create the {@code AuthInfo} for the specified {@code tokenInfo} as well as
 * userId and principals, that have been set upon {@link #login}.
 *
 * @param tokenInfo The tokenInfo to retrieve attributes from.
 * @return The {@code AuthInfo} resulting from the successful login.
 */
@Nonnull
private AuthInfo getAuthInfo(TokenInfo tokenInfo) {
    Map<String, Object> attributes = new HashMap<String, Object>();
    if (tokenProvider != null && tokenInfo != null) {
        Map<String, String> publicAttributes = tokenInfo.getPublicAttributes();
        for (String attrName : publicAttributes.keySet()) {
            attributes.put(attrName, publicAttributes.get(attrName));
        }
    }
    return new AuthInfoImpl(userId, attributes, principals);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1363_69b68890,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authentication/token/TokenLoginModule.java,251,267,"private void updateSubject(@Nonnull TokenCredentials tc, @Nonnull AuthInfo authInfo, @Nullable Set<? extends Principal> principals) {
    if (!subject.isReadOnly()) {
        subject.getPublicCredentials().add(tc);
        if (principals != null) {
            subject.getPrincipals().addAll(principals);
        }
        // replace all existing auth-info
        Set<AuthInfo> ais = subject.getPublicCredentials(AuthInfo.class);
        if (!ais.isEmpty()) {
            subject.getPublicCredentials().removeAll(ais);
        }
        subject.getPublicCredentials().add(authInfo);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1363_69b68890,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authentication/user/LoginModuleImpl.java,136,155,"@Override
public boolean commit() {
    if (credentials == null || principals == null) {
        // login attempt in this login module was not successful
        clearState();
        return false;
    } else {
        if (!subject.isReadOnly()) {
            subject.getPrincipals().addAll(principals);
            subject.getPublicCredentials().add(credentials);
            Set<AuthInfo> ais = subject.getPublicCredentials(AuthInfo.class);
            if (ais.isEmpty()) {
                subject.getPublicCredentials().add(createAuthInfo());
            }
        } else {
            log.debug(""Could not add information to read only subject {}"", subject);
        }
        return true;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1363_69b68890,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authentication/user/LoginModuleImpl.java,215,230,"private AuthInfo createAuthInfo() {
    Map<String, Object> attributes = new HashMap<String, Object>();
    Credentials creds;
    if (credentials instanceof ImpersonationCredentials) {
        creds = ((ImpersonationCredentials) credentials).getBaseCredentials();
    } else {
        creds = credentials;
    }
    if (creds instanceof SimpleCredentials) {
        SimpleCredentials sc = (SimpleCredentials) creds;
        for (String attrName : sc.getAttributeNames()) {
            attributes.put(attrName, sc.getAttribute(attrName));
        }
    }
    return new AuthInfoImpl(userId, attributes, principals);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_05c89637,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,157,160,"private Entry<K, V> find(Object key) {
    int hash = getHash(key);
    return getSegment(hash).find(key, hash);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_05c89637,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,181,184,"/**
 * Get the value for the given key if the entry is cached. This method does
 * not modify the internal state.
 *
 * @param key the key (may not be null)
 * @return the value, or null if there is no resident entry
 */
public V peek(K key) {
    Entry<K, V> e = find(key);
    return e == null ? null : e.value;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_05c89637,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,459,465,"/**
 * Get the entry set for all resident entries.
 *
 * @return the entry set
 */
public synchronized Set<Map.Entry<K, V>> entrySet() {
    HashMap<K, V> map = new HashMap<K, V>();
    for (K k : keySet()) {
        map.put(k, find(k).value);
    }
    return map.entrySet();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_05c89637,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,467,476,"protected Collection<V> values() {
    ArrayList<V> list = new ArrayList<V>();
    for (K k : keySet()) {
        V v = find(k).value;
        if (v != null) {
            list.add(v);
        }
    }
    return list;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_05c89637,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,478,488,"boolean containsValue(Object value) {
    for (Segment<K, V> s : segments) {
        for (K k : s.keySet()) {
            V v = find(k).value;
            if (v != null && v.equals(value)) {
                return true;
            }
        }
    }
    return false;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_05c89637,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,860,877,"synchronized V get(K key, int hash, CacheLoader<K, V> loader) throws ExecutionException {
    V value = get(key, hash);
    if (value == null) {
        long start = System.nanoTime();
        try {
            value = loader.load(key);
            loadSuccessCount++;
        } catch (Exception e) {
            loadExceptionCount++;
            throw new ExecutionException(e);
        } finally {
            long time = System.nanoTime() - start;
            totalLoadTime += time;
        }
        put(key, hash, value, cache.sizeOf(key, value));
    }
    return value;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_05c89637,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,1369,1461,"@Override
public ConcurrentMap<K, V> asMap() {
    return new ConcurrentMap<K, V>() {

        @Override
        public int size() {
            long size = CacheLIRS.this.size();
            return (int) Math.min(size, Integer.MAX_VALUE);
        }

        @Override
        public boolean isEmpty() {
            return CacheLIRS.this.size() == 0;
        }

        @Override
        public boolean containsKey(Object key) {
            return CacheLIRS.this.containsKey(key);
        }

        @Override
        public boolean containsValue(Object value) {
            return CacheLIRS.this.containsValue(value);
        }

        @SuppressWarnings(""unchecked"")
        @Override
        public V get(Object key) {
            return CacheLIRS.this.getUnchecked((K) key);
        }

        @Override
        public V put(K key, V value) {
            return CacheLIRS.this.put(key, value, sizeOf(key, value));
        }

        @Override
        public V remove(Object key) {
            @SuppressWarnings(""unchecked"")
            V old = CacheLIRS.this.getUnchecked((K) key);
            CacheLIRS.this.invalidate(key);
            return old;
        }

        @Override
        public void putAll(Map<? extends K, ? extends V> m) {
            for (Map.Entry<? extends K, ? extends V> e : m.entrySet()) {
                put(e.getKey(), e.getValue());
            }
        }

        @Override
        public void clear() {
            CacheLIRS.this.clear();
        }

        @Override
        public Set<K> keySet() {
            return CacheLIRS.this.keySet();
        }

        @Override
        public Collection<V> values() {
            return CacheLIRS.this.values();
        }

        @Override
        public Set<java.util.Map.Entry<K, V>> entrySet() {
            return CacheLIRS.this.entrySet();
        }

        @Override
        public V putIfAbsent(K key, V value) {
            return CacheLIRS.this.putIfAbsent(key, value);
        }

        @Override
        public boolean remove(Object key, Object value) {
            return CacheLIRS.this.remove(key, value);
        }

        @Override
        public boolean replace(K key, V oldValue, V newValue) {
            return CacheLIRS.this.replace(key, oldValue, newValue);
        }

        @Override
        public V replace(K key, V value) {
            return CacheLIRS.this.replace(key, value);
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_05c89637,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,1394,1398,"@SuppressWarnings(""unchecked"")
@Override
public V get(Object key) {
    return CacheLIRS.this.getUnchecked((K) key);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_b481a14c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,713,745,"synchronized void clear() {
    // calculate the size of the map array
    // assume a fill factor of at most 80%
    long maxLen = (long) (maxMemory / averageMemory / 0.75);
    // the size needs to be a power of 2
    long l = 8;
    while (l < maxLen) {
        l += l;
    }
    // the array size is at most 2^31 elements
    int len = (int) Math.min(1L << 31, l);
    // the bit mask has all bits set
    mask = len - 1;
    // initialize the stack and queue heads
    stack = new Entry<K, V>();
    stack.stackPrev = stack.stackNext = stack;
    queue = new Entry<K, V>();
    queue.queuePrev = queue.queueNext = queue;
    queue2 = new Entry<K, V>();
    queue2.queuePrev = queue2.queueNext = queue2;
    // first set to null - avoiding out of memory
    entries = null;
    @SuppressWarnings(""unchecked"")
    Entry<K, V>[] e = new Entry[len];
    entries = e;
    mapSize = 0;
    usedMemory = 0;
    stackSize = queueSize = queue2Size = 0;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_b481a14c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,922,942,"synchronized void refresh(K key, int hash, CacheLoader<K, V> loader) throws ExecutionException {
    V value;
    V old = get(key, hash);
    long start = System.nanoTime();
    try {
        if (old == null) {
            value = loader.load(key);
        } else {
            ListenableFuture<V> future = loader.reload(key, old);
            value = future.get();
        }
        loadSuccessCount++;
    } catch (Exception e) {
        loadExceptionCount++;
        throw new ExecutionException(e);
    } finally {
        long time = System.nanoTime() - start;
        totalLoadTime += time;
    }
    put(key, hash, value, cache.sizeOf(key, value));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_b481a14c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,955,983,"/**
 * Add an entry to the cache. The entry may or may not exist in the
 * cache yet. This method will usually mark unknown entries as cold and
 * known entries as hot.
 *
 * @param key the key (may not be null)
 * @param hash the hash
 * @param value the value (may not be null)
 * @param memory the memory used for the given entry
 * @return the old value, or null if there was no resident entry
 */
synchronized V put(K key, int hash, V value, int memory) {
    if (value == null) {
        throw new NullPointerException(""The value may not be null"");
    }
    V old;
    Entry<K, V> e = find(key, hash);
    if (e == null) {
        old = null;
    } else {
        old = e.value;
        invalidate(key, hash);
    }
    e = new Entry<K, V>();
    e.key = key;
    e.value = value;
    e.memory = memory;
    int index = hash & mask;
    e.mapNext = entries[index];
    entries[index] = e;
    usedMemory += memory;
    if (usedMemory > maxMemory && mapSize > 0) {
        // an old entry needs to be removed
        evict(e);
    }
    mapSize++;
    // added entries are always added to the stack
    addToStack(e);
    return old;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_b481a14c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,992,1030,"/**
 * Remove an entry. Both resident and non-resident entries can be
 * removed.
 *
 * @param key the key (may not be null)
 * @param hash the hash
 */
synchronized void invalidate(Object key, int hash) {
    int index = hash & mask;
    Entry<K, V> e = entries[index];
    if (e == null) {
        return;
    }
    if (e.key.equals(key)) {
        entries[index] = e.mapNext;
    } else {
        Entry<K, V> last;
        do {
            last = e;
            e = e.mapNext;
            if (e == null) {
                return;
            }
        } while (!e.key.equals(key));
        last.mapNext = e.mapNext;
    }
    mapSize--;
    usedMemory -= e.memory;
    if (e.stackNext != null) {
        removeFromStack(e);
    }
    if (e.isHot()) {
        // when removing a hot entry, the newest cold entry gets hot,
        // so the number of hot entries does not change
        e = queue.queueNext;
        if (e != queue) {
            removeFromQueue(e);
            if (e.stackNext == null) {
                addToStackBottom(e);
            }
        }
    } else {
        removeFromQueue(e);
    }
    pruneStack();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1364_b481a14c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,1109,1116,"/**
 * Try to find an entry in the map.
 *
 * @param key the key
 * @param hash the hash
 * @return the entry (might be a non-resident)
 */
Entry<K, V> find(Object key, int hash) {
    int index = hash & mask;
    Entry<K, V> e = entries[index];
    while (e != null && !e.key.equals(key)) {
        e = e.mapNext;
    }
    return e;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1369_ce0b0955,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Expression.java,164,214,"@Override
public String toString() {
    String leftExpr;
    boolean leftExprIsName;
    if (left == null) {
        leftExprIsName = false;
        leftExpr = """";
    } else {
        leftExprIsName = left.isName();
        leftExpr = left.toString();
        if (left.getPrecedence() < precedence) {
            leftExpr = ""("" + leftExpr + "")"";
        }
    }
    boolean impossible = false;
    String rightExpr;
    if (right == null) {
        rightExpr = """";
    } else {
        if (left != null && left instanceof Property && ((Property) left).implicitAsterisk) {
            throw new IllegalArgumentException(""Missing @ in front of the property name: "" + left);
        }
        if (leftExprIsName && !""like"".equals(operator)) {
            // need to de-escape _x0020_ and so on
            if (!(right instanceof Literal)) {
                throw new IllegalArgumentException(""Can only compare a name against a string literal, not "" + right);
            }
            Literal l = (Literal) right;
            String raw = l.rawText;
            String decoded = ISO9075.decode(raw);
            String encoded = ISO9075.encode(decoded);
            rightExpr = SQL2Parser.escapeStringLiteral(decoded);
            if (!encoded.equalsIgnoreCase(raw)) {
                // nothing can potentially match
                impossible = true;
            }
        } else {
            rightExpr = right.toString();
        }
        if (right.getPrecedence() < precedence) {
            rightExpr = ""("" + right + "")"";
        }
    }
    if (impossible) {
        // a condition that can not possibly be true
        return ""upper("" + leftExpr + "") = 'never matches'"";
    }
    return (leftExpr + "" "" + operator + "" "" + rightExpr).trim();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1369_ce0b0955,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Expression.java,276,281,"@Override
public String toString() {
    StringBuilder buff = new StringBuilder(""contains"").append('(').append(left).append("", "").append(right).append(')');
    return buff.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1369_ce0b0955,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/XPathToSQL2Converter.java,514,562,"private Expression parsePropertyOrFunction() throws ParseException {
    StringBuilder buff = new StringBuilder();
    boolean isPath = false;
    while (true) {
        if (currentTokenType == IDENTIFIER) {
            String name = readPathSegment();
            buff.append(name);
        } else if (readIf(""*"")) {
            // any node
            buff.append('*');
            isPath = true;
        } else if (readIf(""."")) {
            buff.append('.');
            if (readIf(""."")) {
                buff.append('.');
            }
            isPath = true;
        } else if (readIf(""@"")) {
            if (readIf(""*"")) {
                // xpath supports @*, even thought jackrabbit may not
                buff.append('*');
            } else {
                buff.append(readPathSegment());
            }
            return new Expression.Property(currentSelector, buff.toString(), false);
        } else {
            break;
        }
        if (readIf(""/"")) {
            isPath = true;
            buff.append('/');
        } else {
            break;
        }
    }
    if (!isPath && readIf(""("")) {
        return parseFunction(buff.toString());
    } else if (buff.length() > 0) {
        // jcr:contains(jcr:content, 'x')
        if (buff.toString().equals(""."")) {
            buff = new StringBuilder(""*"");
        } else {
            buff.append(""/*"");
        }
        return new Expression.Property(currentSelector, buff.toString(), true);
    }
    throw getSyntaxError();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_279bb3ce,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,363,384,"/**
 * Returns the commit root path for the given <code>revision</code> or
 * <code>null</code> if this document does not have a commit root entry for
 * the given <code>revision</code>.
 *
 * @param revision a revision.
 * @return the commit root path or <code>null</code>.
 */
@CheckForNull
public String getCommitRootPath(Revision revision) {
    // check local map first
    Map<Revision, String> local = getLocalCommitRoot();
    String depth = local.get(revision);
    if (depth != null) {
        if (depth.equals(""0"")) {
            return ""/"";
        }
        String p = Utils.getPathFromId(getId());
        return PathUtils.getAncestorPath(p, PathUtils.getDepth(p) - Integer.parseInt(depth));
    }
    // check previous
    for (NodeDocument prev : getPreviousDocs(COMMIT_ROOT, revision)) {
        String path = prev.getCommitRootPath(revision);
        if (path != null) {
            return path;
        }
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentMK.java,185,228,"@Override
public String getNodes(String path, String revisionId, int depth, long offset, int maxChildNodes, String filter) throws MicroKernelException {
    if (depth != 0) {
        throw new MicroKernelException(""Only depth 0 is supported, depth is "" + depth);
    }
    revisionId = revisionId != null ? revisionId : nodeStore.getHeadRevision().toString();
    Revision rev = Revision.fromString(revisionId);
    DocumentNodeState n = nodeStore.getNode(path, rev);
    if (n == null) {
        return null;
    }
    JsopStream json = new JsopStream();
    boolean includeId = filter != null && filter.contains("":id"");
    includeId |= filter != null && filter.contains("":hash"");
    json.object();
    n.append(json, includeId);
    int max;
    if (maxChildNodes == -1) {
        max = Integer.MAX_VALUE;
        maxChildNodes = Integer.MAX_VALUE;
    } else {
        // use long to avoid overflows
        long m = ((long) maxChildNodes) + offset;
        max = (int) Math.min(m, Integer.MAX_VALUE);
    }
    Children c = nodeStore.getChildren(n, null, max);
    for (long i = offset; i < c.children.size(); i++) {
        if (maxChildNodes-- <= 0) {
            break;
        }
        String name = PathUtils.getName(c.children.get((int) i));
        json.key(name).object().endObject();
    }
    if (c.hasMore) {
        // TODO use a better way to notify there are more children
        json.key("":childNodeCount"").value(Long.MAX_VALUE);
    } else {
        json.key("":childNodeCount"").value(c.children.size());
    }
    json.endObject();
    return json.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeState.java,366,440,"// ------------------------------< internal >--------------------------------
private boolean dispatch(@Nonnull String jsonDiff, @Nonnull DocumentNodeState base, @Nonnull NodeStateDiff diff) {
    if (!AbstractNodeState.comparePropertiesAgainstBaseState(this, base, diff)) {
        return false;
    }
    if (jsonDiff.trim().isEmpty()) {
        return true;
    }
    JsopTokenizer t = new JsopTokenizer(jsonDiff);
    boolean continueComparison = true;
    while (continueComparison) {
        int r = t.read();
        if (r == JsopReader.END) {
            break;
        }
        switch(r) {
            case '+':
                {
                    String path = t.readString();
                    t.read(':');
                    t.read('{');
                    while (t.read() != '}') {
                    // skip properties
                    }
                    String name = PathUtils.getName(path);
                    continueComparison = diff.childNodeAdded(name, getChildNode(name));
                    break;
                }
            case '-':
                {
                    String path = t.readString();
                    String name = PathUtils.getName(path);
                    continueComparison = diff.childNodeDeleted(name, base.getChildNode(name));
                    break;
                }
            case '^':
                {
                    String path = t.readString();
                    t.read(':');
                    if (t.matches('{')) {
                        t.read('}');
                        String name = PathUtils.getName(path);
                        continueComparison = diff.childNodeChanged(name, base.getChildNode(name), getChildNode(name));
                    } else if (t.matches('[')) {
                        // ignore multi valued property
                        while (t.read() != ']') {
                        // skip values
                        }
                    } else {
                        // ignore single valued property
                        t.read();
                    }
                    break;
                }
            case '>':
                {
                    String from = t.readString();
                    t.read(':');
                    String to = t.readString();
                    String fromName = PathUtils.getName(from);
                    continueComparison = diff.childNodeDeleted(fromName, base.getChildNode(fromName));
                    if (!continueComparison) {
                        break;
                    }
                    String toName = PathUtils.getName(to);
                    continueComparison = diff.childNodeAdded(toName, getChildNode(toName));
                    break;
                }
            default:
                throw new IllegalArgumentException(""jsonDiff: illegal token '"" + t.getToken() + ""' at pos: "" + t.getLastPos() + ' ' + jsonDiff);
        }
    }
    return continueComparison;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,642,685,"DocumentNodeState.Children readChildren(DocumentNodeState parent, String name, int limit) {
    // TODO use offset, to avoid O(n^2) and running out of memory
    // to do that, use the *name* of the last entry of the previous batch of children
    // as the starting point
    String path = parent.getPath();
    Revision rev = parent.getLastRevision();
    Iterable<NodeDocument> docs;
    DocumentNodeState.Children c = new DocumentNodeState.Children();
    // add one to the requested limit for the raw limit
    // this gives us a chance to detect whether there are more
    // child nodes than requested.
    int rawLimit = (int) Math.min(Integer.MAX_VALUE, ((long) limit) + 1);
    for (; ; ) {
        c.children.clear();
        docs = readChildDocs(path, name, rawLimit);
        int numReturned = 0;
        for (NodeDocument doc : docs) {
            numReturned++;
            // filter out deleted children
            String p = Utils.getPathFromId(doc.getId());
            DocumentNodeState child = getNode(p, rev);
            if (child == null) {
                continue;
            }
            if (c.children.size() < limit) {
                // add to children until limit is reached
                c.children.add(p);
            } else {
                // enough collected and we know there are more
                c.hasMore = true;
                return c;
            }
        }
        // if we get here we have less than or equal the requested children
        if (numReturned < rawLimit) {
            // fewer documents returned than requested
            // -> no more documents
            c.hasMore = false;
            return c;
        }
        // double rawLimit for next round
        rawLimit = (int) Math.min(((long) rawLimit) * 2, Integer.MAX_VALUE);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,773,791,"/**
 * Returns up to {@code limit} child nodes, starting at the given
 * {@code name} (exclusive).
 *
 * @param parent the parent node.
 * @param name the name of the lower bound child node (exclusive) or
 *             {@code null}, if the method should start with the first known
 *             child node.
 * @param limit the maximum number of child nodes to return.
 * @return the child nodes.
 */
@Nonnull
Iterable<DocumentNodeState> getChildNodes(@Nonnull final DocumentNodeState parent, @Nullable final String name, final int limit) {
    // return straight away
    if (checkNotNull(parent).hasNoChildren()) {
        return Collections.emptyList();
    }
    final Revision readRevision = parent.getLastRevision();
    return Iterables.transform(getChildren(parent, name, limit).children, new Function<String, DocumentNodeState>() {

        @Override
        public DocumentNodeState apply(String input) {
            return getNode(input, readRevision);
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,786,789,"@Override
public DocumentNodeState apply(String input) {
    return getNode(input, readRevision);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,819,891,"/**
 * Apply the changes of a node to the cache.
 *
 * @param rev the commit revision
 * @param before the revision right before the commit.
 * @param path the path
 * @param isNew whether this is a new node
 * @param isDelete whether the node is deleted
 * @param pendingLastRev whether the node has a pending _lastRev to write
 * @param isBranchCommit whether this is from a branch commit
 * @param added the list of added child nodes
 * @param removed the list of removed child nodes
 * @param changed the list of changed child nodes.
 */
public void applyChanges(Revision rev, Revision before, String path, boolean isNew, boolean isDelete, boolean pendingLastRev, boolean isBranchCommit, List<String> added, List<String> removed, List<String> changed) {
    UnsavedModifications unsaved = unsavedLastRevisions;
    if (isBranchCommit) {
        Revision branchRev = rev.asBranchRevision();
        unsaved = branches.getBranch(branchRev).getModifications(branchRev);
    }
    if (isBranchCommit || pendingLastRev) {
        // write back _lastRev with background thread
        unsaved.put(path, rev);
    }
    if (isNew) {
        CacheValue key = childNodeCacheKey(path, rev, null);
        DocumentNodeState.Children c = new DocumentNodeState.Children();
        Set<String> set = Sets.newTreeSet(added);
        set.removeAll(removed);
        for (String p : added) {
            set.add(Utils.unshareString(p));
        }
        c.children.addAll(set);
        nodeChildrenCache.put(key, c);
    } else if (!isDelete) {
        // update diff cache for modified nodes
        PathRev key = diffCacheKey(path, before, rev);
        JsopWriter w = new JsopStream();
        for (String p : added) {
            w.tag('+').key(p).object().endObject().newline();
        }
        for (String p : removed) {
            w.tag('-').value(p).newline();
        }
        for (String p : changed) {
            w.tag('^').key(p).object().endObject().newline();
        }
        diffCache.put(key, new StringValue(w.toString()));
    }
    // update docChildrenCache
    if (!added.isEmpty()) {
        CacheValue docChildrenKey = new StringValue(path);
        NodeDocument.Children docChildren = docChildrenCache.getIfPresent(docChildrenKey);
        if (docChildren != null) {
            int currentSize = docChildren.childNames.size();
            NavigableSet<String> names = Sets.newTreeSet(docChildren.childNames);
            // a next name in DocumentStore smaller than the one added
            if (!docChildren.isComplete) {
                for (String childPath : added) {
                    String name = PathUtils.getName(childPath);
                    if (names.higher(name) != null) {
                        names.add(Utils.unshareString(name));
                    }
                }
            } else {
                // add all
                for (String childPath : added) {
                    names.add(Utils.unshareString(PathUtils.getName(childPath)));
                }
            }
            // any changes?
            if (names.size() != currentSize) {
                // create new cache entry with updated names
                boolean complete = docChildren.isComplete;
                docChildren = new NodeDocument.Children();
                docChildren.isComplete = complete;
                docChildren.childNames.addAll(names);
                docChildrenCache.put(docChildrenKey, docChildren);
            }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1130,1164,"String diff(@Nonnull final String fromRevisionId, @Nonnull final String toRevisionId, @Nonnull final String path) throws MicroKernelException {
    if (fromRevisionId.equals(toRevisionId)) {
        return """";
    }
    Revision fromRev = Revision.fromString(fromRevisionId);
    Revision toRev = Revision.fromString(toRevisionId);
    final DocumentNodeState from = getNode(path, fromRev);
    final DocumentNodeState to = getNode(path, toRev);
    if (from == null || to == null) {
        // TODO implement correct behavior if the node does't/didn't exist
        String msg = String.format(""Diff is only supported if the node exists in both cases. "" + ""Node [%s], fromRev [%s] -> %s, toRev [%s] -> %s"", path, fromRev, from != null, toRev, to != null);
        throw new MicroKernelException(msg);
    }
    PathRev key = diffCacheKey(path, fromRev, toRev);
    try {
        JsopWriter writer = new JsopStream();
        diffProperties(from, to, writer);
        return writer.toString() + diffCache.get(key, new Callable<StringValue>() {

            @Override
            public StringValue call() throws Exception {
                return new StringValue(diffImpl(from, to));
            }
        });
    } catch (ExecutionException e) {
        if (e.getCause() instanceof MicroKernelException) {
            throw (MicroKernelException) e.getCause();
        } else {
            throw new MicroKernelException(e.getCause());
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1414,1440,"private String diffImpl(DocumentNodeState from, DocumentNodeState to) throws MicroKernelException {
    JsopWriter w = new JsopStream();
    diffProperties(from, to, w);
    // TODO this does not work well for large child node lists
    // use a document store index instead
    int max = MANY_CHILDREN_THRESHOLD;
    DocumentNodeState.Children fromChildren, toChildren;
    fromChildren = getChildren(from, null, max);
    toChildren = getChildren(to, null, max);
    if (!fromChildren.hasMore && !toChildren.hasMore) {
        diffFewChildren(w, fromChildren, from.getLastRevision(), toChildren, to.getLastRevision());
    } else {
        if (FAST_DIFF) {
            diffManyChildren(w, from.getPath(), from.getLastRevision(), to.getLastRevision());
        } else {
            max = Integer.MAX_VALUE;
            fromChildren = getChildren(from, null, max);
            toChildren = getChildren(to, null, max);
            diffFewChildren(w, fromChildren, from.getLastRevision(), toChildren, to.getLastRevision());
        }
    }
    return w.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1442,1489,"private void diffManyChildren(JsopWriter w, String path, Revision fromRev, Revision toRev) {
    long minTimestamp = Math.min(fromRev.getTimestamp(), toRev.getTimestamp());
    long minValue = Commit.getModified(minTimestamp);
    String fromKey = Utils.getKeyLowerLimit(path);
    String toKey = Utils.getKeyUpperLimit(path);
    Set<String> paths = Sets.newHashSet();
    for (NodeDocument doc : store.query(Collection.NODES, fromKey, toKey, NodeDocument.MODIFIED, minValue, Integer.MAX_VALUE)) {
        paths.add(Utils.getPathFromId(doc.getId()));
    }
    // also consider nodes with not yet stored modifications (OAK-1107)
    Revision minRev = new Revision(minTimestamp, 0, getClusterId());
    addPathsForDiff(path, paths, getPendingModifications(), minRev);
    for (Revision r : new Revision[] { fromRev, toRev }) {
        if (r.isBranch()) {
            Branch b = getBranches().getBranch(fromRev);
            if (b != null) {
                addPathsForDiff(path, paths, b.getModifications(r), r);
            }
        }
    }
    for (String p : paths) {
        DocumentNodeState fromNode = getNode(p, fromRev);
        DocumentNodeState toNode = getNode(p, toRev);
        if (fromNode != null) {
            // exists in fromRev
            if (toNode != null) {
                // check if different
                if (!fromNode.getLastRevision().equals(toNode.getLastRevision())) {
                    w.tag('^').key(p).object().endObject().newline();
                }
            } else {
                // does not exist in toRev -> was removed
                w.tag('-').value(p).newline();
            }
        } else {
            // does not exist in fromRev
            if (toNode != null) {
                // exists in toRev
                w.tag('+').key(p).object().endObject().newline();
            } else {
            // does not exist in either revisions
            // -> do nothing
            }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1429_c2f5ca6c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1506,1531,"private void diffFewChildren(JsopWriter w, DocumentNodeState.Children fromChildren, Revision fromRev, DocumentNodeState.Children toChildren, Revision toRev) {
    Set<String> childrenSet = Sets.newHashSet(toChildren.children);
    for (String n : fromChildren.children) {
        if (!childrenSet.contains(n)) {
            w.tag('-').value(n).newline();
        } else {
            DocumentNodeState n1 = getNode(n, fromRev);
            DocumentNodeState n2 = getNode(n, toRev);
            // this is not fully correct:
            // a change is detected if the node changed recently,
            // even if the revisions are well in the past
            // if this is a problem it would need to be changed
            checkNotNull(n1, ""Node at [%s] not found for fromRev [%s]"", n, fromRev);
            checkNotNull(n2, ""Node at [%s] not found for toRev [%s]"", n, toRev);
            if (!n1.getId().equals(n2.getId())) {
                w.tag('^').key(n).object().endObject().newline();
            }
        }
    }
    childrenSet = Sets.newHashSet(fromChildren.children);
    for (String n : toChildren.children) {
        if (!childrenSet.contains(n)) {
            w.tag('+').key(n).object().endObject().newline();
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1432_808ac9c0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Expression.java,39,46,"/**
 * The ""and"" combination of two conditions.
 *
 * @param old the first expression (may be null)
 * @param add the second expression (may be null)
 * @return the combined expression (may be null)
 */
public static Expression and(Expression old, Expression add) {
    if (old == null) {
        return add;
    } else if (add == null) {
        return old;
    }
    return new Expression.Condition(old, ""and"", add, Expression.PRECEDENCE_AND);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1432_808ac9c0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Statement.java,54,126,"public Statement optimize() {
    if (explain || measure || orderList.size() > 0) {
        return this;
    }
    if (where == null) {
        return this;
    }
    if (where instanceof OrCondition) {
        OrCondition or = (OrCondition) where;
        if (or.getCommonLeftPart() != null) {
        // @x = 1 or @x = 2
        // is automatically converted to
        // @x in (1, 2)
        // within the query engine
        } else if (or.left instanceof Contains && or.right instanceof Contains) {
        // do not optimize ""contains""
        } else {
            // conditions of type
            // @x = 1 or @y = 2
            // or similar are converted to
            // (@x = 1) union (@y = 2)
            Statement s1 = new Statement();
            s1.columnSelector = columnSelector;
            s1.selectors = selectors;
            s1.columnList = columnList;
            s1.where = or.left;
            Statement s2 = new Statement();
            s2.columnSelector = columnSelector;
            s2.selectors = selectors;
            s2.columnList = columnList;
            s2.where = or.right;
            s2.xpathQuery = xpathQuery;
            return new UnionStatement(s1.optimize(), s2.optimize());
        }
    } else if (where instanceof AndCondition) {
        // conditions of type
        // @a = 1 and (@x = 1 or @y = 2)
        // are automatically converted to
        // (@a = 1 and @x = 1) union (@a = 1 and @y = 2)
        AndCondition and = (AndCondition) where;
        if (and.left instanceof OrCondition && !(and.right instanceof OrCondition)) {
            // swap left and right
            and = new AndCondition(and.right, and.left);
        }
        if (and.right instanceof OrCondition) {
            OrCondition or = (OrCondition) and.right;
            if (or.getCommonLeftPart() != null) {
            // @x = 1 or @x = 2
            // is automatically converted to
            // @x in (1, 2)
            // within the query engine
            } else if (or.left instanceof Contains && or.right instanceof Contains) {
            // do not optimize ""contains""
            } else {
                // same as above, but with the added ""and""
                // TODO avoid code duplication if possible
                Statement s1 = new Statement();
                s1.columnSelector = columnSelector;
                s1.selectors = selectors;
                s1.columnList = columnList;
                s1.where = new AndCondition(and.left, or.left);
                Statement s2 = new Statement();
                s2.columnSelector = columnSelector;
                s2.selectors = selectors;
                s2.columnList = columnList;
                s2.where = new AndCondition(and.left, or.right);
                s2.xpathQuery = xpathQuery;
                return new UnionStatement(s1.optimize(), s2.optimize());
            }
        }
    }
    return this;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1460_f1ba7a42,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/commit/ChildOrderConflictHandler.java,41,52,"@Override
public Resolution addExistingProperty(NodeBuilder parent, PropertyState ours, PropertyState theirs) {
    if (isChildOrderProperty(ours)) {
        // that was previously unordered.
        return Resolution.THEIRS;
    } else {
        return handler.addExistingProperty(parent, ours, theirs);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1460_f1ba7a42,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/commit/ChildOrderConflictHandler.java,77,96,"private static void merge(NodeBuilder parent, PropertyState ours, PropertyState theirs) {
    Set<String> theirOrder = Sets.newHashSet(theirs.getValue(Type.STRINGS));
    PropertyBuilder<String> merged = PropertyBuilder.array(Type.STRING).assignFrom(theirs);
    // Append child node names from ours that are not in theirs
    for (String ourChild : ours.getValue(Type.STRINGS)) {
        if (!theirOrder.contains(ourChild)) {
            merged.addValue(ourChild);
        }
    }
    // Remove child node names of nodes that have been removed
    for (String child : merged.getValues()) {
        if (!parent.hasChildNode(child)) {
            merged.removeValue(child);
        }
    }
    parent.setProperty(merged.getPropertyState());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1467_dde7de85,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Commit.java,402,416,"private void rollback(List<UpdateOp> newDocuments, List<UpdateOp> changed, UpdateOp commitRoot) {
    DocumentStore store = nodeStore.getDocumentStore();
    for (UpdateOp op : changed) {
        UpdateOp reverse = op.getReverseOperation();
        store.createOrUpdate(NODES, reverse);
    }
    for (UpdateOp op : newDocuments) {
        store.remove(NODES, op.id);
    }
    UpdateOp removeCollision = new UpdateOp(commitRoot.getId(), false);
    NodeDocument.removeCollision(removeCollision, revision);
    store.createOrUpdate(NODES, removeCollision);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1516_7c62bd81,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,688,727,"static Query tokenToQuery(String text, String fieldName, Analyzer analyzer, IndexReader reader) {
    if (analyzer == null) {
        return null;
    }
    List<String> tokens = tokenize(text, analyzer);
    if (tokens.isEmpty()) {
        // TODO what should be returned in the case there are no tokens?
        return new BooleanQuery();
    }
    if (tokens.size() == 1) {
        String token = tokens.iterator().next();
        if (hasFulltextToken(token)) {
            return new WildcardQuery(newFulltextTerm(token, fieldName));
        } else {
            return new TermQuery(newFulltextTerm(token, fieldName));
        }
    } else {
        if (hasFulltextToken(tokens)) {
            MultiPhraseQuery mpq = new MultiPhraseQuery();
            for (String token : tokens) {
                if (hasFulltextToken(token)) {
                    Term[] terms = extractMatchingTokens(reader, token);
                    if (terms != null && terms.length > 0) {
                        mpq.add(terms);
                    }
                } else {
                    mpq.add(newFulltextTerm(token, fieldName));
                }
            }
            return mpq;
        } else {
            PhraseQuery pq = new PhraseQuery();
            for (String t : tokens) {
                pq.add(newFulltextTerm(t, fieldName));
            }
            return pq;
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1516_7c62bd81,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,729,750,"private static Term[] extractMatchingTokens(IndexReader reader, String token) {
    if (reader == null) {
        // getPlan call
        return null;
    }
    try {
        List<Term> terms = new ArrayList<Term>();
        Terms t = MultiFields.getTerms(reader, FieldNames.FULLTEXT);
        Automaton a = WildcardQuery.toAutomaton(newFulltextTerm(token));
        CompiledAutomaton ca = new CompiledAutomaton(a);
        TermsEnum te = ca.getTermsEnum(t);
        BytesRef text;
        while ((text = te.next()) != null) {
            terms.add(newFulltextTerm(text.utf8ToString()));
        }
        return terms.toArray(new Term[terms.size()]);
    } catch (IOException e) {
        LOG.error(""Building fulltext query failed"", e.getMessage());
        return null;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1614_86edbffb,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/OakAnalyzer.java,43,54,"@Override
protected TokenStreamComponents createComponents(final String fieldName, final Reader reader) {
    WhitespaceTokenizer src = new WhitespaceTokenizer(matchVersion, reader);
    TokenStream tok = new LowerCaseFilter(matchVersion, src);
    tok = new WordDelimiterFilter(tok, WordDelimiterFilter.GENERATE_WORD_PARTS | WordDelimiterFilter.STEM_ENGLISH_POSSESSIVE | WordDelimiterFilter.GENERATE_NUMBER_PARTS, null);
    return new TokenStreamComponents(src, tok);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1624_6d8146f8,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/name/Namespaces.java,240,254,"public static boolean isValidLocalName(String local) {
    if (local.isEmpty() || ""."".equals(local) || "".."".equals(local)) {
        return false;
    }
    for (int i = 0; i < local.length(); i++) {
        char ch = local.charAt(i);
        if (""/:[]|*"".indexOf(ch) != -1) {
            // TODO: XMLChar check
            return false;
        }
    }
    // TODO: Other name rules?
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1648_fdc54465,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Checkpoints.java,75,86,"public Revision create(long lifetimeInMillis, Map<String, String> info) {
    Revision r = nodeStore.getHeadRevision();
    createCounter.getAndIncrement();
    performCleanupIfRequired();
    UpdateOp op = new UpdateOp(ID, false);
    long endTime = BigInteger.valueOf(nodeStore.getClock().getTime()).add(BigInteger.valueOf(lifetimeInMillis)).min(BigInteger.valueOf(Long.MAX_VALUE)).longValue();
    op.setMapEntry(PROP_CHECKPOINT, r, new Info(endTime, info).toString());
    store.createOrUpdate(Collection.SETTINGS, op);
    return r;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1655_01a8b283,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/blob/datastore/DataStoreBlobStore.java,260,270,"@Override
public Iterator<String> getAllChunkIds(long maxLastModifiedTime) throws Exception {
    // TODO Ignores the maxLastModifiedTime currently.
    return Iterators.transform(delegate.getAllIdentifiers(), new Function<DataIdentifier, String>() {

        @Nullable
        @Override
        public String apply(@Nullable DataIdentifier input) {
            return input.toString();
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1655_01a8b283,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/blob/datastore/DataStoreBlobStore.java,264,268,"@Nullable
@Override
public String apply(@Nullable DataIdentifier input) {
    return input.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1655_c91bfa54,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/blob/datastore/DataStoreBlobStore.java,263,284,"@Override
public Iterator<String> getAllChunkIds(final long maxLastModifiedTime) throws Exception {
    return transform(filter(delegate.getAllIdentifiers(), new Predicate<DataIdentifier>() {

        @Override
        public boolean apply(DataIdentifier input) {
            try {
                DataRecord dr = delegate.getRecord(input);
                if (dr != null && dr.getLastModified() < maxLastModifiedTime) {
                    return true;
                }
            } catch (DataStoreException e) {
                log.warn(""Error occurred while fetching DataRecord for identifier {}"", input, e);
            }
            return false;
        }
    }), new Function<DataIdentifier, String>() {

        @Override
        public String apply(DataIdentifier input) {
            return input.toString();
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1655_c91bfa54,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/blob/datastore/DataStoreBlobStore.java,266,277,"@Override
public boolean apply(DataIdentifier input) {
    try {
        DataRecord dr = delegate.getRecord(input);
        if (dr != null && dr.getLastModified() < maxLastModifiedTime) {
            return true;
        }
    } catch (DataStoreException e) {
        log.warn(""Error occurred while fetching DataRecord for identifier {}"", input, e);
    }
    return false;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1662_3efb5cbf,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1209,1216,"@Nonnull
@Override
public NodeState merge(@Nonnull NodeBuilder builder, @Nonnull CommitHook commitHook, @Nullable CommitInfo info) throws CommitFailedException {
    return asDocumentRootBuilder(builder).merge(commitHook, info);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1662_3efb5cbf,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,583,629,"/**
 * Get the revision of the latest change made to this node.
 *
 * @param context the revision context
 * @param changeRev the revision of the current change
 * @param handler the conflict handler, which is called for concurrent changes
 *                preceding <code>changeRev</code>.
 * @return the revision, or null if deleted
 */
@CheckForNull
public Revision getNewestRevision(RevisionContext context, Revision changeRev, CollisionHandler handler) {
    // no need to look at all commits. the primary document
    // always contains at least one commit, including all
    // branch commits which are not yet merged
    SortedMap<Revision, String> revisions = getLocalRevisions();
    SortedMap<Revision, String> commitRoots = getLocalCommitRoot();
    Revision newestRev = null;
    for (Revision r : Iterables.mergeSorted(Arrays.asList(revisions.keySet(), commitRoots.keySet()), revisions.comparator())) {
        if (!r.equals(changeRev)) {
            if (isValidRevision(context, r, null, changeRev, new HashMap<Revision, String>())) {
                newestRev = r;
                // revisions are sorted newest first
                break;
            } else {
                handler.concurrentModification(r);
            }
        }
    }
    if (newestRev == null) {
        return null;
    }
    // the local deleted map contains the most recent revisions
    SortedMap<Revision, String> deleted = getLocalDeleted();
    String value = deleted.get(newestRev);
    if (value == null && deleted.headMap(newestRev).isEmpty()) {
        // no need to check previous docs
        return newestRev;
    }
    if (value == null) {
        // get from complete map
        value = getDeleted().get(newestRev);
    }
    if (""true"".equals(value)) {
        // deleted in the newest revision
        return null;
    }
    return newestRev;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1668_63070cf9,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,321,337,"@Override
public String getPlan(Filter filter, NodeState root) {
    FullTextExpression ft = filter.getFullTextConstraint();
    Set<String> relPaths = getRelativePaths(ft);
    if (relPaths.size() > 1) {
        return new MultiLuceneIndex(filter, root, relPaths).getPlan();
    }
    String parent = relPaths.size() == 0 ? """" : relPaths.iterator().next();
    // we only restrict non-full-text conditions if there is
    // no relative property in the full-text constraint
    boolean nonFullTextConstraints = parent.isEmpty();
    String plan = getQuery(filter, null, nonFullTextConstraints, analyzer) + "" ft:("" + ft + "")"";
    if (!parent.isEmpty()) {
        plan += "" parent:"" + parent;
    }
    return plan;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1668_63070cf9,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,339,420,"@Override
public Cursor query(Filter filter, NodeState root) {
    if (!isLive(root)) {
        throw new IllegalStateException(""Lucene index is not live"");
    }
    FullTextExpression ft = filter.getFullTextConstraint();
    Set<String> relPaths = getRelativePaths(ft);
    if (relPaths.size() > 1) {
        return new MultiLuceneIndex(filter, root, relPaths).query();
    }
    String parent = relPaths.size() == 0 ? """" : relPaths.iterator().next();
    // we only restrict non-full-text conditions if there is
    // no relative property in the full-text constraint
    boolean nonFullTextConstraints = parent.isEmpty();
    Directory directory = newDirectory(root);
    QueryEngineSettings settings = filter.getQueryEngineSettings();
    if (directory == null) {
        return newPathCursor(Collections.<String>emptySet(), settings);
    }
    long s = System.currentTimeMillis();
    try {
        try {
            IndexReader reader = DirectoryReader.open(directory);
            try {
                IndexSearcher searcher = new IndexSearcher(reader);
                List<LuceneResultRow> rows = new ArrayList<LuceneResultRow>();
                Query query = getQuery(filter, reader, nonFullTextConstraints, analyzer);
                // TODO OAK-828
                HashSet<String> seenPaths = new HashSet<String>();
                int parentDepth = getDepth(parent);
                if (query != null) {
                    // OAK-925
                    // TODO how to best avoid loading all entries in memory?
                    // (memory problem and performance problem)
                    TopDocs docs = searcher.search(query, Integer.MAX_VALUE);
                    for (ScoreDoc doc : docs.scoreDocs) {
                        String path = reader.document(doc.doc, PATH_SELECTOR).get(PATH);
                        if (path != null) {
                            if ("""".equals(path)) {
                                path = ""/"";
                            }
                            if (!parent.isEmpty()) {
                                // TODO OAK-828 this breaks node aggregation
                                // get the base path
                                // ensure the path ends with the given
                                // relative path
                                // if (!path.endsWith(""/"" + parent)) {
                                // continue;
                                // }
                                path = getAncestorPath(path, parentDepth);
                                // avoid duplicate entries
                                if (seenPaths.contains(path)) {
                                    continue;
                                }
                                seenPaths.add(path);
                            }
                            LuceneResultRow r = new LuceneResultRow();
                            r.path = path;
                            r.score = doc.score;
                            rows.add(r);
                        }
                    }
                }
                LOG.debug(""query via {} took {} ms."", this, System.currentTimeMillis() - s);
                return new LucenePathCursor(rows, settings);
            } finally {
                reader.close();
            }
        } finally {
            directory.close();
        }
    } catch (IOException e) {
        LOG.warn(""query via {} failed."", this, e);
        return newPathCursor(Collections.<String>emptySet(), settings);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1668_63070cf9,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,433,479,"/**
 * Get the Lucene query for the given filter.
 *
 * @param filter the filter, including full-text constraint
 * @param reader the Lucene reader
 * @param nonFullTextConstraints whether non-full-text constraints (such a
 *            path, node type, and so on) should be added to the Lucene
 *            query
 * @param analyzer the Lucene analyzer used for building the fulltext query
 * @return the Lucene query
 */
private static Query getQuery(Filter filter, IndexReader reader, boolean nonFullTextConstraints, Analyzer analyzer) {
    List<Query> qs = new ArrayList<Query>();
    FullTextExpression ft = filter.getFullTextConstraint();
    if (ft == null) {
    // there might be no full-text constraint
    // when using the LowCostLuceneIndexProvider
    // which is used for testing
    } else {
        qs.add(getFullTextQuery(ft, analyzer, reader));
    }
    PropertyRestriction pr = filter.getPropertyRestriction(NATIVE_QUERY_FUNCTION);
    if (pr != null) {
        String query = String.valueOf(pr.first.getValue(pr.first.getType()));
        QueryParser queryParser = new QueryParser(VERSION, """", analyzer);
        if (query.startsWith(""mlt?"")) {
            String mltQueryString = query.replace(""mlt?"", """");
            if (reader != null) {
                Query moreLikeThis = MoreLikeThisHelper.getMoreLikeThis(reader, analyzer, mltQueryString);
                if (moreLikeThis != null) {
                    qs.add(moreLikeThis);
                }
            }
        } else {
            try {
                qs.add(queryParser.parse(query));
            } catch (ParseException e) {
                throw new RuntimeException(e);
            }
        }
    } else if (nonFullTextConstraints) {
        addNonFullTextConstraints(qs, filter, reader, analyzer);
    }
    if (qs.size() == 0) {
        return new MatchAllDocsQuery();
    }
    if (qs.size() == 1) {
        return qs.get(0);
    }
    BooleanQuery bq = new BooleanQuery();
    for (Query q : qs) {
        bq.add(q, MUST);
    }
    return bq;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1668_63070cf9,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,481,608,"private static void addNonFullTextConstraints(List<Query> qs, Filter filter, IndexReader reader, Analyzer analyzer) {
    if (!filter.matchesAllTypes()) {
        addNodeTypeConstraints(qs, filter);
    }
    String path = filter.getPath();
    switch(filter.getPathRestriction()) {
        case ALL_CHILDREN:
            if (""/"".equals(path)) {
                break;
            }
            if (!path.endsWith(""/"")) {
                path += ""/"";
            }
            qs.add(new PrefixQuery(newPathTerm(path)));
            break;
        case DIRECT_CHILDREN:
            if (!path.endsWith(""/"")) {
                path += ""/"";
            }
            qs.add(new PrefixQuery(newPathTerm(path)));
            break;
        case EXACT:
            qs.add(new TermQuery(newPathTerm(path)));
            break;
        case PARENT:
            if (denotesRoot(path)) {
                // there's no parent of the root node
                // we add a path that can not possibly occur because there
                // is no way to say ""match no documents"" in Lucene
                qs.add(new TermQuery(new Term(FieldNames.PATH, ""///"")));
            } else {
                qs.add(new TermQuery(newPathTerm(getParentPath(path))));
            }
            break;
        case NO_RESTRICTION:
            break;
    }
    for (PropertyRestriction pr : filter.getPropertyRestrictions()) {
        if (pr.first == null && pr.last == null) {
            // is not null' queries (OAK-1208)
            continue;
        }
        String name = pr.propertyName;
        if (name.contains(""/"")) {
            // lucene cannot handle child-level property restrictions
            continue;
        }
        if (""rep:excerpt"".equals(name)) {
            continue;
        }
        if (JCR_PRIMARYTYPE.equals(name)) {
            continue;
        }
        if (skipTokenization(name)) {
            qs.add(new TermQuery(new Term(name, pr.first.getValue(STRING))));
            continue;
        }
        String first = null;
        String last = null;
        boolean isLike = pr.isLike;
        // TODO what to do with escaped tokens?
        if (pr.first != null) {
            first = pr.first.getValue(STRING);
            first = first.replace(""\\"", """");
        }
        if (pr.last != null) {
            last = pr.last.getValue(STRING);
            last = last.replace(""\\"", """");
        }
        if (isLike) {
            first = first.replace('%', WildcardQuery.WILDCARD_STRING);
            first = first.replace('_', WildcardQuery.WILDCARD_CHAR);
            int indexOfWS = first.indexOf(WildcardQuery.WILDCARD_STRING);
            int indexOfWC = first.indexOf(WildcardQuery.WILDCARD_CHAR);
            int len = first.length();
            if (indexOfWS == len || indexOfWC == len) {
                // remove trailing ""*"" for prefixquery
                first = first.substring(0, first.length() - 1);
                if (JCR_PATH.equals(name)) {
                    qs.add(new PrefixQuery(newPathTerm(first)));
                } else {
                    qs.add(new PrefixQuery(new Term(name, first)));
                }
            } else {
                if (JCR_PATH.equals(name)) {
                    qs.add(new WildcardQuery(newPathTerm(first)));
                } else {
                    qs.add(new WildcardQuery(new Term(name, first)));
                }
            }
            continue;
        }
        if (first != null && first.equals(last) && pr.firstIncluding && pr.lastIncluding) {
            if (JCR_PATH.equals(name)) {
                qs.add(new TermQuery(newPathTerm(first)));
            } else {
                if (""*"".equals(name)) {
                    addReferenceConstraint(first, qs, reader);
                } else {
                    for (String t : tokenize(first, analyzer)) {
                        qs.add(new TermQuery(new Term(name, t)));
                    }
                }
            }
            continue;
        }
        first = tokenizeAndPoll(first, analyzer);
        last = tokenizeAndPoll(last, analyzer);
        qs.add(TermRangeQuery.newStringRange(name, first, last, pr.firstIncluding, pr.lastIncluding));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1674_073b814c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/tree/AbstractTree.java,205,214,"@Override
public Status getStatus() {
    if (nodeBuilder.isNew()) {
        return NEW;
    } else if (nodeBuilder.isModified()) {
        return MODIFIED;
    } else {
        return UNCHANGED;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1697_1552be04,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authentication/token/TokenProviderImpl.java,206,260,"/**
 * Create a separate token node underneath a dedicated token store within
 * the user home node. That token node contains the hashed token, the
 * expiration time and additional mandatory attributes that will be verified
 * during login.
 *
 * @param userId     The identifier of the user for which a new token should
 *                   be created.
 * @param attributes The attributes associated with the new token.
 * @return A new {@code TokenInfo} or {@code null} if the token could not
 *         be created.
 */
@Override
public TokenInfo createToken(String userId, Map<String, ?> attributes) {
    String error = ""Failed to create login token. "";
    NodeUtil tokenParent = getTokenParent(userId);
    if (tokenParent != null) {
        try {
            long creationTime = new Date().getTime();
            Calendar creation = GregorianCalendar.getInstance();
            creation.setTimeInMillis(creationTime);
            String tokenName = Text.replace(ISO8601.format(creation), "":"", ""."");
            NodeUtil tokenNode = tokenParent.addChild(tokenName, TOKEN_NT_NAME);
            tokenNode.setString(JcrConstants.JCR_UUID, IdentifierManager.generateUUID());
            String key = generateKey(options.getConfigValue(PARAM_TOKEN_LENGTH, DEFAULT_KEY_SIZE));
            String nodeId = getIdentifier(tokenNode.getTree());
            String token = new StringBuilder(nodeId).append(DELIM).append(key).toString();
            String keyHash = PasswordUtil.buildPasswordHash(getKeyValue(key, userId));
            tokenNode.setString(TOKEN_ATTRIBUTE_KEY, keyHash);
            long exp;
            if (attributes.containsKey(PARAM_TOKEN_EXPIRATION)) {
                exp = Long.parseLong(attributes.get(PARAM_TOKEN_EXPIRATION).toString());
            } else {
                exp = tokenExpiration;
            }
            long expTime = createExpirationTime(creationTime, exp);
            tokenNode.setDate(TOKEN_ATTRIBUTE_EXPIRY, expTime);
            for (String name : attributes.keySet()) {
                if (!RESERVED_ATTRIBUTES.contains(name)) {
                    String attr = attributes.get(name).toString();
                    tokenNode.setString(name, attr);
                }
            }
            root.commit();
            return new TokenInfoImpl(tokenNode, token, userId);
        } catch (NoSuchAlgorithmException e) {
            // error while generating login token
            log.error(error, e.getMessage());
        } catch (UnsupportedEncodingException e) {
            // error while generating login token
            log.error(error, e.getMessage());
        } catch (CommitFailedException e) {
            // conflict while committing changes
            log.warn(error, e.getMessage());
        } catch (AccessDeniedException e) {
            log.warn(error, e.getMessage());
        }
    } else {
        log.warn(""Unable to get/create token store for user "" + userId);
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1719_c3773d53,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,210,252,"/**
 * Copies the full content from the source to the target repository.
 * <p>
 * The source repository <strong>must not be modified</strong> while
 * the copy operation is running to avoid an inconsistent copy.
 * <p>
 * This method leaves the search indexes of the target repository in
 * an
 * Note that both the source and the target repository must be closed
 * during the copy operation as this method requires exclusive access
 * to the repositories.
 *
 * @throws RepositoryException if the copy operation fails
 */
public void copy() throws RepositoryException {
    RepositoryConfig config = source.getRepositoryConfig();
    logger.info(""Copying repository content from {} to Oak"", config.getHomeDir());
    try {
        NodeBuilder builder = target.getRoot().builder();
        // init target repository first
        new InitialContent().initialize(builder);
        Map<String, String> uriToPrefix = newHashMap();
        Map<Integer, String> idxToPrefix = newHashMap();
        copyNamespaces(builder, uriToPrefix, idxToPrefix);
        copyNodeTypes(builder);
        copyPrivileges(builder);
        NodeState root = builder.getNodeState();
        copyVersionStore(builder, root, uriToPrefix, idxToPrefix);
        String workspaceName = copyWorkspaces(builder, root, uriToPrefix, idxToPrefix);
        logger.info(""Applying default commit hooks"");
        String groupsPath;
        UserManagerConfig userConfig = config.getSecurityConfig().getSecurityManagerConfig().getUserManagerConfig();
        if (userConfig != null) {
            groupsPath = userConfig.getParameters().getProperty(UserManagerImpl.PARAM_GROUPS_PATH, UserConstants.DEFAULT_GROUP_PATH);
        } else {
            groupsPath = UserConstants.DEFAULT_GROUP_PATH;
        }
        // TODO: default hooks?
        List<CommitHook> hooks = newArrayList();
        hooks.add(new EditorHook(new CompositeEditorProvider(new GroupEditorProvider(groupsPath), new TypeEditorProvider(false), new IndexUpdateProvider(new CompositeIndexEditorProvider(new ReferenceEditorProvider(), new PropertyIndexEditorProvider())))));
        hooks.addAll(new AuthorizationConfigurationImpl().getCommitHooks(workspaceName));
        target.merge(builder, CompositeHook.compose(hooks), CommitInfo.EMPTY);
    } catch (Exception e) {
        throw new RepositoryException(""Failed to copy content"", e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1719_c3773d53,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,565,591,"private String copyWorkspaces(NodeBuilder builder, NodeState root, Map<String, String> uriToPrefix, Map<Integer, String> idxToPrefix) throws RepositoryException, IOException {
    logger.info(""Copying default workspace"");
    // Copy all the default workspace content
    RepositoryConfig config = source.getRepositoryConfig();
    String name = config.getDefaultWorkspaceName();
    PersistenceManager pm = source.getWorkspaceInfo(name).getPersistenceManager();
    NodeState state = new JackrabbitNodeState(pm, root, uriToPrefix, ROOT_NODE_ID, ""/"", copyBinariesByReference);
    for (PropertyState property : state.getProperties()) {
        builder.setProperty(property);
    }
    for (ChildNodeEntry child : state.getChildNodeEntries()) {
        String childName = child.getName();
        if (!JCR_SYSTEM.equals(childName)) {
            builder.setChildNode(childName, child.getNodeState());
        }
    }
    return name;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1727_26041fe7,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Revision.java,514,532,"@Override
public int compare(Revision o1, Revision o2) {
    if (o1.getClusterId() == o2.getClusterId()) {
        return o1.compareRevisionTime(o2);
    }
    Revision range1 = getRevisionSeen(o1);
    Revision range2 = getRevisionSeen(o2);
    if (range1 == FUTURE && range2 == FUTURE) {
        return o1.compareRevisionTimeThenClusterId(o2);
    }
    if (range1 == null || range2 == null) {
        return o1.compareRevisionTimeThenClusterId(o2);
    }
    int comp = range1.compareRevisionTimeThenClusterId(range2);
    if (comp != 0) {
        return comp;
    }
    return Integer.signum(o1.getClusterId() - o2.getClusterId());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1729_7ba9dd66,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1337,1354,"/**
 * Set various split document related flag/properties
 *
 * @param mainDoc main document from which split document is being created
 * @param old updateOp of the old document created via split
 * @param oldDoc old document created via split
 * @param maxRev max revision stored in the split document oldDoc
 */
private static void setSplitDocProps(NodeDocument mainDoc, NodeDocument oldDoc, UpdateOp old, Revision maxRev) {
    setSplitDocMaxRev(old, maxRev);
    SplitDocType type = SplitDocType.DEFAULT;
    if (!mainDoc.hasChildren()) {
        type = SplitDocType.DEFAULT_NO_CHILD;
    } else if (oldDoc.getLocalRevisions().isEmpty()) {
        type = SplitDocType.PROP_COMMIT_ONLY;
    }
    // Copy over the hasBinary flag
    if (mainDoc.hasBinary()) {
        setHasBinary(old);
    }
    setSplitDocType(old, type);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1731_024e5d37,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,218,280,"/**
 * Copies the full content from the source to the target repository.
 * <p>
 * The source repository <strong>must not be modified</strong> while
 * the copy operation is running to avoid an inconsistent copy.
 * <p>
 * Note that both the source and the target repository must be closed
 * during the copy operation as this method requires exclusive access
 * to the repositories.
 *
 * @param initializer optional extra repository initializer to use
 * @throws RepositoryException if the copy operation fails
 */
public void copy(RepositoryInitializer initializer) throws RepositoryException {
    RepositoryConfig config = source.getRepositoryConfig();
    logger.info(""Copying repository content from {} to Oak"", config.getHomeDir());
    try {
        NodeBuilder builder = target.getRoot().builder();
        String workspace = source.getRepositoryConfig().getDefaultWorkspaceName();
        SecurityProviderImpl security = new SecurityProviderImpl(mapSecurityConfig(config.getSecurityConfig()));
        // init target repository first
        new InitialContent().initialize(builder);
        if (initializer != null) {
            initializer.initialize(builder);
        }
        for (SecurityConfiguration sc : security.getConfigurations()) {
            sc.getWorkspaceInitializer().initialize(builder, workspace);
        }
        Map<String, String> uriToPrefix = newHashMap();
        Map<Integer, String> idxToPrefix = newHashMap();
        copyNamespaces(builder, uriToPrefix, idxToPrefix);
        copyNodeTypes(builder);
        copyPrivileges(builder);
        NodeState root = builder.getNodeState();
        copyVersionStore(builder, root, uriToPrefix, idxToPrefix);
        copyWorkspace(builder, root, workspace, uriToPrefix, idxToPrefix);
        logger.info(""Applying default commit hooks"");
        // TODO: default hooks?
        List<CommitHook> hooks = newArrayList();
        UserConfiguration userConf = security.getConfiguration(UserConfiguration.class);
        String groupsPath = userConf.getParameters().getConfigValue(UserConstants.PARAM_GROUP_PATH, UserConstants.DEFAULT_GROUP_PATH);
        // hooks specific to the upgrade, need to run first
        hooks.add(new EditorHook(new CompositeEditorProvider(new RestrictionEditorProvider(), new GroupEditorProvider(groupsPath))));
        // security-related hooks
        for (SecurityConfiguration sc : security.getConfigurations()) {
            hooks.addAll(sc.getCommitHooks(workspace));
        }
        // type validation, reference and indexing hooks
        hooks.add(new EditorHook(new CompositeEditorProvider(new TypeEditorProvider(false), new IndexUpdateProvider(new CompositeIndexEditorProvider(new ReferenceEditorProvider(), new PropertyIndexEditorProvider())))));
        target.merge(builder, CompositeHook.compose(hooks), CommitInfo.EMPTY);
    } catch (Exception e) {
        throw new RepositoryException(""Failed to copy content"", e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1731_024e5d37,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,461,476,"private void copyNodeTypes(NodeBuilder root) throws RepositoryException {
    NodeTypeRegistry sourceRegistry = source.getNodeTypeRegistry();
    NodeBuilder system = root.child(JCR_SYSTEM);
    NodeBuilder types = system.child(JCR_NODE_TYPES);
    logger.info(""Copying registered node types"");
    for (Name name : sourceRegistry.getRegisteredNodeTypes()) {
        String oakName = getOakName(name);
        // skip built-in nodetypes (OAK-1235)
        if (!types.hasChildNode(oakName)) {
            QNodeTypeDefinition def = sourceRegistry.getNodeTypeDef(name);
            NodeBuilder type = types.child(oakName);
            copyNodeType(def, type);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1731_024e5d37,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,478,522,"private void copyNodeType(QNodeTypeDefinition def, NodeBuilder builder) throws NamespaceException {
    builder.setProperty(JCR_PRIMARYTYPE, NT_NODETYPE, NAME);
    // - jcr:nodeTypeName (NAME) protected mandatory
    builder.setProperty(JCR_NODETYPENAME, getOakName(def.getName()), NAME);
    // - jcr:supertypes (NAME) protected multiple
    Name[] supertypes = def.getSupertypes();
    if (supertypes != null && supertypes.length > 0) {
        List<String> names = newArrayListWithCapacity(supertypes.length);
        for (Name supertype : supertypes) {
            names.add(getOakName(supertype));
        }
        builder.setProperty(JCR_SUPERTYPES, names, NAMES);
    }
    // - jcr:isAbstract (BOOLEAN) protected mandatory
    builder.setProperty(JCR_IS_ABSTRACT, def.isAbstract());
    // - jcr:isQueryable (BOOLEAN) protected mandatory
    builder.setProperty(JCR_IS_QUERYABLE, def.isQueryable());
    // - jcr:isMixin (BOOLEAN) protected mandatory
    builder.setProperty(JCR_ISMIXIN, def.isMixin());
    // - jcr:hasOrderableChildNodes (BOOLEAN) protected mandatory
    builder.setProperty(JCR_HASORDERABLECHILDNODES, def.hasOrderableChildNodes());
    // - jcr:primaryItemName (NAME) protected
    Name primary = def.getPrimaryItemName();
    if (primary != null) {
        builder.setProperty(JCR_PRIMARYITEMNAME, getOakName(primary), NAME);
    }
    // + jcr:propertyDefinition (nt:propertyDefinition) = nt:propertyDefinition protected sns
    QPropertyDefinition[] properties = def.getPropertyDefs();
    for (int i = 0; i < properties.length; i++) {
        String name = JCR_PROPERTYDEFINITION + '[' + (i + 1) + ']';
        copyPropertyDefinition(properties[i], builder.child(name));
    }
    // + jcr:childNodeDefinition (nt:childNodeDefinition) = nt:childNodeDefinition protected sns
    QNodeDefinition[] childNodes = def.getChildNodeDefs();
    for (int i = 0; i < childNodes.length; i++) {
        String name = JCR_CHILDNODEDEFINITION + '[' + (i + 1) + ']';
        copyChildNodeDefinition(childNodes[i], builder.child(name));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1731_024e5d37,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,524,562,"private void copyPropertyDefinition(QPropertyDefinition def, NodeBuilder builder) throws NamespaceException {
    builder.setProperty(JCR_PRIMARYTYPE, NT_PROPERTYDEFINITION, NAME);
    copyItemDefinition(def, builder);
    // - jcr:requiredType (STRING) protected mandatory
    // < 'STRING', 'URI', 'BINARY', 'LONG', 'DOUBLE',
    // 'DECIMAL', 'BOOLEAN', 'DATE', 'NAME', 'PATH',
    // 'REFERENCE', 'WEAKREFERENCE', 'UNDEFINED'
    builder.setProperty(JCR_REQUIREDTYPE, Type.fromTag(def.getRequiredType(), false).toString());
    // - jcr:valueConstraints (STRING) protected multiple
    QValueConstraint[] constraints = def.getValueConstraints();
    if (constraints != null && constraints.length > 0) {
        List<String> strings = newArrayListWithCapacity(constraints.length);
        for (QValueConstraint constraint : constraints) {
            strings.add(constraint.getString());
        }
        builder.setProperty(JCR_VALUECONSTRAINTS, strings, STRINGS);
    }
    // - jcr:defaultValues (UNDEFINED) protected multiple
    QValue[] values = def.getDefaultValues();
    if (values != null) {
    // TODO
    }
    // - jcr:multiple (BOOLEAN) protected mandatory
    builder.setProperty(JCR_MULTIPLE, def.isMultiple());
    // - jcr:availableQueryOperators (NAME) protected mandatory multiple
    List<String> operators = asList(def.getAvailableQueryOperators());
    builder.setProperty(JCR_AVAILABLE_QUERY_OPERATORS, operators, NAMES);
    // - jcr:isFullTextSearchable (BOOLEAN) protected mandatory
    builder.setProperty(JCR_IS_FULLTEXT_SEARCHABLE, def.isFullTextSearchable());
    // - jcr:isQueryOrderable (BOOLEAN) protected mandatory
    builder.setProperty(JCR_IS_QUERY_ORDERABLE, def.isQueryOrderable());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1739_8188ef54,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/ComparisonImpl.java,82,105,"@Override
public boolean evaluate() {
    // JCR 2.0 spec, 6.7.16 Comparison:
    // ""operand1 may evaluate to an array of values""
    PropertyValue p1 = operand1.currentProperty();
    if (p1 == null) {
        return false;
    }
    PropertyValue p2 = operand2.currentValue();
    if (p2 == null) {
        // even for ""null <> 'x'"" (same as in SQL)
        return false;
    }
    // property type of the value of operand1""
    try {
        p2 = convertValueToType(p2, p1);
    } catch (IllegalArgumentException ex) {
        // unable to convert, just skip this node
        return false;
    }
    return evaluate(p1, p2);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1749_591e4d4a,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,135,227,"@Override
public synchronized void run() {
    log.debug(""Running background index task {}"", name);
    if (isAlreadyRunning(store, name)) {
        log.debug(""Async job '{}' found to be already running. Skipping"", name);
        return;
    }
    String checkpoint = store.checkpoint(lifetime);
    NodeState after = store.retrieve(checkpoint);
    if (after == null) {
        log.debug(""Unable to retrieve checkpoint {}"", checkpoint);
        return;
    }
    NodeBuilder builder = store.getRoot().builder();
    NodeBuilder async = builder.child(ASYNC);
    NodeState before = null;
    final PropertyState state = async.getProperty(name);
    if (state != null && state.getType() == STRING) {
        before = store.retrieve(state.getValue(STRING));
    }
    if (before == null) {
        before = MISSING_NODE;
    }
    AsyncUpdateCallback callback = new AsyncUpdateCallback();
    preAsyncRunStatsStats(indexStats);
    IndexUpdate indexUpdate = new IndexUpdate(provider, name, after, builder, callback);
    CommitFailedException exception = EditorDiff.process(indexUpdate, before, after);
    if (exception == null) {
        if (callback.dirty) {
            async.setProperty(name, checkpoint);
            try {
                store.merge(builder, newCommitHook(name, state), CommitInfo.EMPTY);
            } catch (CommitFailedException e) {
                if (e != CONCURRENT_UPDATE) {
                    exception = e;
                }
            }
            if (switchOnSync) {
                reindexedDefinitions.addAll(indexUpdate.getReindexedDefinitions());
            } else {
                postAsyncRunStatsStatus(indexStats);
            }
        } else if (switchOnSync) {
            log.debug(""No changes detected after diff, will try to switch to synchronous updates on "" + reindexedDefinitions);
            async.setProperty(name, checkpoint);
            // no changes after diff, switch to sync on the async defs
            for (String path : reindexedDefinitions) {
                NodeBuilder c = builder;
                for (String p : elements(path)) {
                    c = c.getChildNode(p);
                }
                if (c.exists() && !c.getBoolean(REINDEX_PROPERTY_NAME)) {
                    c.removeProperty(ASYNC_PROPERTY_NAME);
                }
            }
            try {
                store.merge(builder, newCommitHook(name, state), CommitInfo.EMPTY);
                reindexedDefinitions.clear();
                postAsyncRunStatsStatus(indexStats);
            } catch (CommitFailedException e) {
                if (e != CONCURRENT_UPDATE) {
                    exception = e;
                }
            }
        }
    }
    if (exception != null) {
        if (!failing) {
            log.warn(""Index update {} failed"", name, exception);
        }
        failing = true;
    } else {
        if (failing) {
            log.info(""Index update {} no longer fails"", name);
        }
        failing = false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1761_f37ce716,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,278,290,"@Override
public String serialize(Blob blob) {
    if (blob instanceof BlobStoreBlob) {
        return ((BlobStoreBlob) blob).getBlobId();
    }
    String id;
    try {
        id = createBlob(blob.getNewStream()).getBlobId();
    } catch (IOException e) {
        throw new IllegalStateException(e);
    }
    return id;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1770_192ee9e4,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,871,1022,"/**
 * Returns update operations to split this document. The implementation may
 * decide to not return any operations if no splitting is required.
 *
 * @param context the revision context.
 * @return the split operations.
 */
@Nonnull
public Iterable<UpdateOp> split(@Nonnull RevisionContext context) {
    SortedMap<Revision, Range> previous = getPreviousRanges();
    // unless document is really big
    if (getLocalRevisions().size() + getLocalCommitRoot().size() <= NUM_REVS_THRESHOLD && getMemory() < DOC_SIZE_THRESHOLD && previous.size() < PREV_SPLIT_FACTOR) {
        return Collections.emptyList();
    }
    String path = getPath();
    String id = getId();
    if (id == null) {
        throw new IllegalStateException(""document does not have an id: "" + this);
    }
    // collect ranges and create a histogram of the height
    Map<Integer, List<Range>> prevHisto = Maps.newHashMap();
    for (Map.Entry<Revision, Range> entry : previous.entrySet()) {
        Revision rev = entry.getKey();
        if (rev.getClusterId() != context.getClusterId()) {
            continue;
        }
        Range r = entry.getValue();
        List<Range> list = prevHisto.get(r.getHeight());
        if (list == null) {
            list = new ArrayList<Range>();
            prevHisto.put(r.getHeight(), list);
        }
        list.add(r);
    }
    Map<String, NavigableMap<Revision, String>> splitValues = new HashMap<String, NavigableMap<Revision, String>>();
    for (String property : data.keySet()) {
        if (IGNORE_ON_SPLIT.contains(property)) {
            continue;
        }
        NavigableMap<Revision, String> splitMap = new TreeMap<Revision, String>(context.getRevisionComparator());
        splitValues.put(property, splitMap);
        Map<Revision, String> valueMap = getLocalMap(property);
        // most recent previous split revision
        for (Map.Entry<Revision, String> entry : valueMap.entrySet()) {
            Revision rev = entry.getKey();
            if (rev.getClusterId() != context.getClusterId()) {
                continue;
            }
            if (isCommitted(rev)) {
                splitMap.put(rev, entry.getValue());
            }
        }
    }
    List<UpdateOp> splitOps = Lists.newArrayList();
    int numValues = 0;
    Revision high = null;
    Revision low = null;
    for (NavigableMap<Revision, String> splitMap : splitValues.values()) {
        // keep the most recent in the main document
        if (!splitMap.isEmpty()) {
            splitMap.remove(splitMap.lastKey());
        }
        if (splitMap.isEmpty()) {
            continue;
        }
        // remember highest / lowest revision
        if (high == null || isRevisionNewer(context, splitMap.lastKey(), high)) {
            high = splitMap.lastKey();
        }
        if (low == null || isRevisionNewer(context, low, splitMap.firstKey())) {
            low = splitMap.firstKey();
        }
        numValues += splitMap.size();
    }
    UpdateOp main = null;
    if (high != null && low != null && (numValues >= NUM_REVS_THRESHOLD || getMemory() > DOC_SIZE_THRESHOLD)) {
        // enough revisions to split off
        // move to another document
        main = new UpdateOp(id, false);
        setPrevious(main, new Range(high, low, 0));
        String oldPath = Utils.getPreviousPathFor(path, high, 0);
        UpdateOp old = new UpdateOp(Utils.getIdFromPath(oldPath), true);
        old.set(ID, old.getId());
        if (Utils.isLongPath(oldPath)) {
            old.set(PATH, oldPath);
        }
        for (String property : splitValues.keySet()) {
            NavigableMap<Revision, String> splitMap = splitValues.get(property);
            for (Map.Entry<Revision, String> entry : splitMap.entrySet()) {
                Revision r = entry.getKey();
                main.removeMapEntry(property, r);
                old.setMapEntry(property, r, entry.getValue());
            }
        }
        // check size of old document
        NodeDocument oldDoc = new NodeDocument(store);
        UpdateUtils.applyChanges(oldDoc, old, context.getRevisionComparator());
        setSplitDocProps(this, oldDoc, old, high);
        // only split if enough of the data can be moved to old document
        if (oldDoc.getMemory() > getMemory() * SPLIT_RATIO) {
            splitOps.add(old);
        } else {
            main = null;
        }
    }
    // check if we need to create intermediate previous documents
    for (Map.Entry<Integer, List<Range>> entry : prevHisto.entrySet()) {
        if (entry.getValue().size() >= PREV_SPLIT_FACTOR) {
            if (main == null) {
                main = new UpdateOp(id, false);
            }
            // calculate range new range
            Revision h = null;
            Revision l = null;
            for (Range r : entry.getValue()) {
                if (h == null || isRevisionNewer(context, r.high, h)) {
                    h = r.high;
                }
                if (l == null || isRevisionNewer(context, l, r.low)) {
                    l = r.low;
                }
                removePrevious(main, r);
            }
            if (h == null || l == null) {
                throw new IllegalStateException();
            }
            String prevPath = Utils.getPreviousPathFor(path, h, entry.getKey() + 1);
            String prevId = Utils.getIdFromPath(prevPath);
            UpdateOp intermediate = new UpdateOp(prevId, true);
            intermediate.set(ID, prevId);
            if (Utils.isLongPath(prevPath)) {
                intermediate.set(PATH, prevPath);
            }
            setPrevious(main, new Range(h, l, entry.getKey() + 1));
            for (Range r : entry.getValue()) {
                setPrevious(intermediate, r);
            }
            setIntermediateDocProps(intermediate, h);
            splitOps.add(intermediate);
        }
    }
    // main document must be updated last
    if (main != null && !splitOps.isEmpty()) {
        splitOps.add(main);
    }
    return splitOps;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1779_9d36bede,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/VersionGarbageCollector.java,97,125,"private void collectDeletedDocuments(VersionGCStats stats, Revision headRevision, long oldestRevTimeStamp) {
    List<String> docIdsToDelete = new ArrayList<String>();
    Iterable<NodeDocument> itr = versionStore.getPossiblyDeletedDocs(oldestRevTimeStamp);
    try {
        for (NodeDocument doc : itr) {
            // So deleting it is safe
            if (doc.getNodeAtRevision(nodeStore, headRevision, null) == null) {
                docIdsToDelete.add(doc.getId());
                // Collect id of all previous docs also
                for (NodeDocument prevDoc : ImmutableList.copyOf(doc.getAllPreviousDocs())) {
                    docIdsToDelete.add(prevDoc.getId());
                }
            }
        }
    } finally {
        Utils.closeIfCloseable(itr);
    }
    if (log.isDebugEnabled()) {
        StringBuilder sb = new StringBuilder(""Deleted document with following ids were deleted as part of GC \n"");
        Joiner.on(StandardSystemProperty.LINE_SEPARATOR.value()).appendTo(sb, docIdsToDelete);
        log.debug(sb.toString());
    }
    nodeStore.getDocumentStore().remove(Collection.NODES, docIdsToDelete);
    stats.deletedDocGCCount += docIdsToDelete.size();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1784_2426deae,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,227,245,"private static CommitHook newCommitHook(final String name, final PropertyState state) throws CommitFailedException {
    return new CommitHook() {

        @Override
        @Nonnull
        public NodeState processCommit(NodeState before, NodeState after, CommitInfo info) throws CommitFailedException {
            // check for concurrent updates by this async task
            PropertyState stateAfterRebase = before.getChildNode(ASYNC).getProperty(name);
            if (Objects.equal(state, stateAfterRebase)) {
                return postAsyncRunNodeStatus(after.builder(), name).getNodeState();
            } else {
                throw CONCURRENT_UPDATE;
            }
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1788_dd3437d4,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Revision.java,572,610,"/**
 * Get the seen-at revision from the revision range.
 * <p>
 * <ul>
 *     <li>
 *         {@code null} if the revision is older than the earliest range
 *     </li>
 *     <li>
 *         if the revision is newer than the lower bound of the newest
 *         range, then {@link #NEWEST} is returned for a local cluster
 *         revision and {@link #FUTURE} for a foreign cluster revision.
 *     </li>
 *     <li>
 *         if the revision matches the lower seen-at bound of a range,
 *         then this seen-at revision is returned.
 *     </li>
 *     <li>
 *         otherwise the lower bound seen-at revision of next higher
 *         range is returned.
 *     </li>
 * </ul>
 *
 * @param r the revision
 * @return the seen-at revision or {@code null} if the revision is older
 *          than the earliest range.
 */
Revision getRevisionSeen(Revision r) {
    List<RevisionRange> list = map.get(r.getClusterId());
    if (list == null) {
        if (r.getTimestamp() <= oldestTimestamp) {
            // old revision with already purged range
            return null;
        }
        if (r.getClusterId() != currentClusterNodeId) {
            // see also OAK-1170
            return FUTURE;
        }
        return null;
    }
    // at the end of the list)
    for (int i = list.size() - 1; i >= 0; i--) {
        RevisionRange range = list.get(i);
        int compare = r.compareRevisionTime(range.revision);
        if (compare == 0) {
            return range.seenAt;
        } else if (compare > 0) {
            if (i == list.size() - 1) {
                // newer than the newest range
                if (r.getClusterId() == currentClusterNodeId) {
                    // newer than all others, except for FUTURE
                    return NEWEST;
                }
                // happens in the future (not visible yet)
                return FUTURE;
            } else {
                // there is a newer range
                return list.get(i + 1).seenAt;
            }
        }
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1789_07646fba,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/JackrabbitNodeState.java,315,341,"private void fixFrozenUuid() {
    // OAK-1789: Convert the jcr:frozenUuid of a non-referenceable
    // frozen node from UUID to a path identifier
    PropertyState frozenUuid = properties.get(JCR_FROZENUUID);
    if (frozenUuid != null && frozenUuid.getType() == STRING && isFrozenNode.apply(this)) {
        String frozenPrimary = NT_BASE;
        Set<String> frozenMixins = newHashSet();
        PropertyState property = properties.get(JCR_FROZENPRIMARYTYPE);
        if (property != null && property.getType() == NAME) {
            frozenPrimary = property.getValue(NAME);
        }
        property = properties.get(JCR_FROZENMIXINTYPES);
        if (property != null && property.getType() == NAMES) {
            addAll(frozenMixins, property.getValue(NAMES));
        }
        if (!isReferenceable.apply(frozenPrimary, frozenMixins)) {
            frozenUuid = PropertyStates.createProperty(JCR_FROZENUUID, parent.getString(JCR_FROZENUUID) + ""/"" + name);
            properties.put(JCR_FROZENUUID, frozenUuid);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1789_07646fba,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,236,298,"/**
 * Copies the full content from the source to the target repository.
 * <p>
 * The source repository <strong>must not be modified</strong> while
 * the copy operation is running to avoid an inconsistent copy.
 * <p>
 * Note that both the source and the target repository must be closed
 * during the copy operation as this method requires exclusive access
 * to the repositories.
 *
 * @param initializer optional extra repository initializer to use
 * @throws RepositoryException if the copy operation fails
 */
public void copy(RepositoryInitializer initializer) throws RepositoryException {
    RepositoryConfig config = source.getRepositoryConfig();
    logger.info(""Copying repository content from {} to Oak"", config.getHomeDir());
    try {
        NodeBuilder builder = target.getRoot().builder();
        String workspace = source.getRepositoryConfig().getDefaultWorkspaceName();
        SecurityProviderImpl security = new SecurityProviderImpl(mapSecurityConfig(config.getSecurityConfig()));
        // init target repository first
        new InitialContent().initialize(builder);
        if (initializer != null) {
            initializer.initialize(builder);
        }
        for (SecurityConfiguration sc : security.getConfigurations()) {
            sc.getWorkspaceInitializer().initialize(builder, workspace);
        }
        HashBiMap<String, String> uriToPrefix = HashBiMap.create();
        Map<Integer, String> idxToPrefix = newHashMap();
        copyNamespaces(builder, uriToPrefix, idxToPrefix);
        copyNodeTypes(builder, uriToPrefix.inverse());
        copyPrivileges(builder);
        NodeState root = builder.getNodeState();
        copyVersionStore(builder, root, uriToPrefix, idxToPrefix);
        copyWorkspace(builder, root, workspace, uriToPrefix, idxToPrefix);
        logger.info(""Applying default commit hooks"");
        // TODO: default hooks?
        List<CommitHook> hooks = newArrayList();
        UserConfiguration userConf = security.getConfiguration(UserConfiguration.class);
        String groupsPath = userConf.getParameters().getConfigValue(UserConstants.PARAM_GROUP_PATH, UserConstants.DEFAULT_GROUP_PATH);
        // hooks specific to the upgrade, need to run first
        hooks.add(new EditorHook(new CompositeEditorProvider(new RestrictionEditorProvider(), new GroupEditorProvider(groupsPath))));
        // security-related hooks
        for (SecurityConfiguration sc : security.getConfigurations()) {
            hooks.addAll(sc.getCommitHooks(workspace));
        }
        // type validation, reference and indexing hooks
        hooks.add(new EditorHook(new CompositeEditorProvider(new TypeEditorProvider(false), new IndexUpdateProvider(new CompositeIndexEditorProvider(new ReferenceEditorProvider(), new PropertyIndexEditorProvider())))));
        target.merge(builder, CompositeHook.compose(hooks), CommitInfo.EMPTY);
    } catch (Exception e) {
        throw new RepositoryException(""Failed to copy content"", e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1789_08ba79d4,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/JackrabbitNodeState.java,242,294,"public Map<String, PropertyState> createProperties(NodePropBundle bundle) {
    Map<String, PropertyState> properties = newHashMap();
    String primary;
    if (bundle.getNodeTypeName() != null) {
        primary = createName(bundle.getNodeTypeName());
    } else {
        warn(""Missing primary node type; defaulting to nt:unstructured"");
        primary = NT_UNSTRUCTURED;
    }
    properties.put(JCR_PRIMARYTYPE, PropertyStates.createProperty(JCR_PRIMARYTYPE, primary, Type.NAME));
    Set<String> mixins = newLinkedHashSet();
    if (bundle.getMixinTypeNames() != null) {
        for (Name mixin : bundle.getMixinTypeNames()) {
            mixins.add(createName(mixin));
        }
    }
    if (!mixins.isEmpty()) {
        properties.put(JCR_MIXINTYPES, PropertyStates.createProperty(JCR_MIXINTYPES, mixins, Type.NAMES));
    }
    if (bundle.isReferenceable() || isReferenceable.apply(primary, mixins)) {
        properties.put(JCR_UUID, PropertyStates.createProperty(JCR_UUID, bundle.getId().toString()));
    }
    if (isOrderable.apply(primary, mixins)) {
        properties.put(OAK_CHILD_ORDER, PropertyStates.createProperty(OAK_CHILD_ORDER, nodes.keySet(), Type.NAMES));
    }
    for (PropertyEntry property : bundle.getPropertyEntries()) {
        String name = createName(property.getName());
        try {
            int type = property.getType();
            if (property.isMultiValued()) {
                properties.put(name, createProperty(name, type, property.getValues()));
            } else {
                properties.put(name, createProperty(name, type, property.getValues()[0]));
            }
        } catch (Exception e) {
            warn(""Skipping broken property entry "" + name, e);
        }
    }
    return properties;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1789_9f7c1df0,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/JackrabbitNodeState.java,255,333,"private Map<String, PropertyState> createProperties(NodePropBundle bundle) {
    Map<String, PropertyState> properties = newHashMap();
    String primary;
    if (bundle.getNodeTypeName() != null) {
        primary = createName(bundle.getNodeTypeName());
    } else {
        warn(""Missing primary node type; defaulting to nt:unstructured"");
        primary = NT_UNSTRUCTURED;
    }
    properties.put(JCR_PRIMARYTYPE, PropertyStates.createProperty(JCR_PRIMARYTYPE, primary, Type.NAME));
    Set<String> mixins = newLinkedHashSet();
    if (bundle.getMixinTypeNames() != null) {
        for (Name mixin : bundle.getMixinTypeNames()) {
            mixins.add(createName(mixin));
        }
    }
    if (!mixins.isEmpty()) {
        properties.put(JCR_MIXINTYPES, PropertyStates.createProperty(JCR_MIXINTYPES, mixins, Type.NAMES));
    }
    if (bundle.isReferenceable() || isReferenceable.apply(primary, mixins)) {
        properties.put(JCR_UUID, PropertyStates.createProperty(JCR_UUID, bundle.getId().toString()));
    }
    if (isOrderable.apply(primary, mixins)) {
        properties.put(OAK_CHILD_ORDER, PropertyStates.createProperty(OAK_CHILD_ORDER, nodes.keySet(), Type.NAMES));
    }
    for (PropertyEntry property : bundle.getPropertyEntries()) {
        String name = createName(property.getName());
        try {
            int type = property.getType();
            if (property.isMultiValued()) {
                properties.put(name, createProperty(name, type, property.getValues()));
            } else {
                properties.put(name, createProperty(name, type, property.getValues()[0]));
            }
        } catch (Exception e) {
            warn(""Skipping broken property entry "" + name, e);
        }
    }
    // OAK-1789: Convert the jcr:frozenUuid of a non-referenceable
    // frozen node from UUID to a path identifier
    PropertyState frozenUuid = properties.get(JCR_FROZENUUID);
    if (frozenUuid != null && frozenUuid.getType() == STRING && isFrozenNode.apply(primary, mixins)) {
        String frozenPrimary = NT_UNSTRUCTURED;
        Set<String> frozenMixins = newHashSet();
        PropertyState property = properties.get(JCR_FROZENPRIMARYTYPE);
        if (property != null && property.getType() == NAME) {
            primary = property.getValue(NAME);
        }
        property = properties.get(JCR_FROZENMIXINTYPES);
        if (property != null && property.getType() == NAMES) {
            addAll(frozenMixins, property.getValue(NAMES));
        }
        if (!isReferenceable.apply(frozenPrimary, frozenMixins)) {
            frozenUuid = PropertyStates.createProperty(JCR_FROZENUUID, parent.getString(JCR_FROZENUUID) + ""/"" + name);
            properties.put(JCR_FROZENUUID, frozenUuid);
        }
    }
    return properties;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1807_077efee5,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Revision.java,155,167,"/**
 * Create a simple revision id. The format is similar to MongoDB ObjectId.
 *
 * @param clusterId the unique machineId + processId
 * @return the unique revision id
 */
static Revision newRevision(int clusterId) {
    long timestamp = getCurrentTimestamp();
    int c;
    synchronized (Revision.class) {
        if (timestamp == lastRevisionTimestamp) {
            c = ++lastRevisionCount;
        } else {
            lastRevisionTimestamp = timestamp;
            lastRevisionCount = c = 0;
        }
    }
    return new Revision(timestamp, c, clusterId);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1817_78c37386,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentWriter.java,166,234,"public synchronized void flush() {
    if (length > 0) {
        int refcount = segment.getRefCount();
        int rootcount = roots.size();
        buffer[Segment.ROOT_COUNT_OFFSET] = (byte) (rootcount >> 8);
        buffer[Segment.ROOT_COUNT_OFFSET + 1] = (byte) rootcount;
        int blobrefcount = blobrefs.size();
        buffer[Segment.BLOBREF_COUNT_OFFSET] = (byte) (blobrefcount >> 8);
        buffer[Segment.BLOBREF_COUNT_OFFSET + 1] = (byte) blobrefcount;
        length = align(refcount * 16 + rootcount * 3 + blobrefcount * 2 + length, 16);
        int pos = refcount * 16;
        if (pos + length <= buffer.length) {
            // the whole segment fits to the space *after* the referenced
            // segment identifiers we've already written, so we can safely
            // copy those bits ahead even if concurrent code is still
            // reading from that part of the buffer
            System.arraycopy(buffer, 0, buffer, buffer.length - length, pos);
            pos += buffer.length - length;
        } else {
            // this might leave some empty space between the header and
            // the record data, but this case only occurs when the
            // segment is >252kB in size and the maximum overhead is <<4kB,
            // which is acceptable
            length = buffer.length;
        }
        for (Map.Entry<RecordId, RecordType> entry : roots.entrySet()) {
            int offset = entry.getKey().getOffset();
            buffer[pos++] = (byte) entry.getValue().ordinal();
            buffer[pos++] = (byte) (offset >> (8 + Segment.RECORD_ALIGN_BITS));
            buffer[pos++] = (byte) (offset >> Segment.RECORD_ALIGN_BITS);
        }
        for (RecordId blobref : blobrefs) {
            int offset = blobref.getOffset();
            buffer[pos++] = (byte) (offset >> (8 + Segment.RECORD_ALIGN_BITS));
            buffer[pos++] = (byte) (offset >> Segment.RECORD_ALIGN_BITS);
        }
        SegmentId id = segment.getSegmentId();
        log.debug(""Writing data segment {} ({} bytes)"", id, length);
        store.writeSegment(id, buffer, buffer.length - length, length);
        // Keep this segment in memory as it's likely to be accessed soon
        ByteBuffer data;
        if (buffer.length - length > 4096) {
            data = ByteBuffer.allocate(length);
            data.put(buffer, buffer.length - length, length);
            data.rewind();
        } else {
            data = ByteBuffer.wrap(buffer);
        }
        tracker.setSegment(id, new Segment(tracker, id, data));
        buffer = createNewBuffer();
        roots.clear();
        blobrefs.clear();
        length = 0;
        position = buffer.length;
        segment = new Segment(tracker, buffer);
        segment.getSegmentId().setSegment(segment);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1206,1209,"public static void setModified(@Nonnull UpdateOp op, @Nonnull Revision revision) {
    checkNotNull(op).set(MODIFIED_IN_SECS, getModifiedInSecs(checkNotNull(revision).getTimestamp()));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,133,138,"/**
 * Add a new or update an existing map entry.
 * The property is a map of revisions / values.
 *
 * @param property the property
 * @param revision the revision
 * @param value the value
 */
void setMapEntry(@Nonnull String property, @Nonnull Revision revision, Object value) {
    Operation op = new Operation();
    op.type = Operation.Type.SET_MAP_ENTRY;
    op.value = value;
    changes.put(new Key(property, checkNotNull(revision)), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,147,151,"/**
 * Remove a map entry.
 * The property is a map of revisions / values.
 *
 * @param property the property
 * @param revision the revision
 */
public void removeMapEntry(@Nonnull String property, @Nonnull Revision revision) {
    Operation op = new Operation();
    op.type = Operation.Type.REMOVE_MAP_ENTRY;
    changes.put(new Key(property, checkNotNull(revision)), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,159,164,"/**
 * Set the property to the given value.
 *
 * @param property the property name
 * @param value the value
 */
void set(String property, Object value) {
    Operation op = new Operation();
    op.type = Operation.Type.SET;
    op.value = value;
    changes.put(new Key(property, null), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,184,194,"/**
 * Checks if the named key exists or is absent in the MongoDB document. This
 * method can be used to make a conditional update.
 *
 * @param property the property name
 * @param revision the revision
 */
void containsMapEntry(@Nonnull String property, @Nonnull Revision revision, boolean exists) {
    if (isNew) {
        throw new IllegalStateException(""Cannot use containsMapEntry() on new document"");
    }
    Operation op = new Operation();
    op.type = Operation.Type.CONTAINS_MAP_ENTRY;
    op.value = exists;
    changes.put(new Key(property, checkNotNull(revision)), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,202,207,"/**
 * Increment the value.
 *
 * @param property the key
 * @param value the increment
 */
public void increment(@Nonnull String property, long value) {
    Operation op = new Operation();
    op.type = Operation.Type.INCREMENT;
    op.value = value;
    changes.put(new Key(property, null), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,282,301,"public Operation getReverse() {
    Operation reverse = null;
    switch(type) {
        case INCREMENT:
            reverse = new Operation();
            reverse.type = Type.INCREMENT;
            reverse.value = -(Long) value;
            break;
        case SET:
        case REMOVE_MAP_ENTRY:
        case CONTAINS_MAP_ENTRY:
            // nothing to do
            break;
        case SET_MAP_ENTRY:
            reverse = new Operation();
            reverse.type = Type.REMOVE_MAP_ENTRY;
            break;
    }
    return reverse;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateUtils.java,47,93,"/**
 * Apply the changes to the in-memory document.
 *
 * @param doc
 *            the target document.
 * @param update
 *            the changes to apply.
 * @param comparator
 *            the revision comparator.
 */
public static void applyChanges(@Nonnull Document doc, @Nonnull UpdateOp update, @Nonnull Comparator<Revision> comparator) {
    for (Entry<Key, Operation> e : checkNotNull(update).getChanges().entrySet()) {
        Key k = e.getKey();
        Operation op = e.getValue();
        switch(op.type) {
            case SET:
                {
                    doc.put(k.toString(), op.value);
                    break;
                }
            case INCREMENT:
                {
                    Object old = doc.get(k.toString());
                    Long x = (Long) op.value;
                    if (old == null) {
                        old = 0L;
                    }
                    doc.put(k.toString(), ((Long) old) + x);
                    break;
                }
            case SET_MAP_ENTRY:
                {
                    Object old = doc.get(k.getName());
                    @SuppressWarnings(""unchecked"")
                    Map<Revision, Object> m = (Map<Revision, Object>) old;
                    if (m == null) {
                        m = new TreeMap<Revision, Object>(comparator);
                        doc.put(k.getName(), m);
                    }
                    if (k.getRevision() == null) {
                        throw new IllegalArgumentException(""Cannot set map entry "" + k.getName() + "" with null revision"");
                    }
                    m.put(k.getRevision(), op.value);
                    break;
                }
            case REMOVE_MAP_ENTRY:
                {
                    Object old = doc.get(k.getName());
                    @SuppressWarnings(""unchecked"")
                    Map<Revision, Object> m = (Map<Revision, Object>) old;
                    if (m != null) {
                        m.remove(k.getRevision());
                    }
                    break;
                }
            case CONTAINS_MAP_ENTRY:
                // no effect
                break;
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/mongo/MongoDocumentStore.java,556,626,"@Override
public <T extends Document> boolean create(Collection<T> collection, List<UpdateOp> updateOps) {
    log(""create"", updateOps);
    List<T> docs = new ArrayList<T>();
    DBObject[] inserts = new DBObject[updateOps.size()];
    for (int i = 0; i < updateOps.size(); i++) {
        inserts[i] = new BasicDBObject();
        UpdateOp update = updateOps.get(i);
        T target = collection.newDocument(this);
        UpdateUtils.applyChanges(target, update, comparator);
        docs.add(target);
        for (Entry<Key, Operation> entry : update.getChanges().entrySet()) {
            Key k = entry.getKey();
            Operation op = entry.getValue();
            switch(op.type) {
                case SET:
                case INCREMENT:
                    {
                        inserts[i].put(k.toString(), op.value);
                        break;
                    }
                case SET_MAP_ENTRY:
                    {
                        Revision r = k.getRevision();
                        if (r == null) {
                            throw new IllegalStateException(""SET_MAP_ENTRY must not have null revision"");
                        }
                        DBObject value = new RevisionEntry(r, op.value);
                        inserts[i].put(k.getName(), value);
                        break;
                    }
                case REMOVE_MAP_ENTRY:
                    // nothing to do for new entries
                    break;
                case CONTAINS_MAP_ENTRY:
                    // no effect
                    break;
            }
        }
        if (!inserts[i].containsField(Document.MOD_COUNT)) {
            inserts[i].put(Document.MOD_COUNT, 1L);
            target.put(Document.MOD_COUNT, 1L);
        }
    }
    DBCollection dbCollection = getDBCollection(collection);
    long start = start();
    try {
        try {
            WriteResult writeResult = dbCollection.insert(inserts, WriteConcern.SAFE);
            if (writeResult.getError() != null) {
                return false;
            }
            if (collection == Collection.NODES) {
                for (T doc : docs) {
                    Lock lock = getAndLock(doc.getId());
                    try {
                        addToCache((NodeDocument) doc);
                    } finally {
                        lock.unlock();
                    }
                }
            }
            return true;
        } catch (MongoException e) {
            return false;
        }
    } finally {
        end(""create"", start);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_016df669,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/mongo/MongoDocumentStore.java,965,1014,"/**
 * Creates a MongoDB update object from the given UpdateOp.
 *
 * @param updateOp the update op.
 * @return the DBObject.
 */
@Nonnull
private static DBObject createUpdate(UpdateOp updateOp) {
    BasicDBObject setUpdates = new BasicDBObject();
    BasicDBObject incUpdates = new BasicDBObject();
    BasicDBObject unsetUpdates = new BasicDBObject();
    // always increment modCount
    updateOp.increment(Document.MOD_COUNT, 1);
    // other updates
    for (Entry<Key, Operation> entry : updateOp.getChanges().entrySet()) {
        Key k = entry.getKey();
        if (k.getName().equals(Document.ID)) {
            // avoid exception ""Mod on _id not allowed""
            continue;
        }
        Operation op = entry.getValue();
        switch(op.type) {
            case SET:
                {
                    setUpdates.append(k.toString(), op.value);
                    break;
                }
            case INCREMENT:
                {
                    incUpdates.append(k.toString(), op.value);
                    break;
                }
            case SET_MAP_ENTRY:
                {
                    setUpdates.append(k.toString(), op.value);
                    break;
                }
            case REMOVE_MAP_ENTRY:
                {
                    unsetUpdates.append(k.toString(), ""1"");
                    break;
                }
        }
    }
    BasicDBObject update = new BasicDBObject();
    if (!setUpdates.isEmpty()) {
        update.append(""$set"", setUpdates);
    }
    if (!incUpdates.isEmpty()) {
        update.append(""$inc"", incUpdates);
    }
    if (!unsetUpdates.isEmpty()) {
        update.append(""$unset"", unsetUpdates);
    }
    return update;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1206,1209,"public static void setModified(@Nonnull UpdateOp op, @Nonnull Revision revision) {
    checkNotNull(op).set(MODIFIED_IN_SECS, getModifiedInSecs(checkNotNull(revision).getTimestamp()));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,133,138,"/**
 * Add a new or update an existing map entry.
 * The property is a map of revisions / values.
 *
 * @param property the property
 * @param revision the revision
 * @param value the value
 */
void setMapEntry(@Nonnull String property, @Nonnull Revision revision, String value) {
    Operation op = new Operation();
    op.type = Operation.Type.SET_MAP_ENTRY;
    op.value = value;
    changes.put(new Key(property, checkNotNull(revision)), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,147,151,"/**
 * Remove a map entry.
 * The property is a map of revisions / values.
 *
 * @param property the property
 * @param revision the revision
 */
public void removeMapEntry(@Nonnull String property, @Nonnull Revision revision) {
    Operation op = new Operation();
    op.type = Operation.Type.REMOVE_MAP_ENTRY;
    changes.put(new Key(property, checkNotNull(revision)), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,159,164,"/**
 * Set the property to the given value.
 *
 * @param property the property name
 * @param value the value
 */
void set(String property, Object value) {
    Operation op = new Operation();
    op.type = Operation.Type.SET;
    op.value = value;
    changes.put(new Key(property, null), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,184,194,"/**
 * Checks if the named key exists or is absent in the MongoDB document. This
 * method can be used to make a conditional update.
 *
 * @param property the property name
 * @param revision the revision
 */
void containsMapEntry(@Nonnull String property, @Nonnull Revision revision, boolean exists) {
    if (isNew) {
        throw new IllegalStateException(""Cannot use containsMapEntry() on new document"");
    }
    Operation op = new Operation();
    op.type = Operation.Type.CONTAINS_MAP_ENTRY;
    op.value = exists;
    changes.put(new Key(property, checkNotNull(revision)), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,202,207,"/**
 * Increment the value.
 *
 * @param property the key
 * @param value the increment
 */
public void increment(@Nonnull String property, long value) {
    Operation op = new Operation();
    op.type = Operation.Type.INCREMENT;
    op.value = value;
    changes.put(new Key(property, null), op);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,282,301,"public Operation getReverse() {
    Operation reverse = null;
    switch(type) {
        case INCREMENT:
            reverse = new Operation();
            reverse.type = Type.INCREMENT;
            reverse.value = -(Long) value;
            break;
        case SET:
        case REMOVE_MAP_ENTRY:
        case CONTAINS_MAP_ENTRY:
            // nothing to do
            break;
        case SET_MAP_ENTRY:
            reverse = new Operation();
            reverse.type = Type.REMOVE_MAP_ENTRY;
            break;
    }
    return reverse;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateUtils.java,47,93,"/**
 * Apply the changes to the in-memory document.
 *
 * @param doc
 *            the target document.
 * @param update
 *            the changes to apply.
 * @param comparator
 *            the revision comparator.
 */
public static void applyChanges(@Nonnull Document doc, @Nonnull UpdateOp update, @Nonnull Comparator<Revision> comparator) {
    for (Entry<Key, Operation> e : checkNotNull(update).getChanges().entrySet()) {
        Key k = e.getKey();
        Operation op = e.getValue();
        switch(op.type) {
            case SET:
                {
                    doc.put(k.toString(), op.value);
                    break;
                }
            case INCREMENT:
                {
                    Object old = doc.get(k.toString());
                    Long x = (Long) op.value;
                    if (old == null) {
                        old = 0L;
                    }
                    doc.put(k.toString(), ((Long) old) + x);
                    break;
                }
            case SET_MAP_ENTRY:
                {
                    Object old = doc.get(k.getName());
                    @SuppressWarnings(""unchecked"")
                    Map<Revision, Object> m = (Map<Revision, Object>) old;
                    if (m == null) {
                        m = new TreeMap<Revision, Object>(comparator);
                        doc.put(k.getName(), m);
                    }
                    if (k.getRevision() == null) {
                        throw new IllegalArgumentException(""Cannot set map entry "" + k.getName() + "" with null revision"");
                    }
                    m.put(k.getRevision(), op.value);
                    break;
                }
            case REMOVE_MAP_ENTRY:
                {
                    Object old = doc.get(k.getName());
                    @SuppressWarnings(""unchecked"")
                    Map<Revision, Object> m = (Map<Revision, Object>) old;
                    if (m != null) {
                        m.remove(k.getRevision());
                    }
                    break;
                }
            case CONTAINS_MAP_ENTRY:
                // no effect
                break;
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/mongo/MongoDocumentStore.java,556,626,"@Override
public <T extends Document> boolean create(Collection<T> collection, List<UpdateOp> updateOps) {
    log(""create"", updateOps);
    List<T> docs = new ArrayList<T>();
    DBObject[] inserts = new DBObject[updateOps.size()];
    for (int i = 0; i < updateOps.size(); i++) {
        inserts[i] = new BasicDBObject();
        UpdateOp update = updateOps.get(i);
        T target = collection.newDocument(this);
        UpdateUtils.applyChanges(target, update, comparator);
        docs.add(target);
        for (Entry<Key, Operation> entry : update.getChanges().entrySet()) {
            Key k = entry.getKey();
            Operation op = entry.getValue();
            switch(op.type) {
                case SET:
                case INCREMENT:
                    {
                        inserts[i].put(k.toString(), op.value);
                        break;
                    }
                case SET_MAP_ENTRY:
                    {
                        Revision r = k.getRevision();
                        if (r == null) {
                            throw new IllegalStateException(""SET_MAP_ENTRY must not have null revision"");
                        }
                        DBObject value = new RevisionEntry(r, op.value);
                        inserts[i].put(k.getName(), value);
                        break;
                    }
                case REMOVE_MAP_ENTRY:
                    // nothing to do for new entries
                    break;
                case CONTAINS_MAP_ENTRY:
                    // no effect
                    break;
            }
        }
        if (!inserts[i].containsField(Document.MOD_COUNT)) {
            inserts[i].put(Document.MOD_COUNT, 1L);
            target.put(Document.MOD_COUNT, 1L);
        }
    }
    DBCollection dbCollection = getDBCollection(collection);
    long start = start();
    try {
        try {
            WriteResult writeResult = dbCollection.insert(inserts, WriteConcern.SAFE);
            if (writeResult.getError() != null) {
                return false;
            }
            if (collection == Collection.NODES) {
                for (T doc : docs) {
                    Lock lock = getAndLock(doc.getId());
                    try {
                        addToCache((NodeDocument) doc);
                    } finally {
                        lock.unlock();
                    }
                }
            }
            return true;
        } catch (MongoException e) {
            return false;
        }
    } finally {
        end(""create"", start);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1822_3e83a4c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/mongo/MongoDocumentStore.java,965,1014,"/**
 * Creates a MongoDB update object from the given UpdateOp.
 *
 * @param updateOp the update op.
 * @return the DBObject.
 */
@Nonnull
private static DBObject createUpdate(UpdateOp updateOp) {
    BasicDBObject setUpdates = new BasicDBObject();
    BasicDBObject incUpdates = new BasicDBObject();
    BasicDBObject unsetUpdates = new BasicDBObject();
    // always increment modCount
    updateOp.increment(Document.MOD_COUNT, 1);
    // other updates
    for (Entry<Key, Operation> entry : updateOp.getChanges().entrySet()) {
        Key k = entry.getKey();
        if (k.getName().equals(Document.ID)) {
            // avoid exception ""Mod on _id not allowed""
            continue;
        }
        Operation op = entry.getValue();
        switch(op.type) {
            case SET:
                {
                    setUpdates.append(k.toString(), op.value);
                    break;
                }
            case INCREMENT:
                {
                    incUpdates.append(k.toString(), op.value);
                    break;
                }
            case SET_MAP_ENTRY:
                {
                    setUpdates.append(k.toString(), op.value);
                    break;
                }
            case REMOVE_MAP_ENTRY:
                {
                    unsetUpdates.append(k.toString(), ""1"");
                    break;
                }
        }
    }
    BasicDBObject update = new BasicDBObject();
    if (!setUpdates.isEmpty()) {
        update.append(""$set"", setUpdates);
    }
    if (!incUpdates.isEmpty()) {
        update.append(""$inc"", incUpdates);
    }
    if (!unsetUpdates.isEmpty()) {
        update.append(""$unset"", unsetUpdates);
    }
    return update;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1829_ca36450e,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/LowerCaseImpl.java,67,78,"@Override
public PropertyValue currentProperty() {
    PropertyValue p = operand.currentProperty();
    if (p == null) {
        return null;
    }
    // TODO what is the expected result of LOWER(x) for an array property?
    // currently throws an exception
    String value = p.getValue(STRING);
    // TODO toLowerCase(): document the Turkish locale problem
    return PropertyValues.newString(value.toLowerCase());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1848_093b9128,Major,oak-auth-external/src/main/java/org/apache/jackrabbit/oak/spi/security/authentication/external/impl/DefaultSyncHandler.java,639,660,"/**
 * Syncs the properties specified in the {@code mapping} from the external identity to the given authorizable.
 * Note that this method does not check for value equality and just blindly copies or deletes the properties.
 *
 * @param ext external identity
 * @param auth the authorizable
 * @param mapping the property mapping
 * @throws RepositoryException if an error occurs
 */
private void syncProperties(ExternalIdentity ext, Authorizable auth, Map<String, String> mapping) throws RepositoryException {
    Map<String, ?> properties = ext.getProperties();
    for (Map.Entry<String, String> entry : mapping.entrySet()) {
        String relPath = entry.getKey();
        String name = entry.getValue();
        Object obj = properties.get(name);
        if (obj == null) {
            auth.removeProperty(relPath);
        } else {
            if (obj instanceof Collection) {
                auth.setProperty(relPath, createValues((Collection) obj));
            } else if (obj instanceof byte[] || obj instanceof char[]) {
                auth.setProperty(relPath, createValue(obj));
            } else if (obj instanceof Object[]) {
                auth.setProperty(relPath, createValues(Arrays.asList((Object[]) obj)));
            } else {
                auth.setProperty(relPath, createValue(obj));
            }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-185_7fe28a0e,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,261,278,"/**
 * @see Node#setProperty(String, javax.jcr.Value, int)
 */
@Override
@Nonnull
public Property setProperty(String jcrName, Value value, int type) throws RepositoryException {
    checkStatus();
    int targetType = getTargetType(value, type);
    Value targetValue = ValueHelper.convert(value, targetType, getValueFactory());
    if (value == null) {
        Property p = getProperty(jcrName);
        p.remove();
        return p;
    } else {
        String oakName = sessionDelegate.getOakPathOrThrow(jcrName);
        CoreValue oakValue = ValueConverter.toCoreValue(targetValue, sessionDelegate);
        return new PropertyImpl(dlg.setProperty(oakName, oakValue));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1874_3ae276c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/IndexUpdate.java,108,123,"@Override
public void enter(NodeState before, NodeState after) throws CommitFailedException {
    collectIndexEditors(builder.getChildNode(INDEX_DEFINITIONS_NAME));
    // no-op when reindex is empty
    CommitFailedException exception = EditorDiff.process(CompositeEditor.compose(reindex.values()), MISSING_NODE, after);
    if (exception != null) {
        throw exception;
    }
    for (Editor editor : editors) {
        editor.enter(before, after);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1874_3ae276c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/IndexUpdate.java,125,155,"private void collectIndexEditors(NodeBuilder definitions) throws CommitFailedException {
    for (String name : definitions.getChildNodeNames()) {
        NodeBuilder definition = definitions.getChildNode(name);
        if (Objects.equal(async, definition.getString(ASYNC_PROPERTY_NAME))) {
            String type = definition.getString(TYPE_PROPERTY_NAME);
            Editor editor = provider.getIndexEditor(type, definition, root, updateCallback);
            if (editor == null) {
                // trigger reindexing when an indexer becomes available
                definition.setProperty(REINDEX_PROPERTY_NAME, true);
            } else if (definition.getBoolean(REINDEX_PROPERTY_NAME)) {
                if (definition.getBoolean(REINDEX_ASYNC_PROPERTY_NAME) && definition.getString(ASYNC_PROPERTY_NAME) == null) {
                    // switch index to an async update mode
                    definition.setProperty(ASYNC_PROPERTY_NAME, ASYNC_REINDEX_VALUE);
                } else {
                    definition.setProperty(REINDEX_PROPERTY_NAME, false);
                    // beforehand, we'll remove all child nodes
                    for (String rm : definition.getChildNodeNames()) {
                        definition.getChildNode(rm).remove();
                    }
                    reindex.put(concat(getPath(), INDEX_DEFINITIONS_NAME, name), wrap(editor));
                }
            } else {
                editors.add(wrap(editor));
            }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1877_716e1237,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,130,136,"@Override
public void indexUpdate() throws CommitFailedException {
    if (!dirty) {
        dirty = true;
        preAsyncRun(store, name);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1877_716e1237,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,140,258,"@Override
public synchronized void run() {
    log.debug(""Running background index task {}"", name);
    if (isAlreadyRunning(store, name)) {
        log.debug(""The {} indexer is already running; skipping this update"", name);
        return;
    }
    NodeState before;
    NodeState root = store.getRoot();
    String refCheckpoint = root.getChildNode(ASYNC).getString(name);
    if (refCheckpoint != null) {
        NodeState state = store.retrieve(refCheckpoint);
        if (state == null) {
            log.warn(""Failed to retrieve previously indexed checkpoint {};"" + "" rerunning the initial {} index update"", refCheckpoint, name);
            before = MISSING_NODE;
        } else if (noVisibleChanges(state, root)) {
            log.debug(""No changes since last checkpoint;"" + "" skipping the {} index update"", name);
            return;
        } else {
            before = state;
        }
    } else {
        log.info(""Initial {} index update"", name);
        before = MISSING_NODE;
    }
    String checkpoint = store.checkpoint(lifetime);
    NodeState after = store.retrieve(checkpoint);
    if (after == null) {
        log.warn(""Unable to retrieve newly created checkpoint {},"" + "" skipping the {} index update"", checkpoint, name);
        return;
    }
    NodeBuilder builder = store.getRoot().builder();
    NodeBuilder async = builder.child(ASYNC);
    AsyncUpdateCallback callback = new AsyncUpdateCallback();
    preAsyncRunStatsStats(indexStats);
    IndexUpdate indexUpdate = new IndexUpdate(provider, name, after, builder, callback);
    CommitFailedException exception = EditorDiff.process(indexUpdate, before, after);
    if (exception == null) {
        if (callback.dirty) {
            async.setProperty(name, checkpoint);
            try {
                store.merge(builder, newCommitHook(name, refCheckpoint), CommitInfo.EMPTY);
            } catch (CommitFailedException e) {
                if (e != CONCURRENT_UPDATE) {
                    exception = e;
                }
            }
            if (switchOnSync) {
                reindexedDefinitions.addAll(indexUpdate.getReindexedDefinitions());
            }
        } else if (switchOnSync) {
            log.debug(""No changes detected after diff, will try to switch to synchronous updates on "" + reindexedDefinitions);
            async.setProperty(name, checkpoint);
            // no changes after diff, switch to sync on the async defs
            for (String path : reindexedDefinitions) {
                NodeBuilder c = builder;
                for (String p : elements(path)) {
                    c = c.getChildNode(p);
                }
                if (c.exists() && !c.getBoolean(REINDEX_PROPERTY_NAME)) {
                    c.removeProperty(ASYNC_PROPERTY_NAME);
                }
            }
            try {
                store.merge(builder, newCommitHook(name, refCheckpoint), CommitInfo.EMPTY);
                reindexedDefinitions.clear();
            } catch (CommitFailedException e) {
                if (e != CONCURRENT_UPDATE) {
                    exception = e;
                }
            }
        }
    }
    postAsyncRunStatsStatus(indexStats);
    // checkpoints cleanup
    if (exception != null || (exception == null && !callback.dirty)) {
        log.debug(""The {} index update failed; releasing the related checkpoint {}"", name, checkpoint);
        store.release(checkpoint);
    } else {
        if (refCheckpoint != null) {
            log.debug(""The {} index update succeeded; releasing the previous checkpoint {}"", name, refCheckpoint);
            store.release(refCheckpoint);
        }
    }
    if (exception != null) {
        if (!failing) {
            log.warn(""Index update {} failed"", name, exception);
        }
        failing = true;
    } else {
        if (failing) {
            log.info(""Index update {} no longer fails"", name);
        }
        failing = false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1877_716e1237,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,260,281,"private static CommitHook newCommitHook(final String name, final String checkpoint) {
    return new CompositeHook(new ConflictHook(new AnnotatingConflictHandler()), new EditorHook(new ConflictValidatorProvider()), new CommitHook() {

        @Override
        @Nonnull
        public NodeState processCommit(NodeState before, NodeState after, CommitInfo info) throws CommitFailedException {
            // check for concurrent updates by this async task
            String checkpointAfterRebase = before.getChildNode(ASYNC).getString(name);
            if (Objects.equal(checkpoint, checkpointAfterRebase)) {
                return postAsyncRunNodeStatus(after.builder(), name).getNodeState();
            } else {
                throw CONCURRENT_UPDATE;
            }
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1877_716e1237,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,266,279,"@Override
@Nonnull
public NodeState processCommit(NodeState before, NodeState after, CommitInfo info) throws CommitFailedException {
    // check for concurrent updates by this async task
    String checkpointAfterRebase = before.getChildNode(ASYNC).getString(name);
    if (Objects.equal(checkpoint, checkpointAfterRebase)) {
        return postAsyncRunNodeStatus(after.builder(), name).getNodeState();
    } else {
        throw CONCURRENT_UPDATE;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1877_716e1237,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,283,287,"private static void preAsyncRun(NodeStore store, String name) throws CommitFailedException {
    NodeBuilder builder = store.getRoot().builder();
    preAsyncRunNodeStatus(builder, name);
    store.merge(builder, EmptyHook.INSTANCE, CommitInfo.EMPTY);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1877_716e1237,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,289,315,"private static boolean isAlreadyRunning(NodeStore store, String name) {
    NodeState indexState = store.getRoot().getChildNode(INDEX_DEFINITIONS_NAME);
    // Probably the first run
    if (!indexState.exists()) {
        return false;
    }
    // Check if already running or timed out
    if (STATUS_RUNNING.equals(indexState.getString(name + ""-status""))) {
        PropertyState startTime = indexState.getProperty(name + ""-start"");
        Calendar start = Conversions.convert(startTime.getValue(Type.DATE)).toCalendar();
        Calendar now = Calendar.getInstance();
        long delta = now.getTimeInMillis() - start.getTimeInMillis();
        // Check if the job has timed out and we need to take over
        if (TimeUnit.MILLISECONDS.toMinutes(delta) > ASYNC_TIMEOUT) {
            log.info(""Async job found which stated on {} has timed out in {} minutes. "" + ""This node would take over the job."", startTime.getValue(Type.DATE), ASYNC_TIMEOUT);
            return false;
        }
        return true;
    }
    return false;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1877_716e1237,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,317,323,"private static void preAsyncRunNodeStatus(NodeBuilder builder, String name) {
    String now = now();
    builder.getChildNode(INDEX_DEFINITIONS_NAME).setProperty(name + ""-status"", STATUS_RUNNING).setProperty(name + ""-start"", now, Type.DATE).removeProperty(name + ""-done"");
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1877_716e1237,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,329,337,"private static NodeBuilder postAsyncRunNodeStatus(NodeBuilder builder, String name) {
    String now = now();
    builder.getChildNode(INDEX_DEFINITIONS_NAME).setProperty(name + ""-status"", STATUS_DONE).setProperty(name + ""-done"", now, Type.DATE).removeProperty(name + ""-start"");
    return builder;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1883_9c2421ed,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/MissingLastRevSeeker.java,94,98,"public void releaseRecoveryLock(int clusterId) {
    UpdateOp update = new UpdateOp(Integer.toString(clusterId), true);
    update.set(ClusterNodeInfo.REV_RECOVERY_LOCK, null);
    store.createOrUpdate(Collection.CLUSTER_NODES, update);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1894_35562cce,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/PropertyIndex.java,133,168,"@Override
public double getCost(Filter filter, NodeState root) {
    if (filter.getFullTextConstraint() != null) {
        // not an appropriate index for full-text search
        return Double.POSITIVE_INFINITY;
    }
    if (filter.containsNativeConstraint()) {
        // not an appropriate index for native search
        return Double.POSITIVE_INFINITY;
    }
    PropertyIndexLookup lookup = getLookup(root);
    for (PropertyRestriction pr : filter.getPropertyRestrictions()) {
        String propertyName = PathUtils.getName(pr.propertyName);
        // currently, only indexes on the root node are supported
        if (lookup.isIndexed(propertyName, ""/"", filter)) {
            if (pr.firstIncluding && pr.lastIncluding && pr.first != null && pr.first.equals(pr.last)) {
                // ""[property] = $value""
                return lookup.getCost(filter, propertyName, pr.first);
            } else if (pr.list != null) {
                double cost = 0;
                for (PropertyValue p : pr.list) {
                    cost += lookup.getCost(filter, propertyName, p);
                }
                return cost;
            } else {
                // processed as ""[property] is not null""
                return lookup.getCost(filter, propertyName, null);
            }
        }
    }
    // not an appropriate index
    return Double.POSITIVE_INFINITY;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1894_35562cce,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/PropertyIndex.java,170,213,"@Override
public Cursor query(Filter filter, NodeState root) {
    Iterable<String> paths = null;
    PropertyIndexLookup lookup = getLookup(root);
    int depth = 1;
    for (PropertyRestriction pr : filter.getPropertyRestrictions()) {
        String propertyName = PathUtils.getName(pr.propertyName);
        depth = PathUtils.getDepth(pr.propertyName);
        // currently, only indexes on the root node are supported
        if (lookup.isIndexed(propertyName, ""/"", filter)) {
            // equality
            if (pr.firstIncluding && pr.lastIncluding && pr.first != null && pr.first.equals(pr.last)) {
                // ""[property] = $value""
                paths = lookup.query(filter, propertyName, pr.first);
                break;
            } else if (pr.list != null) {
                for (PropertyValue pv : pr.list) {
                    Iterable<String> p = lookup.query(filter, propertyName, pv);
                    if (paths == null) {
                        paths = p;
                    } else {
                        paths = Iterables.concat(paths, p);
                    }
                }
                break;
            } else {
                // processed as ""[property] is not null""
                paths = lookup.query(filter, propertyName, null);
                break;
            }
        }
    }
    if (paths == null) {
        throw new IllegalStateException(""Property index is used even when no index is available for filter "" + filter);
    }
    Cursor c = Cursors.newPathCursor(paths, filter.getQueryEngineSettings());
    if (depth > 1) {
        c = Cursors.newAncestorCursor(c, depth - 1, filter.getQueryEngineSettings());
    }
    return c;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1894_35562cce,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/PropertyIndex.java,215,252,"@Override
public String getPlan(Filter filter, NodeState root) {
    StringBuilder buff = new StringBuilder(""property"");
    StringBuilder notIndexed = new StringBuilder();
    PropertyIndexLookup lookup = getLookup(root);
    for (PropertyRestriction pr : filter.getPropertyRestrictions()) {
        String propertyName = PathUtils.getName(pr.propertyName);
        // currently, only indexes on the root node are supported
        if (lookup.isIndexed(propertyName, ""/"", filter)) {
            if (pr.firstIncluding && pr.lastIncluding && pr.first != null && pr.first.equals(pr.last)) {
                buff.append(' ').append(propertyName).append('=').append(pr.first);
            } else {
                buff.append(' ').append(propertyName);
            }
        } else if (pr.list != null) {
            buff.append(' ').append(propertyName).append("" IN("");
            int i = 0;
            for (PropertyValue pv : pr.list) {
                if (i++ > 0) {
                    buff.append("", "");
                }
                buff.append(pv);
            }
            buff.append(')');
        } else {
            notIndexed.append(' ').append(propertyName);
            if (!pr.toString().isEmpty()) {
                notIndexed.append(':').append(pr);
            }
        }
    }
    if (notIndexed.length() > 0) {
        buff.append("" ("").append(notIndexed.toString().trim()).append("")"");
    }
    return buff.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1899_b6f89048,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,1020,1028,"/**
 * return the 'next' value at the provided position
 *
 * @param nodeState the node state to inspect
 * @return the next value
 */
static String getPropertyNext(@Nonnull final NodeState state, final int lane) {
    String next = """";
    PropertyState ps = state.getProperty(NEXT);
    if (ps != null) {
        next = (lane < OrderedIndex.LANES) ? ps.getValue(Type.STRING, lane) : """";
    }
    return next;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1899_df59fb45,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,150,183,"@Override
void prune(final NodeBuilder index, final Deque<NodeBuilder> builders, final String key) {
    for (NodeBuilder node : builders) {
        if (node.hasProperty(""match"") || node.getChildNodeCount(1) > 0) {
            return;
        } else if (node.exists()) {
            if (node.hasProperty(NEXT)) {
                ChildNodeEntry[] walkedLanes = new ChildNodeEntry[OrderedIndex.LANES];
                ChildNodeEntry entry;
                String lane0Next, prevNext, currNext;
                // to keep searching and update
                do {
                    entry = seek(index.getNodeState(), new PredicateEquals(key), walkedLanes);
                    lane0Next = getPropertyNext(walkedLanes[0]);
                    for (int lane = walkedLanes.length - 1; lane >= 0; lane--) {
                        prevNext = getPropertyNext(walkedLanes[lane], lane);
                        if (key.equals(prevNext)) {
                            // if it's actually pointing to us let's deal with it
                            currNext = getPropertyNext(node, lane);
                            setPropertyNext(index.getChildNode(walkedLanes[lane].getName()), currNext, lane);
                        }
                    }
                } while (entry != null && !key.equals(lane0Next));
            }
            node.remove();
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1899_df59fb45,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,995,1005,"/**
 * set the value of the :next at the given position. If the property :next won't be there by the
 * time this method is invoked it won't perform any action
 *
 * @param node
 * @param value
 * @param lane
 */
static void setPropertyNext(@Nonnull final NodeBuilder node, final String value, final int lane) {
    if (node != null && value != null && lane >= 0 && lane < OrderedIndex.LANES) {
        PropertyState next = node.getProperty(NEXT);
        if (next != null) {
            String[] values = Iterables.toArray(next.getValue(Type.STRINGS), String.class);
            values[lane] = value;
            setPropertyNext(node, values);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1916_705ce1d1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeState.java,115,138,"@Override
@CheckForNull
public PropertyState getProperty(String name) {
    checkNotNull(name);
    Template template = getTemplate();
    if (JCR_PRIMARYTYPE.equals(name)) {
        return template.getPrimaryType();
    } else if (JCR_MIXINTYPES.equals(name)) {
        return template.getMixinTypes();
    }
    PropertyTemplate propertyTemplate = template.getPropertyTemplate(name);
    if (propertyTemplate != null) {
        Segment segment = getSegment();
        int ids = 1 + propertyTemplate.getIndex();
        if (template.getChildName() != Template.ZERO_CHILD_NODES) {
            ids++;
        }
        return new SegmentPropertyState(segment.readRecordId(getOffset(0, ids)), propertyTemplate);
    } else {
        return null;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1926_9225a3e2,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,567,583,"/**
 * Gets a sorted map of uncommitted revisions of this document with the
 * local cluster node id as returned by the {@link RevisionContext}. These
 * are the {@link #REVISIONS} entries where {@link Utils#isCommitted(String)}
 * returns false.
 *
 * @param context the revision context.
 * @return the uncommitted revisions of this document.
 */
public SortedMap<Revision, Revision> getUncommittedRevisions(RevisionContext context) {
    // only look at revisions in this document.
    // uncommitted revisions are not split off
    Map<Revision, String> valueMap = getLocalRevisions();
    SortedMap<Revision, Revision> revisions = new TreeMap<Revision, Revision>(context.getRevisionComparator());
    for (Map.Entry<Revision, String> commit : valueMap.entrySet()) {
        if (!Utils.isCommitted(commit.getValue())) {
            Revision r = commit.getKey();
            if (r.getClusterId() == context.getClusterId()) {
                Revision b = Revision.fromString(commit.getValue());
                revisions.put(r, b);
            }
        }
    }
    return revisions;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1926_9225a3e2,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UnmergedBranches.java,67,87,"/**
 * Initialize with un-merged branches from <code>store</code> for this
 * <code>clusterId</code>.
 *
 * @param store the document store.
 * @param context the revision context.
 */
void init(DocumentStore store, RevisionContext context) {
    if (!initialized.compareAndSet(false, true)) {
        throw new IllegalStateException(""already initialized"");
    }
    NodeDocument doc = store.find(Collection.NODES, Utils.getIdFromPath(""/""));
    if (doc == null) {
        return;
    }
    SortedMap<Revision, Revision> revisions = doc.getUncommittedRevisions(context);
    while (!revisions.isEmpty()) {
        SortedSet<Revision> commits = new TreeSet<Revision>(comparator);
        Revision head = revisions.lastKey();
        commits.add(head);
        Revision base = revisions.remove(head).asTrunkRevision();
        while (revisions.containsKey(base)) {
            commits.add(base);
            base = revisions.remove(base).asTrunkRevision();
        }
        branches.add(new Branch(commits, base));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1932_913c2f53,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentWriter.java,943,1049,"public SegmentNodeState writeNode(NodeState state) {
    if (state instanceof SegmentNodeState && store.containsSegment(((SegmentNodeState) state).getRecordId().getSegmentId())) {
        return (SegmentNodeState) state;
    }
    SegmentNodeState before = null;
    Template beforeTemplate = null;
    ModifiedNodeState after = null;
    if (state instanceof ModifiedNodeState) {
        after = (ModifiedNodeState) state;
        NodeState base = after.getBaseState();
        if (base instanceof SegmentNodeState && store.containsSegment(((SegmentNodeState) base).getRecordId().getSegmentId())) {
            before = (SegmentNodeState) base;
            beforeTemplate = before.getTemplate();
        }
    }
    Template template = new Template(state);
    RecordId templateId;
    if (before != null && template.equals(beforeTemplate)) {
        templateId = before.getTemplateId();
    } else {
        templateId = writeTemplate(template);
    }
    List<RecordId> ids = Lists.newArrayList();
    ids.add(templateId);
    String childName = template.getChildName();
    if (childName == Template.MANY_CHILD_NODES) {
        MapRecord base;
        final Map<String, RecordId> childNodes = Maps.newHashMap();
        if (before != null && before.getChildNodeCount(2) > 1 && after.getChildNodeCount(2) > 1) {
            base = before.getChildNodeMap();
            after.compareAgainstBaseState(before, new DefaultNodeStateDiff() {

                @Override
                public boolean childNodeAdded(String name, NodeState after) {
                    childNodes.put(name, writeNode(after).getRecordId());
                    return true;
                }

                @Override
                public boolean childNodeChanged(String name, NodeState before, NodeState after) {
                    childNodes.put(name, writeNode(after).getRecordId());
                    return true;
                }

                @Override
                public boolean childNodeDeleted(String name, NodeState before) {
                    childNodes.put(name, null);
                    return true;
                }
            });
        } else {
            base = null;
            for (ChildNodeEntry entry : state.getChildNodeEntries()) {
                childNodes.put(entry.getName(), writeNode(entry.getNodeState()).getRecordId());
            }
        }
        ids.add(writeMap(base, childNodes).getRecordId());
    } else if (childName != Template.ZERO_CHILD_NODES) {
        ids.add(writeNode(state.getChildNode(template.getChildName())).getRecordId());
    }
    for (PropertyTemplate pt : template.getPropertyTemplates()) {
        String name = pt.getName();
        PropertyState property = state.getProperty(name);
        if (property instanceof SegmentPropertyState && store.containsSegment(((SegmentPropertyState) property).getRecordId().getSegmentId())) {
            ids.add(((SegmentPropertyState) property).getRecordId());
        } else if (!(before instanceof SegmentNodeState) || store.containsSegment(((SegmentNodeState) before).getRecordId().getSegmentId())) {
            ids.add(writeProperty(property));
        } else {
            // reuse previously stored property, if possible
            PropertyTemplate bt = beforeTemplate.getPropertyTemplate(name);
            if (bt == null) {
                // new property
                ids.add(writeProperty(property));
            } else {
                SegmentPropertyState bp = beforeTemplate.getProperty(before.getRecordId(), bt.getIndex());
                if (property.equals(bp)) {
                    // no changes
                    ids.add(bp.getRecordId());
                } else if (bp.isArray() && bp.getType() != BINARIES) {
                    // reuse entries from the previous list
                    ids.add(writeProperty(property, bp.getValueRecords()));
                } else {
                    ids.add(writeProperty(property));
                }
            }
        }
    }
    synchronized (this) {
        RecordId recordId = prepare(RecordType.NODE, 0, ids);
        for (RecordId id : ids) {
            writeRecordId(id);
        }
        return new SegmentNodeState(recordId);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1932_913c2f53,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/file/FileStore.java,409,431,"public void compact() {
    long start = System.nanoTime();
    log.info(""TarMK compaction started"");
    SegmentWriter writer = new SegmentWriter(this, tracker);
    Compactor compactor = new Compactor(writer);
    SegmentNodeState before = getHead();
    SegmentNodeState after = compactor.compact(EMPTY_NODE, before);
    while (!setHead(before, after)) {
        // Some other concurrent changes have been made.
        // Rebase (and compact) those changes on top of the
        // compacted state before retrying to set the head.
        SegmentNodeState head = getHead();
        after = compactor.compact(before, head);
        before = head;
    }
    tracker.setCompactionMap(compactor.getCompactionMap());
    log.info(""TarMK compaction completed in {}ms"", MILLISECONDS.convert(System.nanoTime() - start, NANOSECONDS));
    cleanupNeeded.set(true);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1932_c215b267,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/Compactor.java,82,85,"public SegmentNodeState compact(NodeState before, NodeState after) {
    after.compareAgainstBaseState(before, new CompactDiff(builder));
    return builder.getNodeState();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1933_2e16a983,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/AndImpl.java,99,119,"@Override
public Map<DynamicOperandImpl, Set<StaticOperandImpl>> getInMap() {
    Map<DynamicOperandImpl, Set<StaticOperandImpl>> m1 = constraint1.getInMap();
    Map<DynamicOperandImpl, Set<StaticOperandImpl>> m2 = constraint2.getInMap();
    if (m1.isEmpty()) {
        return m2;
    } else if (m2.isEmpty()) {
        return m1;
    }
    Map<DynamicOperandImpl, Set<StaticOperandImpl>> result = Maps.newHashMap();
    result.putAll(m1);
    for (Entry<DynamicOperandImpl, Set<StaticOperandImpl>> e2 : m2.entrySet()) {
        Set<StaticOperandImpl> s = result.get(e2.getKey());
        if (s != null) {
            s.retainAll(e2.getValue());
        } else {
            result.put(e2.getKey(), e2.getValue());
        }
    }
    return result;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1933_2e16a983,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/query/QueryIndex.java,202,202,"/**
 * The estimated number of entries. This value does not have to be
 * accurate.
 *
 * @return the estimated number of entries
 */
long getEstimatedEntryCount();"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1959_93c1aa40,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,311,334,"private void mergeWithConcurrencyCheck(NodeBuilder builder, final String checkpoint, final long lease) throws CommitFailedException {
    CommitHook concurrentUpdateCheck = new CommitHook() {

        @Override
        @Nonnull
        public NodeState processCommit(NodeState before, NodeState after, CommitInfo info) throws CommitFailedException {
            // check for concurrent updates by this async task
            NodeState async = before.getChildNode(ASYNC);
            if (Objects.equal(checkpoint, async.getString(name)) && lease == async.getLong(name + ""-lease"")) {
                return after;
            } else {
                throw CONCURRENT_UPDATE;
            }
        }
    };
    CompositeHook hooks = new CompositeHook(new ConflictHook(new AnnotatingConflictHandler()), new EditorHook(new ConflictValidatorProvider()), concurrentUpdateCheck);
    store.merge(builder, hooks, CommitInfo.EMPTY);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1959_93c1aa40,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,315,327,"@Override
@Nonnull
public NodeState processCommit(NodeState before, NodeState after, CommitInfo info) throws CommitFailedException {
    // check for concurrent updates by this async task
    NodeState async = before.getChildNode(ASYNC);
    if (Objects.equal(checkpoint, async.getString(name)) && lease == async.getLong(name + ""-lease"")) {
        return after;
    } else {
        throw CONCURRENT_UPDATE;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java,47,49,"public String getIndexName() {
    return TYPE;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java,60,62,"/**
 * retrieve the cost for the query.
 *
 * !!! for now we want to skip the use-case of NON range-queries !!!
 */
public double getCost(Filter filter, NodeState root) {
    throw new UnsupportedOperationException(""Not supported as implementing AdvancedQueryIndex"");
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java,176,217,"@Override
public Cursor query(IndexPlan plan, NodeState root) {
    LOG.debug(""query(IndexPlan, NodeState)"");
    LOG.debug(""query() - plan: {}"", plan);
    LOG.debug(""query() - rootState: {}"", root);
    Filter filter = plan.getFilter();
    List<OrderEntry> sortOrder = plan.getSortOrder();
    Iterable<String> paths = null;
    OrderedContentMirrorStoreStrategy strategy = OrderedPropertyIndexLookup.getStrategy(plan.getDefinition());
    int depth = 1;
    PropertyRestriction pr = plan.getPropertyRestriction();
    if (pr != null) {
        String propertyName = PathUtils.getName(pr.propertyName);
        depth = PathUtils.getDepth(propertyName);
        paths = strategy.query(plan.getFilter(), propertyName, plan.getDefinition(), pr);
    }
    if (paths == null && sortOrder != null && !sortOrder.isEmpty()) {
        // we could be here if we have a query where the ORDER BY makes us play it.
        for (OrderEntry oe : sortOrder) {
            String propertyName = PathUtils.getName(oe.getPropertyName());
            depth = PathUtils.getDepth(oe.getPropertyName());
            paths = strategy.query(plan.getFilter(), propertyName, plan.getDefinition(), new PropertyRestriction());
        }
    }
    if (paths == null) {
        // if still here then something went wrong.
        throw new IllegalStateException(""OrderedPropertyIndex index is used even when no index is available for filter "" + filter);
    }
    Cursor cursor = Cursors.newPathCursor(paths, filter.getQueryEngineSettings());
    cursor = Cursors.newPrefixCursor(cursor, plan.getPathPrefix());
    if (depth > 1) {
        cursor = Cursors.newAncestorCursor(cursor, depth - 1, filter.getQueryEngineSettings());
    }
    return cursor;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndexLookup.java,201,207,"/**
 * query the strategy for the provided constrains
 *
 * @param filter
 * @param propertyName
 * @param pr
 * @return the result set
 */
public Iterable<String> query(Filter filter, String propertyName, PropertyRestriction pr) {
    NodeState indexMeta = getIndexNode(root, propertyName, filter);
    if (indexMeta == null) {
        throw new IllegalArgumentException(""No index for "" + propertyName);
    }
    return getStrategy(indexMeta).query(filter, propertyName, indexMeta, pr);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/PropertyIndexLookup.java,126,133,"public double getCost(Filter filter, String propertyName, PropertyValue value) {
    NodeState indexMeta = getIndexNode(root, propertyName, filter);
    if (indexMeta == null) {
        return Double.POSITIVE_INFINITY;
    }
    return COST_OVERHEAD + getStrategy(indexMeta).count(indexMeta, encode(value), MAX_COST);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/PropertyIndexPlan.java,211,229,"private Set<String> getValues(PropertyRestriction restriction) {
    if (restriction.firstIncluding && restriction.lastIncluding && restriction.first != null && restriction.first.equals(restriction.last)) {
        // ""[property] = $value""
        return encode(restriction.first);
    } else if (restriction.list != null) {
        // ""[property] IN (...)
        // keep order for testing
        Set<String> values = newLinkedHashSet();
        for (PropertyValue value : restriction.list) {
            values.addAll(encode(value));
        }
        return values;
    } else {
        // processed as ""[property] is not null""
        return null;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/PropertyIndexPlan.java,252,275,"// ------------------------------------------------------------< Object >--
public String toString() {
    StringBuilder buffer = new StringBuilder(""property "");
    buffer.append(name);
    if (values == null) {
        buffer.append("" IS NOT NULL"");
    } else if (values.isEmpty()) {
        buffer.append("" NOT APPLICABLE"");
    } else if (values.size() == 1) {
        buffer.append("" = "");
        buffer.append(values.iterator().next());
    } else {
        buffer.append("" IN ("");
        boolean comma = false;
        for (String value : values) {
            if (comma) {
                buffer.append("", "");
            }
            buffer.append(value);
            comma = true;
        }
        buffer.append("")"");
    }
    return buffer.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/ContentMirrorStoreStrategy.java,117,141,"public Iterable<String> query(final Filter filter, final String indexName, final NodeState indexMeta, final String indexStorageNodeName, final Iterable<String> values) {
    final NodeState index = indexMeta.getChildNode(indexStorageNodeName);
    return new Iterable<String>() {

        @Override
        public Iterator<String> iterator() {
            PathIterator it = new PathIterator(filter, indexName);
            if (values == null) {
                it.setPathContainsValue(true);
                it.enqueue(getChildNodeEntries(index).iterator());
            } else {
                for (String p : values) {
                    NodeState property = index.getChildNode(p);
                    if (property.exists()) {
                        // we have an entry for this value, so use it
                        it.enqueue(Iterators.singletonIterator(new MemoryChildNodeEntry("""", property)));
                    }
                }
            }
            return it;
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/ContentMirrorStoreStrategy.java,122,139,"@Override
public Iterator<String> iterator() {
    PathIterator it = new PathIterator(filter, indexName);
    if (values == null) {
        it.setPathContainsValue(true);
        it.enqueue(getChildNodeEntries(index).iterator());
    } else {
        for (String p : values) {
            NodeState property = index.getChildNode(p);
            if (property.exists()) {
                // we have an entry for this value, so use it
                it.enqueue(Iterators.singletonIterator(new MemoryChildNodeEntry("""", property)));
            }
        }
    }
    return it;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/ContentMirrorStoreStrategy.java,160,216,"public long count(NodeState indexMeta, final String indexStorageNodeName, Set<String> values, int max) {
    NodeState index = indexMeta.getChildNode(indexStorageNodeName);
    int count = 0;
    if (values == null) {
        PropertyState ec = indexMeta.getProperty(ENTRY_COUNT_PROPERTY_NAME);
        if (ec != null) {
            return ec.getValue(Type.LONG);
        }
        CountingNodeVisitor v = new CountingNodeVisitor(max);
        v.visit(index);
        count = v.getEstimatedCount();
        if (count >= max) {
            // ""is not null"" queries typically read more data
            count *= 10;
        }
    } else {
        int size = values.size();
        if (size == 0) {
            return 0;
        }
        PropertyState ec = indexMeta.getProperty(ENTRY_COUNT_PROPERTY_NAME);
        if (ec != null) {
            long entryCount = ec.getValue(Type.LONG);
            // assume 10000 entries per key, so that this index is used
            // instead of traversal, but not instead of a regular property index
            long keyCount = entryCount / 10000;
            ec = indexMeta.getProperty(KEY_COUNT_PROPERTY_NAME);
            if (ec != null) {
                keyCount = ec.getValue(Type.LONG);
            }
            // otherwise the traversing index might be used
            return (long) ((double) entryCount / keyCount) + size;
        }
        max = Math.max(10, max / size);
        int i = 0;
        for (String p : values) {
            if (count > max && i > 3) {
                // the total count is extrapolated from the the number
                // of values counted so far to the total number of values
                count = count * size / i;
                break;
            }
            NodeState s = index.getChildNode(p);
            if (s.exists()) {
                CountingNodeVisitor v = new CountingNodeVisitor(max);
                v.visit(s);
                count += v.getEstimatedCount();
            }
            i++;
        }
    }
    return count;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/ContentMirrorStoreStrategy.java,288,322,"private void fetchNextPossiblyDuplicate() {
    while (!nodeIterators.isEmpty()) {
        Iterator<? extends ChildNodeEntry> iterator = nodeIterators.getLast();
        if (iterator.hasNext()) {
            ChildNodeEntry entry = iterator.next();
            readCount++;
            if (readCount % 1000 == 0) {
                FilterIterators.checkReadLimit(readCount, maxMemoryEntries);
                LOG.warn(""Traversed "" + readCount + "" nodes using index "" + indexName + "" with filter "" + filter);
            }
            NodeState node = entry.getNodeState();
            String name = entry.getName();
            if (NodeStateUtils.isHidden(name)) {
                continue;
            }
            currentPath = PathUtils.concat(parentPath, name);
            nodeIterators.addLast(node.getChildNodeEntries().iterator());
            parentPath = currentPath;
            if (node.getBoolean(""match"")) {
                return;
            }
        } else {
            nodeIterators.removeLast();
            parentPath = PathUtils.getParentPath(parentPath);
        }
    }
    currentPath = null;
    closed = true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/ContentMirrorStoreStrategy.java,324,336,"@Override
public String next() {
    if (closed) {
        throw new IllegalStateException(""This iterator is closed"");
    }
    if (!init) {
        fetchNext();
        init = true;
    }
    String result = currentPath;
    fetchNext();
    return result;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/IndexStoreStrategy.java,52,52,"/**
 * Search for a given set of values.
 *
 * @param filter the filter (used for logging)
 * @param indexName the name of the index (for logging)
 * @param indexMeta the index metadata node (may not be null)
 * @param values values to look for (null to check for property existence)
 * @return an iterator of paths
 */
Iterable<String> query(Filter filter, String indexName, NodeState indexMeta, Iterable<String> values);"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,277,280,"/**
 * search the index for the provided PropertyRestriction
 *
 * @param filter
 * @param indexName
 * @param indexMeta
 * @param pr
 * @return the iterable
 */
public Iterable<String> query(final Filter filter, final String indexName, final NodeState indexMeta, final PropertyRestriction pr) {
    return query(filter, indexName, indexMeta, INDEX_CONTENT_NODE_NAME, pr);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,293,403,"/**
 * queries through the index as other query() but provides the PropertyRestriction to be applied
 * for advanced cases like range queries
 *
 * @param filter
 * @param indexName
 * @param indexMeta
 * @param indexStorageNodeName
 * @param pr
 * @return the iterable
 */
public Iterable<String> query(final Filter filter, final String indexName, final NodeState indexMeta, final String indexStorageNodeName, final PropertyRestriction pr) {
    if (LOG.isDebugEnabled()) {
        LOG.debug(""query() - filter: {}"", filter);
        LOG.debug(""query() - indexName: {}"", indexName);
        LOG.debug(""query() - indexMeta: {}"", indexMeta);
        LOG.debug(""query() - indexStorageNodeName: {}"", indexStorageNodeName);
        LOG.debug(""query() - pr: {}"", pr);
    }
    final NodeState indexState = indexMeta.getChildNode(indexStorageNodeName);
    final NodeBuilder index = new ReadOnlyBuilder(indexState);
    final String firstEncoded = (pr.first == null) ? null : encode(pr.first.getValue(Type.STRING));
    final String lastEncoded = (pr.last == null) ? null : encode(pr.last.getValue(Type.STRING));
    if (firstEncoded != null && !firstEncoded.equals(lastEncoded)) {
        // '>' & '>=' and between use case
        LOG.debug(""'>' & '>=' and between use case"");
        ChildNodeEntry firstValueableItem;
        String firstValuableItemKey;
        Iterable<String> it = Collections.emptyList();
        Iterable<ChildNodeEntry> childrenIterable;
        if (lastEncoded == null) {
            LOG.debug(""> & >= case."");
            firstValuableItemKey = seek(index, new PredicateGreaterThan(firstEncoded, pr.firstIncluding));
            if (firstValuableItemKey != null) {
                firstValueableItem = new OrderedChildNodeEntry(firstValuableItemKey, indexState.getChildNode(firstValuableItemKey));
                if (direction.isAscending()) {
                    childrenIterable = new SeekedIterable(indexState, firstValueableItem);
                    it = new QueryResultsWrapper(filter, indexName, childrenIterable);
                } else {
                    it = new QueryResultsWrapper(filter, indexName, new BetweenIterable(indexState, firstValueableItem, firstEncoded, pr.firstIncluding, direction));
                }
            }
        } else {
            String first, last;
            boolean includeFirst, includeLast;
            first = firstEncoded;
            last = lastEncoded;
            includeFirst = pr.firstIncluding;
            includeLast = pr.lastIncluding;
            if (LOG.isDebugEnabled()) {
                final String op1 = includeFirst ? "">="" : "">"";
                final String op2 = includeLast ? ""<="" : ""<"";
                LOG.debug(""in between case. direction: {} - Condition: (x {} {} AND x {} {})"", new Object[] { direction, op1, first, op2, last });
            }
            if (direction.equals(OrderDirection.ASC)) {
                firstValuableItemKey = seek(index, new PredicateGreaterThan(first, includeFirst));
            } else {
                firstValuableItemKey = seek(index, new PredicateLessThan(last, includeLast));
            }
            LOG.debug(""firstValueableItem: {}"", firstValuableItemKey);
            if (firstValuableItemKey != null) {
                firstValueableItem = new OrderedChildNodeEntry(firstValuableItemKey, indexState.getChildNode(firstValuableItemKey));
                childrenIterable = new BetweenIterable(indexState, firstValueableItem, last, includeLast, direction);
                it = new QueryResultsWrapper(filter, indexName, childrenIterable);
            }
        }
        return it;
    } else if (lastEncoded != null && !lastEncoded.equals(firstEncoded)) {
        // '<' & '<=' use case
        LOG.debug(""'<' & '<=' use case"");
        final String searchfor = lastEncoded;
        final boolean include = pr.lastIncluding;
        Predicate<String> predicate = new PredicateLessThan(searchfor, include);
        LOG.debug(""< & <= case. - searchfor: {} - include: {} - predicate: {}"", new Object[] { searchfor, include, predicate });
        ChildNodeEntry firstValueableItem;
        String firstValueableItemKey = seek(index, predicate);
        LOG.debug(""firstValuableItem: {}"", firstValueableItemKey);
        Iterable<String> it = Collections.emptyList();
        if (firstValueableItemKey != null) {
            firstValueableItem = new OrderedChildNodeEntry(firstValueableItemKey, indexState.getChildNode(firstValueableItemKey));
            if (direction.isAscending()) {
                it = new QueryResultsWrapper(filter, indexName, new BetweenIterable(indexState, firstValueableItem, searchfor, include, direction));
            } else {
                it = new QueryResultsWrapper(filter, indexName, new SeekedIterable(indexState, firstValueableItem));
            }
        }
        return it;
    } else {
        // property is not null. AKA ""open query""
        LOG.debug(""property is not null. AKA 'open query'. FullIterable"");
        return new QueryResultsWrapper(filter, indexName, new FullIterable(indexState, false));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,613,619,"@Override
public Iterator<String> iterator() {
    PathIterator pi = new PathIterator(filter, indexName);
    pi.setPathContainsValue(true);
    pi.enqueue(children.iterator());
    return pi;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/query/Cursors.java,85,91,"/**
 * Creates a cursor which wraps another cursor and adds a path prefix to
 * each of row of the wrapped cursor. This method will return the passed
 * cursor as is if {@code path} is the empty string or the root path (""/"").
 *
 * @param c    the cursor to wrap.
 * @param path the path prefix.
 * @return the cursor.
 */
public static Cursor newPrefixCursor(Cursor c, String path) {
    if (path.isEmpty() || PathUtils.denotesRoot(path)) {
        // no need to wrap
        return c;
    }
    return new PrefixCursor(c, path);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/query/Cursors.java,236,256,"@Override
public IndexRow next() {
    final IndexRow r = c.next();
    return new IndexRow() {

        @Override
        public String getPath() {
            String sub = r.getPath();
            if (PathUtils.isAbsolute(sub)) {
                return path + sub;
            } else {
                return PathUtils.concat(path, r.getPath());
            }
        }

        @Override
        public PropertyValue getValue(String columnName) {
            return r.getValue(columnName);
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/query/Cursors.java,241,249,"@Override
public String getPath() {
    String sub = r.getPath();
    if (PathUtils.isAbsolute(sub)) {
        return path + sub;
    } else {
        return PathUtils.concat(path, r.getPath());
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/query/Cursors.java,251,254,"@Override
public PropertyValue getValue(String columnName) {
    return r.getValue(columnName);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1977_4bfbfcdd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/query/Cursors.java,258,261,"@Override
public boolean hasNext() {
    return c.hasNext();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1985_f620b79b,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authentication/token/TokenProviderImpl.java,207,257,"/**
 * Create a separate token node underneath a dedicated token store within
 * the user home node. That token node contains the hashed token, the
 * expiration time and additional mandatory attributes that will be verified
 * during login.
 *
 * @param userId     The identifier of the user for which a new token should
 *                   be created.
 * @param attributes The attributes associated with the new token.
 * @return A new {@code TokenInfo} or {@code null} if the token could not
 *         be created.
 */
@Override
public TokenInfo createToken(String userId, Map<String, ?> attributes) {
    String error = ""Failed to create login token. "";
    NodeUtil tokenParent = getTokenParent(userId);
    if (tokenParent != null) {
        try {
            long creationTime = new Date().getTime();
            NodeUtil tokenNode = createTokenNode(tokenParent, creationTime);
            tokenNode.setString(JcrConstants.JCR_UUID, IdentifierManager.generateUUID());
            String key = generateKey(options.getConfigValue(PARAM_TOKEN_LENGTH, DEFAULT_KEY_SIZE));
            String nodeId = getIdentifier(tokenNode.getTree());
            String token = new StringBuilder(nodeId).append(DELIM).append(key).toString();
            String keyHash = PasswordUtil.buildPasswordHash(getKeyValue(key, userId), options);
            tokenNode.setString(TOKEN_ATTRIBUTE_KEY, keyHash);
            long exp;
            if (attributes.containsKey(PARAM_TOKEN_EXPIRATION)) {
                exp = Long.parseLong(attributes.get(PARAM_TOKEN_EXPIRATION).toString());
            } else {
                exp = tokenExpiration;
            }
            long expTime = createExpirationTime(creationTime, exp);
            tokenNode.setDate(TOKEN_ATTRIBUTE_EXPIRY, expTime);
            for (String name : attributes.keySet()) {
                if (!RESERVED_ATTRIBUTES.contains(name)) {
                    String attr = attributes.get(name).toString();
                    tokenNode.setString(name, attr);
                }
            }
            root.commit();
            return new TokenInfoImpl(tokenNode, token, userId);
        } catch (NoSuchAlgorithmException e) {
            // error while generating login token
            log.error(error, e.getMessage());
        } catch (UnsupportedEncodingException e) {
            // error while generating login token
            log.error(error, e.getMessage());
        } catch (CommitFailedException e) {
            // conflict while committing changes
            log.warn(error, e.getMessage());
        } catch (AccessDeniedException e) {
            log.warn(error, e.getMessage());
        }
    } else {
        log.warn(""Unable to get/create token store for user "" + userId);
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1985_f620b79b,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authentication/token/TokenProviderImpl.java,322,325,"@Nonnull
private static String getKeyValue(String key, String userId) {
    return key + userId;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-1985_f620b79b,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authentication/token/TokenProviderImpl.java,361,395,"@CheckForNull
private NodeUtil getTokenParent(String userId) {
    NodeUtil tokenParent = null;
    String parentPath = null;
    try {
        Authorizable user = userManager.getAuthorizable(userId);
        if (user != null && !user.isGroup()) {
            String userPath = user.getPath();
            NodeUtil userNode = new NodeUtil(root.getTree(userPath));
            tokenParent = userNode.getChild(TOKENS_NODE_NAME);
            if (tokenParent == null) {
                tokenParent = userNode.addChild(TOKENS_NODE_NAME, TOKENS_NT_NAME);
                parentPath = userPath + '/' + TOKENS_NODE_NAME;
                root.commit();
            }
        } else {
            log.debug(""Cannot create login token: No corresponding node for User "" + userId + '.');
        }
    } catch (RepositoryException e) {
        // error while accessing user.
        log.debug(""Error while accessing user "" + userId + '.', e);
    } catch (CommitFailedException e) {
        // conflict while creating token store for this user -> refresh and
        // try to get the tree from the updated root.
        log.debug(""Conflict while creating token store -> retrying"", e.getMessage());
        root.refresh();
        if (parentPath != null) {
            Tree parentTree = root.getTree(parentPath);
            if (parentTree.exists()) {
                tokenParent = new NodeUtil(parentTree);
            }
        }
    }
    return tokenParent;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2021_004db804,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Expression.java,166,171,"/**
 * Get the left-hand-side expression for equality conditions.
 * For example, for x=1, it is x. If it is not equality, return null.
 *
 * @return the left-hand-side expression, or null
 */
public String getCommonLeftPart() {
    if (!""="".equals(operator)) {
        return null;
    }
    return left.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2021_004db804,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Expression.java,244,254,"/**
 * Get the left-hand-side expression if it is the same for
 * both sides. For example, for x=1 or x=2, it is x,
 * but for x=1 or y=2, it is null
 *
 * @return the left-hand-side expression, or null
 */
@Override
public String getCommonLeftPart() {
    if (left instanceof Condition && right instanceof Condition) {
        String l = ((Condition) left).getCommonLeftPart();
        String r = ((Condition) right).getCommonLeftPart();
        if (l != null && r != null && l.equals(r)) {
            return l;
        }
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2021_004db804,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Statement.java,54,84,"public Statement optimize() {
    if (explain || measure || orderList.size() > 0) {
        return this;
    }
    if (where == null) {
        return this;
    }
    ArrayList<Expression> unionList = new ArrayList<Expression>();
    addToUnionList(where, unionList);
    if (unionList.size() == 1) {
        return this;
    }
    Statement union = null;
    for (int i = 0; i < unionList.size(); i++) {
        Expression e = unionList.get(i);
        Statement s = new Statement();
        s.columnSelector = columnSelector;
        s.selectors = selectors;
        s.columnList = columnList;
        s.where = e;
        if (i == unionList.size() - 1) {
            s.xpathQuery = xpathQuery;
        }
        if (union == null) {
            union = s;
        } else {
            union = new UnionStatement(union.optimize(), s.optimize());
        }
    }
    return union;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2021_004db804,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Statement.java,86,130,"private static void addToUnionList(Expression condition, ArrayList<Expression> unionList) {
    if (condition instanceof OrCondition) {
        OrCondition or = (OrCondition) condition;
        if (or.getCommonLeftPart() != null) {
        // @x = 1 or @x = 2
        // is automatically converted to
        // @x in (1, 2)
        // within the query engine
        } else if (or.left instanceof Contains && or.right instanceof Contains) {
        // do not optimize ""contains""
        } else {
            // conditions of type
            // @x = 1 or @y = 2
            // or similar are converted to
            // (@x = 1) union (@y = 2)
            addToUnionList(or.left, unionList);
            addToUnionList(or.right, unionList);
            return;
        }
    } else if (condition instanceof AndCondition) {
        // conditions of type
        // @a = 1 and (@x = 1 or @y = 2)
        // are automatically converted to
        // (@a = 1 and @x = 1) union (@a = 1 and @y = 2)
        AndCondition and = (AndCondition) condition;
        and = and.pullOrRight();
        if (and.right instanceof OrCondition) {
            OrCondition or = (OrCondition) and.right;
            if (or.getCommonLeftPart() != null) {
            // @x = 1 or @x = 2
            // is automatically converted to
            // @x in (1, 2)
            // within the query engine
            } else if (or.left instanceof Contains && or.right instanceof Contains) {
            // do not optimize ""contains""
            } else {
                // same as above, but with the added ""and""
                addToUnionList(new AndCondition(and.left, or.left), unionList);
                addToUnionList(new AndCondition(and.left, or.right), unionList);
                return;
            }
        }
    }
    unionList.add(condition);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2021_004db804,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Statement.java,256,259,"@Override
public String toString() {
    return s1 + "" union "" + s2;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2029_e30023ba,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditorContext.java,165,169,"/**
 * close writer if it's not null
 */
void closeWriter() throws IOException {
    if (writer != null) {
        writer.close();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2047_a0a495f0,Critical,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,241,312,"/**
 * Copies the full content from the source to the target repository.
 * <p>
 * The source repository <strong>must not be modified</strong> while
 * the copy operation is running to avoid an inconsistent copy.
 * <p>
 * Note that both the source and the target repository must be closed
 * during the copy operation as this method requires exclusive access
 * to the repositories.
 *
 * @param initializer optional extra repository initializer to use
 * @throws RepositoryException if the copy operation fails
 */
public void copy(RepositoryInitializer initializer) throws RepositoryException {
    RepositoryConfig config = source.getRepositoryConfig();
    logger.info(""Copying repository content from {} to Oak"", config.getHomeDir());
    try {
        NodeState base = target.getRoot();
        NodeBuilder builder = base.builder();
        String workspaceName = source.getRepositoryConfig().getDefaultWorkspaceName();
        SecurityProviderImpl security = new SecurityProviderImpl(mapSecurityConfig(config.getSecurityConfig()));
        // init target repository first
        new InitialContent().initialize(builder);
        if (initializer != null) {
            initializer.initialize(builder);
        }
        for (SecurityConfiguration sc : security.getConfigurations()) {
            sc.getRepositoryInitializer().initialize(builder);
        }
        for (SecurityConfiguration sc : security.getConfigurations()) {
            sc.getWorkspaceInitializer().initialize(builder, workspaceName);
        }
        HashBiMap<String, String> uriToPrefix = HashBiMap.create();
        Map<Integer, String> idxToPrefix = newHashMap();
        copyNamespaces(builder, uriToPrefix, idxToPrefix);
        copyNodeTypes(builder, uriToPrefix.inverse());
        copyPrivileges(builder);
        // Triggers compilation of type information, which we need for
        // the type predicates used by the bulk  copy operations below.
        new TypeEditorProvider(false).getRootEditor(base, builder.getNodeState(), builder, null);
        Map<String, String> versionablePaths = newHashMap();
        NodeState root = builder.getNodeState();
        copyWorkspace(builder, root, workspaceName, uriToPrefix, idxToPrefix, versionablePaths);
        copyVersionStore(builder, root, workspaceName, uriToPrefix, idxToPrefix, versionablePaths);
        logger.info(""Applying default commit hooks"");
        // TODO: default hooks?
        List<CommitHook> hooks = newArrayList();
        UserConfiguration userConf = security.getConfiguration(UserConfiguration.class);
        String groupsPath = userConf.getParameters().getConfigValue(UserConstants.PARAM_GROUP_PATH, UserConstants.DEFAULT_GROUP_PATH);
        // hooks specific to the upgrade, need to run first
        hooks.add(new EditorHook(new CompositeEditorProvider(new RestrictionEditorProvider(), new GroupEditorProvider(groupsPath))));
        // security-related hooks
        for (SecurityConfiguration sc : security.getConfigurations()) {
            hooks.addAll(sc.getCommitHooks(workspaceName));
        }
        // type validation, reference and indexing hooks
        hooks.add(new EditorHook(new CompositeEditorProvider(createTypeEditorProvider(), createIndexEditorProvider())));
        target.merge(builder, CompositeHook.compose(hooks), CommitInfo.EMPTY);
    } catch (Exception e) {
        throw new RepositoryException(""Failed to copy content"", e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2047_a0a495f0,Critical,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,468,511,"@SuppressWarnings(""deprecation"")
private void copyPrivileges(NodeBuilder root) throws RepositoryException {
    PrivilegeRegistry registry = source.getPrivilegeRegistry();
    NodeBuilder privileges = root.child(JCR_SYSTEM).child(REP_PRIVILEGES);
    privileges.setProperty(JCR_PRIMARYTYPE, NT_REP_PRIVILEGES, NAME);
    PrivilegeBits next = PrivilegeBits.NEXT_AFTER_BUILT_INS;
    logger.info(""Copying registered privileges"");
    for (Privilege privilege : registry.getRegisteredPrivileges()) {
        String name = privilege.getName();
        NodeBuilder def = privileges.child(name);
        def.setProperty(JCR_PRIMARYTYPE, NT_REP_PRIVILEGE, NAME);
        if (privilege.isAbstract()) {
            def.setProperty(REP_IS_ABSTRACT, true);
        }
        Privilege[] aggregate = privilege.getDeclaredAggregatePrivileges();
        if (aggregate.length > 0) {
            List<String> names = newArrayListWithCapacity(aggregate.length);
            for (Privilege p : aggregate) {
                names.add(p.getName());
            }
            def.setProperty(REP_AGGREGATES, names, NAMES);
        }
        PrivilegeBits bits = PrivilegeBits.BUILT_IN.get(name);
        if (bits != null) {
            def.setProperty(bits.asPropertyState(REP_BITS));
        } else if (aggregate.length == 0) {
            bits = next;
            next = next.nextBits();
            def.setProperty(bits.asPropertyState(REP_BITS));
        }
    }
    privileges.setProperty(next.asPropertyState(REP_NEXT));
    // resolve privilege bits also for all aggregates
    for (String name : privileges.getChildNodeNames()) {
        resolvePrivilegeBits(privileges, name);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2047_a0a495f0,Critical,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,513,528,"private PrivilegeBits resolvePrivilegeBits(NodeBuilder privileges, String name) {
    NodeBuilder def = privileges.getChildNode(name);
    PropertyState b = def.getProperty(REP_BITS);
    if (b != null) {
        return PrivilegeBits.getInstance(b);
    }
    PrivilegeBits bits = PrivilegeBits.getInstance();
    for (String n : def.getNames(REP_AGGREGATES)) {
        bits.add(resolvePrivilegeBits(privileges, n));
    }
    def.setProperty(bits.asPropertyState(REP_BITS));
    return bits;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2047_ca63fdf3,Critical,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,241,309,"/**
 * Copies the full content from the source to the target repository.
 * <p>
 * The source repository <strong>must not be modified</strong> while
 * the copy operation is running to avoid an inconsistent copy.
 * <p>
 * Note that both the source and the target repository must be closed
 * during the copy operation as this method requires exclusive access
 * to the repositories.
 *
 * @param initializer optional extra repository initializer to use
 * @throws RepositoryException if the copy operation fails
 */
public void copy(RepositoryInitializer initializer) throws RepositoryException {
    RepositoryConfig config = source.getRepositoryConfig();
    logger.info(""Copying repository content from {} to Oak"", config.getHomeDir());
    try {
        NodeState base = target.getRoot();
        NodeBuilder builder = base.builder();
        String workspaceName = source.getRepositoryConfig().getDefaultWorkspaceName();
        SecurityProviderImpl security = new SecurityProviderImpl(mapSecurityConfig(config.getSecurityConfig()));
        // init target repository first
        new InitialContent().initialize(builder);
        if (initializer != null) {
            initializer.initialize(builder);
        }
        for (SecurityConfiguration sc : security.getConfigurations()) {
            sc.getWorkspaceInitializer().initialize(builder, workspaceName);
        }
        HashBiMap<String, String> uriToPrefix = HashBiMap.create();
        Map<Integer, String> idxToPrefix = newHashMap();
        copyNamespaces(builder, uriToPrefix, idxToPrefix);
        copyNodeTypes(builder, uriToPrefix.inverse());
        copyPrivileges(builder);
        // Triggers compilation of type information, which we need for
        // the type predicates used by the bulk  copy operations below.
        new TypeEditorProvider(false).getRootEditor(base, builder.getNodeState(), builder, null);
        Map<String, String> versionablePaths = newHashMap();
        NodeState root = builder.getNodeState();
        copyWorkspace(builder, root, workspaceName, uriToPrefix, idxToPrefix, versionablePaths);
        copyVersionStore(builder, root, workspaceName, uriToPrefix, idxToPrefix, versionablePaths);
        logger.info(""Applying default commit hooks"");
        // TODO: default hooks?
        List<CommitHook> hooks = newArrayList();
        UserConfiguration userConf = security.getConfiguration(UserConfiguration.class);
        String groupsPath = userConf.getParameters().getConfigValue(UserConstants.PARAM_GROUP_PATH, UserConstants.DEFAULT_GROUP_PATH);
        // hooks specific to the upgrade, need to run first
        hooks.add(new EditorHook(new CompositeEditorProvider(new RestrictionEditorProvider(), new GroupEditorProvider(groupsPath))));
        // security-related hooks
        for (SecurityConfiguration sc : security.getConfigurations()) {
            hooks.addAll(sc.getCommitHooks(workspaceName));
        }
        // type validation, reference and indexing hooks
        hooks.add(new EditorHook(new CompositeEditorProvider(createTypeEditorProvider(), createIndexEditorProvider())));
        target.merge(builder, CompositeHook.compose(hooks), CommitInfo.EMPTY);
    } catch (Exception e) {
        throw new RepositoryException(""Failed to copy content"", e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2049_4af0d4ee,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentWriter.java,178,246,"/**
 * Adds a segment header to the buffer and writes a segment to the segment
 * store. This is done automatically (called from prepare) when there is not
 * enough space for a record. It can also be called explicitly.
 */
public synchronized void flush() {
    if (length > 0) {
        int refcount = segment.getRefCount();
        int rootcount = roots.size();
        buffer[Segment.ROOT_COUNT_OFFSET] = (byte) (rootcount >> 8);
        buffer[Segment.ROOT_COUNT_OFFSET + 1] = (byte) rootcount;
        int blobrefcount = blobrefs.size();
        buffer[Segment.BLOBREF_COUNT_OFFSET] = (byte) (blobrefcount >> 8);
        buffer[Segment.BLOBREF_COUNT_OFFSET + 1] = (byte) blobrefcount;
        length = align(refcount * 16 + rootcount * 3 + blobrefcount * 2 + length, 16);
        int pos = refcount * 16;
        if (pos + length <= buffer.length) {
            // the whole segment fits to the space *after* the referenced
            // segment identifiers we've already written, so we can safely
            // copy those bits ahead even if concurrent code is still
            // reading from that part of the buffer
            System.arraycopy(buffer, 0, buffer, buffer.length - length, pos);
            pos += buffer.length - length;
        } else {
            // this might leave some empty space between the header and
            // the record data, but this case only occurs when the
            // segment is >252kB in size and the maximum overhead is <<4kB,
            // which is acceptable
            length = buffer.length;
        }
        for (Map.Entry<RecordId, RecordType> entry : roots.entrySet()) {
            int offset = entry.getKey().getOffset();
            buffer[pos++] = (byte) entry.getValue().ordinal();
            buffer[pos++] = (byte) (offset >> (8 + Segment.RECORD_ALIGN_BITS));
            buffer[pos++] = (byte) (offset >> Segment.RECORD_ALIGN_BITS);
        }
        for (RecordId blobref : blobrefs) {
            int offset = blobref.getOffset();
            buffer[pos++] = (byte) (offset >> (8 + Segment.RECORD_ALIGN_BITS));
            buffer[pos++] = (byte) (offset >> Segment.RECORD_ALIGN_BITS);
        }
        SegmentId id = segment.getSegmentId();
        log.debug(""Writing data segment {} ({} bytes)"", id, length);
        store.writeSegment(id, buffer, buffer.length - length, length);
        // Keep this segment in memory as it's likely to be accessed soon
        ByteBuffer data;
        if (buffer.length - length > 4096) {
            data = ByteBuffer.allocate(length);
            data.put(buffer, buffer.length - length, length);
            data.rewind();
        } else {
            data = ByteBuffer.wrap(buffer, buffer.length - length, length);
        }
        tracker.setSegment(id, new Segment(tracker, id, data));
        buffer = createNewBuffer();
        roots.clear();
        blobrefs.clear();
        length = 0;
        position = buffer.length;
        segment = new Segment(tracker, buffer);
        segment.getSegmentId().setSegment(segment);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2049_4af0d4ee,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentWriter.java,269,327,"/**
 * Before writing a record (which are written backwards, from the end of the
 * file to the beginning), this method is called, to ensure there is enough
 * space. A new segment is also created if there is not enough space in the
 * segment lookup table or elsewhere.
 * <p>
 * This method does not actually write into the segment, just allocates the
 * space (flushing the segment if needed and starting a new one), and sets
 * the write position (records are written from the end to the beginning,
 * but within a record from left to right).
 *
 * @param type the record type (only used for root records)
 * @param size the size of the record, excluding the size used for the
 *            record ids
 * @param ids the record ids
 * @return a new record id
 */
private RecordId prepare(RecordType type, int size, Collection<RecordId> ids) {
    checkArgument(size >= 0);
    checkNotNull(ids);
    int idcount = ids.size();
    int recordSize = align(size + idcount * RECORD_ID_BYTES);
    // First compute the header and segment sizes based on the assumption
    // that *all* identifiers stored in this record point to previously
    // unreferenced segments.
    int refcount = segment.getRefCount() + idcount;
    int blobrefcount = blobrefs.size() + 1;
    int rootcount = roots.size() + 1;
    int headerSize = refcount * 16 + rootcount * 3 + blobrefcount * 2;
    int segmentSize = align(headerSize + recordSize + length, 16);
    // avoid the somewhat expensive list and set traversals.
    if (segmentSize > buffer.length - 1 || refcount > Segment.SEGMENT_REFERENCE_LIMIT) {
        refcount -= idcount;
        Set<SegmentId> segmentIds = newIdentityHashSet();
        for (RecordId recordId : ids) {
            SegmentId segmentId = recordId.getSegmentId();
            if (segmentId != segment.getSegmentId()) {
                segmentIds.add(segmentId);
            } else if (roots.containsKey(recordId)) {
                rootcount--;
            }
        }
        if (!segmentIds.isEmpty()) {
            for (int refid = 1; refid < refcount; refid++) {
                segmentIds.remove(segment.getRefId(refid));
            }
            refcount += segmentIds.size();
        }
        headerSize = refcount * 16 + rootcount * 3 + blobrefcount * 2;
        segmentSize = align(headerSize + recordSize + length, 16);
    }
    if (segmentSize > buffer.length - 1 || blobrefcount > 0xffff || rootcount > 0xffff || refcount > Segment.SEGMENT_REFERENCE_LIMIT) {
        flush();
    }
    length += recordSize;
    position = buffer.length - length;
    checkState(position >= 0);
    RecordId id = new RecordId(segment.getSegmentId(), position);
    roots.put(id, type);
    return id;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2062_5c4589bd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SelectorImpl.java,546,600,"private PropertyValue currentOakProperty(String oakPropertyName, Integer propertyType) {
    boolean asterisk = oakPropertyName.indexOf('*') >= 0;
    if (asterisk) {
        Tree t = currentTree();
        ArrayList<PropertyValue> list = new ArrayList<PropertyValue>();
        readOakProperties(list, t, oakPropertyName, propertyType);
        if (list.size() == 0) {
            return null;
        } else if (list.size() == 1) {
            return list.get(0);
        }
        Type<?> type = list.get(0).getType();
        for (int i = 1; i < list.size(); i++) {
            Type<?> t2 = list.get(i).getType();
            if (t2 != type) {
                // types don't match
                type = Type.STRING;
                break;
            }
        }
        if (type == Type.STRING) {
            ArrayList<String> strings = new ArrayList<String>();
            for (PropertyValue p : list) {
                Iterables.addAll(strings, p.getValue(Type.STRINGS));
            }
            return PropertyValues.newString(strings);
        }
        @SuppressWarnings(""unchecked"")
        PropertyBuilder<Object> builder = (PropertyBuilder<Object>) PropertyBuilder.array(type);
        builder.setName("""");
        for (PropertyValue v : list) {
            builder.addValue(v.getValue(type));
        }
        PropertyState s = builder.getPropertyState();
        return PropertyValues.create(s);
    }
    boolean relative = oakPropertyName.indexOf('/') >= 0;
    Tree t = currentTree();
    if (relative) {
        for (String p : PathUtils.elements(PathUtils.getParentPath(oakPropertyName))) {
            if (t == null) {
                return null;
            }
            if (p.equals("".."")) {
                t = t.isRoot() ? null : t.getParent();
            } else if (p.equals(""."")) {
            // same node
            } else {
                t = t.getChild(p);
            }
        }
        oakPropertyName = PathUtils.getName(oakPropertyName);
    }
    return currentOakProperty(t, oakPropertyName, propertyType);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2062_5c4589bd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SelectorImpl.java,631,672,"private void readOakProperties(ArrayList<PropertyValue> target, Tree t, String oakPropertyName, Integer propertyType) {
    boolean skipCurrentNode = false;
    while (true) {
        if (t == null || !t.exists()) {
            return;
        }
        int slash = oakPropertyName.indexOf('/');
        if (slash < 0) {
            break;
        }
        String parent = oakPropertyName.substring(0, slash);
        oakPropertyName = oakPropertyName.substring(slash + 1);
        if (parent.equals("".."")) {
            t = t.isRoot() ? null : t.getParent();
        } else if (parent.equals(""."")) {
        // same node
        } else if (parent.equals(""*"")) {
            for (Tree child : t.getChildren()) {
                readOakProperties(target, child, oakPropertyName, propertyType);
            }
            skipCurrentNode = true;
        } else {
            t = t.getChild(parent);
        }
    }
    if (skipCurrentNode) {
        return;
    }
    if (!""*"".equals(oakPropertyName)) {
        PropertyValue value = currentOakProperty(t, oakPropertyName, propertyType);
        if (value != null) {
            target.add(value);
        }
        return;
    }
    for (PropertyState p : t.getProperties()) {
        if (propertyType == null || p.getType().tag() == propertyType) {
            PropertyValue v = PropertyValues.create(p);
            target.add(v);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-208_daf9a4ef,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/RootImpl.java,227,232,"// ------------------------------------------------------------< private >---
/**
 * Purge all pending changes to the underlying {@link NodeStoreBranch}.
 * All registered {@link PurgeListener}s are notified.
 */
private void purgePendingChanges() {
    if (hasPendingChanges()) {
        branch.setRoot(rootTree.getNodeState());
    }
    notifyListeners();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-208_daf9a4ef,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStoreBranch.java,81,85,"@Override
public void setRoot(NodeState newRoot) {
    currentRoot = newRoot;
    commit(buildJsop());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2117_c7669f31,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/IndexUpdate.java,150,182,"private void collectIndexEditors(NodeBuilder definitions, NodeState before) throws CommitFailedException {
    for (String name : definitions.getChildNodeNames()) {
        NodeBuilder definition = definitions.getChildNode(name);
        if (Objects.equal(async, definition.getString(ASYNC_PROPERTY_NAME))) {
            String type = definition.getString(TYPE_PROPERTY_NAME);
            boolean shouldReindex = shouldReindex(definition, before, name);
            Editor editor = provider.getIndexEditor(type, definition, root, updateCallback);
            if (editor == null) {
                // trigger reindexing when an indexer becomes available
                definition.setProperty(REINDEX_PROPERTY_NAME, true);
            } else if (shouldReindex) {
                if (definition.getBoolean(REINDEX_ASYNC_PROPERTY_NAME) && definition.getString(ASYNC_PROPERTY_NAME) == null) {
                    // switch index to an async update mode
                    definition.setProperty(ASYNC_PROPERTY_NAME, ASYNC_REINDEX_VALUE);
                } else {
                    definition.setProperty(REINDEX_PROPERTY_NAME, false);
                    // beforehand, we'll remove all child nodes
                    for (String rm : definition.getChildNodeNames()) {
                        definition.getChildNode(rm).remove();
                    }
                    reindex.put(concat(getPath(), INDEX_DEFINITIONS_NAME, name), editor);
                }
            } else {
                editors.add(editor);
            }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2147_a1556c30,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,807,894,"/**
 * seek for an element in the index given the provided Predicate. If {@code walkedLanes} won't
 * be null it will have on the way out the last elements of each lane walked through during the
 * seek.
 *
 * @param index the index content node {@code :index}
 * @param condition the predicate to evaluate
 * @param walkedLanes if not null will contain the last element of the walked lanes with each
 *            lane represented by the corresponding position in the array. <b>You have</b> to
 *            pass in an array already sized as {@link OrderedIndex#LANES} or an
 *            {@link IllegalArgumentException} will be raised
 * @return the entry or null if not found
 */
String seek(@Nonnull final NodeBuilder index, @Nonnull final Predicate<String> condition, @Nullable final String[] walkedLanes) {
    boolean keepWalked = false;
    String searchfor = condition.getSearchFor();
    if (LOG.isDebugEnabled()) {
        LOG.debug(""seek() - Searching for: {}"", condition.getSearchFor());
        LOG.debug(""seek() - condition: {}"", condition);
    }
    Predicate<String> walkingPredicate = direction.isAscending() ? new PredicateLessThan(searchfor, true) : new PredicateGreaterThan(searchfor, true);
    // we always begin with :start
    String currentKey = START;
    String found = null;
    if (walkedLanes != null) {
        if (walkedLanes.length != OrderedIndex.LANES) {
            throw new IllegalArgumentException(String.format(""Wrong size for keeping track of the Walked Lanes. Expected %d but was %d"", OrderedIndex.LANES, walkedLanes.length));
        }
        // ensuring the right data
        for (int i = 0; i < walkedLanes.length; i++) {
            walkedLanes[i] = currentKey;
        }
        keepWalked = true;
    }
    int lane;
    boolean stillLaning;
    String nextkey;
    if ((direction.isAscending() && condition instanceof PredicateLessThan) || (direction.isDescending() && condition instanceof PredicateGreaterThan)) {
        // we're asking for a <, <= query from ascending index or >, >= from descending
        // we have to walk the lanes from bottom to up rather than up to bottom.
        LOG.debug(""seek() - cross case"");
        lane = 0;
        do {
            stillLaning = lane < OrderedIndex.LANES;
            nextkey = getPropertyNext(index.getChildNode(currentKey), lane);
            if ((Strings.isNullOrEmpty(nextkey) || !walkingPredicate.apply(nextkey)) && lane < OrderedIndex.LANES) {
                // if we're currently pointing to NIL or the next element does not fit the search
                // but we still have lanes left
                lane++;
            } else {
                if (condition.apply(nextkey)) {
                    found = nextkey;
                } else {
                    currentKey = nextkey;
                    if (keepWalked && !Strings.isNullOrEmpty(currentKey)) {
                        walkedLanes[lane] = currentKey;
                    }
                }
            }
        } while (((!Strings.isNullOrEmpty(nextkey) && walkingPredicate.apply(nextkey)) || stillLaning) && (found == null));
    } else {
        LOG.debug(""seek() - plain case"");
        lane = OrderedIndex.LANES - 1;
        do {
            stillLaning = lane > 0;
            nextkey = getPropertyNext(index.getChildNode(currentKey), lane);
            if ((Strings.isNullOrEmpty(nextkey) || !walkingPredicate.apply(nextkey)) && lane > 0) {
                // if we're currently pointing to NIL or the next element does not fit the search
                // but we still have lanes left, let's lower the lane;
                lane--;
            } else {
                if (condition.apply(nextkey)) {
                    found = nextkey;
                } else {
                    currentKey = nextkey;
                    if (keepWalked && !Strings.isNullOrEmpty(currentKey)) {
                        for (int l = lane; l >= 0; l--) {
                            walkedLanes[l] = currentKey;
                        }
                    }
                }
            }
        } while (((!Strings.isNullOrEmpty(nextkey) && walkingPredicate.apply(nextkey)) || stillLaning) && (found == null));
    }
    return found;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2147_a1556c30,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,1073,1082,"/**
 * set the value of the the :next at position 0
 *
 * @param node the node to modify
 * @param next the 'next' value
 */
static void setPropertyNext(@Nonnull final NodeBuilder node, final String... next) {
    if (node != null && next != null) {
        String n1 = (next.length > 0) ? next[0] : """";
        String n2 = (next.length > 1) ? next[1] : """";
        String n3 = (next.length > 2) ? next[2] : """";
        String n4 = (next.length > 3) ? next[3] : """";
        node.setProperty(NEXT, ImmutableList.of(n1, n2, n3, n4), Type.STRINGS);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2147_a1556c30,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,1092,1118,"/**
 * set the value of the :next at the given position. If the property :next won't be there by the
 * time this method is invoked it won't perform any action
 *
 * @param node
 * @param value
 * @param lane
 */
static void setPropertyNext(@Nonnull final NodeBuilder node, final String value, final int lane) {
    if (node != null && value != null && lane >= 0 && lane < OrderedIndex.LANES) {
        PropertyState next = node.getProperty(NEXT);
        if (next != null) {
            String[] values;
            if (next.isArray()) {
                values = Iterables.toArray(next.getValue(Type.STRINGS), String.class);
                if (values.length < OrderedIndex.LANES) {
                    // it could be we increased the number of lanes and running on some existing
                    // content
                    LOG.debug(""topping-up the number of lanes."");
                    List<String> vv = Lists.newArrayList(values);
                    for (int i = vv.size(); i <= OrderedIndex.LANES; i++) {
                        vv.add("""");
                    }
                    values = vv.toArray(new String[vv.size()]);
                }
            } else {
                values = Iterables.toArray(EMPTY_NEXT, String.class);
                values[0] = next.getValue(Type.STRING);
            }
            values[lane] = value;
            setPropertyNext(node, values);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2147_a1556c30,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/strategy/OrderedContentMirrorStoreStrategy.java,1147,1160,"/**
 * short-cut for using NodeBuilder. See {@code getNext(NodeState)}
 */
static String getPropertyNext(@Nonnull final NodeBuilder node, final int lane) {
    checkNotNull(node);
    String next = """";
    PropertyState ps = node.getProperty(NEXT);
    if (ps != null) {
        if (ps.isArray()) {
            next = ps.getValue(Type.STRING, Math.min(ps.count() - 1, lane));
        } else {
            next = ps.getValue(Type.STRING);
        }
    }
    return next;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2174_5931a4a7,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/Oak.java,509,580,"public ContentRepository createContentRepository() {
    final List<Registration> regs = Lists.newArrayList();
    regs.add(whiteboard.register(Executor.class, getExecutor(), Collections.emptyMap()));
    IndexEditorProvider indexEditors = CompositeIndexEditorProvider.compose(indexEditorProviders);
    OakInitializer.initialize(store, new CompositeInitializer(initializers), indexEditors);
    QueryIndexProvider indexProvider = CompositeQueryIndexProvider.compose(queryIndexProviders);
    List<CommitHook> initHooks = new ArrayList<CommitHook>(commitHooks);
    initHooks.add(new EditorHook(CompositeEditorProvider.compose(editorProviders)));
    if (asyncIndexing) {
        String name = ""async"";
        AsyncIndexUpdate task = new AsyncIndexUpdate(name, store, indexEditors);
        regs.add(scheduleWithFixedDelay(whiteboard, task, 5, true));
        regs.add(registerMBean(whiteboard, IndexStatsMBean.class, task.getIndexStats(), IndexStatsMBean.TYPE, name));
        PropertyIndexAsyncReindex asyncPI = new PropertyIndexAsyncReindex(new AsyncIndexUpdate(""async-reindex"", store, indexEditors, true), getExecutor());
        regs.add(registerMBean(whiteboard, PropertyIndexAsyncReindexMBean.class, asyncPI, PropertyIndexAsyncReindexMBean.TYPE, name));
    }
    regs.add(registerMBean(whiteboard, QueryEngineSettingsMBean.class, queryEngineSettings, QueryEngineSettingsMBean.TYPE, ""settings""));
    // FIXME: OAK-810 move to proper workspace initialization
    // initialize default workspace
    Iterable<WorkspaceInitializer> workspaceInitializers = Iterables.transform(securityProvider.getConfigurations(), new Function<SecurityConfiguration, WorkspaceInitializer>() {

        @Override
        public WorkspaceInitializer apply(SecurityConfiguration sc) {
            return sc.getWorkspaceInitializer();
        }
    });
    OakInitializer.initialize(workspaceInitializers, store, defaultWorkspaceName, indexEditors);
    // add index hooks later to prevent the OakInitializer to do excessive indexing
    with(new IndexUpdateProvider(indexEditors));
    withEditorHook();
    // Register observer last to prevent sending events while initialising
    for (Observer observer : observers) {
        regs.add(registerObserver(whiteboard, observer));
    }
    RepositoryManager repositoryManager = new RepositoryManager(whiteboard);
    regs.add(registerMBean(whiteboard, RepositoryManagementMBean.class, repositoryManager, RepositoryManagementMBean.TYPE, repositoryManager.getName()));
    return new ContentRepositoryImpl(store, CompositeHook.compose(commitHooks), defaultWorkspaceName, queryEngineSettings, indexProvider, securityProvider) {

        @Override
        public void close() throws IOException {
            super.close();
            new CompositeRegistration(regs).unregister();
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2174_5931a4a7,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/AsyncIndexUpdate.java,329,383,"private void updateIndex(NodeState before, String beforeCheckpoint, NodeState after, String afterCheckpoint, String afterTime) throws CommitFailedException {
    // start collecting runtime statistics
    preAsyncRunStatsStats(indexStats);
    // create an update callback for tracking index updates
    // and maintaining the update lease
    AsyncUpdateCallback callback = new AsyncUpdateCallback(beforeCheckpoint, afterCheckpoint);
    try {
        NodeBuilder builder = store.getRoot().builder();
        IndexUpdate indexUpdate = new IndexUpdate(provider, name, after, builder, callback);
        CommitFailedException exception = EditorDiff.process(VisibleEditor.wrap(indexUpdate), before, after);
        if (exception != null) {
            throw exception;
        }
        builder.child(ASYNC).setProperty(name, afterCheckpoint);
        builder.child(ASYNC).setProperty(PropertyStates.createProperty(lastIndexedTo, afterTime, Type.DATE));
        if (callback.isDirty() || before == MISSING_NODE) {
            if (switchOnSync) {
                reindexedDefinitions.addAll(indexUpdate.getReindexedDefinitions());
            } else {
                postAsyncRunStatsStatus(indexStats);
            }
        } else if (switchOnSync) {
            log.debug(""No changes detected after diff; will try to"" + "" switch to synchronous updates on {}"", reindexedDefinitions);
            // no changes after diff, switch to sync on the async defs
            for (String path : reindexedDefinitions) {
                NodeBuilder c = builder;
                for (String p : elements(path)) {
                    c = c.getChildNode(p);
                }
                if (c.exists() && !c.getBoolean(REINDEX_PROPERTY_NAME)) {
                    c.removeProperty(ASYNC_PROPERTY_NAME);
                }
            }
            reindexedDefinitions.clear();
        }
        mergeWithConcurrencyCheck(builder, beforeCheckpoint, callback.lease);
    } finally {
        callback.close();
    }
    postAsyncRunStatsStatus(indexStats);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2219_f2740ce1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/OrderedPropertyIndex.java,178,219,"@Override
public Cursor query(IndexPlan plan, NodeState root) {
    LOG.debug(""query(IndexPlan, NodeState)"");
    LOG.debug(""query() - plan: {}"", plan);
    LOG.debug(""query() - rootState: {}"", root);
    Filter filter = plan.getFilter();
    List<OrderEntry> sortOrder = plan.getSortOrder();
    String pathPrefix = plan.getPathPrefix();
    Iterable<String> paths = null;
    OrderedContentMirrorStoreStrategy strategy = OrderedPropertyIndexLookup.getStrategy(plan.getDefinition());
    int depth = 1;
    PropertyRestriction pr = plan.getPropertyRestriction();
    if (pr != null) {
        String propertyName = PathUtils.getName(pr.propertyName);
        depth = PathUtils.getDepth(propertyName);
        paths = strategy.query(plan.getFilter(), propertyName, plan.getDefinition(), pr, pathPrefix);
    }
    if (paths == null && sortOrder != null && !sortOrder.isEmpty()) {
        // we could be here if we have a query where the ORDER BY makes us play it.
        for (OrderEntry oe : sortOrder) {
            String propertyName = PathUtils.getName(oe.getPropertyName());
            depth = PathUtils.getDepth(oe.getPropertyName());
            paths = strategy.query(plan.getFilter(), propertyName, plan.getDefinition(), new PropertyRestriction(), pathPrefix);
        }
    }
    if (paths == null) {
        // if still here then something went wrong.
        throw new IllegalStateException(""OrderedPropertyIndex index is used even when no index is available for filter "" + filter);
    }
    Cursor cursor = Cursors.newPathCursor(paths, filter.getQueryEngineSettings());
    if (depth > 1) {
        cursor = Cursors.newAncestorCursor(cursor, depth - 1, filter.getQueryEngineSettings());
    }
    return cursor;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2235_29d3d8f1,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditor.java,122,125,"@Override
public void enter(NodeState before, NodeState after) throws CommitFailedException {
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2235_29d3d8f1,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditorContext.java,134,145,"/**
 * close writer if it's not null
 */
void closeWriter() throws IOException {
    if (writer != null) {
        writer.close();
        // OAK-2029 Record the last updated status so
        // as to make IndexTracker detect changes when index
        // is stored in file system
        NodeBuilder status = definitionBuilder.child("":status"");
        status.setProperty(""lastUpdated"", ISO8601.format(Calendar.getInstance()), Type.DATE);
        status.setProperty(""indexedNodes"", indexedNodes);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2238_a28098fd,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/delegate/SessionDelegate.java,422,439,"/**
 * Returns the node or property delegate at the given path.
 *
 * @param path Oak path
 * @return node or property delegate, or {@code null} if none exists
 */
@CheckForNull
public ItemDelegate getItem(String path) {
    String name = PathUtils.getName(path);
    if (name.isEmpty()) {
        return getRootNode();
    } else {
        Tree parent = root.getTree(PathUtils.getParentPath(path));
        if (parent.hasProperty(name)) {
            return new PropertyDelegate(this, parent, name);
        }
        Tree child = parent.getChild(name);
        if (child.exists()) {
            return new NodeDelegate(this, child);
        } else {
            return null;
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2246_dcadb0e1,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/xml/ImporterImpl.java,353,506,"@Override
public void startNode(NodeInfo nodeInfo, List<PropInfo> propInfos) throws RepositoryException {
    Tree parent = parents.peek();
    Tree tree = null;
    String id = nodeInfo.getUUID();
    String nodeName = nodeInfo.getName();
    String ntName = nodeInfo.getPrimaryTypeName();
    if (parent == null) {
        log.debug(""Skipping node: "" + nodeName);
        // parent node was skipped, skip this child node too
        // push null onto stack for skipped node
        parents.push(null);
        // notify the p-i-importer
        if (pnImporter != null) {
            pnImporter.startChildInfo(nodeInfo, propInfos);
        }
        return;
    }
    NodeDefinition parentDef = getDefinition(parent);
    if (parentDef.isProtected()) {
        // skip protected node
        parents.push(null);
        log.debug(""Skipping protected node: "" + nodeName);
        if (pnImporter != null) {
            // pnImporter was already started (current nodeInfo is a sibling)
            // notify it about this child node.
            pnImporter.startChildInfo(nodeInfo, propInfos);
        } else {
            // potentially is able to deal with it, notify it about the child node.
            for (ProtectedNodeImporter pni : getNodeImporters()) {
                if (pni.start(parent)) {
                    log.debug(""Protected node -> delegated to ProtectedNodeImporter"");
                    pnImporter = pni;
                    pnImporter.startChildInfo(nodeInfo, propInfos);
                    break;
                }
            /* else: p-i-Importer isn't able to deal with the protected tree.
                     try next. and if none can handle the passed parent the
                     tree below will be skipped */
            }
        }
        return;
    }
    if (parent.hasChild(nodeName)) {
        // a node with that name already exists...
        Tree existing = parent.getChild(nodeName);
        NodeDefinition def = getDefinition(existing);
        if (!def.allowsSameNameSiblings()) {
            // check for potential conflicts
            if (def.isProtected() && isNodeType(existing, ntName)) {
                /*
                     use the existing node as parent for the possible subsequent
                     import of a protected tree, that the protected node importer
                     may or may not be able to deal with.
                     -> upon the next 'startNode' the check for the parent being
                        protected will notify the protected node importer.
                     -> if the importer is able to deal with that node it needs
                        to care of the complete subtree until it is notified
                        during the 'endNode' call.
                     -> if the import can't deal with that node or if that node
                        is the a leaf in the tree to be imported 'end' will
                        not have an effect on the importer, that was never started.
                    */
                log.debug(""Skipping protected node: "" + existing);
                parents.push(existing);
                /**
                 * let ProtectedPropertyImporters handle the properties
                 * associated with the imported node. this may include overwriting,
                 * merging or just adding missing properties.
                 */
                importProperties(existing, propInfos, true);
                return;
            }
            if (def.isAutoCreated() && isNodeType(existing, ntName)) {
                // this node has already been auto-created, no need to create it
                tree = existing;
            } else {
                // edge case: colliding node does have same uuid
                // (see http://issues.apache.org/jira/browse/JCR-1128)
                String existingIdentifier = IdentifierManager.getIdentifier(existing);
                if (!(existingIdentifier.equals(id) && (uuidBehavior == ImportUUIDBehavior.IMPORT_UUID_COLLISION_REMOVE_EXISTING || uuidBehavior == ImportUUIDBehavior.IMPORT_UUID_COLLISION_REPLACE_EXISTING))) {
                    throw new ItemExistsException(""Node with the same UUID exists:"" + existing);
                }
            // fall through
            }
        }
    }
    if (tree == null) {
        // create node
        if (id == null) {
            // no potential uuid conflict, always add new node
            tree = createTree(parent, nodeInfo, null);
        } else if (uuidBehavior == ImportUUIDBehavior.IMPORT_UUID_CREATE_NEW) {
            // always create a new UUID even if no
            // conflicting node exists. see OAK-1244
            tree = createTree(parent, nodeInfo, UUID.randomUUID().toString());
            // remember uuid mapping
            if (isNodeType(tree, JcrConstants.MIX_REFERENCEABLE)) {
                refTracker.put(nodeInfo.getUUID(), TreeUtil.getString(tree, JcrConstants.JCR_UUID));
            }
        } else {
            // 1. First check from base state that tree corresponding to
            // this id exist
            Tree conflicting = baseStateIdManager.getTree(id);
            if (conflicting == null) {
                // 1.a. Check if id is found in newly created nodes
                if (uuids.contains(id)) {
                    conflicting = currentStateIdManager.getTree(id);
                }
            } else {
                // 1.b Re obtain the conflicting tree from Id Manager
                // associated with current root. Such that any operation
                // on it gets reflected in later operations
                // In case a tree with same id was removed earlier then it
                // would return null
                conflicting = currentStateIdManager.getTree(id);
            }
            if (conflicting != null && conflicting.exists()) {
                // resolve uuid conflict
                tree = resolveUUIDConflict(parent, conflicting, id, nodeInfo);
                if (tree == null) {
                    // no new node has been created, so skip this node
                    // push null onto stack for skipped node
                    parents.push(null);
                    log.debug(""Skipping existing node "" + nodeInfo.getName());
                    return;
                }
            } else {
                // create new with given uuid
                tree = createTree(parent, nodeInfo, id);
            }
        }
    }
    // process properties
    importProperties(tree, propInfos, false);
    parents.push(tree);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2246_dcadb0e1,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/xml/ImporterImpl.java,509,526,"@Override
public void endNode(NodeInfo nodeInfo) throws RepositoryException {
    Tree parent = parents.pop();
    if (parent == null) {
        if (pnImporter != null) {
            pnImporter.endChildInfo();
        }
    } else if (getDefinition(parent).isProtected()) {
        if (pnImporter != null) {
            pnImporter.end(parent);
            // and reset the pnImporter field waiting for the next protected
            // parent -> selecting again from available importers
            pnImporter = null;
        }
    }
    collectUUIDs(parent);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2246_dcadb0e1,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/xml/ImporterImpl.java,528,541,"private void collectUUIDs(Tree tree) {
    if (tree == null) {
        return;
    }
    String uuid = TreeUtil.getString(tree, JcrConstants.JCR_UUID);
    if (uuid != null) {
        uuids.add(uuid);
    }
    for (Tree child : tree.getChildren()) {
        collectUUIDs(child);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2249_6dde8e9d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/FullTextSearchImpl.java,250,259,"@Override
public void restrict(FilterImpl f) {
    if (propertyName != null) {
        if (f.getSelector().equals(selector)) {
            String pn = normalizePropertyName(propertyName);
            f.restrictProperty(pn, Operator.NOT_EQUAL, null);
        }
    }
    f.restrictFulltextCondition(fullTextSearchExpression.currentValue().getValue(Type.STRING));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2249_6dde8e9d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/index/FilterImpl.java,393,422,"@Override
public String toString() {
    if (alwaysFalse) {
        return ""Filter(always false)"";
    }
    StringBuilder buff = new StringBuilder();
    buff.append(""Filter("");
    if (queryStatement != null) {
        buff.append(""query="").append(queryStatement);
    }
    if (fullTextConstraint != null) {
        buff.append(""fullText="").append(fullTextConstraint);
    }
    buff.append("", path="").append(getPathPlan());
    if (!propertyRestrictions.isEmpty()) {
        buff.append("", property=["");
        Iterator<Entry<String, PropertyRestriction>> iterator = propertyRestrictions.entrySet().iterator();
        while (iterator.hasNext()) {
            Entry<String, PropertyRestriction> p = iterator.next();
            buff.append(p.getKey()).append(""="").append(p.getValue());
            if (iterator.hasNext()) {
                buff.append("", "");
            }
        }
        buff.append(""]"");
    }
    buff.append("")"");
    return buff.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2249_6dde8e9d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Statement.java,85,113,"private static void addToUnionList(Expression condition, ArrayList<Expression> unionList) {
    if (condition.containsFullTextCondition()) {
    // do not use union
    } else if (condition instanceof OrCondition) {
        OrCondition or = (OrCondition) condition;
        // conditions of type
        // @x = 1 or @y = 2
        // or similar are converted to
        // (@x = 1) union (@y = 2)
        addToUnionList(or.left, unionList);
        addToUnionList(or.right, unionList);
        return;
    } else if (condition instanceof AndCondition) {
        // conditions of type
        // @a = 1 and (@x = 1 or @y = 2)
        // are automatically converted to
        // (@a = 1 and @x = 1) union (@a = 1 and @y = 2)
        AndCondition and = (AndCondition) condition;
        and = and.pullOrRight();
        if (and.right instanceof OrCondition) {
            OrCondition or = (OrCondition) and.right;
            // same as above, but with the added ""and""
            addToUnionList(new AndCondition(and.left, or.left), unionList);
            addToUnionList(new AndCondition(and.left, or.right), unionList);
            return;
        }
    }
    unionList.add(condition);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2250_08b25cb0,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexDefinition.java,285,301,"private Map<String, PropertyDefinition> collectPropertyDefns(NodeBuilder defn) {
    Map<String, PropertyDefinition> propDefns = newHashMap();
    NodeBuilder propNode = defn.getChildNode(LuceneIndexConstants.PROP_NODE);
    for (String propName : Iterables.concat(includes, orderedProps)) {
        NodeBuilder propDefnNode;
        if (relativeProps.containsKey(propName)) {
            propDefnNode = relativeProps.get(propName).getPropDefnNode(propNode);
        } else {
            propDefnNode = propNode.getChildNode(propName);
        }
        if (propDefnNode.exists()) {
            propDefns.put(propName, new PropertyDefinition(this, propName, propDefnNode));
        }
    }
    return ImmutableMap.copyOf(propDefns);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-225_e33328e0,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/XPathToSQL2Converter.java,355,389,"private Expression parseFunction(String functionName) throws ParseException {
    if (""jcr:like"".equals(functionName)) {
        Condition c = new Condition(parseExpression(), ""like"", null);
        read("","");
        c.right = parseExpression();
        read("")"");
        return c;
    } else if (""jcr:contains"".equals(functionName)) {
        Function f = new Function(""contains"");
        if (readIf(""."")) {
            // special case: jcr:contains(., expr)
            f.params.add(new Literal(""*""));
        } else {
            f.params.add(parseExpression());
        }
        read("","");
        f.params.add(parseExpression());
        read("")"");
        return f;
    } else if (""jcr:score"".equals(functionName)) {
        Function f = new Function(""score"");
        // TODO score: support parameters?
        read("")"");
        return f;
    } else if (""xs:dateTime"".equals(functionName)) {
        Expression expr = parseExpression();
        Cast c = new Cast(expr, ""date"");
        read("")"");
        return c;
    // } else if (""jcr:deref"".equals(functionName)) {
    // TODO support jcr:deref?
    } else {
        throw getSyntaxError(""jcr:like | jcr:contains | jcr:score | jcr:deref"");
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-225_e33328e0,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/XPathToSQL2Converter.java,521,624,"private void read() throws ParseException {
    currentTokenQuoted = false;
    if (expected != null) {
        expected.clear();
    }
    int[] types = characterTypes;
    int i = parseIndex;
    int type = types[i];
    while (type == 0) {
        type = types[++i];
    }
    int start = i;
    char[] chars = statementChars;
    char c = chars[i++];
    currentToken = """";
    switch(type) {
        case CHAR_NAME:
            while (true) {
                type = types[i];
                if (type != CHAR_NAME && type != CHAR_VALUE) {
                    c = chars[i];
                    break;
                }
                i++;
            }
            currentToken = statement.substring(start, i);
            if (currentToken.isEmpty()) {
                throw getSyntaxError();
            }
            currentTokenType = IDENTIFIER;
            parseIndex = i;
            return;
        case CHAR_SPECIAL_2:
            if (types[i] == CHAR_SPECIAL_2) {
                i++;
            }
        // fall through
        case CHAR_SPECIAL_1:
            currentToken = statement.substring(start, i);
            switch(c) {
                case '+':
                    currentTokenType = PLUS;
                    break;
                case '-':
                    currentTokenType = MINUS;
                    break;
                case '(':
                    currentTokenType = OPEN;
                    break;
                case ')':
                    currentTokenType = CLOSE;
                    break;
                default:
                    currentTokenType = KEYWORD;
            }
            parseIndex = i;
            return;
        case CHAR_VALUE:
            long number = c - '0';
            while (true) {
                c = chars[i];
                if (c < '0' || c > '9') {
                    if (c == '.') {
                        readDecimal(start, i);
                        break;
                    }
                    if (c == 'E' || c == 'e') {
                        readDecimal(start, i);
                        break;
                    }
                    currentTokenType = VALUE_NUMBER;
                    currentToken = String.valueOf(number);
                    parseIndex = i;
                    break;
                }
                number = number * 10 + (c - '0');
                if (number > Integer.MAX_VALUE) {
                    readDecimal(start, i);
                    break;
                }
                i++;
            }
            return;
        case CHAR_DECIMAL:
            if (types[i] != CHAR_VALUE) {
                currentTokenType = KEYWORD;
                currentToken = ""."";
                parseIndex = i;
                return;
            }
            readDecimal(i - 1, i);
            return;
        case CHAR_STRING:
            readString(i, '\'');
            return;
        case CHAR_END:
            currentToken = """";
            currentTokenType = END;
            parseIndex = i;
            return;
        default:
            throw getSyntaxError();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2260_0ac7ff20,Major,oak-tarmk-standby/src/main/java/org/apache/jackrabbit/oak/plugins/segment/standby/client/SegmentLoaderHandler.java,133,137,"@Override
public Segment readSegment(final String id) {
    ctx.writeAndFlush(newGetSegmentReq(this.clientID, id));
    return getSegment();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2260_0ac7ff20,Major,oak-tarmk-standby/src/main/java/org/apache/jackrabbit/oak/plugins/segment/standby/client/SegmentLoaderHandler.java,148,167,"// implementation of RemoteSegmentLoader
public Segment getSegment() {
    boolean interrupted = false;
    try {
        for (; ; ) {
            try {
                // log.debug(""polling segment"");
                Segment s = segment.poll(timeoutMs, TimeUnit.MILLISECONDS);
                // log.debug(""returning segment "" + s.getSegmentId());
                return s;
            } catch (InterruptedException ignore) {
                interrupted = true;
            }
        }
    } finally {
        if (interrupted) {
            Thread.currentThread().interrupt();
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2288_57bd2dc5,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1329,1366,"/**
 * Returns <code>true</code> if the given revision
 * {@link Utils#isCommitted(String)} in the revisions map (including
 * revisions split off to previous documents) and is visible from the
 * <code>readRevision</code>.
 *
 * @param revision  the revision to check.
 * @param commitValue the commit value of the revision to check or
 *                    <code>null</code> if unknown.
 * @param readRevision the read revision.
 * @return <code>true</code> if the revision is committed, otherwise
 *         <code>false</code>.
 */
private boolean isCommitted(@Nonnull RevisionContext context, @Nonnull Revision revision, @Nullable String commitValue, @Nonnull Revision readRevision) {
    if (revision.equalsIgnoreBranch(readRevision)) {
        return true;
    }
    if (commitValue == null) {
        commitValue = getCommitValue(revision);
    }
    if (commitValue == null) {
        return false;
    }
    if (Utils.isCommitted(commitValue)) {
        if (context.getBranches().getBranch(readRevision) == null && !readRevision.isBranch()) {
            // resolve commit revision
            revision = Utils.resolveCommitRevision(revision, commitValue);
            // compare resolved revision as is
            return !isRevisionNewer(context, revision, readRevision);
        } else {
            // on same merged branch?
            if (commitValue.equals(getCommitValue(readRevision.asTrunkRevision()))) {
                // compare unresolved revision
                return !isRevisionNewer(context, revision, readRevision);
            }
        }
    } else {
        // branch commit (not merged)
        if (Revision.fromString(commitValue).getClusterId() != context.getClusterId()) {
            // hence never visible to us
            return false;
        }
    }
    return includeRevision(context, Utils.resolveCommitRevision(revision, commitValue), readRevision);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2308_f4d5bbe1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryAgent.java,268,303,"/**
 * Determines the last revision value which needs to set for given clusterId
 * on the passed document. If the last rev entries are consisted
 *
 * @param doc NodeDocument where lastRev entries needs to be fixed
 * @param clusterId clusterId for which lastRev has to be checked
 * @return lastRev which needs to be updated. <tt>null</tt> if no
 *         updated is required i.e. lastRev entries are valid
 */
@CheckForNull
private Revision determineMissedLastRev(NodeDocument doc, int clusterId) {
    Revision currentLastRev = doc.getLastRev().get(clusterId);
    if (currentLastRev == null) {
        currentLastRev = new Revision(0, 0, clusterId);
    }
    ClusterPredicate cp = new ClusterPredicate(clusterId);
    // Merge sort the revs for which changes have been made
    // to this doc
    // localMap always keeps the most recent valid commit entry
    // per cluster node so looking into that should be sufficient
    Iterable<Revision> revs = mergeSorted(of(filter(doc.getLocalCommitRoot().keySet(), cp), filter(doc.getLocalRevisions().keySet(), cp)), StableRevisionComparator.REVERSE);
    // if found then lastRev needs to be fixed
    for (Revision rev : revs) {
        if (rev.compareRevisionTime(currentLastRev) > 0) {
            if (doc.isCommitted(rev)) {
                return rev;
            }
        } else {
            // and no further checks are required
            break;
        }
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2311_ca85ecce,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1383,1387,"@CheckForNull
@Override
public NodeState retrieve(@Nonnull String checkpoint) {
    return getRoot(Revision.fromString(checkpoint));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2318_1d08cbd3,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Revision.java,548,579,"/**
 * Returns the minimum timestamp of the most recent revisions from all
 * active cluster nodes as seen from the given {@code revision}.
 *
 * @param revision a revision.
 * @param inactive map of cluster nodes considered inactive.
 * @return the minimum timestamp.
 */
public long getMinimumTimestamp(@Nonnull Revision revision, @Nonnull Map<Integer, Long> inactive) {
    long timestamp = checkNotNull(revision).getTimestamp();
    Revision seenAt = getRevisionSeen(revision);
    if (seenAt == null) {
        // already purged
        return timestamp;
    }
    // go through all known cluster nodes
    for (List<RevisionRange> list : map.values()) {
        RevisionRange range;
        for (int i = list.size() - 1; i >= 0; i--) {
            range = list.get(i);
            if (range.seenAt.compareRevisionTimeThenClusterId(seenAt) <= 0) {
                // found newest range older or equal the given seenAt
                // check if the cluster node is still active
                Long inactiveSince = inactive.get(range.revision.getClusterId());
                if (inactiveSince != null && revision.getTimestamp() > inactiveSince && range.revision.getTimestamp() < inactiveSince) {
                // ignore, because the revision is after the
                // cluster node became inactive and the most recent
                // range is before it became inactive
                } else {
                    timestamp = Math.min(timestamp, range.revision.getTimestamp());
                }
                break;
            }
        }
    }
    return timestamp;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2330_408a566e,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditor.java,270,331,"private Document makeDocument(String path, NodeState state, boolean isUpdate) throws CommitFailedException {
    if (!isIndexable()) {
        return null;
    }
    List<Field> fields = new ArrayList<Field>();
    boolean dirty = false;
    for (PropertyState property : state.getProperties()) {
        String pname = property.getName();
        if (!isVisible(pname)) {
            continue;
        }
        PropertyDefinition pd = indexingRule.getConfig(pname);
        if (pd == null || !pd.index) {
            continue;
        }
        if (pd.ordered) {
            dirty |= addTypedOrderedFields(fields, property, pname, pd);
        }
        dirty |= indexProperty(path, fields, state, property, pname, false, pd);
    }
    dirty |= indexAggregates(path, fields, state);
    if (isUpdate && !dirty) {
        // updated the state but had no relevant changes
        return null;
    }
    // none of the properties are indexed
    if (!indexingRule.isFulltextEnabled() && !dirty) {
        return null;
    }
    Document document = new Document();
    document.add(newPathField(path));
    String name = getName(path);
    // TODO Possibly index nodeName without tokenization for node name based queries
    if (indexingRule.isFulltextEnabled()) {
        document.add(newFulltextField(name));
    }
    if (getDefinition().evaluatePathRestrictions()) {
        document.add(newAncestorsField(PathUtils.getParentPath(path)));
        document.add(newDepthField(path));
    }
    for (Field f : fields) {
        document.add(f);
    }
    return document;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2330_408a566e,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditor.java,333,371,"private boolean indexProperty(String path, List<Field> fields, NodeState state, PropertyState property, String pname, boolean aggregateMode, PropertyDefinition pd) throws CommitFailedException {
    boolean includeTypeForFullText = indexingRule.includePropertyType(property.getType().tag());
    if (Type.BINARY.tag() == property.getType().tag() && includeTypeForFullText) {
        this.context.indexUpdate();
        fields.addAll(newBinary(property, state, null, path + ""@"" + pname));
        return true;
    } else {
        boolean dirty = false;
        if (pd.propertyIndex && pd.includePropertyType(property.getType().tag())) {
            dirty |= addTypedFields(fields, property, pname);
        }
        if (pd.fulltextEnabled() && includeTypeForFullText) {
            for (String value : property.getValue(Type.STRINGS)) {
                this.context.indexUpdate();
                if (pd.analyzed && pd.includePropertyType(property.getType().tag())) {
                    String analyzedPropName = constructAnalyzedPropertyName(pname);
                    fields.add(newPropertyField(analyzedPropName, value, !pd.skipTokenization(pname), pd.stored));
                }
                if (pd.nodeScopeIndex && !aggregateMode) {
                    Field field = newFulltextField(value);
                    field.setBoost(pd.boost);
                    fields.add(field);
                }
                dirty = true;
            }
        }
        return dirty;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2330_408a566e,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditor.java,516,544,"private boolean indexAggregates(final String path, final List<Field> fields, final NodeState state) throws CommitFailedException {
    final AtomicBoolean dirtyFlag = new AtomicBoolean();
    indexingRule.getAggregate().collectAggregates(state, new Aggregate.ResultCollector() {

        @Override
        public void onResult(Aggregate.NodeIncludeResult result) throws CommitFailedException {
            boolean dirty = indexAggregatedNode(path, fields, result);
            if (dirty) {
                dirtyFlag.set(true);
            }
        }

        @Override
        public void onResult(Aggregate.PropertyIncludeResult result) throws CommitFailedException {
            boolean dirty = false;
            if (result.pd.ordered) {
                dirty |= addTypedOrderedFields(fields, result.propertyState, result.propertyPath, result.pd);
            }
            dirty |= indexProperty(path, fields, state, result.propertyState, result.propertyPath, true, result.pd);
            if (dirty) {
                dirtyFlag.set(true);
            }
        }
    });
    return dirtyFlag.get();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2330_408a566e,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditor.java,528,541,"@Override
public void onResult(Aggregate.PropertyIncludeResult result) throws CommitFailedException {
    boolean dirty = false;
    if (result.pd.ordered) {
        dirty |= addTypedOrderedFields(fields, result.propertyState, result.propertyPath, result.pd);
    }
    dirty |= indexProperty(path, fields, state, result.propertyState, result.propertyPath, true, result.pd);
    if (dirty) {
        dirtyFlag.set(true);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2336_d0f6715d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,749,851,"/**
 * Returns a {@link DocumentNodeState} as seen at the given
 * <code>readRevision</code>.
 *
 * @param nodeStore    the node store.
 * @param readRevision the read revision.
 * @param lastModified the revision when this node was last modified, but
 *                     the value is potentially not yet reflected in this
 *                     document.
 *                     See {@link RevisionContext#getPendingModifications()}.
 * @return the node or <code>null</code> if the node doesn't exist at the
 *         given read revision.
 */
@CheckForNull
public DocumentNodeState getNodeAtRevision(@Nonnull DocumentNodeStore nodeStore, @Nonnull Revision readRevision, @Nullable Revision lastModified) {
    Map<Revision, String> validRevisions = Maps.newHashMap();
    Branch branch = nodeStore.getBranches().getBranch(readRevision);
    LastRevs lastRevs = new LastRevs(getLastRev(), readRevision, branch);
    // overlay with unsaved last modified from this instance
    lastRevs.update(lastModified);
    Revision min = getLiveRevision(nodeStore, readRevision, validRevisions, lastRevs);
    if (min == null) {
        // deleted
        return null;
    }
    String path = getPath();
    DocumentNodeState n = new DocumentNodeState(nodeStore, path, readRevision, hasChildren());
    Revision lastRevision = min;
    for (String key : keySet()) {
        if (!Utils.isPropertyName(key)) {
            continue;
        }
        // first check local map, which contains most recent values
        Value value = getLatestValue(nodeStore, getLocalMap(key), min, readRevision, validRevisions, lastRevs);
        // check if there may be more recent values in a previous document
        if (value != null && !getPreviousRanges().isEmpty()) {
            Revision newest = getLocalMap(key).firstKey();
            if (!value.revision.equals(newest)) {
                // not reading the most recent value, we may need to
                // consider previous documents as well
                Revision newestPrev = getPreviousRanges().firstKey();
                if (isRevisionNewer(nodeStore, newestPrev, value.revision)) {
                    // a previous document has more recent changes
                    // than value.revision
                    value = null;
                }
            }
        }
        if (value == null && !getPreviousRanges().isEmpty()) {
            // check complete revision history
            value = getLatestValue(nodeStore, getValueMap(key), min, readRevision, validRevisions, lastRevs);
        }
        String propertyName = Utils.unescapePropertyName(key);
        String v = value != null ? value.value : null;
        n.setProperty(propertyName, v);
        // keep track of when this node was last modified
        if (value != null && isRevisionNewer(nodeStore, value.revision, lastRevision)) {
            lastRevision = value.revision;
        }
    }
    // lastRevision now points to the revision when this node was
    // last modified directly. but it may also have been 'modified'
    // by an operation on a descendant node, which is tracked in
    // _lastRev.
    // when was this node last modified?
    Revision branchBase = null;
    if (branch != null) {
        branchBase = branch.getBase(readRevision);
    }
    for (Revision r : lastRevs.get().values()) {
        // ignore if newer than readRevision
        if (isRevisionNewer(nodeStore, r, readRevision)) {
            // the node has a _lastRev which is newer than readRevision
            // this means we don't know when this node was
            // modified by an operation on a descendant node between
            // current lastRevision and readRevision. therefore we have
            // to stay on the safe side and use readRevision
            lastRevision = readRevision;
            continue;
        } else if (branchBase != null && isRevisionNewer(nodeStore, r, branchBase)) {
            // readRevision is on a branch and the node has a
            // _lastRev which is newer than the base of the branch
            // we cannot use this _lastRev because it is not visible
            // from this branch. highest possible revision of visible
            // changes is the base of the branch
            r = branchBase;
        }
        if (revisionAreAmbiguous(nodeStore, r, lastRevision)) {
            // _lastRev entries from multiple cluster nodes are ambiguous
            // use readRevision to make sure read is consistent
            lastRevision = readRevision;
        } else if (isRevisionNewer(nodeStore, r, lastRevision)) {
            lastRevision = r;
        }
    }
    if (branch != null) {
        // read from a branch
        // -> possibly overlay with unsaved last revs from branch
        lastRevs.updateBranch(branch.getUnsavedLastRevision(path, readRevision));
        Revision r = lastRevs.getBranchRevision();
        if (r != null) {
            lastRevision = r;
        }
    }
    n.setLastRevision(lastRevision);
    return n;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2345_a0dc4c89,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1510,1566,"/**
 * Perform a background read and make external changes visible.
 *
 * @param dispatchChange whether to dispatch external changes
 *                       to {@link #dispatcher}.
 */
void backgroundRead(boolean dispatchChange) {
    String id = Utils.getIdFromPath(""/"");
    NodeDocument doc = store.find(Collection.NODES, id, asyncDelay);
    if (doc == null) {
        return;
    }
    Map<Integer, Revision> lastRevMap = doc.getLastRev();
    Revision.RevisionComparator revisionComparator = getRevisionComparator();
    // the (old) head occurred first
    Revision headSeen = Revision.newRevision(0);
    // then we saw this new revision (from another cluster node)
    Revision otherSeen = Revision.newRevision(0);
    Map<Revision, Revision> externalChanges = Maps.newHashMap();
    for (Map.Entry<Integer, Revision> e : lastRevMap.entrySet()) {
        int machineId = e.getKey();
        if (machineId == clusterId) {
            // ignore own lastRev
            continue;
        }
        Revision r = e.getValue();
        Revision last = lastKnownRevision.get(machineId);
        if (last == null || r.compareRevisionTime(last) > 0) {
            lastKnownRevision.put(machineId, r);
            externalChanges.put(r, otherSeen);
        }
    }
    if (!externalChanges.isEmpty()) {
        // invalidate caches
        store.invalidateCache();
        // TODO only invalidate affected items
        docChildrenCache.invalidateAll();
        // make sure update to revision comparator is atomic
        // and no local commit is in progress
        backgroundOperationLock.writeLock().lock();
        try {
            // the latest revisions of the current cluster node
            // happened before the latest revisions of other cluster nodes
            revisionComparator.add(newRevision(), headSeen);
            // then we saw other revisions
            for (Map.Entry<Revision, Revision> e : externalChanges.entrySet()) {
                revisionComparator.add(e.getKey(), e.getValue());
            }
            // the new head revision is after other revisions
            setHeadRevision(newRevision());
            if (dispatchChange) {
                dispatcher.contentChanged(getRoot(), null);
            }
        } finally {
            backgroundOperationLock.writeLock().unlock();
        }
    }
    revisionComparator.purge(Revision.getCurrentTimestamp() - REMEMBER_REVISION_ORDER_MILLIS);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2359_b3071839,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,774,876,"/**
 * Returns a {@link DocumentNodeState} as seen at the given
 * <code>readRevision</code>.
 *
 * @param nodeStore    the node store.
 * @param readRevision the read revision.
 * @param lastModified the revision when this node was last modified, but
 *                     the value is potentially not yet reflected in this
 *                     document.
 *                     See {@link RevisionContext#getPendingModifications()}.
 * @return the node or <code>null</code> if the node doesn't exist at the
 *         given read revision.
 */
@CheckForNull
public DocumentNodeState getNodeAtRevision(@Nonnull DocumentNodeStore nodeStore, @Nonnull Revision readRevision, @Nullable Revision lastModified) {
    Map<Revision, String> validRevisions = Maps.newHashMap();
    Branch branch = nodeStore.getBranches().getBranch(readRevision);
    LastRevs lastRevs = new LastRevs(getLastRev(), readRevision, branch);
    // overlay with unsaved last modified from this instance
    lastRevs.update(lastModified);
    Revision min = getLiveRevision(nodeStore, readRevision, validRevisions, lastRevs);
    if (min == null) {
        // deleted
        return null;
    }
    String path = getPath();
    DocumentNodeState n = new DocumentNodeState(nodeStore, path, readRevision, hasChildren());
    Revision lastRevision = min;
    for (String key : keySet()) {
        if (!Utils.isPropertyName(key)) {
            continue;
        }
        // first check local map, which contains most recent values
        Value value = getLatestValue(nodeStore, getLocalMap(key), min, readRevision, validRevisions, lastRevs);
        // check if there may be more recent values in a previous document
        if (value != null && !getPreviousRanges().isEmpty()) {
            Revision newest = getLocalMap(key).firstKey();
            if (isRevisionNewer(nodeStore, newest, value.revision)) {
                // not reading the most recent value, we may need to
                // consider previous documents as well
                Revision newestPrev = getPreviousRanges().firstKey();
                if (isRevisionNewer(nodeStore, newestPrev, value.revision)) {
                    // a previous document has more recent changes
                    // than value.revision
                    value = null;
                }
            }
        }
        if (value == null && !getPreviousRanges().isEmpty()) {
            // check complete revision history
            value = getLatestValue(nodeStore, getValueMap(key), min, readRevision, validRevisions, lastRevs);
        }
        String propertyName = Utils.unescapePropertyName(key);
        String v = value != null ? value.value : null;
        n.setProperty(propertyName, v);
        // keep track of when this node was last modified
        if (value != null && isRevisionNewer(nodeStore, value.revision, lastRevision)) {
            lastRevision = value.revision;
        }
    }
    // lastRevision now points to the revision when this node was
    // last modified directly. but it may also have been 'modified'
    // by an operation on a descendant node, which is tracked in
    // _lastRev.
    // when was this node last modified?
    Revision branchBase = null;
    if (branch != null) {
        branchBase = branch.getBase(readRevision);
    }
    for (Revision r : lastRevs.get().values()) {
        // ignore if newer than readRevision
        if (isRevisionNewer(nodeStore, r, readRevision)) {
            // the node has a _lastRev which is newer than readRevision
            // this means we don't know when this node was
            // modified by an operation on a descendant node between
            // current lastRevision and readRevision. therefore we have
            // to stay on the safe side and use readRevision
            lastRevision = readRevision;
            continue;
        } else if (branchBase != null && isRevisionNewer(nodeStore, r, branchBase)) {
            // readRevision is on a branch and the node has a
            // _lastRev which is newer than the base of the branch
            // we cannot use this _lastRev because it is not visible
            // from this branch. highest possible revision of visible
            // changes is the base of the branch
            r = branchBase;
        }
        if (revisionAreAmbiguous(nodeStore, r, lastRevision)) {
            // _lastRev entries from multiple cluster nodes are ambiguous
            // use readRevision to make sure read is consistent
            lastRevision = readRevision;
        } else if (isRevisionNewer(nodeStore, r, lastRevision)) {
            lastRevision = r;
        }
    }
    if (branch != null) {
        // read from a branch
        // -> possibly overlay with unsaved last revs from branch
        lastRevs.updateBranch(branch.getUnsavedLastRevision(path, readRevision));
        Revision r = lastRevs.getBranchRevision();
        if (r != null) {
            lastRevision = r;
        }
    }
    n.setLastRevision(lastRevision);
    return n;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2359_b3071839,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,890,904,"/**
 * Get the earliest (oldest) revision where the node was alive at or before
 * the provided revision, if the node was alive at the given revision.
 *
 * @param context the revision context
 * @param maxRev the maximum revision to return
 * @param validRevisions the map of revisions to commit value already
 *                       checked against maxRev and considered valid.
 * @param lastRevs to keep track of the last modification.
 * @return the earliest revision, or null if the node is deleted at the
 *         given revision
 */
@CheckForNull
public Revision getLiveRevision(RevisionContext context, Revision maxRev, Map<Revision, String> validRevisions, LastRevs lastRevs) {
    // check local deleted map first
    Value value = getLatestValue(context, getLocalDeleted(), null, maxRev, validRevisions, lastRevs);
    if (value == null && !getPreviousRanges().isEmpty()) {
        // need to check complete map
        value = getLatestValue(context, getDeleted(), null, maxRev, validRevisions, lastRevs);
    }
    return value != null && ""false"".equals(value.value) ? value.revision : null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2359_b3071839,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1451,1490,"/**
 * Get the latest property value that is larger or equal the min revision,
 * and smaller or equal the readRevision revision. A {@code null} return
 * value indicates that the property was not set or removed within the given
 * range. A non-null value means the the property was either set or removed
 * depending on {@link Value#value}.
 *
 * @param valueMap the sorted revision-value map
 * @param min the minimum revision (null meaning unlimited)
 * @param readRevision the maximum revision
 * @param validRevisions map of revision to commit value considered valid
 *                       against the given readRevision.
 * @param lastRevs to keep track of the most recent modification.
 * @return the value, or null if not found
 */
@CheckForNull
private Value getLatestValue(@Nonnull RevisionContext context, @Nonnull Map<Revision, String> valueMap, @Nullable Revision min, @Nonnull Revision readRevision, @Nonnull Map<Revision, String> validRevisions, @Nonnull LastRevs lastRevs) {
    for (Map.Entry<Revision, String> entry : valueMap.entrySet()) {
        Revision propRev = entry.getKey();
        String commitValue = validRevisions.get(propRev);
        if (commitValue == null) {
            // resolve revision
            NodeDocument commitRoot = getCommitRoot(propRev);
            if (commitRoot == null) {
                continue;
            }
            commitValue = commitRoot.getCommitValue(propRev);
            if (commitValue == null) {
                continue;
            }
        }
        Revision commitRev = resolveCommitRevision(propRev, commitValue);
        if (Utils.isCommitted(commitValue)) {
            lastRevs.update(commitRev);
        } else {
            // branch commit
            lastRevs.updateBranch(commitRev.asBranchRevision());
        }
        if (min != null && isRevisionNewer(context, min, commitRev)) {
            continue;
        }
        if (isValidRevision(context, propRev, commitValue, readRevision, validRevisions)) {
            // TODO: need to check older revisions as well?
            return new Value(commitRev, entry.getValue());
        }
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2359_b3071839,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ValueMap.java,45,146,"@Nonnull
static Map<Revision, String> create(@Nonnull final NodeDocument doc, @Nonnull final String property) {
    final SortedMap<Revision, String> map = doc.getLocalMap(property);
    if (doc.getPreviousRanges().isEmpty()) {
        return map;
    }
    final Set<Map.Entry<Revision, String>> entrySet = new AbstractSet<Map.Entry<Revision, String>>() {

        @Override
        @Nonnull
        public Iterator<Map.Entry<Revision, String>> iterator() {
            final Comparator<? super Revision> c = map.comparator();
            final Iterator<NodeDocument> docs;
            if (map.isEmpty()) {
                docs = doc.getPreviousDocs(property, null).iterator();
            } else {
                docs = Iterators.concat(Iterators.singletonIterator(doc), doc.getPreviousDocs(property, null).iterator());
            }
            return new MergeSortedIterators<Map.Entry<Revision, String>>(new Comparator<Map.Entry<Revision, String>>() {

                @Override
                public int compare(Map.Entry<Revision, String> o1, Map.Entry<Revision, String> o2) {
                    return c.compare(o1.getKey(), o2.getKey());
                }
            }) {

                @Override
                public Iterator<Map.Entry<Revision, String>> nextIterator() {
                    NodeDocument d = docs.hasNext() ? docs.next() : null;
                    if (d == null) {
                        return null;
                    }
                    Map<Revision, String> values;
                    if (Objects.equal(d.getId(), doc.getId())) {
                        // return local map for main document
                        values = d.getLocalMap(property);
                    } else {
                        values = d.getValueMap(property);
                    }
                    return values.entrySet().iterator();
                }

                @Override
                public String description() {
                    return ""Revisioned values for property "" + doc.getId() + ""/"" + property + "":"";
                }
            };
        }

        @Override
        public int size() {
            int size = map.size();
            for (NodeDocument prev : doc.getPreviousDocs(property, null)) {
                size += prev.getValueMap(property).size();
            }
            return size;
        }
    };
    return new AbstractMap<Revision, String>() {

        private final Map<Revision, String> map = doc.getLocalMap(property);

        @Override
        @Nonnull
        public Set<Entry<Revision, String>> entrySet() {
            return entrySet;
        }

        @Override
        public String get(Object key) {
            // first check values map of this document
            String value = map.get(key);
            if (value != null) {
                return value;
            }
            Revision r = (Revision) key;
            for (NodeDocument prev : doc.getPreviousDocs(property, r)) {
                value = prev.getValueMap(property).get(key);
                if (value != null) {
                    return value;
                }
            }
            // not found
            return null;
        }

        @Override
        public boolean containsKey(Object key) {
            // the values map does not have null values
            return get(key) != null;
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2359_b3071839,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ValueMap.java,121,137,"@Override
public String get(Object key) {
    // first check values map of this document
    String value = map.get(key);
    if (value != null) {
        return value;
    }
    Revision r = (Revision) key;
    for (NodeDocument prev : doc.getPreviousDocs(property, r)) {
        value = prev.getValueMap(property).get(key);
        if (value != null) {
            return value;
        }
    }
    // not found
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2359_b3071839,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ValueMap.java,139,144,"@Override
public boolean containsKey(Object key) {
    // the values map does not have null values
    return get(key) != null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2363_90ea7aa5,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1403,1412,"@CheckForNull
@Override
public NodeState retrieve(@Nonnull String checkpoint) {
    Revision r = Revision.fromString(checkpoint);
    if (checkpoints.getCheckpoints().containsKey(r)) {
        return getRoot(r);
    } else {
        return null;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2388_487de751,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/OakDirectory.java,251,274,"public void readBytes(byte[] b, int offset, int len) throws IOException {
    checkPositionIndexes(offset, offset + len, checkNotNull(b).length);
    if (len < 0 || position + len > length) {
        throw new IOException(""Invalid byte range request"");
    }
    int i = (int) (position / blobSize);
    int o = (int) (position % blobSize);
    while (len > 0) {
        loadBlob(i);
        int l = Math.min(len, blobSize - o);
        System.arraycopy(blob, o, b, offset, l);
        offset += l;
        len -= l;
        position += l;
        i++;
        o = 0;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2389_0fa892b3,Major,oak-commons/src/main/java/org/apache/jackrabbit/oak/commons/json/JsopBuilder.java,247,266,"/**
 * Convert a string to a quoted Json literal using the correct escape
 * sequences. The literal is enclosed in double quotes. Characters outside
 * the range 32..127 are encoded (backslash u xxxx). The forward slash
 * (solidus) is not escaped. Null is encoded as ""null"" (without quotes).
 *
 * @param s the text to convert
 * @return the Json representation (including double quotes)
 */
public static String encode(String s) {
    if (s == null) {
        return ""null"";
    }
    int length = s.length();
    if (length == 0) {
        return ""\""\"""";
    }
    for (int i = 0; i < length; i++) {
        char c = s.charAt(i);
        if (c == '\""' || c == '\\' || c < ' ') {
            StringBuilder buff = new StringBuilder(length + 2 + length / 8);
            buff.append('\""');
            escape(s, length, buff);
            return buff.append('\""').toString();
        }
    }
    StringBuilder buff = new StringBuilder(length + 2);
    return buff.append('\""').append(s).append('\""').toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2389_0fa892b3,Major,oak-commons/src/main/java/org/apache/jackrabbit/oak/commons/json/JsopBuilder.java,285,337,"/**
 * Escape a string into the target buffer.
 *
 * @param s      the string to escape
 * @param length the number of characters.
 * @param buff   the target buffer
 */
private static void escape(String s, int length, StringBuilder buff) {
    for (int i = 0; i < length; i++) {
        char c = s.charAt(i);
        int ic = (int) c;
        switch(c) {
            case '""':
                // quotation mark
                buff.append(""\\\"""");
                break;
            case '\\':
                // backslash
                buff.append(""\\\\"");
                break;
            case '\b':
                // backspace
                buff.append(""\\b"");
                break;
            case '\f':
                // formfeed
                buff.append(""\\f"");
                break;
            case '\n':
                // newline
                buff.append(""\\n"");
                break;
            case '\r':
                // carriage return
                buff.append(""\\r"");
                break;
            case '\t':
                // horizontal tab
                buff.append(""\\t"");
                break;
            default:
                if (c < ' ') {
                    buff.append(String.format(""\\u%04x"", ic));
                } else if (ic >= 0xD800 && ic <= 0xDBFF) {
                    // isSurrogate(), only available in Java 7
                    if (i < length - 1 && Character.isSurrogatePair(c, s.charAt(i + 1))) {
                        // ok surrogate
                        buff.append(c);
                        buff.append(s.charAt(i + 1));
                        i += 1;
                    } else {
                        // broken surrogate -> escape
                        buff.append(String.format(""\\u%04x"", ic));
                    }
                } else {
                    buff.append(c);
                }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2389_7c320b1e,Major,oak-commons/src/main/java/org/apache/jackrabbit/oak/commons/json/JsopBuilder.java,247,266,"/**
 * Convert a string to a quoted Json literal using the correct escape
 * sequences. The literal is enclosed in double quotes. Characters outside
 * the range 32..127 are encoded (backslash u xxxx). The forward slash
 * (solidus) is not escaped. Null is encoded as ""null"" (without quotes).
 *
 * @param s the text to convert
 * @return the Json representation (including double quotes)
 */
public static String encode(String s) {
    if (s == null) {
        return ""null"";
    }
    int length = s.length();
    if (length == 0) {
        return ""\""\"""";
    }
    for (int i = 0; i < length; i++) {
        char c = s.charAt(i);
        if (c == '\""' || c == '\\' || c < ' ' || c >= 127) {
            StringBuilder buff = new StringBuilder(length + 2 + length / 8);
            buff.append('\""');
            escape(s, length, buff);
            return buff.append('\""').toString();
        }
    }
    StringBuilder buff = new StringBuilder(length + 2);
    return buff.append('\""').append(s).append('\""').toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2389_7c320b1e,Major,oak-commons/src/main/java/org/apache/jackrabbit/oak/commons/json/JsopBuilder.java,275,332,"/**
 * Escape a string into the target buffer.
 *
 * @param s      the string to escape
 * @param length the number of characters.
 * @param buff   the target buffer
 */
public static void escape(String s, int length, StringBuilder buff) {
    // needs more time, memory, and storage space
    for (int i = 0; i < length; i++) {
        char c = s.charAt(i);
        switch(c) {
            case '""':
                // quotation mark
                buff.append(""\\\"""");
                break;
            case '\\':
                // backslash
                buff.append(""\\\\"");
                break;
            case '\b':
                // backspace
                buff.append(""\\b"");
                break;
            case '\f':
                // formfeed
                buff.append(""\\f"");
                break;
            case '\n':
                // newline
                buff.append(""\\n"");
                break;
            case '\r':
                // carriage return
                buff.append(""\\r"");
                break;
            case '\t':
                // horizontal tab
                buff.append(""\\t"");
                break;
            default:
                if (c < ' ') {
                    // guaranteed to be 1 or 2 hex digits only
                    buff.append(""\\u00"");
                    String hex = Integer.toHexString(c);
                    if (hex.length() == 1) {
                        buff.append('0');
                    }
                    buff.append(hex);
                } else if (c >= 127) {
                    // ascii only mode
                    buff.append(""\\u"");
                    String hex = Integer.toHexString(c);
                    for (int len = hex.length(); len < 4; len++) {
                        buff.append('0');
                    }
                    buff.append(hex);
                } else {
                    buff.append(c);
                }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2389_8079f7b5,Major,oak-commons/src/main/java/org/apache/jackrabbit/oak/commons/json/JsopBuilder.java,285,328,"/**
 * Escape a string into the target buffer.
 *
 * @param s      the string to escape
 * @param length the number of characters.
 * @param buff   the target buffer
 */
private static void escape(String s, int length, StringBuilder buff) {
    for (int i = 0; i < length; i++) {
        char c = s.charAt(i);
        switch(c) {
            case '""':
                // quotation mark
                buff.append(""\\\"""");
                break;
            case '\\':
                // backslash
                buff.append(""\\\\"");
                break;
            case '\b':
                // backspace
                buff.append(""\\b"");
                break;
            case '\f':
                // formfeed
                buff.append(""\\f"");
                break;
            case '\n':
                // newline
                buff.append(""\\n"");
                break;
            case '\r':
                // carriage return
                buff.append(""\\r"");
                break;
            case '\t':
                // horizontal tab
                buff.append(""\\t"");
                break;
            default:
                if (c < ' ') {
                    buff.append(""\\u00"");
                    // guaranteed to be 1 or 2 hex digits only
                    buff.append(Character.forDigit(c >>> 4, 16));
                    buff.append(Character.forDigit(c & 15, 16));
                } else {
                    buff.append(c);
                }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-238_24ce6788,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/value/ValueFactoryImpl.java,146,205,"@Override
public Value createValue(String value, int type) throws ValueFormatException {
    if (value == null) {
        throw new ValueFormatException();
    }
    try {
        CoreValue cv;
        switch(type) {
            case PropertyType.NAME:
                String oakName = namePathMapper.getOakName(value);
                if (oakName == null) {
                    throw new ValueFormatException(""Invalid name: "" + value);
                }
                cv = factory.createValue(oakName, type);
                break;
            case PropertyType.PATH:
                // TODO we special case identifier paths here for now
                // eventually this should be done in the path mapper (OAK-23)
                String oakValue;
                if (value.startsWith(""["") && value.endsWith(""]"")) {
                    oakValue = value;
                } else {
                    oakValue = namePathMapper.getOakPath(value);
                    if (oakValue == null) {
                        throw new ValueFormatException(""Invalid path: "" + value);
                    }
                }
                cv = factory.createValue(oakValue, type);
                break;
            case PropertyType.DATE:
                if (ISO8601.parse(value) == null) {
                    throw new ValueFormatException(""Invalid date "" + value);
                }
                cv = factory.createValue(value, type);
                break;
            case PropertyType.BINARY:
                cv = factory.createValue(new ByteArrayInputStream(value.getBytes(""UTF-8"")));
                break;
            default:
                cv = factory.createValue(value, type);
                break;
        }
        return new ValueImpl(cv, namePathMapper);
    } catch (UnsupportedEncodingException e) {
        throw new ValueFormatException(""Encoding UTF-8 not supported (this should not happen!)"", e);
    } catch (IOException e) {
        throw new ValueFormatException(e);
    } catch (NumberFormatException e) {
        throw new ValueFormatException(""Invalid value "" + value + "" for type "" + PropertyType.nameFromValue(type));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2418_039f892d,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/query/FilterIterators.java,198,219,"private void init() {
    if (result != null) {
        return;
    }
    ArrayList<K> list = new ArrayList<K>();
    while (source.hasNext()) {
        K x = source.next();
        list.add(x);
        checkMemoryLimit(list.size(), settings);
        // which is close to the optimum O(n*log(keep))
        if (list.size() > max * 2) {
            // remove tail entries right now, to save memory
            Collections.sort(list, orderBy);
            keepFirst(list, max);
        }
    }
    Collections.sort(list, orderBy);
    keepFirst(list, max);
    result = list.iterator();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2420_24cb1908,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,868,930,"/**
 * Returns the child documents at the given {@code path} and returns up to
 * {@code limit} documents. The returned child documents are sorted in
 * ascending child node name order. If a {@code name} is passed, the first
 * child document returned is after the given name. That is, the name is the
 * lower exclusive bound.
 *
 * @param path the path of the parent document.
 * @param name the lower exclusive bound or {@code null}.
 * @param limit the maximum number of child documents to return.
 * @return the child documents.
 */
@Nonnull
Iterable<NodeDocument> readChildDocs(@Nonnull final String path, @Nullable String name, int limit) {
    String to = Utils.getKeyUpperLimit(checkNotNull(path));
    String from;
    if (name != null) {
        from = Utils.getIdFromPath(concat(path, name));
    } else {
        from = Utils.getKeyLowerLimit(path);
    }
    if (name != null || limit > NUM_CHILDREN_CACHE_LIMIT) {
        // or more than 16k child docs are requested
        return store.query(Collection.NODES, from, to, limit);
    }
    StringValue key = new StringValue(path);
    // check cache
    NodeDocument.Children c = docChildrenCache.getIfPresent(key);
    if (c == null) {
        c = new NodeDocument.Children();
        List<NodeDocument> docs = store.query(Collection.NODES, from, to, limit);
        for (NodeDocument doc : docs) {
            String p = doc.getPath();
            c.childNames.add(PathUtils.getName(p));
        }
        c.isComplete = docs.size() < limit;
        docChildrenCache.put(key, c);
        return docs;
    } else if (c.childNames.size() < limit && !c.isComplete) {
        // fetch more and update cache
        String lastName = c.childNames.get(c.childNames.size() - 1);
        String lastPath = concat(path, lastName);
        from = Utils.getIdFromPath(lastPath);
        int remainingLimit = limit - c.childNames.size();
        List<NodeDocument> docs = store.query(Collection.NODES, from, to, remainingLimit);
        NodeDocument.Children clone = c.clone();
        for (NodeDocument doc : docs) {
            String p = doc.getPath();
            clone.childNames.add(PathUtils.getName(p));
        }
        clone.isComplete = docs.size() < remainingLimit;
        docChildrenCache.put(key, clone);
        c = clone;
    }
    Iterable<NodeDocument> it = transform(c.childNames, new Function<String, NodeDocument>() {

        @Override
        public NodeDocument apply(String name) {
            String p = concat(path, name);
            NodeDocument doc = store.find(Collection.NODES, Utils.getIdFromPath(p));
            if (doc == null) {
                docChildrenCache.invalidateAll();
                throw new NullPointerException(""Document "" + p + "" not found"");
            }
            return doc;
        }
    });
    if (c.childNames.size() > limit * 2) {
        it = Iterables.limit(it, limit * 2);
    }
    return it;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2420_24cb1908,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,915,924,"@Override
public NodeDocument apply(String name) {
    String p = concat(path, name);
    NodeDocument doc = store.find(Collection.NODES, Utils.getIdFromPath(p));
    if (doc == null) {
        docChildrenCache.invalidateAll();
        throw new NullPointerException(""Document "" + p + "" not found"");
    }
    return doc;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2426_920f32d0,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/Aggregate.java,241,251,"@Override
public void collectResults(NodeInclude rootInclude, String rootIncludePath, String nodePath, NodeState nodeState, ResultCollector results) throws CommitFailedException {
    // For supporting jcr:contains(jcr:content, 'foo')
    if (rootInclude != this && rootInclude.relativeNode) {
        results.onResult(new NodeIncludeResult(nodePath, rootIncludePath, nodeState));
    }
    // For supporting jcr:contains(., 'foo')
    results.onResult(new NodeIncludeResult(nodePath, nodeState));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2426_920f32d0,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/Aggregate.java,511,517,"public void collectResults(ResultCollector results) throws CommitFailedException {
    checkArgument(status == Status.MATCH_FOUND);
    String rootIncludePath = aggregateStack.isEmpty() ? null : aggregateStack.get(0);
    currentInclude.collectResults(rootState.rootInclude, rootIncludePath, currentPath, matchedNodeState, results);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2427_e6d4f9a6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Statement.java,113,193,"@Override
public String toString() {
    StringBuilder buff = new StringBuilder();
    // explain | measure ...
    if (explain) {
        buff.append(""explain "");
    } else if (measure) {
        buff.append(""measure "");
    }
    // select ...
    buff.append(""select "");
    buff.append(new Expression.Property(columnSelector, QueryImpl.JCR_PATH, false).toString());
    if (selectors.size() > 1) {
        buff.append("" as "").append('[').append(QueryImpl.JCR_PATH).append(']');
    }
    buff.append("", "");
    buff.append(new Expression.Property(columnSelector, QueryImpl.JCR_SCORE, false).toString());
    if (selectors.size() > 1) {
        buff.append("" as "").append('[').append(QueryImpl.JCR_SCORE).append(']');
    }
    if (columnList.isEmpty()) {
        buff.append("", "");
        buff.append(new Expression.Property(columnSelector, ""*"", false).toString());
    } else {
        for (int i = 0; i < columnList.size(); i++) {
            buff.append("", "");
            Expression e = columnList.get(i);
            String columnName = e.toString();
            buff.append(columnName);
            if (selectors.size() > 1) {
                buff.append("" as ["").append(e.getColumnAliasName()).append(""]"");
            }
        }
    }
    // from ...
    buff.append("" from "");
    for (int i = 0; i < selectors.size(); i++) {
        Selector s = selectors.get(i);
        if (i > 0) {
            buff.append("" inner join "");
        }
        String nodeType = s.nodeType;
        if (nodeType == null) {
            nodeType = ""nt:base"";
        }
        buff.append('[' + nodeType + ']').append("" as "").append(s.name);
        if (s.joinCondition != null) {
            buff.append("" on "").append(s.joinCondition);
        }
    }
    // where ...
    if (where != null) {
        buff.append("" where "").append(where.toString());
    }
    // order by ...
    if (!orderList.isEmpty()) {
        buff.append("" order by "");
        for (int i = 0; i < orderList.size(); i++) {
            if (i > 0) {
                buff.append("", "");
            }
            buff.append(orderList.get(i));
        }
    }
    // leave original xpath string as a comment
    if (xpathQuery != null) {
        buff.append("" /* xpath: "");
        // the xpath query may not contain the ""end comment"" marker
        String xpathEscaped = xpathQuery.replaceAll(""\\*\\/"", ""* /"");
        buff.append(xpathEscaped);
        buff.append("" */"");
    }
    return buff.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2427_e6d4f9a6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/Statement.java,239,260,"@Override
public String toString() {
    StringBuilder buff = new StringBuilder();
    buff.append(s1).append("" union "").append(s2);
    // order by ...
    if (orderList != null && !orderList.isEmpty()) {
        buff.append("" order by "");
        for (int i = 0; i < orderList.size(); i++) {
            if (i > 0) {
                buff.append("", "");
            }
            buff.append(orderList.get(i));
        }
    }
    // leave original xpath string as a comment
    if (xpathQuery != null) {
        buff.append("" /* xpath: "");
        buff.append(xpathQuery);
        buff.append("" */"");
    }
    return buff.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2430_be3a9114,Major,oak-tarmk-standby/src/main/java/org/apache/jackrabbit/oak/plugins/segment/standby/client/StandbyApplyDiff.java,71,78,"@Override
public boolean propertyAdded(PropertyState after) {
    if (!loader.isRunning()) {
        return false;
    }
    builder.setProperty(binaryCheck(after));
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2430_be3a9114,Major,oak-tarmk-standby/src/main/java/org/apache/jackrabbit/oak/plugins/segment/standby/client/StandbyApplyDiff.java,80,87,"@Override
public boolean propertyChanged(PropertyState before, PropertyState after) {
    if (!loader.isRunning()) {
        return false;
    }
    builder.setProperty(binaryCheck(after));
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2430_be3a9114,Major,oak-tarmk-standby/src/main/java/org/apache/jackrabbit/oak/plugins/segment/standby/client/StandbyApplyDiff.java,89,96,"@Override
public boolean propertyDeleted(PropertyState before) {
    if (!loader.isRunning()) {
        return false;
    }
    builder.removeProperty(before.getName());
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2430_be3a9114,Major,oak-tarmk-standby/src/main/java/org/apache/jackrabbit/oak/plugins/segment/standby/client/StandbyApplyDiff.java,141,153,"@Override
public boolean childNodeAdded(String name, NodeState after) {
    if (!loader.isRunning()) {
        return false;
    }
    NodeBuilder child = EmptyNodeState.EMPTY_NODE.builder();
    boolean success = EmptyNodeState.compareAgainstEmptyState(after, new StandbyApplyDiff(child, store, loader, path + name + ""/""));
    if (success) {
        builder.setChildNode(name, child.getNodeState());
    }
    return success;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2430_be3a9114,Major,oak-tarmk-standby/src/main/java/org/apache/jackrabbit/oak/plugins/segment/standby/client/StandbyApplyDiff.java,155,164,"@Override
public boolean childNodeChanged(String name, NodeState before, NodeState after) {
    if (!loader.isRunning()) {
        return false;
    }
    return after.compareAgainstBaseState(before, new StandbyApplyDiff(builder.getChildNode(name), store, loader, path + name + ""/""));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2430_be3a9114,Major,oak-tarmk-standby/src/main/java/org/apache/jackrabbit/oak/plugins/segment/standby/client/StandbyApplyDiff.java,166,173,"@Override
public boolean childNodeDeleted(String name, NodeState before) {
    if (!loader.isRunning()) {
        return false;
    }
    builder.getChildNode(name).remove();
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2433_7fca85bf,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ValueMap.java,45,153,"@Nonnull
static Map<Revision, String> create(@Nonnull final NodeDocument doc, @Nonnull final String property) {
    final SortedMap<Revision, String> map = doc.getLocalMap(property);
    if (doc.getPreviousRanges().isEmpty()) {
        return map;
    }
    final Set<Map.Entry<Revision, String>> entrySet = new AbstractSet<Map.Entry<Revision, String>>() {

        @Override
        @Nonnull
        public Iterator<Map.Entry<Revision, String>> iterator() {
            final Comparator<? super Revision> c = map.comparator();
            final Iterator<NodeDocument> docs;
            if (map.isEmpty()) {
                docs = doc.getPreviousDocs(property, null).iterator();
            } else {
                docs = Iterators.concat(Iterators.singletonIterator(doc), doc.getPreviousDocs(property, null).iterator());
            }
            return new MergeSortedIterators<Map.Entry<Revision, String>>(new Comparator<Map.Entry<Revision, String>>() {

                @Override
                public int compare(Map.Entry<Revision, String> o1, Map.Entry<Revision, String> o2) {
                    return c.compare(o1.getKey(), o2.getKey());
                }
            }) {

                @Override
                public Iterator<Map.Entry<Revision, String>> nextIterator() {
                    NodeDocument d = docs.hasNext() ? docs.next() : null;
                    if (d == null) {
                        return null;
                    }
                    Map<Revision, String> values;
                    if (Objects.equal(d.getId(), doc.getId())) {
                        // return local map for main document
                        values = d.getLocalMap(property);
                    } else {
                        values = d.getValueMap(property);
                    }
                    return values.entrySet().iterator();
                }

                @Override
                public String description() {
                    return ""Revisioned values for property "" + doc.getId() + ""/"" + property + "":"";
                }
            };
        }

        @Override
        public int size() {
            int size = map.size();
            for (NodeDocument prev : doc.getPreviousDocs(property, null)) {
                size += prev.getValueMap(property).size();
            }
            return size;
        }
    };
    return new AbstractMap<Revision, String>() {

        private final Map<Revision, String> map = doc.getLocalMap(property);

        @Override
        @Nonnull
        public Set<Entry<Revision, String>> entrySet() {
            return entrySet;
        }

        @Override
        public String get(Object key) {
            Revision r = (Revision) key;
            // first check values map of this document
            if (map.containsKey(r)) {
                return map.get(r);
            }
            for (NodeDocument prev : doc.getPreviousDocs(property, r)) {
                String value = prev.getValueMap(property).get(r);
                if (value != null) {
                    return value;
                }
            }
            // not found or null
            return null;
        }

        @Override
        public boolean containsKey(Object key) {
            // check local map first
            if (map.containsKey(key)) {
                return true;
            }
            Revision r = (Revision) key;
            for (NodeDocument prev : doc.getPreviousDocs(property, r)) {
                if (prev.getValueMap(property).containsKey(key)) {
                    return true;
                }
            }
            return false;
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2433_7fca85bf,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ValueMap.java,55,99,"@Override
@Nonnull
public Iterator<Map.Entry<Revision, String>> iterator() {
    final Comparator<? super Revision> c = map.comparator();
    final Iterator<NodeDocument> docs;
    if (map.isEmpty()) {
        docs = doc.getPreviousDocs(property, null).iterator();
    } else {
        docs = Iterators.concat(Iterators.singletonIterator(doc), doc.getPreviousDocs(property, null).iterator());
    }
    return new MergeSortedIterators<Map.Entry<Revision, String>>(new Comparator<Map.Entry<Revision, String>>() {

        @Override
        public int compare(Map.Entry<Revision, String> o1, Map.Entry<Revision, String> o2) {
            return c.compare(o1.getKey(), o2.getKey());
        }
    }) {

        @Override
        public Iterator<Map.Entry<Revision, String>> nextIterator() {
            NodeDocument d = docs.hasNext() ? docs.next() : null;
            if (d == null) {
                return null;
            }
            Map<Revision, String> values;
            if (Objects.equal(d.getId(), doc.getId())) {
                // return local map for main document
                values = d.getLocalMap(property);
            } else {
                values = d.getValueMap(property);
            }
            return values.entrySet().iterator();
        }

        @Override
        public String description() {
            return ""Revisioned values for property "" + doc.getId() + ""/"" + property + "":"";
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2433_7fca85bf,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/util/MergeSortedIterators.java,97,109,"// ----------------------------< internal >----------------------------------
private void fetchNextIterator() {
    Iterator<T> it = nextIterator();
    if (it != null && it.hasNext()) {
        PeekingIterator<T> pIt = Iterators.peekingIterator(it);
        if (!iterators.isEmpty() && comparator.compare(pIt.peek(), lastPeek) < 0) {
            throw new IllegalStateException(description() + "" First element of next iterator must be greater than previous iterator"");
        }
        lastPeek = pIt.peek();
        iterators.add(pIt);
        adjustLast();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2434_8159fc21,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,700,769,"static Query getFullTextQuery(FullTextExpression ft, final Analyzer analyzer, final IndexReader reader) {
    // a reference to the query, so it can be set in the visitor
    // (a ""non-local return"")
    final AtomicReference<Query> result = new AtomicReference<Query>();
    ft.accept(new FullTextVisitor() {

        @Override
        public boolean visit(FullTextContains contains) {
            return contains.getBase().accept(this);
        }

        @Override
        public boolean visit(FullTextOr or) {
            BooleanQuery q = new BooleanQuery();
            for (FullTextExpression e : or.list) {
                Query x = getFullTextQuery(e, analyzer, reader);
                q.add(x, SHOULD);
            }
            result.set(q);
            return true;
        }

        @Override
        public boolean visit(FullTextAnd and) {
            BooleanQuery q = new BooleanQuery();
            for (FullTextExpression e : and.list) {
                Query x = getFullTextQuery(e, analyzer, reader);
                // Lucene can't deal with ""must(must_not(x))""
                if (x instanceof BooleanQuery) {
                    BooleanQuery bq = (BooleanQuery) x;
                    for (BooleanClause c : bq.clauses()) {
                        q.add(c);
                    }
                } else {
                    q.add(x, MUST);
                }
            }
            result.set(q);
            return true;
        }

        @Override
        public boolean visit(FullTextTerm term) {
            return visitTerm(term.getPropertyName(), term.getText(), term.getBoost(), term.isNot());
        }

        private boolean visitTerm(String propertyName, String text, String boost, boolean not) {
            String p = propertyName;
            if (p != null && p.indexOf('/') >= 0) {
                p = getName(p);
            }
            Query q = tokenToQuery(text, p, analyzer, reader);
            if (q == null) {
                return false;
            }
            if (boost != null) {
                q.setBoost(Float.parseFloat(boost));
            }
            if (not) {
                BooleanQuery bq = new BooleanQuery();
                bq.add(q, MUST_NOT);
                result.set(bq);
            } else {
                result.set(q);
            }
            return true;
        }
    });
    return result.get();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2434_8159fc21,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,722,739,"@Override
public boolean visit(FullTextAnd and) {
    BooleanQuery q = new BooleanQuery();
    for (FullTextExpression e : and.list) {
        Query x = getFullTextQuery(e, analyzer, reader);
        // Lucene can't deal with ""must(must_not(x))""
        if (x instanceof BooleanQuery) {
            BooleanQuery bq = (BooleanQuery) x;
            for (BooleanClause c : bq.clauses()) {
                q.add(c);
            }
        } else {
            q.add(x, MUST);
        }
    }
    result.set(q);
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2434_8159fc21,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java,809,878,"static Query getFullTextQuery(final IndexPlan plan, FullTextExpression ft, final Analyzer analyzer) {
    final PlanResult pr = pr(plan);
    // a reference to the query, so it can be set in the visitor
    // (a ""non-local return"")
    final AtomicReference<Query> result = new AtomicReference<Query>();
    ft.accept(new FullTextVisitor() {

        @Override
        public boolean visit(FullTextContains contains) {
            visitTerm(contains.getPropertyName(), contains.getRawText(), null, false);
            return true;
        }

        @Override
        public boolean visit(FullTextOr or) {
            BooleanQuery q = new BooleanQuery();
            for (FullTextExpression e : or.list) {
                Query x = getFullTextQuery(plan, e, analyzer);
                q.add(x, SHOULD);
            }
            result.set(q);
            return true;
        }

        @Override
        public boolean visit(FullTextAnd and) {
            BooleanQuery q = new BooleanQuery();
            for (FullTextExpression e : and.list) {
                Query x = getFullTextQuery(plan, e, analyzer);
                // Lucene can't deal with ""must(must_not(x))""
                if (x instanceof BooleanQuery) {
                    BooleanQuery bq = (BooleanQuery) x;
                    for (BooleanClause c : bq.clauses()) {
                        q.add(c);
                    }
                } else {
                    q.add(x, MUST);
                }
            }
            result.set(q);
            return true;
        }

        @Override
        public boolean visit(FullTextTerm term) {
            return visitTerm(term.getPropertyName(), term.getText(), term.getBoost(), term.isNot());
        }

        private boolean visitTerm(String propertyName, String text, String boost, boolean not) {
            String p = getLuceneFieldName(propertyName, pr);
            Query q = tokenToQuery(text, p, analyzer);
            if (q == null) {
                return false;
            }
            if (boost != null) {
                q.setBoost(Float.parseFloat(boost));
            }
            if (not) {
                BooleanQuery bq = new BooleanQuery();
                bq.add(q, MUST_NOT);
                result.set(bq);
            } else {
                result.set(q);
            }
            return true;
        }
    });
    return result.get();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2434_8159fc21,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java,834,851,"@Override
public boolean visit(FullTextAnd and) {
    BooleanQuery q = new BooleanQuery();
    for (FullTextExpression e : and.list) {
        Query x = getFullTextQuery(plan, e, analyzer);
        // Lucene can't deal with ""must(must_not(x))""
        if (x instanceof BooleanQuery) {
            BooleanQuery bq = (BooleanQuery) x;
            for (BooleanClause c : bq.clauses()) {
                q.add(c);
            }
        } else {
            q.add(x, MUST);
        }
    }
    result.set(q);
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2435_7e250001,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,366,374,"@Override
public boolean equals(Object obj) {
    if (obj instanceof Key) {
        Key other = (Key) obj;
        return name.equals(other.name) && revision != null ? revision.equals(other.revision) : other.revision == null;
    }
    return false;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2439_beaca1a4,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexPlanner.java,102,192,"private IndexPlan.Builder getPlanBuilder() {
    log.trace(""Evaluating plan with index definition {}"", defn);
    FullTextExpression ft = filter.getFullTextConstraint();
    if (!defn.getVersion().isAtLeast(IndexFormatVersion.V2)) {
        log.trace(""Index is old format. Not supported"");
        return null;
    }
    // Query Fulltext and Index does not support fulltext
    if (ft != null && !defn.isFullTextEnabled()) {
        return null;
    }
    IndexingRule indexingRule = getApplicableRule();
    if (indexingRule == null) {
        return null;
    }
    // Query Fulltext and indexing rule does not support fulltext
    if (ft != null && !indexingRule.isFulltextEnabled()) {
        return null;
    }
    result = new PlanResult(indexPath, defn, indexingRule);
    if (defn.hasFunctionDefined() && filter.getPropertyRestriction(defn.getFunctionName()) != null) {
        // that lowest cost if returned
        return defaultPlan().setEstimatedEntryCount(1);
    }
    List<String> indexedProps = newArrayListWithCapacity(filter.getPropertyRestrictions().size());
    // for property index
    if (indexingRule.propertyIndexEnabled) {
        for (PropertyRestriction pr : filter.getPropertyRestrictions()) {
            PropertyDefinition pd = indexingRule.getConfig(pr.propertyName);
            if (pd != null && pd.propertyIndexEnabled()) {
                indexedProps.add(pr.propertyName);
                result.propDefns.put(pr.propertyName, pd);
            }
        }
    }
    boolean evalPathRestrictions = canEvalPathRestrictions(indexingRule);
    boolean canEvalAlFullText = canEvalAllFullText(indexingRule, ft);
    if (ft != null && !canEvalAlFullText) {
        return null;
    }
    // Fulltext expression can also be like jcr:contains(jcr:content/metadata/@format, 'image')
    List<OrderEntry> sortOrder = createSortOrder(indexingRule);
    if (!indexedProps.isEmpty() || !sortOrder.isEmpty() || ft != null || evalPathRestrictions) {
        // TODO Need a way to have better cost estimate to indicate that
        // this index can evaluate more propertyRestrictions natively (if more props are indexed)
        // For now we reduce cost per entry
        int costPerEntryFactor = indexedProps.size();
        costPerEntryFactor += sortOrder.size();
        // this index can evaluate more propertyRestrictions natively (if more props are indexed)
        // For now we reduce cost per entry
        IndexPlan.Builder plan = defaultPlan();
        if (!sortOrder.isEmpty()) {
            plan.setSortOrder(sortOrder);
        }
        if (costPerEntryFactor == 0) {
            costPerEntryFactor = 1;
        }
        if (ft == null) {
            result.enableNonFullTextConstraints();
        }
        return plan.setCostPerEntry(defn.getCostPerEntry() / costPerEntryFactor);
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2442_ea7a6199,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,783,885,"/**
 * Returns a {@link DocumentNodeState} as seen at the given
 * <code>readRevision</code>.
 *
 * @param nodeStore    the node store.
 * @param readRevision the read revision.
 * @param lastModified the revision when this node was last modified, but
 *                     the value is potentially not yet reflected in this
 *                     document.
 *                     See {@link RevisionContext#getPendingModifications()}.
 * @return the node or <code>null</code> if the node doesn't exist at the
 *         given read revision.
 */
@CheckForNull
public DocumentNodeState getNodeAtRevision(@Nonnull DocumentNodeStore nodeStore, @Nonnull Revision readRevision, @Nullable Revision lastModified) {
    Map<Revision, String> validRevisions = Maps.newHashMap();
    Branch branch = nodeStore.getBranches().getBranch(readRevision);
    LastRevs lastRevs = new LastRevs(getLastRev(), readRevision, branch);
    // overlay with unsaved last modified from this instance
    lastRevs.update(lastModified);
    Revision min = getLiveRevision(nodeStore, readRevision, validRevisions, lastRevs);
    if (min == null) {
        // deleted
        return null;
    }
    String path = getPath();
    DocumentNodeState n = new DocumentNodeState(nodeStore, path, readRevision, hasChildren());
    Revision lastRevision = min;
    for (String key : keySet()) {
        if (!Utils.isPropertyName(key)) {
            continue;
        }
        // first check local map, which contains most recent values
        Value value = getLatestValue(nodeStore, getLocalMap(key), min, readRevision, validRevisions, lastRevs);
        // check if there may be more recent values in a previous document
        if (!getPreviousRanges().isEmpty()) {
            Revision newest = getLocalMap(key).firstKey();
            if (isRevisionNewer(nodeStore, newest, value.revision)) {
                // not reading the most recent value, we may need to
                // consider previous documents as well
                Revision newestPrev = getPreviousRanges().firstKey();
                if (isRevisionNewer(nodeStore, newestPrev, value.revision)) {
                    // a previous document has more recent changes
                    // than value.revision
                    value = null;
                }
            }
        }
        if (value == null && !getPreviousRanges().isEmpty()) {
            // check complete revision history
            value = getLatestValue(nodeStore, getValueMap(key), min, readRevision, validRevisions, lastRevs);
        }
        String propertyName = Utils.unescapePropertyName(key);
        String v = value != null ? value.value : null;
        n.setProperty(propertyName, v);
        // keep track of when this node was last modified
        if (value != null && isRevisionNewer(nodeStore, value.revision, lastRevision)) {
            lastRevision = value.revision;
        }
    }
    // lastRevision now points to the revision when this node was
    // last modified directly. but it may also have been 'modified'
    // by an operation on a descendant node, which is tracked in
    // _lastRev.
    // when was this node last modified?
    Revision branchBase = null;
    if (branch != null) {
        branchBase = branch.getBase(readRevision);
    }
    for (Revision r : lastRevs.get().values()) {
        // ignore if newer than readRevision
        if (isRevisionNewer(nodeStore, r, readRevision)) {
            // the node has a _lastRev which is newer than readRevision
            // this means we don't know when this node was
            // modified by an operation on a descendant node between
            // current lastRevision and readRevision. therefore we have
            // to stay on the safe side and use readRevision
            lastRevision = readRevision;
            continue;
        } else if (branchBase != null && isRevisionNewer(nodeStore, r, branchBase)) {
            // readRevision is on a branch and the node has a
            // _lastRev which is newer than the base of the branch
            // we cannot use this _lastRev because it is not visible
            // from this branch. highest possible revision of visible
            // changes is the base of the branch
            r = branchBase;
        }
        if (revisionAreAmbiguous(nodeStore, r, lastRevision)) {
            // _lastRev entries from multiple cluster nodes are ambiguous
            // use readRevision to make sure read is consistent
            lastRevision = readRevision;
        } else if (isRevisionNewer(nodeStore, r, lastRevision)) {
            lastRevision = r;
        }
    }
    if (branch != null) {
        // read from a branch
        // -> possibly overlay with unsaved last revs from branch
        lastRevs.updateBranch(branch.getUnsavedLastRevision(path, readRevision));
        Revision r = lastRevs.getBranchRevision();
        if (r != null) {
            lastRevision = r;
        }
    }
    n.setLastRevision(lastRevision);
    return n;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2465_60186813,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/PermissionEntryProviderImpl.java,63,82,"private void init() {
    long cnt = 0;
    existingNames.clear();
    for (String name : principalNames) {
        long n = cache.getNumEntries(store, name, maxSize);
        cnt += n;
        if (n > 0) {
            existingNames.add(name);
        }
    }
    if (cnt < maxSize) {
        // cache all entries of all principals
        pathEntryMap = new HashMap<String, Collection<PermissionEntry>>();
        for (String name : principalNames) {
            cache.load(store, pathEntryMap, name);
        }
    } else {
        pathEntryMap = null;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2528_239de7b8,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java,114,150,"private List<UpdateOp> create() {
    if (!considerSplit()) {
        return Collections.emptyList();
    }
    splitOps = Lists.newArrayList();
    mostRecentRevs = Sets.newHashSet();
    splitRevs = Sets.newHashSet();
    garbage = Maps.newHashMap();
    committedChanges = getCommittedLocalChanges();
    // revisions of the most recent committed changes on this document
    // these are kept in the main document. _revisions and _commitRoot
    // entries with these revisions are retained in the main document
    populateSplitRevs();
    // collect _revisions and _commitRoot entries for split document
    collectRevisionsAndCommitRoot();
    // create split ops out of the split values
    main = createSplitOps();
    // create intermediate docs if needed
    createIntermediateDocs();
    // remove stale references to previous docs
    disconnectStalePrevDocs();
    // remove garbage
    removeGarbage();
    // main document must be updated last
    if (main != null) {
        splitOps.add(main);
    }
    return splitOps;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2528_239de7b8,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java,190,224,"/**
 * Collect _revisions and _commitRoot entries that can be moved to a
 * previous document.
 */
private void collectRevisionsAndCommitRoot() {
    NavigableMap<Revision, String> revisions = new TreeMap<Revision, String>(context.getRevisionComparator());
    for (Map.Entry<Revision, String> entry : doc.getLocalRevisions().entrySet()) {
        if (splitRevs.contains(entry.getKey())) {
            revisions.put(entry.getKey(), entry.getValue());
            numValues++;
        } else {
            // local changes
            if (context.getClusterId() != entry.getKey().getClusterId()) {
                // only consider local changes
                continue;
            }
            if (doc.isCommitted(entry.getKey()) && !mostRecentRevs.contains(entry.getKey())) {
                // this is a commit root for changes in other documents
                revisions.put(entry.getKey(), entry.getValue());
                numValues++;
                trackHigh(entry.getKey());
                trackLow(entry.getKey());
            }
        }
    }
    committedChanges.put(REVISIONS, revisions);
    NavigableMap<Revision, String> commitRoot = new TreeMap<Revision, String>(context.getRevisionComparator());
    for (Map.Entry<Revision, String> entry : doc.getLocalCommitRoot().entrySet()) {
        if (splitRevs.contains(entry.getKey())) {
            commitRoot.put(entry.getKey(), entry.getValue());
            numValues++;
        }
    }
    committedChanges.put(COMMIT_ROOT, commitRoot);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2528_239de7b8,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java,358,381,"/**
 * Returns a map of all local property changes committed by the current
 * cluster node.
 *
 * @return local changes committed by the current cluster node.
 */
@Nonnull
private Map<String, NavigableMap<Revision, String>> getCommittedLocalChanges() {
    Map<String, NavigableMap<Revision, String>> committedLocally = new HashMap<String, NavigableMap<Revision, String>>();
    for (String property : filter(doc.keySet(), PROPERTY_OR_DELETED)) {
        NavigableMap<Revision, String> splitMap = new TreeMap<Revision, String>(context.getRevisionComparator());
        committedLocally.put(property, splitMap);
        Map<Revision, String> valueMap = doc.getLocalMap(property);
        // collect committed changes of this cluster node
        for (Map.Entry<Revision, String> entry : valueMap.entrySet()) {
            Revision rev = entry.getKey();
            if (rev.getClusterId() != context.getClusterId()) {
                continue;
            }
            if (doc.isCommitted(rev)) {
                splitMap.put(rev, entry.getValue());
            } else if (isGarbage(rev)) {
                addGarbage(rev, property);
            }
        }
    }
    return committedLocally;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2528_239de7b8,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java,394,401,"private void addGarbage(Revision rev, String property) {
    Set<Revision> revisions = garbage.get(property);
    if (revisions == null) {
        revisions = Sets.newHashSet();
        garbage.put(property, revisions);
    }
    revisions.add(rev);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2528_239de7b8,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java,438,451,"private void removeGarbage() {
    if (garbage.isEmpty()) {
        return;
    } else if (main == null) {
        main = new UpdateOp(id, false);
    }
    for (Map.Entry<String, Set<Revision>> entry : garbage.entrySet()) {
        for (Revision r : entry.getValue()) {
            main.removeMapEntry(entry.getKey(), r);
            NodeDocument.removeCommitRoot(main, r);
            NodeDocument.removeRevision(main, r);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2559_dfa87520,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexDefinition.java,698,712,"/**
 * @param propertyName name of a property.
 * @return the property configuration or <code>null</code> if this
 *         indexing rule does not contain a configuration for the given
 *         property.
 */
@CheckForNull
public PropertyDefinition getConfig(String propertyName) {
    PropertyDefinition config = propConfigs.get(propertyName);
    if (config != null) {
        return config;
    } else if (namePatterns.size() > 0) {
        // check patterns
        for (NamePattern np : namePatterns) {
            if (np.matches(propertyName)) {
                return np.getConfig();
            }
        }
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2559_dfa87520,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexDefinition.java,739,777,"private Map<String, PropertyDefinition> collectPropConfigs(NodeState config, List<NamePattern> patterns, List<Aggregate.Include> propAggregate, List<PropertyDefinition> nonExistentProperties) {
    Map<String, PropertyDefinition> propDefns = newHashMap();
    NodeState propNode = config.getChildNode(LuceneIndexConstants.PROP_NODE);
    if (!propNode.exists()) {
        return Collections.emptyMap();
    }
    if (!hasOrderableChildren(propNode)) {
        log.warn(""Properties node for [{}] does not have orderable "" + ""children in [{}]"", this, IndexDefinition.this);
    }
    // Include all immediate child nodes to 'properties' node by default
    Tree propTree = TreeFactory.createReadOnlyTree(propNode);
    for (Tree prop : propTree.getChildren()) {
        String propName = prop.getName();
        NodeState propDefnNode = propNode.getChildNode(propName);
        if (propDefnNode.exists() && !propDefns.containsKey(propName)) {
            PropertyDefinition pd = new PropertyDefinition(this, propName, propDefnNode);
            if (pd.isRegexp) {
                patterns.add(new NamePattern(pd.name, pd));
            } else {
                propDefns.put(pd.name, pd);
            }
            if (pd.relative) {
                propAggregate.add(new Aggregate.PropertyInclude(pd));
            }
            if (pd.nullCheckEnabled) {
                nonExistentProperties.add(pd);
            }
        }
    }
    return ImmutableMap.copyOf(propDefns);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2603_77d2d3b0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/VersionGarbageCollector.java,91,120,"private void collectDeletedDocuments(VersionGCStats stats, Revision headRevision, long oldestRevTimeStamp) {
    List<String> docIdsToDelete = new ArrayList<String>();
    Iterable<NodeDocument> itr = versionStore.getPossiblyDeletedDocs(oldestRevTimeStamp);
    try {
        for (NodeDocument doc : itr) {
            // So deleting it is safe
            if (doc.getNodeAtRevision(nodeStore, headRevision, null) == null) {
                docIdsToDelete.add(doc.getId());
                // Collect id of all previous docs also
                for (NodeDocument prevDoc : ImmutableList.copyOf(doc.getAllPreviousDocs())) {
                    docIdsToDelete.add(prevDoc.getId());
                }
            }
        }
    } finally {
        Utils.closeIfCloseable(itr);
    }
    if (log.isDebugEnabled()) {
        StringBuilder sb = new StringBuilder(""Deleted document with following ids were deleted as part of GC \n"");
        Joiner.on(StandardSystemProperty.LINE_SEPARATOR.value()).appendTo(sb, docIdsToDelete);
        log.debug(sb.toString());
    }
    nodeStore.getDocumentStore().remove(Collection.NODES, docIdsToDelete);
    nodeStore.invalidateDocChildrenCache();
    stats.deletedDocGCCount += docIdsToDelete.size();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2642_36fe017c,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,461,496,"public void dispose() {
    runBackgroundOperations();
    if (!isDisposed.getAndSet(true)) {
        synchronized (isDisposed) {
            isDisposed.notifyAll();
        }
        try {
            backgroundThread.join();
        } catch (InterruptedException e) {
        // ignore
        }
        if (leaseUpdateThread != null) {
            try {
                leaseUpdateThread.join();
            } catch (InterruptedException e) {
            // ignore
            }
        }
        if (clusterNodeInfo != null) {
            clusterNodeInfo.dispose();
        }
        store.dispose();
        LOG.info(""Disposed DocumentNodeStore with clusterNodeId: {}"", clusterId);
        if (blobStore instanceof Closeable) {
            try {
                ((Closeable) blobStore).close();
            } catch (IOException ex) {
                LOG.debug(""Error closing blob store "" + blobStore, ex);
            }
        }
    }
    if (persistentCache != null) {
        persistentCache.close();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2642_36fe017c,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,540,558,"/**
 * Creates a new commit. The caller must acknowledge the commit either with
 * {@link #done(Commit, boolean, CommitInfo)} or {@link #canceled(Commit)},
 * depending on the result of the commit.
 *
 * @param base the base revision for the commit or <code>null</code> if the
 *             commit should use the current head revision as base.
 * @param branch the branch instance if this is a branch commit. The life
 *               time of this branch commit is controlled by the
 *               reachability of this parameter. Once {@code branch} is
 *               weakly reachable, the document store implementation is
 *               free to remove the commits associated with the branch.
 * @return a new commit.
 */
@Nonnull
Commit newCommit(@Nullable Revision base, @Nullable DocumentNodeStoreBranch branch) {
    if (base == null) {
        base = headRevision;
    }
    backgroundOperationLock.readLock().lock();
    boolean success = false;
    Commit c;
    try {
        c = new Commit(this, commitQueue.createRevision(), base, branch);
        success = true;
    } finally {
        if (!success) {
            backgroundOperationLock.readLock().unlock();
        }
    }
    return c;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2642_36fe017c,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,570,587,"/**
 * Creates a new merge commit. The caller must acknowledge the commit either with
 * {@link #done(Commit, boolean, CommitInfo)} or {@link #canceled(Commit)},
 * depending on the result of the commit.
 *
 * @param base the base revision for the commit or <code>null</code> if the
 *             commit should use the current head revision as base.
 * @param numBranchCommits the number of branch commits to merge.
 * @return a new merge commit.
 */
@Nonnull
MergeCommit newMergeCommit(@Nullable Revision base, int numBranchCommits) {
    if (base == null) {
        base = headRevision;
    }
    backgroundOperationLock.readLock().lock();
    boolean success = false;
    MergeCommit c;
    try {
        c = new MergeCommit(this, base, commitQueue.createRevisions(numBranchCommits));
        success = true;
    } finally {
        if (!success) {
            backgroundOperationLock.readLock().unlock();
        }
    }
    return c;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2642_36fe017c,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1505,1545,"// ----------------------< background operations >---------------------------
public synchronized void runBackgroundOperations() {
    if (isDisposed.get()) {
        return;
    }
    if (simpleRevisionCounter != null) {
        // only when using timestamp
        return;
    }
    try {
        long start = clock.getTime();
        long time = start;
        // clean orphaned branches and collisions
        cleanOrphanedBranches();
        cleanCollisions();
        long cleanTime = clock.getTime() - time;
        time = clock.getTime();
        // split documents (does not create new revisions)
        backgroundSplit();
        long splitTime = clock.getTime() - time;
        time = clock.getTime();
        // write back pending updates to _lastRev
        backgroundWrite();
        long writeTime = clock.getTime() - time;
        time = clock.getTime();
        // pull in changes from other cluster nodes
        BackgroundReadStats readStats = backgroundRead(true);
        long readTime = clock.getTime() - time;
        String msg = ""Background operations stats (clean:{}, split:{}, write:{}, read:{} {})"";
        if (clock.getTime() - start > TimeUnit.SECONDS.toMillis(10)) {
            // log as info if it took more than 10 seconds
            LOG.info(msg, cleanTime, splitTime, writeTime, readTime, readStats);
        } else {
            LOG.debug(msg, cleanTime, splitTime, writeTime, readTime, readStats);
        }
    } catch (RuntimeException e) {
        if (isDisposed.get()) {
            return;
        }
        throw e;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2649_72d24f4b,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,186,221,"private void copy(final FileReference reference) {
    executor.execute(new Runnable() {

        @Override
        public void run() {
            String name = reference.name;
            try {
                if (!local.fileExists(name)) {
                    long start = System.currentTimeMillis();
                    remote.copy(local, name, name, IOContext.READ);
                    reference.markValid();
                    downloadTime.addAndGet(System.currentTimeMillis() - start);
                    downloadSize.addAndGet(remote.fileLength(name));
                } else {
                    long localLength = local.fileLength(name);
                    long remoteLength = remote.fileLength(name);
                    // updated but still do a check if the copy is consistent
                    if (localLength != remoteLength) {
                        log.warn(""Found local copy for {} in {} but size of local {} differs from remote {}. "" + ""Content would be read from remote file only"", name, local, localLength, remoteLength);
                        invalidFileCount.incrementAndGet();
                    } else {
                        reference.markValid();
                    }
                }
            } catch (IOException e) {
                // TODO In case of exception there would not be any other attempt
                // to download the file. Look into support for retry
                log.warn(""Error occurred while copying file [{}] "" + ""from {} to {}"", name, remote, local, e);
            }
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2649_72d24f4b,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,188,219,"@Override
public void run() {
    String name = reference.name;
    try {
        if (!local.fileExists(name)) {
            long start = System.currentTimeMillis();
            remote.copy(local, name, name, IOContext.READ);
            reference.markValid();
            downloadTime.addAndGet(System.currentTimeMillis() - start);
            downloadSize.addAndGet(remote.fileLength(name));
        } else {
            long localLength = local.fileLength(name);
            long remoteLength = remote.fileLength(name);
            // updated but still do a check if the copy is consistent
            if (localLength != remoteLength) {
                log.warn(""Found local copy for {} in {} but size of local {} differs from remote {}. "" + ""Content would be read from remote file only"", name, local, localLength, remoteLength);
                invalidFileCount.incrementAndGet();
            } else {
                reference.markValid();
            }
        }
    } catch (IOException e) {
        // TODO In case of exception there would not be any other attempt
        // to download the file. Look into support for retry
        log.warn(""Error occurred while copying file [{}] "" + ""from {} to {}"", name, remote, local, e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2691_d2da7499,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/identifier/ClusterRepositoryInfo.java,60,62,"/**
 * Retrieves the {# CLUSTER_ID_PROP}
 *
 * @param store the NodeStore instance
 * @return the repository id
 */
public static String getId(NodeStore store) {
    return store.getRoot().getChildNode(CLUSTER_CONFIG_NODE).getProperty(CLUSTER_ID_PROP).getValue(Type.STRING);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2695_0598498e,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeState.java,168,183,"@Nonnull
@Override
public NodeState getChildNode(@Nonnull String name) {
    if (!hasChildren) {
        checkValidName(name);
        return EmptyNodeState.MISSING_NODE;
    }
    String p = PathUtils.concat(getPath(), name);
    DocumentNodeState child = store.getNode(p, lastRevision);
    if (child == null) {
        checkValidName(name);
        return EmptyNodeState.MISSING_NODE;
    } else {
        return child;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2695_0598498e,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1883,1944,"private boolean dispatch(@Nonnull String jsonDiff, @Nonnull DocumentNodeState node, @Nonnull DocumentNodeState base, @Nonnull NodeStateDiff diff, boolean useReadRevision) {
    if (jsonDiff.trim().isEmpty()) {
        return true;
    }
    Revision nodeRev = useReadRevision ? node.getRevision() : node.getLastRevision();
    Revision baseRev = useReadRevision ? base.getRevision() : base.getLastRevision();
    JsopTokenizer t = new JsopTokenizer(jsonDiff);
    boolean continueComparison = true;
    while (continueComparison) {
        int r = t.read();
        if (r == JsopReader.END) {
            break;
        }
        switch(r) {
            case '+':
                {
                    String name = unshareString(t.readString());
                    t.read(':');
                    t.read('{');
                    while (t.read() != '}') {
                    // skip properties
                    }
                    NodeState child = getNode(concat(node.getPath(), name), nodeRev);
                    continueComparison = diff.childNodeAdded(name, child);
                    break;
                }
            case '-':
                {
                    String name = unshareString(t.readString());
                    NodeState child = getNode(concat(base.getPath(), name), baseRev);
                    continueComparison = diff.childNodeDeleted(name, child);
                    break;
                }
            case '^':
                {
                    String name = unshareString(t.readString());
                    t.read(':');
                    if (t.matches('{')) {
                        t.read('}');
                        NodeState nodeChild = getNode(concat(node.getPath(), name), nodeRev);
                        NodeState baseChild = getNode(concat(base.getPath(), name), baseRev);
                        continueComparison = diff.childNodeChanged(name, baseChild, nodeChild);
                    } else if (t.matches('[')) {
                        // ignore multi valued property
                        while (t.read() != ']') {
                        // skip values
                        }
                    } else {
                        // ignore single valued property
                        t.read();
                    }
                    break;
                }
            default:
                throw new IllegalArgumentException(""jsonDiff: illegal token '"" + t.getToken() + ""' at pos: "" + t.getLastPos() + ' ' + jsonDiff);
        }
    }
    return continueComparison;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2740_429baf4d,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/AuthorizationContext.java,47,51,"@Override
public boolean definesContextRoot(@Nonnull Tree tree) {
    String name = tree.getName();
    return POLICY_NODE_NAMES.contains(name) || REP_PERMISSION_STORE.equals(name);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,56,83,"// ---------------------------------------------------< Persistence >
public void initialize(File homeDir) throws Exception {
    File dbDir = new File(homeDir, ""db"");
    if (!dbDir.exists()) {
        dbDir.mkdirs();
    }
    Driver.load();
    String url = ""jdbc:h2:"" + dbDir.getCanonicalPath() + ""/revs"";
    if (FAST) {
        url += "";log=0;undo_log=0"";
    }
    cp = JdbcConnectionPool.create(url, ""sa"", """");
    cp.setMaxConnections(40);
    Connection con = cp.getConnection();
    try {
        Statement stmt = con.createStatement();
        stmt.execute(""create table if not exists REVS(ID binary primary key, DATA binary, TIME timestamp)"");
        stmt.execute(""create table if not exists HEAD(ID binary) as select null"");
        stmt.execute(""create sequence if not exists DATASTORE_ID"");
    /*
            DbBlobStore store = new DbBlobStore();
            store.setConnectionPool(cp);
            blobStore = store;
*/
    } finally {
        con.close();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,89,103,"public Id readHead() throws Exception {
    Connection con = cp.getConnection();
    try {
        PreparedStatement stmt = con.prepareStatement(""select * from HEAD"");
        ResultSet rs = stmt.executeQuery();
        byte[] rawId = null;
        if (rs.next()) {
            rawId = rs.getBytes(1);
        }
        stmt.close();
        return rawId == null ? null : new Id(rawId);
    } finally {
        con.close();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,117,137,"public void readNode(StoredNode node) throws NotFoundException, Exception {
    Id id = node.getId();
    Connection con = cp.getConnection();
    try {
        PreparedStatement stmt = con.prepareStatement(""select DATA from REVS where ID = ?"");
        try {
            stmt.setBytes(1, id.getBytes());
            ResultSet rs = stmt.executeQuery();
            if (rs.next()) {
                ByteArrayInputStream in = new ByteArrayInputStream(rs.getBytes(1));
                node.deserialize(new BinaryBinding(in));
            } else {
                throw new NotFoundException(id.toString());
            }
        } finally {
            stmt.close();
        }
    } finally {
        con.close();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,139,165,"public Id writeNode(Node node) throws Exception {
    ByteArrayOutputStream out = new ByteArrayOutputStream();
    node.serialize(new BinaryBinding(out));
    byte[] bytes = out.toByteArray();
    byte[] rawId = idFactory.createContentId(bytes);
    Timestamp ts = new Timestamp(System.currentTimeMillis());
    // String id = StringUtils.convertBytesToHex(rawId);
    Connection con = cp.getConnection();
    try {
        PreparedStatement stmt = con.prepareStatement(""insert into REVS (ID, DATA, TIME) select ?, ?, ? where not exists (select 1 from REVS where ID = ?)"");
        try {
            stmt.setBytes(1, rawId);
            stmt.setBytes(2, bytes);
            stmt.setTimestamp(3, ts);
            stmt.setBytes(4, rawId);
            stmt.executeUpdate();
        } finally {
            stmt.close();
        }
    } finally {
        con.close();
    }
    return new Id(rawId);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,212,231,"public ChildNodeEntriesMap readCNEMap(Id id) throws NotFoundException, Exception {
    Connection con = cp.getConnection();
    try {
        PreparedStatement stmt = con.prepareStatement(""select DATA from REVS where ID = ?"");
        try {
            stmt.setBytes(1, id.getBytes());
            ResultSet rs = stmt.executeQuery();
            if (rs.next()) {
                ByteArrayInputStream in = new ByteArrayInputStream(rs.getBytes(1));
                return ChildNodeEntriesMap.deserialize(new BinaryBinding(in));
            } else {
                throw new NotFoundException(id.toString());
            }
        } finally {
            stmt.close();
        }
    } finally {
        con.close();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,233,258,"public Id writeCNEMap(ChildNodeEntries map) throws Exception {
    ByteArrayOutputStream out = new ByteArrayOutputStream();
    map.serialize(new BinaryBinding(out));
    byte[] bytes = out.toByteArray();
    byte[] rawId = idFactory.createContentId(bytes);
    Timestamp ts = new Timestamp(System.currentTimeMillis());
    Connection con = cp.getConnection();
    try {
        PreparedStatement stmt = con.prepareStatement(""insert into REVS (ID, DATA, TIME) select ?, ?, ? where not exists (select 1 from REVS where ID = ?)"");
        try {
            stmt.setBytes(1, rawId);
            stmt.setBytes(2, bytes);
            stmt.setTimestamp(3, ts);
            stmt.setBytes(4, rawId);
            stmt.executeUpdate();
        } finally {
            stmt.close();
        }
    } finally {
        con.close();
    }
    return new Id(rawId);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,265,268,"@Override
public boolean markCommit(Id id) throws Exception {
    return touch(id, gcStart);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,293,296,"@Override
public boolean markNode(Id id) throws Exception {
    return touch(id, gcStart);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,298,301,"@Override
public boolean markCNEMap(Id id) throws Exception {
    return touch(id, gcStart);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,303,322,"private boolean touch(Id id, long timeMillis) throws Exception {
    Timestamp ts = new Timestamp(timeMillis);
    Connection con = cp.getConnection();
    try {
        PreparedStatement stmt = con.prepareStatement(""update REVS set TIME = ? where ID = ? and TIME < ?"");
        try {
            stmt.setTimestamp(1, ts);
            stmt.setBytes(2, id.getBytes());
            stmt.setTimestamp(3, ts);
            return stmt.executeUpdate() == 1;
        } finally {
            stmt.close();
        }
    } finally {
        con.close();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/H2Persistence.java,324,342,"@Override
public int sweep() throws Exception {
    Timestamp ts = new Timestamp(gcStart);
    Connection con = cp.getConnection();
    try {
        PreparedStatement stmt = con.prepareStatement(""delete REVS where TIME < ?"");
        try {
            stmt.setTimestamp(1, ts);
            return stmt.executeUpdate();
        } finally {
            stmt.close();
        }
    } finally {
        con.close();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/InMemPersistence.java,56,58,"public Id readHead() {
    return head;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/InMemPersistence.java,60,62,"public void writeHead(Id id) {
    head = id;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/persistence/Persistence.java,39,39,Id readHead() throws Exception;
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-276_1bf5c550,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/store/DefaultRevisionStore.java,128,173,"public void initialize() throws Exception {
    if (initialized) {
        throw new IllegalStateException(""already initialized"");
    }
    initialCacheSize = determineInitialCacheSize();
    cache = Collections.synchronizedMap(SimpleLRUCache.<Id, Object>newInstance(initialCacheSize));
    // make sure we've got a HEAD commit
    head = pm.readHead();
    if (head == null || head.getBytes().length == 0) {
        // assume virgin repository
        byte[] rawHead = Id.fromLong(commitCounter.incrementAndGet()).getBytes();
        head = new Id(rawHead);
        Id rootNodeId = pm.writeNode(new MutableNode(this));
        MutableCommit initialCommit = new MutableCommit();
        initialCommit.setCommitTS(System.currentTimeMillis());
        initialCommit.setRootNodeId(rootNodeId);
        pm.writeCommit(head, initialCommit);
        pm.writeHead(head);
    } else {
        commitCounter.set(Long.parseLong(head.toString(), 16));
    }
    if (gcpm != null) {
        gcExecutor = Executors.newScheduledThreadPool(1, new ThreadFactory() {

            @Override
            public Thread newThread(Runnable r) {
                return new Thread(r, ""RevisionStore-GC"");
            }
        });
        gcExecutor.scheduleWithFixedDelay(new Runnable() {

            @Override
            public void run() {
                if (cache.size() >= initialCacheSize) {
                    gc();
                }
            }
        }, 10, 1, TimeUnit.MINUTES);
    }
    initialized = true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-278_db19e70f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,247,263,"@Override
public boolean remove() {
    if (isRemoved()) {
        throw new IllegalStateException(""Cannot remove removed tree"");
    }
    if (!isRoot() && parent.hasChild(name)) {
        NodeBuilder builder = parent.getNodeBuilder();
        builder.removeNode(name);
        parent.children.remove(name);
        parent = this;
        root.purge();
        return true;
    } else {
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-278_db19e70f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,392,433,"private Status internalGetPropertyStatus(String name) {
    NodeState baseState = getBaseState();
    boolean exists = internalGetProperty(name) != null;
    if (baseState == null) {
        // This instance is NEW...
        if (exists) {
            // ...so all children are new
            return Status.NEW;
        } else {
            // ...unless they don't exist.
            return null;
        }
    } else {
        if (exists) {
            // We have the property...
            if (baseState.getProperty(name) == null) {
                // ...but didn't have it before. So its NEW.
                return Status.NEW;
            } else {
                // ... and did have it before. So...
                PropertyState base = baseState.getProperty(name);
                PropertyState head = getProperty(name);
                if (base == null ? head == null : base.equals(head)) {
                    // ...it's EXISTING if it hasn't changed
                    return Status.EXISTING;
                } else {
                    // ...and MODIFIED otherwise.
                    return Status.MODIFIED;
                }
            }
        } else {
            // We don't have the property
            if (baseState.getProperty(name) == null) {
                // ...and didn't have it before. So it doesn't exist.
                return null;
            } else {
                // ...but did have it before. So it's REMOVED
                return Status.REMOVED;
            }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-278_db19e70f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,435,437,"private boolean isRemoved() {
    return parent == this;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-278_db19e70f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,439,448,"private void buildPath(StringBuilder sb) {
    if (isRemoved()) {
        throw new IllegalStateException(""Cannot build the path of a removed tree"");
    }
    if (!isRoot()) {
        parent.buildPath(sb);
        sb.append('/').append(name);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2799_3979fa8d,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/OakDirectory.java,378,381,"@Override
public OakIndexInput clone() {
    return new OakIndexInput(this);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2799_3979fa8d,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/OakDirectory.java,383,386,"@Override
public void readBytes(byte[] b, int o, int n) throws IOException {
    file.readBytes(b, o, n);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2799_3979fa8d,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/OakDirectory.java,388,393,"@Override
public byte readByte() throws IOException {
    byte[] b = new byte[1];
    readBytes(b, 0, 1);
    return b[0];
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2799_3979fa8d,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/OakDirectory.java,410,414,"@Override
public void close() {
    file.blob = null;
    file.data = null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2864_f51ea2a2,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/XPathToSQL2Converter.java,496,526,"private Expression parseExpression() throws ParseException {
    if (readIf(""@"")) {
        return readProperty();
    } else if (readIf(""true"")) {
        return Expression.Literal.newBoolean(true);
    } else if (readIf(""false"")) {
        return Expression.Literal.newBoolean(false);
    } else if (currentTokenType == VALUE_NUMBER) {
        Expression.Literal l = Expression.Literal.newNumber(currentToken);
        read();
        return l;
    } else if (currentTokenType == VALUE_STRING) {
        Expression.Literal l = Expression.Literal.newString(currentToken);
        read();
        return l;
    } else if (readIf(""-"")) {
        if (currentTokenType != VALUE_NUMBER) {
            throw getSyntaxError();
        }
        Expression.Literal l = Expression.Literal.newNumber('-' + currentToken);
        read();
        return l;
    } else if (readIf(""+"")) {
        if (currentTokenType != VALUE_NUMBER) {
            throw getSyntaxError();
        }
        return parseExpression();
    } else {
        return parsePropertyOrFunction();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2929_a2950285,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,722,785,"/**
 * Get the revision of the latest change made to this node.
 *
 * @param context the revision context
 * @param changeRev the revision of the current change
 * @param handler the conflict handler, which is called for concurrent changes
 *                preceding <code>changeRev</code>.
 * @return the revision, or null if deleted
 */
@CheckForNull
public Revision getNewestRevision(final RevisionContext context, final Revision changeRev, final CollisionHandler handler) {
    final Map<Revision, String> validRevisions = Maps.newHashMap();
    Predicate<Revision> predicate = new Predicate<Revision>() {

        @Override
        public boolean apply(Revision input) {
            if (input.equals(changeRev)) {
                return false;
            }
            if (isValidRevision(context, input, null, changeRev, validRevisions)) {
                return true;
            }
            handler.concurrentModification(input);
            return false;
        }
    };
    Revision newestRev = null;
    // check local commits first
    SortedMap<Revision, String> revisions = getLocalRevisions();
    SortedMap<Revision, String> commitRoots = getLocalCommitRoot();
    Iterator<Revision> it = filter(Iterables.mergeSorted(ImmutableList.of(revisions.keySet(), commitRoots.keySet()), revisions.comparator()), predicate).iterator();
    if (it.hasNext()) {
        newestRev = it.next();
    } else {
        // check full history (only needed in rare cases)
        if (LOG.isDebugEnabled()) {
            LOG.debug(""getNewestRevision() with changeRev {} on {}, "" + ""_revisions {}, _commitRoot {}"", changeRev, getId(), getLocalRevisions(), getLocalCommitRoot());
        }
        it = filter(getAllChanges(), predicate).iterator();
        if (it.hasNext()) {
            newestRev = it.next();
        }
    }
    if (newestRev == null) {
        return null;
    }
    // the local deleted map contains the most recent revisions
    SortedMap<Revision, String> deleted = getLocalDeleted();
    String value = deleted.get(newestRev);
    if (value == null && deleted.headMap(newestRev).isEmpty()) {
        // no need to check previous docs
        return newestRev;
    }
    if (value == null) {
        // get from complete map
        value = getDeleted().get(newestRev);
    }
    if (""true"".equals(value)) {
        // deleted in the newest revision
        return null;
    }
    return newestRev;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2933_44585b0c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/MoveAwarePermissionValidator.java,75,85,"private Validator visibleValidator(@Nonnull Tree source, @Nonnull Tree dest) {
    // TODO improve: avoid calculating the 'before' permissions in case the current parent permissions already point to the correct tree.
    ImmutableTree parent = (ImmutableTree) moveCtx.rootBefore.getTree(""/"");
    TreePermission tp = getPermissionProvider().getTreePermission(parent, TreePermission.EMPTY);
    for (String n : PathUtils.elements(source.getPath())) {
        tp = tp.getChildPermission(n, parent.getChild(n).getNodeState());
    }
    Validator validator = createValidator(source, dest, tp, this);
    return new VisibleValidator(validator, true, false);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-296_5449bf39,Major,oak-commons/src/main/java/org/apache/jackrabbit/oak/commons/PathUtils.java,285,295,"/**
 * Check if a path is a (direct or indirect) ancestor of another path.
 *
 * @param ancestor the ancestor path
 * @param path the potential offspring path
 * @return true if the path is an offspring of the ancestor
 */
public static boolean isAncestor(String ancestor, String path) {
    assert isValid(ancestor);
    assert isValid(path);
    if (ancestor.isEmpty() || path.isEmpty()) {
        return false;
    }
    if (!denotesRoot(ancestor)) {
        ancestor += ""/"";
    }
    return path.startsWith(ancestor);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2999_3bf07779,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditor.java,222,226,"@Override
public void propertyChanged(PropertyState before, PropertyState after) {
    markPropertyChanged(before.getName());
    checkAggregates(before.getName());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2999_3bf07779,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditor.java,228,232,"@Override
public void propertyDeleted(PropertyState before) {
    markPropertyChanged(before.getName());
    checkAggregates(before.getName());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-2999_3bf07779,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditor.java,305,381,"private Document makeDocument(String path, NodeState state, boolean isUpdate) {
    if (!isIndexable()) {
        return null;
    }
    List<Field> fields = new ArrayList<Field>();
    boolean dirty = false;
    for (PropertyState property : state.getProperties()) {
        String pname = property.getName();
        if (!isVisible(pname)) {
            continue;
        }
        PropertyDefinition pd = indexingRule.getConfig(pname);
        if (pd == null || !pd.index) {
            continue;
        }
        if (pd.ordered) {
            dirty |= addTypedOrderedFields(fields, property, pname, pd);
        }
        dirty |= indexProperty(path, fields, state, property, pname, pd);
    }
    dirty |= indexAggregates(path, fields, state);
    dirty |= indexNullCheckEnabledProps(path, fields, state);
    dirty |= indexNotNullCheckEnabledProps(path, fields, state);
    if (isUpdate && !dirty) {
        // updated the state but had no relevant changes
        return null;
    }
    // none of the properties are indexed
    if (!indexingRule.isFulltextEnabled() && !dirty) {
        return null;
    }
    Document document = new Document();
    document.add(newPathField(path));
    String name = getName(path);
    // TODO Possibly index nodeName without tokenization for node name based queries
    if (indexingRule.isFulltextEnabled()) {
        document.add(newFulltextField(name));
    }
    if (getDefinition().evaluatePathRestrictions()) {
        document.add(newAncestorsField(PathUtils.getParentPath(path)));
        document.add(newDepthField(path));
    }
    // because of LUCENE-5833 we have to merge the suggest fields into a single one
    Field suggestField = null;
    for (Field f : fields) {
        if (FieldNames.SUGGEST.endsWith(f.name())) {
            if (suggestField == null) {
                suggestField = FieldFactory.newSuggestField(f.stringValue());
            } else {
                suggestField = FieldFactory.newSuggestField(suggestField.stringValue(), f.stringValue());
            }
        } else {
            document.add(f);
        }
    }
    if (suggestField != null) {
        document.add(suggestField);
    }
    return document;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3013_eabb4066,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/UnionQueryImpl.java,91,96,"@Override
public void setLimit(long limit) {
    this.limit = limit;
    left.setLimit(limit);
    right.setLimit(limit);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3013_eabb4066,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/UnionQueryImpl.java,98,101,"@Override
public void setOffset(long offset) {
    this.offset = offset;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3019_5135cf4b,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/version/VersionablePathHook.java,108,114,"@Override
public boolean childNodeChanged(String name, NodeState before, NodeState after) {
    Node node = new Node(nodeAfter, name);
    return after.compareAgainstBaseState(before, new Diff(versionManager, node, exceptions));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3019_5135cf4b,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/version/VersionablePathHook.java,116,138,"private boolean setVersionablePath(PropertyState after) {
    if (JcrConstants.JCR_VERSIONHISTORY.equals(after.getName()) && nodeAfter.isVersionable(versionManager)) {
        NodeBuilder vhBuilder;
        try {
            vhBuilder = versionManager.getOrCreateVersionHistory(nodeAfter.builder, Collections.EMPTY_MAP);
        } catch (CommitFailedException e) {
            exceptions.add(e);
            // stop further comparison
            return false;
        }
        if (!vhBuilder.hasProperty(JcrConstants.JCR_MIXINTYPES)) {
            vhBuilder.setProperty(JcrConstants.JCR_MIXINTYPES, ImmutableSet.of(MIX_REP_VERSIONABLE_PATHS), Type.NAMES);
        }
        String versionablePath = nodeAfter.path;
        vhBuilder.setProperty(workspaceName, versionablePath, Type.PATH);
    }
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3020_147515ae,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditor.java,460,511,"private boolean addTypedOrderedFields(List<Field> fields, PropertyState property, String pname, PropertyDefinition pd) throws CommitFailedException {
    int tag = property.getType().tag();
    int idxDefinedTag = pd.getType();
    // Try converting type to the defined type in the index definition
    if (tag != idxDefinedTag) {
        log.debug(""Ordered property defined with type {} differs from property {} with type {} in "" + ""path {}"", Type.fromTag(idxDefinedTag, false), property.toString(), Type.fromTag(tag, false), getPath());
        tag = idxDefinedTag;
    }
    String name = FieldNames.createDocValFieldName(pname);
    boolean fieldAdded = false;
    for (int i = 0; i < property.count(); i++) {
        Field f = null;
        try {
            if (tag == Type.LONG.tag()) {
                // TODO Distinguish fields which need to be used for search and for sort
                // If a field is only used for Sort then it can be stored with less precision
                f = new NumericDocValuesField(name, property.getValue(Type.LONG, i));
            } else if (tag == Type.DATE.tag()) {
                String date = property.getValue(Type.DATE, i);
                f = new NumericDocValuesField(name, FieldFactory.dateToLong(date));
            } else if (tag == Type.DOUBLE.tag()) {
                f = new DoubleDocValuesField(name, property.getValue(Type.DOUBLE, i));
            } else if (tag == Type.BOOLEAN.tag()) {
                f = new SortedDocValuesField(name, new BytesRef(property.getValue(Type.BOOLEAN, i).toString()));
            } else if (tag == Type.STRING.tag()) {
                f = new SortedDocValuesField(name, new BytesRef(property.getValue(Type.STRING, i)));
            }
            if (f != null) {
                fields.add(f);
                fieldAdded = true;
            }
        } catch (Exception e) {
            log.warn(""Ignoring ordered property. Could not convert property {} of type {} to type "" + ""{} for path {}"", pname, Type.fromTag(property.getType().tag(), false), Type.fromTag(tag, false), getPath(), e);
        }
    }
    return fieldAdded;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3021_494da6de,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/accesscontrol/AccessControlValidator.java,120,126,"@Override
public Validator childNodeAdded(String name, NodeState after) throws CommitFailedException {
    Tree treeAfter = checkNotNull(parentAfter.getChild(name));
    checkValidTree(parentAfter, treeAfter, after);
    return new AccessControlValidator(this, treeAfter);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3021_494da6de,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/accesscontrol/AccessControlValidator.java,128,134,"@Override
public Validator childNodeChanged(String name, NodeState before, NodeState after) throws CommitFailedException {
    Tree treeAfter = checkNotNull(parentAfter.getChild(name));
    checkValidTree(parentAfter, treeAfter, after);
    return new AccessControlValidator(this, treeAfter);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3021_494da6de,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/user/UserValidator.java,137,143,"@Override
public Validator childNodeAdded(String name, NodeState after) throws CommitFailedException {
    Tree tree = checkNotNull(parentAfter.getChild(name));
    validateAuthorizable(tree, UserUtil.getType(tree));
    return new VisibleValidator(new UserValidator(null, tree, provider), true, true);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3021_494da6de,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/user/UserValidator.java,145,148,"@Override
public Validator childNodeChanged(String name, NodeState before, NodeState after) throws CommitFailedException {
    return new UserValidator(parentBefore.getChild(name), parentAfter.getChild(name), provider);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3021_494da6de,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/user/UserValidator.java,150,163,"@Override
public Validator childNodeDeleted(String name, NodeState before) throws CommitFailedException {
    Tree tree = parentBefore.getChild(name);
    AuthorizableType type = UserUtil.getType(tree);
    if (type == AuthorizableType.USER || type == AuthorizableType.GROUP) {
        if (isAdminUser(tree)) {
            String msg = ""The admin user cannot be removed."";
            throw constraintViolation(27, msg);
        }
        return null;
    } else {
        return new VisibleValidator(new UserValidator(tree, null, provider), true, true);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3028_89317b28,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Commit.java,271,417,"/**
 * Apply the changes to the document store.
 *
 * @param baseBranchRevision the base revision of this commit. Currently only
 *                     used for branch commits.
 */
private void applyToDocumentStore(Revision baseBranchRevision) {
    // the value in _revisions.<revision> property of the commit root node
    // regular commits use ""c"", which makes the commit visible to
    // other readers. branch commits use the base revision to indicate
    // the visibility of the commit
    String commitValue = baseBranchRevision != null ? baseBranchRevision.toString() : ""c"";
    DocumentStore store = nodeStore.getDocumentStore();
    String commitRootPath = null;
    if (baseBranchRevision != null) {
        // branch commits always use root node as commit root
        commitRootPath = ""/"";
    }
    ArrayList<UpdateOp> newNodes = new ArrayList<UpdateOp>();
    ArrayList<UpdateOp> changedNodes = new ArrayList<UpdateOp>();
    // operations are added to this list before they are executed,
    // so that all operations can be rolled back if there is a conflict
    ArrayList<UpdateOp> opLog = new ArrayList<UpdateOp>();
    // Compute the commit root
    for (String p : operations.keySet()) {
        markChanged(p);
        if (commitRootPath == null) {
            commitRootPath = p;
        } else {
            while (!PathUtils.isAncestor(commitRootPath, p)) {
                commitRootPath = PathUtils.getParentPath(commitRootPath);
                if (denotesRoot(commitRootPath)) {
                    break;
                }
            }
        }
    }
    // push branch changes to journal
    if (baseBranchRevision != null) {
        // store as external change
        JournalEntry doc = JOURNAL.newDocument(store);
        doc.modified(modifiedNodes);
        Revision r = revision.asBranchRevision();
        store.create(JOURNAL, singletonList(doc.asUpdateOp(r)));
    }
    int commitRootDepth = PathUtils.getDepth(commitRootPath);
    // check if there are real changes on the commit root
    boolean commitRootHasChanges = operations.containsKey(commitRootPath);
    // create a ""root of the commit"" if there is none
    UpdateOp commitRoot = getUpdateOperationForNode(commitRootPath);
    for (String p : operations.keySet()) {
        UpdateOp op = operations.get(p);
        if (op.isNew()) {
            NodeDocument.setDeleted(op, revision, false);
        }
        if (op == commitRoot) {
            if (!op.isNew() && commitRootHasChanges) {
                // commit root already exists and this is an update
                changedNodes.add(op);
            }
        } else {
            NodeDocument.setCommitRoot(op, revision, commitRootDepth);
            if (op.isNew()) {
                newNodes.add(op);
            } else {
                changedNodes.add(op);
            }
        }
    }
    if (changedNodes.size() == 0 && commitRoot.isNew()) {
        // no updates and root of commit is also new. that is,
        // it is the root of a subtree added in a commit.
        // so we try to add the root like all other nodes
        NodeDocument.setRevision(commitRoot, revision, commitValue);
        newNodes.add(commitRoot);
    }
    try {
        if (newNodes.size() > 0) {
            // set commit root on new nodes
            if (!store.create(NODES, newNodes)) {
                // try to apply all changes one by one
                for (UpdateOp op : newNodes) {
                    if (op == commitRoot) {
                        // don't write the commit root just yet
                        // (because there might be a conflict)
                        NodeDocument.unsetRevision(commitRoot, revision);
                    }
                    changedNodes.add(op);
                }
                newNodes.clear();
            }
        }
        for (UpdateOp op : changedNodes) {
            // set commit root on changed nodes. this may even apply
            // to the commit root. the _commitRoot entry is removed
            // again when the _revisions entry is set at the end
            NodeDocument.setCommitRoot(op, revision, commitRootDepth);
            opLog.add(op);
            createOrUpdateNode(store, op);
        }
        // the revision, with the revision property set)
        if (changedNodes.size() > 0 || !commitRoot.isNew()) {
            // set revision to committed
            NodeDocument.setRevision(commitRoot, revision, commitValue);
            if (commitRootHasChanges) {
                // remove previously added commit root
                NodeDocument.removeCommitRoot(commitRoot, revision);
            }
            opLog.add(commitRoot);
            if (baseBranchRevision == null) {
                // create a clone of the commitRoot in order
                // to set isNew to false. If we get here the
                // commitRoot document already exists and
                // only needs an update
                UpdateOp commit = commitRoot.shallowCopy(commitRoot.getId());
                commit.setNew(false);
                // only set revision on commit root when there is
                // no collision for this commit revision
                commit.containsMapEntry(COLLISIONS, revision, false);
                NodeDocument before = nodeStore.updateCommitRoot(commit);
                if (before == null) {
                    String msg = ""Conflicting concurrent change. "" + ""Update operation failed: "" + commitRoot;
                    throw new DocumentStoreException(msg);
                } else {
                    // if we get here the commit was successful and
                    // the commit revision is set on the commitRoot
                    // document for this commit.
                    // now check for conflicts/collisions by other commits.
                    // use original commitRoot operation with
                    // correct isNew flag.
                    checkConflicts(commitRoot, before);
                    checkSplitCandidate(before);
                }
            } else {
                // this is a branch commit, do not fail on collisions now
                // trying to merge the branch will fail later
                createOrUpdateNode(store, commitRoot);
            }
            operations.put(commitRootPath, commitRoot);
        }
    } catch (DocumentStoreException e) {
        rollback(newNodes, opLog, commitRoot);
        throw e;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3028_89317b28,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1170,1190,"/**
 * Updates a commit root document.
 *
 * @param commit the updates to apply on the commit root document.
 * @return the document before the update was applied or <code>null</code>
 *          if the update failed because of a collision.
 * @throws DocumentStoreException if the update fails with an error.
 */
@CheckForNull
NodeDocument updateCommitRoot(UpdateOp commit) throws DocumentStoreException {
    // use batch commit when there are only revision and modified updates
    // and collision checks
    boolean batch = true;
    for (Map.Entry<Key, Operation> op : commit.getChanges().entrySet()) {
        String name = op.getKey().getName();
        if (NodeDocument.isRevisionsEntry(name) || NodeDocument.MODIFIED_IN_SECS.equals(name) || NodeDocument.COLLISIONS.equals(name)) {
            continue;
        }
        batch = false;
        break;
    }
    if (batch) {
        return batchUpdateCommitRoot(commit);
    } else {
        return store.findAndUpdate(NODES, commit);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3028_89317b28,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,64,70,"static UpdateOp combine(String id, Iterable<UpdateOp> ops) {
    Map<Key, Operation> changes = Maps.newHashMap();
    for (UpdateOp op : ops) {
        changes.putAll(op.getChanges());
    }
    return new UpdateOp(id, false, false, changes);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3028_89317b28,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,78,80,"/**
 * Creates an update operation for the document with the given id. The
 * changes are shared with the this update operation.
 *
 * @param id the primary key.
 */
public UpdateOp shallowCopy(String id) {
    return new UpdateOp(id, isNew, isDelete, changes);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3028_89317b28,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,88,91,"/**
 * Creates a deep copy of this update operation. Changes to the returned
 * {@code UpdateOp} do not affect this object.
 *
 * @return a copy of this operation.
 */
public UpdateOp copy() {
    return new UpdateOp(id, isNew, isDelete, new HashMap<Key, Operation>(changes));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3028_89317b28,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UpdateOp.java,255,258,"@Override
public String toString() {
    return ""key: "" + id + "" "" + (isNew ? ""new"" : ""update"") + "" "" + changes;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3053_7552a10b,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,139,162,"protected Directory createLocalDirForIndexWriter(IndexDefinition definition) throws IOException {
    String indexPath = definition.getIndexPathFromConfig();
    File indexWriterDir;
    if (indexPath == null) {
        // If indexPath is not known create a unique directory for work
        indexWriterDir = new File(indexWorkDir, String.valueOf(UNIQUE_COUNTER.incrementAndGet()));
    } else {
        File indexDir = getIndexDir(indexPath);
        String newVersion = String.valueOf(definition.getReindexCount());
        indexWriterDir = getVersionedDir(indexPath, indexDir, newVersion);
    }
    Directory dir = FSDirectory.open(indexWriterDir);
    log.debug(""IndexWriter would use {}"", indexWriterDir);
    if (indexPath == null) {
        dir = new DeleteOldDirOnClose(dir, indexWriterDir);
        log.debug(""IndexPath [{}] not configured in index definition {}. Writer would create index "" + ""files in temporary dir {} which would be deleted upon close. For better performance do "" + ""configure the 'indexPath' as part of your index definition"", LuceneIndexConstants.INDEX_PATH, definition, indexWriterDir);
    }
    return dir;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3079_33c18762,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryAgent.java,136,253,"/**
 * Recover the correct _lastRev updates for the given candidate nodes.
 *
 * @param suspects the potential suspects
 * @param clusterId the cluster id for which _lastRev recovery needed
 * @param dryRun if {@code true}, this method will only perform a check
 *               but not apply the changes to the _lastRev fields.
 * @return the number of documents that required recovery. This method
 *          returns the number of the affected documents even if
 *          {@code dryRun} is set true and no document was changed.
 */
public int recover(Iterator<NodeDocument> suspects, int clusterId, boolean dryRun) {
    UnsavedModifications unsaved = new UnsavedModifications();
    UnsavedModifications unsavedParents = new UnsavedModifications();
    // Map of known last rev of checked paths
    Map<String, Revision> knownLastRevs = MapFactory.getInstance().create();
    final DocumentStore docStore = nodeStore.getDocumentStore();
    final JournalEntry changes = JOURNAL.newDocument(docStore);
    long count = 0;
    while (suspects.hasNext()) {
        NodeDocument doc = suspects.next();
        count++;
        if (count % 100000 == 0) {
            log.info(""Scanned {} suspects so far..."", count);
        }
        Revision currentLastRev = doc.getLastRev().get(clusterId);
        if (currentLastRev != null) {
            knownLastRevs.put(doc.getPath(), currentLastRev);
        }
        // 1. determine last committed modification on document
        Revision lastModifiedRev = determineLastModification(doc, clusterId);
        Revision lastRevForParents = Utils.max(lastModifiedRev, currentLastRev);
        // 2. Update lastRev for parent paths aka rollup
        if (lastRevForParents != null) {
            String path = doc.getPath();
            // track all changes
            changes.modified(path);
            while (true) {
                if (PathUtils.denotesRoot(path)) {
                    break;
                }
                path = PathUtils.getParentPath(path);
                unsavedParents.put(path, lastRevForParents);
            }
        }
    }
    for (String parentPath : unsavedParents.getPaths()) {
        Revision calcLastRev = unsavedParents.get(parentPath);
        Revision knownLastRev = knownLastRevs.get(parentPath);
        // This check ensures that unnecessary updates are not made
        if (knownLastRev == null || calcLastRev.compareRevisionTime(knownLastRev) > 0) {
            unsaved.put(parentPath, calcLastRev);
        }
    }
    // take the root's lastRev
    final Revision lastRootRev = unsaved.get(""/"");
    // Note the size before persist as persist operation
    // would empty the internal state
    int size = unsaved.getPaths().size();
    String updates = unsaved.toString();
    if (dryRun) {
        log.info(""Dry run of lastRev recovery identified [{}] documents for "" + ""cluster node [{}]: {}"", size, clusterId, updates);
    } else {
        // UnsavedModifications is designed to be used in concurrent
        // access mode. For recovery case there is no concurrent access
        // involve so just pass a new lock instance
        // the lock uses to do the persisting is a plain reentrant lock
        // thus it doesn't matter, where exactly the check is done
        // as to whether the recovered lastRev has already been
        // written to the journal.
        unsaved.persist(nodeStore, new UnsavedModifications.Snapshot() {

            @Override
            public void acquiring() {
                if (lastRootRev == null) {
                    // then we cannot and probably don't have to persist anything
                    return;
                }
                // lastRootRev never null at this point
                final String id = JournalEntry.asId(lastRootRev);
                final JournalEntry existingEntry = docStore.find(Collection.JOURNAL, id);
                if (existingEntry != null) {
                    // hence: nothing to be done here. return.
                    return;
                }
                // otherwise store a new journal entry now
                docStore.create(JOURNAL, singletonList(changes.asUpdateOp(lastRootRev)));
            }
        }, new ReentrantLock());
        log.info(""Updated lastRev of [{}] documents while performing lastRev recovery for "" + ""cluster node [{}]: {}"", size, clusterId, updates);
    }
    return size;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3079_33c18762,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryAgent.java,305,326,"/**
 * Determines the last committed modification to the given document by
 * a {@code clusterId}.
 *
 * @param doc a document.
 * @param clusterId clusterId for which the last committed modification is
 *                  looked up.
 * @return the commit revision of the last modification by {@code clusterId}
 *          to the given document.
 */
@CheckForNull
private Revision determineLastModification(NodeDocument doc, int clusterId) {
    ClusterPredicate cp = new ClusterPredicate(clusterId);
    // Merge sort the revs for which changes have been made
    // to this doc
    // localMap always keeps the most recent valid commit entry
    // per cluster node so looking into that should be sufficient
    Iterable<Revision> revs = mergeSorted(of(filter(doc.getLocalCommitRoot().keySet(), cp), filter(doc.getLocalRevisions().keySet(), cp)), StableRevisionComparator.REVERSE);
    Revision lastModified = null;
    // Look for latest valid revision
    for (Revision rev : revs) {
        lastModified = Utils.max(lastModified, doc.getCommitRevision(rev));
    }
    return lastModified;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3082_29e5b734,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/accesscontrol/AccessControlManagerImpl.java,357,382,"@Nonnull
@Override
public AccessControlPolicy[] getEffectivePolicies(@Nonnull Set<Principal> principals) throws RepositoryException {
    Util.checkValidPrincipals(principals, principalManager);
    Root r = getLatestRoot();
    Result aceResult = searchAces(principals, r);
    List<AccessControlPolicy> effective = new ArrayList<AccessControlPolicy>();
    for (ResultRow row : aceResult.getRows()) {
        String acePath = row.getPath();
        String aclName = Text.getName(Text.getRelativeParent(acePath, 1));
        Tree accessControlledTree = r.getTree(Text.getRelativeParent(acePath, 2));
        if (aclName.isEmpty() || !accessControlledTree.exists()) {
            log.debug(""Isolated access control entry -> ignore query result at "" + acePath);
            continue;
        }
        String path = (REP_REPO_POLICY.equals(aclName)) ? null : accessControlledTree.getPath();
        AccessControlPolicy policy = createACL(path, accessControlledTree, true);
        if (policy != null) {
            effective.add(policy);
        }
    }
    return effective.toArray(new AccessControlPolicy[effective.size()]);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3089_ba38c380,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/cache/CacheLIRS.java,411,422,"/**
 * Set the maximum memory this cache should use. This will not
 * immediately cause entries to get removed however; it will only change
 * the limit. To resize the internal array, call the clear method.
 *
 * @param maxMemory the maximum size (1 or larger)
 */
public void setMaxMemory(long maxMemory) {
    if (maxMemory <= 0) {
        throw new IllegalArgumentException(""Max memory must be larger than 0"");
    }
    this.maxMemory = maxMemory;
    if (segments != null) {
        long max = 1 + maxMemory / segments.length;
        for (Segment<K, V> s : segments) {
            s.setMaxMemory(max);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3099_25850476,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitDocumentCleanUp.java,73,98,"private void disconnect(NodeDocument splitDoc) {
    String splitId = splitDoc.getId();
    String mainId = Utils.getIdFromPath(splitDoc.getMainPath());
    NodeDocument doc = store.find(NODES, mainId);
    if (doc == null) {
        LOG.warn(""Main document {} already removed. Split document is {}"", mainId, splitId);
        return;
    }
    int slashIdx = splitId.lastIndexOf('/');
    int height = Integer.parseInt(splitId.substring(slashIdx + 1));
    Revision rev = Revision.fromString(splitId.substring(splitId.lastIndexOf('/', slashIdx - 1) + 1, slashIdx));
    doc = doc.findPrevReferencingDoc(rev, height);
    if (doc == null) {
        LOG.warn(""Split document {} not referenced anymore. Main document is {}"", splitId, mainId);
        return;
    }
    // remove reference
    if (doc.getSplitDocType() == INTERMEDIATE) {
        disconnectFromIntermediate(doc, rev);
    } else {
        markStaleOnMain(doc, rev, height);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3104_38f5ef13,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Commit.java,445,460,"private void rollback(List<UpdateOp> newDocuments, List<UpdateOp> changed, UpdateOp commitRoot) {
    DocumentStore store = nodeStore.getDocumentStore();
    for (UpdateOp op : changed) {
        UpdateOp reverse = op.getReverseOperation();
        store.findAndUpdate(NODES, reverse);
    }
    for (UpdateOp op : newDocuments) {
        UpdateOp reverse = op.getReverseOperation();
        store.findAndUpdate(NODES, reverse);
    }
    UpdateOp removeCollision = new UpdateOp(commitRoot.getId(), false);
    NodeDocument.removeCollision(removeCollision, revision);
    store.findAndUpdate(NODES, removeCollision);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3104_38f5ef13,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1369,1379,"public static void setDeleted(@Nonnull UpdateOp op, @Nonnull Revision revision, boolean deleted) {
    if (deleted) {
        // DELETED_ONCE would be set upon every delete.
        // possibly we can avoid that
        checkNotNull(op).set(DELETED_ONCE, Boolean.TRUE);
    }
    checkNotNull(op).setMapEntry(DELETED, checkNotNull(revision), String.valueOf(deleted));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3105_311e8b33,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentWriter.java,594,610,"/**
 * Write a reference to an external blob.
 *
 * @param reference reference
 * @return record id
 */
private synchronized RecordId writeValueRecord(String reference) {
    byte[] data = reference.getBytes(Charsets.UTF_8);
    int length = data.length;
    checkArgument(length < 8192);
    RecordId id = prepare(RecordType.VALUE, 2 + length);
    int len = length | 0xE000;
    buffer[position++] = (byte) (len >> 8);
    buffer[position++] = (byte) len;
    System.arraycopy(data, 0, buffer, position, length);
    position += length;
    blobrefs.add(id);
    return id;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3110_d10362c0,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,131,135,"public Directory wrapForRead(String indexPath, IndexDefinition definition, Directory remote) throws IOException {
    Directory local = createLocalDirForIndexReader(indexPath, definition);
    return new CopyOnReadDirectory(remote, local, prefetchEnabled, indexPath);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3110_d10362c0,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,137,140,"public Directory wrapForWrite(IndexDefinition definition, Directory remote, boolean reindexMode) throws IOException {
    Directory local = createLocalDirForIndexWriter(definition);
    return new CopyOnWriteDirectory(remote, local, reindexMode, getIndexPathForLogging(definition));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3110_d10362c0,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,642,651,"@Override
public IndexOutput createOutput(String name, IOContext context) throws IOException {
    COWFileReference ref = fileMap.remove(name);
    if (ref != null) {
        ref.delete();
    }
    ref = new COWLocalFileReference(name);
    fileMap.put(name, ref);
    return ref.createOutput(context);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3110_d10362c0,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,672,726,"@Override
public void close() throws IOException {
    int pendingCopies = queue.size();
    addTask(STOP);
    // Wait for all pending copy task to finish
    try {
        long start = PERF_LOGGER.start();
        // prevent any bug causing the thread to wait indefinitely
        while (!copyDone.await(10, TimeUnit.SECONDS)) {
            if (closed) {
                throw new IndexCopierClosedException(""IndexCopier found to be closed "" + ""while processing copy task for"" + remote.toString());
            }
        }
        PERF_LOGGER.end(start, -1, ""[COW][{}] Completed pending copying task {}"", indexPathForLogging, pendingCopies);
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
        throw new IOException(e);
    }
    Throwable t = errorInCopy.get();
    if (t != null) {
        throw new IOException(""Error occurred while copying files for "" + indexPathForLogging, t);
    }
    // Sanity check
    checkArgument(queue.isEmpty(), ""Copy queue still "" + ""has pending task left [%d]. %s"", queue.size(), queue);
    long skippedFilesSize = getSkippedFilesSize();
    for (String fileName : deletedFilesLocal) {
        deleteLocalFile(fileName);
    }
    skippedFromUploadSize.addAndGet(skippedFilesSize);
    String msg = ""[COW][{}] CopyOnWrite stats : Skipped copying {} files with total size {}"";
    if (reindexMode || skippedFilesSize > 10 * FileUtils.ONE_MB) {
        log.info(msg, indexPathForLogging, skippedFiles.size(), humanReadableByteCount(skippedFilesSize));
    } else {
        log.debug(msg, indexPathForLogging, skippedFiles.size(), humanReadableByteCount(skippedFilesSize));
    }
    if (log.isTraceEnabled()) {
        log.trace(""[COW][{}] File listing - Upon completion {}"", indexPathForLogging, Arrays.toString(remote.listAll()));
    }
    local.close();
    remote.close();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3110_d10362c0,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,983,1000,"private boolean deleteFile(Directory dir, String fileName, boolean copiedFromRemote) {
    LocalIndexFile file = new LocalIndexFile(dir, fileName, getFileLength(dir, fileName), copiedFromRemote);
    boolean successFullyDeleted = false;
    try {
        boolean fileExisted = false;
        if (dir.fileExists(fileName)) {
            fileExisted = true;
            dir.deleteFile(fileName);
        }
        successfullyDeleted(file, fileExisted);
        successFullyDeleted = true;
    } catch (IOException e) {
        failedToDelete(file);
        log.debug(""Error occurred while removing deleted file {} from Local {}. "" + ""Attempt would be maid to delete it on next run "", fileName, dir, e);
    }
    return successFullyDeleted;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3123_f3c9c818,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/RecordIdMap.java,41,70,"/**
 * Associates {@code key} with {@code value} if not already present
 * @param key
 * @param value
 * @return  {@code true} if added, {@code false} if already present
 */
public boolean put(short key, @Nonnull RecordId value) {
    if (keys == null) {
        keys = new short[1];
        values = new RecordId[1];
        keys[0] = key;
        values[0] = value;
        return true;
    } else {
        int k = binarySearch(keys, key);
        if (k < 0) {
            int l = -k - 1;
            short[] newKeys = new short[keys.length + 1];
            RecordId[] newValues = new RecordId[(values.length + 1)];
            arraycopy(keys, 0, newKeys, 0, l);
            arraycopy(values, 0, newValues, 0, l);
            newKeys[l] = key;
            newValues[l] = value;
            int c = keys.length - l;
            if (c > 0) {
                arraycopy(keys, l, newKeys, l + 1, c);
                arraycopy(values, l, newValues, l + 1, c);
            }
            keys = newKeys;
            values = newValues;
            return true;
        } else {
            return false;
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3123_f3c9c818,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/RecordIdMap.java,92,94,"/**
 * Check whether {@code key} is present is this map.
 * @param key  the key to check for
 * @return  {@code true} iff {@code key} is present.
 */
public boolean containsKey(short key) {
    return keys != null && binarySearch(keys, key) >= 0;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3123_f3c9c818,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/RecordIdMap.java,109,111,"/**
 * Retrieve the key at a given index. Keys are ordered according
 * the natural ordering of shorts.
 * @param index
 * @return the key at {@code index}
 */
public short getKey(int index) {
    return keys[index];
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3123_f3c9c818,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/RecordIdMap.java,119,122,"/**
 * Retrieve the value at a given index. Keys are ordered according
 * the natural ordering of shorts.
 * @param index
 * @return the value at {@code index}
 */
@Nonnull
public RecordId getRecordId(int index) {
    return values[index];
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3137_c65b07c3,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexPlanner.java,317,325,"private boolean canEvalPathRestrictions(IndexingRule rule) {
    if (filter.getPathRestriction() == Filter.PathRestriction.NO_RESTRICTION) {
        return false;
    }
    // allows indexing all the path for given nodeType
    return definition.evaluatePathRestrictions() && rule.indexesAllNodesOfMatchingType();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-313_e115fd90,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/NamePathMapperImpl.java,153,293,"private String getOakPath(String jcrPath, final boolean keepIndex) {
    final List<String> elements = new ArrayList<String>();
    final StringBuilder parseErrors = new StringBuilder();
    if (""/"".equals(jcrPath)) {
        // avoid the need to special case the root path later on
        return ""/"";
    }
    int length = jcrPath.length();
    // identifier path?
    if (length > 0 && jcrPath.charAt(0) == '[') {
        if (jcrPath.charAt(length - 1) != ']') {
            // TODO error handling?
            log.debug(""Could not parse path "" + jcrPath + "": unterminated identifier"");
            return null;
        }
        if (this.idManager == null) {
            // TODO error handling?
            log.debug(""Could not parse path "" + jcrPath + "": could not resolve identifier"");
            return null;
        }
        return this.idManager.getPath(jcrPath.substring(1, length - 1));
    }
    boolean hasClarkBrackets = false;
    boolean hasIndexBrackets = false;
    boolean hasColon = false;
    boolean hasNameStartingWithDot = false;
    char prev = 0;
    for (int i = 0; i < length; i++) {
        char c = jcrPath.charAt(i);
        if (c == '{' || c == '}') {
            hasClarkBrackets = true;
        } else if (c == '[' || c == ']') {
            hasIndexBrackets = true;
        } else if (c == ':') {
            hasColon = true;
        } else if (c == '.' && (prev == 0 || prev == '/')) {
            hasNameStartingWithDot = true;
        }
        prev = c;
    }
    // try a shortcut
    if (!hasNameStartingWithDot && !hasClarkBrackets && !hasIndexBrackets) {
        if (!hasColon || !hasSessionLocalMappings()) {
            if (JcrPathParser.validate(jcrPath)) {
                return jcrPath;
            } else {
                log.debug(""Invalid path: {}"", jcrPath);
                return null;
            }
        }
    }
    JcrPathParser.Listener listener = new JcrPathParser.Listener() {

        @Override
        public boolean root() {
            if (!elements.isEmpty()) {
                parseErrors.append(""/ on non-empty path"");
                return false;
            }
            elements.add("""");
            return true;
        }

        @Override
        public boolean current() {
            // nothing to do here
            return true;
        }

        @Override
        public boolean parent() {
            if (elements.isEmpty() || "".."".equals(elements.get(elements.size() - 1))) {
                elements.add("".."");
                return true;
            }
            elements.remove(elements.size() - 1);
            return true;
        }

        @Override
        public void error(String message) {
            parseErrors.append(message);
        }

        @Override
        public boolean name(String name, int index) {
            if (!keepIndex && index > 1) {
                parseErrors.append(""index > 1"");
                return false;
            }
            String p = nameMapper.getOakName(name);
            if (p == null) {
                parseErrors.append(""Invalid name: "").append(name);
                return false;
            }
            if (keepIndex && index > 0) {
                p += ""["" + index + ']';
            }
            elements.add(p);
            return true;
        }
    };
    JcrPathParser.parse(jcrPath, listener);
    if (parseErrors.length() != 0) {
        log.debug(""Could not parse path "" + jcrPath + "": "" + parseErrors.toString());
        return null;
    }
    // Empty path maps to """"
    if (elements.isEmpty()) {
        return """";
    }
    StringBuilder oakPath = new StringBuilder();
    for (String element : elements) {
        if (element.isEmpty()) {
            // root
            oakPath.append('/');
        } else {
            oakPath.append(element);
            oakPath.append('/');
        }
    }
    // root path is special-cased early on so it does not need to
    // be considered here
    oakPath.deleteCharAt(oakPath.length() - 1);
    return oakPath.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3156_786b3d76,Blocker,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,1106,1134,"@Override
public IndexRow next() {
    final IndexRow pathRow = pathCursor.next();
    return new IndexRow() {

        @Override
        public boolean isVirtualRow() {
            return getPath() == null;
        }

        @Override
        public String getPath() {
            return pathRow.getPath();
        }

        @Override
        public PropertyValue getValue(String columnName) {
            // overlay the score
            if (QueryImpl.JCR_SCORE.equals(columnName)) {
                return PropertyValues.newDouble(currentRow.score);
            }
            if (QueryImpl.REP_SPELLCHECK.equals(columnName) || QueryImpl.REP_SUGGEST.equals(columnName)) {
                return PropertyValues.newString(Iterables.toString(currentRow.suggestWords));
            }
            return pathRow.getValue(columnName);
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3156_786b3d76,Blocker,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndex.java,1111,1114,"@Override
public boolean isVirtualRow() {
    return getPath() == null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3156_786b3d76,Blocker,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java,1350,1383,"@Override
public IndexRow next() {
    final IndexRow pathRow = pathCursor.next();
    return new IndexRow() {

        @Override
        public boolean isVirtualRow() {
            return getPath() == null;
        }

        @Override
        public String getPath() {
            String sub = pathRow.getPath();
            if (PathUtils.isAbsolute(sub)) {
                return pathPrefix + sub;
            } else {
                return PathUtils.concat(pathPrefix, sub);
            }
        }

        @Override
        public PropertyValue getValue(String columnName) {
            // overlay the score
            if (QueryImpl.JCR_SCORE.equals(columnName)) {
                return PropertyValues.newDouble(currentRow.score);
            }
            if (QueryImpl.REP_SPELLCHECK.equals(columnName) || QueryImpl.REP_SUGGEST.equals(columnName)) {
                return PropertyValues.newString(Iterables.toString(currentRow.suggestWords));
            }
            return pathRow.getValue(columnName);
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3156_786b3d76,Blocker,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java,1355,1358,"@Override
public boolean isVirtualRow() {
    return getPath() == null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3249_64712735,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,345,471,"/**
 * Copies the full content from the source to the target repository.
 * <p>
 * The source repository <strong>must not be modified</strong> while
 * the copy operation is running to avoid an inconsistent copy.
 * <p>
 * Note that both the source and the target repository must be closed
 * during the copy operation as this method requires exclusive access
 * to the repositories.
 *
 * @param initializer optional extra repository initializer to use
 * @throws RepositoryException if the copy operation fails
 */
public void copy(RepositoryInitializer initializer) throws RepositoryException {
    RepositoryConfig config = source.getRepositoryConfig();
    logger.info(""Copying repository content from {} to Oak"", config.getHomeDir());
    try {
        NodeState base = target.getRoot();
        NodeBuilder builder = base.builder();
        final Root upgradeRoot = new UpgradeRoot(builder);
        String workspaceName = source.getRepositoryConfig().getDefaultWorkspaceName();
        SecurityProviderImpl security = new SecurityProviderImpl(mapSecurityConfig(config.getSecurityConfig()));
        // init target repository first
        logger.info(""Initializing initial repository content from {}"", config.getHomeDir());
        new InitialContent().initialize(builder);
        if (initializer != null) {
            initializer.initialize(builder);
        }
        logger.debug(""InitialContent completed from {}"", config.getHomeDir());
        for (SecurityConfiguration sc : security.getConfigurations()) {
            RepositoryInitializer ri = sc.getRepositoryInitializer();
            ri.initialize(builder);
            logger.debug(""Repository initializer '"" + ri.getClass().getName() + ""' completed"", config.getHomeDir());
        }
        for (SecurityConfiguration sc : security.getConfigurations()) {
            WorkspaceInitializer wi = sc.getWorkspaceInitializer();
            wi.initialize(builder, workspaceName);
            logger.debug(""Workspace initializer '"" + wi.getClass().getName() + ""' completed"", config.getHomeDir());
        }
        HashBiMap<String, String> uriToPrefix = HashBiMap.create();
        logger.info(""Copying registered namespaces"");
        copyNamespaces(builder, uriToPrefix);
        logger.debug(""Namespace registration completed."");
        logger.info(""Copying registered node types"");
        NodeTypeManager ntMgr = new ReadWriteNodeTypeManager() {

            @Override
            protected Tree getTypes() {
                return upgradeRoot.getTree(NODE_TYPES_PATH);
            }

            @Nonnull
            @Override
            protected Root getWriteRoot() {
                return upgradeRoot;
            }
        };
        copyNodeTypes(ntMgr, new ValueFactoryImpl(upgradeRoot, NamePathMapper.DEFAULT));
        logger.debug(""Node type registration completed."");
        // migrate privileges
        logger.info(""Copying registered privileges"");
        PrivilegeConfiguration privilegeConfiguration = security.getConfiguration(PrivilegeConfiguration.class);
        copyCustomPrivileges(privilegeConfiguration.getPrivilegeManager(upgradeRoot, NamePathMapper.DEFAULT));
        logger.debug(""Privilege registration completed."");
        // Triggers compilation of type information, which we need for
        // the type predicates used by the bulk  copy operations below.
        new TypeEditorProvider(false).getRootEditor(base, builder.getNodeState(), builder, null);
        NodeState root = builder.getNodeState();
        final NodeState sourceState = JackrabbitNodeState.createRootNodeState(source, workspaceName, root, uriToPrefix, copyBinariesByReference, skipOnError);
        final Stopwatch watch = Stopwatch.createStarted();
        logger.info(""Copying workspace content"");
        copyWorkspace(sourceState, builder, workspaceName);
        // on TarMK this does call triggers the actual copy
        builder.getNodeState();
        logger.info(""Upgrading workspace content completed in {}s ({})"", watch.elapsed(TimeUnit.SECONDS), watch);
        if (!versionCopyConfiguration.skipOrphanedVersionsCopy()) {
            logger.info(""Copying version storage"");
            watch.reset().start();
            copyVersionStorage(sourceState, builder, versionCopyConfiguration);
            // on TarMK this does call triggers the actual copy
            builder.getNodeState();
            logger.info(""Version storage copied in {}s ({})"", watch.elapsed(TimeUnit.SECONDS), watch);
        } else {
            logger.info(""Skipping the version storage as the copyOrphanedVersions is set to false"");
        }
        watch.reset().start();
        logger.info(""Applying default commit hooks"");
        // TODO: default hooks?
        List<CommitHook> hooks = newArrayList();
        UserConfiguration userConf = security.getConfiguration(UserConfiguration.class);
        String groupsPath = userConf.getParameters().getConfigValue(UserConstants.PARAM_GROUP_PATH, UserConstants.DEFAULT_GROUP_PATH);
        // hooks specific to the upgrade, need to run first
        hooks.add(new EditorHook(new CompositeEditorProvider(new RestrictionEditorProvider(), new GroupEditorProvider(groupsPath), // copy referenced version histories
        new VersionableEditor.Provider(sourceState, workspaceName, versionCopyConfiguration))));
        // security-related hooks
        for (SecurityConfiguration sc : security.getConfigurations()) {
            hooks.addAll(sc.getCommitHooks(workspaceName));
        }
        if (customCommitHooks != null) {
            hooks.addAll(customCommitHooks);
        }
        // type validation, reference and indexing hooks
        hooks.add(new EditorHook(new CompositeEditorProvider(createTypeEditorProvider(), createIndexEditorProvider())));
        target.merge(builder, new LoggingCompositeHook(hooks, source, earlyShutdown), CommitInfo.EMPTY);
        logger.info(""Processing commit hooks completed in {}s ({})"", watch.elapsed(TimeUnit.SECONDS), watch);
        logger.debug(""Repository upgrade completed."");
    } catch (Exception e) {
        throw new RepositoryException(""Failed to copy content"", e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3310_4416a9f8,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/NodeImpl.java,1423,1445,"private Property internalRemoveProperty(final String jcrName) throws RepositoryException {
    final String oakName = getOakName(checkNotNull(jcrName));
    return perform(new ItemWriteOperation<Property>(""internalRemoveProperty"") {

        @Nonnull
        @Override
        public Property perform() throws RepositoryException {
            PropertyDelegate property = dlg.getPropertyOrNull(oakName);
            if (property != null) {
                property.remove();
            } else {
                // Return an instance which throws on access; see OAK-395
                property = dlg.getProperty(oakName);
            }
            return new PropertyImpl(property, sessionContext);
        }

        @Override
        public String toString() {
            return String.format(""Removing property [%s]"", jcrName);
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3310_4416a9f8,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/PropertyImpl.java,109,122,"@Override
public void remove() throws RepositoryException {
    sessionDelegate.performVoid(new ItemWriteOperation(""remove"") {

        @Override
        public void performVoid() {
            dlg.remove();
        }

        @Override
        public String toString() {
            return String.format(""Removing property [%s/%s] "", dlg.getPath(), dlg.getName());
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3310_4416a9f8,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/PropertyImpl.java,450,471,"private void internalSetValue(@Nonnull final Value value) throws RepositoryException {
    sessionDelegate.performVoid(new ItemWriteOperation(""internalSetValue"") {

        @Override
        public void performVoid() throws RepositoryException {
            Type<?> type = dlg.getPropertyState().getType();
            if (type.isArray()) {
                throw new ValueFormatException(""This is a multi-valued property"");
            }
            Value converted = ValueHelper.convert(value, type.tag(), getValueFactory());
            dlg.setState(createSingleState(dlg.getName(), converted, type));
        }

        @Override
        public String toString() {
            return String.format(""Setting property [%s/%s]"", dlg.getPath(), dlg.getName());
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3310_4416a9f8,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/PropertyImpl.java,473,504,"private void internalSetValue(@Nonnull final Value[] values) throws RepositoryException {
    if (values.length > MV_PROPERTY_WARN_THRESHOLD) {
        LOG.warn(""Large multi valued property [{}] detected ({} values)."", dlg.getPath(), values.length);
    }
    sessionDelegate.performVoid(new ItemWriteOperation(""internalSetValue"") {

        @Override
        public void performVoid() throws RepositoryException {
            Type<?> type = dlg.getPropertyState().getType();
            if (!type.isArray()) {
                throw new ValueFormatException(""This is a single-valued property"");
            }
            List<Value> converted = newArrayListWithCapacity(values.length);
            ValueFactory factory = getValueFactory();
            for (Value value : values) {
                if (value != null) {
                    converted.add(ValueHelper.convert(value, type.tag(), factory));
                }
            }
            dlg.setState(createMultiState(dlg.getName(), converted, type));
        }

        @Override
        public String toString() {
            return String.format(""Setting property [%s/%s]"", dlg.getPath(), dlg.getName());
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3318_e12e2052,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexDefinition.java,750,757,"/**
 * Returns <code>true</code> if this rule applies to the given node
 * <code>state</code>.
 *
 * @param state the state to check.
 * @return <code>true</code> the rule applies to the given node;
 *         <code>false</code> otherwise.
 */
public boolean appliesTo(Tree state) {
    if (!nodeTypeName.equals(getPrimaryTypeName(state))) {
        return false;
    }
    // return condition == null || condition.evaluate(state);
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3318_e12e2052,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexDefinition.java,1244,1247,"private static Iterable<String> getMixinTypeNames(Tree tree) {
    PropertyState property = tree.getProperty(JcrConstants.JCR_MIMETYPE);
    return property != null ? property.getValue(Type.NAMES) : Collections.<String>emptyList();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/CompiledPermissionImpl.java,142,151,"@Nonnull
@Override
public RepositoryPermission getRepositoryPermission() {
    return new RepositoryPermission() {

        @Override
        public boolean isGranted(long repositoryPermissions) {
            return hasPermissions(getEntryIterator(new EntryPredicate()), repositoryPermissions, null);
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/CompiledPermissionImpl.java,146,149,"@Override
public boolean isGranted(long repositoryPermissions) {
    return hasPermissions(getEntryIterator(new EntryPredicate()), repositoryPermissions, null);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/CompiledPermissionImpl.java,243,247,"@Override
public boolean isGranted(@Nonnull String path, long permissions) {
    Iterator<PermissionEntry> it = getEntryIterator(new EntryPredicate(path, Permissions.respectParentPermissions(permissions)));
    return hasPermissions(it, permissions, path);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/CompiledPermissionImpl.java,262,265,"// ------------------------------------------------------------< private >---
private boolean internalIsGranted(@Nonnull Tree tree, @Nullable PropertyState property, long permissions) {
    Iterator<PermissionEntry> it = getEntryIterator(tree, property, permissions);
    return hasPermissions(it, permissions, tree.getPath());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/CompiledPermissionImpl.java,267,330,"private boolean hasPermissions(@Nonnull Iterator<PermissionEntry> entries, long permissions, @Nullable String path) {
    // calculate readable paths if the given permissions includes any read permission.
    boolean isReadable = Permissions.diff(Permissions.READ, permissions) != Permissions.READ && readPolicy.isReadablePath(path, false);
    if (!entries.hasNext() && !isReadable) {
        return false;
    }
    boolean respectParent = (path != null) && Permissions.respectParentPermissions(permissions);
    long allows = (isReadable) ? Permissions.READ : Permissions.NO_PERMISSION;
    long denies = Permissions.NO_PERMISSION;
    PrivilegeBits allowBits = PrivilegeBits.getInstance();
    if (isReadable) {
        allowBits.add(bitsProvider.getBits(PrivilegeConstants.JCR_READ));
    }
    PrivilegeBits denyBits = PrivilegeBits.getInstance();
    PrivilegeBits parentAllowBits;
    PrivilegeBits parentDenyBits;
    String parentPath;
    if (respectParent) {
        parentAllowBits = PrivilegeBits.getInstance();
        parentDenyBits = PrivilegeBits.getInstance();
        parentPath = PermissionUtil.getParentPathOrNull(path);
    } else {
        parentAllowBits = PrivilegeBits.EMPTY;
        parentDenyBits = PrivilegeBits.EMPTY;
        parentPath = null;
    }
    while (entries.hasNext()) {
        PermissionEntry entry = entries.next();
        if (respectParent && (parentPath != null)) {
            boolean matchesParent = entry.matchesParent(parentPath);
            if (matchesParent) {
                if (entry.isAllow) {
                    parentAllowBits.addDifference(entry.privilegeBits, parentDenyBits);
                } else {
                    parentDenyBits.addDifference(entry.privilegeBits, parentAllowBits);
                }
            }
        }
        if (entry.isAllow) {
            allowBits.addDifference(entry.privilegeBits, denyBits);
            long ap = PrivilegeBits.calculatePermissions(allowBits, parentAllowBits, true);
            allows |= Permissions.diff(ap, denies);
            if ((allows | ~permissions) == -1) {
                return true;
            }
        } else {
            denyBits.addDifference(entry.privilegeBits, allowBits);
            long dp = PrivilegeBits.calculatePermissions(denyBits, parentDenyBits, false);
            denies |= Permissions.diff(dp, allows);
            if (Permissions.includes(denies, permissions)) {
                return false;
            }
        }
    }
    return (allows | ~permissions) == -1;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/CompiledPermissionImpl.java,379,382,"@Nonnull
private Iterator<PermissionEntry> getEntryIterator(@Nonnull Tree tree, @Nullable PropertyState property, long permissions) {
    return getEntryIterator(new EntryPredicate(tree, property, Permissions.respectParentPermissions(permissions)));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/CompiledPermissionImpl.java,527,530,"@Override
public boolean isGranted(long permissions) {
    return hasPermissions(getIterator(null, permissions), permissions, tree.getPath());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/CompiledPermissionImpl.java,532,535,"@Override
public boolean isGranted(long permissions, @Nonnull PropertyState property) {
    return hasPermissions(getIterator(property, permissions), permissions, tree.getPath());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/EntryPredicate.java,74,86,"@Override
public boolean apply(@Nullable PermissionEntry entry) {
    if (entry == null) {
        return false;
    }
    if (tree != null) {
        return entry.matches(tree, property) || applyToParent(entry);
    } else if (path != null) {
        return entry.matches(path) || applyToParent(entry);
    } else {
        return entry.matches();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3324_5f863af6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/EntryPredicate.java,88,96,"private boolean applyToParent(@Nonnull PermissionEntry entry) {
    if (parent != null) {
        return entry.matches(parent, null);
    } else if (parentPath != null) {
        return entry.matches(parentPath);
    } else {
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3333_194999ed,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java,209,249,"/**
 * Collect _revisions and _commitRoot entries that can be moved to a
 * previous document.
 */
private void collectRevisionsAndCommitRoot() {
    NavigableMap<Revision, String> revisions = new TreeMap<Revision, String>(context.getRevisionComparator());
    for (Map.Entry<Revision, String> entry : doc.getLocalRevisions().entrySet()) {
        if (splitRevs.contains(entry.getKey())) {
            revisions.put(entry.getKey(), entry.getValue());
            numValues++;
        } else {
            // local changes
            if (context.getClusterId() != entry.getKey().getClusterId()) {
                // only consider local changes
                continue;
            }
            if (doc.isCommitted(entry.getKey()) && !mostRecentRevs.contains(entry.getKey())) {
                // this is a commit root for changes in other documents
                revisions.put(entry.getKey(), entry.getValue());
                numValues++;
                trackHigh(entry.getKey());
                trackLow(entry.getKey());
            }
        }
    }
    committedChanges.put(REVISIONS, revisions);
    NavigableMap<Revision, String> commitRoot = new TreeMap<Revision, String>(context.getRevisionComparator());
    for (Map.Entry<Revision, String> entry : doc.getLocalCommitRoot().entrySet()) {
        Revision r = entry.getKey();
        if (splitRevs.contains(r)) {
            commitRoot.put(r, entry.getValue());
            numValues++;
        } else if (r.getClusterId() == context.getClusterId() && !changes.contains(r)) {
            // OAK-2528: _commitRoot entry without associated
            // change -> consider as garbage
            addGarbage(r, COMMIT_ROOT);
        }
    }
    committedChanges.put(COMMIT_ROOT, commitRoot);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3367_06812d25,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexDefinition.java,824,876,"private Map<String, PropertyDefinition> collectPropConfigs(NodeState config, List<NamePattern> patterns, List<Aggregate.Include> propAggregate, List<PropertyDefinition> nonExistentProperties, List<PropertyDefinition> existentProperties, List<PropertyDefinition> boostedProps) {
    Map<String, PropertyDefinition> propDefns = newHashMap();
    NodeState propNode = config.getChildNode(LuceneIndexConstants.PROP_NODE);
    if (!propNode.exists()) {
        return Collections.emptyMap();
    }
    if (!hasOrderableChildren(propNode)) {
        log.warn(""Properties node for [{}] does not have orderable "" + ""children in [{}]"", this, IndexDefinition.this);
    }
    // Include all immediate child nodes to 'properties' node by default
    Tree propTree = TreeFactory.createReadOnlyTree(propNode);
    for (Tree prop : propTree.getChildren()) {
        String propName = prop.getName();
        NodeState propDefnNode = propNode.getChildNode(propName);
        if (propDefnNode.exists() && !propDefns.containsKey(propName)) {
            PropertyDefinition pd = new PropertyDefinition(this, propName, propDefnNode);
            if (pd.isRegexp) {
                patterns.add(new NamePattern(pd.name, pd));
            } else {
                propDefns.put(pd.name.toLowerCase(Locale.ENGLISH), pd);
            }
            if (pd.relative) {
                propAggregate.add(new Aggregate.PropertyInclude(pd));
            }
            if (pd.nullCheckEnabled) {
                nonExistentProperties.add(pd);
            }
            if (pd.notNullCheckEnabled) {
                existentProperties.add(pd);
            }
            // Include props with name, boosted and nodeScopeIndex
            if (pd.nodeScopeIndex && pd.boost != PropertyDefinition.DEFAULT_BOOST && pd.analyzed && !pd.isRegexp) {
                boostedProps.add(pd);
            }
        }
    }
    return ImmutableMap.copyOf(propDefns);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3377_00b9bc52,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/fulltext/FullTextParser.java,81,190,"FullTextExpression parseTerm() throws ParseException {
    if (parseIndex >= text.length()) {
        throw getSyntaxError(""term"");
    }
    boolean not = false;
    StringBuilder buff = new StringBuilder();
    char c = text.charAt(parseIndex);
    if (c == '-') {
        if (++parseIndex >= text.length()) {
            throw getSyntaxError(""term"");
        }
        not = true;
    }
    boolean escaped = false;
    String boost = null;
    if (c == '\""') {
        parseIndex++;
        while (true) {
            if (parseIndex >= text.length()) {
                throw getSyntaxError(""double quote"");
            }
            c = text.charAt(parseIndex++);
            if (c == '\\') {
                escaped = true;
                if (parseIndex >= text.length()) {
                    throw getSyntaxError(""escaped char"");
                }
                c = text.charAt(parseIndex++);
                buff.append(c);
            } else if (c == '\""') {
                if (parseIndex < text.length()) {
                    if (text.charAt(parseIndex) == '^') {
                        boost = """";
                    } else if (text.charAt(parseIndex) != ' ') {
                        throw getSyntaxError(""space"");
                    }
                }
                parseIndex++;
                break;
            } else {
                buff.append(c);
            }
        }
    } else if (c == '\'' && FullTextSearchImpl.JACKRABBIT_2_SINGLE_QUOTED_PHRASE) {
        // basically the same as double quote
        parseIndex++;
        while (true) {
            if (parseIndex >= text.length()) {
                throw getSyntaxError(""single quote"");
            }
            c = text.charAt(parseIndex++);
            if (c == '\\') {
                escaped = true;
                if (parseIndex >= text.length()) {
                    throw getSyntaxError(""escaped char"");
                }
                c = text.charAt(parseIndex++);
                buff.append(c);
            } else if (c == '\'') {
                if (parseIndex < text.length()) {
                    if (text.charAt(parseIndex) == '^') {
                        boost = """";
                    } else if (text.charAt(parseIndex) != ' ') {
                        throw getSyntaxError(""space"");
                    }
                }
                parseIndex++;
                break;
            } else {
                buff.append(c);
            }
        }
    } else {
        do {
            c = text.charAt(parseIndex++);
            if (c == '\\') {
                escaped = true;
                if (parseIndex >= text.length()) {
                    throw getSyntaxError(""escaped char"");
                }
                c = text.charAt(parseIndex++);
                buff.append(c);
            } else if (c == '^') {
                boost = """";
                break;
            } else if (c == ' ') {
                break;
            } else {
                buff.append(c);
            }
        } while (parseIndex < text.length());
    }
    if (boost != null) {
        StringBuilder b = new StringBuilder();
        while (parseIndex < text.length()) {
            c = text.charAt(parseIndex++);
            if ((c < '0' || c > '9') && c != '.') {
                break;
            }
            b.append(c);
        }
        boost = b.toString();
    }
    if (buff.length() == 0) {
        throw getSyntaxError(""term"");
    }
    String text = buff.toString();
    FullTextTerm term = new FullTextTerm(propertyName, text, not, escaped, boost);
    return term.simplify();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3396_c83755c3,Blocker,oak-auth-ldap/src/main/java/org/apache/jackrabbit/oak/security/authentication/ldap/impl/LdapIdentityProvider.java,700,714,"@Nonnull
private ExternalUser createUser(@Nonnull Entry entry, @CheckForNull String id) throws LdapInvalidAttributeValueException {
    ExternalIdentityRef ref = new ExternalIdentityRef(entry.getDn().getName(), this.getName());
    if (id == null) {
        id = entry.get(config.getUserConfig().getIdAttribute()).getString();
    }
    String path = config.getUserConfig().makeDnPath() ? createDNPath(entry.getDn()) : null;
    LdapUser user = new LdapUser(this, ref, id, path);
    Map<String, Object> props = user.getProperties();
    applyAttributes(props, entry);
    return user;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3396_c83755c3,Blocker,oak-auth-ldap/src/main/java/org/apache/jackrabbit/oak/security/authentication/ldap/impl/LdapIdentityProvider.java,716,731,"@Nonnull
private ExternalGroup createGroup(@Nonnull Entry entry, @CheckForNull String name) throws LdapInvalidAttributeValueException {
    ExternalIdentityRef ref = new ExternalIdentityRef(entry.getDn().getName(), this.getName());
    if (name == null) {
        name = entry.get(config.getGroupConfig().getIdAttribute()).getString();
    }
    String path = config.getGroupConfig().makeDnPath() ? createDNPath(entry.getDn()) : null;
    LdapGroup group = new LdapGroup(this, ref, name, path);
    Map<String, Object> props = group.getProperties();
    applyAttributes(props, entry);
    return group;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3411_978c77ff,Blocker,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,719,782,"/**
 * Get the revision of the latest change made to this node.
 *
 * @param context the revision context
 * @param changeRev the revision of the current change
 * @param handler the conflict handler, which is called for concurrent changes
 *                preceding <code>changeRev</code>.
 * @return the revision, or null if deleted
 */
@CheckForNull
public Revision getNewestRevision(final RevisionContext context, final Revision changeRev, final CollisionHandler handler) {
    final Map<Revision, String> validRevisions = Maps.newHashMap();
    Predicate<Revision> predicate = new Predicate<Revision>() {

        @Override
        public boolean apply(Revision input) {
            if (input.equals(changeRev)) {
                return false;
            }
            if (isValidRevision(context, input, null, changeRev, validRevisions)) {
                return true;
            }
            handler.concurrentModification(input);
            return false;
        }
    };
    Revision newestRev = null;
    // check local commits first
    Comparator<Revision> comp = reverseOrder(context.getRevisionComparator());
    SortedSet<Revision> revisions = Sets.newTreeSet(comp);
    revisions.addAll(getLocalRevisions().keySet());
    revisions.addAll(getLocalCommitRoot().keySet());
    Iterator<Revision> it = filter(revisions, predicate).iterator();
    if (it.hasNext()) {
        newestRev = it.next();
    } else {
        // check full history (only needed in rare cases)
        if (LOG.isDebugEnabled()) {
            LOG.debug(""getNewestRevision() with changeRev {} on {}, "" + ""_revisions {}, _commitRoot {}"", changeRev, getId(), getLocalRevisions(), getLocalCommitRoot());
        }
        it = filter(getAllChanges(), predicate).iterator();
        if (it.hasNext()) {
            newestRev = it.next();
        }
    }
    if (newestRev == null) {
        return null;
    }
    // the local deleted map contains the most recent revisions
    SortedMap<Revision, String> deleted = getLocalDeleted();
    String value = deleted.get(newestRev);
    if (value == null && deleted.headMap(newestRev).isEmpty()) {
        // no need to check previous docs
        return newestRev;
    }
    if (value == null) {
        // get from complete map
        value = getDeleted().get(newestRev);
    }
    if (""true"".equals(value)) {
        // deleted in the newest revision
        return null;
    }
    return newestRev;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3412_2f85bd78,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/name/Namespaces.java,240,262,"public static boolean isValidLocalName(String local) {
    if (local.isEmpty() || ""."".equals(local) || "".."".equals(local)) {
        return false;
    }
    for (int i = 0; i < local.length(); i++) {
        char ch = local.charAt(i);
        if (Character.isSpaceChar(ch)) {
            if (i == 0) {
                // leading whitespace
                return false;
            } else if (i == local.length() - 1) {
                // trailing whitespace
                return false;
            } else if (ch != ' ') {
                // only spaces are allowed as whitespace
                return false;
            }
        } else if (""/:[]|*"".indexOf(ch) != -1) {
            // invalid name character
            return false;
        }
    }
    // TODO: Other name rules?
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3424_f4349a96,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfo.java,364,409,"/**
 * Create a cluster node info instance for the store.
 *
 * @param store the document store (for the lease)
 * @param machineId the machine id (null for MAC address)
 * @param instanceId the instance id (null for current working directory)
 * @param configuredClusterId the configured cluster id (or 0 for dynamic assignment)
 * @param updateLease whether to update the lease
 * @return the cluster node info
 */
public static ClusterNodeInfo getInstance(DocumentStore store, String machineId, String instanceId, int configuredClusterId, boolean updateLease) {
    // defaults for machineId and instanceID
    if (machineId == null) {
        machineId = MACHINE_ID;
    }
    if (instanceId == null) {
        instanceId = WORKING_DIR;
    }
    int retries = 10;
    for (int i = 0; i < retries; i++) {
        ClusterNodeInfo clusterNode = createInstance(store, machineId, instanceId, configuredClusterId);
        String key = String.valueOf(clusterNode.id);
        UpdateOp update = new UpdateOp(key, true);
        update.set(ID, key);
        update.set(MACHINE_ID_KEY, clusterNode.machineId);
        update.set(INSTANCE_ID_KEY, clusterNode.instanceId);
        if (updateLease) {
            update.set(LEASE_END_KEY, getCurrentTime() + clusterNode.leaseTime);
        } else {
            update.set(LEASE_END_KEY, clusterNode.leaseEndTime);
        }
        update.set(INFO_KEY, clusterNode.toString());
        update.set(STATE, clusterNode.state.name());
        update.set(REV_RECOVERY_LOCK, clusterNode.revRecoveryLock.name());
        update.set(OAK_VERSION_KEY, OAK_VERSION);
        final boolean success;
        if (clusterNode.newEntry) {
            // For new entry do a create. This ensures that if two nodes
            // create entry with same id then only one would succeed
            success = store.create(Collection.CLUSTER_NODES, Collections.singletonList(update));
        } else {
            // No expiration of earlier cluster info, so update
            store.createOrUpdate(Collection.CLUSTER_NODES, update);
            success = true;
        }
        if (success) {
            return clusterNode;
        }
    }
    throw new DocumentStoreException(""Could not get cluster node info (retried "" + retries + "" times)"");
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3424_f4349a96,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ClusterNodeInfo.java,411,507,"private static ClusterNodeInfo createInstance(DocumentStore store, String machineId, String instanceId, int configuredClusterId) {
    long now = getCurrentTime();
    int clusterNodeId = 0;
    int maxId = 0;
    ClusterNodeState state = ClusterNodeState.NONE;
    Long prevLeaseEnd = null;
    boolean newEntry = false;
    ClusterNodeInfoDocument alreadyExistingConfigured = null;
    String reuseFailureReason = """";
    List<ClusterNodeInfoDocument> list = ClusterNodeInfoDocument.all(store);
    for (ClusterNodeInfoDocument doc : list) {
        String key = doc.getId();
        int id;
        try {
            id = doc.getClusterId();
        } catch (Exception e) {
            LOG.debug(""Skipping cluster node info document {} because ID is invalid"", key);
            continue;
        }
        maxId = Math.max(maxId, id);
        // not match
        if (configuredClusterId != 0) {
            if (configuredClusterId != id) {
                continue;
            } else {
                alreadyExistingConfigured = doc;
            }
        }
        Long leaseEnd = (Long) doc.get(LEASE_END_KEY);
        if (leaseEnd != null && leaseEnd > now) {
            // TODO wait for lease end, see OAK-3449
            reuseFailureReason = ""leaseEnd "" + leaseEnd + "" > "" + now + "" - "" + (leaseEnd - now) + ""ms in the future"";
            continue;
        }
        String mId = """" + doc.get(MACHINE_ID_KEY);
        String iId = """" + doc.get(INSTANCE_ID_KEY);
        // remove entries with ""random:"" keys if not in use (no lease at all)
        if (mId.startsWith(RANDOM_PREFIX) && leaseEnd == null) {
            store.remove(Collection.CLUSTER_NODES, key);
            LOG.debug(""Cleaned up cluster node info for clusterNodeId {} [machineId: {}, leaseEnd: {}]"", id, mId, leaseEnd == null ? ""n/a"" : Utils.timestampToString(leaseEnd));
            if (alreadyExistingConfigured == doc) {
                // we removed it, so we can't re-use it after all
                alreadyExistingConfigured = null;
            }
            continue;
        }
        if (!mId.equals(machineId) || !iId.equals(instanceId)) {
            // a different machine or instance
            reuseFailureReason = ""machineId/instanceId do not match: "" + mId + ""/"" + iId + "" != "" + machineId + ""/"" + instanceId;
            continue;
        }
        // not being used
        if (clusterNodeId == 0 || id < clusterNodeId) {
            // if there are multiple, use the smallest value
            clusterNodeId = id;
            state = ClusterNodeState.fromString((String) doc.get(STATE));
            prevLeaseEnd = leaseEnd;
        }
    }
    // create a new entry
    if (clusterNodeId == 0) {
        newEntry = true;
        if (configuredClusterId != 0) {
            if (alreadyExistingConfigured != null) {
                throw new DocumentStoreException(""Configured cluster node id "" + configuredClusterId + "" already in use: "" + reuseFailureReason);
            }
            clusterNodeId = configuredClusterId;
        } else {
            clusterNodeId = maxId + 1;
        }
    }
    // that _lastRev recovery if needed is done.
    return new ClusterNodeInfo(clusterNodeId, store, machineId, instanceId, state, RecoverLockState.NONE, prevLeaseEnd, newEntry);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3433_b76b31f7,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,2084,2094,"BackgroundWriteStats backgroundWrite() {
    return unsavedLastRevisions.persist(this, new UnsavedModifications.Snapshot() {

        @Override
        public void acquiring() {
            if (store.create(JOURNAL, singletonList(changes.asUpdateOp(getHeadRevision())))) {
                changes = JOURNAL.newDocument(getDocumentStore());
            }
        }
    }, backgroundOperationLock.writeLock());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3433_b76b31f7,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,2086,2092,"@Override
public void acquiring() {
    if (store.create(JOURNAL, singletonList(changes.asUpdateOp(getHeadRevision())))) {
        changes = JOURNAL.newDocument(getDocumentStore());
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3433_b76b31f7,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryAgent.java,136,271,"/**
 * Recover the correct _lastRev updates for the given candidate nodes.
 *
 * @param suspects the potential suspects
 * @param clusterId the cluster id for which _lastRev recovery needed
 * @param dryRun if {@code true}, this method will only perform a check
 *               but not apply the changes to the _lastRev fields.
 * @return the number of documents that required recovery. This method
 *          returns the number of the affected documents even if
 *          {@code dryRun} is set true and no document was changed.
 */
public int recover(Iterator<NodeDocument> suspects, int clusterId, boolean dryRun) {
    UnsavedModifications unsaved = new UnsavedModifications();
    UnsavedModifications unsavedParents = new UnsavedModifications();
    // Map of known last rev of checked paths
    Map<String, Revision> knownLastRevOrModification = MapFactory.getInstance().create();
    final DocumentStore docStore = nodeStore.getDocumentStore();
    final JournalEntry changes = JOURNAL.newDocument(docStore);
    long count = 0;
    while (suspects.hasNext()) {
        NodeDocument doc = suspects.next();
        count++;
        if (count % 100000 == 0) {
            log.info(""Scanned {} suspects so far..."", count);
        }
        Revision currentLastRev = doc.getLastRev().get(clusterId);
        // 1. determine last committed modification on document
        Revision lastModifiedRev = determineLastModification(doc, clusterId);
        Revision lastRevForParents = Utils.max(lastModifiedRev, currentLastRev);
        // _lastRev entry or an explicit modification on the document
        if (lastRevForParents != null) {
            knownLastRevOrModification.put(doc.getPath(), lastRevForParents);
        }
        // 2. Update lastRev for parent paths aka rollup
        if (lastRevForParents != null) {
            String path = doc.getPath();
            // track all changes
            changes.modified(path);
            while (true) {
                if (PathUtils.denotesRoot(path)) {
                    break;
                }
                path = PathUtils.getParentPath(path);
                unsavedParents.put(path, lastRevForParents);
            }
        }
    }
    for (String parentPath : unsavedParents.getPaths()) {
        Revision calcLastRev = unsavedParents.get(parentPath);
        Revision knownLastRev = knownLastRevOrModification.get(parentPath);
        if (knownLastRev == null) {
            // we don't know when the document was last modified with
            // the given clusterId. need to read from store
            String id = Utils.getIdFromPath(parentPath);
            NodeDocument doc = docStore.find(NODES, id);
            if (doc != null) {
                Revision lastRev = doc.getLastRev().get(clusterId);
                Revision lastMod = determineLastModification(doc, clusterId);
                knownLastRev = Utils.max(lastRev, lastMod);
            } else {
                log.warn(""Unable to find document: {}"", id);
                continue;
            }
        }
        // This check ensures that unnecessary updates are not made
        if (knownLastRev == null || calcLastRev.compareRevisionTime(knownLastRev) > 0) {
            unsaved.put(parentPath, calcLastRev);
        }
    }
    // take the root's lastRev
    final Revision lastRootRev = unsaved.get(""/"");
    // Note the size before persist as persist operation
    // would empty the internal state
    int size = unsaved.getPaths().size();
    String updates = unsaved.toString();
    if (dryRun) {
        log.info(""Dry run of lastRev recovery identified [{}] documents for "" + ""cluster node [{}]: {}"", size, clusterId, updates);
    } else {
        // UnsavedModifications is designed to be used in concurrent
        // access mode. For recovery case there is no concurrent access
        // involve so just pass a new lock instance
        // the lock uses to do the persisting is a plain reentrant lock
        // thus it doesn't matter, where exactly the check is done
        // as to whether the recovered lastRev has already been
        // written to the journal.
        unsaved.persist(nodeStore, new UnsavedModifications.Snapshot() {

            @Override
            public void acquiring() {
                if (lastRootRev == null) {
                    // then we cannot and probably don't have to persist anything
                    return;
                }
                // lastRootRev never null at this point
                final String id = JournalEntry.asId(lastRootRev);
                final JournalEntry existingEntry = docStore.find(Collection.JOURNAL, id);
                if (existingEntry != null) {
                    // hence: nothing to be done here. return.
                    return;
                }
                // otherwise store a new journal entry now
                docStore.create(JOURNAL, singletonList(changes.asUpdateOp(lastRootRev)));
            }
        }, new ReentrantLock());
        log.info(""Updated lastRev of [{}] documents while performing lastRev recovery for "" + ""cluster node [{}]: {}"", size, clusterId, updates);
    }
    return size;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3433_b76b31f7,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/LastRevRecoveryAgent.java,237,263,"@Override
public void acquiring() {
    if (lastRootRev == null) {
        // then we cannot and probably don't have to persist anything
        return;
    }
    // lastRootRev never null at this point
    final String id = JournalEntry.asId(lastRootRev);
    final JournalEntry existingEntry = docStore.find(Collection.JOURNAL, id);
    if (existingEntry != null) {
        // hence: nothing to be done here. return.
        return;
    }
    // otherwise store a new journal entry now
    docStore.create(JOURNAL, singletonList(changes.asUpdateOp(lastRootRev)));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3433_b76b31f7,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UnsavedModifications.java,143,230,"/**
 * Persist the pending changes to _lastRev to the given store. This method
 * will persist a snapshot of the pending revisions by acquiring the passed
 * lock for a short period of time.
 *
 * @param store the document node store.
 * @param snapshot callback when the snapshot of the pending changes is
 *                 acquired.
 * @param lock the lock to acquire to get a consistent snapshot of the
 *             revisions to write back.
 * @return stats about the write operation.
 */
public BackgroundWriteStats persist(@Nonnull DocumentNodeStore store, @Nonnull Snapshot snapshot, @Nonnull Lock lock) {
    BackgroundWriteStats stats = new BackgroundWriteStats();
    if (map.size() == 0) {
        return stats;
    }
    checkNotNull(store);
    checkNotNull(lock);
    Clock clock = store.getClock();
    long time = clock.getTime();
    // get a copy of the map while holding the lock
    lock.lock();
    stats.lock = clock.getTime() - time;
    time = clock.getTime();
    Map<String, Revision> pending;
    try {
        snapshot.acquiring();
        pending = Maps.newTreeMap(PathComparator.INSTANCE);
        pending.putAll(map);
    } finally {
        lock.unlock();
    }
    stats.num = pending.size();
    UpdateOp updateOp = null;
    Revision lastRev = null;
    PeekingIterator<String> paths = Iterators.peekingIterator(pending.keySet().iterator());
    int i = 0;
    ArrayList<String> pathList = new ArrayList<String>();
    while (paths.hasNext()) {
        String p = paths.peek();
        Revision r = pending.get(p);
        int size = pathList.size();
        if (updateOp == null) {
            // create UpdateOp
            Commit commit = new Commit(store, r, null, null);
            updateOp = commit.getUpdateOperationForNode(p);
            NodeDocument.setLastRev(updateOp, r);
            lastRev = r;
            pathList.add(p);
            paths.next();
            i++;
        } else if (r.equals(lastRev)) {
            // use multi update when possible
            pathList.add(p);
            paths.next();
            i++;
        }
        // - the update limit is reached
        if (i + 2 > pending.size() || size == pathList.size() || pathList.size() >= BACKGROUND_MULTI_UPDATE_LIMIT) {
            List<String> ids = new ArrayList<String>();
            for (String path : pathList) {
                ids.add(Utils.getIdFromPath(path));
            }
            store.getDocumentStore().update(NODES, ids, updateOp);
            LOG.debug(""Updated _lastRev to {} on {}"", lastRev, ids);
            for (String path : pathList) {
                map.remove(path, lastRev);
            }
            pathList.clear();
            updateOp = null;
            lastRev = null;
        }
    }
    Revision writtenRootRev = pending.get(""/"");
    if (writtenRootRev != null) {
        int cid = writtenRootRev.getClusterId();
        if (store.getDocumentStore().find(org.apache.jackrabbit.oak.plugins.document.Collection.CLUSTER_NODES, String.valueOf(cid)) != null) {
            UpdateOp update = new UpdateOp(String.valueOf(cid), false);
            update.equals(Document.ID, null, String.valueOf(cid));
            update.set(ClusterNodeInfo.LAST_WRITTEN_ROOT_REV_KEY, writtenRootRev.toString());
            store.getDocumentStore().findAndUpdate(org.apache.jackrabbit.oak.plugins.document.Collection.CLUSTER_NODES, update);
        }
    }
    stats.write = clock.getTime() - time;
    return stats;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3433_b76b31f7,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UnsavedModifications.java,240,242,"@Override
public void acquiring() {
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3433_b76b31f7,Critical,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/UnsavedModifications.java,245,245,void acquiring();
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3442_17032c50,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java,205,227,"@Override
public List<IndexPlan> getPlans(Filter filter, List<OrderEntry> sortOrder, NodeState rootState) {
    Collection<String> indexPaths = new LuceneIndexLookup(rootState).collectIndexNodePaths(filter);
    List<IndexPlan> plans = Lists.newArrayListWithCapacity(indexPaths.size());
    IndexNode indexNode = null;
    for (String path : indexPaths) {
        try {
            indexNode = tracker.acquireIndexNode(path);
            if (indexNode != null) {
                IndexPlan plan = new IndexPlanner(indexNode, path, filter, sortOrder).getPlan();
                if (plan != null) {
                    plans.add(plan);
                }
            }
        } finally {
            if (indexNode != null) {
                indexNode.release();
            }
        }
    }
    return plans;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3474_ff81ef72,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,936,1043,"/**
 * Returns a {@link DocumentNodeState} as seen at the given
 * <code>readRevision</code>.
 *
 * @param nodeStore    the node store.
 * @param readRevision the read revision.
 * @param lastModified the revision when this node was last modified, but
 *                     the value is potentially not yet reflected in this
 *                     document.
 *                     See {@link RevisionContext#getPendingModifications()}.
 * @return the node or <code>null</code> if the node doesn't exist at the
 *         given read revision.
 */
@CheckForNull
public DocumentNodeState getNodeAtRevision(@Nonnull DocumentNodeStore nodeStore, @Nonnull Revision readRevision, @Nullable Revision lastModified) {
    Map<Revision, String> validRevisions = Maps.newHashMap();
    Branch branch = nodeStore.getBranches().getBranch(readRevision);
    LastRevs lastRevs = new LastRevs(getLastRev(), readRevision, branch);
    // overlay with unsaved last modified from this instance
    lastRevs.update(lastModified);
    Revision min = getLiveRevision(nodeStore, readRevision, validRevisions, lastRevs);
    if (min == null) {
        // deleted
        return null;
    }
    String path = getPath();
    DocumentNodeState n = new DocumentNodeState(nodeStore, path, readRevision, hasChildren());
    Revision lastRevision = min;
    for (String key : keySet()) {
        if (!Utils.isPropertyName(key)) {
            continue;
        }
        // ignore when local map is empty (OAK-2442)
        SortedMap<Revision, String> local = getLocalMap(key);
        if (local.isEmpty()) {
            continue;
        }
        // first check local map, which contains most recent values
        Value value = getLatestValue(nodeStore, local, min, readRevision, validRevisions, lastRevs);
        // check if there may be more recent values in a previous document
        if (!getPreviousRanges().isEmpty()) {
            Revision newest = local.firstKey();
            if (isRevisionNewer(nodeStore, newest, value.revision)) {
                // not reading the most recent value, we may need to
                // consider previous documents as well
                Revision newestPrev = getPreviousRanges().firstKey();
                if (isRevisionNewer(nodeStore, newestPrev, value.revision)) {
                    // a previous document has more recent changes
                    // than value.revision
                    value = null;
                }
            }
        }
        if (value == null && !getPreviousRanges().isEmpty()) {
            // check complete revision history
            value = getLatestValue(nodeStore, getValueMap(key), min, readRevision, validRevisions, lastRevs);
        }
        String propertyName = Utils.unescapePropertyName(key);
        String v = value != null ? value.value : null;
        n.setProperty(propertyName, v);
        // keep track of when this node was last modified
        if (value != null && isRevisionNewer(nodeStore, value.revision, lastRevision)) {
            lastRevision = value.revision;
        }
    }
    // lastRevision now points to the revision when this node was
    // last modified directly. but it may also have been 'modified'
    // by an operation on a descendant node, which is tracked in
    // _lastRev.
    // when was this node last modified?
    Revision branchBase = null;
    if (branch != null) {
        branchBase = branch.getBase(readRevision);
    }
    for (Revision r : lastRevs.get().values()) {
        // ignore if newer than readRevision
        if (isRevisionNewer(nodeStore, r, readRevision)) {
            // the node has a _lastRev which is newer than readRevision
            // this means we don't know when this node was
            // modified by an operation on a descendant node between
            // current lastRevision and readRevision. therefore we have
            // to stay on the safe side and use readRevision
            lastRevision = readRevision;
            continue;
        } else if (branchBase != null && isRevisionNewer(nodeStore, r, branchBase)) {
            // readRevision is on a branch and the node has a
            // _lastRev which is newer than the base of the branch
            // we cannot use this _lastRev because it is not visible
            // from this branch. highest possible revision of visible
            // changes is the base of the branch
            r = branchBase;
        }
        if (revisionAreAmbiguous(nodeStore, r, lastRevision)) {
            // _lastRev entries from multiple cluster nodes are ambiguous
            // use readRevision to make sure read is consistent
            lastRevision = readRevision;
        } else if (isRevisionNewer(nodeStore, r, lastRevision)) {
            lastRevision = r;
        }
    }
    if (branch != null) {
        // read from a branch
        // -> possibly overlay with unsaved last revs from branch
        lastRevs.updateBranch(branch.getUnsavedLastRevision(path, readRevision));
        Revision r = lastRevs.getBranchRevision();
        if (r != null) {
            lastRevision = r;
        }
    }
    n.setLastRevision(lastRevision);
    return n;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3510_01f5a26f,Major,oak-auth-external/src/main/java/org/apache/jackrabbit/oak/spi/security/authentication/external/ExternalIdentityRef.java,85,95,"/**
 * Creates an external identity reference from a string representation.
 * @param str the string
 * @return the reference
 */
public static ExternalIdentityRef fromString(@Nonnull String str) {
    int idx = str.indexOf(';');
    if (idx < 0) {
        return new ExternalIdentityRef(Text.unescape(str), null);
    } else {
        return new ExternalIdentityRef(Text.unescape(str.substring(0, idx)), Text.unescape(str.substring(idx + 1)));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3510_01f5a26f,Major,oak-auth-external/src/main/java/org/apache/jackrabbit/oak/spi/security/authentication/external/ExternalIdentityRef.java,102,114,"/**
 * Escapes the given string and appends it to the builder.
 * @param builder the builder
 * @param str the string
 */
private void escape(StringBuilder builder, CharSequence str) {
    final int len = str.length();
    for (int i = 0; i < len; i++) {
        char c = str.charAt(i);
        if (c == '%') {
            builder.append(""%25"");
        } else if (c == ';') {
            builder.append(""%3b"");
        } else {
            builder.append(c);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3510_01f5a26f,Major,oak-auth-external/src/main/java/org/apache/jackrabbit/oak/spi/security/authentication/external/ExternalIdentityRef.java,124,132,"/**
 * Tests if the given object is an external identity reference and if it's getString() is equal to this.
 */
@Override
public boolean equals(Object o) {
    try {
        // assuming that we never compare other types of classes
        return this == o || string.equals(((ExternalIdentityRef) o).string);
    } catch (Exception e) {
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3511_5138a1e2,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/segment/PersistedCompactionMap.java,176,238,"private void compress(@Nonnull Set<UUID> removed) {
    if (recent.isEmpty() && removed.isEmpty()) {
        return;
    }
    SegmentWriter writer = null;
    Map<String, RecordId> segmentIdMap = newHashMap();
    for (Entry<UUID, RecordIdMap> recentEntry : recent.entrySet()) {
        UUID uuid = recentEntry.getKey();
        RecordIdMap newSegment = recentEntry.getValue();
        if (removed.contains(uuid)) {
            continue;
        }
        MapRecord base;
        MapEntry baseEntry = entries == null ? null : entries.getEntry(uuid.toString());
        base = baseEntry == null ? null : new MapRecord(baseEntry.getValue());
        if (writer == null) {
            writer = store.createSegmentWriter();
        }
        Map<String, RecordId> offsetMap = newHashMap();
        for (int k = 0; k < newSegment.size(); k++) {
            offsetMap.put(String.valueOf(newSegment.getKey(k)), writer.writeString(newSegment.getRecordId(k).toString10()));
        }
        RecordId newEntryId = writer.writeMap(base, offsetMap).getRecordId();
        segmentIdMap.put(uuid.toString(), newEntryId);
        recordCount += offsetMap.size();
    }
    if (entries != null) {
        for (UUID uuid : removed) {
            MapEntry toRemove = entries.getEntry(uuid.toString());
            if (toRemove != null) {
                segmentIdMap.put(uuid.toString(), null);
                recordCount -= new MapRecord(toRemove.getValue()).size();
            }
        }
    }
    if (!segmentIdMap.isEmpty()) {
        if (writer == null) {
            writer = store.createSegmentWriter();
        }
        RecordId previousBaseId = entries == null ? null : entries.getRecordId();
        entries = writer.writeMap(entries, segmentIdMap);
        entries.getSegment().getSegmentId().pin();
        String mapInfo = PERSISTED_COMPACTION_MAP + '{' + ""id="" + entries.getRecordId() + "", baseId="" + previousBaseId + '}';
        writer.writeString(mapInfo);
        writer.flush();
        recent.clear();
    }
    if (recordCount == 0) {
        entries = null;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3517_24f7f60a,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/NodeImpl.java,250,308,"@Override
@Nonnull
public Node addNode(final String relPath, String primaryNodeTypeName) throws RepositoryException {
    final String oakPath = getOakPathOrThrowNotFound(relPath);
    final String oakTypeName;
    if (primaryNodeTypeName != null) {
        oakTypeName = getOakName(primaryNodeTypeName);
    } else {
        oakTypeName = null;
    }
    checkIndexOnName(relPath);
    return perform(new ItemWriteOperation<Node>(""addNode"") {

        @Nonnull
        @Override
        public Node perform() throws RepositoryException {
            String oakName = PathUtils.getName(oakPath);
            String parentPath = PathUtils.getParentPath(oakPath);
            NodeDelegate parent = dlg.getChild(parentPath);
            if (parent == null) {
                // is it a property?
                String grandParentPath = PathUtils.getParentPath(parentPath);
                NodeDelegate grandParent = dlg.getChild(grandParentPath);
                if (grandParent != null) {
                    String propName = PathUtils.getName(parentPath);
                    if (grandParent.getPropertyOrNull(propName) != null) {
                        throw new ConstraintViolationException(""Can't add new node to property."");
                    }
                }
                throw new PathNotFoundException(relPath);
            }
            if (parent.getChild(oakName) != null) {
                throw new ItemExistsException(relPath);
            }
            // modification of that property in the PermissionValidator
            if (oakTypeName != null) {
                PropertyState prop = PropertyStates.createProperty(JCR_PRIMARYTYPE, oakTypeName, NAME);
                sessionContext.getAccessManager().checkPermissions(dlg.getTree(), prop, Permissions.NODE_TYPE_MANAGEMENT);
            }
            NodeDelegate added = parent.addChild(oakName, oakTypeName);
            if (added == null) {
                throw new ItemExistsException();
            }
            return createNode(added, sessionContext);
        }

        @Override
        public String toString() {
            return String.format(""Adding node [%s/%s]"", dlg.getPath(), relPath);
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3517_24f7f60a,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/session/NodeImpl.java,263,301,"@Nonnull
@Override
public Node perform() throws RepositoryException {
    String oakName = PathUtils.getName(oakPath);
    String parentPath = PathUtils.getParentPath(oakPath);
    NodeDelegate parent = dlg.getChild(parentPath);
    if (parent == null) {
        // is it a property?
        String grandParentPath = PathUtils.getParentPath(parentPath);
        NodeDelegate grandParent = dlg.getChild(grandParentPath);
        if (grandParent != null) {
            String propName = PathUtils.getName(parentPath);
            if (grandParent.getPropertyOrNull(propName) != null) {
                throw new ConstraintViolationException(""Can't add new node to property."");
            }
        }
        throw new PathNotFoundException(relPath);
    }
    if (parent.getChild(oakName) != null) {
        throw new ItemExistsException(relPath);
    }
    // modification of that property in the PermissionValidator
    if (oakTypeName != null) {
        PropertyState prop = PropertyStates.createProperty(JCR_PRIMARYTYPE, oakTypeName, NAME);
        sessionContext.getAccessManager().checkPermissions(dlg.getTree(), prop, Permissions.NODE_TYPE_MANAGEMENT);
    }
    NodeDelegate added = parent.addChild(oakName, oakTypeName);
    if (added == null) {
        throw new ItemExistsException();
    }
    return createNode(added, sessionContext);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3530_4d231938,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/TreeTypeProvider.java,64,70,"public int getType(Tree tree) {
    if (tree.isRoot()) {
        return TYPE_DEFAULT;
    } else {
        return getType(tree, getType(tree.getParent()));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3530_4d231938,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/permission/TreeTypeProvider.java,72,106,"public int getType(Tree tree, int parentType) {
    if (tree.isRoot()) {
        return TYPE_DEFAULT;
    }
    int type;
    switch(parentType) {
        case TYPE_HIDDEN:
            type = TYPE_HIDDEN;
            break;
        case TYPE_VERSION:
            type = TYPE_VERSION;
            break;
        case TYPE_INTERNAL:
            type = TYPE_INTERNAL;
            break;
        case TYPE_AC:
            type = TYPE_AC;
            break;
        default:
            String name = tree.getName();
            if (NodeStateUtils.isHidden(name)) {
                type = TYPE_HIDDEN;
            } else if (VersionConstants.VERSION_STORE_ROOT_NAMES.contains(name)) {
                type = TYPE_VERSION;
            } else if (PermissionConstants.REP_PERMISSION_STORE.equals(name)) {
                type = TYPE_INTERNAL;
            } else if (contextInfo.definesContextRoot(tree)) {
                type = TYPE_AC;
            } else {
                type = TYPE_DEFAULT;
            }
    }
    return type;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3549_9772f5b2,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentMK.java,129,131,"void backgroundRead() {
    nodeStore.backgroundRead(true);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3549_9772f5b2,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1692,1706,"/**
 * OAK-2624 : background read operations are split from background update ops
 */
private void internalRunBackgroundReadOperations() {
    synchronized (backgroundReadMonitor) {
        long start = clock.getTime();
        // pull in changes from other cluster nodes
        BackgroundReadStats readStats = backgroundRead(true);
        long readTime = clock.getTime() - start;
        String msg = ""Background read operations stats (read:{} {})"";
        if (clock.getTime() - start > TimeUnit.SECONDS.toMillis(10)) {
            // log as info if it took more than 10 seconds
            LOG.info(msg, readTime, readStats);
        } else {
            LOG.debug(msg, readTime, readStats);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3549_9772f5b2,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1769,1932,"/**
 * Perform a background read and make external changes visible.
 *
 * @param dispatchChange whether to dispatch external changes
 *                       to {@link #dispatcher}.
 */
BackgroundReadStats backgroundRead(boolean dispatchChange) {
    BackgroundReadStats stats = new BackgroundReadStats();
    long time = clock.getTime();
    String id = Utils.getIdFromPath(""/"");
    NodeDocument doc = store.find(Collection.NODES, id, asyncDelay);
    if (doc == null) {
        return stats;
    }
    Map<Integer, Revision> lastRevMap = doc.getLastRev();
    try {
        long externalTime = Utils.getMaxExternalTimestamp(lastRevMap.values(), clusterId);
        long localTime = clock.getTime();
        if (localTime < externalTime) {
            LOG.warn(""Detected clock differences. Local time is '{}', "" + ""while most recent external time is '{}'. "" + ""Current _lastRev entries: {}"", new Date(localTime), new Date(externalTime), lastRevMap.values());
            double delay = ((double) externalTime - localTime) / 1000d;
            String msg = String.format(""Background read will be delayed by %.1f seconds. "" + ""Please check system time on cluster nodes."", delay);
            LOG.warn(msg);
            clock.waitUntil(externalTime + 1);
        } else if (localTime == externalTime) {
            // make sure local time is past external time
            // but only log at debug
            LOG.debug(""Local and external time are equal. Waiting until local"" + ""time is more recent than external reported time."");
            clock.waitUntil(externalTime + 1);
        }
    } catch (InterruptedException e) {
        throw new RuntimeException(""Background read interrupted"", e);
    }
    Revision.RevisionComparator revisionComparator = getRevisionComparator();
    // the (old) head occurred first
    Revision headSeen = Revision.newRevision(0);
    // then we saw this new revision (from another cluster node)
    Revision otherSeen = Revision.newRevision(0);
    StringSort externalSort = JournalEntry.newSorter();
    try {
        Map<Revision, Revision> externalChanges = Maps.newHashMap();
        for (Map.Entry<Integer, Revision> e : lastRevMap.entrySet()) {
            int machineId = e.getKey();
            if (machineId == clusterId) {
                // ignore own lastRev
                continue;
            }
            Revision r = e.getValue();
            Revision last = lastKnownRevision.get(machineId);
            if (last == null || r.compareRevisionTime(last) > 0) {
                lastKnownRevision.put(machineId, r);
                // - the revision is within the time frame we remember revisions
                if (last != null || r.getTimestamp() > revisionPurgeMillis()) {
                    externalChanges.put(r, otherSeen);
                }
                // collect external changes
                if (last != null && externalSort != null) {
                    // add changes for this particular clusterId to the externalSort
                    try {
                        fillExternalChanges(externalSort, last, r, store);
                    } catch (IOException e1) {
                        LOG.error(""backgroundRead: Exception while reading external changes from journal: "" + e1, e1);
                        IOUtils.closeQuietly(externalSort);
                        externalSort = null;
                    }
                }
            }
        }
        stats.readHead = clock.getTime() - time;
        time = clock.getTime();
        if (!externalChanges.isEmpty()) {
            // invalidate caches
            if (externalSort == null) {
                // if no externalSort available, then invalidate the classic way: everything
                stats.cacheStats = store.invalidateCache();
                docChildrenCache.invalidateAll();
            } else {
                try {
                    externalSort.sort();
                    stats.cacheStats = store.invalidateCache(pathToId(externalSort));
                    // OAK-3002: only invalidate affected items (using journal)
                    long origSize = docChildrenCache.size();
                    if (origSize == 0) {
                        // if docChildrenCache is empty, don't bother
                        // calling invalidateAll either way
                        // (esp calling invalidateAll(Iterable) will
                        // potentially iterate over all keys even though
                        // there's nothing to be deleted)
                        LOG.trace(""backgroundRead: docChildrenCache nothing to invalidate"");
                    } else {
                        // however, if the docChildrenCache is not empty,
                        // use the invalidateAll(Iterable) variant,
                        // passing it a Iterable<StringValue>, as that's
                        // what is contained in the cache
                        docChildrenCache.invalidateAll(asStringValueIterable(externalSort));
                        long newSize = docChildrenCache.size();
                        LOG.trace(""backgroundRead: docChildrenCache invalidation result: orig: {}, new: {} "", origSize, newSize);
                    }
                } catch (Exception ioe) {
                    LOG.error(""backgroundRead: got IOException during external sorting/cache invalidation (as a result, invalidating entire cache): "" + ioe, ioe);
                    stats.cacheStats = store.invalidateCache();
                    docChildrenCache.invalidateAll();
                }
            }
            stats.cacheInvalidationTime = clock.getTime() - time;
            time = clock.getTime();
            // make sure update to revision comparator is atomic
            // and no local commit is in progress
            backgroundOperationLock.writeLock().lock();
            try {
                stats.lock = clock.getTime() - time;
                // the latest revisions of the current cluster node
                // happened before the latest revisions of other cluster nodes
                revisionComparator.add(newRevision(), headSeen);
                // then we saw other revisions
                for (Map.Entry<Revision, Revision> e : externalChanges.entrySet()) {
                    revisionComparator.add(e.getKey(), e.getValue());
                }
                Revision oldHead = headRevision;
                // the new head revision is after other revisions
                setHeadRevision(newRevision());
                if (dispatchChange) {
                    commitQueue.headRevisionChanged();
                    time = clock.getTime();
                    if (externalSort != null) {
                        // was successful -> apply them to the diff cache
                        try {
                            JournalEntry.applyTo(externalSort, diffCache, oldHead, headRevision);
                        } catch (Exception e1) {
                            LOG.error(""backgroundRead: Exception while processing external changes from journal: {}"", e1, e1);
                        }
                    }
                    stats.populateDiffCache = clock.getTime() - time;
                    time = clock.getTime();
                    dispatcher.contentChanged(getRoot().fromExternalChange(), null);
                }
            } finally {
                backgroundOperationLock.writeLock().unlock();
            }
            stats.dispatchChanges = clock.getTime() - time;
            time = clock.getTime();
        }
    } finally {
        IOUtils.closeQuietly(externalSort);
    }
    revisionComparator.purge(revisionPurgeMillis());
    stats.purge = clock.getTime() - time;
    return stats;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3579_2565d74a,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,2574,2597,"@Override
public void run() {
    while (delay != 0 && !isDisposed.get()) {
        synchronized (isDisposed) {
            try {
                isDisposed.wait(delay);
            } catch (InterruptedException e) {
            // ignore
            }
        }
        DocumentNodeStore nodeStore = ref.get();
        if (nodeStore != null) {
            try {
                execute(nodeStore);
            } catch (Throwable t) {
                LOG.warn(""Background operation failed: "" + t.toString(), t);
            }
            delay = nodeStore.getAsyncDelay();
        } else {
            // node store not in use anymore
            break;
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3630_fcd64766,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/Aggregate.java,81,86,"public void collectAggregates(NodeState root, ResultCollector collector) {
    if (nodeTypeName.equals(ConfigUtil.getPrimaryTypeName(root))) {
        List<Matcher> matchers = createMatchers();
        collectAggregates(root, matchers, collector);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3630_fcd64766,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/Aggregate.java,228,238,"@Override
public boolean match(String name, NodeState nodeState, int depth) {
    // last segment -> add to collector if node type matches
    if (depth == maxDepth() - 1 && primaryType != null && !primaryType.equals(ConfigUtil.getPrimaryTypeName(nodeState))) {
        return false;
    }
    return super.match(name, nodeState, depth);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3630_fcd64766,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/Aggregate.java,257,260,"@Override
public Aggregate getAggregate(NodeState matchedNodeState) {
    return aggMapper.getAggregate(ConfigUtil.getPrimaryTypeName(matchedNodeState));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3634_90ad50da,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/mongo/MongoDocumentStore.java,265,313,"@Override
public CacheInvalidationStats invalidateCache(Iterable<String> keys) {
    LOG.debug(""invalidateCache: start"");
    final InvalidationResult result = new InvalidationResult();
    int size = 0;
    final Iterator<String> it = keys.iterator();
    while (it.hasNext()) {
        // read chunks of documents only
        final List<String> ids = new ArrayList<String>(IN_CLAUSE_BATCH_SIZE);
        while (it.hasNext() && ids.size() < IN_CLAUSE_BATCH_SIZE) {
            final String id = it.next();
            if (nodesCache.getIfPresent(id) != null) {
                // only add those that we actually do have cached
                ids.add(id);
            }
        }
        size += ids.size();
        if (LOG.isTraceEnabled()) {
            LOG.trace(""invalidateCache: batch size: {} of total so far {}"", ids.size(), size);
        }
        QueryBuilder query = QueryBuilder.start(Document.ID).in(ids);
        // Fetch only the modCount and id
        final BasicDBObject fields = new BasicDBObject(Document.ID, 1);
        fields.put(Document.MOD_COUNT, 1);
        DBCursor cursor = nodes.find(query.get(), fields);
        cursor.setReadPreference(ReadPreference.primary());
        result.queryCount++;
        Map<String, Number> modCounts = new HashMap<String, Number>();
        for (DBObject obj : cursor) {
            String id = (String) obj.get(Document.ID);
            Number modCount = (Number) obj.get(Document.MOD_COUNT);
            modCounts.put(id, modCount);
        }
        int invalidated = nodesCache.invalidateOutdated(modCounts);
        result.cacheEntriesProcessedCount += modCounts.size();
        result.invalidationCount += invalidated;
        result.upToDateCount = modCounts.size() - invalidated;
    }
    result.cacheSize = size;
    LOG.trace(""invalidateCache: end. total: {}"", size);
    return result;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3634_90ad50da,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/mongo/MongoDocumentStore.java,886,933,"@Override
public <T extends Document> void update(Collection<T> collection, List<String> keys, UpdateOp updateOp) {
    log(""update"", keys, updateOp);
    UpdateUtils.assertUnconditional(updateOp);
    DBCollection dbCollection = getDBCollection(collection);
    QueryBuilder query = QueryBuilder.start(Document.ID).in(keys);
    // make sure we don't modify the original updateOp
    updateOp = updateOp.copy();
    DBObject update = createUpdate(updateOp);
    final long start = PERFLOG.start();
    try {
        Map<String, NodeDocument> cachedDocs = Collections.emptyMap();
        if (collection == Collection.NODES) {
            cachedDocs = Maps.newHashMap();
            for (String key : keys) {
                cachedDocs.put(key, nodesCache.getIfPresent(key));
            }
        }
        try {
            dbCollection.update(query.get(), update, false, true);
            if (collection == Collection.NODES) {
                // update cache
                for (Entry<String, NodeDocument> entry : cachedDocs.entrySet()) {
                    // the cachedDocs is not empty, so the collection = NODES
                    Lock lock = nodeLocks.acquire(entry.getKey());
                    try {
                        if (entry.getValue() == null || entry.getValue() == NodeDocument.NULL) {
                            // make sure concurrently loaded document is
                            // invalidated
                            nodesCache.invalidate(entry.getKey());
                        } else {
                            NodeDocument newDoc = applyChanges(Collection.NODES, entry.getValue(), updateOp.shallowCopy(entry.getKey()));
                            nodesCache.replaceCachedDocument(entry.getValue(), newDoc);
                        }
                    } finally {
                        lock.unlock();
                    }
                }
            }
        } catch (MongoException e) {
            throw DocumentStoreException.convert(e);
        }
    } finally {
        PERFLOG.end(start, 1, ""update"");
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3634_90ad50da,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/rdb/RDBDocumentStore.java,1236,1322,"@CheckForNull
private <T extends Document> void internalUpdate(Collection<T> collection, List<String> ids, UpdateOp update) {
    if (isAppendableUpdate(update) && !requiresPreviousState(update)) {
        Operation modOperation = update.getChanges().get(MODIFIEDKEY);
        long modified = getModifiedFromOperation(modOperation);
        boolean modifiedIsConditional = modOperation == null || modOperation.type != UpdateOp.Operation.Type.SET;
        String appendData = ser.asString(update);
        for (List<String> chunkedIds : Lists.partition(ids, CHUNKSIZE)) {
            Set<QueryContext> seenQueryContext = Collections.emptySet();
            Map<String, NodeDocument> cachedDocs = Collections.emptyMap();
            if (collection == Collection.NODES) {
                // remember what we already have in the cache
                cachedDocs = new HashMap<String, NodeDocument>();
                for (String key : chunkedIds) {
                    cachedDocs.put(key, nodesCache.getIfPresent(key));
                }
                // keep concurrently running queries from updating
                // the cache entry for this key
                seenQueryContext = new HashSet<QueryContext>();
                for (QueryContext qc : qmap.values()) {
                    qc.addKeys(chunkedIds);
                    seenQueryContext.add(qc);
                }
            }
            Connection connection = null;
            RDBTableMetaData tmd = getTable(collection);
            boolean success = false;
            try {
                connection = this.ch.getRWConnection();
                success = db.batchedAppendingUpdate(connection, tmd, chunkedIds, modified, modifiedIsConditional, appendData);
                connection.commit();
            } catch (SQLException ex) {
                success = false;
                this.ch.rollbackConnection(connection);
            } finally {
                this.ch.closeConnection(connection);
            }
            if (success) {
                if (collection == Collection.NODES) {
                    // the cache entry for this key
                    for (QueryContext qc : qmap.values()) {
                        if (!seenQueryContext.contains(qc)) {
                            qc.addKeys(chunkedIds);
                        }
                    }
                }
                for (Entry<String, NodeDocument> entry : cachedDocs.entrySet()) {
                    T oldDoc = castAsT(entry.getValue());
                    String id = entry.getKey();
                    Lock lock = locks.acquire(id);
                    try {
                        if (oldDoc == null) {
                            // make sure concurrently loaded document is
                            // invalidated
                            nodesCache.invalidate(id);
                        } else {
                            addUpdateCounters(update);
                            T newDoc = createNewDocument(collection, oldDoc, update);
                            nodesCache.replaceCachedDocument((NodeDocument) oldDoc, (NodeDocument) newDoc);
                        }
                    } finally {
                        lock.unlock();
                    }
                }
            } else {
                for (String id : chunkedIds) {
                    UpdateOp up = update.copy();
                    up = up.shallowCopy(id);
                    internalCreateOrUpdate(collection, up, false, true);
                }
            }
        }
    } else {
        for (String id : ids) {
            UpdateOp up = update.copy();
            up = up.shallowCopy(id);
            internalCreateOrUpdate(collection, up, false, true);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-369_4e245a76,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeDelegate.java,95,102,"/**
 * Get a property
 * @param relPath  oak path
 * @return  property at the path given by {@code relPath} or {@code null} if
 * no such property exists
 */
@CheckForNull
public PropertyDelegate getProperty(String relPath) throws InvalidItemStateException {
    TreeLocation propertyLocation = getChildLocation(relPath);
    PropertyState propertyState = propertyLocation.getProperty();
    return propertyState == null ? null : new PropertyDelegate(sessionDelegate, propertyLocation);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-369_4e245a76,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeDelegate.java,128,131,"/**
 * Get child node
 * @param relPath  oak path
 * @return  node at the path given by {@code relPath} or {@code null} if
 * no such node exists
 */
@CheckForNull
public NodeDelegate getChild(String relPath) throws InvalidItemStateException {
    return create(sessionDelegate, getChildLocation(relPath));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-369_4e245a76,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeDelegate.java,244,246,"// -----------------------------------------------------------< private >---
private TreeLocation getChildLocation(String relPath) throws InvalidItemStateException {
    return getLocation().getChild(relPath);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3733_a5ff019e,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Commit.java,508,585,"/**
 * Checks if the update operation introduced any conflicts on the given
 * document. The document shows the state right before the operation was
 * applied.
 *
 * @param op the update operation.
 * @param before how the document looked before the update was applied or
 *               {@code null} if it didn't exist before.
 * @throws ConflictException if there was a conflict introduced by the
 *          given update operation.
 */
private void checkConflicts(@Nonnull UpdateOp op, @Nullable NodeDocument before) throws ConflictException {
    DocumentStore store = nodeStore.getDocumentStore();
    collisions.clear();
    if (baseRevision != null) {
        Revision newestRev = null;
        if (before != null) {
            Revision base = baseRevision;
            if (nodeStore.isDisableBranches()) {
                base = base.asTrunkRevision();
            }
            newestRev = before.getNewestRevision(nodeStore, base, revision, getBranch(), collisions);
        }
        String conflictMessage = null;
        Revision conflictRevision = newestRev;
        if (newestRev == null) {
            if ((op.isDelete() || !op.isNew()) && isConflicting(before, op)) {
                conflictMessage = ""The node "" + op.getId() + "" does not exist or is already deleted"";
                if (before != null && !before.getLocalDeleted().isEmpty()) {
                    conflictRevision = before.getLocalDeleted().firstKey();
                }
            }
        } else {
            if (op.isNew() && isConflicting(before, op)) {
                conflictMessage = ""The node "" + op.getId() + "" was already added in revision\n"" + formatConflictRevision(newestRev);
            } else if (nodeStore.isRevisionNewer(newestRev, baseRevision) && (op.isDelete() || isConflicting(before, op))) {
                conflictMessage = ""The node "" + op.getId() + "" was changed in revision\n"" + formatConflictRevision(newestRev) + "", which was applied after the base revision\n"" + baseRevision;
            }
        }
        if (conflictMessage == null) {
            // TODO: unify above conflict detection and isConflicting()
            if (!collisions.isEmpty() && isConflicting(before, op)) {
                for (Revision r : collisions) {
                    // mark collisions on commit root
                    Collision c = new Collision(before, r, op, revision);
                    if (c.mark(store).equals(revision)) {
                        // our revision was marked
                        if (baseRevision.isBranch()) {
                        // this is a branch commit. do not fail immediately
                        // merging this branch will fail later.
                        } else {
                            // fail immediately
                            conflictMessage = ""The node "" + op.getId() + "" was changed in revision\n"" + formatConflictRevision(r) + "", which was applied after the base revision\n"" + baseRevision;
                            conflictRevision = r;
                        }
                    }
                }
            }
        }
        if (conflictMessage != null) {
            conflictMessage += "", before\n"" + revision;
            if (LOG.isDebugEnabled()) {
                LOG.debug(conflictMessage + ""; document:\n"" + (before == null ? """" : before.format()) + "",\nrevision order:\n"" + nodeStore.getRevisionComparator());
            }
            throw new ConflictException(conflictMessage, conflictRevision);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3763_ab1a0cc2,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/EmptyNodeState.java,183,193,"public boolean equals(Object object) {
    if (object == EMPTY_NODE || object == MISSING_NODE) {
        return exists == (object == EMPTY_NODE);
    } else if (object instanceof NodeState) {
        NodeState that = (NodeState) object;
        return that.getPropertyCount() == 0 && that.getChildNodeCount(1) == 0;
    } else {
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3769_306a9e00,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java,1340,1373,"/**
 * Following logic is taken from org.apache.jackrabbit.core.query.lucene.JackrabbitQueryParser#parse(java.lang.String)
 */
private static String rewriteQueryText(String textsearch) {
    // replace escaped ' with just '
    StringBuilder rewritten = new StringBuilder();
    // the default lucene query parser recognizes 'AND' and 'NOT' as
    // keywords.
    textsearch = textsearch.replaceAll(""AND"", ""and"");
    textsearch = textsearch.replaceAll(""NOT"", ""not"");
    boolean escaped = false;
    for (int i = 0; i < textsearch.length(); i++) {
        if (textsearch.charAt(i) == '\\') {
            if (escaped) {
                rewritten.append(""\\\\"");
                escaped = false;
            } else {
                escaped = true;
            }
        } else if (textsearch.charAt(i) == '\'') {
            if (escaped) {
                escaped = false;
            }
            rewritten.append(textsearch.charAt(i));
        } else if (textsearch.charAt(i) == ':') {
            // fields as known in lucene are not supported
            rewritten.append(""\\:"");
        } else {
            if (escaped) {
                rewritten.append('\\');
                escaped = false;
            }
            rewritten.append(textsearch.charAt(i));
        }
    }
    return rewritten.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3792_94110f21,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/security/user/UserAuthentication.java,156,181,"private boolean changePassword(User user, SimpleCredentials credentials) {
    try {
        Object newPasswordObject = credentials.getAttribute(CREDENTIALS_ATTRIBUTE_NEWPASSWORD);
        if (newPasswordObject != null) {
            if (newPasswordObject instanceof String) {
                user.changePassword((String) newPasswordObject);
                root.commit();
                log.debug(""User "" + userId + "": changed user password"");
                return true;
            } else {
                log.warn(""Aborted password change for user "" + userId + "": provided new password is of incompatible type "" + newPasswordObject.getClass().getName());
            }
        }
    } catch (PasswordHistoryException e) {
        credentials.setAttribute(e.getClass().getName(), e.getMessage());
        log.error(""Failed to change password for user "" + userId, e.getMessage());
    } catch (RepositoryException e) {
        log.error(""Failed to change password for user "" + userId, e.getMessage());
    } catch (CommitFailedException e) {
        root.refresh();
        log.error(""Failed to change password for user "" + userId, e.getMessage());
    }
    return false;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3798_2ac1dccd,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,741,881,"/**
 * Get the revision of the latest change made to this node. At the same
 * time this method collects all collisions that happened for the given
 * {@code changeRev}. The reported latest change takes branches into
 * account. This means, if {@code changeRev} is on a branch, the latest
 * change is either a change that was done by a preceding branch commit or
 * a change that happened before the base of the branch. Changes done after
 * the branch base on trunk are not considered in this case. For a trunk
 * commit the latest change is reported similarly. In this case, unmerged
 * branch commits are not considered as latest change. Only commits to trunk
 * are considered.
 *
 * Collisions include the following cases:
 * <ul>
 *     <li>The other change is not yet committed</li>
 *     <li>The other change is a branch commit and not yet merged</li>
 *     <li>The {@code changeRev} is a branch commit and the other change
 *       happened after the base revision of the branch</li>
 *     <li>The other change is from another cluster node and not yet
 *       visible</li>
 * </ul>
 *
 * @param context the revision context.
 * @param baseRev the base revision of the current change.
 * @param changeRev the revision of the current change.
 * @param branch the branch associated with the current change or
 *              {@code null} if {@code changeRev} is not a branch commit.
 * @param collisions changes that happened after {@code baseRev}.
 */
@CheckForNull
Revision getNewestRevision(final RevisionContext context, final Revision baseRev, final Revision changeRev, final Branch branch, final Set<Revision> collisions) {
    checkArgument(!baseRev.isBranch() || branch != null, ""Branch must be non-null if baseRev is a branch revision"");
    Revision head = context.getHeadRevision();
    Revision lower = branch != null ? branch.getBase() : baseRev;
    // the clusterIds to check when walking the changes
    Set<Integer> clusterIds = Collections.emptySet();
    if (!getPreviousRanges().isEmpty()) {
        clusterIds = Sets.newHashSet();
        for (Revision prevRev : getPreviousRanges().keySet()) {
            if (!isRevisionNewer(context, lower, prevRev)) {
                clusterIds.add(prevRev.getClusterId());
            }
        }
    }
    // if we don't have clusterIds, we can use the local changes only
    boolean fullScan = true;
    Iterable<Revision> changes;
    if (clusterIds.isEmpty()) {
        // baseRev is newer than all previous documents
        changes = Iterables.mergeSorted(ImmutableList.of(getLocalRevisions().keySet(), getLocalCommitRoot().keySet()), getLocalRevisions().comparator());
    } else {
        // include previous documents as well (only needed in rare cases)
        fullScan = false;
        changes = getAllChanges();
        if (LOG.isDebugEnabled()) {
            LOG.debug(""getNewestRevision() with changeRev {} on {}, "" + ""_revisions {}, _commitRoot {}"", changeRev, getId(), getLocalRevisions(), getLocalCommitRoot());
        }
    }
    Map<Integer, Revision> newestRevs = Maps.newHashMap();
    Map<Revision, String> validRevisions = Maps.newHashMap();
    for (Revision r : changes) {
        if (r.equals(changeRev)) {
            continue;
        }
        if (!fullScan) {
            // check if we can stop going through changes
            if (clusterIds.contains(r.getClusterId())) {
                if (isRevisionNewer(context, lower, r)) {
                    clusterIds.remove(r.getClusterId());
                    if (clusterIds.isEmpty()) {
                        // the lower bound
                        break;
                    }
                }
            }
        }
        if (newestRevs.containsKey(r.getClusterId())) {
            // of the branch if this is for a commit on a branch
            if (branch != null && !branch.containsCommit(r)) {
                // change does not belong to the branch
                if (isRevisionNewer(context, r, branch.getBase())) {
                    // and happened after the base of the branch
                    collisions.add(r);
                }
            }
        } else {
            // check if change is visible from baseRev
            if (isValidRevision(context, r, null, baseRev, validRevisions)) {
                // consider for newestRev
                newestRevs.put(r.getClusterId(), r);
            } else {
                // not valid means:
                // 1) 'r' is not committed -> collision
                // 2) 'r' is on a branch, but not the same as
                // changeRev -> collisions
                // 3) changeRev is on a branch and 'r' is newer than
                // the base of the branch -> collision
                // 4) 'r' is committed but not yet visible to current
                // cluster node -> collisions
                // 5) changeRev is not on a branch, 'r' is committed and
                // newer than baseRev -> newestRev
                NodeDocument commitRoot = getCommitRoot(r);
                Revision commitRevision = null;
                if (commitRoot != null) {
                    commitRevision = commitRoot.getCommitRevision(r);
                }
                if (// committed but not yet visible
                commitRevision != null && isRevisionNewer(context, commitRevision, head)) {
                    // case 4)
                    collisions.add(r);
                } else if (// committed
                commitRevision != null && // changeRev not on branch
                branch == null && isRevisionNewer(context, r, baseRev)) {
                    // case 5)
                    newestRevs.put(r.getClusterId(), r);
                } else {
                    // remaining cases 1), 2) and 3)
                    collisions.add(r);
                }
            }
        }
    }
    // select the newest committed change
    Revision newestRev = null;
    for (Revision r : newestRevs.values()) {
        newestRev = Utils.max(newestRev, r, context.getRevisionComparator());
    }
    if (newestRev == null) {
        return null;
    }
    // the local deleted map contains the most recent revisions
    SortedMap<Revision, String> deleted = getLocalDeleted();
    String value = deleted.get(newestRev);
    if (value == null && deleted.headMap(newestRev).isEmpty()) {
        // no need to check previous docs
        return newestRev;
    }
    if (value == null) {
        // get from complete map
        value = getDeleted().get(newestRev);
    }
    if (""true"".equals(value)) {
        // deleted in the newest revision
        return null;
    }
    return newestRev;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-379_621a5101,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/security/SecurityProviderImpl.java,68,81,"@Nonnull
@Override
public LoginContextProvider getLoginContextProvider(NodeStore nodeStore) {
    String appName = configuration.getConfigValue(PARAM_APP_NAME, DEFAULT_APP_NAME);
    Configuration loginConfig;
    try {
        loginConfig = Configuration.getConfiguration();
    } catch (SecurityException e) {
        log.warn(""Failed to retrieve login configuration: using default."", e);
        loginConfig = new OakConfiguration();
        Configuration.setConfiguration(loginConfig);
    }
    return new LoginContextProviderImpl(appName, loginConfig, nodeStore, this);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3817_2a02a138,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/NodeStateAnalyzerFactory.java,198,210,"Map<String, String> convertNodeState(NodeState state) {
    Map<String, String> result = Maps.newHashMap();
    for (PropertyState ps : state.getProperties()) {
        String name = ps.getName();
        if (ps.getType() != Type.BINARY && !ps.isArray() && !IGNORE_PROP_NAMES.contains(name)) {
            result.put(name, ps.getValue(Type.STRING));
        }
    }
    result.put(LuceneIndexConstants.ANL_LUCENE_MATCH_VERSION, getVersion(state).toString());
    return result;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3872_c13708e3,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/rdb/RDBBlobStore.java,491,536,"@Override
public long countDeleteChunks(List<String> chunkIds, long maxLastModifiedTime) throws Exception {
    long count = 0;
    for (List<String> chunk : Lists.partition(chunkIds, RDBJDBCTools.MAX_IN_CLAUSE)) {
        Connection con = this.ch.getRWConnection();
        PreparedStatement prepMeta = null;
        PreparedStatement prepData = null;
        try {
            PreparedStatementComponent inClause = RDBJDBCTools.createInStatement(""ID"", chunk, false);
            StringBuilder metaStatement = new StringBuilder(""delete from "" + this.tnMeta + "" where "").append(inClause.getStatementComponent());
            StringBuilder dataStatement = new StringBuilder(""delete from "" + this.tnData + "" where "").append(inClause.getStatementComponent());
            if (maxLastModifiedTime > 0) {
                metaStatement.append("" and LASTMOD <= ?"");
                dataStatement.append("" and not exists(select * from "" + this.tnMeta + "" m where ID = m.ID and m.LASTMOD <= ?)"");
            }
            prepMeta = con.prepareStatement(metaStatement.toString());
            prepData = con.prepareStatement(dataStatement.toString());
            int mindex = 1, dindex = 1;
            mindex = inClause.setParameters(prepMeta, mindex);
            dindex = inClause.setParameters(prepData, dindex);
            if (maxLastModifiedTime > 0) {
                prepMeta.setLong(mindex, maxLastModifiedTime);
                prepData.setLong(dindex, maxLastModifiedTime);
            }
            count += prepMeta.executeUpdate();
            prepData.execute();
        } finally {
            closeStatement(prepMeta);
            closeStatement(prepData);
            con.commit();
            this.ch.closeConnection(con);
        }
    }
    return count;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3879_4faf31e3,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java,1342,1378,"/**
 * Following logic is taken from org.apache.jackrabbit.core.query.lucene.JackrabbitQueryParser#parse(java.lang.String)
 */
static String rewriteQueryText(String textsearch) {
    // replace escaped ' with just '
    StringBuilder rewritten = new StringBuilder();
    // the default lucene query parser recognizes 'AND' and 'NOT' as
    // keywords.
    textsearch = textsearch.replaceAll(""AND"", ""and"");
    textsearch = textsearch.replaceAll(""NOT"", ""not"");
    boolean escaped = false;
    for (int i = 0; i < textsearch.length(); i++) {
        char c = textsearch.charAt(i);
        if (c == '\\') {
            if (escaped) {
                rewritten.append(""\\\\"");
                escaped = false;
            } else {
                escaped = true;
            }
        } else if (c == '\'') {
            if (escaped) {
                escaped = false;
            }
            rewritten.append(c);
        } else if (c == ':' || c == '/') {
            // TODO Some other chars are also considered special See OAK-3769 for details
            // ':' fields as known in lucene are not supported
            // '/' its a special char used for regex search in Lucene
            rewritten.append('\\').append(c);
        } else {
            if (escaped) {
                rewritten.append('\\');
                escaped = false;
            }
            rewritten.append(c);
        }
    }
    return rewritten.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3897_94c6c575,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentMK.java,325,342,"@Nonnull
public String reset(@Nonnull String branchRevisionId, @Nonnull String ancestorRevisionId) throws DocumentStoreException {
    RevisionVector branch = RevisionVector.fromString(branchRevisionId);
    if (!branch.isBranch()) {
        throw new DocumentStoreException(""Not a branch revision: "" + branchRevisionId);
    }
    RevisionVector ancestor = RevisionVector.fromString(ancestorRevisionId);
    if (!ancestor.isBranch()) {
        throw new DocumentStoreException(""Not a branch revision: "" + ancestorRevisionId);
    }
    try {
        return nodeStore.reset(branch, ancestor, null).toString();
    } catch (DocumentStoreException e) {
        throw new DocumentStoreException(e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3897_94c6c575,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1250,1321,"@Nonnull
RevisionVector reset(@Nonnull RevisionVector branchHead, @Nonnull RevisionVector ancestor, @Nullable DocumentNodeStoreBranch branch) {
    checkNotNull(branchHead);
    checkNotNull(ancestor);
    Branch b = getBranches().getBranch(branchHead);
    if (b == null) {
        throw new DocumentStoreException(""Empty branch cannot be reset"");
    }
    if (!b.getCommits().last().equals(branchHead.getRevision(getClusterId()))) {
        throw new DocumentStoreException(branchHead + "" is not the head "" + ""of a branch"");
    }
    if (!b.containsCommit(ancestor.getBranchRevision())) {
        throw new DocumentStoreException(ancestor + "" is not "" + ""an ancestor revision of "" + branchHead);
    }
    if (branchHead.equals(ancestor)) {
        // trivial
        return branchHead;
    }
    boolean success = false;
    Commit commit = newCommit(branchHead, branch);
    try {
        Iterator<Revision> it = b.getCommits().tailSet(ancestor.getBranchRevision()).iterator();
        // first revision is the ancestor (tailSet is inclusive)
        // do not undo changes for this revision
        it.next();
        Map<String, UpdateOp> operations = Maps.newHashMap();
        if (it.hasNext()) {
            Revision reset = it.next();
            // TODO: correct?
            getRoot(b.getCommit(reset).getBase().update(reset)).compareAgainstBaseState(getRoot(ancestor), new ResetDiff(reset.asTrunkRevision(), operations));
            UpdateOp rootOp = operations.get(""/"");
            if (rootOp == null) {
                rootOp = new UpdateOp(Utils.getIdFromPath(""/""), false);
                NodeDocument.setModified(rootOp, commit.getRevision());
                operations.put(""/"", rootOp);
            }
            NodeDocument.removeCollision(rootOp, reset.asTrunkRevision());
            NodeDocument.removeRevision(rootOp, reset.asTrunkRevision());
        }
        // update root document first
        if (store.findAndUpdate(Collection.NODES, operations.get(""/"")) != null) {
            // clean up in-memory branch data
            // first revision is the ancestor (tailSet is inclusive)
            List<Revision> revs = Lists.newArrayList(b.getCommits().tailSet(ancestor.getBranchRevision()));
            for (Revision r : revs.subList(1, revs.size())) {
                b.removeCommit(r);
            }
            // successfully updating the root document can be considered
            // as success because the changes are not marked as committed
            // anymore
            success = true;
        }
        operations.remove(""/"");
        // update remaining documents
        for (UpdateOp op : operations.values()) {
            store.findAndUpdate(Collection.NODES, op);
        }
    } finally {
        if (!success) {
            canceled(commit);
        } else {
            done(commit, true, null);
        }
    }
    return ancestor;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3897_94c6c575,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStoreBranch.java,619,630,"private void resetBranch(DocumentNodeState branchHead, DocumentNodeState ancestor) {
    try {
        head = store.getRoot(store.reset(branchHead.getRevision(), ancestor.getRevision(), DocumentNodeStoreBranch.this));
    } catch (Exception e) {
        CommitFailedException ex = new CommitFailedException(OAK, 100, ""Branch reset failed"", e);
        branchState = new ResetFailed(base, ex);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3897_94c6c575,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/ResetDiff.java,75,82,"@Override
public boolean childNodeAdded(String name, NodeState after) {
    String p = PathUtils.concat(path, name);
    ResetDiff diff = new ResetDiff(revision, p, operations);
    UpdateOp op = diff.getUpdateOp();
    NodeDocument.removeDeleted(op, revision);
    return after.compareAgainstBaseState(EMPTY_NODE, diff);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3903_690fb9f4,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/Commit.java,270,432,"/**
 * Apply the changes to the document store.
 *
 * @param baseBranchRevision the base revision of this commit. Currently only
 *                     used for branch commits.
 */
private void applyToDocumentStore(RevisionVector baseBranchRevision) {
    // the value in _revisions.<revision> property of the commit root node
    // regular commits use ""c"", which makes the commit visible to
    // other readers. branch commits use the base revision to indicate
    // the visibility of the commit
    String commitValue = baseBranchRevision != null ? baseBranchRevision.toString() : ""c"";
    DocumentStore store = nodeStore.getDocumentStore();
    String commitRootPath = null;
    if (baseBranchRevision != null) {
        // branch commits always use root node as commit root
        commitRootPath = ""/"";
    }
    ArrayList<UpdateOp> newNodes = new ArrayList<UpdateOp>();
    ArrayList<UpdateOp> changedNodes = new ArrayList<UpdateOp>();
    // operations are added to this list before they are executed,
    // so that all operations can be rolled back if there is a conflict
    ArrayList<UpdateOp> opLog = new ArrayList<UpdateOp>();
    // Compute the commit root
    for (String p : operations.keySet()) {
        markChanged(p);
        if (commitRootPath == null) {
            commitRootPath = p;
        } else {
            while (!PathUtils.isAncestor(commitRootPath, p)) {
                commitRootPath = PathUtils.getParentPath(commitRootPath);
                if (denotesRoot(commitRootPath)) {
                    break;
                }
            }
        }
    }
    // push branch changes to journal
    if (baseBranchRevision != null) {
        // store as external change
        JournalEntry doc = JOURNAL.newDocument(store);
        doc.modified(modifiedNodes);
        Revision r = revision.asBranchRevision();
        store.create(JOURNAL, singletonList(doc.asUpdateOp(r)));
    }
    int commitRootDepth = PathUtils.getDepth(commitRootPath);
    // check if there are real changes on the commit root
    boolean commitRootHasChanges = operations.containsKey(commitRootPath);
    // create a ""root of the commit"" if there is none
    UpdateOp commitRoot = getUpdateOperationForNode(commitRootPath);
    for (String p : operations.keySet()) {
        UpdateOp op = operations.get(p);
        if (op.isNew()) {
            NodeDocument.setDeleted(op, revision, false);
        }
        if (op == commitRoot) {
            if (!op.isNew() && commitRootHasChanges) {
                // commit root already exists and this is an update
                changedNodes.add(op);
            }
        } else {
            NodeDocument.setCommitRoot(op, revision, commitRootDepth);
            if (op.isNew()) {
                newNodes.add(op);
            } else {
                changedNodes.add(op);
            }
        }
    }
    if (changedNodes.size() == 0 && commitRoot.isNew()) {
        // no updates and root of commit is also new. that is,
        // it is the root of a subtree added in a commit.
        // so we try to add the root like all other nodes
        NodeDocument.setRevision(commitRoot, revision, commitValue);
        newNodes.add(commitRoot);
    }
    boolean success = false;
    try {
        if (newNodes.size() > 0) {
            // set commit root on new nodes
            if (!store.create(NODES, newNodes)) {
                // try to apply all changes one by one
                for (UpdateOp op : newNodes) {
                    if (op == commitRoot) {
                        // don't write the commit root just yet
                        // (because there might be a conflict)
                        NodeDocument.unsetRevision(commitRoot, revision);
                    }
                    changedNodes.add(op);
                }
                newNodes.clear();
            }
        }
        for (UpdateOp op : changedNodes) {
            // set commit root on changed nodes. this may even apply
            // to the commit root. the _commitRoot entry is removed
            // again when the _revisions entry is set at the end
            NodeDocument.setCommitRoot(op, revision, commitRootDepth);
            opLog.add(op);
            createOrUpdateNode(store, op);
        }
        // the revision, with the revision property set)
        if (changedNodes.size() > 0 || !commitRoot.isNew()) {
            // set revision to committed
            NodeDocument.setRevision(commitRoot, revision, commitValue);
            if (commitRootHasChanges) {
                // remove previously added commit root
                NodeDocument.removeCommitRoot(commitRoot, revision);
            }
            opLog.add(commitRoot);
            if (baseBranchRevision == null) {
                // create a clone of the commitRoot in order
                // to set isNew to false. If we get here the
                // commitRoot document already exists and
                // only needs an update
                UpdateOp commit = commitRoot.copy();
                commit.setNew(false);
                // only set revision on commit root when there is
                // no collision for this commit revision
                commit.containsMapEntry(COLLISIONS, revision, false);
                NodeDocument before = nodeStore.updateCommitRoot(commit);
                if (before == null) {
                    String msg = ""Conflicting concurrent change. "" + ""Update operation failed: "" + commitRoot;
                    NodeDocument commitRootDoc = store.find(NODES, commitRoot.getId());
                    DocumentStoreException dse;
                    if (commitRootDoc == null) {
                        dse = new DocumentStoreException(msg);
                    } else {
                        dse = new ConflictException(msg, commitRootDoc.getConflictsFor(Collections.singleton(revision)));
                    }
                    throw dse;
                } else {
                    success = true;
                    // if we get here the commit was successful and
                    // the commit revision is set on the commitRoot
                    // document for this commit.
                    // now check for conflicts/collisions by other commits.
                    // use original commitRoot operation with
                    // correct isNew flag.
                    checkConflicts(commitRoot, before);
                    checkSplitCandidate(before);
                }
            } else {
                // this is a branch commit, do not fail on collisions now
                // trying to merge the branch will fail later
                createOrUpdateNode(store, commitRoot);
            }
            operations.put(commitRootPath, commitRoot);
        }
    } catch (DocumentStoreException e) {
        // OAK-3084 do not roll back if already committed
        if (success) {
            LOG.error(""Exception occurred after commit. Rollback will be suppressed."", e);
        } else {
            rollback(newNodes, opLog, commitRoot);
            throw e;
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3903_690fb9f4,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/DocumentNodeStore.java,1171,1189,"/**
 * Updates a commit root document.
 *
 * @param commit the updates to apply on the commit root document.
 * @return the document before the update was applied or <code>null</code>
 *          if the update failed because of a collision.
 * @throws DocumentStoreException if the update fails with an error.
 */
@CheckForNull
NodeDocument updateCommitRoot(UpdateOp commit) throws DocumentStoreException {
    // use batch commit when there are only revision and modified updates
    boolean batch = true;
    for (Map.Entry<Key, Operation> op : commit.getChanges().entrySet()) {
        String name = op.getKey().getName();
        if (NodeDocument.isRevisionsEntry(name) || NodeDocument.MODIFIED_IN_SECS.equals(name)) {
            continue;
        }
        batch = false;
        break;
    }
    if (batch) {
        return batchUpdateCommitRoot(commit);
    } else {
        return store.findAndUpdate(NODES, commit);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-3930_b939aa6e,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/xml/SysViewImportHandler.java,211,293,"@Override
public void endElement(String namespaceURI, String localName, String qName) throws SAXException {
    // check element name
    ImportState state = stack.peek();
    if (namespaceURI.equals(NamespaceConstants.NAMESPACE_SV) && ""node"".equals(localName)) {
        // sv:node element
        if (!state.started) {
            // need to start & end current node
            processNode(state, true, true);
            state.started = true;
        } else {
            // need to end current node
            processNode(state, false, true);
        }
        // pop current state from stack
        stack.pop();
    } else if (namespaceURI.equals(NamespaceConstants.NAMESPACE_SV) && ""property"".equals(localName)) {
        // have been collected and create node as necessary primaryType
        if (currentPropName != null && currentPropName.getNamespaceUri().equals(NamespaceRegistry.NAMESPACE_JCR) && currentPropName.getLocalName().equals(""primaryType"")) {
            BufferedStringValue val = currentPropValues.get(0);
            String s = null;
            try {
                s = val.retrieve();
                state.nodeTypeName = new NameInfo(s).getRepoQualifiedName();
            } catch (IOException e) {
                throw new SAXException(new InvalidSerializedDataException(""illegal node type name: "" + s, e));
            } catch (RepositoryException e) {
                throw new SAXException(new InvalidSerializedDataException(""illegal node type name: "" + s, e));
            }
        } else if (currentPropName != null && currentPropName.getNamespaceUri().equals(NamespaceRegistry.NAMESPACE_JCR) && currentPropName.getLocalName().equals(""mixinTypes"")) {
            if (state.mixinNames == null) {
                state.mixinNames = new ArrayList<String>(currentPropValues.size());
            }
            for (BufferedStringValue val : currentPropValues) {
                String s = null;
                try {
                    s = val.retrieve();
                    state.mixinNames.add(new NameInfo(s).getRepoQualifiedName());
                } catch (IOException ioe) {
                    throw new SAXException(""error while retrieving value"", ioe);
                } catch (RepositoryException e) {
                    throw new SAXException(new InvalidSerializedDataException(""illegal mixin type name: "" + s, e));
                }
            }
        } else if (currentPropName != null && currentPropName.getNamespaceUri().equals(NamespaceRegistry.NAMESPACE_JCR) && currentPropName.getLocalName().equals(""uuid"")) {
            BufferedStringValue val = currentPropValues.get(0);
            try {
                state.uuid = val.retrieve();
            } catch (IOException ioe) {
                throw new SAXException(""error while retrieving value"", ioe);
            }
        } else {
            if (currentPropMultipleStatus == PropInfo.MultipleStatus.UNKNOWN && currentPropValues.size() != 1) {
                currentPropMultipleStatus = PropInfo.MultipleStatus.MULTIPLE;
            }
            PropInfo prop = new PropInfo(currentPropName == null ? null : currentPropName.getRepoQualifiedName(), currentPropType, currentPropValues);
            state.props.add(prop);
        }
        // reset temp fields
        currentPropValues.clear();
    } else if (namespaceURI.equals(NamespaceConstants.NAMESPACE_SV) && ""value"".equals(localName)) {
        // sv:value element
        currentPropValues.add(currentPropValue);
        // reset temp fields
        currentPropValue = null;
    } else {
        throw new SAXException(new InvalidSerializedDataException(""invalid element in system view xml document: "" + localName));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-395_4ed7bc8e,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,304,325,"/**
 * @see Node#setProperty(String, javax.jcr.Value, int)
 */
@Override
@CheckForNull
public Property setProperty(final String jcrName, final Value value, final int type) throws RepositoryException {
    checkStatus();
    return sessionDelegate.perform(new SessionOperation<PropertyImpl>() {

        @Override
        public PropertyImpl perform() throws RepositoryException {
            String oakName = sessionDelegate.getOakPathOrThrow(jcrName);
            if (value == null) {
                dlg.removeProperty(oakName);
                return null;
            } else {
                int targetType = getTargetType(value, type);
                Value targetValue = ValueHelper.convert(value, targetType, getValueFactory());
                return new PropertyImpl(dlg.setProperty(oakName, targetValue));
            }
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-395_4ed7bc8e,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,311,323,"@Override
public PropertyImpl perform() throws RepositoryException {
    String oakName = sessionDelegate.getOakPathOrThrow(jcrName);
    if (value == null) {
        dlg.removeProperty(oakName);
        return null;
    } else {
        int targetType = getTargetType(value, type);
        Value targetValue = ValueHelper.convert(value, targetType, getValueFactory());
        return new PropertyImpl(dlg.setProperty(oakName, targetValue));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-395_e6c31270,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,1445,1478,"private Property internalSetProperty(final String jcrName, final Value value, final int type, final boolean exactTypeMatch) throws RepositoryException {
    checkStatus();
    checkProtected();
    return sessionDelegate.perform(new SessionOperation<Property>() {

        @Override
        public Property perform() throws RepositoryException {
            if (value == null) {
                Property property = getProperty(jcrName);
                property.remove();
                return property;
            } else {
                String oakName = sessionDelegate.getOakPathOrThrow(jcrName);
                PropertyDefinition definition;
                if (hasProperty(jcrName)) {
                    definition = getProperty(jcrName).getDefinition();
                } else {
                    definition = dlg.sessionDelegate.getDefinitionProvider().getDefinition(NodeImpl.this, oakName, false, type, exactTypeMatch);
                }
                checkProtected(definition);
                if (definition.isMultiple()) {
                    throw new ValueFormatException(""Cannot set single value to multivalued property"");
                }
                int targetType = getTargetType(value, definition);
                Value targetValue = ValueHelper.convert(value, targetType, getValueFactory());
                return new PropertyImpl(dlg.setProperty(oakName, targetValue));
            }
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-395_e6c31270,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,1451,1476,"@Override
public Property perform() throws RepositoryException {
    if (value == null) {
        Property property = getProperty(jcrName);
        property.remove();
        return property;
    } else {
        String oakName = sessionDelegate.getOakPathOrThrow(jcrName);
        PropertyDefinition definition;
        if (hasProperty(jcrName)) {
            definition = getProperty(jcrName).getDefinition();
        } else {
            definition = dlg.sessionDelegate.getDefinitionProvider().getDefinition(NodeImpl.this, oakName, false, type, exactTypeMatch);
        }
        checkProtected(definition);
        if (definition.isMultiple()) {
            throw new ValueFormatException(""Cannot set single value to multivalued property"");
        }
        int targetType = getTargetType(value, definition);
        Value targetValue = ValueHelper.convert(value, targetType, getValueFactory());
        return new PropertyImpl(dlg.setProperty(oakName, targetValue));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-395_e6c31270,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,1480,1516,"private Property internalSetProperty(final String jcrName, final Value[] values, final int type, final boolean exactTypeMatch) throws RepositoryException {
    checkStatus();
    checkProtected();
    return sessionDelegate.perform(new SessionOperation<Property>() {

        @Override
        public Property perform() throws RepositoryException {
            if (values == null) {
                Property p = getProperty(jcrName);
                p.remove();
                return p;
            } else {
                String oakName = sessionDelegate.getOakPathOrThrow(jcrName);
                PropertyDefinition definition;
                if (hasProperty(jcrName)) {
                    definition = getProperty(jcrName).getDefinition();
                } else {
                    definition = dlg.sessionDelegate.getDefinitionProvider().getDefinition(NodeImpl.this, oakName, true, type, exactTypeMatch);
                }
                checkProtected(definition);
                if (!definition.isMultiple()) {
                    throw new ValueFormatException(""Cannot set value array to single value property"");
                }
                int targetType = getTargetType(values, definition);
                Value[] targetValues = ValueHelper.convert(values, targetType, getValueFactory());
                Iterable<Value> nonNullValues = Iterables.filter(Arrays.asList(targetValues), Predicates.notNull());
                return new PropertyImpl(dlg.setProperty(oakName, nonNullValues));
            }
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-395_e6c31270,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,1486,1514,"@Override
public Property perform() throws RepositoryException {
    if (values == null) {
        Property p = getProperty(jcrName);
        p.remove();
        return p;
    } else {
        String oakName = sessionDelegate.getOakPathOrThrow(jcrName);
        PropertyDefinition definition;
        if (hasProperty(jcrName)) {
            definition = getProperty(jcrName).getDefinition();
        } else {
            definition = dlg.sessionDelegate.getDefinitionProvider().getDefinition(NodeImpl.this, oakName, true, type, exactTypeMatch);
        }
        checkProtected(definition);
        if (!definition.isMultiple()) {
            throw new ValueFormatException(""Cannot set value array to single value property"");
        }
        int targetType = getTargetType(values, definition);
        Value[] targetValues = ValueHelper.convert(values, targetType, getValueFactory());
        Iterable<Value> nonNullValues = Iterables.filter(Arrays.asList(targetValues), Predicates.notNull());
        return new PropertyImpl(dlg.setProperty(oakName, nonNullValues));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4036_f4324736,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexProviderService.java,437,453,"private void initializeExtractedTextCache(BundleContext bundleContext, Map<String, ?> config) {
    int cacheSizeInMB = PropertiesUtil.toInteger(config.get(PROP_EXTRACTED_TEXT_CACHE_SIZE), PROP_EXTRACTED_TEXT_CACHE_SIZE_DEFAULT);
    int cacheExpiryInSecs = PropertiesUtil.toInteger(config.get(PROP_EXTRACTED_TEXT_CACHE_EXPIRY), PROP_EXTRACTED_TEXT_CACHE_EXPIRY_DEFAULT);
    extractedTextCache = new ExtractedTextCache(cacheSizeInMB * ONE_MB, cacheExpiryInSecs);
    CacheStats stats = extractedTextCache.getCacheStats();
    if (stats != null) {
        oakRegs.add(registerMBean(whiteboard, CacheStatsMBean.class, stats, CacheStatsMBean.TYPE, stats.getName()));
        log.info(""Extracted text caching enabled with maxSize {} MB, expiry time {} secs"", cacheSizeInMB, cacheExpiryInSecs);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4038_557eec4f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/PropertyIndex.java,185,206,"@Override
public double getCost(Filter filter, NodeState root) {
    if (filter.getFullTextConstraint() != null) {
        // not an appropriate index for full-text search
        return Double.POSITIVE_INFINITY;
    }
    if (filter.containsNativeConstraint()) {
        // not an appropriate index for native search
        return Double.POSITIVE_INFINITY;
    }
    if (filter.getPropertyRestrictions().isEmpty() && filter.getSelector().getSelectorConstraints().isEmpty()) {
        // not an appropriate index for no property restrictions & selector constraints
        return Double.POSITIVE_INFINITY;
    }
    PropertyIndexPlan plan = getPlan(root, filter);
    if (plan != null) {
        return plan.getCost();
    } else {
        return Double.POSITIVE_INFINITY;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4038_557eec4f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/PropertyIndexPlan.java,190,215,"private Set<String> findMultiProperty(OrImpl or) {
    Set<String> values = newLinkedHashSet();
    for (ConstraintImpl constraint : or.getConstraints()) {
        if (constraint instanceof ComparisonImpl) {
            ComparisonImpl comparison = (ComparisonImpl) constraint;
            if (isIndexed(comparison.getOperand1()) && comparison.getOperator() == Operator.EQUAL) {
                values.addAll(encode(comparison.getOperand2().currentValue()));
            } else {
                return null;
            }
        } else if (constraint instanceof InImpl) {
            InImpl in = (InImpl) constraint;
            if (isIndexed(in.getOperand1())) {
                for (StaticOperandImpl operand : in.getOperand2()) {
                    values.addAll(encode(operand.currentValue()));
                }
            } else {
                return null;
            }
        } else {
            return null;
        }
    }
    return values;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4038_557eec4f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/property/PropertyIndexPlan.java,221,228,"/**
 * Checks whether the given dynamic operand is a property
 * covered by this index.
 */
private boolean isIndexed(DynamicOperandImpl operand) {
    if (operand instanceof PropertyValueImpl) {
        PropertyValueImpl property = (PropertyValueImpl) operand;
        return properties.contains(property.getPropertyName());
    } else {
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4038_557eec4f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/index/FilterImpl.java,221,224,"@Override
public SelectorImpl getSelector() {
    return selector;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4038_557eec4f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/query/Filter.java,52,52,"/**
 * Get the selector associated with this filter.
 *
 * @return selector
 */
SelectorImpl getSelector();"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4050_52ca008c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/SplitOperations.java,207,252,"/**
 * Collect _revisions and _commitRoot entries that can be moved to a
 * previous document.
 */
private void collectRevisionsAndCommitRoot() {
    NavigableMap<Revision, String> revisions = new TreeMap<Revision, String>(StableRevisionComparator.INSTANCE);
    for (Map.Entry<Revision, String> entry : doc.getLocalRevisions().entrySet()) {
        if (splitRevs.contains(entry.getKey())) {
            revisions.put(entry.getKey(), entry.getValue());
            numValues++;
        } else {
            // local changes
            if (context.getClusterId() != entry.getKey().getClusterId()) {
                // only consider local changes
                continue;
            }
            if (doc.isCommitted(entry.getKey()) && !mostRecentRevs.contains(entry.getKey())) {
                // this is a commit root for changes in other documents
                revisions.put(entry.getKey(), entry.getValue());
                numValues++;
                trackHigh(entry.getKey());
                trackLow(entry.getKey());
            }
        }
    }
    committedChanges.put(REVISIONS, revisions);
    NavigableMap<Revision, String> commitRoot = new TreeMap<Revision, String>(StableRevisionComparator.INSTANCE);
    boolean mostRecent = true;
    for (Map.Entry<Revision, String> entry : doc.getLocalCommitRoot().entrySet()) {
        Revision r = entry.getKey();
        if (splitRevs.contains(r)) {
            commitRoot.put(r, entry.getValue());
            numValues++;
        } else if (r.getClusterId() == context.getClusterId() && !changes.contains(r)) {
            // consider all but most recent as garbage (OAK-3333)
            if (mostRecent) {
                mostRecent = false;
            } else {
                addGarbage(r, COMMIT_ROOT);
            }
        }
    }
    committedChanges.put(COMMIT_ROOT, commitRoot);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4066_9a109aa3,Blocker,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditorContext.java,239,275,"/**
 * close writer if it's not null
 */
void closeWriter() throws IOException {
    // in directory
    if (reindex && writer == null) {
        getWriter();
    }
    if (writer != null) {
        if (log.isTraceEnabled()) {
            trackIndexSizeInfo(writer, definition, directory);
        }
        final long start = PERF_LOGGER.start();
        updateSuggester(writer.getAnalyzer());
        PERF_LOGGER.end(start, -1, ""Completed suggester for directory {}"", definition);
        writer.close();
        PERF_LOGGER.end(start, -1, ""Closed writer for directory {}"", definition);
        directory.close();
        PERF_LOGGER.end(start, -1, ""Closed directory for directory {}"", definition);
        // OAK-2029 Record the last updated status so
        // as to make IndexTracker detect changes when index
        // is stored in file system
        NodeBuilder status = definitionBuilder.child("":status"");
        status.setProperty(""lastUpdated"", ISO8601.format(getCalendar()), Type.DATE);
        status.setProperty(""indexedNodes"", indexedNodes);
        PERF_LOGGER.end(start, -1, ""Overall Closed IndexWriter for directory {}"", definition);
        textExtractionStats.log(reindex);
        textExtractionStats.collectStats(extractedTextCache);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4066_9a109aa3,Blocker,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LuceneIndexEditorContext.java,282,314,"/**
 * eventually update suggest dictionary
 * @throws IOException if suggest dictionary update fails
 * @param analyzer the analyzer used to update the suggester
 */
private void updateSuggester(Analyzer analyzer) throws IOException {
    if (definition.isSuggestEnabled()) {
        boolean updateSuggester = false;
        NodeBuilder suggesterStatus = definitionBuilder.child("":suggesterStatus"");
        if (suggesterStatus.hasProperty(""lastUpdated"")) {
            PropertyState suggesterLastUpdatedValue = suggesterStatus.getProperty(""lastUpdated"");
            Calendar suggesterLastUpdatedTime = ISO8601.parse(suggesterLastUpdatedValue.getValue(Type.DATE));
            int updateFrequency = definition.getSuggesterUpdateFrequencyMinutes();
            suggesterLastUpdatedTime.add(Calendar.MINUTE, updateFrequency);
            if (getCalendar().after(suggesterLastUpdatedTime)) {
                updateSuggester = true;
            }
        } else {
            updateSuggester = true;
        }
        if (updateSuggester) {
            DirectoryReader reader = DirectoryReader.open(writer, false);
            final OakDirectory suggestDirectory = new OakDirectory(definitionBuilder, "":suggest-data"", definition, false);
            try {
                SuggestHelper.updateSuggester(suggestDirectory, analyzer, reader);
                suggesterStatus.setProperty(""lastUpdated"", ISO8601.format(getCalendar()), Type.DATE);
            } catch (Throwable e) {
                log.warn(""could not update suggester"", e);
            } finally {
                suggestDirectory.close();
                reader.close();
            }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4067_56accddf,Critical,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/util/SuggestHelper.java,57,79,"public static void updateSuggester(Directory directory, Analyzer analyzer, IndexReader reader) throws IOException {
    File tempDir = null;
    try {
        // Analyzing infix suggester takes a file parameter. It uses its path to getDirectory()
        // for actual storage of suggester data. BUT, while building it also does getDirectory() to
        // a temporary location (original path + "".tmp""). So, instead we create a temp dir and also
        // create a placeholder non-existing-sub-child which would mark the location when we want to return
        // our internal suggestion OakDirectory. After build is done, we'd delete the temp directory
        // thereby removing any temp stuff that suggester created in the interim.
        tempDir = Files.createTempDir();
        File tempSubChild = new File(tempDir, ""non-existing-sub-child"");
        Dictionary dictionary = new LuceneDictionary(reader, FieldNames.SUGGEST);
        getLookup(directory, analyzer, tempSubChild).build(dictionary);
    } catch (RuntimeException e) {
        log.debug(""could not update the suggester"", e);
    } finally {
        // cleanup temp dir
        if (tempDir != null && !FileUtils.deleteQuietly(tempDir)) {
            log.error(""Cleanup failed for temp dir {}"", tempDir.getAbsolutePath());
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4153_9120fd1b,Critical,oak-segment/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeState.java,429,587,"@Override
public boolean compareAgainstBaseState(NodeState base, NodeStateDiff diff) {
    if (this == base || fastEquals(this, base)) {
        // no changes
        return true;
    } else if (base == EMPTY_NODE || !base.exists()) {
        // special case
        return EmptyNodeState.compareAgainstEmptyState(this, diff);
    } else if (!(base instanceof SegmentNodeState)) {
        // fallback
        return AbstractNodeState.compareAgainstBaseState(this, base, diff);
    }
    SegmentNodeState that = (SegmentNodeState) base;
    if (that.wasCompactedTo(this)) {
        // no changes during compaction
        return true;
    }
    Template beforeTemplate = that.getTemplate();
    RecordId beforeId = that.getRecordId();
    Template afterTemplate = getTemplate();
    RecordId afterId = getRecordId();
    // Compare type properties
    if (!compareProperties(beforeTemplate.getPrimaryType(), afterTemplate.getPrimaryType(), diff)) {
        return false;
    }
    if (!compareProperties(beforeTemplate.getMixinTypes(), afterTemplate.getMixinTypes(), diff)) {
        return false;
    }
    // Compare other properties, leveraging the ordering
    int beforeIndex = 0;
    int afterIndex = 0;
    PropertyTemplate[] beforeProperties = beforeTemplate.getPropertyTemplates();
    PropertyTemplate[] afterProperties = afterTemplate.getPropertyTemplates();
    while (beforeIndex < beforeProperties.length && afterIndex < afterProperties.length) {
        int d = Integer.valueOf(afterProperties[afterIndex].hashCode()).compareTo(Integer.valueOf(beforeProperties[beforeIndex].hashCode()));
        if (d == 0) {
            d = afterProperties[afterIndex].getName().compareTo(beforeProperties[beforeIndex].getName());
        }
        PropertyState beforeProperty = null;
        PropertyState afterProperty = null;
        if (d < 0) {
            afterProperty = afterTemplate.getProperty(afterId, afterIndex++);
        } else if (d > 0) {
            beforeProperty = beforeTemplate.getProperty(beforeId, beforeIndex++);
        } else {
            afterProperty = afterTemplate.getProperty(afterId, afterIndex++);
            beforeProperty = beforeTemplate.getProperty(beforeId, beforeIndex++);
        }
        if (!compareProperties(beforeProperty, afterProperty, diff)) {
            return false;
        }
    }
    while (afterIndex < afterProperties.length) {
        if (!diff.propertyAdded(afterTemplate.getProperty(afterId, afterIndex++))) {
            return false;
        }
    }
    while (beforeIndex < beforeProperties.length) {
        PropertyState beforeProperty = beforeTemplate.getProperty(beforeId, beforeIndex++);
        if (!diff.propertyDeleted(beforeProperty)) {
            return false;
        }
    }
    String beforeChildName = beforeTemplate.getChildName();
    String afterChildName = afterTemplate.getChildName();
    if (afterChildName == Template.ZERO_CHILD_NODES) {
        if (beforeChildName != Template.ZERO_CHILD_NODES) {
            for (ChildNodeEntry entry : beforeTemplate.getChildNodeEntries(beforeId)) {
                if (!diff.childNodeDeleted(entry.getName(), entry.getNodeState())) {
                    return false;
                }
            }
        }
    } else if (afterChildName != Template.MANY_CHILD_NODES) {
        NodeState afterNode = afterTemplate.getChildNode(afterChildName, afterId);
        NodeState beforeNode = beforeTemplate.getChildNode(afterChildName, beforeId);
        if (!beforeNode.exists()) {
            if (!diff.childNodeAdded(afterChildName, afterNode)) {
                return false;
            }
        } else if (!fastEquals(afterNode, beforeNode)) {
            if (!diff.childNodeChanged(afterChildName, beforeNode, afterNode)) {
                return false;
            }
        }
        if (beforeChildName == Template.MANY_CHILD_NODES || (beforeChildName != Template.ZERO_CHILD_NODES && !beforeNode.exists())) {
            for (ChildNodeEntry entry : beforeTemplate.getChildNodeEntries(beforeId)) {
                if (!afterChildName.equals(entry.getName())) {
                    if (!diff.childNodeDeleted(entry.getName(), entry.getNodeState())) {
                        return false;
                    }
                }
            }
        }
    } else if (beforeChildName == Template.ZERO_CHILD_NODES) {
        for (ChildNodeEntry entry : afterTemplate.getChildNodeEntries(afterId)) {
            if (!diff.childNodeAdded(entry.getName(), entry.getNodeState())) {
                return false;
            }
        }
    } else if (beforeChildName != Template.MANY_CHILD_NODES) {
        for (ChildNodeEntry entry : afterTemplate.getChildNodeEntries(afterId)) {
            String childName = entry.getName();
            NodeState afterChild = entry.getNodeState();
            if (beforeChildName.equals(childName)) {
                NodeState beforeChild = beforeTemplate.getChildNode(beforeChildName, beforeId);
                if (beforeChild.exists()) {
                    if (!fastEquals(afterChild, beforeChild) && !diff.childNodeChanged(childName, beforeChild, afterChild)) {
                        return false;
                    }
                } else {
                    if (!diff.childNodeAdded(childName, afterChild)) {
                        return false;
                    }
                }
            } else if (!diff.childNodeAdded(childName, afterChild)) {
                return false;
            }
        }
    } else {
        MapRecord afterMap = afterTemplate.getChildNodeMap(afterId);
        MapRecord beforeMap = beforeTemplate.getChildNodeMap(beforeId);
        return afterMap.compare(beforeMap, diff);
    }
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4166_374e3f3d,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositoryUpgrade.java,359,494,"/**
 * Copies the full content from the source to the target repository.
 * <p>
 * The source repository <strong>must not be modified</strong> while
 * the copy operation is running to avoid an inconsistent copy.
 * <p>
 * Note that both the source and the target repository must be closed
 * during the copy operation as this method requires exclusive access
 * to the repositories.
 *
 * @param initializer optional extra repository initializer to use
 * @throws RepositoryException if the copy operation fails
 */
public void copy(RepositoryInitializer initializer) throws RepositoryException {
    RepositoryConfig config = source.getRepositoryConfig();
    logger.info(""Copying repository content from {} to Oak"", config.getHomeDir());
    try {
        NodeBuilder targetBuilder = target.getRoot().builder();
        final Root upgradeRoot = new UpgradeRoot(targetBuilder);
        String workspaceName = source.getRepositoryConfig().getDefaultWorkspaceName();
        SecurityProviderImpl security = new SecurityProviderImpl(mapSecurityConfig(config.getSecurityConfig()));
        // init target repository first
        logger.info(""Initializing initial repository content from {}"", config.getHomeDir());
        new InitialContent().initialize(targetBuilder);
        if (initializer != null) {
            initializer.initialize(targetBuilder);
        }
        logger.debug(""InitialContent completed from {}"", config.getHomeDir());
        for (SecurityConfiguration sc : security.getConfigurations()) {
            RepositoryInitializer ri = sc.getRepositoryInitializer();
            ri.initialize(targetBuilder);
            logger.debug(""Repository initializer '"" + ri.getClass().getName() + ""' completed"", config.getHomeDir());
        }
        for (SecurityConfiguration sc : security.getConfigurations()) {
            WorkspaceInitializer wi = sc.getWorkspaceInitializer();
            wi.initialize(targetBuilder, workspaceName);
            logger.debug(""Workspace initializer '"" + wi.getClass().getName() + ""' completed"", config.getHomeDir());
        }
        HashBiMap<String, String> uriToPrefix = HashBiMap.create();
        logger.info(""Copying registered namespaces"");
        copyNamespaces(targetBuilder, uriToPrefix);
        logger.debug(""Namespace registration completed."");
        logger.info(""Copying registered node types"");
        NodeTypeManager ntMgr = new ReadWriteNodeTypeManager() {

            @Override
            protected Tree getTypes() {
                return upgradeRoot.getTree(NODE_TYPES_PATH);
            }

            @Nonnull
            @Override
            protected Root getWriteRoot() {
                return upgradeRoot;
            }
        };
        copyNodeTypes(ntMgr, new ValueFactoryImpl(upgradeRoot, NamePathMapper.DEFAULT));
        logger.debug(""Node type registration completed."");
        // migrate privileges
        logger.info(""Copying registered privileges"");
        PrivilegeConfiguration privilegeConfiguration = security.getConfiguration(PrivilegeConfiguration.class);
        copyCustomPrivileges(privilegeConfiguration.getPrivilegeManager(upgradeRoot, NamePathMapper.DEFAULT));
        logger.debug(""Privilege registration completed."");
        // Triggers compilation of type information, which we need for
        // the type predicates used by the bulk  copy operations below.
        new TypeEditorProvider(false).getRootEditor(targetBuilder.getBaseState(), targetBuilder.getNodeState(), targetBuilder, null);
        final NodeState reportingSourceRoot = ReportingNodeState.wrap(JackrabbitNodeState.createRootNodeState(source, workspaceName, targetBuilder.getNodeState(), uriToPrefix, copyBinariesByReference, skipOnError), new LoggingReporter(logger, ""Migrating"", 10000, -1));
        final NodeState sourceRoot;
        if (skipLongNames) {
            sourceRoot = NameFilteringNodeState.wrap(reportingSourceRoot);
        } else {
            sourceRoot = reportingSourceRoot;
        }
        final Stopwatch watch = Stopwatch.createStarted();
        logger.info(""Copying workspace content"");
        copyWorkspace(sourceRoot, targetBuilder, workspaceName);
        // on TarMK this does call triggers the actual copy
        targetBuilder.getNodeState();
        logger.info(""Upgrading workspace content completed in {}s ({})"", watch.elapsed(TimeUnit.SECONDS), watch);
        if (!versionCopyConfiguration.skipOrphanedVersionsCopy()) {
            logger.info(""Copying version storage"");
            watch.reset().start();
            copyVersionStorage(sourceRoot, targetBuilder, versionCopyConfiguration);
            // on TarMK this does call triggers the actual copy
            targetBuilder.getNodeState();
            logger.info(""Version storage copied in {}s ({})"", watch.elapsed(TimeUnit.SECONDS), watch);
        } else {
            logger.info(""Skipping the version storage as the copyOrphanedVersions is set to false"");
        }
        watch.reset().start();
        logger.info(""Applying default commit hooks"");
        // TODO: default hooks?
        List<CommitHook> hooks = newArrayList();
        UserConfiguration userConf = security.getConfiguration(UserConfiguration.class);
        String groupsPath = userConf.getParameters().getConfigValue(UserConstants.PARAM_GROUP_PATH, UserConstants.DEFAULT_GROUP_PATH);
        // hooks specific to the upgrade, need to run first
        hooks.add(new EditorHook(new CompositeEditorProvider(new RestrictionEditorProvider(), new GroupEditorProvider(groupsPath), // copy referenced version histories
        new VersionableEditor.Provider(sourceRoot, workspaceName, versionCopyConfiguration), new SameNameSiblingsEditor.Provider())));
        // security-related hooks
        for (SecurityConfiguration sc : security.getConfigurations()) {
            hooks.addAll(sc.getCommitHooks(workspaceName));
        }
        if (customCommitHooks != null) {
            hooks.addAll(customCommitHooks);
        }
        // type validation, reference and indexing hooks
        hooks.add(new EditorHook(new CompositeEditorProvider(createTypeEditorProvider(), createIndexEditorProvider())));
        target.merge(targetBuilder, new LoggingCompositeHook(hooks, source, overrideEarlyShutdown()), CommitInfo.EMPTY);
        logger.info(""Processing commit hooks completed in {}s ({})"", watch.elapsed(TimeUnit.SECONDS), watch);
        logger.debug(""Repository upgrade completed."");
    } catch (Exception e) {
        throw new RepositoryException(""Failed to copy content"", e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4170_2a489d05,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/FullTextSearchImpl.java,274,287,"@Override
public void restrict(FilterImpl f) {
    if (propertyName != null) {
        if (f.getSelector().equals(selector)) {
            String p = propertyName;
            if (relativePath != null) {
                p = PathUtils.concat(relativePath, p);
            }
            p = normalizePropertyName(p);
            restrictPropertyOnFilter(p, f);
        }
    }
    f.restrictFulltextCondition(fullTextSearchExpression.currentValue().getValue(Type.STRING));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-421_36e70bd7,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,263,272,"@Override
public void reset(NodeState newBase) {
    if (this == root) {
        baseState = checkNotNull(newBase);
        writeState = new MutableNodeState(baseState);
        revision++;
    } else {
        throw new IllegalStateException(""Cannot reset a non-root builder"");
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-428_916cd92f,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/TypeCodes.java,63,70,"/**
 * Splits a {@code jsonString}, which is prefixed with a type code
 * at the location where the prefix ends.
 * @param jsonString  json string to split
 * @return  the location where the prefix ends or -1 if no prefix is present
 */
public static int split(String jsonString) {
    if (jsonString.length() >= 4 && jsonString.charAt(3) == ':') {
        return 3;
    } else {
        return -1;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4291_cdb34ffc,Critical,oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentBufferWriterPool.java,95,110,"@Override
public void flush() throws IOException {
    List<SegmentBufferWriter> toFlush = newArrayList();
    synchronized (this) {
        toFlush.addAll(writers.values());
        toFlush.addAll(disposed);
        writers.clear();
        disposed.clear();
        borrowed.clear();
    }
    // deadlocks of that method calling SegmentStore.writeSegment
    for (SegmentBufferWriter writer : toFlush) {
        writer.flush();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4291_cdb34ffc,Critical,oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentBufferWriterPool.java,112,122,"private synchronized SegmentBufferWriter borrowWriter(Object key) {
    SegmentBufferWriter writer = writers.remove(key);
    if (writer == null) {
        writer = new SegmentBufferWriter(store, tracker, reader, version, getWriterId(wid), gcGeneration.get());
    } else if (writer.getGeneration() != gcGeneration.get()) {
        disposed.add(writer);
        writer = new SegmentBufferWriter(store, tracker, reader, version, getWriterId(wid), gcGeneration.get());
    }
    borrowed.add(writer);
    return writer;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4291_cdb34ffc,Critical,oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentBufferWriterPool.java,124,131,"private synchronized void returnWriter(Object key, SegmentBufferWriter writer) {
    if (borrowed.remove(writer)) {
        checkState(writers.put(key, writer) == null);
    } else {
        // Defer flush this writer as it was borrowed while flush() was called.
        disposed.add(writer);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4291_cdb34ffc,Critical,oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/WriteOperationHandler.java,66,66,"/**
 * Flush any pending changes on any {@link SegmentBufferWriter} managed by this instance.
 * This method <em>does not block</em> to wait for concurrent write operations. However, if
 * a write operation is currently in progress a call to this method ensures the respective
 * changes are properly flushed at the end of that call.
 * @throws IOException
 */
void flush() throws IOException;"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-429_c02ecef8,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryPropertyBuilder.java,218,234,"@SuppressWarnings(""unchecked"")
@Nonnull
@Override
public PropertyBuilder<T> assignFrom(PropertyState property) {
    if (property != null) {
        setName(property.getName());
        if (property.isArray()) {
            isArray = true;
            setValues((Iterable<T>) property.getValue(type.getArrayType()));
        } else {
            isArray = false;
            setValue(property.getValue(type));
        }
    }
    return this;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4307_f303c916,Major,oak-segment-next/src/main/java/org/apache/jackrabbit/oak/segment/SegmentWriter.java,607,619,"private RecordId writeStream(InputStream stream) throws IOException {
    boolean threw = true;
    try {
        RecordId id = SegmentStream.getRecordIdIfAvailable(stream, store);
        if (id == null || isOldGen(id)) {
            id = internalWriteStream(stream);
        }
        threw = false;
        return id;
    } finally {
        Closeables.close(stream, threw);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4307_f303c916,Major,oak-segment-next/src/main/java/org/apache/jackrabbit/oak/segment/SegmentWriter.java,621,667,"private RecordId internalWriteStream(InputStream stream) throws IOException {
    if (stream instanceof SegmentStream) {
        SegmentStream segmentStream = (SegmentStream) stream;
        List<RecordId> blockIds = segmentStream.getBlockIds();
        if (blockIds != null) {
            return writeValueRecord(segmentStream.getLength(), writeList(blockIds));
        }
    }
    // Special case for short binaries (up to about 16kB):
    // store them directly as small- or medium-sized value records
    byte[] data = new byte[Segment.MEDIUM_LIMIT];
    int n = read(stream, data, 0, data.length);
    if (n < Segment.MEDIUM_LIMIT) {
        return writeValueRecord(n, data);
    }
    BlobStore blobStore = store.getBlobStore();
    if (blobStore != null) {
        String blobId = blobStore.writeBlob(new SequenceInputStream(new ByteArrayInputStream(data, 0, n), stream));
        return writeBlobId(blobId);
    }
    data = Arrays.copyOf(data, Segment.MAX_SEGMENT_SIZE);
    n += read(stream, data, n, Segment.MAX_SEGMENT_SIZE - n);
    long length = n;
    List<RecordId> blockIds = newArrayListWithExpectedSize(2 * n / BLOCK_SIZE);
    // Write the data to bulk segments and collect the list of block ids
    while (n != 0) {
        SegmentId bulkId = getTracker().newBulkSegmentId();
        int len = Segment.align(n, 1 << Segment.RECORD_ALIGN_BITS);
        LOG.debug(""Writing bulk segment {} ({} bytes)"", bulkId, n);
        store.writeSegment(bulkId, data, 0, len);
        for (int i = 0; i < n; i += BLOCK_SIZE) {
            blockIds.add(new RecordId(bulkId, data.length - len + i));
        }
        n = read(stream, data, 0, data.length);
        length += n;
    }
    return writeValueRecord(length, writeList(blockIds));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4351_59a83d23,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java,1516,1579,"@Override
public IndexRow next() {
    final IndexRow pathRow = pathCursor.next();
    return new IndexRow() {

        @Override
        public boolean isVirtualRow() {
            return currentRow.isVirutal;
        }

        @Override
        public String getPath() {
            String sub = pathRow.getPath();
            if (isVirtualRow()) {
                return sub;
            } else if (PathUtils.isAbsolute(sub)) {
                return pathPrefix + sub;
            } else {
                return PathUtils.concat(pathPrefix, sub);
            }
        }

        @Override
        public PropertyValue getValue(String columnName) {
            // overlay the score
            if (QueryImpl.JCR_SCORE.equals(columnName)) {
                return PropertyValues.newDouble(currentRow.score);
            }
            if (QueryImpl.REP_SPELLCHECK.equals(columnName) || QueryImpl.REP_SUGGEST.equals(columnName)) {
                return PropertyValues.newString(currentRow.suggestion);
            }
            if (QueryImpl.OAK_SCORE_EXPLANATION.equals(columnName)) {
                return PropertyValues.newString(currentRow.explanation);
            }
            if (QueryImpl.REP_EXCERPT.equals(columnName)) {
                return PropertyValues.newString(currentRow.excerpt);
            }
            if (columnName.startsWith(QueryImpl.REP_FACET)) {
                String facetFieldName = FacetHelper.parseFacetField(columnName);
                Facets facets = currentRow.facets;
                try {
                    if (facets != null) {
                        FacetResult topChildren = facets.getTopChildren(10, facetFieldName);
                        if (topChildren != null) {
                            JsopWriter writer = new JsopBuilder();
                            writer.object();
                            for (LabelAndValue lav : topChildren.labelValues) {
                                writer.key(lav.label).value(lav.value.intValue());
                            }
                            writer.endObject();
                            return PropertyValues.newString(writer.toString());
                        } else {
                            return null;
                        }
                    }
                } catch (Exception e) {
                    throw new RuntimeException(e);
                }
            }
            return pathRow.getValue(columnName);
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4351_59a83d23,Minor,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/LucenePropertyIndex.java,1526,1536,"@Override
public String getPath() {
    String sub = pathRow.getPath();
    if (isVirtualRow()) {
        return sub;
    } else if (PathUtils.isAbsolute(sub)) {
        return pathPrefix + sub;
    } else {
        return PathUtils.concat(pathPrefix, sub);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4353_b0014b7d,Major,oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/Segment.java,317,319,"public static int getGcGen(ByteBuffer data) {
    return data.getInt(GC_GEN_OFFSET);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4353_b0014b7d,Major,oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/Segment.java,321,323,"public int getGcGen() {
    return getGcGen(data);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4353_b0014b7d,Major,oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/FileStore.java,1367,1383,"@Override
public void writeSegment(SegmentId id, byte[] data, int offset, int length) throws IOException {
    fileStoreLock.writeLock().lock();
    try {
        int generation = Segment.getGcGen(wrap(data, offset, length));
        long size = writer.writeEntry(id.getMostSignificantBits(), id.getLeastSignificantBits(), data, offset, length, generation);
        if (size >= maxFileSize) {
            newWriter();
        }
        approximateSize.addAndGet(TarWriter.BLOCK_SIZE + length + TarWriter.getPaddingSize(length));
    } finally {
        fileStoreLock.writeLock().unlock();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4353_b0014b7d,Major,oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/file/TarReader.java,214,228,"/**
 * Regenerates a tar file from a list of entries.
 *
 * @param entries
 * @param file
 * @throws IOException
 */
private static void generateTarFile(LinkedHashMap<UUID, byte[]> entries, File file) throws IOException {
    log.info(""Regenerating tar file {}"", file);
    TarWriter writer = new TarWriter(file);
    for (Map.Entry<UUID, byte[]> entry : entries.entrySet()) {
        UUID uuid = entry.getKey();
        byte[] data = entry.getValue();
        int generation = getGcGen(wrap(data));
        writer.writeEntry(uuid.getMostSignificantBits(), uuid.getLeastSignificantBits(), data, 0, data.length, generation);
    }
    writer.close();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4358_74cbba24,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,730,880,"/**
 * Get the revision of the latest change made to this node. At the same
 * time this method collects all collisions that happened for the given
 * {@code changeRev}. The reported latest change takes branches into
 * account. This means, if {@code changeRev} is on a branch, the latest
 * change is either a change that was done by a preceding branch commit or
 * a change that happened before the base of the branch. Changes done after
 * the branch base on trunk are not considered in this case. For a trunk
 * commit the latest change is reported similarly. In this case, unmerged
 * branch commits are not considered as latest change. Only commits to trunk
 * are considered.
 *
 * Collisions include the following cases:
 * <ul>
 *     <li>The other change is not yet committed</li>
 *     <li>The other change is a branch commit and not yet merged</li>
 *     <li>The {@code changeRev} is a branch commit and the other change
 *       happened after the base revision of the branch</li>
 *     <li>The other change is from another cluster node and not yet
 *       visible</li>
 * </ul>
 *
 * @param context the revision context.
 * @param baseRev the base revision of the current change.
 * @param changeRev the revision of the current change.
 * @param branch the branch associated with the current change or
 *              {@code null} if {@code changeRev} is not a branch commit.
 * @param collisions changes that happened after {@code baseRev}.
 */
@CheckForNull
Revision getNewestRevision(final RevisionContext context, final RevisionVector baseRev, final Revision changeRev, final Branch branch, final Set<Revision> collisions) {
    checkArgument(!baseRev.isBranch() || branch != null, ""Branch must be non-null if baseRev is a branch revision"");
    RevisionVector head = context.getHeadRevision();
    RevisionVector lower = branch != null ? branch.getBase() : baseRev;
    // the clusterIds to check when walking the changes
    Set<Integer> clusterIds = Collections.emptySet();
    if (!getPreviousRanges().isEmpty()) {
        clusterIds = Sets.newHashSet();
        for (Revision prevRev : getPreviousRanges().keySet()) {
            if (lower.isRevisionNewer(prevRev) || equal(prevRev, lower.getRevision(prevRev.getClusterId()))) {
                clusterIds.add(prevRev.getClusterId());
            }
        }
        if (!clusterIds.isEmpty()) {
            // add clusterIds of local changes as well
            for (Revision r : getLocalCommitRoot().keySet()) {
                clusterIds.add(r.getClusterId());
            }
            for (Revision r : getLocalRevisions().keySet()) {
                clusterIds.add(r.getClusterId());
            }
        }
    }
    // if we don't have clusterIds, we can use the local changes only
    boolean fullScan = true;
    Iterable<Revision> changes;
    if (clusterIds.isEmpty()) {
        // baseRev is newer than all previous documents
        changes = Iterables.mergeSorted(ImmutableList.of(getLocalRevisions().keySet(), getLocalCommitRoot().keySet()), getLocalRevisions().comparator());
    } else {
        // include previous documents as well (only needed in rare cases)
        fullScan = false;
        changes = getAllChanges();
        if (LOG.isDebugEnabled()) {
            LOG.debug(""getNewestRevision() with changeRev {} on {}, "" + ""_revisions {}, _commitRoot {}"", changeRev, getId(), getLocalRevisions(), getLocalCommitRoot());
        }
    }
    Map<Integer, Revision> newestRevs = Maps.newHashMap();
    Map<Revision, String> validRevisions = Maps.newHashMap();
    for (Revision r : changes) {
        if (r.equals(changeRev)) {
            continue;
        }
        if (!fullScan) {
            // check if we can stop going through changes
            if (clusterIds.contains(r.getClusterId()) && !lower.isRevisionNewer(r) && newestRevs.containsKey(r.getClusterId())) {
                clusterIds.remove(r.getClusterId());
                if (clusterIds.isEmpty()) {
                    // the lower bound
                    break;
                }
            }
        }
        if (newestRevs.containsKey(r.getClusterId())) {
            // of the branch if this is for a commit on a branch
            if (branch != null && !branch.containsCommit(r)) {
                // change does not belong to the branch
                if (branch.getBase(changeRev).isRevisionNewer(r)) {
                    // and happened after the base of the branch
                    collisions.add(r);
                }
            }
        } else {
            // check if change is visible from baseRev
            if (isValidRevision(context, r, null, baseRev, validRevisions)) {
                // consider for newestRev
                newestRevs.put(r.getClusterId(), r);
            } else {
                // not valid means:
                // 1) 'r' is not committed -> collision
                // 2) 'r' is on a branch, but not the same as
                // changeRev -> collisions
                // 3) changeRev is on a branch and 'r' is newer than
                // the base of the branch -> collision
                // 4) 'r' is committed but not yet visible to current
                // cluster node -> collisions
                // 5) changeRev is not on a branch, 'r' is committed and
                // newer than baseRev -> newestRev
                NodeDocument commitRoot = getCommitRoot(r);
                Revision commitRevision = null;
                if (commitRoot != null) {
                    commitRevision = commitRoot.getCommitRevision(r);
                }
                if (// committed but not yet visible
                commitRevision != null && head.isRevisionNewer(commitRevision)) {
                    // case 4)
                    collisions.add(r);
                } else if (// committed
                commitRevision != null && // changeRev not on branch
                branch == null && baseRev.isRevisionNewer(r)) {
                    // case 5)
                    newestRevs.put(r.getClusterId(), r);
                } else {
                    // remaining cases 1), 2) and 3)
                    collisions.add(r);
                }
            }
        }
    }
    // select the newest committed change
    Revision newestRev = null;
    for (Revision r : newestRevs.values()) {
        newestRev = Utils.max(newestRev, r, StableRevisionComparator.INSTANCE);
    }
    if (newestRev == null) {
        return null;
    }
    // the local deleted map contains the most recent revisions
    SortedMap<Revision, String> deleted = getLocalDeleted();
    String value = deleted.get(newestRev);
    if (value == null && deleted.headMap(newestRev).isEmpty()) {
        // no need to check previous docs
        return newestRev;
    }
    if (value == null) {
        // get from complete map
        value = getDeleted().get(newestRev);
    }
    if (""true"".equals(value)) {
        // deleted in the newest revision
        return null;
    }
    return newestRev;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4358_74cbba24,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1455,1534,"/**
 * Returns an {@link Iterable} of {@link Revision} of all changes performed
 * on this document. This covers all entries for {@link #REVISIONS} and
 * {@link #COMMIT_ROOT} including previous documents. The revisions are
 * returned in descending stable revision order using
 * {@link StableRevisionComparator#REVERSE}.
 *
 * @return revisions of all changes performed on this document.
 */
Iterable<Revision> getAllChanges() {
    final SortedSet<Revision> stack = Sets.newTreeSet(REVERSE);
    // initialize with local revisions and commitRoot entries
    stack.addAll(getLocalCommitRoot().keySet());
    stack.addAll(getLocalRevisions().keySet());
    if (getPreviousRanges().isEmpty()) {
        return stack;
    }
    return new Iterable<Revision>() {

        @Override
        public Iterator<Revision> iterator() {
            final Iterator<NodeDocument> previousDocs = getPreviousDocLeaves();
            return new AbstractIterator<Revision>() {

                private NodeDocument nextDoc;

                private Revision nextRevision;

                @Override
                protected Revision computeNext() {
                    if (stack.isEmpty()) {
                        return endOfData();
                    }
                    Revision next = stack.first();
                    stack.remove(next);
                    fillStackIfNeeded();
                    return next;
                }

                private void fillStackIfNeeded() {
                    for (; ; ) {
                        fetchNextDoc();
                        // no more changes to compare with
                        if (nextDoc == null) {
                            return;
                        }
                        // most recent revision of next document
                        if (!stack.isEmpty()) {
                            Revision top = stack.first();
                            if (top.compareRevisionTimeThenClusterId(nextRevision) > 0) {
                                return;
                            }
                        }
                        // if we get here, we need to pull in changes
                        // from nextDoc
                        Iterables.addAll(stack, nextDoc.getAllChanges());
                        nextDoc = null;
                        nextRevision = null;
                    }
                }

                /**
                 * Fetch the next document if {@code nextDoc} is
                 * {@code null} and there are more documents.
                 */
                private void fetchNextDoc() {
                    for (; ; ) {
                        if (nextDoc != null) {
                            break;
                        }
                        if (!previousDocs.hasNext()) {
                            // no more previous docs
                            break;
                        }
                        nextDoc = previousDocs.next();
                        Iterator<Revision> changes = nextDoc.getAllChanges().iterator();
                        if (changes.hasNext()) {
                            nextRevision = changes.next();
                            break;
                        } else {
                            // empty document, try next
                            nextDoc = null;
                        }
                    }
                }
            };
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4358_74cbba24,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1464,1532,"@Override
public Iterator<Revision> iterator() {
    final Iterator<NodeDocument> previousDocs = getPreviousDocLeaves();
    return new AbstractIterator<Revision>() {

        private NodeDocument nextDoc;

        private Revision nextRevision;

        @Override
        protected Revision computeNext() {
            if (stack.isEmpty()) {
                return endOfData();
            }
            Revision next = stack.first();
            stack.remove(next);
            fillStackIfNeeded();
            return next;
        }

        private void fillStackIfNeeded() {
            for (; ; ) {
                fetchNextDoc();
                // no more changes to compare with
                if (nextDoc == null) {
                    return;
                }
                // most recent revision of next document
                if (!stack.isEmpty()) {
                    Revision top = stack.first();
                    if (top.compareRevisionTimeThenClusterId(nextRevision) > 0) {
                        return;
                    }
                }
                // if we get here, we need to pull in changes
                // from nextDoc
                Iterables.addAll(stack, nextDoc.getAllChanges());
                nextDoc = null;
                nextRevision = null;
            }
        }

        /**
         * Fetch the next document if {@code nextDoc} is
         * {@code null} and there are more documents.
         */
        private void fetchNextDoc() {
            for (; ; ) {
                if (nextDoc != null) {
                    break;
                }
                if (!previousDocs.hasNext()) {
                    // no more previous docs
                    break;
                }
                nextDoc = previousDocs.next();
                Iterator<Revision> changes = nextDoc.getAllChanges().iterator();
                if (changes.hasNext()) {
                    nextRevision = changes.next();
                    break;
                } else {
                    // empty document, try next
                    nextDoc = null;
                }
            }
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4358_74cbba24,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1470,1479,"@Override
protected Revision computeNext() {
    if (stack.isEmpty()) {
        return endOfData();
    }
    Revision next = stack.first();
    stack.remove(next);
    fillStackIfNeeded();
    return next;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4358_74cbba24,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1481,1505,"private void fillStackIfNeeded() {
    for (; ; ) {
        fetchNextDoc();
        // no more changes to compare with
        if (nextDoc == null) {
            return;
        }
        // most recent revision of next document
        if (!stack.isEmpty()) {
            Revision top = stack.first();
            if (top.compareRevisionTimeThenClusterId(nextRevision) > 0) {
                return;
            }
        }
        // if we get here, we need to pull in changes
        // from nextDoc
        Iterables.addAll(stack, nextDoc.getAllChanges());
        nextDoc = null;
        nextRevision = null;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4358_74cbba24,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1511,1530,"/**
 * Fetch the next document if {@code nextDoc} is
 * {@code null} and there are more documents.
 */
private void fetchNextDoc() {
    for (; ; ) {
        if (nextDoc != null) {
            break;
        }
        if (!previousDocs.hasNext()) {
            // no more previous docs
            break;
        }
        nextDoc = previousDocs.next();
        Iterator<Revision> changes = nextDoc.getAllChanges().iterator();
        if (changes.hasNext()) {
            nextRevision = changes.next();
            break;
        } else {
            // empty document, try next
            nextDoc = null;
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4358_74cbba24,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1545,1585,"/**
 * Returns all changes for the given property back to {@code min} revision
 * (exclusive). The revisions include committed as well as uncommitted
 * changes.
 *
 * @param property the name of the property.
 * @param min the lower bound revision (exclusive).
 * @return changes back to {@code min} revision.
 */
@Nonnull
Iterable<Revision> getChanges(@Nonnull final String property, @Nonnull final RevisionVector min) {
    return new Iterable<Revision>() {

        @Override
        public Iterator<Revision> iterator() {
            final Set<Revision> changes = getValueMap(property).keySet();
            final Set<Integer> clusterIds = Sets.newHashSet();
            for (Revision r : getLocalMap(property).keySet()) {
                clusterIds.add(r.getClusterId());
            }
            for (Range r : getPreviousRanges().values()) {
                if (min.isRevisionNewer(r.high)) {
                    clusterIds.add(r.high.getClusterId());
                }
            }
            final Iterator<Revision> unfiltered = changes.iterator();
            return new AbstractIterator<Revision>() {

                @Override
                protected Revision computeNext() {
                    while (unfiltered.hasNext()) {
                        Revision next = unfiltered.next();
                        if (min.isRevisionNewer(next)) {
                            return next;
                        } else {
                            // further revisions with this clusterId
                            // are older than min revision
                            clusterIds.remove(next.getClusterId());
                            // no more revisions to check
                            if (clusterIds.isEmpty()) {
                                return endOfData();
                            }
                        }
                    }
                    return endOfData();
                }
            };
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4358_74cbba24,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1549,1582,"@Override
public Iterator<Revision> iterator() {
    final Set<Revision> changes = getValueMap(property).keySet();
    final Set<Integer> clusterIds = Sets.newHashSet();
    for (Revision r : getLocalMap(property).keySet()) {
        clusterIds.add(r.getClusterId());
    }
    for (Range r : getPreviousRanges().values()) {
        if (min.isRevisionNewer(r.high)) {
            clusterIds.add(r.high.getClusterId());
        }
    }
    final Iterator<Revision> unfiltered = changes.iterator();
    return new AbstractIterator<Revision>() {

        @Override
        protected Revision computeNext() {
            while (unfiltered.hasNext()) {
                Revision next = unfiltered.next();
                if (min.isRevisionNewer(next)) {
                    return next;
                } else {
                    // further revisions with this clusterId
                    // are older than min revision
                    clusterIds.remove(next.getClusterId());
                    // no more revisions to check
                    if (clusterIds.isEmpty()) {
                        return endOfData();
                    }
                }
            }
            return endOfData();
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4358_74cbba24,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/document/NodeDocument.java,1563,1580,"@Override
protected Revision computeNext() {
    while (unfiltered.hasNext()) {
        Revision next = unfiltered.next();
        if (min.isRevisionNewer(next)) {
            return next;
        } else {
            // further revisions with this clusterId
            // are older than min revision
            clusterIds.remove(next.getClusterId());
            // no more revisions to check
            if (clusterIds.isEmpty()) {
                return endOfData();
            }
        }
    }
    return endOfData();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4376_037dea72,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/XPathToSQL2Converter.java,89,325,"private Statement convertToStatement(String query) throws ParseException {
    query = query.trim();
    Statement statement = new Statement();
    if (query.startsWith(""explain "")) {
        query = query.substring(""explain"".length()).trim();
        statement.setExplain(true);
    }
    if (query.startsWith(""measure"")) {
        query = query.substring(""measure"".length()).trim();
        statement.setMeasure(true);
    }
    if (query.isEmpty()) {
        // special case, will always result in an empty result
        query = ""//jcr:root"";
    }
    statement.setOriginalQuery(query);
    initialize(query);
    expected = new ArrayList<String>();
    read();
    if (currentTokenType == END) {
        throw getSyntaxError(""the query may not be empty"");
    }
    currentSelector.name = ""a"";
    String pathPattern = """";
    boolean startOfQuery = true;
    while (true) {
        // if true, path or nodeType conditions are not allowed
        boolean shortcut = false;
        boolean slash = readIf(""/"");
        if (!slash) {
            if (startOfQuery) {
                // the query doesn't start with ""/""
                currentSelector.path = ""/"";
                pathPattern = ""/"";
                currentSelector.isChild = true;
            } else {
                break;
            }
        } else if (readIf(""jcr:root"")) {
            // ""/jcr:root"" may only appear at the beginning
            if (!pathPattern.isEmpty()) {
                throw getSyntaxError(""jcr:root needs to be at the beginning"");
            }
            if (readIf(""/"")) {
                // ""/jcr:root/""
                currentSelector.path = ""/"";
                pathPattern = ""/"";
                if (readIf(""/"")) {
                    // ""/jcr:root//""
                    pathPattern = ""//"";
                    currentSelector.isDescendant = true;
                } else {
                    currentSelector.isChild = true;
                }
            } else {
                // for example ""/jcr:root[condition]""
                pathPattern = ""/%"";
                currentSelector.path = ""/"";
                shortcut = true;
            }
        } else if (readIf(""/"")) {
            // ""//"" was read
            pathPattern += ""%"";
            currentSelector.isDescendant = true;
        } else {
            // the token ""/"" was read
            pathPattern += ""/"";
            if (startOfQuery) {
                currentSelector.path = ""/"";
            } else {
                currentSelector.isChild = true;
            }
        }
        int startParseIndex = parseIndex;
        if (shortcut) {
        // ""*"" and so on are not allowed now
        } else if (readIf(""*"")) {
            // ""...*""
            pathPattern += ""%"";
            if (!currentSelector.isDescendant) {
                if (selectors.size() == 0 && currentSelector.path.equals("""")) {
                    // the query /* is special
                    currentSelector.path = ""/"";
                }
            }
        } else if (readIf(""text"")) {
            // ""...text()""
            currentSelector.isChild = false;
            pathPattern += ""jcr:xmltext"";
            read(""("");
            read("")"");
            if (currentSelector.isDescendant) {
                currentSelector.nodeName = ""jcr:xmltext"";
            } else {
                currentSelector.path = PathUtils.concat(currentSelector.path, ""jcr:xmltext"");
            }
        } else if (readIf(""element"")) {
            // ""...element(...""
            read(""("");
            if (readIf("")"")) {
                // any
                pathPattern += ""%"";
            } else {
                if (readIf(""*"")) {
                    // any
                    pathPattern += ""%"";
                } else {
                    String name = readPathSegment();
                    pathPattern += name;
                    appendNodeName(name);
                }
                if (readIf("","")) {
                    currentSelector.nodeType = readIdentifier();
                }
                read("")"");
            }
        } else if (readIf(""@"")) {
            rewindSelector();
            Expression.Property p = readProperty();
            statement.addSelectColumn(p);
        } else if (readIf(""rep:excerpt"")) {
            rewindSelector();
            readExcerpt();
            Expression.Property p = new Expression.Property(currentSelector, ""rep:excerpt"", false);
            statement.addSelectColumn(p);
        } else if (readIf(""("")) {
            rewindSelector();
            do {
                if (readIf(""@"")) {
                    Expression.Property p = readProperty();
                    statement.addSelectColumn(p);
                } else if (readIf(""rep:excerpt"")) {
                    readExcerpt();
                    Expression.Property p = new Expression.Property(currentSelector, ""rep:excerpt"", false);
                    statement.addSelectColumn(p);
                } else if (readIf(""rep:spellcheck"")) {
                    // only rep:spellcheck() is currently supported
                    read(""("");
                    read("")"");
                    Expression.Property p = new Expression.Property(currentSelector, ""rep:spellcheck()"", false);
                    statement.addSelectColumn(p);
                } else if (readIf(""rep:suggest"")) {
                    readExcerpt();
                    Expression.Property p = new Expression.Property(currentSelector, ""rep:suggest()"", false);
                    statement.addSelectColumn(p);
                }
            } while (readIf(""|""));
            if (!readIf("")"")) {
                return convertToUnion(query, statement, startParseIndex - 1);
            }
        } else if (currentTokenType == IDENTIFIER) {
            // path restriction
            String name = readPathSegment();
            pathPattern += name;
            appendNodeName(name);
        } else if (readIf(""."")) {
            // ""a/./b"" is the same as ""a/b""
            if (readIf(""."")) {
                // "".."" means ""the parent of the node""
                // handle like a regular path restriction
                String name = "".."";
                pathPattern += name;
                if (!currentSelector.isChild) {
                    currentSelector.nodeName = name;
                } else {
                    if (currentSelector.isChild) {
                        currentSelector.isChild = false;
                        currentSelector.isParent = true;
                    }
                }
            } else {
                if (selectors.size() > 0) {
                    currentSelector = selectors.remove(selectors.size() - 1);
                    currentSelector.condition = null;
                    currentSelector.joinCondition = null;
                }
            }
        } else {
            throw getSyntaxError();
        }
        if (readIf(""["")) {
            Expression c = parseConstraint();
            currentSelector.condition = Expression.and(currentSelector.condition, c);
            read(""]"");
        }
        startOfQuery = false;
        nextSelector(false);
    }
    if (selectors.size() == 0) {
        nextSelector(true);
    }
    // the current selector wasn't used so far
    // go back to the last one
    currentSelector = selectors.get(selectors.size() - 1);
    if (selectors.size() == 1) {
        currentSelector.onlySelector = true;
    }
    if (readIf(""order"")) {
        read(""by"");
        do {
            Order order = new Order();
            order.expr = parseExpression();
            if (readIf(""descending"")) {
                order.descending = true;
            } else {
                readIf(""ascending"");
            }
            statement.addOrderBy(order);
        } while (readIf("",""));
    }
    if (!currentToken.isEmpty()) {
        throw getSyntaxError(""<end>"");
    }
    statement.setColumnSelector(currentSelector);
    statement.setSelectors(selectors);
    Expression where = null;
    for (Selector s : selectors) {
        where = Expression.and(where, s.condition);
    }
    statement.setWhere(where);
    return statement;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4387_ca05fd06,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/XPathToSQL2Converter.java,89,333,"private Statement convertToStatement(String query) throws ParseException {
    query = query.trim();
    Statement statement = new Statement();
    if (query.startsWith(""explain "")) {
        query = query.substring(""explain"".length()).trim();
        statement.setExplain(true);
    }
    if (query.startsWith(""measure"")) {
        query = query.substring(""measure"".length()).trim();
        statement.setMeasure(true);
    }
    if (query.isEmpty()) {
        // special case, will always result in an empty result
        query = ""//jcr:root"";
    }
    statement.setOriginalQuery(query);
    initialize(query);
    expected = new ArrayList<String>();
    read();
    if (currentTokenType == END) {
        throw getSyntaxError(""the query may not be empty"");
    }
    currentSelector.name = ""a"";
    String pathPattern = """";
    boolean startOfQuery = true;
    while (true) {
        // if true, path or nodeType conditions are not allowed
        boolean shortcut = false;
        boolean slash = readIf(""/"");
        if (!slash) {
            if (startOfQuery) {
                // the query doesn't start with ""/""
                currentSelector.path = ""/"";
                pathPattern = ""/"";
                currentSelector.isChild = true;
            } else {
                break;
            }
        } else if (readIf(""jcr:root"")) {
            // ""/jcr:root"" may only appear at the beginning
            if (!pathPattern.isEmpty()) {
                throw getSyntaxError(""jcr:root needs to be at the beginning"");
            }
            if (readIf(""/"")) {
                // ""/jcr:root/""
                currentSelector.path = ""/"";
                pathPattern = ""/"";
                if (readIf(""/"")) {
                    // ""/jcr:root//""
                    pathPattern = ""//"";
                    currentSelector.isDescendant = true;
                } else {
                    currentSelector.isChild = true;
                }
            } else {
                // for example ""/jcr:root[condition]""
                pathPattern = ""/%"";
                currentSelector.path = ""/"";
                shortcut = true;
            }
        } else if (readIf(""/"")) {
            // ""//"" was read
            pathPattern += ""%"";
            if (currentSelector.isDescendant) {
                // the query started with ""//"", and now ""//"" was read
                nextSelector(true);
            }
            currentSelector.isDescendant = true;
        } else {
            // the token ""/"" was read
            pathPattern += ""/"";
            if (startOfQuery) {
                currentSelector.path = ""/"";
            } else {
                if (currentSelector.isDescendant) {
                    // the query started with ""//"", and now ""/"" was read
                    nextSelector(true);
                }
                currentSelector.isChild = true;
            }
        }
        int startParseIndex = parseIndex;
        if (shortcut) {
        // ""*"" and so on are not allowed now
        } else if (readIf(""*"")) {
            // ""...*""
            pathPattern += ""%"";
            if (!currentSelector.isDescendant) {
                if (selectors.size() == 0 && currentSelector.path.equals("""")) {
                    // the query /* is special
                    currentSelector.path = ""/"";
                }
            }
        } else if (readIf(""text"")) {
            // ""...text()""
            currentSelector.isChild = false;
            pathPattern += ""jcr:xmltext"";
            read(""("");
            read("")"");
            if (currentSelector.isDescendant) {
                currentSelector.nodeName = ""jcr:xmltext"";
            } else {
                currentSelector.path = PathUtils.concat(currentSelector.path, ""jcr:xmltext"");
            }
        } else if (readIf(""element"")) {
            // ""...element(...""
            read(""("");
            if (readIf("")"")) {
                // any
                pathPattern += ""%"";
            } else {
                if (readIf(""*"")) {
                    // any
                    pathPattern += ""%"";
                } else {
                    String name = readPathSegment();
                    pathPattern += name;
                    appendNodeName(name);
                }
                if (readIf("","")) {
                    currentSelector.nodeType = readIdentifier();
                }
                read("")"");
            }
        } else if (readIf(""@"")) {
            rewindSelector();
            Expression.Property p = readProperty();
            statement.addSelectColumn(p);
        } else if (readIf(""rep:excerpt"")) {
            rewindSelector();
            readExcerpt();
            Expression.Property p = new Expression.Property(currentSelector, ""rep:excerpt"", false);
            statement.addSelectColumn(p);
        } else if (readIf(""("")) {
            rewindSelector();
            do {
                if (readIf(""@"")) {
                    Expression.Property p = readProperty();
                    statement.addSelectColumn(p);
                } else if (readIf(""rep:excerpt"")) {
                    readExcerpt();
                    Expression.Property p = new Expression.Property(currentSelector, ""rep:excerpt"", false);
                    statement.addSelectColumn(p);
                } else if (readIf(""rep:spellcheck"")) {
                    // only rep:spellcheck() is currently supported
                    read(""("");
                    read("")"");
                    Expression.Property p = new Expression.Property(currentSelector, ""rep:spellcheck()"", false);
                    statement.addSelectColumn(p);
                } else if (readIf(""rep:suggest"")) {
                    readExcerpt();
                    Expression.Property p = new Expression.Property(currentSelector, ""rep:suggest()"", false);
                    statement.addSelectColumn(p);
                }
            } while (readIf(""|""));
            if (!readIf("")"")) {
                return convertToUnion(query, statement, startParseIndex - 1);
            }
        } else if (currentTokenType == IDENTIFIER) {
            // path restriction
            String name = readPathSegment();
            pathPattern += name;
            appendNodeName(name);
        } else if (readIf(""."")) {
            // ""a/./b"" is the same as ""a/b""
            if (readIf(""."")) {
                // "".."" means ""the parent of the node""
                // handle like a regular path restriction
                String name = "".."";
                pathPattern += name;
                if (!currentSelector.isChild) {
                    currentSelector.nodeName = name;
                } else {
                    if (currentSelector.isChild) {
                        currentSelector.isChild = false;
                        currentSelector.isParent = true;
                    }
                }
            } else {
                if (selectors.size() > 0) {
                    currentSelector = selectors.remove(selectors.size() - 1);
                    currentSelector.condition = null;
                    currentSelector.joinCondition = null;
                }
            }
        } else {
            throw getSyntaxError();
        }
        if (readIf(""["")) {
            Expression c = parseConstraint();
            currentSelector.condition = Expression.and(currentSelector.condition, c);
            read(""]"");
        }
        startOfQuery = false;
        nextSelector(false);
    }
    if (selectors.size() == 0) {
        nextSelector(true);
    }
    // the current selector wasn't used so far
    // go back to the last one
    currentSelector = selectors.get(selectors.size() - 1);
    if (selectors.size() == 1) {
        currentSelector.onlySelector = true;
    }
    if (readIf(""order"")) {
        read(""by"");
        do {
            Order order = new Order();
            order.expr = parseExpression();
            if (readIf(""descending"")) {
                order.descending = true;
            } else {
                readIf(""ascending"");
            }
            statement.addOrderBy(order);
        } while (readIf("",""));
    }
    if (!currentToken.isEmpty()) {
        throw getSyntaxError(""<end>"");
    }
    statement.setColumnSelector(currentSelector);
    statement.setSelectors(selectors);
    Expression where = null;
    for (Selector s : selectors) {
        where = Expression.and(where, s.condition);
    }
    statement.setWhere(where);
    return statement;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4387_ca05fd06,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/xpath/XPathToSQL2Converter.java,720,727,"private void readExcerpt() throws ParseException {
    read(""("");
    if (!readIf("")"")) {
        // only rep:excerpt(.) and rep:excerpt() are currently supported
        read(""."");
        read("")"");
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4397_e33516d5,Critical,oak-auth-external/src/main/java/org/apache/jackrabbit/oak/spi/security/authentication/external/basic/DefaultSyncContext.java,481,569,"/**
 * Recursively sync the memberships of an authorizable up-to the specified depth. If the given depth
 * is equal or less than 0, no syncing is performed.
 *
 * @param external the external identity
 * @param auth the authorizable
 * @param depth recursion depth.
 * @throws RepositoryException
 */
protected void syncMembership(@Nonnull ExternalIdentity external, @Nonnull Authorizable auth, long depth) throws RepositoryException {
    if (depth <= 0) {
        return;
    }
    if (log.isDebugEnabled()) {
        log.debug(""Syncing membership '{}' -> '{}'"", external.getExternalId().getString(), auth.getID());
    }
    final DebugTimer timer = new DebugTimer();
    Iterable<ExternalIdentityRef> externalGroups;
    try {
        externalGroups = external.getDeclaredGroups();
    } catch (ExternalIdentityException e) {
        log.error(""Error while retrieving external declared groups for '{}'"", external.getId(), e);
        return;
    }
    timer.mark(""fetching"");
    // first get the set of the existing groups that are synced ones
    Map<String, Group> declaredExternalGroups = new HashMap<String, Group>();
    Iterator<Group> grpIter = auth.declaredMemberOf();
    while (grpIter.hasNext()) {
        Group grp = grpIter.next();
        if (isSameIDP(grp)) {
            declaredExternalGroups.put(grp.getID(), grp);
        }
    }
    timer.mark(""reading"");
    for (ExternalIdentityRef ref : externalGroups) {
        log.debug(""- processing membership {}"", ref.getId());
        // get group
        ExternalGroup extGroup;
        try {
            ExternalIdentity extId = idp.getIdentity(ref);
            if (extId instanceof ExternalGroup) {
                extGroup = (ExternalGroup) extId;
            } else {
                log.warn(""No external group found for ref '{}'."", ref.getString());
                continue;
            }
        } catch (ExternalIdentityException e) {
            log.warn(""Unable to retrieve external group '{}' from provider."", ref.getString(), e);
            continue;
        }
        log.debug(""- idp returned '{}'"", extGroup.getId());
        Group grp;
        Authorizable a = userManager.getAuthorizable(extGroup.getId());
        if (a == null) {
            grp = createGroup(extGroup);
            log.debug(""- created new group"");
        } else if (a.isGroup()) {
            grp = (Group) a;
        } else {
            log.warn(""Authorizable '{}' is not a group, but should be one."", extGroup.getId());
            continue;
        }
        log.debug(""- user manager returned '{}'"", grp);
        syncGroup(extGroup, grp);
        // ensure membership
        grp.addMember(auth);
        log.debug(""- added '{}' as member to '{}'"", auth, grp);
        // remember the declared group
        declaredExternalGroups.remove(grp.getID());
        // recursively apply further membership
        if (depth > 1) {
            log.debug(""- recursively sync group membership of '{}' (depth = {})."", grp.getID(), depth);
            syncMembership(extGroup, grp, depth - 1);
        } else {
            log.debug(""- group nesting level for '{}' reached"", grp.getID());
        }
    }
    timer.mark(""adding"");
    // remove us from the lost membership groups
    for (Group grp : declaredExternalGroups.values()) {
        grp.removeMember(auth);
        log.debug(""- removing member '{}' for group '{}'"", auth.getID(), grp.getID());
    }
    if (log.isDebugEnabled()) {
        timer.mark(""removing"");
        log.debug(""syncMembership({}) {}"", external.getId(), timer.getString());
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/core/MicroKernelImpl.java,90,101,"public void dispose() {
    gate.commit(""end"");
    if (rep != null) {
        try {
            rep.shutDown();
        } catch (Exception ignore) {
        // fail silently
        }
        rep = null;
    }
    diffCache.clear();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/core/MicroKernelImpl.java,161,223,"public String getJournal(String fromRevision, String toRevision, String filter) throws MicroKernelException {
    if (rep == null) {
        throw new IllegalStateException(""this instance has already been disposed"");
    }
    Id fromRevisionId = Id.fromString(fromRevision);
    Id toRevisionId = toRevision == null ? getHeadRevisionId() : Id.fromString(toRevision);
    List<StoredCommit> commits = new ArrayList<StoredCommit>();
    try {
        StoredCommit toCommit = rep.getCommit(toRevisionId);
        Commit fromCommit;
        if (toRevisionId.equals(fromRevisionId)) {
            fromCommit = toCommit;
        } else {
            fromCommit = rep.getCommit(fromRevisionId);
            if (fromCommit.getCommitTS() > toCommit.getCommitTS()) {
                // negative range, return empty array
                return ""[]"";
            }
        }
        // collect commits, starting with toRevisionId
        // and traversing parent commit links until we've reached
        // fromRevisionId
        StoredCommit commit = toCommit;
        while (commit != null) {
            commits.add(commit);
            if (commit.getId().equals(fromRevisionId)) {
                break;
            }
            Id commitId = commit.getParentId();
            if (commitId == null) {
                break;
            }
            commit = rep.getCommit(commitId);
        }
    } catch (Exception e) {
        throw new MicroKernelException(e);
    }
    JsopBuilder commitBuff = new JsopBuilder().array();
    // starting with oldest commit
    for (int i = commits.size() - 1; i >= 0; i--) {
        StoredCommit commit = commits.get(i);
        if (commit.getParentId() == null) {
            continue;
        }
        commitBuff.object().key(""id"").value(commit.getId().toString()).key(""ts"").value(commit.getCommitTS()).key(""msg"").value(commit.getMsg());
        String diff = diffCache.get(commit.getId());
        if (diff == null) {
            diff = diff(commit.getParentId(), commit.getId(), filter);
            diffCache.put(commit.getId(), diff);
        }
        commitBuff.key(""changes"").value(diff).endObject();
    }
    return commitBuff.endArray().toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/core/MicroKernelImpl.java,450,584,"public String commit(String path, String jsonDiff, String revision, String message) throws MicroKernelException {
    if (rep == null) {
        throw new IllegalStateException(""this instance has already been disposed"");
    }
    if (path.length() > 0 && !PathUtils.isAbsolute(path)) {
        throw new IllegalArgumentException(""absolute path expected: "" + path);
    }
    Id revisionId = revision == null ? getHeadRevisionId() : Id.fromString(revision);
    try {
        JsopTokenizer t = new JsopTokenizer(jsonDiff);
        CommitBuilder cb = rep.getCommitBuilder(revisionId, message);
        while (true) {
            int r = t.read();
            if (r == JsopTokenizer.END) {
                break;
            }
            // used for error reporting
            int pos;
            switch(r) {
                case '+':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        t.read(':');
                        if (t.matches('{')) {
                            String nodePath = PathUtils.concat(path, subPath);
                            if (!PathUtils.isAbsolute(nodePath)) {
                                throw new Exception(""absolute path expected: "" + nodePath + "", pos: "" + pos);
                            }
                            String parentPath = PathUtils.getParentPath(nodePath);
                            String nodeName = PathUtils.getName(nodePath);
                            // build the list of added nodes recursively
                            LinkedList<AddNodeOperation> list = new LinkedList<AddNodeOperation>();
                            addNode(list, parentPath, nodeName, t);
                            for (AddNodeOperation op : list) {
                                cb.addNode(op.path, op.name, op.props);
                            }
                        } else {
                            String value;
                            if (t.matches(JsopTokenizer.NULL)) {
                                value = null;
                            } else {
                                value = t.readRawValue().trim();
                            }
                            String targetPath = PathUtils.concat(path, subPath);
                            if (!PathUtils.isAbsolute(targetPath)) {
                                throw new Exception(""absolute path expected: "" + targetPath + "", pos: "" + pos);
                            }
                            String parentPath = PathUtils.getParentPath(targetPath);
                            String propName = PathUtils.getName(targetPath);
                            cb.setProperty(parentPath, propName, value);
                        }
                        break;
                    }
                case '-':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        String targetPath = PathUtils.concat(path, subPath);
                        if (!PathUtils.isAbsolute(targetPath)) {
                            throw new Exception(""absolute path expected: "" + targetPath + "", pos: "" + pos);
                        }
                        cb.removeNode(targetPath);
                        break;
                    }
                case '^':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        t.read(':');
                        String value;
                        if (t.matches(JsopTokenizer.NULL)) {
                            value = null;
                        } else {
                            value = t.readRawValue().trim();
                        }
                        String targetPath = PathUtils.concat(path, subPath);
                        if (!PathUtils.isAbsolute(targetPath)) {
                            throw new Exception(""absolute path expected: "" + targetPath + "", pos: "" + pos);
                        }
                        String parentPath = PathUtils.getParentPath(targetPath);
                        String propName = PathUtils.getName(targetPath);
                        cb.setProperty(parentPath, propName, value);
                        break;
                    }
                case '>':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        String srcPath = PathUtils.concat(path, subPath);
                        if (!PathUtils.isAbsolute(srcPath)) {
                            throw new Exception(""absolute path expected: "" + srcPath + "", pos: "" + pos);
                        }
                        t.read(':');
                        pos = t.getLastPos();
                        String targetPath = t.readString();
                        if (!PathUtils.isAbsolute(targetPath)) {
                            targetPath = PathUtils.concat(path, targetPath);
                            if (!PathUtils.isAbsolute(targetPath)) {
                                throw new Exception(""absolute path expected: "" + targetPath + "", pos: "" + pos);
                            }
                        }
                        cb.moveNode(srcPath, targetPath);
                        break;
                    }
                case '*':
                    {
                        pos = t.getLastPos();
                        String subPath = t.readString();
                        String srcPath = PathUtils.concat(path, subPath);
                        if (!PathUtils.isAbsolute(srcPath)) {
                            throw new Exception(""absolute path expected: "" + srcPath + "", pos: "" + pos);
                        }
                        t.read(':');
                        pos = t.getLastPos();
                        String targetPath = t.readString();
                        if (!PathUtils.isAbsolute(targetPath)) {
                            targetPath = PathUtils.concat(path, targetPath);
                            if (!PathUtils.isAbsolute(targetPath)) {
                                throw new Exception(""absolute path expected: "" + targetPath + "", pos: "" + pos);
                            }
                        }
                        cb.copyNode(srcPath, targetPath);
                        break;
                    }
                default:
                    throw new AssertionError(""token type: "" + t.getTokenType());
            }
        }
        Id newHead = cb.doCommit();
        if (!newHead.equals(revisionId)) {
            // non-empty commit
            gate.commit(newHead.toString());
        }
        return newHead.toString();
    } catch (Exception e) {
        throw new MicroKernelException(e);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/core/MicroKernelImpl.java,640,657,"static void addNode(LinkedList<AddNodeOperation> list, String path, String name, JsopTokenizer t) throws Exception {
    AddNodeOperation op = new AddNodeOperation();
    op.path = path;
    op.name = name;
    list.add(op);
    if (!t.matches('}')) {
        do {
            String key = t.readString();
            t.read(':');
            if (t.matches('{')) {
                addNode(list, PathUtils.concat(path, name), key, t);
            } else {
                op.props.put(key, t.readRawValue().trim());
            }
        } while (t.matches(','));
        t.read('}');
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/AbstractCommit.java,64,69,"public void serialize(Binding binding) throws Exception {
    binding.write(""rootNodeId"", rootNodeId.getBytes());
    binding.write(""commitTS"", commitTS);
    binding.write(""msg"", msg == null ? """" : msg);
    binding.write(""parentId"", parentId == null ? """" : parentId.toString());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,53,55,"public void addNode(String parentNodePath, String nodeName) throws Exception {
    addNode(parentNodePath, nodeName, Collections.<String, String>emptyMap());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,57,71,"public void addNode(String parentNodePath, String nodeName, Map<String, String> properties) throws Exception {
    MutableNode modParent = getOrCreateStagedNode(parentNodePath);
    if (modParent.getChildNodeEntry(nodeName) != null) {
        throw new Exception(""there's already a child node with name '"" + nodeName + ""'"");
    }
    String newPath = PathUtils.concat(parentNodePath, nodeName);
    MutableNode newChild = new MutableNode(store, newPath);
    newChild.getProperties().putAll(properties);
    // id will be computed on commit
    modParent.add(new ChildNode(nodeName, null));
    staged.put(newPath, newChild);
    // update change log
    changeLog.add(new AddNode(parentNodePath, nodeName, properties));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,73,87,"public void removeNode(String nodePath) throws NotFoundException, Exception {
    String parentPath = PathUtils.getParentPath(nodePath);
    String nodeName = PathUtils.getName(nodePath);
    MutableNode parent = getOrCreateStagedNode(parentPath);
    if (parent.remove(nodeName) == null) {
        throw new NotFoundException(nodePath);
    }
    // update staging area
    removeStagedNodes(nodePath);
    // update change log
    changeLog.add(new RemoveNode(nodePath));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,89,126,"public void moveNode(String srcPath, String destPath) throws NotFoundException, Exception {
    if (PathUtils.isAncestor(srcPath, destPath)) {
        throw new Exception(""target path cannot be descendant of source path: "" + destPath);
    }
    String srcParentPath = PathUtils.getParentPath(srcPath);
    String srcNodeName = PathUtils.getName(srcPath);
    String destParentPath = PathUtils.getParentPath(destPath);
    String destNodeName = PathUtils.getName(destPath);
    MutableNode srcParent = getOrCreateStagedNode(srcParentPath);
    if (srcParentPath.equals(destParentPath)) {
        if (srcParent.getChildNodeEntry(destNodeName) != null) {
            throw new Exception(""node already exists at move destination path: "" + destPath);
        }
        if (srcParent.rename(srcNodeName, destNodeName) == null) {
            throw new NotFoundException(srcPath);
        }
    } else {
        ChildNode srcCNE = srcParent.remove(srcNodeName);
        if (srcCNE == null) {
            throw new NotFoundException(srcPath);
        }
        MutableNode destParent = getOrCreateStagedNode(destParentPath);
        if (destParent.getChildNodeEntry(destNodeName) != null) {
            throw new Exception(""node already exists at move destination path: "" + destPath);
        }
        destParent.add(new ChildNode(destNodeName, srcCNE.getId()));
    }
    // update staging area
    moveStagedNodes(srcPath, destPath);
    // update change log
    changeLog.add(new MoveNode(srcPath, destPath));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,128,153,"public void copyNode(String srcPath, String destPath) throws NotFoundException, Exception {
    String srcParentPath = PathUtils.getParentPath(srcPath);
    String srcNodeName = PathUtils.getName(srcPath);
    String destParentPath = PathUtils.getParentPath(destPath);
    String destNodeName = PathUtils.getName(destPath);
    MutableNode srcParent = getOrCreateStagedNode(srcParentPath);
    ChildNode srcCNE = srcParent.getChildNodeEntry(srcNodeName);
    if (srcCNE == null) {
        throw new NotFoundException(srcPath);
    }
    MutableNode destParent = getOrCreateStagedNode(destParentPath);
    destParent.add(new ChildNode(destNodeName, srcCNE.getId()));
    if (srcCNE.getId() == null) {
        // a 'new' node is being copied
        // update staging area
        copyStagedNodes(srcPath, destPath);
    }
    // update change log
    changeLog.add(new CopyNode(srcPath, destPath));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,155,167,"public void setProperty(String nodePath, String propName, String propValue) throws Exception {
    MutableNode node = getOrCreateStagedNode(nodePath);
    Map<String, String> properties = node.getProperties();
    if (propValue == null) {
        properties.remove(propName);
    } else {
        properties.put(propName, propValue);
    }
    // update change log
    changeLog.add(new SetProperty(nodePath, propName, propValue));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,169,177,"public void setProperties(String nodePath, Map<String, String> properties) throws Exception {
    MutableNode node = getOrCreateStagedNode(nodePath);
    node.getProperties().clear();
    node.getProperties().putAll(properties);
    // update change log
    changeLog.add(new SetProperties(nodePath, properties));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,179,236,"public Id doCommit() throws Exception {
    if (staged.isEmpty()) {
        // nothing to commit
        return baseRevId;
    }
    Id currentHead = store.getHeadCommitId();
    if (!currentHead.equals(baseRevId)) {
        // todo gracefully handle certain conflicts (e.g. changes on moved sub-trees, competing deletes etc)
        // update base revision to new head
        baseRevId = currentHead;
        // clear staging area
        staged.clear();
        // replay change log on new base revision
        // copy log in order to avoid concurrent modifications
        List<Change> log = new ArrayList<Change>(changeLog);
        for (Change change : log) {
            change.apply();
        }
    }
    Id rootNodeId = persistStagedNodes();
    Id newRevId;
    store.lockHead();
    try {
        currentHead = store.getHeadCommitId();
        if (!currentHead.equals(baseRevId)) {
            StoredNode baseRoot = store.getRootNode(baseRevId);
            StoredNode theirRoot = store.getRootNode(currentHead);
            StoredNode ourRoot = store.getNode(rootNodeId);
            rootNodeId = mergeTree(baseRoot, ourRoot, theirRoot);
            baseRevId = currentHead;
        }
        if (store.getCommit(currentHead).getRootNodeId().equals(rootNodeId)) {
            // no need to create new commit object/update head revision
            return currentHead;
        }
        MutableCommit newCommit = new MutableCommit();
        newCommit.setParentId(baseRevId);
        newCommit.setCommitTS(System.currentTimeMillis());
        newCommit.setMsg(msg);
        newCommit.setRootNodeId(rootNodeId);
        newRevId = store.putHeadCommit(newCommit);
    } finally {
        store.unlockHead();
    }
    // reset instance in order to be reusable
    staged.clear();
    changeLog.clear();
    return newRevId;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,436,438,"void apply() throws Exception {
    addNode(parentNodePath, nodeName, properties);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,448,450,"void apply() throws Exception {
    removeNode(nodePath);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,462,464,"void apply() throws Exception {
    moveNode(srcPath, destPath);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,476,478,"void apply() throws Exception {
    copyNode(srcPath, destPath);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,492,494,"void apply() throws Exception {
    setProperty(nodePath, propName, propValue);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/CommitBuilder.java,506,508,"void apply() throws Exception {
    setProperties(nodePath, properties);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-43_668f08f2,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/StoredCommit.java,28,35,"public static StoredCommit deserialize(Id id, Binding binding) throws Exception {
    Id rootNodeId = new Id(binding.readBytesValue(""rootNodeId""));
    long commitTS = binding.readLongValue(""commitTS"");
    String msg = binding.readStringValue(""msg"");
    String parentId = binding.readStringValue(""parentId"");
    return new StoredCommit(id, """".equals(parentId) ? null : Id.fromString(parentId), commitTS, rootNodeId, """".equals(msg) ? null : msg);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4420_d645112f,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositorySidegrade.java,258,262,"private void removeCheckpointReferences(NodeBuilder builder) throws CommitFailedException {
    // removing references to the checkpoints,
    // which don't exist in the new repository
    builder.setChildNode("":async"");
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4420_d645112f,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/RepositorySidegrade.java,264,282,"private void copyState(NodeState sourceRoot, NodeBuilder targetRoot) throws CommitFailedException {
    copyWorkspace(sourceRoot, targetRoot);
    removeCheckpointReferences(targetRoot);
    if (!versionCopyConfiguration.skipOrphanedVersionsCopy()) {
        copyVersionStorage(sourceRoot, targetRoot, versionCopyConfiguration);
    }
    final List<CommitHook> hooks = new ArrayList<CommitHook>();
    hooks.add(new EditorHook(new VersionableEditor.Provider(sourceRoot, Oak.DEFAULT_WORKSPACE_NAME, versionCopyConfiguration)));
    if (customCommitHooks != null) {
        hooks.addAll(customCommitHooks);
    }
    markIndexesToBeRebuilt(targetRoot);
    target.merge(targetRoot, new LoggingCompositeHook(hooks, null, false), CommitInfo.EMPTY);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4420_d645112f,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/cli/node/SegmentFactory.java,45,55,"@Override
public NodeStore create(BlobStore blobStore, Closer closer) throws IOException {
    Builder builder = FileStore.builder(new File(dir, ""segmentstore""));
    if (blobStore != null) {
        builder.withBlobStore(blobStore);
    }
    builder.withMaxFileSize(256).withMemoryMapping(mmap);
    FileStore fs = builder.build();
    closer.register(asCloseable(fs));
    return SegmentNodeStore.builder(fs).build();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4420_d645112f,Major,oak-upgrade/src/main/java/org/apache/jackrabbit/oak/upgrade/cli/node/SegmentTarFactory.java,46,56,"@Override
public NodeStore create(BlobStore blobStore, Closer closer) throws IOException {
    FileStoreBuilder builder = fileStoreBuilder(new File(dir, ""segmentstore""));
    if (blobStore != null) {
        builder.withBlobStore(blobStore);
    }
    builder.withMaxFileSize(256).withMemoryMapping(mmap);
    FileStore fs = builder.build();
    closer.register(asCloseable(fs));
    return SegmentNodeStoreBuilders.builder(fs).build();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4423_08f0b280,Minor,oak-segment-tar/src/main/java/org/apache/jackrabbit/oak/segment/SegmentNodeStore.java,387,423,"@Override
public Boolean call() {
    long now = System.currentTimeMillis();
    refreshHead();
    SegmentNodeState state = head.get();
    SegmentNodeBuilder builder = state.builder();
    NodeBuilder checkpoints = builder.child(""checkpoints"");
    for (String n : checkpoints.getChildNodeNames()) {
        NodeBuilder cp = checkpoints.getChildNode(n);
        PropertyState ts = cp.getProperty(""timestamp"");
        if (ts == null || ts.getType() != LONG || now > ts.getValue(LONG)) {
            cp.remove();
        }
    }
    NodeBuilder cp = checkpoints.child(name);
    cp.setProperty(""timestamp"", now + lifetime);
    cp.setProperty(""created"", now);
    NodeBuilder props = cp.setChildNode(""properties"");
    for (Entry<String, String> p : properties.entrySet()) {
        props.setProperty(p.getKey(), p.getValue());
    }
    cp.setChildNode(ROOT, state.getChildNode(ROOT));
    SegmentNodeState newState = builder.getNodeState();
    if (revisions.setHead(state.getRecordId(), newState.getRecordId())) {
        refreshHead();
        return true;
    } else {
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4423_275eca83,Minor,oak-segment/src/main/java/org/apache/jackrabbit/oak/plugins/segment/SegmentNodeStore.java,399,435,"@Override
public Boolean call() {
    long now = System.currentTimeMillis();
    refreshHead();
    SegmentNodeState state = head.get();
    SegmentNodeBuilder builder = state.builder();
    NodeBuilder checkpoints = builder.child(""checkpoints"");
    for (String n : checkpoints.getChildNodeNames()) {
        NodeBuilder cp = checkpoints.getChildNode(n);
        PropertyState ts = cp.getProperty(""timestamp"");
        if (ts == null || ts.getType() != LONG || now > ts.getValue(LONG)) {
            cp.remove();
        }
    }
    NodeBuilder cp = checkpoints.child(name);
    cp.setProperty(""timestamp"", now + lifetime);
    cp.setProperty(""created"", now);
    NodeBuilder props = cp.setChildNode(""properties"");
    for (Entry<String, String> p : properties.entrySet()) {
        props.setProperty(p.getKey(), p.getValue());
    }
    cp.setChildNode(ROOT, state.getChildNode(ROOT));
    SegmentNodeState newState = builder.getNodeState();
    if (store.setHead(state, newState)) {
        refreshHead();
        return true;
    } else {
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4431_7441a3d5,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,137,141,"public Directory wrapForRead(String indexPath, IndexDefinition definition, Directory remote) throws IOException {
    Directory local = createLocalDirForIndexReader(indexPath, definition);
    return new CopyOnReadDirectory(remote, local, prefetchEnabled, indexPath, getSharedWorkingSet(definition));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4431_7441a3d5,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,143,147,"public Directory wrapForWrite(IndexDefinition definition, Directory remote, boolean reindexMode) throws IOException {
    Directory local = createLocalDirForIndexWriter(definition);
    return new CopyOnWriteDirectory(remote, local, reindexMode, getIndexPathForLogging(definition), getSharedWorkingSet(definition));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4431_7441a3d5,Major,oak-lucene/src/main/java/org/apache/jackrabbit/oak/plugins/index/lucene/IndexCopier.java,241,253,"/**
 * Provide the corresponding shared state to enable COW inform COR
 * about new files it is creating while indexing. This would allow COR to ignore
 * such files while determining the deletion candidates.
 *
 * @param defn index definition for which the directory is being created
 * @return a set to maintain the state of new files being created by the COW Directory
 */
private Set<String> getSharedWorkingSet(IndexDefinition defn) {
    String indexPath = defn.getIndexPathFromConfig();
    Set<String> sharedSet;
    synchronized (sharedWorkingSetMap) {
        sharedSet = sharedWorkingSetMap.get(indexPath);
        if (sharedSet == null) {
            sharedSet = Sets.newConcurrentHashSet();
            sharedWorkingSetMap.put(indexPath, sharedSet);
        }
    }
    return sharedSet;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4432_c9765c21,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/blob/datastore/OakFileDataStore.java,68,84,"@Override
public Iterator<DataIdentifier> getAllIdentifiers() {
    final String path = FilenameUtils.normalizeNoEndSeparator(getPath());
    return Files.fileTreeTraverser().postOrderTraversal(new File(getPath())).filter(new Predicate<File>() {

        @Override
        public boolean apply(File input) {
            return input.isFile() && !input.getParent().equals(path);
        }
    }).transform(new Function<File, DataIdentifier>() {

        @Override
        public DataIdentifier apply(File input) {
            return new DataIdentifier(input.getName());
        }
    }).iterator();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-4432_c9765c21,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/blob/datastore/OakFileDataStore.java,73,76,"@Override
public boolean apply(File input) {
    return input.isFile() && !input.getParent().equals(path);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-447_00df38d2,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,420,451,"@Override
public NodeBuilder child(String name) {
    // shortcut when dealing with a read-only child node
    read();
    if (baseState != null && baseState.hasChildNode(name) && (writeState == null || !writeState.nodes.containsKey(name))) {
        return createChildBuilder(name);
    }
    // no read-only child node found, switch to write mode
    write();
    // guaranteed by write()
    assert writeState != null;
    NodeState childBase = null;
    if (baseState != null) {
        childBase = baseState.getChildNode(name);
    }
    if (writeState.nodes.get(name) == null) {
        if (writeState.nodes.containsKey(name)) {
            // The child node was removed earlier and we're creating
            // a new child with the same name. Use the null state to
            // prevent the previous child state from re-surfacing.
            childBase = null;
        }
        writeState.nodes.put(name, new MutableNodeState(childBase));
    }
    MemoryNodeBuilder builder = createChildBuilder(name);
    builder.write();
    return builder;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-448_999097e1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,269,295,"@Override
public boolean isModified() {
    if (writeState == null) {
        return false;
    } else {
        NodeState baseState = getBaseState();
        for (Entry<String, MutableNodeState> n : writeState.nodes.entrySet()) {
            if (n.getValue() == null) {
                return true;
            }
            if (baseState == null || !baseState.hasChildNode(n.getKey())) {
                return true;
            }
        }
        for (Entry<String, PropertyState> p : writeState.properties.entrySet()) {
            PropertyState pState = p.getValue();
            if (pState == null) {
                return true;
            }
            if (baseState == null || !pState.equals(baseState.getProperty(p.getKey()))) {
                return true;
            }
        }
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-448_999097e1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,309,312,"@Override
public NodeState getBaseState() {
    return baseState;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-478_a7f0e808,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/commit/ValidatingHook.java,152,155,"@Override
public void childNodeAdded(String name, NodeState after) {
    childNodeChanged(name, EMPTY_NODE, after);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-478_a7f0e808,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/spi/commit/ValidatingHook.java,176,179,"@Override
public void childNodeDeleted(String name, NodeState before) {
    childNodeChanged(name, before, EMPTY_NODE);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-479_3270e761,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/ItemImpl.java,171,174,"void checkProtected() throws RepositoryException {
    ItemDefinition definition = (isNode()) ? ((Node) this).getDefinition() : ((Property) this).getDefinition();
    checkProtected(definition);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-47_b62f1c26,Major,oak-core/src/main/java/org/apache/jackrabbit/mk/index/Indexer.java,305,373,"/**
 * Update the index with the given changes.
 *
 * @param t the changes
 * @param lastRevision
 */
public void updateIndex(String rootPath, JsopReader t, String lastRevision) {
    while (true) {
        int r = t.read();
        if (r == JsopTokenizer.END) {
            break;
        }
        String path = PathUtils.concat(rootPath, t.readString());
        switch(r) {
            case '+':
                {
                    t.read(':');
                    NodeMap map = new NodeMap();
                    if (t.matches('{')) {
                        NodeImpl n = NodeImpl.parse(map, t, 0, path);
                        addOrRemoveRecursive(n, false, true);
                    } else {
                        String value = t.readRawValue().trim();
                        String nodePath = PathUtils.getParentPath(path);
                        NodeImpl node = new NodeImpl(map, 0);
                        node.setPath(nodePath);
                        String propertyName = PathUtils.getName(path);
                        node.cloneAndSetProperty(propertyName, value, 0);
                        addOrRemoveRecursive(node, true, true);
                    }
                    break;
                }
            case '-':
                moveNode(path, null, lastRevision);
                break;
            case '^':
                {
                    removeProperty(path, lastRevision);
                    t.read(':');
                    if (t.matches(JsopTokenizer.NULL)) {
                    // ignore
                    } else {
                        String value = t.readRawValue().trim();
                        addProperty(path, value);
                    }
                    break;
                }
            case '>':
                t.read(':');
                String name = PathUtils.getName(path);
                String target, position;
                if (t.matches('{')) {
                    position = t.readString();
                    t.read(':');
                    target = t.readString();
                    t.read('}');
                } else {
                    position = null;
                    target = t.readString();
                }
                if (""last"".equals(position) || ""first"".equals(position)) {
                    target = PathUtils.concat(target, name);
                } else if (""before"".equals(position) || ""after"".equals(position)) {
                    target = PathUtils.getParentPath(target);
                    target = PathUtils.concat(target, name);
                } else if (position == null) {
                // move
                } else {
                    throw ExceptionFactory.get(""position: "" + position);
                }
                moveNode(path, target, lastRevision);
                break;
            default:
                throw new AssertionError(""token: "" + (char) t.getTokenType());
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-47_b62f1c26,Major,oak-core/src/main/java/org/apache/jackrabbit/mk/index/Indexer.java,433,455,"private void moveNode(String sourcePath, String targetPath, String lastRevision) {
    if (isInIndex(sourcePath)) {
        // don't index the index
        return;
    }
    if (!mk.nodeExists(sourcePath, lastRevision)) {
        return;
    }
    // TODO move: support large trees
    String node = mk.getNodes(sourcePath, lastRevision, Integer.MAX_VALUE, 0, Integer.MAX_VALUE, null);
    JsopTokenizer t = new JsopTokenizer(node);
    NodeMap map = new NodeMap();
    t.read('{');
    NodeImpl n = NodeImpl.parse(map, t, 0, sourcePath);
    addOrRemoveRecursive(n, true, false);
    if (targetPath != null) {
        t = new JsopTokenizer(node);
        map = new NodeMap();
        t.read('{');
        n = NodeImpl.parse(map, t, 0, targetPath);
        addOrRemoveRecursive(n, false, true);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-47_b62f1c26,Major,oak-core/src/main/java/org/apache/jackrabbit/mk/simple/SimpleKernelImpl.java,143,327,"private String doCommit(String rootPath, JsopReader t, String revisionId, String message) {
    long oldRevision = headRevId, rev = headRevId + 1;
    NodeImpl root = nodeMap.getRootId().getNode(nodeMap);
    NodeImpl head = root.getNode(""head""), oldHead = head;
    NodeImpl data = head.getNode(""data"");
    JsopWriter diff = new JsopStream();
    while (true) {
        int r = t.read();
        if (r == JsopTokenizer.END) {
            break;
        }
        String path = PathUtils.concat(rootPath, t.readString());
        String from = PathUtils.relativize(""/"", path);
        switch(r) {
            case '+':
                t.read(':');
                diff.tag('+').key(path);
                if (t.matches('{')) {
                    NodeImpl n = NodeImpl.parse(nodeMap, t, rev);
                    data = data.cloneAndAddChildNode(from, false, null, n, rev);
                    n.append(diff, Integer.MAX_VALUE, 0, Integer.MAX_VALUE, false);
                } else {
                    String value = t.readRawValue().trim();
                    String nodeName = PathUtils.getParentPath(from);
                    String propertyName = PathUtils.getName(from);
                    if (data.getNode(nodeName).hasProperty(propertyName)) {
                        throw ExceptionFactory.get(""Property already exists: "" + propertyName);
                    }
                    data = data.cloneAndSetProperty(from, value, rev);
                    diff.encodedValue(value);
                }
                diff.newline();
                break;
            case '-':
                diff.tag('-').value(path).newline();
                if (data.exists(from) || !getRevisionDataRoot(revisionId).exists(from)) {
                    // this will fail if the node didn't exist
                    data = data.cloneAndRemoveChildNode(from, rev);
                }
                break;
            case '^':
                t.read(':');
                boolean isConfigChange = from.startsWith("":root/head/config/"");
                String value;
                if (t.matches(JsopTokenizer.NULL)) {
                    value = null;
                    diff.tag('^').key(path).value(null);
                } else {
                    value = t.readRawValue().trim();
                    String nodeName = PathUtils.getParentPath(from);
                    String propertyName = PathUtils.getName(from);
                    if (isConfigChange || data.getNode(nodeName).hasProperty(propertyName)) {
                        diff.tag('^');
                    } else {
                        diff.tag('+');
                    }
                    diff.key(path).encodedValue(value);
                }
                if (isConfigChange) {
                    String p = PathUtils.relativize("":root/head"", from);
                    if (!head.exists(""config"")) {
                        head = head.setChild(""config"", new NodeImpl(nodeMap, rev), rev);
                    }
                    head = head.cloneAndSetProperty(p, value, rev);
                    applyConfig(head);
                } else {
                    data = data.cloneAndSetProperty(from, value, rev);
                }
                diff.newline();
                break;
            case '>':
                {
                    t.read(':');
                    diff.tag('>').key(path);
                    String name = PathUtils.getName(from);
                    String position, target, to;
                    boolean rename;
                    if (t.matches('{')) {
                        rename = false;
                        position = t.readString();
                        t.read(':');
                        target = t.readString();
                        t.read('}');
                        diff.object().key(position);
                        if (!PathUtils.isAbsolute(target)) {
                            target = PathUtils.concat(rootPath, target);
                        }
                        diff.value(target).endObject();
                    } else {
                        rename = true;
                        position = null;
                        target = t.readString();
                        if (!PathUtils.isAbsolute(target)) {
                            target = PathUtils.concat(rootPath, target);
                        }
                        diff.value(target);
                    }
                    diff.newline();
                    boolean before = false;
                    if (""last"".equals(position)) {
                        target = PathUtils.concat(target, name);
                        position = null;
                    } else if (""first"".equals(position)) {
                        target = PathUtils.concat(target, name);
                        position = null;
                        before = true;
                    } else if (""before"".equals(position)) {
                        position = PathUtils.getName(target);
                        target = PathUtils.getParentPath(target);
                        target = PathUtils.concat(target, name);
                        before = true;
                    } else if (""after"".equals(position)) {
                        position = PathUtils.getName(target);
                        target = PathUtils.getParentPath(target);
                        target = PathUtils.concat(target, name);
                    } else if (position == null) {
                    // move
                    } else {
                        throw ExceptionFactory.get(""position: "" + position);
                    }
                    to = PathUtils.relativize(""/"", target);
                    boolean inPlaceRename = false;
                    if (rename) {
                        if (PathUtils.getParentPath(from).equals(PathUtils.getParentPath(to))) {
                            inPlaceRename = true;
                            position = PathUtils.getName(from);
                        }
                    }
                    NodeImpl node = data.getNode(from);
                    if (!inPlaceRename) {
                        data = data.cloneAndRemoveChildNode(from, rev);
                    }
                    data = data.cloneAndAddChildNode(to, before, position, node, rev);
                    if (inPlaceRename) {
                        data = data.cloneAndRemoveChildNode(from, rev);
                    }
                    break;
                }
            case '*':
                {
                    // TODO is it really required?
                    // TODO possibly support target position notation
                    // TODO support copy in wrappers, index,...
                    t.read(':');
                    String target = t.readString();
                    diff.tag('*').key(path).value(target);
                    if (!PathUtils.isAbsolute(target)) {
                        target = PathUtils.concat(rootPath, target);
                    }
                    NodeImpl node = data.getNode(from);
                    String to = PathUtils.relativize(""/"", target);
                    data = data.cloneAndAddChildNode(to, false, null, node, rev);
                    break;
                }
            default:
                throw ExceptionFactory.get(""token: "" + (char) t.getTokenType());
        }
    }
    head = head.setChild(""data"", data, rev);
    Revision revNode = new Revision(rev, clock.nanoTime(), diff.toString(), message);
    revisionCache.put(rev, revNode);
    head = revNode.store(head, new NodeImpl(nodeMap, rev));
    root = root.setChild(""head"", head, rev);
    String old = Revision.formatId(oldRevision);
    NodeImpl oldRev = new NodeImpl(nodeMap, rev);
    oldRev.addChildNode(""head"", oldHead);
    String lastRev = Revision.formatId(oldRevision - 1);
    if (root.exists(lastRev)) {
        NodeImpl lastRevNode = root.getNode(lastRev);
        root = root.cloneAndRemoveChildNode(lastRev, rev);
        oldRev.setChild(lastRev, lastRevNode, rev);
        if (oldRevision % REV_SKIP_OFFSET == 0) {
            long skip = oldRevision - REV_SKIP_OFFSET;
            NodeImpl n = getRevisionNode(getRoot(), skip, skip);
            if (n != null) {
                oldRev.setChild(Revision.formatId(skip), n, rev);
            // TODO remove old link to reduce descendant count
            }
        }
    }
    root = root.setChild(old, oldRev, rev);
    nodeMap.commit(root);
    headRevId = rev;
    headRevision = Revision.formatId(rev);
    gate.commit(headRevision);
    return headRevision;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-47_b62f1c26,Major,oak-core/src/main/java/org/apache/jackrabbit/mk/simple/SimpleKernelImpl.java,558,560,"public String toString() {
    return ""simple:"" + name;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-498_f2a2edec,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/JcrPathParser.java,262,297,"public static boolean validate(String jcrPath) {
    Listener listener = new Listener() {

        boolean hasRoot;

        @Override
        public boolean root() {
            if (hasRoot) {
                return false;
            } else {
                hasRoot = true;
                return true;
            }
        }

        @Override
        public boolean current() {
            return true;
        }

        @Override
        public boolean parent() {
            return true;
        }

        @Override
        public void error(String message) {
        }

        @Override
        public boolean name(String name, int index) {
            return true;
        }
    };
    return parse(jcrPath, listener);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-498_f2a2edec,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/JcrPathParser.java,281,284,"@Override
public boolean parent() {
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-498_f2a2edec,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/JcrPathParser.java,290,293,"@Override
public boolean name(String name, int index) {
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-498_f2a2edec,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/NamePathMapperImpl.java,78,151,"@Override
@Nonnull
public String getJcrPath(String oakPath) {
    final List<String> elements = new ArrayList<String>();
    if (""/"".equals(oakPath)) {
        // avoid the need to special case the root path later on
        return ""/"";
    }
    JcrPathParser.Listener listener = new JcrPathParser.Listener() {

        @Override
        public boolean root() {
            if (!elements.isEmpty()) {
                throw new IllegalArgumentException(""/ on non-empty path"");
            }
            elements.add("""");
            return true;
        }

        @Override
        public boolean current() {
            // nothing to do here
            return false;
        }

        @Override
        public boolean parent() {
            if (elements.isEmpty() || "".."".equals(elements.get(elements.size() - 1))) {
                elements.add("".."");
                return true;
            }
            elements.remove(elements.size() - 1);
            return true;
        }

        @Override
        public void error(String message) {
            throw new IllegalArgumentException(message);
        }

        @Override
        public boolean name(String name, int index) {
            if (index > 1) {
                throw new IllegalArgumentException(""index > 1"");
            }
            String p = nameMapper.getJcrName(name);
            elements.add(p);
            return true;
        }
    };
    JcrPathParser.parse(oakPath, listener);
    // empty path: map to "".""
    if (elements.isEmpty()) {
        return ""."";
    }
    StringBuilder jcrPath = new StringBuilder();
    for (String element : elements) {
        if (element.isEmpty()) {
            // root
            jcrPath.append('/');
        } else {
            jcrPath.append(element);
            jcrPath.append('/');
        }
    }
    jcrPath.deleteCharAt(jcrPath.length() - 1);
    return jcrPath.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-498_f2a2edec,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/NamePathMapperImpl.java,104,112,"@Override
public boolean parent() {
    if (elements.isEmpty() || "".."".equals(elements.get(elements.size() - 1))) {
        elements.add("".."");
        return true;
    }
    elements.remove(elements.size() - 1);
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-498_f2a2edec,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/NamePathMapperImpl.java,153,299,"private String getOakPath(String jcrPath, final boolean keepIndex) {
    if (""/"".equals(jcrPath)) {
        // avoid the need to special case the root path later on
        return ""/"";
    }
    int length = jcrPath.length();
    // identifier path?
    if (length > 0 && jcrPath.charAt(0) == '[') {
        if (jcrPath.charAt(length - 1) != ']') {
            // TODO error handling?
            log.debug(""Could not parse path "" + jcrPath + "": unterminated identifier"");
            return null;
        }
        if (this.idManager == null) {
            // TODO error handling?
            log.debug(""Could not parse path "" + jcrPath + "": could not resolve identifier"");
            return null;
        }
        return this.idManager.getPath(jcrPath.substring(1, length - 1));
    }
    boolean hasClarkBrackets = false;
    boolean hasIndexBrackets = false;
    boolean hasColon = false;
    boolean hasNameStartingWithDot = false;
    boolean hasTrailingSlash = false;
    char prev = 0;
    for (int i = 0; i < length; i++) {
        char c = jcrPath.charAt(i);
        if (c == '{' || c == '}') {
            hasClarkBrackets = true;
        } else if (c == '[' || c == ']') {
            hasIndexBrackets = true;
        } else if (c == ':') {
            hasColon = true;
        } else if (c == '.' && (prev == 0 || prev == '/')) {
            hasNameStartingWithDot = true;
        } else if (c == '/' && i == (length - 1)) {
            hasTrailingSlash = true;
        }
        prev = c;
    }
    // try a shortcut
    if (!hasNameStartingWithDot && !hasClarkBrackets && !hasIndexBrackets) {
        if (!hasColon || !hasSessionLocalMappings()) {
            if (JcrPathParser.validate(jcrPath)) {
                if (hasTrailingSlash) {
                    return jcrPath.substring(0, length - 1);
                }
                return jcrPath;
            } else {
                log.debug(""Invalid path: {}"", jcrPath);
                return null;
            }
        }
    }
    final List<String> elements = new ArrayList<String>();
    final StringBuilder parseErrors = new StringBuilder();
    JcrPathParser.Listener listener = new JcrPathParser.Listener() {

        @Override
        public boolean root() {
            if (!elements.isEmpty()) {
                parseErrors.append(""/ on non-empty path"");
                return false;
            }
            elements.add("""");
            return true;
        }

        @Override
        public boolean current() {
            // nothing to do here
            return true;
        }

        @Override
        public boolean parent() {
            if (elements.isEmpty() || "".."".equals(elements.get(elements.size() - 1))) {
                elements.add("".."");
                return true;
            }
            elements.remove(elements.size() - 1);
            return true;
        }

        @Override
        public void error(String message) {
            parseErrors.append(message);
        }

        @Override
        public boolean name(String name, int index) {
            if (!keepIndex && index > 1) {
                parseErrors.append(""index > 1"");
                return false;
            }
            String p = nameMapper.getOakName(name);
            if (p == null) {
                parseErrors.append(""Invalid name: "").append(name);
                return false;
            }
            if (keepIndex && index > 0) {
                p += ""["" + index + ']';
            }
            elements.add(p);
            return true;
        }
    };
    JcrPathParser.parse(jcrPath, listener);
    if (parseErrors.length() != 0) {
        log.debug(""Could not parse path "" + jcrPath + "": "" + parseErrors.toString());
        return null;
    }
    // Empty path maps to """"
    if (elements.isEmpty()) {
        return """";
    }
    StringBuilder oakPath = new StringBuilder();
    for (String element : elements) {
        if (element.isEmpty()) {
            // root
            oakPath.append('/');
        } else {
            oakPath.append(element);
            oakPath.append('/');
        }
    }
    // root path is special-cased early on so it does not need to
    // be considered here
    oakPath.deleteCharAt(oakPath.length() - 1);
    return oakPath.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-498_f2a2edec,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/NamePathMapperImpl.java,238,246,"@Override
public boolean parent() {
    if (elements.isEmpty() || "".."".equals(elements.get(elements.size() - 1))) {
        elements.add("".."");
        return true;
    }
    elements.remove(elements.size() - 1);
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-499_61381ea2,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/SQL2Parser.java,525,603,"private StaticOperandImpl parseStaticOperand() throws ParseException {
    if (currentTokenType == PLUS) {
        read();
    } else if (currentTokenType == MINUS) {
        read();
        if (currentTokenType != VALUE) {
            throw getSyntaxError(""number"");
        }
        int valueType = currentValue.getType().tag();
        switch(valueType) {
            case PropertyType.LONG:
                currentValue = PropertyValues.newLong(-currentValue.getValue(Type.LONG));
                break;
            case PropertyType.DOUBLE:
                currentValue = PropertyValues.newDouble(-currentValue.getValue(Type.DOUBLE));
                break;
            case PropertyType.BOOLEAN:
                currentValue = PropertyValues.newBoolean(!currentValue.getValue(Type.BOOLEAN));
                break;
            case PropertyType.DECIMAL:
                currentValue = PropertyValues.newDecimal(currentValue.getValue(Type.DECIMAL).negate());
                break;
            default:
                throw getSyntaxError(""Illegal operation: -"" + currentValue);
        }
    }
    if (currentTokenType == VALUE) {
        LiteralImpl literal = getUncastLiteral(currentValue);
        read();
        return literal;
    } else if (currentTokenType == PARAMETER) {
        read();
        String name = readName();
        if (readIf("":"")) {
            name = name + ':' + readName();
        }
        BindVariableValueImpl var = bindVariables.get(name);
        if (var == null) {
            var = factory.bindVariable(name);
            bindVariables.put(name, var);
        }
        return var;
    } else if (readIf(""TRUE"")) {
        LiteralImpl literal = getUncastLiteral(PropertyValues.newBoolean(true));
        return literal;
    } else if (readIf(""FALSE"")) {
        LiteralImpl literal = getUncastLiteral(PropertyValues.newBoolean(false));
        return literal;
    } else if (readIf(""CAST"")) {
        read(""("");
        StaticOperandImpl op = parseStaticOperand();
        if (!(op instanceof LiteralImpl)) {
            throw getSyntaxError(""literal"");
        }
        LiteralImpl literal = (LiteralImpl) op;
        PropertyValue value = literal.getLiteralValue();
        read(""AS"");
        value = parseCastAs(value);
        read("")"");
        // CastLiteral
        literal = factory.literal(value);
        return literal;
    } else {
        if (supportSQL1) {
            if (readIf(""TIMESTAMP"")) {
                StaticOperandImpl op = parseStaticOperand();
                if (!(op instanceof LiteralImpl)) {
                    throw getSyntaxError(""literal"");
                }
                LiteralImpl literal = (LiteralImpl) op;
                PropertyValue value = literal.getLiteralValue();
                value = PropertyValues.newDate(value.getValue(Type.STRING));
                literal = factory.literal(value);
                return literal;
            }
        }
        throw getSyntaxError(""static operand"");
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-499_61381ea2,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/SQL2Parser.java,886,1016,"private void read() throws ParseException {
    currentTokenQuoted = false;
    if (expected != null) {
        expected.clear();
    }
    int[] types = characterTypes;
    int i = parseIndex;
    int type = types[i];
    while (type == 0) {
        type = types[++i];
    }
    int start = i;
    char[] chars = statementChars;
    char c = chars[i++];
    currentToken = """";
    switch(type) {
        case CHAR_NAME:
            while (true) {
                type = types[i];
                if (type != CHAR_NAME && type != CHAR_VALUE) {
                    c = chars[i];
                    if (supportSQL1 && c == ':') {
                        i++;
                        continue;
                    }
                    break;
                }
                i++;
            }
            currentToken = statement.substring(start, i);
            if (currentToken.isEmpty()) {
                throw getSyntaxError();
            }
            currentTokenType = IDENTIFIER;
            parseIndex = i;
            return;
        case CHAR_SPECIAL_2:
            if (types[i] == CHAR_SPECIAL_2) {
                i++;
            }
        // fall through
        case CHAR_SPECIAL_1:
            currentToken = statement.substring(start, i);
            switch(c) {
                case '$':
                    currentTokenType = PARAMETER;
                    break;
                case '+':
                    currentTokenType = PLUS;
                    break;
                case '-':
                    currentTokenType = MINUS;
                    break;
                case '(':
                    currentTokenType = OPEN;
                    break;
                case ')':
                    currentTokenType = CLOSE;
                    break;
                default:
                    currentTokenType = KEYWORD;
            }
            parseIndex = i;
            return;
        case CHAR_VALUE:
            long number = c - '0';
            while (true) {
                c = chars[i];
                if (c < '0' || c > '9') {
                    if (c == '.') {
                        readDecimal(start, i);
                        break;
                    }
                    if (c == 'E' || c == 'e') {
                        readDecimal(start, i);
                        break;
                    }
                    checkLiterals(false);
                    currentValue = PropertyValues.newLong(number);
                    currentTokenType = VALUE;
                    currentToken = ""0"";
                    parseIndex = i;
                    break;
                }
                number = number * 10 + (c - '0');
                if (number > Integer.MAX_VALUE) {
                    readDecimal(start, i);
                    break;
                }
                i++;
            }
            return;
        case CHAR_DECIMAL:
            if (types[i] != CHAR_VALUE) {
                currentTokenType = KEYWORD;
                currentToken = ""."";
                parseIndex = i;
                return;
            }
            readDecimal(i - 1, i);
            return;
        case CHAR_BRACKETED:
            readString(i, ']');
            currentTokenType = IDENTIFIER;
            currentToken = currentValue.getValue(Type.STRING);
            return;
        case CHAR_STRING:
            readString(i, '\'');
            return;
        case CHAR_QUOTED:
            readString(i, '\""');
            if (supportSQL1) {
                // for SQL-2, this is a literal, as defined in
                // the JCR 2.0 spec, 6.7.34 Literal - UncastLiteral
                // but for compatibility with Jackrabbit 2.x, for
                // SQL-1, this is an identifier, as in ANSI SQL
                // (not in the JCR 1.0 spec)
                // (confusing isn't it?)
                currentTokenType = IDENTIFIER;
                currentToken = currentValue.getValue(Type.STRING);
            }
            return;
        case CHAR_END:
            currentToken = """";
            currentTokenType = END;
            parseIndex = i;
            return;
        default:
            throw getSyntaxError();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-509_b896c926,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/namepath/LocalNameMapper.java,40,82,"@Override
@CheckForNull
public String getJcrName(String oakName) {
    checkNotNull(oakName);
    // hidden name
    checkArgument(!oakName.startsWith("":""));
    // expanded name
    checkArgument(isExpandedName(oakName));
    if (hasSessionLocalMappings()) {
        int colon = oakName.indexOf(':');
        if (colon > 0) {
            String oakPrefix = oakName.substring(0, colon);
            String uri = getNamespaceMap().get(oakPrefix);
            if (uri == null) {
                throw new IllegalStateException(""No namespace mapping found for "" + oakName);
            }
            Map<String, String> local = getSessionLocalMappings();
            for (Map.Entry<String, String> entry : local.entrySet()) {
                if (uri.equals(entry.getValue())) {
                    String jcrPrefix = entry.getKey();
                    if (jcrPrefix.equals(oakPrefix)) {
                        return oakName;
                    } else {
                        return jcrPrefix + oakName.substring(colon);
                    }
                }
            }
            // is no conflicting local mapping for the prefix
            if (local.containsKey(oakPrefix)) {
                for (int i = 2; true; i++) {
                    String jcrPrefix = oakPrefix + i;
                    if (!local.containsKey(jcrPrefix)) {
                        return jcrPrefix + oakName.substring(colon);
                    }
                }
            }
        }
    }
    return oakName;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-510_f63d745a,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/ItemImpl.java,424,442,"/**
 * Create a single value property state given a {@code name}, a {@code type}, a
 * {@code value} and a property {@code definition}. If the type does not match the
 * property definition it is converted accordingly
 *
 * @param name
 * @param type
 * @param values
 * @param definition
 * @return  array valued property state
 * @throws ValueFormatException  if {@code definition} does not define a multi valued property
 * @throws RepositoryException  if value conversion fails
 */
PropertyState createMultiState(String name, int type, Value[] values, PropertyDefinition definition) throws RepositoryException {
    if (!definition.isMultiple()) {
        throw new ValueFormatException(""Cannot set value array to single value property"");
    }
    Value[] nonNullValues = compact(values);
    int targetType = getType(definition, type);
    if (nonNullValues.length == 0) {
        return MemoryPropertyBuilder.array(Type.fromTag(type, false), name).getPropertyState();
    } else if (targetType == type) {
        return PropertyStates.createProperty(name, Arrays.asList(nonNullValues));
    } else {
        return PropertyStates.createProperty(name, Arrays.asList(ValueHelper.convert(values, targetType, getValueFactory())));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-520_ec961a38,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/p2/strategy/ContentMirrorStoreStrategy.java,35,79,"@Override
public void remove(NodeBuilder index, String key, Iterable<String> values) {
    if (!index.hasChildNode(key)) {
        return;
    }
    NodeBuilder child = index.child(key);
    Queue<NodeBuilder> parentQueue = new LinkedList<NodeBuilder>();
    for (String rm : values) {
        if (PathUtils.denotesRoot(rm)) {
            child.removeProperty(""match"");
        } else {
            NodeBuilder indexEntry = child;
            Iterator<String> segments = PathUtils.elements(rm).iterator();
            while (segments.hasNext()) {
                String segment = segments.next();
                if (segments.hasNext()) {
                    parentQueue.add(indexEntry);
                    indexEntry = indexEntry.child(segment);
                } else {
                    // last segment
                    if (indexEntry.hasChildNode(segment)) {
                        indexEntry.removeNode(segment);
                    }
                }
            }
        }
    }
    // finally remove the index node if empty
    if (child.getChildNodeCount() == 0) {
        index.removeNode(key);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-520_ec961a38,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/p2/strategy/ContentMirrorStoreStrategy.java,81,101,"@Override
public void insert(NodeBuilder index, String key, boolean unique, Iterable<String> values) throws CommitFailedException {
    NodeBuilder child = index.child(key);
    for (String add : values) {
        NodeBuilder indexEntry = child;
        Iterator<String> segments = PathUtils.elements(add).iterator();
        while (segments.hasNext()) {
            String segment = segments.next();
            indexEntry = indexEntry.child(segment);
        }
        indexEntry.setProperty(""match"", true);
    }
    long matchCount = countMatchingLeaves(child.getNodeState());
    if (matchCount == 0) {
        index.removeNode(key);
    } else if (unique && matchCount > 1) {
        throw new CommitFailedException(""Uniqueness constraint violated"");
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-531_90c45a02,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,197,199,"/**
 * Determine whether the named child has been removed. This is the
 * case when the write state has a corresponding {@code null} entry.
 * Assumes {@code read()}, {@code write()} needs not be called.
 * @param name  name of the child
 * @return  {@code true} iff a child with the given name has been removed
 */
private boolean removed(String name) {
    return writeState != null && writeState.isRemoved(name);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-531_90c45a02,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,201,224,"@Nonnull
private NodeState read() {
    if (revision != root.revision) {
        // root never gets here since revision == root.revision
        assert (!isRoot());
        checkState(!parent.removed(name), ""This node has already been removed"");
        parent.read();
        // The builder could have been reset, need to re-get base state
        baseState = parent.getBaseState(name);
        // ... same for the write state
        writeState = parent.getWriteState(name);
        revision = root.revision;
    }
    assert classInvariants();
    if (writeState != null) {
        return writeState;
    } else {
        return baseState;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-531_90c45a02,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,231,262,"@Nonnull
private MutableNodeState write(long newRevision, boolean skipRemovedCheck) {
    // make sure that all revision numbers up to the root gets updated
    if (!isRoot()) {
        checkState(skipRemovedCheck || !parent.removed(name));
        parent.write(newRevision, skipRemovedCheck);
    }
    if (writeState == null || revision != root.revision) {
        // root never gets here since revision == root.revision
        assert (!isRoot());
        // The builder could have been reset, need to re-get base state
        baseState = parent.getBaseState(name);
        writeState = parent.getWriteState(name);
        if (writeState == null) {
            if (parent.removed(name)) {
                writeState = new MutableNodeState(null);
            } else {
                writeState = new MutableNodeState(baseState);
            }
            // guaranteed by called parent.write()
            assert parent.writeState != null;
            parent.writeState.nodes.put(name, writeState);
        }
    }
    revision = newRevision;
    assert classInvariants();
    assert writeState != null;
    return writeState;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-537_a8493efc,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/p2/Property2IndexLookup.java,74,91,"/**
 * Checks whether the named property is indexed somewhere along the given
 * path. Lookup starts at the current path (at the root of this object) and
 * traverses down the path.
 *
 * @param name property name
 * @param path lookup path
 * @return true if the property is indexed
 */
public boolean isIndexed(String name, String path) {
    if (getIndexDefinitionNode(name) != null) {
        return true;
    }
    // TODO use PathUtils
    if (path.startsWith(""/"")) {
        path = path.substring(1);
    }
    int slash = path.indexOf('/');
    if (slash == -1) {
        return false;
    }
    NodeState child = root.getChildNode(path.substring(0, slash));
    return new Property2IndexLookup(child).isIndexed(name, path.substring(slash));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-537_a8493efc,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/p2/Property2IndexLookup.java,114,162,"/**
 * Searches for a given value within this index.
 *
 * @param name the property name
 * @param value the property value (null to check for property existence)
 * @return the set of matched paths
 */
public Set<String> find(String name, PropertyValue value) {
    Set<String> paths = Sets.newHashSet();
    NodeState state = getIndexDefinitionNode(name);
    if (state != null && state.getChildNode("":index"") != null) {
        state = state.getChildNode("":index"");
        if (value == null) {
            paths.addAll(store.find(state, null));
        } else {
            paths.addAll(store.find(state, Property2Index.encode(value)));
        }
    } else {
        // No index available, so first check this node for a match
        PropertyState property = root.getProperty(name);
        if (property != null) {
            if (value == null || value.isArray()) {
                // let query engine handle property existence and
                // multi-valued look ups;
                // simply return all nodes that have this property
                paths.add("""");
            } else {
                // does it match any of the values of this property?
                for (int i = 0; i < property.count(); i++) {
                    if (property.getValue(value.getType(), i).equals(value.getValue(value.getType()))) {
                        paths.add("""");
                        // no need to check for more matches in this property
                        break;
                    }
                }
            }
        }
        // ... and then recursively look up from the rest of the tree
        for (ChildNodeEntry entry : root.getChildNodeEntries()) {
            String base = entry.getName();
            Property2IndexLookup lookup = new Property2IndexLookup(entry.getNodeState());
            for (String path : lookup.find(name, value)) {
                if (path.isEmpty()) {
                    paths.add(base);
                } else {
                    paths.add(base + ""/"" + path);
                }
            }
        }
    }
    return paths;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-537_a8493efc,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/p2/Property2IndexLookup.java,164,180,"public double getCost(String name, PropertyValue value) {
    double cost = 0.0;
    // TODO the cost method is currently reading all the data -
    // is not supposed to do that, it is only supposed to estimate
    NodeState state = getIndexDefinitionNode(name);
    if (state != null && state.getChildNode("":index"") != null) {
        state = state.getChildNode("":index"");
        if (value == null) {
            cost += store.count(state, null);
        } else {
            cost += store.count(state, Property2Index.encode(value));
        }
    } else {
        cost = Double.POSITIVE_INFINITY;
    }
    return cost;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-537_a8493efc,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/p2/Property2IndexLookup.java,189,209,"/**
 * Get the node with the index definition node for the given property.
 *
 * @param name the property name
 * @return the node where the index definition is stored, or null if no
 *         index definition node was found
 */
@Nullable
private NodeState getIndexDefinitionNode(String name) {
    NodeState state = root.getChildNode(INDEX_DEFINITIONS_NAME);
    if (state != null) {
        for (ChildNodeEntry entry : state.getChildNodeEntries()) {
            PropertyState type = entry.getNodeState().getProperty(IndexConstants.TYPE_PROPERTY_NAME);
            if (type == null || type.isArray() || !Property2Index.TYPE.equals(type.getValue(Type.STRING))) {
                continue;
            }
            PropertyState names = entry.getNodeState().getProperty(""propertyNames"");
            if (names != null) {
                for (int i = 0; i < names.count(); i++) {
                    if (name.equals(names.getValue(Type.STRING, i))) {
                        return entry.getNodeState();
                    }
                }
            }
        }
    }
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-539_ffa818f3,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/Id.java,109,120,"@Override
public int compareTo(Id o) {
    byte[] other = o.getBytes();
    int len = Math.min(raw.length, other.length);
    for (int i = 0; i < len; i++) {
        if (raw[i] != other[i]) {
            return raw[i] - other[i];
        }
    }
    return raw.length - other.length;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-546_428e32c6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/api/QueryEngine.java,63,65,"/**
 * Execute a query and get the result.
 *
 * @param statement the query statement
 * @param language the language
 * @param limit the maximum result set size
 * @param offset the number of rows to skip
 * @param bindings the bind variable value bindings
 * @param namePathMapper the name and path mapper to use
 * @return the result
 * @throws ParseException if the statement could not be parsed
 * @throws IllegalArgumentException if there was an error executing the query
 */
Result executeQuery(String statement, String language, long limit, long offset, Map<String, ? extends PropertyValue> bindings, NamePathMapper namePathMapper) throws ParseException;"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-546_428e32c6,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/query/QueryEngineImpl.java,137,155,"@Override
public Result executeQuery(String statement, String language, long limit, long offset, Map<String, ? extends PropertyValue> bindings, NamePathMapper namePathMapper) throws ParseException {
    Query q = parseQuery(statement, language);
    q.setRootTree(getRootTree());
    q.setRootState(getRootState());
    q.setNamePathMapper(namePathMapper);
    q.setLimit(limit);
    q.setOffset(offset);
    if (bindings != null) {
        for (Entry<String, ? extends PropertyValue> e : bindings.entrySet()) {
            q.bindValue(e.getKey(), e.getValue());
        }
    }
    q.setQueryEngine(this);
    q.prepare();
    return q.executeQuery();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-548_717186d6,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/tree/DiffBuilder.java,47,268,"public String build() throws Exception {
    final JsopBuilder buff = new JsopBuilder();
    // maps (key: id of target node, value: path/to/target)
    // for tracking added/removed nodes; this allows us
    // to detect 'move' operations
    final HashMap<NodeState, String> addedNodes = new HashMap<NodeState, String>();
    final HashMap<NodeState, String> removedNodes = new HashMap<NodeState, String>();
    if (!PathUtils.isAncestor(path, pathFilter) && !path.startsWith(pathFilter)) {
        return """";
    }
    if (before == null) {
        if (after != null) {
            buff.tag('+').key(path).object();
            toJson(buff, after);
            return buff.endObject().newline().toString();
        } else {
            // path doesn't exist in the specified revisions
            return """";
        }
    } else if (after == null) {
        buff.tag('-');
        buff.value(path);
        return buff.newline().toString();
    }
    TraversingNodeDiffHandler diffHandler = new TraversingNodeDiffHandler(store) {

        int levels = depth < 0 ? Integer.MAX_VALUE : depth;

        @Override
        public void propertyAdded(PropertyState after) {
            String p = PathUtils.concat(getCurrentPath(), after.getName());
            if (p.startsWith(pathFilter)) {
                buff.tag('^').key(p).encodedValue(after.getEncodedValue()).newline();
            }
        }

        @Override
        public void propertyChanged(PropertyState before, PropertyState after) {
            String p = PathUtils.concat(getCurrentPath(), after.getName());
            if (p.startsWith(pathFilter)) {
                buff.tag('^').key(p).encodedValue(after.getEncodedValue()).newline();
            }
        }

        @Override
        public void propertyDeleted(PropertyState before) {
            String p = PathUtils.concat(getCurrentPath(), before.getName());
            if (p.startsWith(pathFilter)) {
                // since property and node deletions can't be distinguished
                // using the ""- <path>"" notation we're representing
                // property deletions as ""^ <path>:null""
                buff.tag('^').key(p).value(null).newline();
            }
        }

        @Override
        public void childNodeAdded(String name, NodeState after) {
            String p = PathUtils.concat(getCurrentPath(), name);
            if (p.startsWith(pathFilter)) {
                addedNodes.put(after, p);
                buff.tag('+').key(p).object();
                toJson(buff, after);
                buff.endObject().newline();
            }
        }

        @Override
        public void childNodeDeleted(String name, NodeState before) {
            String p = PathUtils.concat(getCurrentPath(), name);
            if (p.startsWith(pathFilter)) {
                removedNodes.put(before, p);
                buff.tag('-');
                buff.value(p);
                buff.newline();
            }
        }

        @Override
        public void childNodeChanged(String name, NodeState before, NodeState after) {
            String p = PathUtils.concat(getCurrentPath(), name);
            if (PathUtils.isAncestor(p, pathFilter) || p.startsWith(pathFilter)) {
                --levels;
                if (levels >= 0) {
                    // recurse
                    super.childNodeChanged(name, before, after);
                } else {
                    buff.tag('^');
                    buff.key(p);
                    buff.object().endObject();
                    buff.newline();
                }
                ++levels;
            }
        }
    };
    diffHandler.start(before, after, path);
    // check if this commit includes 'move' operations
    // by building intersection of added and removed nodes
    addedNodes.keySet().retainAll(removedNodes.keySet());
    if (!addedNodes.isEmpty()) {
        // this commit includes 'move' operations
        removedNodes.keySet().retainAll(addedNodes.keySet());
        // addedNodes & removedNodes now only contain information about moved nodes
        // re-build the diff in a 2nd pass, this time representing moves correctly
        buff.resetWriter();
        // TODO refactor code, avoid duplication
        diffHandler = new TraversingNodeDiffHandler(store) {

            int levels = depth < 0 ? Integer.MAX_VALUE : depth;

            @Override
            public void propertyAdded(PropertyState after) {
                String p = PathUtils.concat(getCurrentPath(), after.getName());
                if (p.startsWith(pathFilter)) {
                    buff.tag('^').key(p).encodedValue(after.getEncodedValue()).newline();
                }
            }

            @Override
            public void propertyChanged(PropertyState before, PropertyState after) {
                String p = PathUtils.concat(getCurrentPath(), after.getName());
                if (p.startsWith(pathFilter)) {
                    buff.tag('^').key(p).encodedValue(after.getEncodedValue()).newline();
                }
            }

            @Override
            public void propertyDeleted(PropertyState before) {
                String p = PathUtils.concat(getCurrentPath(), before.getName());
                if (p.startsWith(pathFilter)) {
                    // since property and node deletions can't be distinguished
                    // using the ""- <path>"" notation we're representing
                    // property deletions as ""^ <path>:null""
                    buff.tag('^').key(p).value(null).newline();
                }
            }

            @Override
            public void childNodeAdded(String name, NodeState after) {
                if (addedNodes.containsKey(after)) {
                    // moved node, will be processed separately
                    return;
                }
                String p = PathUtils.concat(getCurrentPath(), name);
                if (p.startsWith(pathFilter)) {
                    buff.tag('+').key(p).object();
                    toJson(buff, after);
                    buff.endObject().newline();
                }
            }

            @Override
            public void childNodeDeleted(String name, NodeState before) {
                if (addedNodes.containsKey(before)) {
                    // moved node, will be processed separately
                    return;
                }
                String p = PathUtils.concat(getCurrentPath(), name);
                if (p.startsWith(pathFilter)) {
                    buff.tag('-');
                    buff.value(p);
                    buff.newline();
                }
            }

            @Override
            public void childNodeChanged(String name, NodeState before, NodeState after) {
                String p = PathUtils.concat(getCurrentPath(), name);
                if (PathUtils.isAncestor(p, pathFilter) || p.startsWith(pathFilter)) {
                    --levels;
                    if (levels >= 0) {
                        // recurse
                        super.childNodeChanged(name, before, after);
                    } else {
                        buff.tag('^');
                        buff.value(p);
                        buff.newline();
                    }
                    ++levels;
                }
            }
        };
        diffHandler.start(before, after, path);
        // finally process moved nodes
        for (Map.Entry<NodeState, String> entry : addedNodes.entrySet()) {
            buff.tag('>').key(removedNodes.get(entry.getKey())).value(entry.getValue()).newline();
        }
    }
    return buff.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-548_717186d6,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/tree/DiffBuilder.java,113,123,"@Override
public void childNodeAdded(String name, NodeState after) {
    String p = PathUtils.concat(getCurrentPath(), name);
    if (p.startsWith(pathFilter)) {
        addedNodes.put(after, p);
        buff.tag('+').key(p).object();
        toJson(buff, after);
        buff.endObject().newline();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-548_717186d6,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/tree/DiffBuilder.java,208,221,"@Override
public void childNodeAdded(String name, NodeState after) {
    if (addedNodes.containsKey(after)) {
        // moved node, will be processed separately
        return;
    }
    String p = PathUtils.concat(getCurrentPath(), name);
    if (p.startsWith(pathFilter)) {
        buff.tag('+').key(p).object();
        toJson(buff, after);
        buff.endObject().newline();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-548_717186d6,Major,oak-mk/src/main/java/org/apache/jackrabbit/mk/model/tree/DiffBuilder.java,270,279,"private void toJson(JsopBuilder builder, NodeState node) {
    for (PropertyState property : node.getProperties()) {
        builder.key(property.getName()).encodedValue(property.getEncodedValue());
    }
    for (ChildNode entry : node.getChildNodeEntries(0, -1)) {
        builder.key(entry.getName()).object();
        toJson(builder, entry.getNode());
        builder.endObject();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-554_3f51fb09,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/PropertyStates.java,53,74,"/**
 * Create a {@code PropertyState} based on a {@link Value}. The
 * {@link Type} of the property state is determined by the
 * type of the value.
 * @param name  The name of the property state
 * @param value  The value of the property state
 * @return  The new property state
 * @throws RepositoryException forwarded from {@code value}
 */
@Nonnull
public static PropertyState createProperty(String name, Value value) throws RepositoryException {
    int type = value.getType();
    switch(type) {
        case PropertyType.STRING:
            return StringPropertyState.stringProperty(name, value.getString());
        case PropertyType.BINARY:
            return BinaryPropertyState.binaryProperty(name, value);
        case PropertyType.LONG:
            return LongPropertyState.createLongProperty(name, value.getLong());
        case PropertyType.DOUBLE:
            return DoublePropertyState.doubleProperty(name, value.getDouble());
        case PropertyType.DATE:
            return LongPropertyState.createDateProperty(name, value.getLong());
        case PropertyType.BOOLEAN:
            return BooleanPropertyState.booleanProperty(name, value.getBoolean());
        case PropertyType.DECIMAL:
            return DecimalPropertyState.decimalProperty(name, value.getDecimal());
        default:
            return new GenericPropertyState(name, value.getString(), Type.fromTag(type, false));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-554_3f51fb09,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/PropertyStates.java,87,145,"/**
 * Create a multi valued {@code PropertyState} based on a list of
 * {@link Value} instances. The {@link Type} of the property is determined
 * by the type of the first value in the list or {@link Type#STRING} if the
 * list is empty.
 *
 * @param name  The name of the property state
 * @param values  The values of the property state
 * @return  The new property state
 * @throws RepositoryException forwarded from {@code value}
 */
@Nonnull
public static PropertyState createProperty(String name, Iterable<Value> values) throws RepositoryException {
    Value first = Iterables.getFirst(values, null);
    if (first == null) {
        return EmptyPropertyState.emptyProperty(name, STRINGS);
    }
    int type = first.getType();
    switch(type) {
        case PropertyType.STRING:
            List<String> strings = Lists.newArrayList();
            for (Value value : values) {
                strings.add(value.getString());
            }
            return MultiStringPropertyState.stringProperty(name, strings);
        case PropertyType.BINARY:
            List<Blob> blobs = Lists.newArrayList();
            for (Value value : values) {
                blobs.add(new ValueBasedBlob(value));
            }
            return MultiBinaryPropertyState.binaryPropertyFromBlob(name, blobs);
        case PropertyType.LONG:
            List<Long> longs = Lists.newArrayList();
            for (Value value : values) {
                longs.add(value.getLong());
            }
            return MultiLongPropertyState.createLongProperty(name, longs);
        case PropertyType.DOUBLE:
            List<Double> doubles = Lists.newArrayList();
            for (Value value : values) {
                doubles.add(value.getDouble());
            }
            return MultiDoublePropertyState.doubleProperty(name, doubles);
        case PropertyType.DATE:
            List<Long> dates = Lists.newArrayList();
            for (Value value : values) {
                dates.add(value.getLong());
            }
            return MultiLongPropertyState.createDatePropertyFromLong(name, dates);
        case PropertyType.BOOLEAN:
            List<Boolean> booleans = Lists.newArrayList();
            for (Value value : values) {
                booleans.add(value.getBoolean());
            }
            return MultiBooleanPropertyState.booleanProperty(name, booleans);
        case PropertyType.DECIMAL:
            List<BigDecimal> decimals = Lists.newArrayList();
            for (Value value : values) {
                decimals.add(value.getDecimal());
            }
            return MultiDecimalPropertyState.decimalProperty(name, decimals);
        default:
            List<String> vals = Lists.newArrayList();
            for (Value value : values) {
                vals.add(value.getString());
            }
            return new MultiGenericPropertyState(name, vals, Type.fromTag(type, true));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-554_3f51fb09,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/value/ValueImpl.java,203,223,"/**
 * @see javax.jcr.Value#getString()
 */
@Override
public String getString() throws RepositoryException {
    checkState(getType() != PropertyType.BINARY || stream == null, ""getStream has previously been called on this Value instance. "" + ""In this case a new Value instance must be acquired in order to successfully call this method."");
    switch(getType()) {
        case PropertyType.NAME:
            return namePathMapper.getJcrName(propertyState.getValue(Type.STRING, index));
        case PropertyType.PATH:
            String s = propertyState.getValue(Type.STRING, index);
            if (s.startsWith(""["") && s.endsWith(""]"")) {
                // identifier paths are returned as-is (JCR 2.0, 3.4.3.1)
                return s;
            } else {
                return namePathMapper.getJcrPath(s);
            }
        default:
            return propertyState.getValue(Type.STRING, index);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-554_3f51fb09,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/value/ValueImpl.java,270,278,"/**
 * @see Object#hashCode()
 */
@Override
public int hashCode() {
    if (getType() == PropertyType.BINARY) {
        return propertyState.getValue(Type.BINARY, index).hashCode();
    } else {
        return propertyState.getValue(Type.STRING, index).hashCode();
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-554_3f51fb09,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/value/ValueImpl.java,280,283,"@Override
public String toString() {
    return propertyState.getValue(Type.STRING, index);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/Query.java,307,397,"Iterator<ResultRowImpl> getRows() {
    prepare();
    Iterator<ResultRowImpl> it;
    if (explain) {
        String plan = source.getPlan(rootState);
        columns = new ColumnImpl[] { new ColumnImpl(""explain"", ""plan"", ""plan"") };
        ResultRowImpl r = new ResultRowImpl(this, new String[0], new PropertyValue[] { PropertyValues.newString(plan) }, null);
        it = Arrays.asList(r).iterator();
    } else {
        if (LOG.isDebugEnabled()) {
            LOG.debug(""plan: "" + source.getPlan(rootState));
        }
        if (orderings == null) {
            // can apply limit and offset directly
            it = new RowIterator(rootState, limit, offset);
        } else {
            // read and order first; skip and limit afterwards
            it = new RowIterator(rootState, Long.MAX_VALUE, 0);
        }
        long readCount = 0;
        if (orderings != null) {
            // TODO ""order by"" is not necessary if the used index returns
            // rows in the same order
            // avoid overflow (both offset and limit could be Long.MAX_VALUE)
            int keep = (int) Math.min(Integer.MAX_VALUE, Math.min(Integer.MAX_VALUE, offset) + Math.min(Integer.MAX_VALUE, limit));
            ArrayList<ResultRowImpl> list = new ArrayList<ResultRowImpl>();
            while (it.hasNext()) {
                readCount++;
                ResultRowImpl r = it.next();
                list.add(r);
                // which is close to the optimum O(n*log(keep))
                if (list.size() > keep * 2) {
                    // remove tail entries right now, to save memory
                    Collections.sort(list);
                    keepFirst(list, keep);
                }
            }
            Collections.sort(list);
            keepFirst(list, keep);
            it = list.iterator();
            // if there are many entries)
            for (int i = 0; i < offset && it.hasNext(); i++) {
                it.next();
            }
            size = list.size() - offset;
        } else if (measure) {
            while (it.hasNext()) {
                readCount++;
                it.next();
            }
        }
        if (measure) {
            columns = new ColumnImpl[] { new ColumnImpl(""measure"", ""selector"", ""selector""), new ColumnImpl(""measure"", ""scanCount"", ""scanCount"") };
            ArrayList<ResultRowImpl> list = new ArrayList<ResultRowImpl>();
            ResultRowImpl r = new ResultRowImpl(this, new String[0], new PropertyValue[] { PropertyValues.newString(""query""), PropertyValues.newLong(readCount) }, null);
            list.add(r);
            for (SelectorImpl selector : selectors) {
                r = new ResultRowImpl(this, new String[0], new PropertyValue[] { PropertyValues.newString(selector.getSelectorName()), PropertyValues.newLong(selector.getScanCount()) }, null);
                list.add(r);
            }
            it = list.iterator();
        }
    }
    return it;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/QueryEngineImpl.java,163,186,"public QueryIndex getBestIndex(Query query, NodeState rootState, Filter filter) {
    QueryIndex best = null;
    if (LOG.isDebugEnabled()) {
        LOG.debug(""cost using filter "" + filter);
    }
    double bestCost = Double.POSITIVE_INFINITY;
    for (QueryIndex index : getIndexes(rootState)) {
        double cost = index.getCost(filter, rootState);
        if (LOG.isDebugEnabled()) {
            LOG.debug(""cost for "" + index.getIndexName() + "" is "" + cost);
        }
        if (cost < bestCost) {
            bestCost = cost;
            best = index;
        }
    }
    if (best == null) {
        if (LOG.isDebugEnabled()) {
            LOG.debug(""no indexes found - using TraversingIndex; indexProvider: "" + indexProvider);
        }
        best = new TraversingIndex();
    }
    return best;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/ChildNodeJoinConditionImpl.java,65,79,"@Override
public void restrict(FilterImpl f) {
    if (f.getSelector() == parentSelector) {
        String c = childSelector.currentPath();
        if (c != null) {
            f.restrictPath(PathUtils.getParentPath(c), Filter.PathRestriction.EXACT);
        }
    }
    if (f.getSelector() == childSelector) {
        String p = parentSelector.currentPath();
        if (p != null) {
            f.restrictPath(p, Filter.PathRestriction.DIRECT_CHILDREN);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/DescendantNodeJoinConditionImpl.java,65,79,"@Override
public void restrict(FilterImpl f) {
    if (f.getSelector() == ancestorSelector) {
        String d = descendantSelector.currentPath();
        if (d != null) {
            f.restrictPath(PathUtils.getParentPath(d), Filter.PathRestriction.PARENT);
        }
    }
    if (f.getSelector() == descendantSelector) {
        String a = ancestorSelector.currentPath();
        if (a != null) {
            f.restrictPath(a, Filter.PathRestriction.DIRECT_CHILDREN);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/EquiJoinConditionImpl.java,96,116,"@Override
public void restrict(FilterImpl f) {
    if (f.getSelector() == selector1) {
        PropertyValue p2 = selector2.currentProperty(property2Name);
        if (p2 != null) {
            if (!p2.isArray()) {
                // TODO support join on multi-valued properties
                f.restrictProperty(property1Name, Operator.EQUAL, p2);
            }
        }
    }
    if (f.getSelector() == selector2) {
        PropertyValue p1 = selector1.currentProperty(property1Name);
        if (p1 != null) {
            if (!p1.isArray()) {
                // TODO support join on multi-valued properties
                f.restrictProperty(property2Name, Operator.EQUAL, p1);
            }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/JoinConditionImpl.java,23,23,public abstract boolean evaluate();
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/JoinConditionImpl.java,25,25,public abstract void restrict(FilterImpl f);
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/JoinConditionImpl.java,27,27,public abstract void restrictPushDown(SelectorImpl selectorImpl);
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/JoinImpl.java,61,65,"@Override
public String getPlan(NodeState rootState) {
    return left.getPlan(rootState) + ' ' + joinType + "" "" + right.getPlan(rootState) + "" on "" + joinCondition;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SameNodeJoinConditionImpl.java,80,104,"@Override
public void restrict(FilterImpl f) {
    if (f.getSelector() == selector1) {
        String p2 = selector2.currentPath();
        if (p2 != null) {
            if (selector2Path.equals(""."")) {
                f.restrictPath(p2, Filter.PathRestriction.EXACT);
            } else {
                // TODO normalize paths; support more complex relative path ("".."" and so on)
                String p = PathUtils.concat(p2, selector2Path);
                f.restrictPath(p, Filter.PathRestriction.EXACT);
            }
        }
    }
    if (f.getSelector() == selector2) {
        String p1 = selector1.currentPath();
        if (p1 != null) {
            if (selector2Path.equals(""."")) {
                f.restrictPath(p1, Filter.PathRestriction.EXACT);
            } else {
            // TODO normalize paths; support relative path ("".."" and so on)
            }
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SelectorImpl.java,99,110,"@Override
public void prepare() {
    if (queryConstraint != null) {
        queryConstraint.restrictPushDown(this);
    }
    if (!outerJoinLeftHandSide && !outerJoinRightHandSide) {
        for (JoinConditionImpl c : allJoinConditions) {
            c.restrictPushDown(this);
        }
    }
    index = query.getBestIndex(createFilter());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SelectorImpl.java,112,115,"@Override
public void execute(NodeState rootState) {
    cursor = index.query(createFilter(), rootState);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SelectorImpl.java,117,127,"@Override
public String getPlan(NodeState rootState) {
    StringBuilder buff = new StringBuilder();
    buff.append(toString());
    buff.append("" /* "").append(index.getPlan(createFilter(), rootState));
    if (selectorCondition != null) {
        buff.append("" where "").append(selectorCondition);
    }
    buff.append("" */"");
    return buff.toString();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SelectorImpl.java,129,151,"private Filter createFilter() {
    FilterImpl f = new FilterImpl(this, query.getStatement());
    validateNodeType(nodeTypeName);
    f.setNodeType(nodeTypeName);
    if (joinCondition != null) {
        joinCondition.restrict(f);
    }
    // ("".. is null"" must be written as ""not .. is not null"").
    if (queryConstraint != null) {
        queryConstraint.restrict(f);
    }
    return f;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-579_7d72e6ed,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/query/ast/SourceImpl.java,147,147,"/**
 * Prepare executing the query. This method will decide which index to use.
 */
public abstract void prepare();"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-596_9b268da0,Major,oak-mongomk/src/main/java/org/apache/jackrabbit/mongomk/impl/model/MongoNode.java,147,152,"@Override
public MongoNode copy() {
    MongoNode copy = new MongoNode();
    copy.putAll((Map) super.copy());
    return copy;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-606_f0fbacab,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/ItemDelegate.java,85,88,"/**
 * Determine whether this item is stale
 * @return  {@code true} iff stale
 */
public boolean isStale() {
    Status status = getLocationOrNull().getStatus();
    return status == Status.DISCONNECTED || status == null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-606_f0fbacab,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/ItemDelegate.java,117,124,"/**
 * The underlying {@link org.apache.jackrabbit.oak.api.TreeLocation} of this item.
 * @return  tree location of the underlying item
 * @throws InvalidItemStateException if the location points to a stale item
 */
@Nonnull
public TreeLocation getLocation() throws InvalidItemStateException {
    TreeLocation location = getLocationOrNull();
    if (!location.exists()) {
        throw new InvalidItemStateException(""Item is stale"");
    }
    return location;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-606_f0fbacab,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/ItemDelegate.java,140,147,"// ------------------------------------------------------------< private >---
/**
 * The underlying {@link org.apache.jackrabbit.oak.api.TreeLocation} of this item.
 * The location is only re-resolved when the revision of this item does not match
 * the revision of the session.
 * @return  tree location of the underlying item.
 */
@Nonnull
private synchronized TreeLocation getLocationOrNull() {
    if (location.exists() && sessionDelegate.getRevision() != revision) {
        location = sessionDelegate.getLocation(location.getPath());
        revision = sessionDelegate.getRevision();
    }
    return location;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-612_df9e6913,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,214,283,"@Override
@Nonnull
public Node addNode(final String relPath, final String primaryNodeTypeName) throws RepositoryException {
    checkStatus();
    checkProtected();
    return sessionDelegate.perform(new SessionOperation<Node>() {

        @Override
        public Node perform() throws RepositoryException {
            String oakPath = sessionDelegate.getOakPathKeepIndexOrThrowNotFound(relPath);
            String oakName = PathUtils.getName(oakPath);
            String parentPath = sessionDelegate.getOakPath(PathUtils.getParentPath(oakPath));
            // handle index
            if (oakName.contains(""["")) {
                throw new RepositoryException(""Cannot create a new node using a name including an index"");
            }
            NodeDelegate parent = dlg.getChild(parentPath);
            if (parent == null) {
                // is it a property?
                String grandParentPath = PathUtils.getParentPath(parentPath);
                NodeDelegate grandParent = dlg.getChild(grandParentPath);
                if (grandParent != null) {
                    String propName = PathUtils.getName(parentPath);
                    if (grandParent.getProperty(propName) != null) {
                        throw new ConstraintViolationException(""Can't add new node to property."");
                    }
                }
                throw new PathNotFoundException(relPath);
            }
            if (parent.getChild(oakName) != null) {
                throw new ItemExistsException(relPath);
            }
            String ntName = primaryNodeTypeName;
            if (ntName == null) {
                DefinitionProvider dp = sessionDelegate.getDefinitionProvider();
                try {
                    String childName = sessionDelegate.getOakName(PathUtils.getName(relPath));
                    NodeDefinition def = dp.getDefinition(new NodeImpl<NodeDelegate>(parent), childName);
                    ntName = def.getDefaultPrimaryTypeName();
                } catch (RepositoryException e) {
                    throw new ConstraintViolationException(""no matching child node definition found for "" + relPath);
                }
            }
            // TODO: figure out the right place for this check
            NodeTypeManager ntm = sessionDelegate.getNodeTypeManager();
            // throws on not found
            NodeType nt = ntm.getNodeType(ntName);
            if (nt.isAbstract() || nt.isMixin()) {
                throw new ConstraintViolationException();
            }
            // TODO: END
            NodeDelegate added = parent.addChild(oakName);
            if (added == null) {
                throw new ItemExistsException();
            }
            NodeImpl<?> childNode = new NodeImpl<NodeDelegate>(added);
            childNode.internalSetPrimaryType(ntName);
            childNode.autoCreateItems();
            return childNode;
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-612_df9e6913,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,221,281,"@Override
public Node perform() throws RepositoryException {
    String oakPath = sessionDelegate.getOakPathKeepIndexOrThrowNotFound(relPath);
    String oakName = PathUtils.getName(oakPath);
    String parentPath = sessionDelegate.getOakPath(PathUtils.getParentPath(oakPath));
    // handle index
    if (oakName.contains(""["")) {
        throw new RepositoryException(""Cannot create a new node using a name including an index"");
    }
    NodeDelegate parent = dlg.getChild(parentPath);
    if (parent == null) {
        // is it a property?
        String grandParentPath = PathUtils.getParentPath(parentPath);
        NodeDelegate grandParent = dlg.getChild(grandParentPath);
        if (grandParent != null) {
            String propName = PathUtils.getName(parentPath);
            if (grandParent.getProperty(propName) != null) {
                throw new ConstraintViolationException(""Can't add new node to property."");
            }
        }
        throw new PathNotFoundException(relPath);
    }
    if (parent.getChild(oakName) != null) {
        throw new ItemExistsException(relPath);
    }
    String ntName = primaryNodeTypeName;
    if (ntName == null) {
        DefinitionProvider dp = sessionDelegate.getDefinitionProvider();
        try {
            String childName = sessionDelegate.getOakName(PathUtils.getName(relPath));
            NodeDefinition def = dp.getDefinition(new NodeImpl<NodeDelegate>(parent), childName);
            ntName = def.getDefaultPrimaryTypeName();
        } catch (RepositoryException e) {
            throw new ConstraintViolationException(""no matching child node definition found for "" + relPath);
        }
    }
    // TODO: figure out the right place for this check
    NodeTypeManager ntm = sessionDelegate.getNodeTypeManager();
    // throws on not found
    NodeType nt = ntm.getNodeType(ntName);
    if (nt.isAbstract() || nt.isMixin()) {
        throw new ConstraintViolationException();
    }
    // TODO: END
    NodeDelegate added = parent.addChild(oakName);
    if (added == null) {
        throw new ItemExistsException();
    }
    NodeImpl<?> childNode = new NodeImpl<NodeDelegate>(added);
    childNode.internalSetPrimaryType(ntName);
    childNode.autoCreateItems();
    return childNode;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-612_df9e6913,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,1419,1437,"private void internalSetPrimaryType(final String nodeTypeName) throws RepositoryException {
    sessionDelegate.perform(new SessionOperation<Void>() {

        @Override
        public Void perform() throws RepositoryException {
            // TODO: figure out the right place for this check
            NodeTypeManager ntm = sessionDelegate.getNodeTypeManager();
            // throws on not found
            NodeType nt = ntm.getNodeType(nodeTypeName);
            if (nt.isAbstract() || nt.isMixin()) {
                throw new ConstraintViolationException();
            }
            // TODO: END
            String jcrPrimaryType = sessionDelegate.getOakPath(Property.JCR_PRIMARY_TYPE);
            Value value = sessionDelegate.getValueFactory().createValue(nodeTypeName, PropertyType.NAME);
            dlg.setProperty(jcrPrimaryType, value);
            return null;
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-612_df9e6913,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,1421,1435,"@Override
public Void perform() throws RepositoryException {
    // TODO: figure out the right place for this check
    NodeTypeManager ntm = sessionDelegate.getNodeTypeManager();
    // throws on not found
    NodeType nt = ntm.getNodeType(nodeTypeName);
    if (nt.isAbstract() || nt.isMixin()) {
        throw new ConstraintViolationException();
    }
    // TODO: END
    String jcrPrimaryType = sessionDelegate.getOakPath(Property.JCR_PRIMARY_TYPE);
    Value value = sessionDelegate.getValueFactory().createValue(nodeTypeName, PropertyType.NAME);
    dlg.setProperty(jcrPrimaryType, value);
    return null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-614_6feacf6b,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,195,198,"/**
 * Determine whether this child has been removed.
 * Assumes {@code read()}, {@code write()} needs not be called.
 * @return  {@code true} iff this child has been removed
 */
private boolean removed() {
    return !isRoot() && parent.writeState != null && parent.hasBaseState(name) && !parent.writeState.hasChildNode(name);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-614_6feacf6b,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,200,223,"@Nonnull
private NodeState read() {
    if (revision != root.revision) {
        // root never gets here since revision == root.revision
        assert (!isRoot());
        checkState(!removed(), ""This node has already been removed"");
        parent.read();
        // The builder could have been reset, need to re-get base state
        baseState = parent.getBaseState(name);
        // ... same for the write state
        writeState = parent.getWriteState(name);
        revision = root.revision;
    }
    assert classInvariants();
    if (writeState != null) {
        return writeState;
    } else {
        return baseState;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-614_6feacf6b,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,230,261,"@Nonnull
private MutableNodeState write(long newRevision, boolean skipRemovedCheck) {
    // make sure that all revision numbers up to the root gets updated
    if (!isRoot()) {
        checkState(skipRemovedCheck || !removed());
        parent.write(newRevision, skipRemovedCheck);
    }
    if (writeState == null || revision != root.revision) {
        // root never gets here since revision == root.revision
        assert (!isRoot());
        // The builder could have been reset, need to re-get base state
        baseState = parent.getBaseState(name);
        writeState = parent.getWriteState(name);
        if (writeState == null) {
            if (removed()) {
                writeState = new MutableNodeState(null);
            } else {
                writeState = new MutableNodeState(baseState);
            }
            // guaranteed by called parent.write()
            assert parent.writeState != null;
            parent.writeState.nodes.put(name, writeState);
        }
    }
    revision = newRevision;
    assert classInvariants();
    assert writeState != null;
    return writeState;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-614_6feacf6b,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,381,394,"@Override
@Nonnull
public NodeBuilder setNode(String name, NodeState state) {
    write();
    MutableNodeState childState = getWriteState(name);
    if (childState == null) {
        writeState.nodes.remove(name);
        childState = createChildBuilder(name).write();
    }
    childState.reset(state);
    updated();
    return this;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,81,97,"@Nonnull
static TreeImpl createRoot(final RootImpl root) {
    return new TreeImpl(root, null, """") {

        @Override
        protected NodeState getBaseState() {
            return root.getBaseState();
        }

        @Override
        protected synchronized NodeBuilder getNodeBuilder() {
            if (nodeBuilder == null) {
                nodeBuilder = root.createRootBuilder();
            }
            return nodeBuilder;
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,89,95,"@Override
protected synchronized NodeBuilder getNodeBuilder() {
    if (nodeBuilder == null) {
        nodeBuilder = root.createRootBuilder();
    }
    return nodeBuilder;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,189,199,"@Override
public Iterable<? extends PropertyState> getProperties() {
    root.checkLive();
    return Iterables.filter(getNodeBuilder().getProperties(), new Predicate<PropertyState>() {

        @Override
        public boolean apply(PropertyState propertyState) {
            return canRead(propertyState);
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,212,223,"private boolean isDisconnected() {
    if (isRoot()) {
        return false;
    }
    if (parent.nodeBuilder == null) {
        return false;
    }
    if (!parent.nodeBuilder.isConnected()) {
        return true;
    }
    return !getNodeBuilder().isConnected();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,225,241,"@Override
public Status getStatus() {
    root.checkLive();
    if (isDisconnected()) {
        return Status.DISCONNECTED;
    }
    NodeBuilder builder = getNodeBuilder();
    if (builder.isNew()) {
        return Status.NEW;
    } else if (builder.isModified()) {
        return Status.MODIFIED;
    } else {
        return Status.EXISTING;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,249,254,"@Override
public long getChildrenCount() {
    // TODO: make sure cnt respects access control
    root.checkLive();
    return getNodeBuilder().getChildNodeCount();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,256,279,"@Override
public Iterable<Tree> getChildren() {
    root.checkLive();
    Iterable<String> childNames;
    if (hasOrderableChildren()) {
        childNames = getOrderedChildNames();
    } else {
        childNames = getNodeBuilder().getChildNodeNames();
    }
    return Iterables.filter(Iterables.transform(childNames, new Function<String, Tree>() {

        @Override
        public Tree apply(String input) {
            return new TreeImpl(root, TreeImpl.this, input);
        }
    }), new Predicate<Tree>() {

        @Override
        public boolean apply(Tree tree) {
            return tree != null && canRead(tree);
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,281,298,"@Override
public Tree addChild(String name) {
    root.checkLive();
    if (!hasChild(name)) {
        getNodeBuilder().child(name);
        if (hasOrderableChildren()) {
            getNodeBuilder().setProperty(MemoryPropertyBuilder.copy(Type.STRING, internalGetProperty(OAK_CHILD_ORDER)).addValue(name).getPropertyState());
        }
        root.updated();
    }
    TreeImpl child = getChild(name);
    assert child != null;
    return child;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,300,322,"@Override
public boolean remove() {
    root.checkLive();
    if (isDisconnected()) {
        throw new IllegalStateException(""Cannot remove a disconnected tree"");
    }
    if (!isRoot() && parent.hasChild(name)) {
        NodeBuilder builder = parent.getNodeBuilder();
        builder.removeNode(name);
        if (parent.hasOrderableChildren()) {
            builder.setProperty(MemoryPropertyBuilder.copy(Type.STRING, parent.internalGetProperty(OAK_CHILD_ORDER)).removeValue(name).getPropertyState());
        }
        root.updated();
        return true;
    } else {
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,324,367,"@Override
public boolean orderBefore(final String name) {
    root.checkLive();
    if (isRoot()) {
        // root does not have siblings
        return false;
    }
    if (name != null && !parent.hasChild(name)) {
        // so such sibling or not accessible
        return false;
    }
    // perform the reorder
    parent.ensureChildOrderProperty();
    // all siblings but not this one
    Iterable<String> filtered = Iterables.filter(parent.getOrderedChildNames(), new Predicate<String>() {

        @Override
        public boolean apply(@Nullable String input) {
            return !TreeImpl.this.getName().equals(input);
        }
    });
    // create head and tail
    Iterable<String> head;
    Iterable<String> tail;
    if (name == null) {
        head = filtered;
        tail = Collections.emptyList();
    } else {
        int idx = Iterables.indexOf(filtered, new Predicate<String>() {

            @Override
            public boolean apply(@Nullable String input) {
                return name.equals(input);
            }
        });
        head = Iterables.limit(filtered, idx);
        tail = Iterables.skip(filtered, idx);
    }
    // concatenate head, this name and tail
    parent.getNodeBuilder().setProperty(MultiStringPropertyState.stringProperty(OAK_CHILD_ORDER, Iterables.concat(head, Collections.singleton(getName()), tail)));
    root.updated();
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,369,375,"@Override
public void setProperty(PropertyState property) {
    root.checkLive();
    NodeBuilder builder = getNodeBuilder();
    builder.setProperty(property);
    root.updated();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,377,383,"@Override
public <T> void setProperty(String name, T value) {
    root.checkLive();
    NodeBuilder builder = getNodeBuilder();
    builder.setProperty(name, value);
    root.updated();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,385,391,"@Override
public <T> void setProperty(String name, T value, Type<T> type) {
    root.checkLive();
    NodeBuilder builder = getNodeBuilder();
    builder.setProperty(name, value, type);
    root.updated();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,393,399,"@Override
public void removeProperty(String name) {
    root.checkLive();
    NodeBuilder builder = getNodeBuilder();
    builder.removeProperty(name);
    root.updated();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,421,427,"@Nonnull
protected synchronized NodeBuilder getNodeBuilder() {
    if (nodeBuilder == null) {
        nodeBuilder = parent.getNodeBuilder().child(name);
    }
    return nodeBuilder;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,447,450,"@Nonnull
NodeState getNodeState() {
    return getNodeBuilder().getNodeState();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,477,494,"/**
 * Update the child order with children that have been removed or added.
 * Added children are appended to the end of the {@link #OAK_CHILD_ORDER}
 * property.
 */
void updateChildOrder() {
    if (!hasOrderableChildren()) {
        return;
    }
    Set<String> names = Sets.newLinkedHashSet();
    for (String name : getOrderedChildNames()) {
        if (getNodeBuilder().hasChildNode(name)) {
            names.add(name);
        }
    }
    for (String name : getNodeBuilder().getChildNodeNames()) {
        names.add(name);
    }
    PropertyBuilder<String> builder = MemoryPropertyBuilder.array(Type.STRING, OAK_CHILD_ORDER);
    builder.setValues(names);
    getNodeBuilder().setProperty(builder.getPropertyState());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,498,502,"// ------------------------------------------------------------< private >---
private TreeImpl internalGetChild(String childName) {
    return getNodeBuilder().hasChildNode(childName) ? new TreeImpl(root, this, childName) : null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,504,506,"private PropertyState internalGetProperty(String propertyName) {
    return getNodeBuilder().getProperty(propertyName);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-621_00b4b8a0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,576,582,"/**
 * Ensures that the {@link #OAK_CHILD_ORDER} exists. This method will create
 * the property if it doesn't exist and initialize the value with the names
 * of the children as returned by {@link NodeBuilder#getChildNodeNames()}.
 */
public void ensureChildOrderProperty() {
    PropertyState childOrder = getNodeBuilder().getProperty(OAK_CHILD_ORDER);
    if (childOrder == null) {
        getNodeBuilder().setProperty(MultiStringPropertyState.stringProperty(OAK_CHILD_ORDER, getNodeBuilder().getChildNodeNames()));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-642_7a84b3a8,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,213,286,"@Override
@Nonnull
public Node addNode(final String relPath, final String primaryNodeTypeName) throws RepositoryException {
    checkStatus();
    checkProtected();
    return sessionDelegate.perform(new SessionOperation<Node>() {

        @Override
        public Node perform() throws RepositoryException {
            String oakPath = sessionDelegate.getOakPathKeepIndexOrThrowNotFound(relPath);
            String oakName = PathUtils.getName(oakPath);
            String parentPath = sessionDelegate.getOakPath(PathUtils.getParentPath(oakPath));
            // handle index
            if (oakName.contains(""["")) {
                throw new RepositoryException(""Cannot create a new node using a name including an index"");
            }
            NodeDelegate parent = dlg.getChild(parentPath);
            if (parent == null) {
                // is it a property?
                String grandParentPath = PathUtils.getParentPath(parentPath);
                NodeDelegate grandParent = dlg.getChild(grandParentPath);
                if (grandParent != null) {
                    String propName = PathUtils.getName(parentPath);
                    if (grandParent.getProperty(propName) != null) {
                        throw new ConstraintViolationException(""Can't add new node to property."");
                    }
                }
                throw new PathNotFoundException(relPath);
            }
            if (parent.getChild(oakName) != null) {
                throw new ItemExistsException(relPath);
            }
            String ntName = primaryNodeTypeName;
            if (ntName == null) {
                DefinitionProvider dp = sessionDelegate.getDefinitionProvider();
                try {
                    String childName = sessionDelegate.getOakName(PathUtils.getName(relPath));
                    NodeDefinition def = dp.getDefinition(new NodeImpl<NodeDelegate>(parent), childName);
                    ntName = def.getDefaultPrimaryTypeName();
                } catch (RepositoryException e) {
                    throw new ConstraintViolationException(""no matching child node definition found for "" + relPath);
                }
            }
            // TODO: figure out the right place for this check
            NodeTypeManager ntm = sessionDelegate.getNodeTypeManager();
            // throws on not found
            NodeType nt = ntm.getNodeType(ntName);
            if (nt.isAbstract() || nt.isMixin()) {
                throw new ConstraintViolationException();
            }
            // TODO: END
            NodeDelegate added = parent.addChild(oakName);
            if (added == null) {
                throw new ItemExistsException();
            }
            if (getPrimaryNodeType().hasOrderableChildNodes()) {
                dlg.setOrderableChildren(true);
            }
            NodeImpl<?> childNode = new NodeImpl<NodeDelegate>(added);
            childNode.internalSetPrimaryType(ntName);
            childNode.autoCreateItems();
            return childNode;
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-642_7a84b3a8,Minor,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,220,284,"@Override
public Node perform() throws RepositoryException {
    String oakPath = sessionDelegate.getOakPathKeepIndexOrThrowNotFound(relPath);
    String oakName = PathUtils.getName(oakPath);
    String parentPath = sessionDelegate.getOakPath(PathUtils.getParentPath(oakPath));
    // handle index
    if (oakName.contains(""["")) {
        throw new RepositoryException(""Cannot create a new node using a name including an index"");
    }
    NodeDelegate parent = dlg.getChild(parentPath);
    if (parent == null) {
        // is it a property?
        String grandParentPath = PathUtils.getParentPath(parentPath);
        NodeDelegate grandParent = dlg.getChild(grandParentPath);
        if (grandParent != null) {
            String propName = PathUtils.getName(parentPath);
            if (grandParent.getProperty(propName) != null) {
                throw new ConstraintViolationException(""Can't add new node to property."");
            }
        }
        throw new PathNotFoundException(relPath);
    }
    if (parent.getChild(oakName) != null) {
        throw new ItemExistsException(relPath);
    }
    String ntName = primaryNodeTypeName;
    if (ntName == null) {
        DefinitionProvider dp = sessionDelegate.getDefinitionProvider();
        try {
            String childName = sessionDelegate.getOakName(PathUtils.getName(relPath));
            NodeDefinition def = dp.getDefinition(new NodeImpl<NodeDelegate>(parent), childName);
            ntName = def.getDefaultPrimaryTypeName();
        } catch (RepositoryException e) {
            throw new ConstraintViolationException(""no matching child node definition found for "" + relPath);
        }
    }
    // TODO: figure out the right place for this check
    NodeTypeManager ntm = sessionDelegate.getNodeTypeManager();
    // throws on not found
    NodeType nt = ntm.getNodeType(ntName);
    if (nt.isAbstract() || nt.isMixin()) {
        throw new ConstraintViolationException();
    }
    // TODO: END
    NodeDelegate added = parent.addChild(oakName);
    if (added == null) {
        throw new ItemExistsException();
    }
    if (getPrimaryNodeType().hasOrderableChildNodes()) {
        dlg.setOrderableChildren(true);
    }
    NodeImpl<?> childNode = new NodeImpl<NodeDelegate>(added);
    childNode.internalSetPrimaryType(ntName);
    childNode.autoCreateItems();
    return childNode;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-644_55a4f738,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/AccessControlConfigurationImpl.java,67,76,"@Nonnull
@Override
public CommitHookProvider getSecurityHooks() {
    return new CommitHookProvider() {

        @Override
        public CommitHook getCommitHook(String workspaceName) {
            return new CompositeHook(new PermissionHook(workspaceName), new VersionablePathHook(workspaceName));
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-644_55a4f738,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/security/authorization/AccessControlConfigurationImpl.java,71,74,"@Override
public CommitHook getCommitHook(String workspaceName) {
    return new CompositeHook(new PermissionHook(workspaceName), new VersionablePathHook(workspaceName));
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-644_55a4f738,Minor,oak-core/src/main/java/org/apache/jackrabbit/oak/security/privilege/PrivilegeDefinitionStore.java,101,119,"/**
 * @param privilegeNames
 * @return
 */
@Nonnull
public PrivilegeBits getBits(@Nonnull String... privilegeNames) {
    if (privilegeNames.length == 0) {
        return PrivilegeBits.EMPTY;
    }
    Tree privilegesTree = getPrivilegesTree();
    if (privilegesTree == null) {
        return PrivilegeBits.EMPTY;
    }
    PrivilegeBits bits = PrivilegeBits.getInstance();
    for (String privilegeName : privilegeNames) {
        Tree defTree = privilegesTree.getChild(privilegeName);
        if (defTree != null) {
            bits.add(PrivilegeBits.getInstance(defTree));
        }
    }
    return bits.unmodifiable();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-678_6c54045d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,195,200,"/**
 * Determine whether this child exists at its direct parent.
 * @return  {@code true} iff this child exists at its direct parent.
 */
private boolean exists() {
    // retrieved from the base state.
    return isRoot() || parent.writeState == null || parent.writeState.hasChildNode(name);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-678_6c54045d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,206,223,"/**
 * Update the state of this builder for reading.
 * @return  {@code true} is this reader is connected, {@code false} otherwise.
 */
private boolean updateReadState() {
    if (revision != root.revision) {
        // root never gets here since revision == root.revision
        assert (!isRoot());
        if (!exists()) {
            return false;
        }
        parent.updateReadState();
        // The builder could have been reset, need to re-get base state
        baseState = parent.getBaseState(name);
        // ... same for the write state
        writeState = parent.getWriteState(name);
        revision = root.revision;
    }
    return writeState != null || baseState != null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-678_6c54045d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,237,269,"@Nonnull
private MutableNodeState write(long newRevision, boolean reconnect) {
    // make sure that all revision numbers up to the root gets updated
    if (!isRoot()) {
        checkState(reconnect || exists(), ""This node has been removed"");
        parent.write(newRevision, reconnect);
    }
    if (writeState == null || revision != root.revision) {
        // root never gets here since revision == root.revision
        assert (!isRoot());
        // The builder could have been reset, need to re-get base state
        baseState = parent.getBaseState(name);
        writeState = parent.getWriteState(name);
        if (writeState == null) {
            if (exists()) {
                assert baseState != null;
                writeState = new MutableNodeState(baseState);
            } else {
                writeState = new MutableNodeState(null);
            }
            // guaranteed by called parent.write()
            assert parent.writeState != null;
            parent.writeState.nodes.put(name, writeState);
        }
    }
    revision = newRevision;
    assert classInvariants();
    assert writeState != null;
    return writeState;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-738_8ed779dc,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,205,274,"@Override
@Nonnull
public Node addNode(final String relPath, final String primaryNodeTypeName) throws RepositoryException {
    return perform(new ItemWriteOperation<Node>() {

        @Override
        protected void checkPreconditions() throws RepositoryException {
            super.checkPreconditions();
            SessionImpl.checkIndexOnName(sessionContext, relPath);
        }

        @Override
        public Node perform() throws RepositoryException {
            String oakPath = sessionContext.getOakPathOrThrowNotFound(relPath);
            String oakName = PathUtils.getName(oakPath);
            String parentPath = PathUtils.getParentPath(oakPath);
            NodeDelegate parent = dlg.getChild(parentPath);
            if (parent == null) {
                // is it a property?
                String grandParentPath = PathUtils.getParentPath(parentPath);
                NodeDelegate grandParent = dlg.getChild(grandParentPath);
                if (grandParent != null) {
                    String propName = PathUtils.getName(parentPath);
                    if (grandParent.getPropertyOrNull(propName) != null) {
                        throw new ConstraintViolationException(""Can't add new node to property."");
                    }
                }
                throw new PathNotFoundException(relPath);
            }
            if (parent.getChild(oakName) != null) {
                throw new ItemExistsException(relPath);
            }
            String ntName = primaryNodeTypeName;
            if (ntName == null) {
                DefinitionProvider dp = getDefinitionProvider();
                String childName = getOakName(PathUtils.getName(relPath));
                NodeDefinition def = dp.getDefinition(parent.getTree(), childName);
                ntName = def.getDefaultPrimaryTypeName();
                if (ntName == null) {
                    throw new ConstraintViolationException(""no matching child node definition found for "" + relPath);
                }
            }
            // TODO: figure out the right place for this check
            // throws on not found
            NodeType nt = getNodeTypeManager().getNodeType(ntName);
            if (nt.isAbstract() || nt.isMixin()) {
                throw new ConstraintViolationException();
            }
            // TODO: END
            NodeDelegate added = parent.addChild(oakName);
            if (added == null) {
                throw new ItemExistsException();
            }
            if (getPrimaryNodeType().hasOrderableChildNodes()) {
                dlg.setOrderableChildren(true);
            }
            NodeImpl<?> childNode = new NodeImpl<NodeDelegate>(added, sessionContext);
            childNode.internalSetPrimaryType(ntName);
            childNode.autoCreateItems();
            return childNode;
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-738_8ed779dc,Major,oak-jcr/src/main/java/org/apache/jackrabbit/oak/jcr/NodeImpl.java,215,272,"@Override
public Node perform() throws RepositoryException {
    String oakPath = sessionContext.getOakPathOrThrowNotFound(relPath);
    String oakName = PathUtils.getName(oakPath);
    String parentPath = PathUtils.getParentPath(oakPath);
    NodeDelegate parent = dlg.getChild(parentPath);
    if (parent == null) {
        // is it a property?
        String grandParentPath = PathUtils.getParentPath(parentPath);
        NodeDelegate grandParent = dlg.getChild(grandParentPath);
        if (grandParent != null) {
            String propName = PathUtils.getName(parentPath);
            if (grandParent.getPropertyOrNull(propName) != null) {
                throw new ConstraintViolationException(""Can't add new node to property."");
            }
        }
        throw new PathNotFoundException(relPath);
    }
    if (parent.getChild(oakName) != null) {
        throw new ItemExistsException(relPath);
    }
    String ntName = primaryNodeTypeName;
    if (ntName == null) {
        DefinitionProvider dp = getDefinitionProvider();
        String childName = getOakName(PathUtils.getName(relPath));
        NodeDefinition def = dp.getDefinition(parent.getTree(), childName);
        ntName = def.getDefaultPrimaryTypeName();
        if (ntName == null) {
            throw new ConstraintViolationException(""no matching child node definition found for "" + relPath);
        }
    }
    // TODO: figure out the right place for this check
    // throws on not found
    NodeType nt = getNodeTypeManager().getNodeType(ntName);
    if (nt.isAbstract() || nt.isMixin()) {
        throw new ConstraintViolationException();
    }
    // TODO: END
    NodeDelegate added = parent.addChild(oakName);
    if (added == null) {
        throw new ItemExistsException();
    }
    if (getPrimaryNodeType().hasOrderableChildNodes()) {
        dlg.setOrderableChildren(true);
    }
    NodeImpl<?> childNode = new NodeImpl<NodeDelegate>(added, sessionContext);
    childNode.internalSetPrimaryType(ntName);
    childNode.autoCreateItems();
    return childNode;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-740_35a7f014,Major,oak-solr-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/solr/index/SolrIndexUpdate.java,149,157,"private void deleteSubtreeWriter(SolrServer solrServer, String path) throws IOException, SolrServerException {
    // TODO verify the removal of the entire sub-hierarchy
    if (!path.startsWith(""/"")) {
        path = ""/"" + path;
    }
    solrServer.deleteByQuery(new StringBuilder(configuration.getPathField()).append(':').append(path).append(""*"").toString());
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-748_503451c1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/index/p2/strategy/ContentMirrorStoreStrategy.java,117,137,"@Override
public void insert(NodeBuilder index, String key, boolean unique, Iterable<String> values) throws CommitFailedException {
    NodeBuilder child = index.child(key);
    for (String add : values) {
        NodeBuilder indexEntry = child;
        for (String segment : PathUtils.elements(add)) {
            indexEntry = indexEntry.child(segment);
        }
        indexEntry.setProperty(""match"", true);
    }
    CountingNodeVisitor v = new CountingNodeVisitor(2);
    v.visit(child.getNodeState());
    int matchCount = v.getCount();
    if (matchCount == 0) {
        index.removeNode(key);
    } else if (unique && matchCount > 1) {
        throw new CommitFailedException(""Uniqueness constraint violated for key "" + key);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-766_6fc5ea9d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/AbstractNodeLocation.java,58,70,"@Override
public TreeLocation getChild(String name) {
    T child = getChildTree(name);
    if (child != null) {
        return createNodeLocation(child);
    }
    PropertyState prop = getPropertyState(name);
    if (prop != null) {
        return createPropertyLocation(this, name);
    }
    return new NullLocation(this, name);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-766_6fc5ea9d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,185,195,"@Override
public TreeImpl getChild(@Nonnull String name) {
    checkNotNull(name);
    enter();
    TreeImpl child = internalGetChild(name);
    if (child != null && canRead(child)) {
        return child;
    } else {
        return null;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-766_6fc5ea9d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,435,446,"/**
 * Get a tree for the tree identified by {@code path}.
 *
 * @param path the path to the child
 * @return a {@link Tree} instance for the child at {@code path} or
 *         {@code null} if no such tree exits or if the tree is not accessible.
 */
@CheckForNull
TreeImpl getTree(String path) {
    checkArgument(PathUtils.isAbsolute(path));
    TreeImpl child = this;
    for (String name : elements(path)) {
        child = child.internalGetChild(name);
        if (child == null) {
            return null;
        }
    }
    return (canRead(child)) ? child : null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-766_6fc5ea9d,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,528,532,"private TreeImpl internalGetChild(String childName) {
    return nodeBuilder.hasChildNode(childName) ? new TreeImpl(root, this, childName, pendingMoves) : null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-782_45b110e1,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/memory/MemoryNodeBuilder.java,240,271,"@Nonnull
private MutableNodeState write(long newRevision, boolean reconnect) {
    // make sure that all revision numbers up to the root gets updated
    if (!isRoot()) {
        parent.write(newRevision, reconnect);
        checkState(reconnect || exists(), ""This node has been removed"");
    }
    if (writeState == null || revision != root.revision) {
        // root never gets here since revision == root.revision
        assert (!isRoot());
        // The builder could have been reset, need to re-get base state
        baseState = parent.getBaseState(name);
        writeState = parent.getWriteState(name);
        if (writeState == null) {
            if (exists()) {
                writeState = new MutableNodeState(baseState);
            } else {
                writeState = new MutableNodeState(null);
            }
            // guaranteed by called parent.write()
            assert parent.writeState != null;
            parent.writeState.nodes.put(name, writeState);
        }
    }
    revision = newRevision;
    assert classInvariants();
    assert writeState != null;
    return writeState;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-846_7acb091a,Minor,oak-mongomk/src/main/java/org/apache/jackrabbit/mongomk/Collision.java,53,72,"boolean mark(DocumentStore store) {
    if (markCommitRoot(document, theirRev, store)) {
        return true;
    }
    @SuppressWarnings(""unchecked"")
    Map<String, String> revisions = (Map<String, String>) document.get(UpdateOp.REVISIONS);
    if (revisions.containsKey(theirRev)) {
        String value = revisions.get(theirRev);
        if (""true"".equals(value)) {
            // their commit wins, we have to mark ourRev
            Map<String, Object> newDoc = Utils.newMap();
            Utils.deepCopyMap(document, newDoc);
            MemoryDocumentStore.applyChanges(newDoc, ourOp);
            if (markCommitRoot(newDoc, ourRev, store)) {
                return true;
            }
        }
    }
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-846_7acb091a,Minor,oak-mongomk/src/main/java/org/apache/jackrabbit/mongomk/Collision.java,74,96,"private static boolean markCommitRoot(@Nonnull Map<String, Object> document, @Nonnull String revision, @Nonnull DocumentStore store) {
    @SuppressWarnings(""unchecked"")
    Map<String, Integer> commitRoots = (Map<String, Integer>) document.get(UpdateOp.COMMIT_ROOT);
    if (commitRoots != null) {
        Integer depth = commitRoots.get(revision);
        if (depth != null) {
            String p = Utils.getPathFromId((String) document.get(UpdateOp.ID));
            String commitRootPath = PathUtils.getAncestorPath(p, PathUtils.getDepth(p) - depth);
            UpdateOp op = new UpdateOp(commitRootPath, Utils.getIdFromPath(commitRootPath), false);
            op.setMapEntry(UpdateOp.COLLISIONS, revision, true);
            // TODO: detect concurrent commit of previously un-merged changes
            // TODO: check _commitRoot for revision is not 'true'
            store.createOrUpdate(DocumentStore.Collection.NODES, op);
            LOG.debug(""Marked collision on: {} for {} ({})"", new Object[] { commitRootPath, p, revision });
            return true;
        }
    }
    return false;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-846_7acb091a,Minor,oak-mongomk/src/main/java/org/apache/jackrabbit/mongomk/CollisionHandler.java,25,28,"@Override
void uncommittedModification(Revision uncommitted) {
// do nothing
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-846_7acb091a,Minor,oak-mongomk/src/main/java/org/apache/jackrabbit/mongomk/CollisionHandler.java,37,37,"/**
 * Callback for an uncommitted modification in {@link Revision}
 * <code>uncommitted</code>.
 *
 * @param uncommitted the uncommitted revision of the change.
 */
abstract void uncommittedModification(Revision uncommitted);"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-846_7acb091a,Minor,oak-mongomk/src/main/java/org/apache/jackrabbit/mongomk/Commit.java,264,337,"/**
 * Try to create or update the node. If there was a conflict, this method
 * throws an exception, even though the change is still applied.
 *
 * @param store the store
 * @param op the operation
 */
private void createOrUpdateNode(DocumentStore store, UpdateOp op) {
    Map<String, Object> map = store.createOrUpdate(Collection.NODES, op);
    if (baseRevision != null) {
        final AtomicReference<List<Revision>> collisions = new AtomicReference<List<Revision>>();
        Revision newestRev = mk.getNewestRevision(map, revision, new CollisionHandler() {

            @Override
            void uncommittedModification(Revision uncommitted) {
                if (collisions.get() == null) {
                    collisions.set(new ArrayList<Revision>());
                }
                collisions.get().add(uncommitted);
            }
        });
        String conflictMessage = null;
        if (newestRev == null) {
            if (op.isDelete || !op.isNew) {
                conflictMessage = ""The node "" + op.path + "" does not exist or is already deleted"";
            }
        } else {
            if (op.isNew) {
                conflictMessage = ""The node "" + op.path + "" was already added in revision\n"" + newestRev;
            } else if (mk.isRevisionNewer(newestRev, baseRevision) && (op.isDelete || isConflicting(map, op))) {
                conflictMessage = ""The node "" + op.path + "" was changed in revision\n"" + newestRev + "", which was applied after the base revision\n"" + baseRevision;
            }
        }
        if (conflictMessage != null) {
            conflictMessage += "", before\n"" + revision + ""; document:\n"" + map.toString().replaceAll("", _"", "",\n_"").replaceAll(""}, "", ""},\n"") + "",\nrevision order:\n"" + mk.getRevisionComparator();
            throw new MicroKernelException(conflictMessage);
        }
        // on a node are possible if property updates do not overlap)
        if (collisions.get() != null && isConflicting(map, op)) {
            for (Revision r : collisions.get()) {
                // mark collisions on commit root
                Collision c = new Collision(map, r, op, revision);
                boolean success = c.mark(store);
                if (!success) {
                // TODO: fail this commit
                }
            }
        }
    }
    int size = Utils.estimateMemoryUsage(map);
    if (size > MAX_DOCUMENT_SIZE) {
        UpdateOp[] split = splitDocument(map);
        // TODO check if the new main document is actually smaller;
        // otherwise, splitting doesn't make sense
        // the old version
        UpdateOp old = split[0];
        if (old != null) {
            store.createOrUpdate(Collection.NODES, old);
        }
        // the (shrunken) main document
        UpdateOp main = split[1];
        if (main != null) {
            store.createOrUpdate(Collection.NODES, main);
        }
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-846_7acb091a,Minor,oak-mongomk/src/main/java/org/apache/jackrabbit/mongomk/Commit.java,270,276,"@Override
void uncommittedModification(Revision uncommitted) {
    if (collisions.get() == null) {
        collisions.set(new ArrayList<Revision>());
    }
    collisions.get().add(uncommitted);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-846_7acb091a,Minor,oak-mongomk/src/main/java/org/apache/jackrabbit/mongomk/MongoMK.java,1124,1173,"/**
 * Get the revision of the latest change made to this node.
 *
 * @param nodeMap the document
 * @param changeRev the revision of the current change
 * @param handler the conflict handler, which is called for un-committed revisions
 *                preceding <code>before</code>.
 * @return the revision, or null if deleted
 */
@SuppressWarnings(""unchecked"")
@Nullable
Revision getNewestRevision(Map<String, Object> nodeMap, Revision changeRev, CollisionHandler handler) {
    if (nodeMap == null) {
        return null;
    }
    SortedSet<String> revisions = new TreeSet<String>(Collections.reverseOrder());
    if (nodeMap.containsKey(UpdateOp.REVISIONS)) {
        revisions.addAll(((Map<String, String>) nodeMap.get(UpdateOp.REVISIONS)).keySet());
    }
    if (nodeMap.containsKey(UpdateOp.COMMIT_ROOT)) {
        revisions.addAll(((Map<String, Integer>) nodeMap.get(UpdateOp.COMMIT_ROOT)).keySet());
    }
    Map<String, String> deletedMap = (Map<String, String>) nodeMap.get(UpdateOp.DELETED);
    if (deletedMap != null) {
        revisions.addAll(deletedMap.keySet());
    }
    Revision newestRev = null;
    for (String r : revisions) {
        Revision propRev = Revision.fromString(r);
        if (isRevisionNewer(propRev, changeRev)) {
            // we have seen a previous change from another cluster node
            // (which might be conflicting or not) - we need to make
            // sure this change is visible from now on
            publishRevision(propRev, changeRev);
        }
        if (newestRev == null || isRevisionNewer(propRev, newestRev)) {
            if (!propRev.equals(changeRev)) {
                if (!isValidRevision(propRev, changeRev, nodeMap, new HashSet<Revision>())) {
                    handler.uncommittedModification(propRev);
                } else {
                    newestRev = propRev;
                }
            }
        }
    }
    if (newestRev == null) {
        return null;
    }
    if (deletedMap != null) {
        String value = deletedMap.get(newestRev.toString());
        if (""true"".equals(value)) {
            // deleted in the newest revision
            return null;
        }
    }
    return newestRev;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-847_65aa40dd,Minor,oak-mongomk/src/main/java/org/apache/jackrabbit/mongomk/MemoryDocumentStore.java,168,199,"private static boolean checkConditions(Map<String, Object> target, UpdateOp update) {
    for (Map.Entry<String, Operation> change : update.changes.entrySet()) {
        Operation op = change.getValue();
        if (op.type == Operation.Type.CONTAINS_MAP_ENTRY) {
            String k = change.getKey();
            String[] kv = k.split(""\\."");
            Object value = target.get(kv[0]);
            if (value == null) {
                if (Boolean.TRUE.equals(op.value)) {
                    return false;
                }
            } else {
                if (value instanceof java.util.Collection) {
                    java.util.Collection<?> col = (java.util.Collection<?>) value;
                    if (Boolean.TRUE.equals(op.value)) {
                        if (!col.contains(kv[1])) {
                            return false;
                        }
                    } else {
                        if (col.contains(kv[1])) {
                            return false;
                        }
                    }
                } else {
                    return false;
                }
            }
        }
    }
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-888_6d82cb64,Major,oak-commons/src/main/java/org/apache/jackrabbit/oak/commons/PathUtils.java,185,202,"/**
 * Calculate the number of elements in the path. The root path has zero
 * elements.
 *
 * @param path the path
 * @return the number of elements
 */
public static int getDepth(String path) {
    assert isValid(path);
    int count = 1, i = 0;
    if (isAbsolutePath(path)) {
        if (denotesRootPath(path)) {
            return 0;
        }
        i++;
    }
    while (true) {
        i = path.indexOf('/', i) + 1;
        if (i == 0) {
            return count;
        }
        count++;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-926_e1ae968c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/NodeDocument.java,159,172,"/**
 * Returns <code>true</code> if the given <code>revision</code> is marked
 * committed in <strong>this</strong> document including previous documents.
 *
 * @param revision the revision.
 * @return <code>true</code> if committed; <code>false</code> otherwise.
 */
public boolean isCommitted(@Nonnull Revision revision) {
    String rev = checkNotNull(revision).toString();
    String value = getLocalRevisions().get(rev);
    if (value != null) {
        return Utils.isCommitted(value);
    }
    // check previous docs
    for (NodeDocument prev : getPreviousDocs(revision, REVISIONS)) {
        if (prev.containsRevision(revision)) {
            return prev.isCommitted(revision);
        }
    }
    return false;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-926_e1ae968c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/NodeDocument.java,584,667,"/**
 * Returns update operations to split this document. The implementation may
 * decide to not return any operations if no splitting is required.
 *
 * @param context the revision context.
 * @return the split operations.
 */
@Nonnull
public Iterable<UpdateOp> split(@Nonnull RevisionContext context) {
    // only consider if there are enough commits
    if (getLocalRevisions().size() + getLocalCommitRoot().size() <= REVISIONS_SPLIT_OFF_SIZE) {
        return Collections.emptyList();
    }
    String id = getId();
    SortedMap<Revision, Range> previous = getPreviousRanges();
    // what's the most recent previous revision?
    Revision recentPrevious = null;
    for (Revision rev : previous.keySet()) {
        if (rev.getClusterId() != context.getClusterId()) {
            continue;
        }
        if (recentPrevious == null || isRevisionNewer(context, rev, recentPrevious)) {
            recentPrevious = rev;
        }
    }
    Map<String, NavigableMap<Revision, String>> splitValues = new HashMap<String, NavigableMap<Revision, String>>();
    for (String property : new String[] { REVISIONS, COMMIT_ROOT, DELETED }) {
        NavigableMap<Revision, String> splitMap = new TreeMap<Revision, String>(context.getRevisionComparator());
        splitValues.put(property, splitMap);
        Map<String, String> valueMap = getLocalMap(property);
        // most recent previous split revision
        for (Map.Entry<String, String> entry : valueMap.entrySet()) {
            Revision rev = Revision.fromString(entry.getKey());
            if (rev.getClusterId() != context.getClusterId()) {
                continue;
            }
            if (recentPrevious == null || isRevisionNewer(context, rev, recentPrevious)) {
                if (isCommitted(rev)) {
                    splitMap.put(rev, entry.getValue());
                }
            }
        }
    }
    List<UpdateOp> splitOps = Collections.emptyList();
    int numValues = 0;
    Revision high = null;
    Revision low = null;
    for (NavigableMap<Revision, String> splitMap : splitValues.values()) {
        // keep the most recent in the main document
        if (!splitMap.isEmpty()) {
            splitMap.remove(splitMap.lastKey());
        }
        if (splitMap.isEmpty()) {
            continue;
        }
        // remember highest / lowest revision
        if (high == null || isRevisionNewer(context, splitMap.lastKey(), high)) {
            high = splitMap.lastKey();
        }
        if (low == null || isRevisionNewer(context, low, splitMap.firstKey())) {
            low = splitMap.firstKey();
        }
        numValues += splitMap.size();
    }
    if (high != null && low != null && numValues >= REVISIONS_SPLIT_OFF_SIZE) {
        // enough revisions to split off
        splitOps = new ArrayList<UpdateOp>(2);
        // move to another document
        UpdateOp main = new UpdateOp(id, false);
        main.setMapEntry(PREVIOUS, high.toString(), low.toString());
        UpdateOp old = new UpdateOp(Utils.getPreviousIdFor(id, high), true);
        old.set(ID, old.getKey());
        for (String property : splitValues.keySet()) {
            NavigableMap<Revision, String> splitMap = splitValues.get(property);
            for (Map.Entry<Revision, String> entry : splitMap.entrySet()) {
                String r = entry.getKey().toString();
                main.removeMapEntry(property, r);
                old.setMapEntry(property, r, entry.getValue());
            }
            splitOps.add(old);
            splitOps.add(main);
        }
    }
    return splitOps;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-926_e1ae968c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/NodeDocument.java,669,699,"@Override
@Nonnull
protected Map<?, ?> transformAndSeal(@Nonnull Map<Object, Object> map, @Nullable String key, int level) {
    if (level == 1) {
        if (PREVIOUS.equals(key)) {
            SortedMap<Revision, Range> transformed = new TreeMap<Revision, Range>(new Comparator<Revision>() {

                @Override
                public int compare(Revision o1, Revision o2) {
                    // in reverse order!
                    int c = o2.compareRevisionTime(o1);
                    if (c == 0) {
                        c = o1.getClusterId() < o2.getClusterId() ? -1 : (o1.getClusterId() == o2.getClusterId() ? 0 : 1);
                    }
                    return c;
                }
            });
            for (Map.Entry<Object, Object> entry : map.entrySet()) {
                Revision high = Revision.fromString(entry.getKey().toString());
                Revision low = Revision.fromString(entry.getValue().toString());
                transformed.put(high, new Range(high, low));
            }
            return Collections.unmodifiableSortedMap(transformed);
        }
    }
    return super.transformAndSeal(map, key, level);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-926_e1ae968c,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/plugins/mongomk/NodeDocument.java,707,715,"/**
 * Returns previous revision ranges for this document. The revision keys are
 * sorted descending, newest first!
 *
 * @return the previous ranges for this document.
 */
@Nonnull
SortedMap<Revision, Range> getPreviousRanges() {
    @SuppressWarnings(""unchecked"")
    SortedMap<Revision, Range> previous = (SortedMap<Revision, Range>) get(PREVIOUS);
    if (previous == null) {
        previous = EMPTY_RANGE_MAP;
    }
    return previous;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,148,159,"@Override
public String getPath() {
    if (parent == null) {
        return name;
    } else {
        String path = parent.getPath();
        return path.isEmpty() ? name : path + '/' + name;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,234,247,"@Override
public TreeImpl getChild(String name) {
    NodeStateBuilder childBuilder = builder.getChildBuilder(name);
    if (childBuilder == null) {
        return null;
    } else {
        NodeState childBaseState = baseState == null ? null : baseState.getChildNode(name);
        return new TreeImpl(store, childBaseState, childBuilder, this, name, listener);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,305,322,"@Override
public Iterable<Tree> getChildren() {
    return new Iterable<Tree>() {

        @Override
        public Iterator<Tree> iterator() {
            Iterator<? extends ChildNodeEntry> childEntries = getNodeState().getChildNodeEntries().iterator();
            return Iterators.map(childEntries, new Function1<ChildNodeEntry, Tree>() {

                @Override
                public Tree apply(ChildNodeEntry entry) {
                    NodeStateBuilder childBuilder = builder.getChildBuilder(entry.getName());
                    return new TreeImpl(store, childBuilder.getNodeState(), childBuilder, TreeImpl.this, entry.getName(), listener);
                }
            });
        }
    };
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,308,320,"@Override
public Iterator<Tree> iterator() {
    Iterator<? extends ChildNodeEntry> childEntries = getNodeState().getChildNodeEntries().iterator();
    return Iterators.map(childEntries, new Function1<ChildNodeEntry, Tree>() {

        @Override
        public Tree apply(ChildNodeEntry entry) {
            NodeStateBuilder childBuilder = builder.getChildBuilder(entry.getName());
            return new TreeImpl(store, childBuilder.getNodeState(), childBuilder, TreeImpl.this, entry.getName(), listener);
        }
    });
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,314,318,"@Override
public Tree apply(ChildNodeEntry entry) {
    NodeStateBuilder childBuilder = builder.getChildBuilder(entry.getName());
    return new TreeImpl(store, childBuilder.getNodeState(), childBuilder, TreeImpl.this, entry.getName(), listener);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,324,330,"@Override
public Tree addChild(String name) {
    if (builder.addNode(name) != null) {
        listener.addChild(this, name);
    }
    return getChild(name);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,332,339,"@Override
public boolean removeChild(String name) {
    boolean result = builder.removeNode(name);
    if (result) {
        listener.removeChild(this, name);
    }
    return result;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,341,348,"@Override
public PropertyState setProperty(String name, CoreValue value) {
    PropertyState property = builder.setProperty(name, value);
    if (listener != null) {
        listener.setProperty(this, name, value);
    }
    return property;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,350,357,"@Override
public PropertyState setProperty(String name, List<CoreValue> values) {
    PropertyState property = builder.setProperty(name, values);
    if (listener != null) {
        listener.setProperty(this, name, values);
    }
    return property;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,359,365,"@Override
public void removeProperty(String name) {
    builder.removeProperty(name);
    if (listener != null) {
        listener.removeProperty(this, name);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,376,390,"/**
 * Move this tree to the parent at {@code destParent} with the new name
 * {@code destName}.
 *
 * @param destParent  new parent for this tree
 * @param destName  new name for this tree
 * @return  {@code true} if successful, {@code false otherwise}. I.e.
 * when {@code destName} already exists at {@code destParent}
 */
public boolean move(TreeImpl destParent, String destName) {
    boolean result = builder.moveTo(destParent.builder, destName);
    if (result) {
        TreeImpl oldParent = parent;
        String oldName = name;
        name = destName;
        parent = destParent;
        if (listener != null) {
            listener.move(oldParent, oldName, this);
        }
    }
    return result;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,400,409,"/**
 * Copy this tree to the parent at {@code destParent} with the name {@code destName}.
 *
 * @param destParent  parent for the copied tree
 * @param destName  name for the copied tree
 * @return  {@code true} if successful, {@code false otherwise}. I.e.
 * when {@code destName} already exists at {@code destParent}
 */
public boolean copy(TreeImpl destParent, String destName) {
    boolean result = builder.copyTo(destParent.builder, destName);
    if (result) {
        if (listener != null) {
            listener.copy(parent, name, destParent.getChild(destName));
        }
        return true;
    }
    return result;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/core/TreeImpl.java,413,415,"// ------------------------------------------------------------< private >---
private NodeState getNodeState() {
    return builder.getNodeState();
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,38,40,"public static NodeStateBuilder create(NodeStateBuilderContext context) {
    return new KernelNodeStateBuilder(context, """");
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,43,46,"@Override
public NodeState getNodeState() {
    return context.getNodeState(path);
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,48,53,"@Override
public NodeStateBuilder getChildBuilder(String name) {
    return hasChild(name) ? new KernelNodeStateBuilder(context, PathUtils.concat(path, name)) : null;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,55,65,"@Override
public NodeStateBuilder addNode(String name, NodeState nodeState) {
    if (hasChild(name)) {
        return null;
    } else {
        String targetPath = PathUtils.concat(path, name);
        context.addNode(nodeState, targetPath);
        return new KernelNodeStateBuilder(context, targetPath);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,67,77,"@Override
public NodeStateBuilder addNode(String name) {
    if (hasChild(name)) {
        return null;
    } else {
        String targetPath = PathUtils.concat(path, name);
        context.addNode(targetPath);
        return new KernelNodeStateBuilder(context, targetPath);
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,79,88,"@Override
public boolean removeNode(String name) {
    if (hasChild(name)) {
        context.removeNode(PathUtils.concat(path, name));
        return true;
    } else {
        return false;
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,90,100,"@Override
public PropertyState setProperty(String name, CoreValue value) {
    PropertyState property = new PropertyStateImpl(name, value);
    if (hasProperty(name)) {
        context.setProperty(property, path);
    } else {
        context.addProperty(property, path);
    }
    return property;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,102,112,"@Override
public PropertyState setProperty(String name, List<CoreValue> values) {
    PropertyState property = new PropertyStateImpl(name, values);
    if (hasProperty(name)) {
        context.setProperty(property, path);
    } else {
        context.addProperty(property, path);
    }
    return property;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,114,119,"@Override
public void removeProperty(String name) {
    if (hasProperty(name)) {
        context.removeProperty(PathUtils.concat(path, name));
    }
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,121,137,"@Override
public boolean moveTo(NodeStateBuilder destParent, String destName) {
    if (!(destParent instanceof KernelNodeStateBuilder)) {
        throw new IllegalArgumentException(""Alien builder for destParent"");
    }
    if (destParent.getChildBuilder(destName) != null) {
        return false;
    }
    KernelNodeStateBuilder destParentBuilder = (KernelNodeStateBuilder) destParent;
    String destPath = PathUtils.concat(destParentBuilder.path, destName);
    context.moveNode(path, destPath);
    path = destPath;
    return true;
}"
jackrabbit-oak,remotes/origin/bugs-dot-jar_OAK-93_0be7e8f0,Major,oak-core/src/main/java/org/apache/jackrabbit/oak/kernel/KernelNodeStateBuilder.java,139,154,"@Override
public boolean copyTo(NodeStateBuilder destParent, String destName) {
    if (!(destParent instanceof KernelNodeStateBuilder)) {
        throw new IllegalArgumentException(""Alien builder for destParent"");
    }
    if (destParent.getChildBuilder(destName) != null) {
        return false;
    }
    KernelNodeStateBuilder destParentBuilder = (KernelNodeStateBuilder) destParent;
    String destPath = PathUtils.concat(destParentBuilder.path, destName);
    context.copyNode(path, destPath);
    return true;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,102,104,"/**
 * Provides access to the classes discovered so far. If no calls have been made to
 * any of the {@code find()} methods, this set will be empty.
 *
 * @return the set of classes that have been discovered.
 */
public Set<Class<?>> getClasses() {
    return classMatches;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,110,112,"/**
 * Returns the matching resources.
 * @return A Set of URIs that match the criteria.
 */
public Set<URI> getResources() {
    return resourceMatches;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,121,123,"/**
 * Returns the classloader that will be used for scanning for classes. If no explicit
 * ClassLoader has been set by the calling, the context class loader will be used.
 *
 * @return the ClassLoader that will be used to scan for classes
 */
public ClassLoader getClassLoader() {
    return classloader != null ? classloader : (classloader = Loader.getClassLoader(ResolverUtil.class, null));
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,131,131,"/**
 * Sets an explicit ClassLoader that should be used when scanning for classes. If none
 * is set then the context classloader will be used.
 *
 * @param classloader a ClassLoader to use when scanning for classes
 */
public void setClassLoader(final ClassLoader classloader) {
    this.classloader = classloader;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,140,148,"/**
 * Attempts to discover classes that pass the test. Accumulated
 * classes can be accessed by calling {@link #getClasses()}.
 *
 * @param test the test to determine matching classes
 * @param packageNames one or more package names to scan (including subpackages) for classes
 */
public void find(final Test test, final String... packageNames) {
    if (packageNames == null) {
        return;
    }
    for (final String pkg : packageNames) {
        findInPackage(test, pkg);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,160,203,"/**
 * Scans for classes starting at the package provided and descending into subpackages.
 * Each class is offered up to the Test as it is discovered, and if the Test returns
 * true the class is retained.  Accumulated classes can be fetched by calling
 * {@link #getClasses()}.
 *
 * @param test an instance of {@link Test} that will be used to filter classes
 * @param packageName the name of the package from which to start scanning for
 *        classes, e.g. {@code net.sourceforge.stripes}
 */
public void findInPackage(final Test test, String packageName) {
    packageName = packageName.replace('.', '/');
    final ClassLoader loader = getClassLoader();
    Enumeration<URL> urls;
    try {
        urls = loader.getResources(packageName);
    } catch (final IOException ioe) {
        LOGGER.warn(""Could not read package: "" + packageName, ioe);
        return;
    }
    while (urls.hasMoreElements()) {
        try {
            final URL url = urls.nextElement();
            final String urlPath = extractPath(url);
            LOGGER.info(""Scanning for classes in ["" + urlPath + ""] matching criteria: "" + test);
            // Check for a jar in a war in JBoss
            if (VFSZIP.equals(url.getProtocol())) {
                final String path = urlPath.substring(0, urlPath.length() - packageName.length() - 2);
                final URL newURL = new URL(url.getProtocol(), url.getHost(), path);
                @SuppressWarnings(""resource"")
                final JarInputStream stream = new JarInputStream(newURL.openStream());
                try {
                    loadImplementationsInJar(test, packageName, path, stream);
                } finally {
                    close(stream, newURL);
                }
            } else if (BUNDLE_RESOURCE.equals(url.getProtocol())) {
                loadImplementationsInBundle(test, packageName);
            } else {
                final File file = new File(urlPath);
                if (file.isDirectory()) {
                    loadImplementationsInDirectory(test, packageName, file);
                } else {
                    loadImplementationsInJar(test, packageName, file);
                }
            }
        } catch (final IOException ioe) {
            LOGGER.warn(""could not read entries"", ioe);
        }
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,205,235,"String extractPath(final URL url) throws UnsupportedEncodingException {
    // same as getFile but without the Query portion
    String urlPath = url.getPath();
    // I would be surprised if URL.getPath() ever starts with ""jar:"" but no harm in checking
    if (urlPath.startsWith(""jar:"")) {
        urlPath = urlPath.substring(4);
    }
    // For jar: URLs, the path part starts with ""file:""
    if (urlPath.startsWith(""file:"")) {
        urlPath = urlPath.substring(5);
    }
    // If it was in a JAR, grab the path to the jar
    if (urlPath.indexOf('!') > 0) {
        urlPath = urlPath.substring(0, urlPath.indexOf('!'));
    }
    // LOG4J2-445
    // Finally, decide whether to URL-decode the file name or not...
    final String protocol = url.getProtocol();
    final List<String> neverDecode = Arrays.asList(VFSZIP, BUNDLE_RESOURCE);
    if (neverDecode.contains(protocol)) {
        return urlPath;
    }
    if (new File(urlPath).exists()) {
        // if URL-encoded file exists, don't decode it
        return urlPath;
    }
    urlPath = URLDecoder.decode(urlPath, Constants.UTF_8.name());
    return urlPath;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,237,248,"private void loadImplementationsInBundle(final Test test, final String packageName) {
    // Do not remove the cast on the next line as removing it will cause a compile error on Java 7.
    @SuppressWarnings(""RedundantCast"")
    final BundleWiring wiring = (BundleWiring) FrameworkUtil.getBundle(ResolverUtil.class).adapt(BundleWiring.class);
    @SuppressWarnings(""unchecked"")
    final Collection<String> list = (Collection<String>) wiring.listResources(packageName, ""*.class"", BundleWiring.LISTRESOURCES_RECURSE);
    for (final String name : list) {
        addIfMatching(test, name);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,263,281,"/**
 * Finds matches in a physical directory on a filesystem.  Examines all
 * files within a directory - if the File object is not a directory, and ends with <i>.class</i>
 * the file is loaded and tested to see if it is acceptable according to the Test.  Operates
 * recursively to find classes within a folder structure matching the package structure.
 *
 * @param test a Test used to filter the classes that are discovered
 * @param parent the package name up to this directory in the package hierarchy.  E.g. if
 *        /classes is in the classpath and we wish to examine files in /classes/org/apache then
 *        the values of <i>parent</i> would be <i>org/apache</i>
 * @param location a File object representing a directory
 */
private void loadImplementationsInDirectory(final Test test, final String parent, final File location) {
    final File[] files = location.listFiles();
    if (files == null) {
        return;
    }
    StringBuilder builder;
    for (final File file : files) {
        builder = new StringBuilder();
        builder.append(parent).append('/').append(file.getName());
        final String packageOrClass = parent == null ? file.getName() : builder.toString();
        if (file.isDirectory()) {
            loadImplementationsInDirectory(test, packageOrClass, file);
        } else if (isTestApplicable(test, file.getName())) {
            addIfMatching(test, packageOrClass);
        }
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,296,311,"/**
 * Finds matching classes within a jar files that contains a folder structure
 * matching the package structure.  If the File is not a JarFile or does not exist a warning
 * will be logged, but no error will be raised.
 *
 * @param test a Test used to filter the classes that are discovered
 * @param parent the parent package under which classes must be in order to be considered
 * @param jarFile the jar file to be examined for classes
 */
private void loadImplementationsInJar(final Test test, final String parent, final File jarFile) {
    @SuppressWarnings(""resource"")
    JarInputStream jarStream = null;
    try {
        jarStream = new JarInputStream(new FileInputStream(jarFile));
        loadImplementationsInJar(test, parent, jarFile.getPath(), jarStream);
    } catch (final FileNotFoundException ex) {
        LOGGER.error(""Could not search jar file '"" + jarFile + ""' for classes matching criteria: "" + test + "" file not found"", ex);
    } catch (final IOException ioe) {
        LOGGER.error(""Could not search jar file '"" + jarFile + ""' for classes matching criteria: "" + test + "" due to an IOException"", ioe);
    } finally {
        close(jarStream, jarFile);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,336,352,"/**
 * Finds matching classes within a jar files that contains a folder structure
 * matching the package structure.  If the File is not a JarFile or does not exist a warning
 * will be logged, but no error will be raised.
 *
 * @param test a Test used to filter the classes that are discovered
 * @param parent the parent package under which classes must be in order to be considered
 * @param stream The jar InputStream
 */
private void loadImplementationsInJar(final Test test, final String parent, final String path, final JarInputStream stream) {
    try {
        JarEntry entry;
        while ((entry = stream.getNextJarEntry()) != null) {
            final String name = entry.getName();
            if (!entry.isDirectory() && name.startsWith(parent) && isTestApplicable(test, name)) {
                addIfMatching(test, name);
            }
        }
    } catch (final IOException ioe) {
        LOGGER.error(""Could not search jar file '"" + path + ""' for classes matching criteria: "" + test + "" due to an IOException"", ioe);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,361,387,"/**
 * Add the class designated by the fully qualified class name provided to the set of
 * resolved classes if and only if it is approved by the Test supplied.
 *
 * @param test the test used to determine if the class matches
 * @param fqn the fully qualified name of a class
 */
protected void addIfMatching(final Test test, final String fqn) {
    try {
        final ClassLoader loader = getClassLoader();
        if (test.doesMatchClass()) {
            final String externalName = fqn.substring(0, fqn.indexOf('.')).replace('/', '.');
            if (LOGGER.isDebugEnabled()) {
                LOGGER.debug(""Checking to see if class "" + externalName + "" matches criteria ["" + test + ']');
            }
            final Class<?> type = loader.loadClass(externalName);
            if (test.matches(type)) {
                classMatches.add(type);
            }
        }
        if (test.doesMatchResource()) {
            URL url = loader.getResource(fqn);
            if (url == null) {
                url = loader.getResource(fqn.substring(1));
            }
            if (url != null && test.matches(url.toURI())) {
                resourceMatches.add(url.toURI());
            }
        }
    } catch (final Throwable t) {
        LOGGER.warn(""Could not examine class '"" + fqn, t);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,400,400,"/**
 * Will be called repeatedly with candidate classes. Must return True if a class
 * is to be included in the results, false otherwise.
 * @param type The Class to match against.
 * @return true if the Class matches.
 */
boolean matches(Class<?> type);"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1008_0c20bfd8,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/util/ResolverUtil.java,407,407,"/**
 * Test for a resource.
 * @param resource The URI to the resource.
 * @return true if the resource matches.
 */
boolean matches(URI resource);"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-101_c79a743b,Major,core/src/main/java/org/apache/logging/log4j/core/appender/SyslogAppender.java,78,129,"/**
 * Create a SyslogAppender.
 * @param host The name of the host to connect to.
 * @param portNum The port to connect to on the target host.
 * @param protocol The Protocol to use.
 * @param delay The interval in which failed writes should be retried.
 * @param name The name of the Appender.
 * @param immediateFlush ""true"" if data should be flushed on each write.
 * @param suppress ""true"" if exceptions should be hidden from the application, ""false"" otherwise.
 * The default is ""true"".
 * @param facility The Facility is used to try to classify the message.
 * @param id The default structured data id to use when formatting according to RFC 5424.
 * @param ein The IANA enterprise number.
 * @param includeMDC Indicates whether data from the ThreadContextMap will be included in the RFC 5424 Syslog
 * record. Defaults to ""true:.
 * @param mdcId The id to use for the MDC Structured Data Element.
 * @param includeNL If true, a newline will be appended to the end of the syslog record. The default is false.
 * @param appName The value to use as the APP-NAME in the RFC 5424 syslog record.
 * @param msgId The default value to be used in the MSGID field of RFC 5424 syslog records.
 * @param excludes A comma separated list of mdc keys that should be excluded from the LogEvent.
 * @param includes A comma separated list of mdc keys that should be included in the FlumeEvent.
 * @param required A comma separated list of mdc keys that must be present in the MDC.
 * @param format If set to ""RFC5424"" the data will be formatted in accordance with RFC 5424. Otherwise,
 * it will be formatted as a BSD Syslog record.
 * @param filter A Filter to determine if the event should be handled by this Appender.
 * @param config The Configuration.
 * @param charset The character set to use when converting the syslog String to a byte array.
 * @return A SyslogAppender.
 */
@PluginFactory
public static SyslogAppender createAppender(@PluginAttr(""host"") String host, @PluginAttr(""port"") String portNum, @PluginAttr(""protocol"") String protocol, @PluginAttr(""reconnectionDelay"") String delay, @PluginAttr(""name"") String name, @PluginAttr(""immediateFlush"") String immediateFlush, @PluginAttr(""suppressExceptions"") String suppress, @PluginAttr(""facility"") String facility, @PluginAttr(""id"") String id, @PluginAttr(""enterpriseNumber"") String ein, @PluginAttr(""includeMDC"") String includeMDC, @PluginAttr(""mdcId"") String mdcId, @PluginAttr(""newLine"") String includeNL, @PluginAttr(""appName"") String appName, @PluginAttr(""messageId"") String msgId, @PluginAttr(""mdcExcludes"") String excludes, @PluginAttr(""mdcIncludes"") String includes, @PluginAttr(""mdcRequired"") String required, @PluginAttr(""format"") String format, @PluginElement(""filters"") Filter filter, @PluginConfiguration Configuration config, @PluginAttr(""charset"") String charset) {
    boolean isFlush = immediateFlush == null ? true : Boolean.valueOf(immediateFlush);
    boolean handleExceptions = suppress == null ? true : Boolean.valueOf(suppress);
    int reconnectDelay = delay == null ? 0 : Integer.parseInt(delay);
    int port = portNum == null ? 0 : Integer.parseInt(portNum);
    Charset c = Charset.isSupported(""UTF-8"") ? Charset.forName(""UTF-8"") : Charset.defaultCharset();
    if (charset != null) {
        if (Charset.isSupported(charset)) {
            c = Charset.forName(charset);
        } else {
            LOGGER.error(""Charset "" + charset + "" is not supported for layout, using "" + c.displayName());
        }
    }
    Layout layout = (format.equalsIgnoreCase(RFC5424)) ? RFC5424Layout.createLayout(facility, id, ein, includeMDC, mdcId, includeNL, appName, msgId, excludes, includes, required, charset, config) : SyslogLayout.createLayout(facility, includeNL, charset);
    if (name == null) {
        LOGGER.error(""No name provided for SyslogAppender"");
        return null;
    }
    AbstractSocketManager manager = createSocketManager(protocol, host, port, reconnectDelay);
    if (manager == null) {
        return null;
    }
    return new SyslogAppender(name, layout, filter, handleExceptions, isFlush, manager);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1025_a96b455c,Major,log4j-jul/src/main/java/org/apache/logging/log4j/jul/DefaultLevelConverter.java,62,64,"/*
     * TODO consider making public.
     */
private void mapJulToLog4j(java.util.logging.Level julLevel, Level level) {
    julToLog4j.put(julLevel, level);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1025_a96b455c,Major,log4j-jul/src/main/java/org/apache/logging/log4j/jul/DefaultLevelConverter.java,69,71,"/*
     * TODO consider making public.
     */
private void mapLog4jToJul(Level level, java.util.logging.Level julLevel) {
    log4jToJul.put(level, julLevel);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1025_a96b455c,Major,log4j-jul/src/main/java/org/apache/logging/log4j/jul/DefaultLevelConverter.java,78,81,"@Override
public Level toLevel(final java.util.logging.Level javaLevel) {
    return julToLog4j.get(javaLevel);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-102_7f391872,Critical,core/src/main/java/org/apache/logging/log4j/core/net/Priority.java,45,47,"/**
 * Returns the priority value based on the Facility and Log Level.
 * @param facility The Facility.
 * @param level The Level.
 * @return The integer value of the priority.
 */
public static int getPriority(Facility facility, Level level) {
    return facility.getCode() << 3 + Severity.getSeverity(level).getCode();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1058_c8fd3c53,Minor,log4j-slf4j-impl/src/main/java/org/apache/logging/slf4j/Log4jMarker.java,86,89,"@Override
public boolean contains(final org.slf4j.Marker marker) {
    return this.marker.isInstanceOf(marker.getName());
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1061_86d8944f,Major,log4j-slf4j-impl/src/main/java/org/apache/logging/slf4j/Log4jMarker.java,57,60,"@Override
public boolean remove(final Marker marker) {
    return this.marker.remove(MarkerManager.getMarker(marker.getName()));
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1062_4cf831b6,Major,log4j-slf4j-impl/src/main/java/org/apache/logging/slf4j/Log4jMarker.java,51,55,"@Override
public void add(final Marker marker) {
    final Marker m = factory.getMarker(marker.getName());
    this.marker.addParents(((Log4jMarker) m).getLog4jMarker());
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1067_4786a739,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/impl/ThrowableProxy.java,204,213,"@SuppressWarnings(""ThrowableResultOfMethodCallIgnored"")
private void formatCause(final StringBuilder sb, final ThrowableProxy cause, final List<String> ignorePackages) {
    if (cause == null) {
        return;
    }
    sb.append(""Caused by: "").append(cause).append(EOL);
    this.formatElements(sb, cause.commonElementCount, cause.getThrowable().getStackTrace(), cause.extendedStackTrace, ignorePackages);
    this.formatCause(sb, cause.causeProxy, ignorePackages);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1068_e7bbeceb,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/pattern/ExtendedThrowablePatternConverter.java,60,93,"/**
 * {@inheritDoc}
 */
@Override
public void format(final LogEvent event, final StringBuilder toAppendTo) {
    ThrowableProxy proxy = null;
    if (event instanceof Log4jLogEvent) {
        proxy = ((Log4jLogEvent) event).getThrownProxy();
    }
    final Throwable throwable = event.getThrown();
    if (throwable != null && options.anyLines()) {
        if (proxy == null) {
            super.format(event, toAppendTo);
            return;
        }
        final String extStackTrace = proxy.getExtendedStackTraceAsString(options.getPackages());
        final int len = toAppendTo.length();
        if (len > 0 && !Character.isWhitespace(toAppendTo.charAt(len - 1))) {
            toAppendTo.append(' ');
        }
        if (!options.allLines() || !Constants.LINE_SEPARATOR.equals(options.getSeparator())) {
            final StringBuilder sb = new StringBuilder();
            final String[] array = extStackTrace.split(Constants.LINE_SEPARATOR);
            final int limit = options.minLines(array.length) - 1;
            for (int i = 0; i <= limit; ++i) {
                sb.append(array[i]);
                if (i < limit) {
                    sb.append(options.getSeparator());
                }
            }
            toAppendTo.append(sb.toString());
        } else {
            toAppendTo.append(extStackTrace);
        }
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1069_e9b628ec,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/net/server/JsonInputStreamLogEventBridge.java,45,84,"@Override
protected int[] getEventIndices(final String text, final int beginIndex) {
    // Scan the text for the end of the next JSON object.
    final int start = text.indexOf(EVENT_START_MARKER, beginIndex);
    if (start == END) {
        return END_PAIR;
    }
    final char[] charArray = text.toCharArray();
    int stack = 0;
    boolean inStr = false;
    boolean inEsc = false;
    for (int i = start; i < charArray.length; i++) {
        final char c = charArray[i];
        if (!inEsc) {
            inEsc = false;
            switch(c) {
                case EVENT_START_MARKER:
                    if (!inStr) {
                        stack++;
                    }
                    break;
                case EVENT_END_MARKER:
                    if (!inStr) {
                        stack--;
                    }
                    break;
                case JSON_STR_DELIM:
                    inStr = !inStr;
                    break;
                case JSON_ESC:
                    inEsc = true;
                    break;
            }
            if (stack == 0) {
                return new int[] { start, i };
            }
        }
    }
    return END_PAIR;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-107_88641f49,Major,core/src/main/java/org/apache/logging/log4j/core/pattern/PatternParser.java,211,239,"/**
 * Extract options.
 *
 * @param pattern conversion pattern.
 * @param i       start of options.
 * @param options array to receive extracted options
 * @return position in pattern after options.
 */
private static int extractOptions(String pattern, int i, List<String> options) {
    while ((i < pattern.length()) && (pattern.charAt(i) == '{')) {
        int begin = i;
        int end;
        int depth = 0;
        do {
            end = pattern.indexOf('}', i);
            if (end != -1) {
                int next = pattern.indexOf(""{"", i + 1);
                if (next != -1 && next < end) {
                    i = end + 1;
                    ++depth;
                } else if (depth > 0) {
                    --depth;
                }
            }
        } while (depth > 0);
        if (end == -1) {
            break;
        }
        String r = pattern.substring(begin + 1, end);
        options.add(r);
        i = end + 1;
    }
    return i;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-113_fc3e9d2d,Major,core/src/main/java/org/apache/logging/log4j/core/filter/StructuredDataFilter.java,100,138,"/**
 * Create the StructuredDataFilter.
 * @param pairs Key and value pairs.
 * @param oper The operator to perform. If not ""or"" the operation will be an ""and"".
 * @param match The action to perform on a match.
 * @param mismatch The action to perform on a mismatch.
 * @return The StructuredDataFilter.
 */
@PluginFactory
public static StructuredDataFilter createFilter(@PluginAttr(""pairs"") KeyValuePair[] pairs, @PluginAttr(""operator"") String oper, @PluginAttr(""onmatch"") String match, @PluginAttr(""onmismatch"") String mismatch) {
    if (pairs == null || pairs.length == 0) {
        LOGGER.error(""keys and values must be specified for the StructuredDataFilter"");
        return null;
    }
    Map<String, List<String>> map = new HashMap<String, List<String>>();
    for (KeyValuePair pair : pairs) {
        String key = pair.getKey();
        if (key == null) {
            LOGGER.error(""A null key is not valid in MapFilter"");
            continue;
        }
        String value = pair.getValue();
        if (value == null) {
            LOGGER.error(""A null value for key "" + key + "" is not allowed in MapFilter"");
            continue;
        }
        List<String> list = map.get(pair.getKey());
        if (list != null) {
            list.add(value);
        } else {
            list = new ArrayList<String>();
            list.add(value);
            map.put(pair.getKey(), list);
        }
    }
    if (map.size() == 0) {
        LOGGER.error(""StructuredDataFilter is not configured with any valid key value pairs"");
        return null;
    }
    boolean isAnd = oper == null || !oper.equalsIgnoreCase(""or"");
    Result onMatch = Result.toResult(match);
    Result onMismatch = Result.toResult(mismatch);
    return new StructuredDataFilter(map, isAnd, onMatch, onMismatch);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-114_afcf92eb,Major,api/src/main/java/org/apache/logging/log4j/message/StructuredDataMessage.java,189,195,"@Override
protected void validate(String key, String value) {
    if (value.length() > MAX_LENGTH) {
        throw new IllegalArgumentException(""Structured data values are limited to 32 characters. key: "" + key + "" value: "" + value);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1153_8acedb4e,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/properties/PropertiesConfigurationFactory.java,65,171,"@Override
public PropertiesConfiguration getConfiguration(ConfigurationSource source) {
    final InputStream configStream = source.getInputStream();
    Properties properties = new Properties();
    try {
        properties.load(configStream);
    } catch (IOException ioe) {
        throw new ConfigurationException(""Unable to load "" + source.toString(), ioe);
    }
    ConfigurationBuilder<PropertiesConfiguration> builder = newConfigurationBuilder(PropertiesConfiguration.class);
    String value = properties.getProperty(STATUS_KEY);
    if (value != null) {
        builder.setStatusLevel(Level.toLevel(value, Level.ERROR));
    } else {
        builder.setStatusLevel(Level.ERROR);
    }
    value = properties.getProperty(SHUTDOWN_HOOK);
    if (value != null) {
        builder.setShutdownHook(value);
    }
    value = properties.getProperty(VERBOSE);
    if (value != null) {
        builder.setVerbosity(value);
    }
    value = properties.getProperty(PACKAGES);
    if (value != null) {
        builder.setPackages(value);
    }
    value = properties.getProperty(CONFIG_NAME);
    if (value != null) {
        builder.setConfigurationName(value);
    }
    value = properties.getProperty(MONITOR_INTERVAL);
    if (value != null) {
        builder.setMonitorInterval(value);
    }
    value = properties.getProperty(ADVERTISER_KEY);
    if (value != null) {
        builder.setAdvertiser(value);
    }
    Properties props = PropertiesUtil.extractSubset(properties, ""property"");
    for (String key : props.stringPropertyNames()) {
        builder.addProperty(key, props.getProperty(key));
    }
    String scriptProp = properties.getProperty(""scripts"");
    if (scriptProp != null) {
        String[] scriptNames = scriptProp.split("","");
        for (String scriptName : scriptNames) {
            String name = scriptName.trim();
            Properties scriptProps = PropertiesUtil.extractSubset(properties, ""script."" + name);
            String type = scriptProps.getProperty(""type"");
            if (type == null) {
                throw new ConfigurationException(""No type provided for script - must be Script or ScriptFile"");
            }
            scriptProps.remove(""type"");
            if (type.equalsIgnoreCase(""script"")) {
                builder.add(createScript(builder, name, scriptProps));
            } else {
                builder.add(createScriptFile(builder, name, scriptProps));
            }
        }
    }
    Properties levelProps = PropertiesUtil.extractSubset(properties, ""customLevel"");
    if (levelProps.size() > 0) {
        for (String key : levelProps.stringPropertyNames()) {
            builder.add(builder.newCustomLevel(key, Integer.parseInt(props.getProperty(key))));
        }
    }
    String filterProp = properties.getProperty(""filters"");
    if (filterProp != null) {
        String[] filterNames = filterProp.split("","");
        for (String filterName : filterNames) {
            String name = filterName.trim();
            builder.add(createFilter(builder, name, PropertiesUtil.extractSubset(properties, ""filter."" + name)));
        }
    }
    String appenderProp = properties.getProperty(""appenders"");
    if (appenderProp != null) {
        String[] appenderNames = appenderProp.split("","");
        for (String appenderName : appenderNames) {
            String name = appenderName.trim();
            builder.add(createAppender(builder, name, PropertiesUtil.extractSubset(properties, ""appender."" + name)));
        }
    }
    String loggerProp = properties.getProperty(""loggers"");
    if (appenderProp != null) {
        String[] loggerNames = loggerProp.split("","");
        for (String loggerName : loggerNames) {
            String name = loggerName.trim();
            if (!name.equals(LoggerConfig.ROOT)) {
                builder.add(createLogger(builder, name, PropertiesUtil.extractSubset(properties, ""logger."" + name)));
            }
        }
    }
    props = PropertiesUtil.extractSubset(properties, ""rootLogger"");
    if (props.size() > 0) {
        builder.add(createRootLogger(builder, props));
    }
    return builder.build();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1153_8acedb4e,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/properties/PropertiesConfigurationFactory.java,403,418,"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
private void processRemainingProperties(ComponentBuilder<?> builder, String name, Properties properties) {
    while (properties.size() > 0) {
        String propertyName = properties.stringPropertyNames().iterator().next();
        int index = propertyName.indexOf('.');
        if (index > 0) {
            String prefix = propertyName.substring(0, index);
            Properties componentProperties = PropertiesUtil.extractSubset(properties, prefix);
            builder.addComponent(createComponent(builder, prefix, componentProperties));
        } else {
            builder.addAttribute(propertyName, properties.getProperty(propertyName));
            properties.remove(propertyName);
        }
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1153_9f924f10,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/properties/PropertiesConfigurationFactory.java,63,150,"@Override
public PropertiesConfiguration getConfiguration(ConfigurationSource source) {
    final InputStream configStream = source.getInputStream();
    Properties properties = new Properties();
    try {
        properties.load(configStream);
    } catch (IOException ioe) {
        throw new ConfigurationException(""Unable to load "" + source.toString(), ioe);
    }
    ConfigurationBuilder<PropertiesConfiguration> builder = newConfigurationBuilder(PropertiesConfiguration.class);
    String value = properties.getProperty(STATUS_KEY);
    if (value != null) {
        builder.setStatusLevel(Level.toLevel(value, Level.ERROR));
    } else {
        builder.setStatusLevel(Level.ERROR);
    }
    value = properties.getProperty(SHUTDOWN_HOOK);
    if (value != null) {
        builder.setShutdownHook(value);
    }
    value = properties.getProperty(VERBOSE);
    if (value != null) {
        builder.setVerbosity(value);
    }
    value = properties.getProperty(PACKAGES);
    if (value != null) {
        builder.setPackages(value);
    }
    value = properties.getProperty(CONFIG_NAME);
    if (value != null) {
        builder.setConfigurationName(value);
    }
    value = properties.getProperty(MONITOR_INTERVAL);
    if (value != null) {
        builder.setMonitorInterval(value);
    }
    value = properties.getProperty(ADVERTISER_KEY);
    if (value != null) {
        builder.setAdvertiser(value);
    }
    Properties props = PropertiesUtil.extractSubset(properties, ""property"");
    for (String key : props.stringPropertyNames()) {
        builder.addProperty(key, props.getProperty(key));
    }
    Properties levelProps = PropertiesUtil.extractSubset(properties, ""customLevel"");
    if (levelProps.size() > 0) {
        for (String key : levelProps.stringPropertyNames()) {
            builder.add(builder.newCustomLevel(key, Integer.parseInt(props.getProperty(key))));
        }
    }
    String filterProp = properties.getProperty(""filters"");
    if (filterProp != null) {
        String[] filterNames = filterProp.split("","");
        for (String filterName : filterNames) {
            String name = filterName.trim();
            builder.add(createFilter(builder, name, PropertiesUtil.extractSubset(properties, ""filter."" + name)));
        }
    }
    String appenderProp = properties.getProperty(""appenders"");
    if (appenderProp != null) {
        String[] appenderNames = appenderProp.split("","");
        for (String appenderName : appenderNames) {
            String name = appenderName.trim();
            builder.add(createAppender(builder, name, PropertiesUtil.extractSubset(properties, ""appender."" + name)));
        }
    }
    String loggerProp = properties.getProperty(""loggers"");
    if (appenderProp != null) {
        String[] loggerNames = loggerProp.split("","");
        for (String loggerName : loggerNames) {
            String name = loggerName.trim();
            if (!name.equals(LoggerConfig.ROOT)) {
                builder.add(createLogger(builder, name, PropertiesUtil.extractSubset(properties, ""logger."" + name)));
            }
        }
    }
    props = PropertiesUtil.extractSubset(properties, ""rootLogger"");
    if (props.size() > 0) {
        builder.add(createRootLogger(builder, props));
    }
    return builder.build();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1153_9f924f10,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/properties/PropertiesConfigurationFactory.java,346,361,"@SuppressWarnings({ ""unchecked"", ""rawtypes"" })
private void processRemainingProperties(ComponentBuilder<?> builder, String name, Properties properties) {
    while (properties.size() > 0) {
        String propertyName = properties.stringPropertyNames().iterator().next();
        int index = propertyName.indexOf('.');
        if (index > 0) {
            String prefix = propertyName.substring(0, index);
            Properties componentProperties = PropertiesUtil.extractSubset(properties, prefix);
            builder.addComponent(createComponent(builder, prefix, componentProperties));
        } else {
            builder.addAttribute(propertyName, properties.getProperty(propertyName));
            properties.remove(propertyName);
        }
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1251_424068f7,Major,log4j-jul/src/main/java/org/apache/logging/log4j/jul/ApiLogger.java,53,62,"@Override
public void log(final LogRecord record) {
    if (isFiltered(record)) {
        return;
    }
    final org.apache.logging.log4j.Level level = LevelTranslator.toLevel(record.getLevel());
    final Message message = logger.getMessageFactory().newMessage(record.getMessage(), record.getParameters());
    final Throwable thrown = record.getThrown();
    logger.logIfEnabled(FQCN, level, null, message, thrown);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1251_424068f7,Major,log4j-jul/src/main/java/org/apache/logging/log4j/jul/ApiLogger.java,99,102,"/**
 * Unsupported operation.
 * @throws UnsupportedOperationException always
 */
@Override
public void setParent(final Logger parent) {
    throw new UnsupportedOperationException(""Cannot set parent logger"");
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-127_029e79da,Major,api/src/main/java/org/apache/logging/log4j/spi/AbstractLogger.java,1158,1162,"/**
 * Logs a message with the specific Marker at the {@link Level#ERROR ERROR} level.
 *
 * @param marker the marker data specific to this log statement
 * @param msg    the message string to be logged
 */
public void error(Marker marker, Message msg) {
    if (isEnabled(Level.ERROR, marker, msg, null)) {
        log(null, FQCN, Level.ERROR, msg, null);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-127_029e79da,Major,api/src/main/java/org/apache/logging/log4j/spi/AbstractLogger.java,1355,1359,"/**
 * Logs a message with the specific Marker at the FATAL level.
 *
 * @param marker the marker data specific to this log statement
 * @param msg    the message string to be logged
 */
public void fatal(Marker marker, Message msg) {
    if (isEnabled(Level.FATAL, marker, msg, null)) {
        log(null, FQCN, Level.FATAL, msg, null);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1310_c6318b63,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/lookup/JndiLookup.java,47,62,"/**
 * Looks up the value of the JNDI resource.
 * @param event The current LogEvent (is ignored by this StrLookup).
 * @param key  the JNDI resource name to be looked up, may be null
 * @return The value of the JNDI resource.
 */
@Override
public String lookup(final LogEvent event, final String key) {
    if (key == null) {
        return null;
    }
    final String jndiName = convertJndiName(key);
    final JndiManager jndiManager = JndiManager.getDefaultManager();
    try {
        return jndiManager.lookup(jndiName);
    } catch (final NamingException e) {
        LOGGER.warn(LOOKUP, ""Error looking up JNDI resource [{}]."", jndiName, e);
        return null;
    } finally {
        jndiManager.release();
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1372_1d12bf0e,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/layout/JacksonFactory.java,101,104,"@Override
protected PrettyPrinter newPrettyPrinter() {
    return new DefaultXmlPrettyPrinter();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1372_ffedf33f,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/layout/JacksonFactory.java,101,104,"@Override
protected PrettyPrinter newPrettyPrinter() {
    return new DefaultXmlPrettyPrinter();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-139_50e19247,Major,core/src/main/java/org/apache/logging/log4j/core/appender/SocketAppender.java,87,131,"/**
 * @param host The name of the host to connect to.
 * @param portNum The port to connect to on the target host.
 * @param protocol The Protocol to use.
 * @param delay The interval in which failed writes should be retried.
 * @param immediateFail True if the write should fail if no socket is immediately available.
 * @param name The name of the Appender.
 * @param immediateFlush ""true"" if data should be flushed on each write.
 * @param suppress ""true"" if exceptions should be hidden from the application, ""false"" otherwise.
 * The default is ""true"".
 * @param layout The layout to use (defaults to SerializedLayout).
 * @param filter The Filter or null.
 * @param advertise ""true"" if the appender configuration should be advertised, ""false"" otherwise.
 * @param config The Configuration
 * @return A SocketAppender.
 */
@PluginFactory
public static <S extends Serializable> SocketAppender<S> createAppender(@PluginAttr(""host"") final String host, @PluginAttr(""port"") final String portNum, @PluginAttr(""protocol"") final String protocol, @PluginAttr(""reconnectionDelay"") final String delay, @PluginAttr(""immediateFail"") final String immediateFail, @PluginAttr(""name"") final String name, @PluginAttr(""immediateFlush"") final String immediateFlush, @PluginAttr(""suppressExceptions"") final String suppress, @PluginElement(""layout"") Layout<S> layout, @PluginElement(""filters"") final Filter filter, @PluginAttr(""advertise"") final String advertise, @PluginConfiguration final Configuration config) {
    boolean isFlush = immediateFlush == null ? true : Boolean.valueOf(immediateFlush);
    boolean isAdvertise = advertise == null ? false : Boolean.valueOf(advertise);
    final boolean handleExceptions = suppress == null ? true : Boolean.valueOf(suppress);
    final boolean fail = immediateFail == null ? true : Boolean.valueOf(immediateFail);
    final int reconnectDelay = delay == null ? 0 : Integer.parseInt(delay);
    final int port = portNum == null ? 0 : Integer.parseInt(portNum);
    if (layout == null) {
        @SuppressWarnings({ ""unchecked"", ""UnnecessaryLocalVariable"" })
        Layout<S> l = (Layout<S>) SerializedLayout.createLayout();
        layout = l;
    }
    if (name == null) {
        LOGGER.error(""No name provided for SocketAppender"");
        return null;
    }
    final String prot = protocol != null ? protocol : Protocol.TCP.name();
    final Protocol p = EnglishEnums.valueOf(Protocol.class, protocol);
    if (p.equals(Protocol.UDP)) {
        isFlush = true;
    }
    final AbstractSocketManager manager = createSocketManager(p, host, port, reconnectDelay, fail, layout);
    if (manager == null) {
        return null;
    }
    return new SocketAppender<S>(name, layout, filter, manager, handleExceptions, isFlush, isAdvertise ? config.getAdvertiser() : null);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1402_7792679c,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/properties/PropertiesConfigurationBuilder.java,79,150,"@Override
public PropertiesConfiguration build() {
    Map<String, String> rootProps = new HashMap<>();
    for (String key : rootProperties.stringPropertyNames()) {
        if (!key.contains(""."")) {
            builder.addRootProperty(key, rootProperties.getProperty(key));
        }
    }
    builder.setStatusLevel(Level.toLevel(rootProperties.getProperty(STATUS_KEY), Level.ERROR)).setShutdownHook(rootProperties.getProperty(SHUTDOWN_HOOK)).setVerbosity(rootProperties.getProperty(VERBOSE)).setPackages(rootProperties.getProperty(PACKAGES)).setConfigurationName(rootProperties.getProperty(CONFIG_NAME)).setMonitorInterval(rootProperties.getProperty(MONITOR_INTERVAL, ""0"")).setAdvertiser(rootProperties.getProperty(ADVERTISER_KEY));
    final Properties propertyPlaceholders = PropertiesUtil.extractSubset(rootProperties, ""property"");
    for (final String key : propertyPlaceholders.stringPropertyNames()) {
        builder.addProperty(key, propertyPlaceholders.getProperty(key));
    }
    final Map<String, Properties> scripts = PropertiesUtil.partitionOnCommonPrefixes(PropertiesUtil.extractSubset(rootProperties, ""script""));
    for (final Map.Entry<String, Properties> entry : scripts.entrySet()) {
        final Properties scriptProps = entry.getValue();
        final String type = (String) scriptProps.remove(""type"");
        if (type == null) {
            throw new ConfigurationException(""No type provided for script - must be Script or ScriptFile"");
        }
        if (type.equalsIgnoreCase(""script"")) {
            builder.add(createScript(scriptProps));
        } else {
            builder.add(createScriptFile(scriptProps));
        }
    }
    final Properties levelProps = PropertiesUtil.extractSubset(rootProperties, ""customLevel"");
    if (levelProps.size() > 0) {
        for (final String key : levelProps.stringPropertyNames()) {
            builder.add(builder.newCustomLevel(key, Integer.parseInt(levelProps.getProperty(key))));
        }
    }
    final Map<String, Properties> filters = PropertiesUtil.partitionOnCommonPrefixes(PropertiesUtil.extractSubset(rootProperties, ""filter""));
    for (final Map.Entry<String, Properties> entry : filters.entrySet()) {
        builder.add(createFilter(entry.getKey().trim(), entry.getValue()));
    }
    final Map<String, Properties> appenders = PropertiesUtil.partitionOnCommonPrefixes(PropertiesUtil.extractSubset(rootProperties, ""appender""));
    for (final Map.Entry<String, Properties> entry : appenders.entrySet()) {
        builder.add(createAppender(entry.getKey().trim(), entry.getValue()));
    }
    final Map<String, Properties> loggers = PropertiesUtil.partitionOnCommonPrefixes(PropertiesUtil.extractSubset(rootProperties, ""logger""));
    for (final Map.Entry<String, Properties> entry : loggers.entrySet()) {
        final String name = entry.getKey().trim();
        if (!name.equals(LoggerConfig.ROOT)) {
            builder.add(createLogger(name, entry.getValue()));
        }
    }
    final Properties props = PropertiesUtil.extractSubset(rootProperties, ""rootLogger"");
    if (props.size() > 0) {
        builder.add(createRootLogger(props));
    }
    return builder.build(false);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-1406_a523dcd5,Critical,log4j-api/src/main/java/org/apache/logging/log4j/message/ReusableParameterizedMessage.java,123,127,"private void initThrowable(final Object[] params, final int argCount, final int usedParams) {
    if (usedParams < argCount && this.throwable == null && params[argCount - 1] instanceof Throwable) {
        this.throwable = (Throwable) params[argCount - 1];
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-143_1461f1f6,Major,core/src/main/java/org/apache/logging/log4j/core/pattern/MessagePatternConverter.java,60,73,"/**
 * {@inheritDoc}
 */
@Override
public void format(final LogEvent event, final StringBuilder toAppendTo) {
    final Message msg = event.getMessage();
    if (msg != null) {
        String result;
        if (msg instanceof MultiformatMessage) {
            result = ((MultiformatMessage) msg).getFormattedMessage(formats);
        } else {
            result = msg.getFormattedMessage();
        }
        toAppendTo.append(config != null && result.contains(""${"") ? config.getSubst().replace(event, result) : result);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-147_17296089,Major,core/src/main/java/org/apache/logging/log4j/core/filter/ThreadContextMapFilter.java,84,102,"private Result filter() {
    boolean match = false;
    if (useMap) {
        for (final Map.Entry<String, List<String>> entry : getMap().entrySet()) {
            final String toMatch = ThreadContext.get(entry.getKey());
            if (toMatch != null) {
                match = entry.getValue().contains(toMatch);
            } else {
                match = false;
            }
            if ((!isAnd() && match) || (isAnd() && !match)) {
                break;
            }
        }
    } else {
        match = key.equals(ThreadContext.get(key));
    }
    return match ? onMatch : onMismatch;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-177_f91ce934,Major,core/src/main/java/org/apache/logging/log4j/core/appender/OutputStreamManager.java,55,63,"/**
 * Set the header to write when the stream is opened.
 * @param header The header.
 */
public synchronized void setHeader(final byte[] header) {
    if (header != null) {
        try {
            this.os.write(header, 0, header.length);
        } catch (final IOException ioe) {
            LOGGER.error(""Unable to write header"", ioe);
        }
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-177_f91ce934,Major,core/src/main/java/org/apache/logging/log4j/core/appender/OutputStreamManager.java,98,100,"protected void setOutputStream(final OutputStream os) {
    this.os = os;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-177_f91ce934,Major,core/src/main/java/org/apache/logging/log4j/core/net/DatagramOutputStream.java,90,97,"@Override
public synchronized void flush() throws IOException {
    if (this.ds != null && this.address != null) {
        final DatagramPacket packet = new DatagramPacket(data, data.length, address, port);
        ds.send(packet);
    }
    data = null;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-210_aeb6fc9d,Major,api/src/main/java/org/apache/logging/log4j/message/MapMessage.java,193,199,"public void asXML(final StringBuilder sb) {
    sb.append(""<Map>\n"");
    for (final Map.Entry<String, String> entry : data.entrySet()) {
        sb.append(""  <Entry key="").append(entry.getKey()).append("">"").append(entry.getValue()).append(""</Entry>\n"");
    }
    sb.append(""</Map>"");
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-219_ed951c76,Major,core/src/main/java/org/apache/logging/log4j/core/config/BaseConfiguration.java,165,228,"@SuppressWarnings(""unchecked"")
protected void doConfigure() {
    boolean setRoot = false;
    boolean setLoggers = false;
    for (final Node child : rootNode.getChildren()) {
        createConfiguration(child, null);
        if (child.getObject() == null) {
            continue;
        }
        if (child.getName().equalsIgnoreCase(""properties"")) {
            if (tempLookup == subst.getVariableResolver()) {
                subst.setVariableResolver((StrLookup) child.getObject());
            } else {
                LOGGER.error(""Properties declaration must be the first element in the configuration"");
            }
            continue;
        } else if (tempLookup == subst.getVariableResolver()) {
            final Map<String, String> map = (Map<String, String>) componentMap.get(CONTEXT_PROPERTIES);
            final StrLookup lookup = map == null ? null : new MapLookup(map);
            subst.setVariableResolver(new Interpolator(lookup));
        }
        if (child.getName().equalsIgnoreCase(""appenders"")) {
            appenders = (ConcurrentMap<String, Appender<?>>) child.getObject();
        } else if (child.getObject() instanceof Filter) {
            addFilter((Filter) child.getObject());
        } else if (child.getName().equalsIgnoreCase(""loggers"")) {
            final Loggers l = (Loggers) child.getObject();
            loggers = l.getMap();
            setLoggers = true;
            if (l.getRoot() != null) {
                root = l.getRoot();
                setRoot = true;
            }
        } else {
            LOGGER.error(""Unknown object \"""" + child.getName() + ""\"" of type "" + child.getObject().getClass().getName() + "" is ignored"");
        }
    }
    if (!setLoggers) {
        LOGGER.warn(""No Loggers were configured, using default. Is the Loggers element missing?"");
        setToDefault();
        return;
    } else if (!setRoot) {
        LOGGER.warn(""No Root logger was configured, using default"");
        setToDefault();
        return;
    }
    for (final Map.Entry<String, LoggerConfig> entry : loggers.entrySet()) {
        final LoggerConfig l = entry.getValue();
        for (final AppenderRef ref : l.getAppenderRefs()) {
            final Appender app = appenders.get(ref.getRef());
            if (app != null) {
                l.addAppender(app, ref.getLevel(), ref.getFilter());
            } else {
                LOGGER.error(""Unable to locate appender "" + ref.getRef() + "" for logger "" + l.getName());
            }
        }
    }
    setParents();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-234_2d7d6311,Major,core/src/main/java/org/apache/logging/log4j/core/filter/RegexFilter.java,57,61,"@Override
public Result filter(final Logger logger, final Level level, final Marker marker, final Object msg, final Throwable t) {
    return filter(msg.toString());
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-234_2d7d6311,Major,core/src/main/java/org/apache/logging/log4j/core/filter/RegexFilter.java,63,68,"@Override
public Result filter(final Logger logger, final Level level, final Marker marker, final Message msg, final Throwable t) {
    final String text = useRawMessage ? msg.getFormat() : msg.getFormattedMessage();
    return filter(text);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-258_7b38965d,Major,core/src/main/java/org/apache/logging/log4j/core/layout/HTMLLayout.java,253,288,"/**
 * Returns appropriate HTML headers.
 * @return The header as a byte array.
 */
@Override
public byte[] getHeader() {
    final StringBuilder sbuf = new StringBuilder();
    sbuf.append(""<!DOCTYPE HTML PUBLIC \""-//W3C//DTD HTML 4.01 Transitional//EN\"" "");
    sbuf.append(""\""http://www.w3.org/TR/html4/loose.dtd\"">"");
    sbuf.append(Constants.LINE_SEP);
    sbuf.append(""<html>"").append(Constants.LINE_SEP);
    sbuf.append(""<head>"").append(Constants.LINE_SEP);
    sbuf.append(""<title>"").append(title).append(""</title>"").append(Constants.LINE_SEP);
    sbuf.append(""<style type=\""text/css\"">"").append(Constants.LINE_SEP);
    sbuf.append(""<!--"").append(Constants.LINE_SEP);
    sbuf.append(""body, table {font-family:"").append(font).append(""; font-size: "");
    sbuf.append(headerSize).append("";}"").append(Constants.LINE_SEP);
    sbuf.append(""th {background: #336699; color: #FFFFFF; text-align: left;}"").append(Constants.LINE_SEP);
    sbuf.append(""-->"").append(Constants.LINE_SEP);
    sbuf.append(""</style>"").append(Constants.LINE_SEP);
    sbuf.append(""</head>"").append(Constants.LINE_SEP);
    sbuf.append(""<body bgcolor=\""#FFFFFF\"" topmargin=\""6\"" leftmargin=\""6\"">"").append(Constants.LINE_SEP);
    sbuf.append(""<hr size=\""1\"" noshade>"").append(Constants.LINE_SEP);
    sbuf.append(""Log session start time "" + new java.util.Date() + ""<br>"").append(Constants.LINE_SEP);
    sbuf.append(""<br>"").append(Constants.LINE_SEP);
    sbuf.append(""<table cellspacing=\""0\"" cellpadding=\""4\"" border=\""1\"" bordercolor=\""#224466\"" width=\""100%\"">"");
    sbuf.append(Constants.LINE_SEP);
    sbuf.append(""<tr>"").append(Constants.LINE_SEP);
    sbuf.append(""<th>Time</th>"").append(Constants.LINE_SEP);
    sbuf.append(""<th>Thread</th>"").append(Constants.LINE_SEP);
    sbuf.append(""<th>Level</th>"").append(Constants.LINE_SEP);
    sbuf.append(""<th>Logger</th>"").append(Constants.LINE_SEP);
    if (locationInfo) {
        sbuf.append(""<th>File:Line</th>"").append(Constants.LINE_SEP);
    }
    sbuf.append(""<th>Message</th>"").append(Constants.LINE_SEP);
    sbuf.append(""</tr>"").append(Constants.LINE_SEP);
    return sbuf.toString().getBytes(getCharset());
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-258_7b38965d,Major,core/src/main/java/org/apache/logging/log4j/core/layout/HTMLLayout.java,313,335,"/**
 * Create an HTML Layout.
 * @param locationInfo If ""true"", location information will be included. The default is false.
 * @param title The title to include in the file header. If none is specified the default title will be used.
 * @param contentType The content type. Defaults to ""text/html"".
 * @param charsetName The character set to use. If not specified, the default will be used.
 * @param fontSize The font size of the text.
 * @param font The font to use for the text.
 * @return An HTML Layout.
 */
@PluginFactory
public static HTMLLayout createLayout(@PluginAttr(""locationInfo"") final String locationInfo, @PluginAttr(""title"") String title, @PluginAttr(""contentType"") String contentType, @PluginAttr(""charset"") final String charsetName, @PluginAttr(""fontSize"") String fontSize, @PluginAttr(""fontName"") String font) {
    final Charset charset = Charsets.getSupportedCharset(charsetName);
    if (font == null) {
        font = ""arial,sans-serif"";
    }
    final FontSize fs = FontSize.getFontSize(fontSize);
    fontSize = fs.getFontSize();
    final String headerSize = fs.larger().getFontSize();
    final boolean info = locationInfo == null ? false : Boolean.valueOf(locationInfo);
    if (title == null) {
        title = DEFAULT_TITLE;
    }
    if (contentType == null) {
        contentType = DEFAULT_CONTENT_TYPE;
    }
    return new HTMLLayout(info, title, contentType, charset, font, fontSize, headerSize);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-259_09175c8b,Major,core/src/main/java/org/apache/logging/log4j/core/layout/HTMLLayout.java,206,212,"@Override
public /**
 * @return The content type.
 */
String getContentType() {
    return ""text/html"";
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-260_9d817953,Major,core/src/main/java/org/apache/logging/log4j/core/layout/XMLLayout.java,237,243,"@Override
public /**
 * @return The content type.
 */
String getContentType() {
    return ""text/xml"";
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-293_25cb587a,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/ConfigurationFactory.java,214,241,"/**
 * Load the configuration from a URI.
 * @param configLocation A URI representing the location of the configuration.
 * @return The ConfigurationSource for the configuration.
 */
protected ConfigurationSource getInputFromURI(final URI configLocation) {
    final File configFile = FileUtils.fileFromURI(configLocation);
    if (configFile != null && configFile.exists() && configFile.canRead()) {
        try {
            return new ConfigurationSource(new FileInputStream(configFile), configFile);
        } catch (final FileNotFoundException ex) {
            LOGGER.error(""Cannot locate file "" + configLocation.getPath(), ex);
        }
    }
    final String scheme = configLocation.getScheme();
    if (scheme == null || scheme.equals(""classloader"")) {
        final ClassLoader loader = this.getClass().getClassLoader();
        final ConfigurationSource source = getInputFromResource(configLocation.getPath(), loader);
        if (source != null) {
            return source;
        }
    }
    try {
        return new ConfigurationSource(configLocation.toURL().openStream(), configLocation.getPath());
    } catch (final MalformedURLException ex) {
        LOGGER.error(""Invalid URL "" + configLocation.toString(), ex);
    } catch (final IOException ex) {
        LOGGER.error(""Unable to access "" + configLocation.toString(), ex);
    } catch (final Exception ex) {
        LOGGER.error(""Unable to access "" + configLocation.toString(), ex);
    }
    return null;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-293_25cb587a,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/ConfigurationFactory.java,339,390,"/**
 * Default Factory Constructor.
 * @param name The configuration name.
 * @param configLocation The configuration location.
 * @return The Configuration.
 */
@Override
public Configuration getConfiguration(final String name, final URI configLocation) {
    if (configLocation == null) {
        final String config = PropertiesUtil.getProperties().getStringProperty(CONFIGURATION_FILE_PROPERTY);
        if (config != null) {
            final ClassLoader loader = this.getClass().getClassLoader();
            final ConfigurationSource source = getInputFromString(config, loader);
            if (source != null) {
                for (final ConfigurationFactory factory : factories) {
                    final String[] types = factory.getSupportedTypes();
                    if (types != null) {
                        for (final String type : types) {
                            if (type.equals(""*"") || config.endsWith(type)) {
                                final Configuration c = factory.getConfiguration(source);
                                if (c != null) {
                                    return c;
                                }
                            }
                        }
                    }
                }
            }
        }
    } else {
        for (final ConfigurationFactory factory : factories) {
            final String[] types = factory.getSupportedTypes();
            if (types != null) {
                for (final String type : types) {
                    if (type.equals(""*"") || configLocation.getPath().endsWith(type)) {
                        final Configuration config = factory.getConfiguration(name, configLocation);
                        if (config != null) {
                            return config;
                        }
                    }
                }
            }
        }
    }
    Configuration config = getConfiguration(true, name);
    if (config == null) {
        config = getConfiguration(true, null);
        if (config == null) {
            config = getConfiguration(false, name);
            if (config == null) {
                config = getConfiguration(false, null);
            }
        }
    }
    return config != null ? config : new DefaultConfiguration();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-293_ca59ece6,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/selector/ClassLoaderContextSelector.java,180,232,"private LoggerContext locateContext(final ClassLoader loader, final URI configLocation) {
    final String name = loader.toString();
    AtomicReference<WeakReference<LoggerContext>> ref = CONTEXT_MAP.get(name);
    if (ref == null) {
        if (configLocation == null) {
            ClassLoader parent = loader.getParent();
            while (parent != null) {
                ref = CONTEXT_MAP.get(parent.toString());
                if (ref != null) {
                    final WeakReference<LoggerContext> r = ref.get();
                    final LoggerContext ctx = r.get();
                    if (ctx != null) {
                        return ctx;
                    }
                }
                parent = parent.getParent();
            /*  In Tomcat 6 the parent of the JSP classloader is the webapp classloader which would be
                    configured by the WebAppContextListener. The WebAppClassLoader is also the ThreadContextClassLoader.
                    In JBoss 5 the parent of the JSP ClassLoader is the WebAppClassLoader which is also the
                    ThreadContextClassLoader. However, the parent of the WebAppClassLoader is the ClassLoader
                    that is configured by the WebAppContextListener.

                    ClassLoader threadLoader = null;
                    try {
                        threadLoader = Thread.currentThread().getContextClassLoader();
                    } catch (Exception ex) {
                        // Ignore SecurityException
                    }
                    if (threadLoader != null && threadLoader == parent) {
                        break;
                    } else {
                        parent = parent.getParent();
                    } */
            }
        }
        LoggerContext ctx = new LoggerContext(name, null, configLocation);
        final AtomicReference<WeakReference<LoggerContext>> r = new AtomicReference<WeakReference<LoggerContext>>();
        r.set(new WeakReference<LoggerContext>(ctx));
        CONTEXT_MAP.putIfAbsent(loader.toString(), r);
        ctx = CONTEXT_MAP.get(name).get().get();
        return ctx;
    }
    final WeakReference<LoggerContext> r = ref.get();
    LoggerContext ctx = r.get();
    if (ctx != null) {
        return ctx;
    }
    ctx = new LoggerContext(name, null, configLocation);
    ref.compareAndSet(r, new WeakReference<LoggerContext>(ctx));
    return ctx;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-310_3f1e0fdc,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/net/SMTPManager.java,133,162,"/**
 * Send the contents of the cyclic buffer as an e-mail message.
 * @param layout The layout for formatting the events.
 * @param appendEvent The event that triggered the send.
 */
public void sendEvents(final Layout<?> layout, final LogEvent appendEvent) {
    if (message == null) {
        connect();
    }
    try {
        final LogEvent[] priorEvents = buffer.removeAll();
        if (priorEvents == null || priorEvents.length == 0) {
            // nothing to do, another thread already took all events
            return;
        }
        final byte[] rawBytes = formatContentToBytes(priorEvents, appendEvent, layout);
        final String contentType = layout.getContentType();
        final String encoding = getEncoding(rawBytes, contentType);
        final byte[] encodedBytes = encodeContentToBytes(rawBytes, encoding);
        final InternetHeaders headers = getHeaders(contentType, encoding);
        final MimeMultipart mp = getMimeMultipart(encodedBytes, headers);
        sendMultipartMessage(message, mp);
    } catch (final MessagingException e) {
        LOGGER.error(""Error occurred while sending e-mail notification."", e);
        throw new LoggingException(""Error occurred while sending email"", e);
    } catch (final IOException e) {
        LOGGER.error(""Error occurred while sending e-mail notification."", e);
        throw new LoggingException(""Error occurred while sending email"", e);
    } catch (final RuntimeException e) {
        LOGGER.error(""Error occurred while sending e-mail notification."", e);
        throw new LoggingException(""Error occurred while sending email"", e);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-344_8dead3bb,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/web/Log4jServletContainerInitializer.java,38,59,"@Override
public void onStartup(final Set<Class<?>> classes, final ServletContext servletContext) throws ServletException {
    if (servletContext.getMajorVersion() > 2 && servletContext.getEffectiveMajorVersion() > 2) {
        servletContext.log(""Log4jServletContainerInitializer starting up Log4j in Servlet 3.0+ environment."");
        final FilterRegistration.Dynamic filter = servletContext.addFilter(""log4jServletFilter"", new Log4jServletFilter());
        if (filter == null) {
            servletContext.log(""WARNING: In a Servlet 3.0+ application, you should not define a "" + ""log4jServletFilter in web.xml. Log4j 2 normally does this for you automatically. Log4j 2 "" + ""web auto-initialization has been canceled."");
            return;
        }
        final Log4jWebInitializer initializer = Log4jWebInitializerImpl.getLog4jWebInitializer(servletContext);
        initializer.initialize();
        // the application is just now starting to start up
        initializer.setLoggerContext();
        servletContext.addListener(new Log4jServletContextListener());
        filter.addMappingForUrlPatterns(EnumSet.allOf(DispatcherType.class), false, ""/*"");
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-359_1df1db27,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/web/Log4jServletContainerInitializer.java,33,45,"@Override
public void onStartup(final Set<Class<?>> classes, final ServletContext servletContext) throws ServletException {
    servletContext.log(""Log4jServletContainerInitializer starting up Log4j in Servlet 3.0+ environment."");
    final Log4jWebInitializer initializer = Log4jWebInitializerImpl.getLog4jWebInitializer(servletContext);
    initializer.initialize();
    // the application is just now starting to start up
    initializer.setLoggerContext();
    servletContext.addListener(new Log4jServletContextListener());
    final FilterRegistration.Dynamic filter = servletContext.addFilter(""log4jServletFilter"", new Log4jServletFilter());
    filter.addMappingForUrlPatterns(EnumSet.allOf(DispatcherType.class), false, ""/*"");
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-359_296ea4a5,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/web/Log4jServletContainerInitializer.java,35,54,"@Override
public void onStartup(final Set<Class<?>> classes, final ServletContext servletContext) throws ServletException {
    if (servletContext.getMajorVersion() > 2) {
        servletContext.log(""Log4jServletContainerInitializer starting up Log4j in Servlet 3.0+ environment."");
        final Log4jWebInitializer initializer = Log4jWebInitializerImpl.getLog4jWebInitializer(servletContext);
        initializer.initialize();
        // the application is just now starting to start up
        initializer.setLoggerContext();
        servletContext.addListener(new Log4jServletContextListener());
        final FilterRegistration.Dynamic filter = servletContext.addFilter(""log4jServletFilter"", new Log4jServletFilter());
        if (filter == null) {
            throw new UnavailableException(""In a Servlet 3.0+ application, you must not define a "" + ""log4jServletFilter in web.xml. Log4j 2 defines this for you automatically."");
        }
        filter.addMappingForUrlPatterns(EnumSet.allOf(DispatcherType.class), false, ""/*"");
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-385_7c2ce5cf,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/appender/rolling/PatternProcessor.java,86,156,"/**
 * Returns the next potential rollover time.
 * @param current The current time.
 * @param increment The increment to the next time.
 * @param modulus If true the time will be rounded to occur on a boundary aligned with the increment.
 * @return the next potential rollover time and the timestamp for the target file.
 */
public long getNextTime(final long current, final int increment, final boolean modulus) {
    prevFileTime = nextFileTime;
    long nextTime;
    if (frequency == null) {
        throw new IllegalStateException(""Pattern does not contain a date"");
    }
    final Calendar currentCal = Calendar.getInstance();
    currentCal.setTimeInMillis(current);
    final Calendar cal = Calendar.getInstance();
    cal.set(currentCal.get(Calendar.YEAR), 0, 1, 0, 0, 0);
    cal.set(Calendar.MILLISECOND, 0);
    if (frequency == RolloverFrequency.ANNUALLY) {
        increment(cal, Calendar.YEAR, increment, modulus);
        nextTime = cal.getTimeInMillis();
        cal.add(Calendar.YEAR, -1);
        nextFileTime = cal.getTimeInMillis();
        return nextTime;
    }
    if (frequency == RolloverFrequency.MONTHLY) {
        increment(cal, Calendar.MONTH, increment, modulus);
        nextTime = cal.getTimeInMillis();
        cal.add(Calendar.MONTH, -1);
        nextFileTime = cal.getTimeInMillis();
        return nextTime;
    }
    if (frequency == RolloverFrequency.WEEKLY) {
        increment(cal, Calendar.WEEK_OF_YEAR, increment, modulus);
        nextTime = cal.getTimeInMillis();
        cal.add(Calendar.WEEK_OF_YEAR, -1);
        nextFileTime = cal.getTimeInMillis();
        return nextTime;
    }
    cal.set(Calendar.DAY_OF_YEAR, currentCal.get(Calendar.DAY_OF_YEAR));
    if (frequency == RolloverFrequency.DAILY) {
        increment(cal, Calendar.DAY_OF_YEAR, increment, modulus);
        nextTime = cal.getTimeInMillis();
        cal.add(Calendar.DAY_OF_YEAR, -1);
        nextFileTime = cal.getTimeInMillis();
        return nextTime;
    }
    cal.set(Calendar.HOUR, currentCal.get(Calendar.HOUR));
    if (frequency == RolloverFrequency.HOURLY) {
        increment(cal, Calendar.HOUR, increment, modulus);
        nextTime = cal.getTimeInMillis();
        cal.add(Calendar.HOUR, -1);
        nextFileTime = cal.getTimeInMillis();
        return nextTime;
    }
    cal.set(Calendar.MINUTE, currentCal.get(Calendar.MINUTE));
    if (frequency == RolloverFrequency.EVERY_MINUTE) {
        increment(cal, Calendar.MINUTE, increment, modulus);
        nextTime = cal.getTimeInMillis();
        cal.add(Calendar.MINUTE, -1);
        nextFileTime = cal.getTimeInMillis();
        return nextTime;
    }
    cal.set(Calendar.SECOND, currentCal.get(Calendar.SECOND));
    if (frequency == RolloverFrequency.EVERY_SECOND) {
        increment(cal, Calendar.SECOND, increment, modulus);
        nextTime = cal.getTimeInMillis();
        cal.add(Calendar.SECOND, -1);
        nextFileTime = cal.getTimeInMillis();
        return nextTime;
    }
    increment(cal, Calendar.MILLISECOND, increment, modulus);
    nextTime = cal.getTimeInMillis();
    cal.add(Calendar.MILLISECOND, -1);
    nextFileTime = cal.getTimeInMillis();
    return nextTime;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-392_731c84b5,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/AbstractConfiguration.java,132,163,"/**
 * Initialize the configuration.
 */
@Override
public void start() {
    LOGGER.debug(""Starting configuration {}"", this);
    this.setStarting();
    pluginManager.collectPlugins();
    final PluginManager levelPlugins = new PluginManager(""Level"");
    levelPlugins.collectPlugins();
    final Map<String, PluginType<?>> plugins = levelPlugins.getPlugins();
    if (plugins != null) {
        for (final PluginType<?> type : plugins.values()) {
            try {
                // Cause the class to be initialized if it isn't already.
                Loader.initializeClass(type.getPluginClass().getName(), type.getPluginClass().getClassLoader());
            } catch (final Exception ex) {
                LOGGER.error(""Unable to initialize {} due to {}: {}"", type.getPluginClass().getName(), ex.getClass().getSimpleName(), ex.getMessage());
            }
        }
    }
    setup();
    setupAdvertisement();
    doConfigure();
    for (final LoggerConfig logger : loggers.values()) {
        logger.start();
    }
    for (final Appender appender : appenders.values()) {
        appender.start();
    }
    // LOG4J2-336
    root.start();
    super.start();
    LOGGER.debug(""Started configuration {} OK."", this);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-392_731c84b5,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/AbstractConfiguration.java,168,258,"/**
 * Tear down the configuration.
 */
@Override
public void stop() {
    this.setStopping();
    LOGGER.trace(""Stopping {}..."", this);
    // LOG4J2-392 first stop AsyncLogger Disruptor thread
    final LoggerContextFactory factory = LogManager.getFactory();
    if (factory instanceof Log4jContextFactory) {
        ContextSelector selector = ((Log4jContextFactory) factory).getSelector();
        if (selector instanceof AsyncLoggerContextSelector) {
        // all loggers are async
        // TODO until LOG4J2-493 is fixed we can only stop AsyncLogger once!
        // but LoggerContext.setConfiguration will call config.stop()
        // every time the configuration changes...
        // 
        // Uncomment the line below after LOG4J2-493 is fixed
        // AsyncLogger.stop();
        // LOGGER.trace(""AbstractConfiguration stopped AsyncLogger disruptor."");
        }
    }
    // similarly, first stop AsyncLoggerConfig Disruptor thread(s)
    Set<LoggerConfig> alreadyStopped = new HashSet<LoggerConfig>();
    int asyncLoggerConfigCount = 0;
    for (final LoggerConfig logger : loggers.values()) {
        if (logger instanceof AsyncLoggerConfig) {
            // LOG4J2-520, LOG4J2-392:
            // Important: do not clear appenders until after all AsyncLoggerConfigs
            // have been stopped! Stopping the last AsyncLoggerConfig will
            // shut down the disruptor and wait for all enqueued events to be processed.
            // Only *after this* the appenders can be cleared or events will be lost.
            logger.stop();
            asyncLoggerConfigCount++;
            alreadyStopped.add(logger);
        }
    }
    if (root instanceof AsyncLoggerConfig) {
        root.stop();
        asyncLoggerConfigCount++;
        alreadyStopped.add(root);
    }
    LOGGER.trace(""AbstractConfiguration stopped {} AsyncLoggerConfigs."", asyncLoggerConfigCount);
    // Stop the appenders in reverse order in case they still have activity.
    final Appender[] array = appenders.values().toArray(new Appender[appenders.size()]);
    // LOG4J2-511, LOG4J2-392 stop AsyncAppenders first
    int asyncAppenderCount = 0;
    for (int i = array.length - 1; i >= 0; --i) {
        if (array[i] instanceof AsyncAppender) {
            array[i].stop();
            asyncAppenderCount++;
        }
    }
    LOGGER.trace(""AbstractConfiguration stopped {} AsyncAppenders."", asyncAppenderCount);
    int appenderCount = 0;
    for (int i = array.length - 1; i >= 0; --i) {
        if (array[i].isStarted()) {
            // then stop remaining Appenders
            array[i].stop();
            appenderCount++;
        }
    }
    LOGGER.trace(""AbstractConfiguration stopped {} Appenders."", appenderCount);
    int loggerCount = 0;
    for (final LoggerConfig logger : loggers.values()) {
        // clear appenders, even if this logger is already stopped.
        logger.clearAppenders();
        // the shared Disruptor may be shut down prematurely, resulting in NPE or other errors.
        if (alreadyStopped.contains(logger)) {
            continue;
        }
        logger.stop();
        loggerCount++;
    }
    LOGGER.trace(""AbstractConfiguration stopped {} Loggers."", loggerCount);
    // the shared Disruptor may be shut down prematurely, resulting in NPE or other errors.
    if (!alreadyStopped.contains(root)) {
        root.stop();
    }
    super.stop();
    if (advertiser != null && advertisement != null) {
        advertiser.unadvertise(advertisement);
    }
    LOGGER.debug(""Stopped {} OK"", this);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-395_a19ecc9e,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/ConfigurationFactory.java,361,412,"/**
 * Default Factory Constructor.
 * @param name The configuration name.
 * @param configLocation The configuration location.
 * @return The Configuration.
 */
@Override
public Configuration getConfiguration(final String name, final URI configLocation) {
    if (configLocation == null) {
        final String config = PropertiesUtil.getProperties().getStringProperty(CONFIGURATION_FILE_PROPERTY);
        if (config != null) {
            final ClassLoader loader = this.getClass().getClassLoader();
            final ConfigurationSource source = getInputFromString(config, loader);
            if (source != null) {
                for (final ConfigurationFactory factory : factories) {
                    final String[] types = factory.getSupportedTypes();
                    if (types != null) {
                        for (final String type : types) {
                            if (type.equals(""*"") || config.endsWith(type)) {
                                final Configuration c = factory.getConfiguration(source);
                                if (c != null) {
                                    return c;
                                }
                            }
                        }
                    }
                }
            }
        }
    } else {
        for (final ConfigurationFactory factory : factories) {
            final String[] types = factory.getSupportedTypes();
            if (types != null) {
                for (final String type : types) {
                    if (type.equals(""*"") || configLocation.toString().endsWith(type)) {
                        final Configuration config = factory.getConfiguration(name, configLocation);
                        if (config != null) {
                            return config;
                        }
                    }
                }
            }
        }
    }
    Configuration config = getConfiguration(true, name);
    if (config == null) {
        config = getConfiguration(true, null);
        if (config == null) {
            config = getConfiguration(false, name);
            if (config == null) {
                config = getConfiguration(false, null);
            }
        }
    }
    return config != null ? config : new DefaultConfiguration();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-398_2c966ad9,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/BaseConfiguration.java,242,305,"@SuppressWarnings(""unchecked"")
protected void doConfigure() {
    boolean setRoot = false;
    boolean setLoggers = false;
    for (final Node child : rootNode.getChildren()) {
        createConfiguration(child, null);
        if (child.getObject() == null) {
            continue;
        }
        if (child.getName().equalsIgnoreCase(""Properties"")) {
            if (tempLookup == subst.getVariableResolver()) {
                subst.setVariableResolver((StrLookup) child.getObject());
            } else {
                LOGGER.error(""Properties declaration must be the first element in the configuration"");
            }
            continue;
        } else if (tempLookup == subst.getVariableResolver()) {
            final Map<String, String> map = (Map<String, String>) componentMap.get(CONTEXT_PROPERTIES);
            final StrLookup lookup = map == null ? null : new MapLookup(map);
            subst.setVariableResolver(new Interpolator(lookup));
        }
        if (child.getName().equalsIgnoreCase(""Appenders"")) {
            appenders = (ConcurrentMap<String, Appender>) child.getObject();
        } else if (child.getObject() instanceof Filter) {
            addFilter((Filter) child.getObject());
        } else if (child.getName().equalsIgnoreCase(""Loggers"")) {
            final Loggers l = (Loggers) child.getObject();
            loggers = l.getMap();
            setLoggers = true;
            if (l.getRoot() != null) {
                root = l.getRoot();
                setRoot = true;
            }
        } else {
            LOGGER.error(""Unknown object \"""" + child.getName() + ""\"" of type "" + child.getObject().getClass().getName() + "" is ignored"");
        }
    }
    if (!setLoggers) {
        LOGGER.warn(""No Loggers were configured, using default. Is the Loggers element missing?"");
        setToDefault();
        return;
    } else if (!setRoot) {
        LOGGER.warn(""No Root logger was configured, creating default ERROR-level Root logger with Console appender"");
        setToDefault();
    // return; // LOG4J2-219: creating default root=ok, but don't exclude configured Loggers
    }
    for (final Map.Entry<String, LoggerConfig> entry : loggers.entrySet()) {
        final LoggerConfig l = entry.getValue();
        for (final AppenderRef ref : l.getAppenderRefs()) {
            final Appender app = appenders.get(ref.getRef());
            if (app != null) {
                l.addAppender(app, ref.getLevel(), ref.getFilter());
            } else {
                LOGGER.error(""Unable to locate appender "" + ref.getRef() + "" for logger "" + l.getName());
            }
        }
    }
    setParents();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-430_238ce8aa,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/layout/RFC5424Layout.java,325,343,"private void appendMessage(final StringBuilder buffer, final LogEvent event) {
    final Message message = event.getMessage();
    final String text = message.getFormat();
    if (text != null && text.length() > 0) {
        buffer.append("" "").append(escapeNewlines(text, escapeNewLine));
    }
    if (exceptionFormatters != null && event.getThrown() != null) {
        final StringBuilder exception = new StringBuilder(LF);
        for (final PatternFormatter formatter : exceptionFormatters) {
            formatter.format(event, exception);
        }
        buffer.append(escapeNewlines(exception.toString(), escapeNewLine));
    }
    if (includeNewLine) {
        buffer.append(LF);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-447_0343e9c7,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/layout/XMLLayout.java,123,277,"/**
 * Formats a {@link org.apache.logging.log4j.core.LogEvent} in conformance with the log4j.dtd.
 *
 * @param event The LogEvent.
 * @return The XML representation of the LogEvent.
 */
@Override
public String toSerializable(final LogEvent event) {
    final StringBuilder buf = new StringBuilder(DEFAULT_SIZE);
    buf.append(this.indent1);
    buf.append('<');
    if (!complete) {
        buf.append(this.namespacePrefix);
    }
    buf.append(""Event logger=\"""");
    String name = event.getLoggerName();
    if (name.isEmpty()) {
        name = ""root"";
    }
    buf.append(Transform.escapeHtmlTags(name));
    buf.append(""\"" timestamp=\"""");
    buf.append(event.getMillis());
    buf.append(""\"" level=\"""");
    buf.append(Transform.escapeHtmlTags(String.valueOf(event.getLevel())));
    buf.append(""\"" thread=\"""");
    buf.append(Transform.escapeHtmlTags(event.getThreadName()));
    buf.append(""\"">"");
    buf.append(this.eol);
    final Message msg = event.getMessage();
    if (msg != null) {
        boolean xmlSupported = false;
        if (msg instanceof MultiformatMessage) {
            final String[] formats = ((MultiformatMessage) msg).getFormats();
            for (final String format : formats) {
                if (format.equalsIgnoreCase(""XML"")) {
                    xmlSupported = true;
                    break;
                }
            }
        }
        buf.append(this.indent2);
        buf.append('<');
        if (!complete) {
            buf.append(this.namespacePrefix);
        }
        buf.append(""Message>"");
        if (xmlSupported) {
            buf.append(((MultiformatMessage) msg).getFormattedMessage(FORMATS));
        } else {
            buf.append(""<![CDATA["");
            // Append the rendered message. Also make sure to escape any
            // existing CDATA sections.
            Transform.appendEscapingCDATA(buf, event.getMessage().getFormattedMessage());
            buf.append(""]]>"");
        }
        buf.append(""</"");
        if (!complete) {
            buf.append(this.namespacePrefix);
        }
        buf.append(""Message>"");
        buf.append(this.eol);
    }
    if (event.getContextStack().getDepth() > 0) {
        buf.append(this.indent2);
        buf.append('<');
        if (!complete) {
            buf.append(this.namespacePrefix);
        }
        buf.append(""NDC><![CDATA["");
        Transform.appendEscapingCDATA(buf, event.getContextStack().toString());
        buf.append(""]]></"");
        if (!complete) {
            buf.append(this.namespacePrefix);
        }
        buf.append(""NDC>"");
        buf.append(this.eol);
    }
    final Throwable throwable = event.getThrown();
    if (throwable != null) {
        final List<String> s = Throwables.toStringList(throwable);
        buf.append(this.indent2);
        buf.append('<');
        if (!complete) {
            buf.append(this.namespacePrefix);
        }
        buf.append(""Throwable><![CDATA["");
        for (final String str : s) {
            Transform.appendEscapingCDATA(buf, str);
            buf.append(this.eol);
        }
        buf.append(""]]></"");
        if (!complete) {
            buf.append(this.namespacePrefix);
        }
        buf.append(""Throwable>"");
        buf.append(this.eol);
    }
    if (locationInfo) {
        final StackTraceElement element = event.getSource();
        buf.append(this.indent2);
        buf.append('<');
        if (!complete) {
            buf.append(this.namespacePrefix);
        }
        buf.append(""LocationInfo class=\"""");
        buf.append(Transform.escapeHtmlTags(element.getClassName()));
        buf.append(""\"" method=\"""");
        buf.append(Transform.escapeHtmlTags(element.getMethodName()));
        buf.append(""\"" file=\"""");
        buf.append(Transform.escapeHtmlTags(element.getFileName()));
        buf.append(""\"" line=\"""");
        buf.append(element.getLineNumber());
        buf.append(""\""/>"");
        buf.append(this.eol);
    }
    if (properties && event.getContextMap().size() > 0) {
        buf.append(this.indent2);
        buf.append('<');
        if (!complete) {
            buf.append(this.namespacePrefix);
        }
        buf.append(""Properties>"");
        buf.append(this.eol);
        for (final Map.Entry<String, String> entry : event.getContextMap().entrySet()) {
            buf.append(this.indent3);
            buf.append('<');
            if (!complete) {
                buf.append(this.namespacePrefix);
            }
            buf.append(""Data name=\"""");
            buf.append(Transform.escapeHtmlTags(entry.getKey()));
            buf.append(""\"" value=\"""");
            buf.append(Transform.escapeHtmlTags(String.valueOf(entry.getValue())));
            buf.append(""\""/>"");
            buf.append(this.eol);
        }
        buf.append(this.indent2);
        buf.append(""</"");
        if (!complete) {
            buf.append(this.namespacePrefix);
        }
        buf.append(""Properties>"");
        buf.append(this.eol);
    }
    buf.append(this.indent1);
    buf.append(""</"");
    if (!complete) {
        buf.append(this.namespacePrefix);
    }
    buf.append(""Event>"");
    buf.append(this.eol);
    return buf.toString();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-464_484c865f,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/config/JSONConfiguration.java,203,257,"private Node constructNode(final String name, final Node parent, final JsonNode jsonNode) {
    final PluginType<?> type = pluginManager.getPluginType(name);
    final Node node = new Node(parent, name, type);
    processAttributes(node, jsonNode);
    final Iterator<Map.Entry<String, JsonNode>> iter = jsonNode.fields();
    final List<Node> children = node.getChildren();
    while (iter.hasNext()) {
        final Map.Entry<String, JsonNode> entry = iter.next();
        final JsonNode n = entry.getValue();
        if (n.isArray() || n.isObject()) {
            if (type == null) {
                status.add(new Status(name, n, ErrorType.CLASS_NOT_FOUND));
            }
            if (n.isArray()) {
                LOGGER.debug(""Processing node for array "" + entry.getKey());
                for (int i = 0; i < n.size(); ++i) {
                    final String pluginType = getType(n.get(i), entry.getKey());
                    final PluginType<?> entryType = pluginManager.getPluginType(pluginType);
                    final Node item = new Node(node, entry.getKey(), entryType);
                    processAttributes(item, n.get(i));
                    if (pluginType.equals(entry.getKey())) {
                        LOGGER.debug(""Processing "" + entry.getKey() + ""["" + i + ""]"");
                    } else {
                        LOGGER.debug(""Processing "" + pluginType + "" "" + entry.getKey() + ""["" + i + ""]"");
                    }
                    final Iterator<Map.Entry<String, JsonNode>> itemIter = n.get(i).fields();
                    final List<Node> itemChildren = item.getChildren();
                    while (itemIter.hasNext()) {
                        final Map.Entry<String, JsonNode> itemEntry = itemIter.next();
                        if (itemEntry.getValue().isObject()) {
                            LOGGER.debug(""Processing node for object "" + itemEntry.getKey());
                            itemChildren.add(constructNode(itemEntry.getKey(), item, itemEntry.getValue()));
                        }
                    }
                    children.add(item);
                }
            } else {
                LOGGER.debug(""Processing node for object "" + entry.getKey());
                children.add(constructNode(entry.getKey(), node, n));
            }
        }
    }
    String t;
    if (type == null) {
        t = ""null"";
    } else {
        t = type.getElementName() + "":"" + type.getPluginClass();
    }
    final String p = node.getParent() == null ? ""null"" : node.getParent().getName() == null ? ""root"" : node.getParent().getName();
    LOGGER.debug(""Returning "" + node.getName() + "" with parent "" + p + "" of type "" + t);
    return node;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-466_7b9e48e8,Trivial,log4j-core/src/main/java/org/apache/logging/log4j/core/helpers/FileUtils.java,52,73,"/**
 * Tries to convert the specified URL to a file object. If this fails,
 * <b>null</b> is returned.
 *
 * @param uri the URI
 * @return the resulting file object
 */
public static File fileFromURI(URI uri) {
    if (uri == null || (uri.getScheme() != null && (!PROTOCOL_FILE.equals(uri.getScheme()) && !JBOSS_FILE.equals(uri.getScheme())))) {
        return null;
    }
    if (uri.getScheme() == null) {
        try {
            uri = new File(uri.getPath()).toURI();
        } catch (final Exception ex) {
            LOGGER.warn(""Invalid URI "" + uri);
            return null;
        }
    }
    try {
        return new File(URLDecoder.decode(uri.toURL().getFile(), ""UTF8""));
    } catch (final MalformedURLException ex) {
        LOGGER.warn(""Invalid URL "" + uri, ex);
    } catch (final UnsupportedEncodingException uee) {
        LOGGER.warn(""Invalid encoding: UTF8"", uee);
    }
    return null;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-470_50340d0c,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/LoggerContext.java,331,355,"/**
 * Set the Configuration to be used.
 * @param config The new Configuration.
 * @return The previous Configuration.
 */
private synchronized Configuration setConfiguration(final Configuration config) {
    if (config == null) {
        throw new NullPointerException(""No Configuration was provided"");
    }
    final Configuration prev = this.config;
    config.addListener(this);
    final Map<String, String> map = new HashMap<String, String>();
    map.put(""hostName"", NetUtils.getLocalHostname());
    map.put(""contextName"", name);
    config.addComponent(Configuration.CONTEXT_PROPERTIES, map);
    config.start();
    this.config = config;
    updateLoggers();
    if (prev != null) {
        prev.removeListener(this);
        prev.stop();
    }
    // notify listeners
    final PropertyChangeEvent evt = new PropertyChangeEvent(this, PROPERTY_CONFIG, prev, config);
    for (final PropertyChangeListener listener : propertyChangeListeners) {
        listener.propertyChange(evt);
    }
    return prev;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-470_50340d0c,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/config/BaseConfiguration.java,127,131,"@Override
@SuppressWarnings(""unchecked"")
public Map<String, String> getProperties() {
    return (Map<String, String>) componentMap.get(CONTEXT_PROPERTIES);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-470_50340d0c,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/config/plugins/PropertiesPlugin.java,43,56,"/**
 * Create the Properties component.
 * @param properties An array of Property elements.
 * @param config The Configuration.
 * @return An Interpolator that includes the configuration properties.
 */
@PluginFactory
public static StrLookup configureSubstitutor(@PluginElement(""Properties"") final Property[] properties, @PluginConfiguration final Configuration config) {
    if (properties == null) {
        return new Interpolator(null);
    }
    final Map<String, String> map = new HashMap<String, String>(config.getProperties());
    for (final Property prop : properties) {
        map.put(prop.getName(), prop.getValue());
    }
    return new Interpolator(new MapLookup(map));
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-478_11763dee,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/helpers/Transform.java,119,181,"/**
 * This method takes a string which may contain JSON reserved chars and
 * escapes them.
 *
 * @param input The text to be converted.
 * @return The input string with the special characters replaced.
 */
public static String escapeJsonControlCharacters(final String input) {
    if (Strings.isEmpty(input) || (input.indexOf('""') == -1 && input.indexOf('\\') == -1 && input.indexOf('/') == -1 && input.indexOf('\b') == -1 && input.indexOf('\f') == -1 && input.indexOf('\n') == -1 && input.indexOf('\r') == -1 && input.indexOf('\t') == -1)) {
        return input;
    }
    final StringBuilder buf = new StringBuilder(input.length() + 6);
    final int len = input.length();
    for (int i = 0; i < len; i++) {
        final char ch = input.charAt(i);
        final String escBs = ""\\\\"";
        switch(ch) {
            case '""':
                buf.append(escBs);
                buf.append(ch);
                break;
            case '\\':
                buf.append(escBs);
                buf.append(ch);
                break;
            case '/':
                buf.append(escBs);
                buf.append(ch);
                break;
            case '\b':
                buf.append(escBs);
                buf.append('b');
                break;
            case '\f':
                buf.append(escBs);
                buf.append('f');
                break;
            case '\n':
                buf.append(escBs);
                buf.append('n');
                break;
            case '\r':
                buf.append(escBs);
                buf.append('r');
                break;
            case '\t':
                buf.append(escBs);
                buf.append('t');
                break;
            default:
                buf.append(ch);
        }
    }
    return buf.toString();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-478_11763dee,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/layout/JSONLayout.java,128,289,"/**
 * Formats a {@link org.apache.logging.log4j.core.LogEvent} in conformance with the log4j.dtd.
 *
 * @param event
 *            The LogEvent.
 * @return The XML representation of the LogEvent.
 */
@Override
public String toSerializable(final LogEvent event) {
    final StringBuilder buf = new StringBuilder(DEFAULT_SIZE);
    // DC locking to avoid synchronizing the whole layout.
    boolean check = this.firstLayoutDone;
    if (!this.firstLayoutDone) {
        synchronized (this) {
            check = this.firstLayoutDone;
            if (!check) {
                this.firstLayoutDone = true;
            } else {
                buf.append(',');
                buf.append(this.eol);
            }
        }
    } else {
        buf.append(',');
        buf.append(this.eol);
    }
    buf.append(this.indent1);
    buf.append('{');
    buf.append(this.eol);
    buf.append(this.indent2);
    buf.append(""\""logger\"":\"""");
    String name = event.getLoggerName();
    if (name.isEmpty()) {
        name = ""root"";
    }
    buf.append(Transform.escapeJsonControlCharacters(name));
    buf.append(""\"","");
    buf.append(this.eol);
    buf.append(this.indent2);
    buf.append(""\""timestamp\"":\"""");
    buf.append(event.getMillis());
    buf.append(""\"","");
    buf.append(this.eol);
    buf.append(this.indent2);
    buf.append(""\""level\"":\"""");
    buf.append(Transform.escapeJsonControlCharacters(String.valueOf(event.getLevel())));
    buf.append(""\"","");
    buf.append(this.eol);
    buf.append(this.indent2);
    buf.append(""\""thread\"":\"""");
    buf.append(Transform.escapeJsonControlCharacters(event.getThreadName()));
    buf.append(""\"","");
    buf.append(this.eol);
    final Message msg = event.getMessage();
    if (msg != null) {
        boolean jsonSupported = false;
        if (msg instanceof MultiformatMessage) {
            final String[] formats = ((MultiformatMessage) msg).getFormats();
            for (final String format : formats) {
                if (format.equalsIgnoreCase(""JSON"")) {
                    jsonSupported = true;
                    break;
                }
            }
        }
        buf.append(this.indent2);
        buf.append(""\""message\"":\"""");
        if (jsonSupported) {
            buf.append(((MultiformatMessage) msg).getFormattedMessage(FORMATS));
        } else {
            Transform.appendEscapingCDATA(buf, event.getMessage().getFormattedMessage());
        }
        buf.append('\""');
    }
    if (event.getContextStack().getDepth() > 0) {
        buf.append("","");
        buf.append(this.eol);
        buf.append(""\""ndc\"":"");
        Transform.appendEscapingCDATA(buf, event.getContextStack().toString());
        buf.append(""\"""");
    }
    final Throwable throwable = event.getThrown();
    if (throwable != null) {
        buf.append("","");
        buf.append(this.eol);
        buf.append(this.indent2);
        buf.append(""\""throwable\"":\"""");
        final List<String> list = Throwables.toStringList(throwable);
        for (final String str : list) {
            buf.append(Transform.escapeJsonControlCharacters(str));
            buf.append(""\\\\n"");
        }
        buf.append(""\"""");
    }
    if (this.locationInfo) {
        final StackTraceElement element = event.getSource();
        buf.append("","");
        buf.append(this.eol);
        buf.append(this.indent2);
        buf.append(""\""LocationInfo\"":{"");
        buf.append(this.eol);
        buf.append(this.indent3);
        buf.append(""\""class\"":\"""");
        buf.append(Transform.escapeJsonControlCharacters(element.getClassName()));
        buf.append(""\"","");
        buf.append(this.eol);
        buf.append(this.indent3);
        buf.append(""\""method\"":\"""");
        buf.append(Transform.escapeJsonControlCharacters(element.getMethodName()));
        buf.append(""\"","");
        buf.append(this.eol);
        buf.append(this.indent3);
        buf.append(""\""file\"":\"""");
        buf.append(Transform.escapeJsonControlCharacters(element.getFileName()));
        buf.append(""\"","");
        buf.append(this.eol);
        buf.append(this.indent3);
        buf.append(""\""line\"":\"""");
        buf.append(element.getLineNumber());
        buf.append(""\"""");
        buf.append(this.eol);
        buf.append(this.indent2);
        buf.append(""}"");
    }
    if (this.properties && event.getContextMap().size() > 0) {
        buf.append("","");
        buf.append(this.eol);
        buf.append(this.indent2);
        buf.append(""\""Properties\"":["");
        buf.append(this.eol);
        final Set<Entry<String, String>> entrySet = event.getContextMap().entrySet();
        int i = 1;
        for (final Map.Entry<String, String> entry : entrySet) {
            buf.append(this.indent3);
            buf.append('{');
            buf.append(this.eol);
            buf.append(this.indent4);
            buf.append(""\""name\"":\"""");
            buf.append(Transform.escapeJsonControlCharacters(entry.getKey()));
            buf.append(""\"","");
            buf.append(this.eol);
            buf.append(this.indent4);
            buf.append(""\""value\"":\"""");
            buf.append(Transform.escapeJsonControlCharacters(String.valueOf(entry.getValue())));
            buf.append(""\"""");
            buf.append(this.eol);
            buf.append(this.indent3);
            buf.append(""}"");
            if (i < entrySet.size()) {
                buf.append("","");
            }
            buf.append(this.eol);
            i++;
        }
        buf.append(this.indent2);
        buf.append(""]"");
    }
    buf.append(this.eol);
    buf.append(this.indent1);
    buf.append(""}"");
    return buf.toString();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-492_24a3bed4,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/jmx/Server.java,70,98,"/**
 * Either returns the specified name as is, or returns a quoted value
 * containing the specified name with the special characters (comma, equals,
 * colon, quote, asterisk, or question mark) preceded with a backslash.
 *
 * @param name the name to escape so it can be used as a value in an
 *            {@link ObjectName}.
 * @return the escaped name
 */
public static String escape(final String name) {
    final StringBuilder sb = new StringBuilder(name.length() * 2);
    boolean needsQuotes = false;
    for (int i = 0; i < name.length(); i++) {
        final char c = name.charAt(i);
        switch(c) {
            case '\\':
            case '*':
            case '?':
            case '\""':
                // quote, star, question & backslash must be escaped
                sb.append('\\');
                // ... and can only appear in quoted value
                needsQuotes = true;
                break;
            case ',':
            case '=':
            case ':':
                // no need to escape these, but value must be quoted
                needsQuotes = true;
                break;
        }
        sb.append(c);
    }
    if (needsQuotes) {
        sb.insert(0, '\""');
        sb.append('\""');
    }
    return sb.toString();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-492_61ccbb95,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/jmx/Server.java,70,106,"/**
 * Either returns the specified name as is, or returns a quoted value
 * containing the specified name with the special characters (comma, equals,
 * colon, quote, asterisk, or question mark) preceded with a backslash.
 *
 * @param name the name to escape so it can be used as a value in an
 *            {@link ObjectName}.
 * @return the escaped name
 */
public static String escape(final String name) {
    final StringBuilder sb = new StringBuilder(name.length() * 2);
    boolean needsQuotes = false;
    for (int i = 0; i < name.length(); i++) {
        final char c = name.charAt(i);
        switch(c) {
            case '\\':
            case '*':
            case '?':
            case '\""':
                // quote, star, question & backslash must be escaped
                sb.append('\\');
                // ... and can only appear in quoted value
                needsQuotes = true;
                break;
            case ',':
            case '=':
            case ':':
                // no need to escape these, but value must be quoted
                needsQuotes = true;
                break;
            case '\r':
                // replace by \\r, no need to quote
                sb.append(""\\r"");
                continue;
            case '\n':
                // replace by \\n, no need to quote
                sb.append(""\\n"");
                continue;
        }
        sb.append(c);
    }
    if (needsQuotes) {
        sb.insert(0, '\""');
        sb.append('\""');
    }
    return sb.toString();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-492_61ccbb95,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/jmx/Server.java,261,270,"/**
 * Unregisters all MBeans associated with the specified logger context
 * (including MBeans for {@code LoggerConfig}s and {@code Appender}s from
 * the platform MBean server.
 *
 * @param loggerContextName name of the logger context to unregister
 * @param mbs the MBean Server to unregister the instrumented objects from
 */
public static void unregisterContext(String contextName, MBeanServer mbs) {
    final String pattern = LoggerContextAdminMBean.PATTERN;
    final String search = String.format(pattern, contextName, ""*"");
    // unregister context mbean
    unregisterAllMatching(search, mbs);
    unregisterLoggerConfigs(contextName, mbs);
    unregisterAppenders(contextName, mbs);
    unregisterAsyncAppenders(contextName, mbs);
    unregisterAsyncLoggerRingBufferAdmins(contextName, mbs);
    unregisterAsyncLoggerConfigRingBufferAdmins(contextName, mbs);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-492_a759d8ae,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/jmx/Server.java,71,93,"/**
 * Either returns the specified name as is, or returns a quoted value
 * containing the specified name with the special characters (comma, equals,
 * colon, quote, asterisk, or question mark) preceded with a backslash.
 *
 * @param name
 *            the name to escape so it can be used as a value in an
 *            {@link ObjectName}.
 * @return the escaped name
 */
public static String escape(final String name) {
    final StringBuilder sb = new StringBuilder(name.length() * 2);
    boolean needsQuotes = false;
    for (int i = 0; i < name.length(); i++) {
        final char c = name.charAt(i);
        switch(c) {
            case ',':
            case '=':
            case ':':
            case '\\':
            case '*':
            case '?':
                sb.append('\\');
                needsQuotes = true;
        }
        sb.append(c);
    }
    if (needsQuotes) {
        sb.insert(0, '\""');
        sb.append('\""');
    }
    return sb.toString();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-523_837dcd89,Major,log4j-api/src/main/java/org/apache/logging/log4j/message/LocalizedMessage.java,255,268,"private void writeObject(final ObjectOutputStream out) throws IOException {
    out.defaultWriteObject();
    getFormattedMessage();
    out.writeUTF(formattedMessage);
    out.writeUTF(messagePattern);
    out.writeUTF(baseName);
    out.writeInt(argArray.length);
    stringArgs = new String[argArray.length];
    int i = 0;
    for (final Object obj : argArray) {
        stringArgs[i] = obj.toString();
        ++i;
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-523_837dcd89,Major,log4j-api/src/main/java/org/apache/logging/log4j/message/LocalizedMessage.java,270,283,"private void readObject(final ObjectInputStream in) throws IOException, ClassNotFoundException {
    in.defaultReadObject();
    formattedMessage = in.readUTF();
    messagePattern = in.readUTF();
    baseName = in.readUTF();
    final int length = in.readInt();
    stringArgs = new String[length];
    for (int i = 0; i < length; ++i) {
        stringArgs[i] = in.readUTF();
    }
    logger = StatusLogger.getLogger();
    resourceBundle = null;
    argArray = null;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-56_3eb44094,Minor,log4j2-api/src/main/java/org/apache/logging/log4j/Level.java,95,102,"/**
 * Convert the string passed as argument to a level. If the
 * conversion fails, then this method returns the value of
 * <code>defaultLevel</code>.
 *
 * @param sArg The name of the desired Level.
 * @param defaultLevel The Level to use if the String is invalid.
 * @return The LEvel associated with the String.
 */
public static Level toLevel(String sArg, Level defaultLevel) {
    if (sArg == null) {
        return defaultLevel;
    }
    Level level = valueOf(sArg);
    return (level == null) ? defaultLevel : level;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-581_bb02fa15,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/appender/OutputStreamManager.java,67,74,"/**
 * Default hook to write footer during close.
 */
@Override
public void releaseSub() {
    byte[] footer = layout.getFooter();
    if (footer != null) {
        write(footer);
    }
    close();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-581_bb02fa15,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/appender/rolling/RollingFileManager.java,154,194,"private boolean rollover(final RolloverStrategy strategy) {
    try {
        // Block until the asynchronous operation is completed.
        semaphore.acquire();
    } catch (final InterruptedException ie) {
        LOGGER.error(""Thread interrupted while attempting to check rollover"", ie);
        return false;
    }
    boolean success = false;
    Thread thread = null;
    try {
        final RolloverDescription descriptor = strategy.rollover(this);
        if (descriptor != null) {
            close();
            if (descriptor.getSynchronous() != null) {
                LOGGER.debug(""RollingFileManager executing synchronous {}"", descriptor.getSynchronous());
                try {
                    success = descriptor.getSynchronous().execute();
                } catch (final Exception ex) {
                    LOGGER.error(""Error in synchronous task"", ex);
                }
            }
            if (success && descriptor.getAsynchronous() != null) {
                LOGGER.debug(""RollingFileManager executing async {}"", descriptor.getAsynchronous());
                thread = new Thread(new AsyncAction(descriptor.getAsynchronous(), this));
                thread.start();
            }
            return true;
        }
        return false;
    } finally {
        if (thread == null) {
            semaphore.release();
        }
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-581_bb02fa15,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/appender/rolling/RollingRandomAccessFileManager.java,96,102,"@Override
protected void createFileAfterRollover() throws IOException {
    this.randomAccessFile = new RandomAccessFile(getFileName(), ""rw"");
    if (isAppend()) {
        randomAccessFile.seek(randomAccessFile.length());
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-619_3b4b370e,Critical,log4j-core/src/main/java/org/apache/logging/log4j/core/config/xml/XmlConfiguration.java,238,253,"@Override
public Configuration reconfigure() {
    if (configFile != null) {
        try {
            final ConfigurationFactory.ConfigurationSource source = new ConfigurationFactory.ConfigurationSource(new FileInputStream(configFile), configFile);
            final XmlConfiguration config = new XmlConfiguration(source);
            if (config.rootElement == null) {
                return null;
            }
        } catch (final FileNotFoundException ex) {
            LOGGER.error(""Cannot locate file "" + configFile, ex);
        }
    }
    return null;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-639_a5a1f1a2,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/async/AsyncLogger.java,226,270,"@Override
public void logMessage(final String fqcn, final Level level, final Marker marker, final Message message, final Throwable thrown) {
    Info info = threadlocalInfo.get();
    if (info == null) {
        info = new Info(new RingBufferLogEventTranslator(), Thread.currentThread().getName(), false);
        threadlocalInfo.set(info);
    }
    // being logged calls Logger.log() from its toString() method
    if (info.isAppenderThread && disruptor.getRingBuffer().remainingCapacity() == 0) {
        // bypass RingBuffer and invoke Appender directly
        config.loggerConfig.log(getName(), fqcn, marker, level, message, thrown);
        return;
    }
    final boolean includeLocation = config.loggerConfig.isIncludeLocation();
    // 
    info.translator.setValues(// 
    this, // 
    getName(), // 
    marker, // 
    fqcn, // 
    level, // 
    message, // 
    thrown, // 
    ThreadContext.getImmutableContext(), // 
    ThreadContext.getImmutableStack(), // LOG4J2-467
    THREAD_NAME_STRATEGY.getThreadName(info), // exclude if not specified or if ""false"" was specified.
    includeLocation ? location(fqcn) : null, // CachedClock: 10% faster than system clock, smaller gaps
    clock.currentTimeMillis());
    disruptor.publishEvent(info.translator);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-639_a5a1f1a2,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/async/AsyncLoggerConfigHelper.java,318,330,"/**
 * If possible, delegates the invocation to {@code callAppenders} to another
 * thread and returns {@code true}. If this is not possible (if it detects
 * that delegating to another thread would cause deadlock because the
 * current call to Logger.log() originated from the appender thread and the
 * ringbuffer is full) then this method does nothing and returns {@code false}.
 * It is the responsibility of the caller to process the event when this
 * method returns {@code false}.
 *
 * @param event the event to delegate to another thread
 * @return {@code true} if delegation was successful, {@code false} if the
 *          calling thread needs to process the event itself
 */
public boolean callAppendersFromAnotherThread(final LogEvent event) {
    // being logged calls Logger.log() from its toString() method
    if (// 
    isAppenderThread.get() == Boolean.TRUE && disruptor.getRingBuffer().remainingCapacity() == 0) {
        // bypass RingBuffer and invoke Appender directly
        return false;
    }
    disruptor.getRingBuffer().publishEvent(translator, event, asyncLoggerConfig);
    return true;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-668_60f64cc1,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/appender/AsyncAppender.java,129,164,"/**
 * Actual writing occurs here.
 * <p/>
 * @param logEvent The LogEvent.
 */
@Override
public void append(final LogEvent logEvent) {
    if (!isStarted()) {
        throw new IllegalStateException(""AsyncAppender "" + getName() + "" is not active"");
    }
    if (!(logEvent instanceof Log4jLogEvent)) {
        // only know how to Serialize Log4jLogEvents
        return;
    }
    Log4jLogEvent coreEvent = (Log4jLogEvent) logEvent;
    boolean appendSuccessful = false;
    if (blocking) {
        if (isAppenderThread.get() == Boolean.TRUE && queue.remainingCapacity() == 0) {
            // LOG4J2-485: avoid deadlock that would result from trying
            // to add to a full queue from appender thread
            // queue is definitely not empty!
            coreEvent.setEndOfBatch(false);
            appendSuccessful = thread.callAppenders(coreEvent);
        } else {
            try {
                // wait for free slots in the queue
                queue.put(Log4jLogEvent.serialize(coreEvent, includeLocation));
                appendSuccessful = true;
            } catch (final InterruptedException e) {
                LOGGER.warn(""Interrupted while waiting for a free slot in the AsyncAppender LogEvent-queue {}"", getName());
            }
        }
    } else {
        appendSuccessful = queue.offer(Log4jLogEvent.serialize(coreEvent, includeLocation));
        if (!appendSuccessful) {
            error(""Appender "" + getName() + "" is unable to write primary appenders. queue is full"");
        }
    }
    if (!appendSuccessful && errorAppender != null) {
        errorAppender.callAppender(coreEvent);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-676_3b2e880e,Major,log4j-nosql/src/main/java/org/apache/logging/log4j/nosql/appender/NoSQLDatabaseManager.java,52,55,"@Override
protected void shutdownInternal() {
    Closer.closeSilent(this.connection);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-676_3b2e880e,Major,log4j-nosql/src/main/java/org/apache/logging/log4j/nosql/appender/NoSQLDatabaseManager.java,156,165,"@Override
protected void commitAndClose() {
    try {
        if (this.connection != null && !this.connection.isClosed()) {
            this.connection.close();
        }
    } catch (Exception e) {
        throw new AppenderLoggingException(""Failed to commit and close NoSQL connection in manager."", e);
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-71_2afe3dff,Major,core/src/main/java/org/apache/logging/log4j/core/appender/rolling/helper/FileRenameAction.java,75,93,"/**
 * Rename file.
 *
 * @param source           current file name.
 * @param destination      new file name.
 * @param renameEmptyFiles if true, rename file even if empty, otherwise delete empty files.
 * @return true if successfully renamed.
 */
public static boolean execute(final File source, final File destination, boolean renameEmptyFiles) {
    if (renameEmptyFiles || (source.length() > 0)) {
        try {
            boolean result = source.renameTo(destination);
            // System.out.println(""Rename of "" + source.getName() + "" to "" + destination.getName() + "": "" + result);
            return result;
        } catch (Exception ex) {
            try {
                copyFile(source, destination);
                return source.delete();
            } catch (IOException iex) {
                iex.printStackTrace();
            }
        }
    }
    return false;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-763_97203de8,Major,log4j-api/src/main/java/org/apache/logging/log4j/message/ObjectMessage.java,48,51,"/**
 * Returns the formatted object message.
 * @return the formatted object message.
 */
@Override
public String getFormattedMessage() {
    return obj.toString();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-763_97203de8,Major,log4j-api/src/main/java/org/apache/logging/log4j/message/ObjectMessage.java,57,60,"/**
 * Returns the object formatted using its toString method.
 * @return the String representation of the object.
 */
@Override
public String getFormat() {
    return obj.toString();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-763_97203de8,Major,log4j-api/src/main/java/org/apache/logging/log4j/message/ObjectMessage.java,90,93,"@Override
public String toString() {
    return ""ObjectMessage[obj="" + obj.toString() + ']';
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-763_b2ec5106,Major,log4j-api/src/main/java/org/apache/logging/log4j/message/ObjectMessage.java,76,87,"@Override
public boolean equals(final Object o) {
    if (this == o) {
        return true;
    }
    if (o == null || getClass() != o.getClass()) {
        return false;
    }
    final ObjectMessage that = (ObjectMessage) o;
    return obj == null ? that.obj == null : obj.equals(that.obj);
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-793_73400bfb,Minor,log4j-slf4j-impl/src/main/java/org/apache/logging/slf4j/Log4jLogger.java,377,379,"private static org.apache.logging.log4j.Marker getMarker(final Marker marker) {
    return marker != null ? ((org.apache.logging.slf4j.Log4jMarker) marker).getLog4jMarker() : null;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-793_73400bfb,Minor,log4j-slf4j-impl/src/main/java/org/apache/logging/slf4j/Log4jMarkerFactory.java,38,51,"/**
 * Return a Log4j Marker that is compatible with SLF4J.
 * @param name The name of the Marker.
 * @return A Marker.
 */
@Override
public Marker getMarker(final String name) {
    if (name == null) {
        throw new IllegalArgumentException(""Marker name must not be null"");
    }
    Marker marker = markerMap.get(name);
    if (marker != null) {
        return marker;
    }
    final org.apache.logging.log4j.Marker log4jMarker = MarkerManager.getMarker(name);
    marker = new Log4jMarker(log4jMarker);
    final Marker existing = markerMap.putIfAbsent(name, marker);
    return existing == null ? marker : existing;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-811_7bb1ad47,Major,log4j-api/src/main/java/org/apache/logging/log4j/simple/SimpleLogger.java,125,169,"@Override
public void logMessage(final String fqcn, final Level level, final Marker marker, final Message msg, final Throwable throwable) {
    final StringBuilder sb = new StringBuilder();
    // Append date-time if so configured
    if (showDateTime) {
        final Date now = new Date();
        String dateText;
        synchronized (dateFormatter) {
            dateText = dateFormatter.format(now);
        }
        sb.append(dateText);
        sb.append(SPACE);
    }
    sb.append(level.toString());
    sb.append(SPACE);
    if (logName != null && logName.length() > 0) {
        sb.append(logName);
        sb.append(SPACE);
    }
    sb.append(msg.getFormattedMessage());
    if (showContextMap) {
        final Map<String, String> mdc = ThreadContext.getContext();
        if (mdc.size() > 0) {
            sb.append(SPACE);
            sb.append(mdc.toString());
            sb.append(SPACE);
        }
    }
    final Object[] params = msg.getParameters();
    Throwable t;
    if (throwable == null && params != null && params[params.length - 1] instanceof Throwable) {
        t = (Throwable) params[params.length - 1];
    } else {
        t = throwable;
    }
    if (t != null) {
        sb.append(SPACE);
        final ByteArrayOutputStream baos = new ByteArrayOutputStream();
        t.printStackTrace(new PrintStream(baos));
        sb.append(baos.toString());
    }
    stream.println(sb.toString());
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-813_0bea17d7,Minor,log4j-api/src/main/java/org/apache/logging/log4j/MarkerManager.java,229,232,"@Override
public boolean hasParents() {
    return this.parents == null;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-832_411dad65,Blocker,log4j-core/src/main/java/org/apache/logging/log4j/core/impl/ThrowableProxy.java,494,517,"/**
 * Loads classes not located via Reflection.getCallerClass.
 *
 * @param lastLoader
 *        The ClassLoader that loaded the Class that called this Class.
 * @param className
 *        The name of the Class.
 * @return The Class object for the Class or null if it could not be located.
 */
private Class<?> loadClass(final ClassLoader lastLoader, final String className) {
    // XXX: this is overly complicated
    Class<?> clazz;
    if (lastLoader != null) {
        try {
            clazz = Loader.initializeClass(className, lastLoader);
            if (clazz != null) {
                return clazz;
            }
        } catch (final Exception ignore) {
        // Ignore exception.
        }
    }
    try {
        clazz = Loader.loadClass(className);
    } catch (final ClassNotFoundException ignored) {
        try {
            clazz = Loader.initializeClass(className, this.getClass().getClassLoader());
        } catch (final ClassNotFoundException ignore) {
            return null;
        }
    }
    return clazz;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-834_d3989b40,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/impl/ThrowableProxy.java,438,461,"/**
 * Loads classes not located via Reflection.getCallerClass.
 *
 * @param lastLoader
 *        The ClassLoader that loaded the Class that called this Class.
 * @param className
 *        The name of the Class.
 * @return The Class object for the Class or null if it could not be located.
 */
private Class<?> loadClass(final ClassLoader lastLoader, final String className) {
    // XXX: this is overly complicated
    Class<?> clazz;
    if (lastLoader != null) {
        try {
            clazz = Loader.initializeClass(className, lastLoader);
            if (clazz != null) {
                return clazz;
            }
        } catch (final Throwable ignore) {
        // Ignore exception.
        }
    }
    try {
        clazz = Loader.loadClass(className);
    } catch (final ClassNotFoundException ignored) {
        try {
            clazz = Loader.initializeClass(className, this.getClass().getClassLoader());
        } catch (final ClassNotFoundException ignore) {
            return null;
        }
    }
    return clazz;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-914_f8a42197,Minor,log4j-core/src/main/java/org/apache/logging/log4j/core/impl/ThrowableProxy.java,338,348,"/**
 * Format the stack trace including packaging information.
 *
 * @param ignorePackages
 *        List of packages to be ignored in the trace.
 * @return The formatted stack trace including packaging information.
 */
public String getExtendedStackTraceAsString(final List<String> ignorePackages) {
    final StringBuilder sb = new StringBuilder(this.name);
    final String msg = this.message;
    if (msg != null) {
        sb.append("": "").append(msg);
    }
    sb.append(EOL);
    this.formatElements(sb, 0, this.throwable.getStackTrace(), this.extendedStackTrace, ignorePackages);
    this.formatCause(sb, this.causeProxy, ignorePackages);
    return sb.toString();
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-94_d8af1c93,Major,core/src/main/java/org/apache/logging/log4j/core/lookup/Interpolator.java,92,116,"/**
 * Resolves the specified variable. This implementation will try to extract
 * a variable prefix from the given variable name (the first colon (':') is
 * used as prefix separator). It then passes the name of the variable with
 * the prefix stripped to the lookup object registered for this prefix. If
 * no prefix can be found or if the associated lookup object cannot resolve
 * this variable, the default lookup object will be used.
 *
 * @param event The current LogEvent or null.
 * @param var the name of the variable whose value is to be looked up
 * @return the value of this variable or <b>null</b> if it cannot be
 * resolved
 */
public String lookup(LogEvent event, String var) {
    if (var == null) {
        return null;
    }
    int prefixPos = var.indexOf(PREFIX_SEPARATOR);
    if (prefixPos >= 0) {
        String prefix = var.substring(0, prefixPos);
        String name = var.substring(prefixPos + 1);
        StrLookup lookup = lookups.get(prefix);
        String value = null;
        if (lookup != null) {
            value = event == null ? lookup.lookup(name) : lookup.lookup(event, name);
        }
        if (value != null) {
            return value;
        }
        var = var.substring(prefixPos);
    }
    if (defaultLookup != null) {
        return event == null ? defaultLookup.lookup(var) : defaultLookup.lookup(event, var);
    }
    return null;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-964_16ad8763,Major,log4j-api/src/main/java/org/apache/logging/log4j/message/StringFormattedMessage.java,127,139,"private void writeObject(final ObjectOutputStream out) throws IOException {
    out.defaultWriteObject();
    getFormattedMessage();
    out.writeUTF(formattedMessage);
    out.writeUTF(messagePattern);
    out.writeInt(argArray.length);
    stringArgs = new String[argArray.length];
    int i = 0;
    for (final Object obj : argArray) {
        stringArgs[i] = obj.toString();
        ++i;
    }
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-965_43517f15,Critical,log4j-core/src/main/java/org/apache/logging/log4j/core/appender/ConsoleAppender.java,181,210,"private static OutputStream getOutputStream(final boolean follow, final Target target) {
    final String enc = Charset.defaultCharset().name();
    PrintStream printStream = null;
    try {
        printStream = target == Target.SYSTEM_OUT ? follow ? new PrintStream(new CloseShieldOutputStream(System.out), true, enc) : System.out : follow ? new PrintStream(new CloseShieldOutputStream(System.err), true, enc) : System.err;
    } catch (final UnsupportedEncodingException ex) {
        // should never happen
        throw new IllegalStateException(""Unsupported default encoding "" + enc, ex);
    }
    final PropertiesUtil propsUtil = PropertiesUtil.getProperties();
    if (!propsUtil.getStringProperty(""os.name"").startsWith(""Windows"") || propsUtil.getBooleanProperty(""log4j.skipJansi"")) {
        return printStream;
    }
    try {
        // We type the parameter as a wildcard to avoid a hard reference to Jansi.
        final Class<?> clazz = Loader.loadClass(JANSI_CLASS);
        final Constructor<?> constructor = clazz.getConstructor(OutputStream.class);
        // LOG4J-965
        return new CloseShieldOutputStream((OutputStream) constructor.newInstance(printStream));
    } catch (final ClassNotFoundException cnfe) {
        LOGGER.debug(""Jansi is not installed, cannot find {}"", JANSI_CLASS);
    } catch (final NoSuchMethodException nsme) {
        LOGGER.warn(""{} is missing the proper constructor"", JANSI_CLASS);
    } catch (final Exception ex) {
        LOGGER.warn(""Unable to instantiate {}"", JANSI_CLASS);
    }
    return printStream;
}"
logging-log4j2,remotes/origin/bugs-dot-jar_LOG4J2-991_3cee912e,Major,log4j-core/src/main/java/org/apache/logging/log4j/core/async/AsyncLoggerConfig.java,216,240,"@PluginFactory
public static LoggerConfig createLogger(@PluginAttribute(""additivity"") final String additivity, @PluginAttribute(""level"") final String levelName, @PluginAttribute(""includeLocation"") final String includeLocation, @PluginElement(""AppenderRef"") final AppenderRef[] refs, @PluginElement(""Properties"") final Property[] properties, @PluginConfiguration final Configuration config, @PluginElement(""Filter"") final Filter filter) {
    final List<AppenderRef> appenderRefs = Arrays.asList(refs);
    Level level;
    try {
        level = Level.toLevel(levelName, Level.ERROR);
    } catch (final Exception ex) {
        LOGGER.error(""Invalid Log level specified: {}. Defaulting to Error"", levelName);
        level = Level.ERROR;
    }
    final boolean additive = Booleans.parseBoolean(additivity, true);
    return new AsyncLoggerConfig(LogManager.ROOT_LOGGER_NAME, appenderRefs, filter, level, additive, properties, config, includeLocation(includeLocation));
}"
maven,remotes/origin/bugs-dot-jar_MNG-1205_1bdeeccc,Major,maven-artifact/src/main/java/org/apache/maven/artifact/resolver/DefaultArtifactCollector.java,56,99,"public ArtifactResolutionResult collect(Set artifacts, Artifact originatingArtifact, Map managedVersions, ArtifactRepository localRepository, List remoteRepositories, ArtifactMetadataSource source, ArtifactFilter filter, List listeners) throws ArtifactResolutionException {
    Map resolvedArtifacts = new HashMap();
    ResolutionNode root = new ResolutionNode(originatingArtifact, remoteRepositories);
    root.addDependencies(artifacts, remoteRepositories, filter);
    recurse(root, resolvedArtifacts, managedVersions, localRepository, remoteRepositories, source, filter, listeners);
    Set set = new HashSet();
    for (Iterator i = resolvedArtifacts.values().iterator(); i.hasNext(); ) {
        List nodes = (List) i.next();
        for (Iterator j = nodes.iterator(); j.hasNext(); ) {
            ResolutionNode node = (ResolutionNode) j.next();
            if (!node.equals(root) && node.isActive()) {
                Artifact artifact = node.getArtifact();
                if (node.filterTrail(filter)) {
                    // If it was optional, we don't add it or its children, just allow the update of the version and scope
                    if (!artifact.isOptional()) {
                        artifact.setDependencyTrail(node.getDependencyTrail());
                        set.add(node);
                    }
                }
            }
        }
    }
    ArtifactResolutionResult result = new ArtifactResolutionResult();
    result.setArtifactResolutionNodes(set);
    return result;
}"
maven,remotes/origin/bugs-dot-jar_MNG-1205_1bdeeccc,Major,maven-artifact/src/main/java/org/apache/maven/artifact/resolver/DefaultArtifactCollector.java,101,310,"private void recurse(ResolutionNode node, Map resolvedArtifacts, Map managedVersions, ArtifactRepository localRepository, List remoteRepositories, ArtifactMetadataSource source, ArtifactFilter filter, List listeners) throws CyclicDependencyException, ArtifactResolutionException, OverConstrainedVersionException {
    fireEvent(ResolutionListener.TEST_ARTIFACT, listeners, node);
    // TODO: use as a conflict resolver
    Object key = node.getKey();
    if (managedVersions.containsKey(key)) {
        Artifact artifact = (Artifact) managedVersions.get(key);
        fireEvent(ResolutionListener.MANAGE_ARTIFACT, listeners, node, artifact);
        if (artifact.getVersion() != null) {
            node.getArtifact().setVersion(artifact.getVersion());
        }
        if (artifact.getScope() != null) {
            node.getArtifact().setScope(artifact.getScope());
        }
    }
    List previousNodes = (List) resolvedArtifacts.get(key);
    if (previousNodes != null) {
        for (Iterator i = previousNodes.iterator(); i.hasNext(); ) {
            ResolutionNode previous = (ResolutionNode) i.next();
            if (previous.isActive()) {
                // Version mediation
                VersionRange previousRange = previous.getArtifact().getVersionRange();
                VersionRange currentRange = node.getArtifact().getVersionRange();
                // TODO: why do we force the version on it? what if they don't match?
                if (previousRange == null) {
                    // version was already resolved
                    node.getArtifact().setVersion(previous.getArtifact().getVersion());
                } else if (currentRange == null) {
                    // version was already resolved
                    previous.getArtifact().setVersion(node.getArtifact().getVersion());
                } else {
                    // TODO: shouldn't need to double up on this work, only done for simplicity of handling recommended
                    // version but the restriction is identical
                    VersionRange newRange = previousRange.restrict(currentRange);
                    // TODO: ick. this forces the OCE that should have come from the previous call. It is still correct
                    if (newRange.isSelectedVersionKnown(previous.getArtifact())) {
                        fireEvent(ResolutionListener.RESTRICT_RANGE, listeners, node, previous.getArtifact(), newRange);
                    }
                    previous.getArtifact().setVersionRange(newRange);
                    node.getArtifact().setVersionRange(currentRange.restrict(previousRange));
                    // Select an appropriate available version from the (now restricted) range
                    // Note this version was selected before to get the appropriate POM
                    // But it was reset by the call to setVersionRange on restricting the version
                    ResolutionNode[] resetNodes = { previous, node };
                    for (int j = 0; j < 2; j++) {
                        Artifact resetArtifact = resetNodes[j].getArtifact();
                        if (resetArtifact.getVersion() == null && resetArtifact.getVersionRange() != null && resetArtifact.getAvailableVersions() != null) {
                            resetArtifact.selectVersion(resetArtifact.getVersionRange().matchVersion(resetArtifact.getAvailableVersions()).toString());
                            fireEvent(ResolutionListener.SELECT_VERSION_FROM_RANGE, listeners, resetNodes[j]);
                        }
                    }
                }
                // previous one is more dominant
                if (previous.getDepth() <= node.getDepth()) {
                    checkScopeUpdate(node, previous, listeners);
                } else {
                    checkScopeUpdate(previous, node, listeners);
                }
                if (previous.getDepth() <= node.getDepth()) {
                    // previous was nearer
                    fireEvent(ResolutionListener.OMIT_FOR_NEARER, listeners, node, previous.getArtifact());
                    node.disable();
                } else {
                    fireEvent(ResolutionListener.OMIT_FOR_NEARER, listeners, previous, node.getArtifact());
                    previous.disable();
                }
            }
        }
    } else {
        previousNodes = new ArrayList();
        resolvedArtifacts.put(key, previousNodes);
    }
    previousNodes.add(node);
    fireEvent(ResolutionListener.INCLUDE_ARTIFACT, listeners, node);
    if (node.isActive()) {
        fireEvent(ResolutionListener.PROCESS_CHILDREN, listeners, node);
        for (Iterator i = node.getChildrenIterator(); i.hasNext(); ) {
            ResolutionNode child = (ResolutionNode) i.next();
            // We leave in optional ones, but don't pick up its dependencies
            if (!child.isResolved() && !child.getArtifact().isOptional()) {
                Artifact artifact = child.getArtifact();
                try {
                    if (artifact.getVersion() == null) {
                        // set the recommended version
                        // TODO: maybe its better to just pass the range through to retrieval and use a transformation?
                        ArtifactVersion version;
                        if (!artifact.isSelectedVersionKnown()) {
                            List versions = artifact.getAvailableVersions();
                            if (versions == null) {
                                versions = source.retrieveAvailableVersions(artifact, localRepository, remoteRepositories);
                                artifact.setAvailableVersions(versions);
                            }
                            VersionRange versionRange = artifact.getVersionRange();
                            version = versionRange.matchVersion(versions);
                            if (version == null) {
                                if (versions.isEmpty()) {
                                    throw new OverConstrainedVersionException(""No versions are present in the repository for the artifact with a range "" + versionRange, artifact, remoteRepositories);
                                } else {
                                    throw new OverConstrainedVersionException(""Couldn't find a version in "" + versions + "" to match range "" + versionRange, artifact, remoteRepositories);
                                }
                            }
                        } else {
                            version = artifact.getSelectedVersion();
                        }
                        artifact.selectVersion(version.toString());
                        fireEvent(ResolutionListener.SELECT_VERSION_FROM_RANGE, listeners, child);
                    }
                    ResolutionGroup rGroup = source.retrieve(artifact, localRepository, remoteRepositories);
                    // and catch here rather than have it return null
                    if (rGroup == null) {
                        // relocated dependency artifact is declared excluded, no need to add and recurse further
                        continue;
                    }
                    child.addDependencies(rGroup.getArtifacts(), rGroup.getResolutionRepositories(), filter);
                } catch (CyclicDependencyException e) {
                    // would like to throw this, but we have crappy stuff in the repo
                    fireEvent(ResolutionListener.OMIT_FOR_CYCLE, listeners, new ResolutionNode(e.getArtifact(), remoteRepositories, child));
                } catch (ArtifactMetadataRetrievalException e) {
                    artifact.setDependencyTrail(node.getDependencyTrail());
                    throw new ArtifactResolutionException(""Unable to get dependency information: "" + e.getMessage(), artifact, remoteRepositories, e);
                }
                recurse(child, resolvedArtifacts, managedVersions, localRepository, remoteRepositories, source, filter, listeners);
            }
        }
        fireEvent(ResolutionListener.FINISH_PROCESSING_CHILDREN, listeners, node);
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-1509_4e955c05,Major,maven-project/src/main/java/org/apache/maven/profiles/activation/OperatingSystemProfileActivator.java,34,47,"public boolean isActive(Profile profile) {
    Activation activation = profile.getActivation();
    ActivationOS os = activation.getOs();
    boolean hasNonNull = ensureAtLeastOneNonNull(os);
    boolean isFamily = determineFamilyMatch(os.getFamily());
    boolean isName = determineNameMatch(os.getName());
    boolean isArch = determineArchMatch(os.getArch());
    boolean isVersion = determineVersionMatch(os.getVersion());
    return hasNonNull && isFamily && isName && isArch && isVersion;
}"
maven,remotes/origin/bugs-dot-jar_MNG-1703_b68c84b8,Major,maven-project/src/main/java/org/apache/maven/project/ModelUtils.java,186,267,"public static void mergePluginDefinitions(Plugin child, Plugin parent, boolean handleAsInheritance) {
    if (child == null || parent == null) {
        // nothing to do.
        return;
    }
    if (parent.isExtensions()) {
        child.setExtensions(true);
    }
    if (child.getVersion() == null && parent.getVersion() != null) {
        child.setVersion(parent.getVersion());
    }
    Xpp3Dom childConfiguration = (Xpp3Dom) child.getConfiguration();
    Xpp3Dom parentConfiguration = (Xpp3Dom) parent.getConfiguration();
    childConfiguration = Xpp3Dom.mergeXpp3Dom(childConfiguration, parentConfiguration);
    child.setConfiguration(childConfiguration);
    // from here to the end of the method is dealing with merging of the <executions/> section.
    String parentInherited = parent.getInherited();
    boolean parentIsInherited = parentInherited == null || Boolean.valueOf(parentInherited).booleanValue();
    List parentExecutions = parent.getExecutions();
    if (parentExecutions != null && !parentExecutions.isEmpty()) {
        List mergedExecutions = new ArrayList();
        Map assembledExecutions = new TreeMap();
        Map childExecutions = child.getExecutionsAsMap();
        for (Iterator it = parentExecutions.iterator(); it.hasNext(); ) {
            PluginExecution parentExecution = (PluginExecution) it.next();
            if (!handleAsInheritance || parentIsInherited) {
                PluginExecution assembled = parentExecution;
                PluginExecution childExecution = (PluginExecution) childExecutions.get(parentExecution.getId());
                if (childExecution != null) {
                    mergePluginExecutionDefinitions(childExecution, parentExecution);
                    assembled = childExecution;
                } else if (handleAsInheritance && parentInherited == null) {
                    parentExecution.unsetInheritanceApplied();
                }
                assembledExecutions.put(assembled.getId(), assembled);
                mergedExecutions.add(assembled);
            }
        }
        for (Iterator it = child.getExecutions().iterator(); it.hasNext(); ) {
            PluginExecution childExecution = (PluginExecution) it.next();
            if (!assembledExecutions.containsKey(childExecution.getId())) {
                mergedExecutions.add(childExecution);
            }
        }
        child.setExecutions(mergedExecutions);
        child.flushExecutionMap();
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-1797_5d99b35c,Major,maven-project/src/main/java/org/apache/maven/project/artifact/MavenMetadataSource.java,302,378,"/**
 * @todo desperately needs refactoring. It's just here because it's implementation is maven-project specific
 */
public static Set createArtifacts(ArtifactFactory artifactFactory, List dependencies, String inheritedScope, ArtifactFilter dependencyFilter, MavenProject project) throws InvalidDependencyVersionException {
    Set projectArtifacts = new LinkedHashSet(dependencies.size());
    for (Iterator i = dependencies.iterator(); i.hasNext(); ) {
        Dependency d = (Dependency) i.next();
        String scope = d.getScope();
        if (StringUtils.isEmpty(scope)) {
            scope = Artifact.SCOPE_COMPILE;
            d.setScope(scope);
        }
        VersionRange versionRange;
        try {
            versionRange = VersionRange.createFromVersionSpec(d.getVersion());
        } catch (InvalidVersionSpecificationException e) {
            throw new InvalidDependencyVersionException(""Unable to parse version '"" + d.getVersion() + ""' for dependency '"" + d.getManagementKey() + ""': "" + e.getMessage(), e);
        }
        Artifact artifact = artifactFactory.createDependencyArtifact(d.getGroupId(), d.getArtifactId(), versionRange, d.getType(), d.getClassifier(), scope, inheritedScope, d.isOptional());
        if (Artifact.SCOPE_SYSTEM.equals(scope)) {
            artifact.setFile(new File(d.getSystemPath()));
        }
        if (artifact != null && (dependencyFilter == null || dependencyFilter.include(artifact))) {
            if (d.getExclusions() != null && !d.getExclusions().isEmpty()) {
                List exclusions = new ArrayList();
                for (Iterator j = d.getExclusions().iterator(); j.hasNext(); ) {
                    Exclusion e = (Exclusion) j.next();
                    exclusions.add(e.getGroupId() + "":"" + e.getArtifactId());
                }
                ArtifactFilter newFilter = new ExcludesArtifactFilter(exclusions);
                if (dependencyFilter != null) {
                    AndArtifactFilter filter = new AndArtifactFilter();
                    filter.add(dependencyFilter);
                    filter.add(newFilter);
                    dependencyFilter = filter;
                } else {
                    dependencyFilter = newFilter;
                }
            }
            artifact.setDependencyFilter(dependencyFilter);
            if (project != null) {
                artifact = project.replaceWithActiveArtifact(artifact);
            }
            projectArtifacts.add(artifact);
        }
    }
    return projectArtifacts;
}"
maven,remotes/origin/bugs-dot-jar_MNG-1856_faa5cf27,Minor,maven-project/src/main/java/org/apache/maven/project/inheritance/DefaultModelInheritanceAssembler.java,65,187,"private void assembleModelInheritance(Model child, Model parent, String childPathAdjustment, boolean appendPaths) {
    // cannot inherit from null parent.
    if (parent == null) {
        return;
    }
    // Group id
    if (child.getGroupId() == null) {
        child.setGroupId(parent.getGroupId());
    }
    // version
    if (child.getVersion() == null) {
        if (child.getParent() != null) {
            child.setVersion(child.getParent().getVersion());
        }
    }
    // inceptionYear
    if (child.getInceptionYear() == null) {
        child.setInceptionYear(parent.getInceptionYear());
    }
    // url
    if (child.getUrl() == null) {
        if (parent.getUrl() != null) {
            child.setUrl(appendPath(parent.getUrl(), child.getArtifactId(), childPathAdjustment, appendPaths));
        } else {
            child.setUrl(parent.getUrl());
        }
    }
    // ----------------------------------------------------------------------
    // Distribution
    // ----------------------------------------------------------------------
    assembleDistributionInheritence(child, parent, childPathAdjustment, appendPaths);
    // issueManagement
    if (child.getIssueManagement() == null) {
        child.setIssueManagement(parent.getIssueManagement());
    }
    // description
    if (child.getDescription() == null) {
        child.setDescription(parent.getDescription());
    }
    // Organization
    if (child.getOrganization() == null) {
        child.setOrganization(parent.getOrganization());
    }
    // Scm
    assembleScmInheritance(child, parent, childPathAdjustment, appendPaths);
    // ciManagement
    if (child.getCiManagement() == null) {
        child.setCiManagement(parent.getCiManagement());
    }
    // developers
    if (child.getDevelopers().size() == 0) {
        child.setDevelopers(parent.getDevelopers());
    }
    // licenses
    if (child.getLicenses().size() == 0) {
        child.setLicenses(parent.getLicenses());
    }
    // developers
    if (child.getContributors().size() == 0) {
        child.setContributors(parent.getContributors());
    }
    // mailingLists
    if (child.getMailingLists().size() == 0) {
        child.setMailingLists(parent.getMailingLists());
    }
    // Build
    assembleBuildInheritance(child, parent);
    assembleDependencyInheritance(child, parent);
    child.setRepositories(ModelUtils.mergeRepositoryLists(child.getRepositories(), parent.getRepositories()));
    child.setPluginRepositories(ModelUtils.mergeRepositoryLists(child.getPluginRepositories(), parent.getPluginRepositories()));
    assembleReportingInheritance(child, parent);
    assembleDependencyManagementInheritance(child, parent);
    assembleDistributionManagementInheritance(child, parent);
    Properties props = new Properties();
    props.putAll(parent.getProperties());
    props.putAll(child.getProperties());
    child.setProperties(props);
}"
maven,remotes/origin/bugs-dot-jar_MNG-1856_faa5cf27,Minor,maven-project/src/main/java/org/apache/maven/project/inheritance/DefaultModelInheritanceAssembler.java,189,227,"private void assembleDistributionManagementInheritance(Model child, Model parent) {
    DistributionManagement cDistMgmt = child.getDistributionManagement();
    DistributionManagement pDistMgmt = parent.getDistributionManagement();
    if (cDistMgmt == null) {
        child.setDistributionManagement(pDistMgmt);
    } else if (pDistMgmt != null) {
        if (cDistMgmt.getRepository() == null) {
            cDistMgmt.setRepository(pDistMgmt.getRepository());
        }
        if (cDistMgmt.getSnapshotRepository() == null) {
            cDistMgmt.setSnapshotRepository(pDistMgmt.getSnapshotRepository());
        }
        if (StringUtils.isEmpty(cDistMgmt.getDownloadUrl())) {
            cDistMgmt.setDownloadUrl(pDistMgmt.getDownloadUrl());
        }
        if (cDistMgmt.getRelocation() == null) {
            cDistMgmt.setRelocation(pDistMgmt.getRelocation());
        }
        if (cDistMgmt.getSite() == null) {
            cDistMgmt.setSite(pDistMgmt.getSite());
        }
    // NOTE: We SHOULD NOT be inheriting status, since this is an assessment of the POM quality.
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-1856_faa5cf27,Minor,maven-project/src/main/java/org/apache/maven/project/inheritance/DefaultModelInheritanceAssembler.java,447,521,"private void assembleDistributionInheritence(Model child, Model parent, String childPathAdjustment, boolean appendPaths) {
    if (parent.getDistributionManagement() != null) {
        DistributionManagement parentDistMgmt = parent.getDistributionManagement();
        DistributionManagement childDistMgmt = child.getDistributionManagement();
        if (childDistMgmt == null) {
            childDistMgmt = new DistributionManagement();
            child.setDistributionManagement(childDistMgmt);
        }
        if (childDistMgmt.getSite() == null) {
            if (parentDistMgmt.getSite() != null) {
                Site site = new Site();
                childDistMgmt.setSite(site);
                site.setId(parentDistMgmt.getSite().getId());
                site.setName(parentDistMgmt.getSite().getName());
                site.setUrl(parentDistMgmt.getSite().getUrl());
                if (site.getUrl() != null) {
                    site.setUrl(appendPath(site.getUrl(), child.getArtifactId(), childPathAdjustment, appendPaths));
                }
            }
        }
        if (childDistMgmt.getRepository() == null) {
            if (parentDistMgmt.getRepository() != null) {
                DeploymentRepository repository = new DeploymentRepository();
                childDistMgmt.setRepository(repository);
                repository.setId(parentDistMgmt.getRepository().getId());
                repository.setName(parentDistMgmt.getRepository().getName());
                repository.setUrl(parentDistMgmt.getRepository().getUrl());
                repository.setUniqueVersion(parentDistMgmt.getRepository().isUniqueVersion());
            }
        }
        if (childDistMgmt.getSnapshotRepository() == null) {
            if (parentDistMgmt.getSnapshotRepository() != null) {
                DeploymentRepository repository = new DeploymentRepository();
                childDistMgmt.setSnapshotRepository(repository);
                repository.setId(parentDistMgmt.getSnapshotRepository().getId());
                repository.setName(parentDistMgmt.getSnapshotRepository().getName());
                repository.setUrl(parentDistMgmt.getSnapshotRepository().getUrl());
                repository.setUniqueVersion(parentDistMgmt.getSnapshotRepository().isUniqueVersion());
            }
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-1895_24db0eb9,Blocker,maven-artifact/src/main/java/org/apache/maven/artifact/resolver/DefaultArtifactCollector.java,102,320,"private void recurse(ResolutionNode node, Map resolvedArtifacts, Map managedVersions, ArtifactRepository localRepository, List remoteRepositories, ArtifactMetadataSource source, ArtifactFilter filter, List listeners) throws CyclicDependencyException, ArtifactResolutionException, OverConstrainedVersionException {
    fireEvent(ResolutionListener.TEST_ARTIFACT, listeners, node);
    // TODO: use as a conflict resolver
    Object key = node.getKey();
    if (managedVersions.containsKey(key)) {
        Artifact artifact = (Artifact) managedVersions.get(key);
        fireEvent(ResolutionListener.MANAGE_ARTIFACT, listeners, node, artifact);
        if (artifact.getVersion() != null) {
            node.getArtifact().setVersion(artifact.getVersion());
        }
        if (artifact.getScope() != null) {
            node.getArtifact().setScope(artifact.getScope());
        }
    }
    List previousNodes = (List) resolvedArtifacts.get(key);
    if (previousNodes != null) {
        for (Iterator i = previousNodes.iterator(); i.hasNext(); ) {
            ResolutionNode previous = (ResolutionNode) i.next();
            if (previous.isActive()) {
                // Version mediation
                VersionRange previousRange = previous.getArtifact().getVersionRange();
                VersionRange currentRange = node.getArtifact().getVersionRange();
                // TODO: why do we force the version on it? what if they don't match?
                if (previousRange == null) {
                    // version was already resolved
                    node.getArtifact().setVersion(previous.getArtifact().getVersion());
                } else if (currentRange == null) {
                    // version was already resolved
                    previous.getArtifact().setVersion(node.getArtifact().getVersion());
                } else {
                    // TODO: shouldn't need to double up on this work, only done for simplicity of handling recommended
                    // version but the restriction is identical
                    VersionRange newRange = previousRange.restrict(currentRange);
                    // TODO: ick. this forces the OCE that should have come from the previous call. It is still correct
                    if (newRange.isSelectedVersionKnown(previous.getArtifact())) {
                        fireEvent(ResolutionListener.RESTRICT_RANGE, listeners, node, previous.getArtifact(), newRange);
                    }
                    previous.getArtifact().setVersionRange(newRange);
                    node.getArtifact().setVersionRange(currentRange.restrict(previousRange));
                    // Select an appropriate available version from the (now restricted) range
                    // Note this version was selected before to get the appropriate POM
                    // But it was reset by the call to setVersionRange on restricting the version
                    ResolutionNode[] resetNodes = { previous, node };
                    for (int j = 0; j < 2; j++) {
                        Artifact resetArtifact = resetNodes[j].getArtifact();
                        if (resetArtifact.getVersion() == null && resetArtifact.getVersionRange() != null && resetArtifact.getAvailableVersions() != null) {
                            resetArtifact.selectVersion(resetArtifact.getVersionRange().matchVersion(resetArtifact.getAvailableVersions()).toString());
                            fireEvent(ResolutionListener.SELECT_VERSION_FROM_RANGE, listeners, resetNodes[j]);
                        }
                    }
                }
                // Conflict Resolution
                // TODO: use as conflict resolver(s), chain
                // TODO: should this be part of mediation?
                // previous one is more dominant
                ResolutionNode nearest, farthest;
                if (previous.getDepth() <= node.getDepth()) {
                    nearest = previous;
                    farthest = node;
                } else {
                    nearest = node;
                    farthest = previous;
                }
                /* if we need to update scope of nearest to use farthest scope */
                if (checkScopeUpdate(farthest, nearest, listeners)) {
                    fireEvent(ResolutionListener.UPDATE_SCOPE, listeners, nearest, farthest.getArtifact());
                    // previously we cloned the artifact, but it is more effecient to just update the scope
                    // if problems are later discovered that the original object needs its original scope value, cloning may
                    // again be appropriate
                    nearest.getArtifact().setScope(farthest.getArtifact().getScope());
                }
                fireEvent(ResolutionListener.OMIT_FOR_NEARER, listeners, farthest, nearest.getArtifact());
                farthest.disable();
            }
        }
    } else {
        previousNodes = new ArrayList();
        resolvedArtifacts.put(key, previousNodes);
    }
    previousNodes.add(node);
    if (node.isActive()) {
        fireEvent(ResolutionListener.INCLUDE_ARTIFACT, listeners, node);
    }
    // don't pull in the transitive deps of a system-scoped dependency.
    if (node.isActive() && !Artifact.SCOPE_SYSTEM.equals(node.getArtifact().getScope())) {
        fireEvent(ResolutionListener.PROCESS_CHILDREN, listeners, node);
        for (Iterator i = node.getChildrenIterator(); i.hasNext(); ) {
            ResolutionNode child = (ResolutionNode) i.next();
            // We leave in optional ones, but don't pick up its dependencies
            if (!child.isResolved() && (!child.getArtifact().isOptional() || child.isChildOfRootNode())) {
                Artifact artifact = child.getArtifact();
                try {
                    if (artifact.getVersion() == null) {
                        // set the recommended version
                        // TODO: maybe its better to just pass the range through to retrieval and use a transformation?
                        ArtifactVersion version;
                        if (!artifact.isSelectedVersionKnown()) {
                            List versions = artifact.getAvailableVersions();
                            if (versions == null) {
                                versions = source.retrieveAvailableVersions(artifact, localRepository, remoteRepositories);
                                artifact.setAvailableVersions(versions);
                            }
                            VersionRange versionRange = artifact.getVersionRange();
                            version = versionRange.matchVersion(versions);
                            if (version == null) {
                                if (versions.isEmpty()) {
                                    throw new OverConstrainedVersionException(""No versions are present in the repository for the artifact with a range "" + versionRange, artifact, remoteRepositories);
                                } else {
                                    throw new OverConstrainedVersionException(""Couldn't find a version in "" + versions + "" to match range "" + versionRange, artifact, remoteRepositories);
                                }
                            }
                        } else {
                            version = artifact.getSelectedVersion();
                        }
                        artifact.selectVersion(version.toString());
                        fireEvent(ResolutionListener.SELECT_VERSION_FROM_RANGE, listeners, child);
                    }
                    artifact.setDependencyTrail(node.getDependencyTrail());
                    ResolutionGroup rGroup = source.retrieve(artifact, localRepository, remoteRepositories);
                    // and catch here rather than have it return null
                    if (rGroup == null) {
                        // relocated dependency artifact is declared excluded, no need to add and recurse further
                        continue;
                    }
                    child.addDependencies(rGroup.getArtifacts(), rGroup.getResolutionRepositories(), filter);
                } catch (CyclicDependencyException e) {
                    // would like to throw this, but we have crappy stuff in the repo
                    fireEvent(ResolutionListener.OMIT_FOR_CYCLE, listeners, new ResolutionNode(e.getArtifact(), remoteRepositories, child));
                } catch (ArtifactMetadataRetrievalException e) {
                    artifact.setDependencyTrail(node.getDependencyTrail());
                    throw new ArtifactResolutionException(""Unable to get dependency information: "" + e.getMessage(), artifact, remoteRepositories, e);
                }
                recurse(child, resolvedArtifacts, managedVersions, localRepository, remoteRepositories, source, filter, listeners);
            }
        }
        fireEvent(ResolutionListener.FINISH_PROCESSING_CHILDREN, listeners, node);
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-1895_806eaeb0,Blocker,maven-artifact/src/main/java/org/apache/maven/artifact/resolver/DefaultArtifactCollector.java,56,100,"public ArtifactResolutionResult collect(Set artifacts, Artifact originatingArtifact, Map managedVersions, ArtifactRepository localRepository, List remoteRepositories, ArtifactMetadataSource source, ArtifactFilter filter, List listeners) throws ArtifactResolutionException {
    Map resolvedArtifacts = new HashMap();
    ResolutionNode root = new ResolutionNode(originatingArtifact, remoteRepositories);
    root.addDependencies(artifacts, remoteRepositories, filter);
    recurse(root, resolvedArtifacts, managedVersions, localRepository, remoteRepositories, source, filter, listeners);
    Set set = new HashSet();
    for (Iterator i = resolvedArtifacts.values().iterator(); i.hasNext(); ) {
        List nodes = (List) i.next();
        for (Iterator j = nodes.iterator(); j.hasNext(); ) {
            ResolutionNode node = (ResolutionNode) j.next();
            if (!node.equals(root) && node.isActive()) {
                Artifact artifact = node.getArtifact();
                if (node.filterTrail(filter)) {
                    // we don't add it or its children, just allow the update of the version and scope
                    if (node.isChildOfRootNode() || !artifact.isOptional()) {
                        artifact.setDependencyTrail(node.getDependencyTrail());
                        set.add(node);
                    }
                }
            }
        }
    }
    ArtifactResolutionResult result = new ArtifactResolutionResult();
    result.setArtifactResolutionNodes(set);
    return result;
}"
maven,remotes/origin/bugs-dot-jar_MNG-1895_806eaeb0,Blocker,maven-artifact/src/main/java/org/apache/maven/artifact/resolver/DefaultArtifactCollector.java,102,321,"private void recurse(ResolutionNode node, Map resolvedArtifacts, Map managedVersions, ArtifactRepository localRepository, List remoteRepositories, ArtifactMetadataSource source, ArtifactFilter filter, List listeners) throws CyclicDependencyException, ArtifactResolutionException, OverConstrainedVersionException {
    fireEvent(ResolutionListener.TEST_ARTIFACT, listeners, node);
    // TODO: use as a conflict resolver
    Object key = node.getKey();
    if (managedVersions.containsKey(key)) {
        Artifact artifact = (Artifact) managedVersions.get(key);
        fireEvent(ResolutionListener.MANAGE_ARTIFACT, listeners, node, artifact);
        if (artifact.getVersion() != null) {
            node.getArtifact().setVersion(artifact.getVersion());
        }
        if (artifact.getScope() != null) {
            node.getArtifact().setScope(artifact.getScope());
        }
    }
    List previousNodes = (List) resolvedArtifacts.get(key);
    if (previousNodes != null) {
        for (Iterator i = previousNodes.iterator(); i.hasNext(); ) {
            ResolutionNode previous = (ResolutionNode) i.next();
            if (previous.isActive()) {
                // Version mediation
                VersionRange previousRange = previous.getArtifact().getVersionRange();
                VersionRange currentRange = node.getArtifact().getVersionRange();
                // TODO: why do we force the version on it? what if they don't match?
                if (previousRange == null) {
                    // version was already resolved
                    node.getArtifact().setVersion(previous.getArtifact().getVersion());
                } else if (currentRange == null) {
                    // version was already resolved
                    previous.getArtifact().setVersion(node.getArtifact().getVersion());
                } else {
                    // TODO: shouldn't need to double up on this work, only done for simplicity of handling recommended
                    // version but the restriction is identical
                    VersionRange newRange = previousRange.restrict(currentRange);
                    // TODO: ick. this forces the OCE that should have come from the previous call. It is still correct
                    if (newRange.isSelectedVersionKnown(previous.getArtifact())) {
                        fireEvent(ResolutionListener.RESTRICT_RANGE, listeners, node, previous.getArtifact(), newRange);
                    }
                    previous.getArtifact().setVersionRange(newRange);
                    node.getArtifact().setVersionRange(currentRange.restrict(previousRange));
                    // Select an appropriate available version from the (now restricted) range
                    // Note this version was selected before to get the appropriate POM
                    // But it was reset by the call to setVersionRange on restricting the version
                    ResolutionNode[] resetNodes = { previous, node };
                    for (int j = 0; j < 2; j++) {
                        Artifact resetArtifact = resetNodes[j].getArtifact();
                        if (resetArtifact.getVersion() == null && resetArtifact.getVersionRange() != null && resetArtifact.getAvailableVersions() != null) {
                            resetArtifact.selectVersion(resetArtifact.getVersionRange().matchVersion(resetArtifact.getAvailableVersions()).toString());
                            fireEvent(ResolutionListener.SELECT_VERSION_FROM_RANGE, listeners, resetNodes[j]);
                        }
                    }
                }
                // Conflict Resolution
                // TODO: use as conflict resolver(s), chain
                // TODO: should this be part of mediation?
                // previous one is more dominant
                ResolutionNode nearest, farthest;
                if (previous.getDepth() <= node.getDepth()) {
                    nearest = previous;
                    farthest = node;
                } else {
                    nearest = node;
                    farthest = previous;
                }
                /* if we need to update scope of nearest to use farthest scope */
                if (checkScopeUpdate(farthest, nearest, listeners)) {
                    fireEvent(ResolutionListener.UPDATE_SCOPE, listeners, nearest, farthest.getArtifact());
                    /* we need nearest version but farthest scope */
                    nearest.disable();
                    farthest.getArtifact().setVersion(nearest.getArtifact().getVersion());
                } else {
                    farthest.disable();
                }
                fireEvent(ResolutionListener.OMIT_FOR_NEARER, listeners, farthest, nearest.getArtifact());
            }
        }
    } else {
        previousNodes = new ArrayList();
        resolvedArtifacts.put(key, previousNodes);
    }
    previousNodes.add(node);
    if (node.isActive()) {
        fireEvent(ResolutionListener.INCLUDE_ARTIFACT, listeners, node);
    }
    // don't pull in the transitive deps of a system-scoped dependency.
    if (node.isActive() && !Artifact.SCOPE_SYSTEM.equals(node.getArtifact().getScope())) {
        fireEvent(ResolutionListener.PROCESS_CHILDREN, listeners, node);
        for (Iterator i = node.getChildrenIterator(); i.hasNext(); ) {
            ResolutionNode child = (ResolutionNode) i.next();
            // We leave in optional ones, but don't pick up its dependencies
            if (!child.isResolved() && (!child.getArtifact().isOptional() || child.isChildOfRootNode())) {
                Artifact artifact = child.getArtifact();
                try {
                    if (artifact.getVersion() == null) {
                        // set the recommended version
                        // TODO: maybe its better to just pass the range through to retrieval and use a transformation?
                        ArtifactVersion version;
                        if (!artifact.isSelectedVersionKnown()) {
                            List versions = artifact.getAvailableVersions();
                            if (versions == null) {
                                versions = source.retrieveAvailableVersions(artifact, localRepository, remoteRepositories);
                                artifact.setAvailableVersions(versions);
                            }
                            VersionRange versionRange = artifact.getVersionRange();
                            version = versionRange.matchVersion(versions);
                            if (version == null) {
                                if (versions.isEmpty()) {
                                    throw new OverConstrainedVersionException(""No versions are present in the repository for the artifact with a range "" + versionRange, artifact, remoteRepositories);
                                } else {
                                    throw new OverConstrainedVersionException(""Couldn't find a version in "" + versions + "" to match range "" + versionRange, artifact, remoteRepositories);
                                }
                            }
                        } else {
                            version = artifact.getSelectedVersion();
                        }
                        artifact.selectVersion(version.toString());
                        fireEvent(ResolutionListener.SELECT_VERSION_FROM_RANGE, listeners, child);
                    }
                    artifact.setDependencyTrail(node.getDependencyTrail());
                    ResolutionGroup rGroup = source.retrieve(artifact, localRepository, remoteRepositories);
                    // and catch here rather than have it return null
                    if (rGroup == null) {
                        // relocated dependency artifact is declared excluded, no need to add and recurse further
                        continue;
                    }
                    child.addDependencies(rGroup.getArtifacts(), rGroup.getResolutionRepositories(), filter);
                } catch (CyclicDependencyException e) {
                    // would like to throw this, but we have crappy stuff in the repo
                    fireEvent(ResolutionListener.OMIT_FOR_CYCLE, listeners, new ResolutionNode(e.getArtifact(), remoteRepositories, child));
                } catch (ArtifactMetadataRetrievalException e) {
                    artifact.setDependencyTrail(node.getDependencyTrail());
                    throw new ArtifactResolutionException(""Unable to get dependency information: "" + e.getMessage(), artifact, remoteRepositories, e);
                }
                recurse(child, resolvedArtifacts, managedVersions, localRepository, remoteRepositories, source, filter, listeners);
            }
        }
        fireEvent(ResolutionListener.FINISH_PROCESSING_CHILDREN, listeners, node);
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-1895_806eaeb0,Blocker,maven-artifact/src/main/java/org/apache/maven/artifact/resolver/DefaultArtifactCollector.java,330,358,"/**
 * Check if the scope of the nearest needs to be updated with the scope of the farthest.
 * <a href=""http://docs.codehaus.org/x/IGU#DependencyMediationandConflictResolution-Scoperesolution"">More info</a>.
 * @param farthest farthest resolution node
 * @param nearest nearest resolution node
 * @param listeners
 */
private boolean checkScopeUpdate(ResolutionNode farthest, ResolutionNode nearest, List listeners) {
    boolean updateScope = false;
    Artifact farthestArtifact = farthest.getArtifact();
    Artifact nearestArtifact = nearest.getArtifact();
    if (Artifact.SCOPE_RUNTIME.equals(farthestArtifact.getScope()) && (Artifact.SCOPE_TEST.equals(nearestArtifact.getScope()) || Artifact.SCOPE_PROVIDED.equals(nearestArtifact.getScope()))) {
        updateScope = true;
    }
    if (Artifact.SCOPE_COMPILE.equals(farthestArtifact.getScope()) && !Artifact.SCOPE_COMPILE.equals(nearestArtifact.getScope())) {
        updateScope = true;
    }
    // current POM rules all
    if (nearest.getDepth() < 2 && updateScope) {
        updateScope = false;
        fireEvent(ResolutionListener.UPDATE_SCOPE_CURRENT_POM, listeners, nearest, farthestArtifact);
    }
    return updateScope;
}"
maven,remotes/origin/bugs-dot-jar_MNG-1895_806eaeb0,Blocker,maven-artifact/src/main/java/org/apache/maven/artifact/resolver/ResolutionNode.java,220,223,"public String toString() {
    return artifact.toString() + "" ("" + depth + "")"";
}"
maven,remotes/origin/bugs-dot-jar_MNG-1999_ad38e46b,Major,maven-project/src/main/java/org/apache/maven/project/inheritance/DefaultModelInheritanceAssembler.java,264,285,"private void assembleReportingInheritance(Model child, Model parent) {
    // Reports :: aggregate
    Reporting childReporting = child.getReporting();
    Reporting parentReporting = parent.getReporting();
    if (parentReporting != null) {
        if (childReporting == null) {
            childReporting = new Reporting();
            child.setReporting(childReporting);
        }
        if (StringUtils.isEmpty(childReporting.getOutputDirectory())) {
            childReporting.setOutputDirectory(parentReporting.getOutputDirectory());
        }
        ModelUtils.mergeReportPluginLists(childReporting, parentReporting, true);
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-2174_778f044e,Major,maven-project/src/main/java/org/apache/maven/project/builder/PomClassicDomainModel.java,294,313,"public List<ModelProperty> getModelProperties() throws IOException {
    if (modelProperties == null) {
        Set<String> s = new HashSet<String>();
        // TODO: Should add all collections from ProjectUri
        s.addAll(PomTransformer.URIS);
        s.add(ProjectUri.Build.PluginManagement.Plugins.Plugin.Executions.xUri);
        s.add(ProjectUri.DependencyManagement.Dependencies.Dependency.Exclusions.xUri);
        s.add(ProjectUri.Dependencies.Dependency.Exclusions.xUri);
        s.add(ProjectUri.Build.Plugins.Plugin.Executions.xUri);
        s.add(ProjectUri.Build.Plugins.Plugin.Executions.Execution.Goals.xURI);
        s.add(ProjectUri.Reporting.Plugins.Plugin.ReportSets.xUri);
        s.add(ProjectUri.Reporting.Plugins.Plugin.ReportSets.ReportSet.configuration);
        s.add(ProjectUri.Build.Plugins.Plugin.Executions.Execution.configuration);
        modelProperties = ModelMarshaller.marshallXmlToModelProperties(getInputStream(), ProjectUri.baseUri, s);
    }
    return new ArrayList<ModelProperty>(modelProperties);
}"
maven,remotes/origin/bugs-dot-jar_MNG-2174_778f044e,Major,maven-project/src/main/java/org/apache/maven/project/builder/impl/DefaultProjectBuilder.java,171,270,"private PomClassicDomainModel buildModel(File pom, List<Model> mixins, Collection<InterpolatorProperty> interpolatorProperties, Collection<String> activeProfileIds, PomArtifactResolver resolver) throws IOException {
    if (pom == null) {
        throw new IllegalArgumentException(""pom: null"");
    }
    if (resolver == null) {
        throw new IllegalArgumentException(""resolver: null"");
    }
    if (mixins == null) {
        mixins = new ArrayList<Model>();
        mixins.add(getSuperModel());
    } else {
        mixins = new ArrayList<Model>(mixins);
        Collections.reverse(mixins);
    }
    if (activeProfileIds == null) {
        activeProfileIds = new ArrayList<String>();
    }
    List<InterpolatorProperty> properties;
    if (interpolatorProperties == null) {
        properties = new ArrayList<InterpolatorProperty>();
    } else {
        properties = new ArrayList<InterpolatorProperty>(interpolatorProperties);
    }
    PomClassicDomainModel domainModel = new PomClassicDomainModel(pom);
    domainModel.setProjectDirectory(pom.getParentFile());
    ProfileContext profileContext = new ProfileContext(new DefaultModelDataSource(domainModel.getModelProperties(), PomTransformer.MODEL_CONTAINER_FACTORIES), activeProfileIds, properties);
    Collection<ModelContainer> profileContainers = profileContext.getActiveProfiles();
    // get mixin
    List<DomainModel> domainModels = new ArrayList<DomainModel>();
    domainModels.add(domainModel);
    File parentFile = null;
    int lineageCount = 0;
    if (domainModel.getModel().getParent() != null) {
        List<DomainModel> mavenParents;
        if (isParentLocal(domainModel.getModel().getParent(), pom.getParentFile())) {
            mavenParents = getDomainModelParentsFromLocalPath(domainModel, resolver, pom.getParentFile(), properties, activeProfileIds);
        } else {
            mavenParents = getDomainModelParentsFromRepository(domainModel, resolver, properties, activeProfileIds);
        }
        if (mavenParents.size() > 0) {
            PomClassicDomainModel dm = (PomClassicDomainModel) mavenParents.get(0);
            parentFile = dm.getFile();
            domainModel.setParentFile(parentFile);
            lineageCount = mavenParents.size();
        }
        domainModels.addAll(mavenParents);
    }
    for (Model model : mixins) {
        domainModels.add(new PomClassicDomainModel(model));
    }
    PomClassicTransformer transformer = new PomClassicTransformer(new PomClassicDomainModelFactory());
    ModelTransformerContext ctx = new ModelTransformerContext(PomTransformer.MODEL_CONTAINER_INFOS);
    PomClassicDomainModel transformedDomainModel = ((PomClassicDomainModel) ctx.transform(domainModels, transformer, transformer, Collections.EMPTY_LIST, properties, listeners));
    // Lineage count is inclusive to add the POM read in itself.
    transformedDomainModel.setLineageCount(lineageCount + 1);
    transformedDomainModel.setParentFile(parentFile);
    return transformedDomainModel;
}"
maven,remotes/origin/bugs-dot-jar_MNG-2221_cc859f5c,Critical,maven-project/src/main/java/org/apache/maven/project/ModelUtils.java,60,126,"public static void mergePluginLists(PluginContainer childContainer, PluginContainer parentContainer, boolean handleAsInheritance) {
    if (childContainer == null || parentContainer == null) {
        // nothing to do.
        return;
    }
    List mergedPlugins = new ArrayList();
    List parentPlugins = parentContainer.getPlugins();
    if (parentPlugins != null && !parentPlugins.isEmpty()) {
        Map assembledPlugins = new TreeMap();
        Map childPlugins = childContainer.getPluginsAsMap();
        for (Iterator it = parentPlugins.iterator(); it.hasNext(); ) {
            Plugin parentPlugin = (Plugin) it.next();
            String parentInherited = parentPlugin.getInherited();
            if (!handleAsInheritance || parentInherited == null || Boolean.valueOf(parentInherited).booleanValue()) {
                Plugin assembledPlugin = parentPlugin;
                Plugin childPlugin = (Plugin) childPlugins.get(parentPlugin.getKey());
                if (childPlugin != null) {
                    assembledPlugin = childPlugin;
                    mergePluginDefinitions(childPlugin, parentPlugin, handleAsInheritance);
                }
                if (handleAsInheritance && parentInherited == null) {
                    assembledPlugin.unsetInheritanceApplied();
                }
                mergedPlugins.add(assembledPlugin);
            }
        }
        // since assembledPlugins is never updated and remains empty.
        for (Iterator it = childPlugins.values().iterator(); it.hasNext(); ) {
            Plugin childPlugin = (Plugin) it.next();
            if (!assembledPlugins.containsKey(childPlugin.getKey())) {
                mergedPlugins.add(childPlugin);
            }
        }
        childContainer.setPlugins(mergedPlugins);
        childContainer.flushPluginMap();
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-2408_b92af0e4,Blocker,maven-artifact-manager/src/main/java/org/apache/maven/artifact/repository/metadata/AbstractRepositoryMetadata.java,77,138,"protected void updateRepositoryMetadata(ArtifactRepository localRepository, ArtifactRepository remoteRepository) throws IOException, XmlPullParserException {
    MetadataXpp3Reader mappingReader = new MetadataXpp3Reader();
    Metadata metadata = null;
    File metadataFile = new File(localRepository.getBasedir(), localRepository.pathOfLocalRepositoryMetadata(this, remoteRepository));
    if (metadataFile.exists()) {
        Reader reader = null;
        try {
            reader = new FileReader(metadataFile);
            metadata = mappingReader.read(reader, false);
        } finally {
            IOUtil.close(reader);
        }
    }
    boolean changed;
    // If file could not be found or was not valid, start from scratch
    if (metadata == null) {
        metadata = this.metadata;
        changed = true;
    } else {
        changed = metadata.merge(this.metadata);
    }
    if (changed) {
        Writer writer = null;
        try {
            metadataFile.getParentFile().mkdirs();
            writer = new FileWriter(metadataFile);
            MetadataXpp3Writer mappingWriter = new MetadataXpp3Writer();
            mappingWriter.write(writer, metadata);
        } finally {
            IOUtil.close(writer);
        }
    } else {
        metadataFile.setLastModified(System.currentTimeMillis());
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-2712_06090da4,Major,maven-artifact-manager/src/main/java/org/apache/maven/artifact/repository/metadata/AbstractRepositoryMetadata.java,77,146,"protected void updateRepositoryMetadata(ArtifactRepository localRepository, ArtifactRepository remoteRepository) throws IOException, XmlPullParserException {
    MetadataXpp3Reader mappingReader = new MetadataXpp3Reader();
    Metadata metadata = null;
    File metadataFile = new File(localRepository.getBasedir(), localRepository.pathOfLocalRepositoryMetadata(this, remoteRepository));
    if (metadataFile.exists()) {
        Reader reader = null;
        try {
            reader = new FileReader(metadataFile);
            metadata = mappingReader.read(reader, false);
        } finally {
            IOUtil.close(reader);
        }
    }
    boolean changed;
    // If file could not be found or was not valid, start from scratch
    if (metadata == null) {
        metadata = this.metadata;
        changed = true;
    } else {
        changed = metadata.merge(this.metadata);
    }
    // beware meta-versions!
    String version = metadata.getVersion();
    if (version != null && (Artifact.LATEST_VERSION.equals(version) || Artifact.RELEASE_VERSION.equals(version))) {
        // meta-versions are not valid <version/> values...don't write them.
        changed = false;
    }
    if (changed) {
        Writer writer = null;
        try {
            metadataFile.getParentFile().mkdirs();
            writer = new FileWriter(metadataFile);
            MetadataXpp3Writer mappingWriter = new MetadataXpp3Writer();
            mappingWriter.write(writer, metadata);
        } finally {
            IOUtil.close(writer);
        }
    } else {
        metadataFile.setLastModified(System.currentTimeMillis());
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-2712_06090da4,Major,maven-artifact-manager/src/main/java/org/apache/maven/artifact/repository/metadata/DefaultRepositoryMetadataManager.java,55,141,"public void resolve(RepositoryMetadata metadata, List remoteRepositories, ArtifactRepository localRepository) throws RepositoryMetadataResolutionException {
    boolean alreadyResolved = alreadyResolved(metadata);
    if (!alreadyResolved) {
        for (Iterator i = remoteRepositories.iterator(); i.hasNext(); ) {
            ArtifactRepository repository = (ArtifactRepository) i.next();
            ArtifactRepositoryPolicy policy = metadata.isSnapshot() ? repository.getSnapshots() : repository.getReleases();
            if (!policy.isEnabled()) {
                getLogger().debug(""Skipping disabled repository "" + repository.getId());
            } else if (repository.isBlacklisted()) {
                getLogger().debug(""Skipping blacklisted repository "" + repository.getId());
            } else {
                File file = new File(localRepository.getBasedir(), localRepository.pathOfLocalRepositoryMetadata(metadata, repository));
                boolean checkForUpdates = policy.checkOutOfDate(new Date(file.lastModified())) || !file.exists();
                boolean metadataIsEmpty = true;
                if (checkForUpdates) {
                    getLogger().info(metadata.getKey() + "": checking for updates from "" + repository.getId());
                    try {
                        resolveAlways(metadata, repository, file, policy.getChecksumPolicy(), true);
                        metadataIsEmpty = false;
                    } catch (TransferFailedException e) {
                        // TODO: [jc; 08-Nov-2005] revisit this for 2.1
                        // suppressing logging to avoid logging this error twice.
                        metadataIsEmpty = true;
                    }
                }
                // touch file so that this is not checked again until interval has passed
                if (file.exists()) {
                    file.setLastModified(System.currentTimeMillis());
                } else if (!metadataIsEmpty) {
                    // this ensures that files are not continuously checked when they don't exist remotely
                    try {
                        metadata.storeInLocalRepository(localRepository, repository);
                    } catch (RepositoryMetadataStoreException e) {
                        throw new RepositoryMetadataResolutionException(""Unable to store local copy of metadata: "" + e.getMessage(), e);
                    }
                }
            }
        }
        cachedMetadata.add(metadata.getKey());
    }
    try {
        mergeMetadata(metadata, remoteRepositories, localRepository);
    } catch (RepositoryMetadataStoreException e) {
        throw new RepositoryMetadataResolutionException(""Unable to store local copy of metadata: "" + e.getMessage(), e);
    } catch (RepositoryMetadataReadException e) {
        throw new RepositoryMetadataResolutionException(""Unable to read local copy of metadata: "" + e.getMessage(), e);
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-2931_d7422212,Major,maven-artifact/src/main/java/org/apache/maven/artifact/resolver/DefaultArtifactCollector.java,61,108,"public ArtifactResolutionResult collect(Set artifacts, Artifact originatingArtifact, Map managedVersions, ArtifactRepository localRepository, List remoteRepositories, ArtifactMetadataSource source, ArtifactFilter filter, List listeners) throws ArtifactResolutionException {
    Map resolvedArtifacts = new LinkedHashMap();
    ResolutionNode root = new ResolutionNode(originatingArtifact, remoteRepositories);
    root.addDependencies(artifacts, remoteRepositories, filter);
    ManagedVersionMap versionMap = (managedVersions != null && managedVersions instanceof ManagedVersionMap) ? (ManagedVersionMap) managedVersions : new ManagedVersionMap(managedVersions);
    recurse(root, resolvedArtifacts, versionMap, localRepository, remoteRepositories, source, filter, listeners);
    Set set = new LinkedHashSet();
    for (Iterator i = resolvedArtifacts.values().iterator(); i.hasNext(); ) {
        List nodes = (List) i.next();
        for (Iterator j = nodes.iterator(); j.hasNext(); ) {
            ResolutionNode node = (ResolutionNode) j.next();
            if (!node.equals(root) && node.isActive()) {
                Artifact artifact = node.getArtifact();
                if (node.filterTrail(filter)) {
                    // we don't add it or its children, just allow the update of the version and scope
                    if (node.isChildOfRootNode() || !artifact.isOptional()) {
                        artifact.setDependencyTrail(node.getDependencyTrail());
                        set.add(node);
                    }
                }
            }
        }
    }
    ArtifactResolutionResult result = new ArtifactResolutionResult();
    result.setArtifactResolutionNodes(set);
    return result;
}"
maven,remotes/origin/bugs-dot-jar_MNG-3092_5ffd8903,Major,maven-artifact/src/main/java/org/apache/maven/artifact/versioning/Restriction.java,72,99,"public boolean containsVersion(ArtifactVersion version) {
    if (lowerBound != null) {
        int comparison = lowerBound.compareTo(version);
        if ((comparison == 0) && !lowerBoundInclusive) {
            return false;
        }
        if (comparison > 0) {
            return false;
        }
    }
    if (upperBound != null) {
        int comparison = upperBound.compareTo(version);
        if ((comparison == 0) && !upperBoundInclusive) {
            return false;
        }
        if (comparison < 0) {
            return false;
        }
    }
    return true;
}"
maven,remotes/origin/bugs-dot-jar_MNG-3131_56cd921f,Major,maven-core/src/main/java/org/apache/maven/plugin/PluginParameterException.java,74,106,"private static void decomposeParameterIntoUserInstructions(MojoDescriptor mojo, Parameter param, StringBuilder messageBuffer) {
    String expression = param.getExpression();
    if (param.isEditable()) {
        messageBuffer.append(""Inside the definition for plugin \'"" + mojo.getPluginDescriptor().getArtifactId() + ""\', specify the following:\n\n<configuration>\n  ...\n  <"" + param.getName() + "">VALUE</"" + param.getName() + "">\n</configuration>"");
        String alias = param.getAlias();
        if (StringUtils.isNotEmpty(alias) && !alias.equals(param.getName())) {
            messageBuffer.append(""\n\n-OR-\n\n<configuration>\n  ...\n  <"" + alias + "">VALUE</"" + alias + "">\n</configuration>\n"");
        }
    }
    if (StringUtils.isEmpty(expression)) {
        messageBuffer.append(""."");
    } else {
        if (param.isEditable()) {
            messageBuffer.append(""\n\n-OR-\n\n"");
        }
    // addParameterUsageInfo( expression, messageBuffer );
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-3131_f6f4ef5e,Major,maven-core/src/main/java/org/apache/maven/plugin/PluginParameterException.java,76,149,"private static void decomposeParameterIntoUserInstructions(MojoDescriptor mojo, Parameter param, StringBuilder messageBuffer) {
    String expression = param.getExpression();
    if (param.isEditable()) {
        boolean isArray = param.getType().endsWith(""[]"");
        boolean isCollection = false;
        boolean isMap = false;
        if (!isArray) {
            try {
                // assuming Type is available in current ClassLoader
                isCollection = Collection.class.isAssignableFrom(Class.forName(param.getType()));
                isMap = Map.class.isAssignableFrom(Class.forName(param.getType()));
            } catch (ClassNotFoundException e) {
            // assume it is not assignable from Collection or Map
            }
        }
        messageBuffer.append(""Inside the definition for plugin \'"");
        messageBuffer.append(mojo.getPluginDescriptor().getArtifactId());
        messageBuffer.append(""\', specify the following:\n\n<configuration>\n  ...\n"");
        messageBuffer.append(""  <"").append(param.getName()).append('>');
        if (isArray || isCollection) {
            messageBuffer.append('\n');
            messageBuffer.append(""    <item>"");
        } else if (isMap) {
            messageBuffer.append('\n');
            messageBuffer.append(""    <KEY>"");
        }
        messageBuffer.append(""VALUE"");
        if (isArray || isCollection) {
            messageBuffer.append(""</item>\n"");
            messageBuffer.append(""  "");
        } else if (isMap) {
            messageBuffer.append(""</KEY>\n"");
            messageBuffer.append(""  "");
        }
        messageBuffer.append(""</"").append(param.getName()).append("">\n"");
        messageBuffer.append(""</configuration>"");
        String alias = param.getAlias();
        if (StringUtils.isNotEmpty(alias) && !alias.equals(param.getName())) {
            messageBuffer.append(""\n\n-OR-\n\n<configuration>\n  ...\n  <"" + alias + "">VALUE</"" + alias + "">\n</configuration>\n"");
        }
    }
    if (StringUtils.isEmpty(expression)) {
        messageBuffer.append(""."");
    } else {
        if (param.isEditable()) {
            messageBuffer.append(""\n\n-OR-\n\n"");
        }
    // addParameterUsageInfo( expression, messageBuffer );
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-3616_912a565f,Major,maven-core/src/main/java/org/apache/maven/settings/validation/DefaultSettingsValidator.java,39,51,"public void validate(Settings settings, SettingsProblemCollector problems) {
    List<Profile> profiles = settings.getProfiles();
    if (profiles != null) {
        for (Profile prof : profiles) {
            validateRepositories(problems, prof.getRepositories(), ""repositories.repository"");
            validateRepositories(problems, prof.getPluginRepositories(), ""pluginRepositories.pluginRepository"");
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-3616_912a565f,Major,maven-core/src/main/java/org/apache/maven/settings/validation/DefaultSettingsValidator.java,53,61,"private void validateRepositories(SettingsProblemCollector problems, List<Repository> repositories, String prefix) {
    for (Repository repository : repositories) {
        validateStringNotEmpty(problems, prefix + "".id"", repository.getId());
        validateStringNotEmpty(problems, prefix + "".url"", repository.getUrl());
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-3616_912a565f,Major,maven-core/src/main/java/org/apache/maven/settings/validation/DefaultSettingsValidator.java,67,70,"// ----------------------------------------------------------------------
// Field validation
// ----------------------------------------------------------------------
private boolean validateStringNotEmpty(SettingsProblemCollector problems, String fieldName, String string) {
    return validateStringNotEmpty(problems, fieldName, string, null);
}"
maven,remotes/origin/bugs-dot-jar_MNG-3991_2169c4a3,Minor,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,114,303,"public void validateEffectiveModel(Model model, ModelBuildingRequest request, ModelProblemCollector problems) {
    validateStringNotEmpty(""modelVersion"", problems, false, model.getModelVersion());
    validateId(""groupId"", problems, model.getGroupId());
    validateId(""artifactId"", problems, model.getArtifactId());
    validateStringNotEmpty(""packaging"", problems, false, model.getPackaging());
    if (!model.getModules().isEmpty() && !""pom"".equals(model.getPackaging())) {
        addViolation(problems, false, ""Packaging '"" + model.getPackaging() + ""' is invalid. Aggregator projects "" + ""require 'pom' as packaging."");
    }
    Parent parent = model.getParent();
    if (parent != null) {
        if (parent.getGroupId().equals(model.getGroupId()) && parent.getArtifactId().equals(model.getArtifactId())) {
            addViolation(problems, false, ""The parent element cannot have the same ID as the project."");
        }
    }
    validateStringNotEmpty(""version"", problems, false, model.getVersion());
    boolean warnOnBadBoolean = request.getValidationLevel() < ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0;
    boolean warnOnBadDependencyScope = request.getValidationLevel() < ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0;
    for (Dependency d : model.getDependencies()) {
        validateId(""dependencies.dependency.artifactId"", problems, d.getArtifactId());
        validateId(""dependencies.dependency.groupId"", problems, d.getGroupId());
        validateStringNotEmpty(""dependencies.dependency.type"", problems, false, d.getType(), d.getManagementKey());
        validateStringNotEmpty(""dependencies.dependency.version"", problems, false, d.getVersion(), d.getManagementKey());
        if (""system"".equals(d.getScope())) {
            String systemPath = d.getSystemPath();
            if (StringUtils.isEmpty(systemPath)) {
                addViolation(problems, false, ""For dependency "" + d + "": system-scoped dependency must specify systemPath."");
            } else {
                if (!new File(systemPath).isAbsolute()) {
                    addViolation(problems, false, ""For dependency "" + d + "": system-scoped dependency must "" + ""specify an absolute path systemPath."");
                }
            }
        } else if (StringUtils.isNotEmpty(d.getSystemPath())) {
            addViolation(problems, false, ""For dependency "" + d + "": only dependency with system scope can specify systemPath."");
        }
        if (request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0) {
            validateBoolean(""dependencies.dependency.optional"", problems, warnOnBadBoolean, d.getOptional(), d.getManagementKey());
            validateEnum(""dependencies.dependency.scope"", problems, warnOnBadDependencyScope, d.getScope(), d.getManagementKey(), ""provided"", ""compile"", ""runtime"", ""test"", ""system"");
        }
    }
    DependencyManagement mgmt = model.getDependencyManagement();
    if (mgmt != null) {
        for (Dependency d : mgmt.getDependencies()) {
            validateSubElementStringNotEmpty(d, ""dependencyManagement.dependencies.dependency.artifactId"", problems, d.getArtifactId());
            validateSubElementStringNotEmpty(d, ""dependencyManagement.dependencies.dependency.groupId"", problems, d.getGroupId());
            if (""system"".equals(d.getScope())) {
                String systemPath = d.getSystemPath();
                if (StringUtils.isEmpty(systemPath)) {
                    addViolation(problems, false, ""For managed dependency "" + d + "": system-scoped dependency must specify systemPath."");
                } else {
                    if (!new File(systemPath).isAbsolute()) {
                        addViolation(problems, false, ""For managed dependency "" + d + "": system-scoped dependency must "" + ""specify an absolute path systemPath."");
                    }
                }
            } else if (StringUtils.isNotEmpty(d.getSystemPath())) {
                addViolation(problems, false, ""For managed dependency "" + d + "": only dependency with system scope can specify systemPath."");
            }
            if (request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0) {
                validateBoolean(""dependencyManagement.dependencies.dependency.optional"", problems, warnOnBadBoolean, d.getOptional(), d.getManagementKey());
            }
        }
    }
    if (request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0) {
        boolean warnOnMissingPluginVersion = request.getValidationLevel() < ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1;
        Build build = model.getBuild();
        if (build != null) {
            for (Plugin p : build.getPlugins()) {
                validateStringNotEmpty(""build.plugins.plugin.artifactId"", problems, false, p.getArtifactId());
                validateStringNotEmpty(""build.plugins.plugin.groupId"", problems, false, p.getGroupId());
                validateStringNotEmpty(""build.plugins.plugin.version"", problems, warnOnMissingPluginVersion, p.getVersion(), p.getKey());
                validateBoolean(""build.plugins.plugin.inherited"", problems, warnOnBadBoolean, p.getInherited(), p.getKey());
                validateBoolean(""build.plugins.plugin.extensions"", problems, warnOnBadBoolean, p.getExtensions(), p.getKey());
                for (Dependency d : p.getDependencies()) {
                    validateEnum(""build.plugins.plugin["" + p.getKey() + ""].dependencies.dependency.scope"", problems, warnOnBadDependencyScope, d.getScope(), d.getManagementKey(), ""compile"", ""runtime"", ""system"");
                }
            }
            validateResources(problems, build.getResources(), ""build.resources.resource"", request);
            validateResources(problems, build.getTestResources(), ""build.testResources.testResource"", request);
        }
        Reporting reporting = model.getReporting();
        if (reporting != null) {
            for (ReportPlugin p : reporting.getPlugins()) {
                validateStringNotEmpty(""reporting.plugins.plugin.artifactId"", problems, false, p.getArtifactId());
                validateStringNotEmpty(""reporting.plugins.plugin.groupId"", problems, false, p.getGroupId());
                validateStringNotEmpty(""reporting.plugins.plugin.version"", problems, warnOnMissingPluginVersion, p.getVersion(), p.getKey());
            }
        }
        forcePluginExecutionIdCollision(model, problems);
        for (Repository repository : model.getRepositories()) {
            validateRepositoryLayout(problems, repository, ""repositories.repository"", request);
        }
        for (Repository repository : model.getPluginRepositories()) {
            validateRepositoryLayout(problems, repository, ""pluginRepositories.pluginRepository"", request);
        }
        DistributionManagement distMgmt = model.getDistributionManagement();
        if (distMgmt != null) {
            validateRepositoryLayout(problems, distMgmt.getRepository(), ""distributionManagement.repository"", request);
            validateRepositoryLayout(problems, distMgmt.getSnapshotRepository(), ""distributionManagement.snapshotRepository"", request);
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-4383_0f3d4d24,Major,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,114,307,"public void validateEffectiveModel(Model model, ModelBuildingRequest request, ModelProblemCollector problems) {
    validateStringNotEmpty(""modelVersion"", problems, false, model.getModelVersion());
    validateId(""groupId"", problems, model.getGroupId());
    validateId(""artifactId"", problems, model.getArtifactId());
    validateStringNotEmpty(""packaging"", problems, false, model.getPackaging());
    if (!model.getModules().isEmpty() && !""pom"".equals(model.getPackaging())) {
        addViolation(problems, false, ""Packaging '"" + model.getPackaging() + ""' is invalid. Aggregator projects "" + ""require 'pom' as packaging."");
    }
    Parent parent = model.getParent();
    if (parent != null) {
        if (parent.getGroupId().equals(model.getGroupId()) && parent.getArtifactId().equals(model.getArtifactId())) {
            addViolation(problems, false, ""The parent element cannot have the same ID as the project."");
        }
    }
    validateStringNotEmpty(""version"", problems, false, model.getVersion());
    boolean warnOnBadBoolean = request.getValidationLevel() < ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0;
    boolean warnOnBadDependencyScope = request.getValidationLevel() < ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0;
    for (Dependency d : model.getDependencies()) {
        validateId(""dependencies.dependency.artifactId"", problems, d.getArtifactId());
        validateId(""dependencies.dependency.groupId"", problems, d.getGroupId());
        validateStringNotEmpty(""dependencies.dependency.type"", problems, false, d.getType(), d.getManagementKey());
        validateStringNotEmpty(""dependencies.dependency.version"", problems, false, d.getVersion(), d.getManagementKey());
        if (""system"".equals(d.getScope())) {
            String systemPath = d.getSystemPath();
            if (StringUtils.isEmpty(systemPath)) {
                addViolation(problems, false, ""For dependency "" + d + "": system-scoped dependency must specify systemPath."");
            } else {
                if (!new File(systemPath).isAbsolute()) {
                    addViolation(problems, false, ""For dependency "" + d + "": system-scoped dependency must "" + ""specify an absolute path systemPath."");
                }
            }
        } else if (StringUtils.isNotEmpty(d.getSystemPath())) {
            addViolation(problems, false, ""For dependency "" + d + "": only dependency with system scope can specify systemPath."");
        }
        if (request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0) {
            validateBoolean(""dependencies.dependency.optional"", problems, warnOnBadBoolean, d.getOptional(), d.getManagementKey());
            /*
                 * TODO: Extensions like Flex Mojos use custom scopes like ""merged"", ""internal"", ""external"", etc. In
                 * order to don't break backward-compat with those, only warn but don't error our.
                 */
            validateEnum(""dependencies.dependency.scope"", problems, true, d.getScope(), d.getManagementKey(), ""provided"", ""compile"", ""runtime"", ""test"", ""system"");
        }
    }
    DependencyManagement mgmt = model.getDependencyManagement();
    if (mgmt != null) {
        for (Dependency d : mgmt.getDependencies()) {
            validateSubElementStringNotEmpty(d, ""dependencyManagement.dependencies.dependency.artifactId"", problems, d.getArtifactId());
            validateSubElementStringNotEmpty(d, ""dependencyManagement.dependencies.dependency.groupId"", problems, d.getGroupId());
            if (""system"".equals(d.getScope())) {
                String systemPath = d.getSystemPath();
                if (StringUtils.isEmpty(systemPath)) {
                    addViolation(problems, false, ""For managed dependency "" + d + "": system-scoped dependency must specify systemPath."");
                } else {
                    if (!new File(systemPath).isAbsolute()) {
                        addViolation(problems, false, ""For managed dependency "" + d + "": system-scoped dependency must "" + ""specify an absolute path systemPath."");
                    }
                }
            } else if (StringUtils.isNotEmpty(d.getSystemPath())) {
                addViolation(problems, false, ""For managed dependency "" + d + "": only dependency with system scope can specify systemPath."");
            }
            if (request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0) {
                validateBoolean(""dependencyManagement.dependencies.dependency.optional"", problems, warnOnBadBoolean, d.getOptional(), d.getManagementKey());
            }
        }
    }
    if (request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0) {
        boolean warnOnMissingPluginVersion = request.getValidationLevel() < ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1;
        Build build = model.getBuild();
        if (build != null) {
            for (Plugin p : build.getPlugins()) {
                validateStringNotEmpty(""build.plugins.plugin.artifactId"", problems, false, p.getArtifactId());
                validateStringNotEmpty(""build.plugins.plugin.groupId"", problems, false, p.getGroupId());
                validateStringNotEmpty(""build.plugins.plugin.version"", problems, warnOnMissingPluginVersion, p.getVersion(), p.getKey());
                validateBoolean(""build.plugins.plugin.inherited"", problems, warnOnBadBoolean, p.getInherited(), p.getKey());
                validateBoolean(""build.plugins.plugin.extensions"", problems, warnOnBadBoolean, p.getExtensions(), p.getKey());
                for (Dependency d : p.getDependencies()) {
                    validateEnum(""build.plugins.plugin["" + p.getKey() + ""].dependencies.dependency.scope"", problems, warnOnBadDependencyScope, d.getScope(), d.getManagementKey(), ""compile"", ""runtime"", ""system"");
                }
            }
            validateResources(problems, build.getResources(), ""build.resources.resource"", request);
            validateResources(problems, build.getTestResources(), ""build.testResources.testResource"", request);
        }
        Reporting reporting = model.getReporting();
        if (reporting != null) {
            for (ReportPlugin p : reporting.getPlugins()) {
                validateStringNotEmpty(""reporting.plugins.plugin.artifactId"", problems, false, p.getArtifactId());
                validateStringNotEmpty(""reporting.plugins.plugin.groupId"", problems, false, p.getGroupId());
                validateStringNotEmpty(""reporting.plugins.plugin.version"", problems, warnOnMissingPluginVersion, p.getVersion(), p.getKey());
            }
        }
        forcePluginExecutionIdCollision(model, problems);
        for (Repository repository : model.getRepositories()) {
            validateRepositoryLayout(problems, repository, ""repositories.repository"", request);
        }
        for (Repository repository : model.getPluginRepositories()) {
            validateRepositoryLayout(problems, repository, ""pluginRepositories.pluginRepository"", request);
        }
        DistributionManagement distMgmt = model.getDistributionManagement();
        if (distMgmt != null) {
            validateRepositoryLayout(problems, distMgmt.getRepository(), ""distributionManagement.repository"", request);
            validateRepositoryLayout(problems, distMgmt.getSnapshotRepository(), ""distributionManagement.snapshotRepository"", request);
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-4383_0f3d4d24,Major,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,566,589,"private boolean validateBoolean(String fieldName, ModelProblemCollector problems, boolean warning, String string, String sourceHint) {
    if (string == null || string.length() <= 0) {
        return true;
    }
    if (""true"".equalsIgnoreCase(string) || ""false"".equalsIgnoreCase(string)) {
        return true;
    }
    if (sourceHint != null) {
        addViolation(problems, warning, ""'"" + fieldName + ""' must be 'true' or 'false' for "" + sourceHint);
    } else {
        addViolation(problems, warning, ""'"" + fieldName + ""' must be 'true' or 'false'."");
    }
    return false;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4383_0f3d4d24,Major,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,591,616,"private boolean validateEnum(String fieldName, ModelProblemCollector problems, boolean warning, String string, String sourceHint, String... validValues) {
    if (string == null || string.length() <= 0) {
        return true;
    }
    List<String> values = Arrays.asList(validValues);
    if (values.contains(string)) {
        return true;
    }
    if (sourceHint != null) {
        addViolation(problems, warning, ""'"" + fieldName + ""' must be one of "" + values + "" for "" + sourceHint);
    } else {
        addViolation(problems, warning, ""'"" + fieldName + ""' must be one of "" + values);
    }
    return false;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4474_269c956e,Major,maven-compat/src/main/java/org/apache/maven/repository/legacy/DefaultWagonManager.java,679,697,"@Deprecated
public Wagon getWagon(String protocol) throws UnsupportedProtocolException {
    if (protocol == null) {
        throw new UnsupportedProtocolException(""Unspecified protocol"");
    }
    String hint = protocol.toLowerCase(java.util.Locale.ENGLISH);
    Wagon wagon = (Wagon) wagons.get(hint);
    if (wagon == null) {
        throw new UnsupportedProtocolException(""Cannot find wagon which supports the requested protocol: "" + protocol);
    }
    return wagon;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4512_8cb04253,Major,maven-model-builder/src/main/java/org/apache/maven/model/profile/activation/JdkVersionProfileActivator.java,99,140,"private static int getRelationOrder(String value, RangeValue rangeValue, boolean isLeft) {
    if (rangeValue.value.length() <= 0) {
        return isLeft ? 1 : -1;
    }
    List<String> valueTokens = new ArrayList<String>(Arrays.asList(value.split(""\\."")));
    List<String> rangeValueTokens = new ArrayList<String>(Arrays.asList(rangeValue.value.split(""\\."")));
    int max = Math.max(valueTokens.size(), rangeValueTokens.size());
    addZeroTokens(valueTokens, max);
    addZeroTokens(rangeValueTokens, max);
    if (value.equals(rangeValue.getValue())) {
        if (!rangeValue.isClosed()) {
            return isLeft ? -1 : 1;
        }
        return 0;
    }
    for (int i = 0; i < valueTokens.size(); i++) {
        int x = Integer.parseInt(valueTokens.get(i));
        int y = Integer.parseInt(rangeValueTokens.get(i));
        if (x < y) {
            return -1;
        } else if (x > y) {
            return 1;
        }
    }
    if (!rangeValue.isClosed()) {
        return isLeft ? -1 : 1;
    }
    return 0;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4518_f5ebc72d,Major,maven-model-builder/src/main/java/org/apache/maven/model/profile/activation/JdkVersionProfileActivator.java,99,142,"private static int getRelationOrder(String value, RangeValue rangeValue, boolean isLeft) {
    if (rangeValue.value.length() <= 0) {
        return isLeft ? 1 : -1;
    }
    value = value.replaceAll(""[^0-9\\.\\-\\_]"", """");
    List<String> valueTokens = new ArrayList<String>(Arrays.asList(value.split(""[\\.\\-\\_]"")));
    List<String> rangeValueTokens = new ArrayList<String>(Arrays.asList(rangeValue.value.split(""\\."")));
    int max = Math.max(valueTokens.size(), rangeValueTokens.size());
    addZeroTokens(valueTokens, max);
    addZeroTokens(rangeValueTokens, max);
    if (value.equals(rangeValue.getValue())) {
        if (!rangeValue.isClosed()) {
            return isLeft ? -1 : 1;
        }
        return 0;
    }
    for (int i = 0; i < valueTokens.size() && i < rangeValueTokens.size(); i++) {
        int x = Integer.parseInt(valueTokens.get(i));
        int y = Integer.parseInt(rangeValueTokens.get(i));
        if (x < y) {
            return -1;
        } else if (x > y) {
            return 1;
        }
    }
    if (!rangeValue.isClosed()) {
        return isLeft ? -1 : 1;
    }
    return 0;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4518_f5ebc72d,Major,maven-model-builder/src/main/java/org/apache/maven/model/profile/activation/JdkVersionProfileActivator.java,144,153,"private static void addZeroTokens(List<String> tokens, int max) {
    if (tokens.size() < max) {
        for (int i = 0; i < (max - tokens.size()); i++) {
            tokens.add(""0"");
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-4529_03a383e3,Major,maven-model-builder/src/main/java/org/apache/maven/model/interpolation/StringSearchModelInterpolator.java,314,333,"private boolean isQualifiedForInterpolation(Field field, Class<?> fieldType) {
    Boolean primitive = fieldIsPrimitiveByClass.get(fieldType);
    if (primitive == null) {
        primitive = Boolean.valueOf(fieldType.isPrimitive());
        fieldIsPrimitiveByClass.put(fieldType, primitive);
    }
    if (primitive.booleanValue()) {
        return false;
    }
    if (""parent"".equals(field.getName())) {
        return false;
    }
    return true;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4565_c6529932,Major,maven-model-builder/src/main/java/org/apache/maven/model/profile/DefaultProfileSelector.java,105,126,"private boolean isActive(Profile profile, ProfileActivationContext context, ModelProblemCollector problems) {
    for (ProfileActivator activator : activators) {
        try {
            if (activator.isActive(profile, context, problems)) {
                return true;
            }
        } catch (RuntimeException e) {
            problems.add(new ModelProblemCollectorRequest(Severity.ERROR, Version.BASE).setMessage(""Failed to determine activation for profile "" + profile.getId()).setLocation(profile.getLocation("""")).setException(e));
            return false;
        }
    }
    return false;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4648_83389c34,Major,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,181,309,"public void validateEffectiveModel(Model model, ModelBuildingRequest request, ModelProblemCollector problems) {
    validateStringNotEmpty(""modelVersion"", problems, Severity.ERROR, model.getModelVersion());
    validateId(""groupId"", problems, model.getGroupId());
    validateId(""artifactId"", problems, model.getArtifactId());
    validateStringNotEmpty(""packaging"", problems, Severity.ERROR, model.getPackaging());
    if (!model.getModules().isEmpty()) {
        if (!""pom"".equals(model.getPackaging())) {
            addViolation(problems, Severity.ERROR, ""packaging"", null, ""with value '"" + model.getPackaging() + ""' is invalid. Aggregator projects "" + ""require 'pom' as packaging."");
        }
        for (int i = 0, n = model.getModules().size(); i < n; i++) {
            String module = model.getModules().get(i);
            if (StringUtils.isBlank(module)) {
                addViolation(problems, Severity.WARNING, ""modules.module["" + i + ""]"", null, ""has been specified without a path to the project directory."");
            }
        }
    }
    validateStringNotEmpty(""version"", problems, Severity.ERROR, model.getVersion());
    Severity errOn30 = getSeverity(request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0);
    validateEffectiveDependencies(problems, model.getDependencies(), false, request);
    DependencyManagement mgmt = model.getDependencyManagement();
    if (mgmt != null) {
        validateEffectiveDependencies(problems, mgmt.getDependencies(), true, request);
    }
    if (request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0) {
        Set<String> modules = new HashSet<String>();
        for (int i = 0, n = model.getModules().size(); i < n; i++) {
            String module = model.getModules().get(i);
            if (!modules.add(module)) {
                addViolation(problems, Severity.ERROR, ""modules.module["" + i + ""]"", null, ""specifies duplicate child module "" + module);
            }
        }
        Severity errOn31 = getSeverity(request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1);
        Build build = model.getBuild();
        if (build != null) {
            for (Plugin p : build.getPlugins()) {
                validateStringNotEmpty(""build.plugins.plugin.artifactId"", problems, Severity.ERROR, p.getArtifactId());
                validateStringNotEmpty(""build.plugins.plugin.groupId"", problems, Severity.ERROR, p.getGroupId());
                validatePluginVersion(""build.plugins.plugin.version"", problems, p.getVersion(), p.getKey(), request);
                validateBoolean(""build.plugins.plugin.inherited"", problems, errOn30, p.getInherited(), p.getKey());
                validateBoolean(""build.plugins.plugin.extensions"", problems, errOn30, p.getExtensions(), p.getKey());
                for (Dependency d : p.getDependencies()) {
                    validateEnum(""build.plugins.plugin["" + p.getKey() + ""].dependencies.dependency.scope"", problems, errOn30, d.getScope(), d.getManagementKey(), ""compile"", ""runtime"", ""system"");
                }
            }
            validateResources(problems, build.getResources(), ""build.resources.resource"", request);
            validateResources(problems, build.getTestResources(), ""build.testResources.testResource"", request);
        }
        Reporting reporting = model.getReporting();
        if (reporting != null) {
            for (ReportPlugin p : reporting.getPlugins()) {
                validateStringNotEmpty(""reporting.plugins.plugin.artifactId"", problems, Severity.ERROR, p.getArtifactId());
                validateStringNotEmpty(""reporting.plugins.plugin.groupId"", problems, Severity.ERROR, p.getGroupId());
                validateStringNotEmpty(""reporting.plugins.plugin.version"", problems, errOn31, p.getVersion(), p.getKey());
            }
        }
        for (Repository repository : model.getRepositories()) {
            validateRepository(problems, repository, ""repositories.repository"", request);
        }
        for (Repository repository : model.getPluginRepositories()) {
            validateRepository(problems, repository, ""pluginRepositories.pluginRepository"", request);
        }
        DistributionManagement distMgmt = model.getDistributionManagement();
        if (distMgmt != null) {
            if (distMgmt.getStatus() != null) {
                addViolation(problems, Severity.ERROR, ""distributionManagement.status"", null, ""must not be specified."");
            }
            validateRepository(problems, distMgmt.getRepository(), ""distributionManagement.repository"", request);
            validateRepository(problems, distMgmt.getSnapshotRepository(), ""distributionManagement.snapshotRepository"", request);
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-4648_83389c34,Major,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,367,441,"private void validateEffectiveDependencies(ModelProblemCollector problems, List<Dependency> dependencies, boolean managed, ModelBuildingRequest request) {
    Severity errOn30 = getSeverity(request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0);
    String prefix = managed ? ""dependencyManagement.dependencies.dependency."" : ""dependencies.dependency."";
    for (Dependency d : dependencies) {
        validateId(prefix + ""artifactId"", problems, d.getArtifactId(), d.getManagementKey());
        validateId(prefix + ""groupId"", problems, d.getGroupId(), d.getManagementKey());
        if (!managed) {
            validateStringNotEmpty(prefix + ""type"", problems, Severity.ERROR, d.getType(), d.getManagementKey());
            validateStringNotEmpty(prefix + ""version"", problems, Severity.ERROR, d.getVersion(), d.getManagementKey());
        }
        if (""system"".equals(d.getScope())) {
            String systemPath = d.getSystemPath();
            if (StringUtils.isEmpty(systemPath)) {
                addViolation(problems, Severity.ERROR, prefix + ""systemPath"", d.getManagementKey(), ""is missing."");
            } else {
                File sysFile = new File(systemPath);
                if (!sysFile.isAbsolute()) {
                    addViolation(problems, Severity.ERROR, prefix + ""systemPath"", d.getManagementKey(), ""must specify an absolute path but is "" + systemPath);
                } else if (!sysFile.isFile()) {
                    String msg = ""refers to a non-existing file "" + sysFile.getAbsolutePath();
                    systemPath = systemPath.replace('/', File.separatorChar).replace('\\', File.separatorChar);
                    String jdkHome = request.getSystemProperties().getProperty(""java.home"", """") + File.separator + "".."";
                    if (systemPath.startsWith(jdkHome)) {
                        msg += "". Please verify that you run Maven using a JDK and not just a JRE."";
                    }
                    addViolation(problems, Severity.WARNING, prefix + ""systemPath"", d.getManagementKey(), msg);
                }
            }
        } else if (StringUtils.isNotEmpty(d.getSystemPath())) {
            addViolation(problems, Severity.ERROR, prefix + ""systemPath"", d.getManagementKey(), ""must be omitted."" + "" This field may only be specified for a dependency with system scope."");
        }
        if (request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0) {
            validateBoolean(prefix + ""optional"", problems, errOn30, d.getOptional(), d.getManagementKey());
            if (!managed) {
                validateVersion(prefix + ""version"", problems, errOn30, d.getVersion(), d.getManagementKey());
                /*
                     * TODO: Extensions like Flex Mojos use custom scopes like ""merged"", ""internal"", ""external"", etc. In
                     * order to don't break backward-compat with those, only warn but don't error out.
                     */
                validateEnum(prefix + ""scope"", problems, Severity.WARNING, d.getScope(), d.getManagementKey(), ""provided"", ""compile"", ""runtime"", ""test"", ""system"");
            }
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-4695_bb39b480,Major,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,63,142,"public void validateRawModel(Model model, ModelBuildingRequest request, ModelProblemCollector problems) {
    Parent parent = model.getParent();
    if (parent != null) {
        validateStringNotEmpty(""parent.groupId"", problems, Severity.FATAL, parent.getGroupId(), parent);
        validateStringNotEmpty(""parent.artifactId"", problems, Severity.FATAL, parent.getArtifactId(), parent);
        validateStringNotEmpty(""parent.version"", problems, Severity.FATAL, parent.getVersion(), parent);
        if (equals(parent.getGroupId(), model.getGroupId()) && equals(parent.getArtifactId(), model.getArtifactId())) {
            addViolation(problems, Severity.FATAL, ""parent.artifactId"", null, ""must be changed"" + "", the parent element cannot have the same groupId:artifactId as the project."", parent);
        }
    }
    if (request.getValidationLevel() >= ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_2_0) {
        Severity errOn30 = getSeverity(request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0);
        validateEnum(""modelVersion"", problems, Severity.ERROR, model.getModelVersion(), null, model, ""4.0.0"");
        validateStringNoExpression(""groupId"", problems, Severity.WARNING, model.getGroupId(), model);
        validateStringNoExpression(""artifactId"", problems, Severity.WARNING, model.getArtifactId(), model);
        validateStringNoExpression(""version"", problems, Severity.WARNING, model.getVersion(), model);
        validateRawDependencies(problems, model.getDependencies(), ""dependencies.dependency"", request);
        if (model.getDependencyManagement() != null) {
            validateRawDependencies(problems, model.getDependencyManagement().getDependencies(), ""dependencyManagement.dependencies.dependency"", request);
        }
        validateRepositories(problems, model.getRepositories(), ""repositories.repository"", request);
        validateRepositories(problems, model.getPluginRepositories(), ""pluginRepositories.pluginRepository"", request);
        Build build = model.getBuild();
        if (build != null) {
            validateRawPlugins(problems, build.getPlugins(), false, request);
            PluginManagement mngt = build.getPluginManagement();
            if (mngt != null) {
                validateRawPlugins(problems, mngt.getPlugins(), true, request);
            }
        }
        Set<String> profileIds = new HashSet<String>();
        for (Profile profile : model.getProfiles()) {
            if (!profileIds.add(profile.getId())) {
                addViolation(problems, errOn30, ""profiles.profile.id"", null, ""must be unique but found duplicate profile with id "" + profile.getId(), profile);
            }
            validateRawDependencies(problems, profile.getDependencies(), ""profiles.profile["" + profile.getId() + ""].dependencies.dependency"", request);
            if (profile.getDependencyManagement() != null) {
                validateRawDependencies(problems, profile.getDependencyManagement().getDependencies(), ""profiles.profile["" + profile.getId() + ""].dependencyManagement.dependencies.dependency"", request);
            }
            validateRepositories(problems, profile.getRepositories(), ""profiles.profile["" + profile.getId() + ""].repositories.repository"", request);
            validateRepositories(problems, profile.getPluginRepositories(), ""profiles.profile["" + profile.getId() + ""].pluginRepositories.pluginRepository"", request);
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-4695_bb39b480,Major,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,144,181,"private void validateRawPlugins(ModelProblemCollector problems, List<Plugin> plugins, boolean managed, ModelBuildingRequest request) {
    Severity errOn31 = getSeverity(request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1);
    String prefix = (managed ? ""build.pluginManagement."" : ""build."") + ""plugins.plugin."";
    Map<String, Plugin> index = new HashMap<String, Plugin>();
    for (Plugin plugin : plugins) {
        String key = plugin.getKey();
        Plugin existing = index.get(key);
        if (existing != null) {
            addViolation(problems, errOn31, prefix + ""(groupId:artifactId)"", null, ""must be unique but found duplicate declaration of plugin "" + key, plugin);
        } else {
            index.put(key, plugin);
        }
        Set<String> executionIds = new HashSet<String>();
        for (PluginExecution exec : plugin.getExecutions()) {
            if (!executionIds.add(exec.getId())) {
                addViolation(problems, Severity.ERROR, ""build.plugins.plugin["" + plugin.getKey() + ""].executions.execution.id"", null, ""must be unique but found duplicate execution with id "" + exec.getId(), exec);
            }
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-4761_8cdb461f,Major,maven-core/src/main/java/org/apache/maven/plugin/internal/DefaultPluginDependenciesResolver.java,89,142,"public List<Artifact> resolve(Plugin plugin, Artifact pluginArtifact, ArtifactResolutionRequest request, ArtifactFilter dependencyFilter) throws PluginResolutionException {
    if (pluginArtifact == null) {
        pluginArtifact = repositorySystem.createPluginArtifact(plugin);
    }
    Set<Artifact> overrideArtifacts = new LinkedHashSet<Artifact>();
    for (Dependency dependency : plugin.getDependencies()) {
        dependency.setScope(Artifact.SCOPE_RUNTIME);
        overrideArtifacts.add(repositorySystem.createDependencyArtifact(dependency));
    }
    ArtifactFilter collectionFilter = new ScopeArtifactFilter(Artifact.SCOPE_RUNTIME_PLUS_SYSTEM);
    ArtifactFilter resolutionFilter = artifactFilterManager.getCoreArtifactFilter();
    PluginDependencyResolutionListener listener = new PluginDependencyResolutionListener(resolutionFilter);
    if (dependencyFilter != null) {
        resolutionFilter = new AndArtifactFilter(Arrays.asList(resolutionFilter, dependencyFilter));
    }
    request.setArtifact(pluginArtifact);
    request.setArtifactDependencies(overrideArtifacts);
    request.setCollectionFilter(collectionFilter);
    request.setResolutionFilter(resolutionFilter);
    request.setResolveRoot(true);
    request.setResolveTransitively(true);
    request.addListener(listener);
    ArtifactResolutionResult result = repositorySystem.resolve(request);
    try {
        resolutionErrorHandler.throwErrors(request, result);
    } catch (ArtifactResolutionException e) {
        throw new PluginResolutionException(plugin, e);
    }
    List<Artifact> pluginArtifacts = new ArrayList<Artifact>(result.getArtifacts());
    listener.removeBannedDependencies(pluginArtifacts);
    addPlexusUtils(pluginArtifacts, plugin, request);
    return pluginArtifacts;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4837_3fca2bb2,Minor,maven-model-builder/src/main/java/org/apache/maven/model/interpolation/StringSearchModelInterpolator.java,325,340,"private boolean isQualifiedForInterpolation(Field field, Class<?> fieldType) {
    Boolean primitive = fieldIsPrimitiveByClass.get(fieldType);
    if (primitive == null) {
        primitive = fieldType.isPrimitive();
        fieldIsPrimitiveByClass.put(fieldType, primitive);
    }
    if (primitive) {
        return false;
    }
    return !""parent"".equals(field.getName());
}"
maven,remotes/origin/bugs-dot-jar_MNG-4915_1c3abfba,Major,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,759,776,"private boolean validateVersion(String fieldName, ModelProblemCollector problems, Severity severity, String string, String sourceHint, InputLocationTracker tracker) {
    if (string == null || string.length() <= 0) {
        return true;
    }
    if (!hasExpression(string)) {
        return true;
    }
    addViolation(problems, severity, fieldName, sourceHint, ""must be a valid version but is '"" + string + ""'."", tracker);
    return false;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4915_1c3abfba,Major,maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java,778,800,"private boolean validatePluginVersion(String fieldName, ModelProblemCollector problems, String string, String sourceHint, InputLocationTracker tracker, ModelBuildingRequest request) {
    Severity errOn30 = getSeverity(request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0);
    if (string == null) {
        // NOTE: The check for missing plugin versions is handled directly by the model builder
        return true;
    }
    if (string.length() > 0 && !hasExpression(string) && !""RELEASE"".equals(string) && !""LATEST"".equals(string)) {
        return true;
    }
    addViolation(problems, errOn30, fieldName, sourceHint, ""must be a valid version but is '"" + string + ""'."", tracker);
    return false;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4918_691a03a7,Major,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,1408,1411,"public void setActiveProfiles(List<Profile> activeProfiles) {
    this.activeProfiles.addAll(activeProfiles);
}"
maven,remotes/origin/bugs-dot-jar_MNG-4933_469d0096,Major,maven-compat/src/main/java/org/apache/maven/project/path/DefaultPathTranslator.java,39,82,"public void alignToBaseDirectory(Model model, File basedir) {
    Build build = model.getBuild();
    if (build != null) {
        build.setDirectory(alignToBaseDirectory(build.getDirectory(), basedir));
        build.setSourceDirectory(alignToBaseDirectory(build.getSourceDirectory(), basedir));
        build.setTestSourceDirectory(alignToBaseDirectory(build.getTestSourceDirectory(), basedir));
        for (Resource resource : build.getResources()) {
            resource.setDirectory(alignToBaseDirectory(resource.getDirectory(), basedir));
        }
        for (Resource resource : build.getTestResources()) {
            resource.setDirectory(alignToBaseDirectory(resource.getDirectory(), basedir));
        }
        if (build.getFilters() != null) {
            List<String> filters = new ArrayList<String>();
            for (String filter : build.getFilters()) {
                filters.add(alignToBaseDirectory(filter, basedir));
            }
            build.setFilters(filters);
        }
        build.setOutputDirectory(alignToBaseDirectory(build.getOutputDirectory(), basedir));
        build.setTestOutputDirectory(alignToBaseDirectory(build.getTestOutputDirectory(), basedir));
    }
    Reporting reporting = model.getReporting();
    if (reporting != null) {
        reporting.setOutputDirectory(alignToBaseDirectory(reporting.getOutputDirectory(), basedir));
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-4933_469d0096,Major,maven-compat/src/main/java/org/apache/maven/project/path/DefaultPathTranslator.java,84,111,"public String alignToBaseDirectory(String path, File basedir) {
    if (path == null) {
        return null;
    }
    String s = stripBasedirToken(path);
    File file = new File(s);
    if (file.isAbsolute()) {
        // path was already absolute, just normalize file separator and we're done
        s = file.getPath();
    } else if (file.getPath().startsWith(File.separator)) {
        // drive-relative Windows path, don't align with project directory but with drive root
        s = file.getAbsolutePath();
    } else {
        // an ordinary relative path, align with project directory
        s = new File(new File(basedir, s).toURI().normalize()).getAbsolutePath();
    }
    return s;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4933_469d0096,Major,maven-compat/src/main/java/org/apache/maven/project/path/DefaultPathTranslator.java,167,210,"public void unalignFromBaseDirectory(Model model, File basedir) {
    Build build = model.getBuild();
    if (build != null) {
        build.setDirectory(unalignFromBaseDirectory(build.getDirectory(), basedir));
        build.setSourceDirectory(unalignFromBaseDirectory(build.getSourceDirectory(), basedir));
        build.setTestSourceDirectory(unalignFromBaseDirectory(build.getTestSourceDirectory(), basedir));
        for (Resource resource : build.getResources()) {
            resource.setDirectory(unalignFromBaseDirectory(resource.getDirectory(), basedir));
        }
        for (Resource resource : build.getTestResources()) {
            resource.setDirectory(unalignFromBaseDirectory(resource.getDirectory(), basedir));
        }
        if (build.getFilters() != null) {
            List<String> filters = new ArrayList<String>();
            for (String filter : build.getFilters()) {
                filters.add(unalignFromBaseDirectory(filter, basedir));
            }
            build.setFilters(filters);
        }
        build.setOutputDirectory(unalignFromBaseDirectory(build.getOutputDirectory(), basedir));
        build.setTestOutputDirectory(unalignFromBaseDirectory(build.getTestOutputDirectory(), basedir));
    }
    Reporting reporting = model.getReporting();
    if (reporting != null) {
        reporting.setOutputDirectory(unalignFromBaseDirectory(reporting.getOutputDirectory(), basedir));
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-4933_469d0096,Major,maven-compat/src/main/java/org/apache/maven/project/path/DefaultPathTranslator.java,212,220,"public String unalignFromBaseDirectory(String directory, File basedir) {
    String path = basedir.getPath();
    if (directory.startsWith(path)) {
        directory = directory.substring(path.length() + 1).replace('\\', '/');
    }
    return directory;
}"
maven,remotes/origin/bugs-dot-jar_MNG-4941_c4002945,Major,maven-plugin-api/src/main/java/org/apache/maven/plugin/descriptor/PluginDescriptorBuilder.java,117,331,"public MojoDescriptor buildComponentDescriptor(PlexusConfiguration c, PluginDescriptor pluginDescriptor) throws PlexusConfigurationException {
    MojoDescriptor mojo = new MojoDescriptor();
    mojo.setPluginDescriptor(pluginDescriptor);
    mojo.setGoal(c.getChild(""goal"").getValue());
    mojo.setImplementation(c.getChild(""implementation"").getValue());
    PlexusConfiguration langConfig = c.getChild(""language"");
    if (langConfig != null) {
        mojo.setLanguage(langConfig.getValue());
    }
    PlexusConfiguration configuratorConfig = c.getChild(""configurator"");
    if (configuratorConfig != null) {
        mojo.setComponentConfigurator(configuratorConfig.getValue());
    }
    PlexusConfiguration composerConfig = c.getChild(""composer"");
    if (composerConfig != null) {
        mojo.setComponentComposer(composerConfig.getValue());
    }
    String since = c.getChild(""since"").getValue();
    if (since != null) {
        mojo.setSince(since);
    }
    PlexusConfiguration deprecated = c.getChild(""deprecated"", false);
    if (deprecated != null) {
        mojo.setDeprecated(deprecated.getValue());
    }
    String phase = c.getChild(""phase"").getValue();
    if (phase != null) {
        mojo.setPhase(phase);
    }
    String executePhase = c.getChild(""executePhase"").getValue();
    if (executePhase != null) {
        mojo.setExecutePhase(executePhase);
    }
    String executeMojo = c.getChild(""executeGoal"").getValue();
    if (executeMojo != null) {
        mojo.setExecuteGoal(executeMojo);
    }
    String executeLifecycle = c.getChild(""executeLifecycle"").getValue();
    if (executeLifecycle != null) {
        mojo.setExecuteLifecycle(executeLifecycle);
    }
    mojo.setInstantiationStrategy(c.getChild(""instantiationStrategy"").getValue());
    mojo.setDescription(c.getChild(""description"").getValue());
    PlexusConfiguration dependencyResolution = c.getChild(""requiresDependencyResolution"", false);
    if (dependencyResolution != null) {
        mojo.setDependencyResolutionRequired(dependencyResolution.getValue());
    }
    PlexusConfiguration dependencyCollection = c.getChild(""requiresDependencyCollection"", false);
    if (dependencyCollection != null) {
        mojo.setDependencyCollectionRequired(dependencyCollection.getValue());
    }
    String directInvocationOnly = c.getChild(""requiresDirectInvocation"").getValue();
    if (directInvocationOnly != null) {
        mojo.setDirectInvocationOnly(Boolean.parseBoolean(directInvocationOnly));
    }
    String requiresProject = c.getChild(""requiresProject"").getValue();
    if (requiresProject != null) {
        mojo.setProjectRequired(Boolean.parseBoolean(requiresProject));
    }
    String requiresReports = c.getChild(""requiresReports"").getValue();
    if (requiresReports != null) {
        mojo.setRequiresReports(Boolean.parseBoolean(requiresReports));
    }
    String aggregator = c.getChild(""aggregator"").getValue();
    if (aggregator != null) {
        mojo.setAggregator(Boolean.parseBoolean(aggregator));
    }
    String requiresOnline = c.getChild(""requiresOnline"").getValue();
    if (requiresOnline != null) {
        mojo.setOnlineRequired(Boolean.parseBoolean(requiresOnline));
    }
    String inheritedByDefault = c.getChild(""inheritedByDefault"").getValue();
    if (inheritedByDefault != null) {
        mojo.setInheritedByDefault(Boolean.parseBoolean(inheritedByDefault));
    }
    String threadSafe = c.getChild(""threadSafe"").getValue();
    if (threadSafe != null) {
        mojo.setThreadSafe(Boolean.parseBoolean(threadSafe));
    }
    // ----------------------------------------------------------------------
    // Parameters
    // ----------------------------------------------------------------------
    PlexusConfiguration[] parameterConfigurations = c.getChild(""parameters"").getChildren(""parameter"");
    List<Parameter> parameters = new ArrayList<Parameter>();
    for (PlexusConfiguration d : parameterConfigurations) {
        Parameter parameter = new Parameter();
        parameter.setName(d.getChild(""name"").getValue());
        parameter.setAlias(d.getChild(""alias"").getValue());
        parameter.setType(d.getChild(""type"").getValue());
        String required = d.getChild(""required"").getValue();
        parameter.setRequired(Boolean.parseBoolean(required));
        PlexusConfiguration editableConfig = d.getChild(""editable"");
        // we need the null check for pre-build legacy plugins...
        if (editableConfig != null) {
            String editable = d.getChild(""editable"").getValue();
            parameter.setEditable(editable == null || Boolean.parseBoolean(editable));
        }
        parameter.setDescription(d.getChild(""description"").getValue());
        parameter.setDeprecated(d.getChild(""deprecated"").getValue());
        parameter.setImplementation(d.getChild(""implementation"").getValue());
        parameters.add(parameter);
    }
    mojo.setParameters(parameters);
    // TODO: this should not need to be handed off...
    // ----------------------------------------------------------------------
    // Configuration
    // ----------------------------------------------------------------------
    mojo.setMojoConfiguration(c.getChild(""configuration""));
    // TODO: Go back to this when we get the container ready to configure mojos...
    // mojo.setConfiguration( c.getChild( ""configuration"" ) );
    // ----------------------------------------------------------------------
    // Requirements
    // ----------------------------------------------------------------------
    PlexusConfiguration[] requirements = c.getChild(""requirements"").getChildren(""requirement"");
    for (PlexusConfiguration requirement : requirements) {
        ComponentRequirement cr = new ComponentRequirement();
        cr.setRole(requirement.getChild(""role"").getValue());
        cr.setRoleHint(requirement.getChild(""role-hint"").getValue());
        cr.setFieldName(requirement.getChild(""field-name"").getValue());
        mojo.addRequirement(cr);
    }
    return mojo;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5003_a7d9b689,Major,maven-core/src/main/java/org/apache/maven/plugin/internal/DefaultMavenPluginManager.java,294,324,"public synchronized void setupPluginRealm(PluginDescriptor pluginDescriptor, MavenSession session, ClassLoader parent, List<String> imports, DependencyFilter filter) throws PluginResolutionException, PluginContainerException {
    Plugin plugin = pluginDescriptor.getPlugin();
    MavenProject project = session.getCurrentProject();
    Map<String, ClassLoader> foreignImports = calcImports(project, parent, imports);
    PluginRealmCache.Key cacheKey = pluginRealmCache.createKey(plugin, parent, foreignImports, filter, project.getRemotePluginRepositories(), session.getRepositorySession());
    PluginRealmCache.CacheRecord cacheRecord = pluginRealmCache.get(cacheKey);
    if (cacheRecord != null) {
        pluginDescriptor.setClassRealm(cacheRecord.realm);
        pluginDescriptor.setArtifacts(new ArrayList<Artifact>(cacheRecord.artifacts));
    } else {
        createPluginRealm(pluginDescriptor, session, parent, foreignImports, filter);
        cacheRecord = pluginRealmCache.put(cacheKey, pluginDescriptor.getClassRealm(), pluginDescriptor.getArtifacts());
    }
    pluginRealmCache.register(project, cacheRecord);
}"
maven,remotes/origin/bugs-dot-jar_MNG-5075_2eb419ed,Major,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,346,386,"public MavenProject getParent() {
    if (parent == null) {
        /*
             * TODO: This is suboptimal. Without a cache in the project builder, rebuilding the parent chain currently
             * causes O(n^2) parser invocations for an inheritance hierarchy of depth n.
             */
        if (parentFile != null) {
            checkProjectBuildingRequest();
            ProjectBuildingRequest request = new DefaultProjectBuildingRequest(projectBuilderConfiguration);
            request.setRemoteRepositories(getRemoteArtifactRepositories());
            try {
                parent = mavenProjectBuilder.build(parentFile, request).getProject();
            } catch (ProjectBuildingException e) {
                throw new IllegalStateException(""Failed to build parent project for "" + getId(), e);
            }
        } else if (model.getParent() != null) {
            checkProjectBuildingRequest();
            ProjectBuildingRequest request = new DefaultProjectBuildingRequest(projectBuilderConfiguration);
            request.setRemoteRepositories(getRemoteArtifactRepositories());
            try {
                parent = mavenProjectBuilder.build(getParentArtifact(), request).getProject();
            } catch (ProjectBuildingException e) {
                throw new IllegalStateException(""Failed to build parent project for "" + getId(), e);
            }
        }
    }
    return parent;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5209_87884c7b,Minor,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,502,522,"public List<String> getCompileClasspathElements() throws DependencyResolutionRequiredException {
    List<String> list = new ArrayList<String>(getArtifacts().size() + 1);
    list.add(getBuild().getOutputDirectory());
    for (Artifact a : getArtifacts()) {
        if (a.getArtifactHandler().isAddedToClasspath()) {
            // TODO: let the scope handler deal with this
            if (Artifact.SCOPE_COMPILE.equals(a.getScope()) || Artifact.SCOPE_PROVIDED.equals(a.getScope()) || Artifact.SCOPE_SYSTEM.equals(a.getScope())) {
                addArtifactPath(a, list);
            }
        }
    }
    return list;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5209_87884c7b,Minor,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,578,596,"// TODO: this checking for file == null happens because the resolver has been confused about the root
// artifact or not. things like the stupid dummy artifact coming from surefire.
public List<String> getTestClasspathElements() throws DependencyResolutionRequiredException {
    List<String> list = new ArrayList<String>(getArtifacts().size() + 2);
    list.add(getBuild().getTestOutputDirectory());
    list.add(getBuild().getOutputDirectory());
    for (Artifact a : getArtifacts()) {
        if (a.getArtifactHandler().isAddedToClasspath()) {
            addArtifactPath(a, list);
        }
    }
    return list;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5209_87884c7b,Minor,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,642,661,"public List<String> getRuntimeClasspathElements() throws DependencyResolutionRequiredException {
    List<String> list = new ArrayList<String>(getArtifacts().size() + 1);
    list.add(getBuild().getOutputDirectory());
    for (Artifact a : getArtifacts()) {
        if (a.getArtifactHandler().isAddedToClasspath()) {
            // TODO: let the scope handler deal with this
            if (Artifact.SCOPE_COMPILE.equals(a.getScope()) || Artifact.SCOPE_RUNTIME.equals(a.getScope())) {
                addArtifactPath(a, list);
            }
        }
    }
    return list;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5209_87884c7b,Minor,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,715,734,"public List<String> getSystemClasspathElements() throws DependencyResolutionRequiredException {
    List<String> list = new ArrayList<String>(getArtifacts().size());
    list.add(getBuild().getOutputDirectory());
    for (Artifact a : getArtifacts()) {
        if (a.getArtifactHandler().isAddedToClasspath()) {
            // TODO: let the scope handler deal with this
            if (Artifact.SCOPE_SYSTEM.equals(a.getScope())) {
                addArtifactPath(a, list);
            }
        }
    }
    return list;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5209_ed651a4d,Minor,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,502,522,"public List<String> getCompileClasspathElements() throws DependencyResolutionRequiredException {
    List<String> list = new ArrayList<String>(getArtifacts().size() + 1);
    list.add(getBuild().getOutputDirectory());
    for (Artifact a : getArtifacts()) {
        if (a.getArtifactHandler().isAddedToClasspath()) {
            // TODO: let the scope handler deal with this
            if (Artifact.SCOPE_COMPILE.equals(a.getScope()) || Artifact.SCOPE_PROVIDED.equals(a.getScope()) || Artifact.SCOPE_SYSTEM.equals(a.getScope())) {
                addArtifactPath(a, list);
            }
        }
    }
    return list;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5209_ed651a4d,Minor,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,578,596,"// TODO: this checking for file == null happens because the resolver has been confused about the root
// artifact or not. things like the stupid dummy artifact coming from surefire.
public List<String> getTestClasspathElements() throws DependencyResolutionRequiredException {
    List<String> list = new ArrayList<String>(getArtifacts().size() + 2);
    list.add(getBuild().getTestOutputDirectory());
    list.add(getBuild().getOutputDirectory());
    for (Artifact a : getArtifacts()) {
        if (a.getArtifactHandler().isAddedToClasspath()) {
            addArtifactPath(a, list);
        }
    }
    return list;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5209_ed651a4d,Minor,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,642,661,"public List<String> getRuntimeClasspathElements() throws DependencyResolutionRequiredException {
    List<String> list = new ArrayList<String>(getArtifacts().size() + 1);
    list.add(getBuild().getOutputDirectory());
    for (Artifact a : getArtifacts()) {
        if (a.getArtifactHandler().isAddedToClasspath()) {
            // TODO: let the scope handler deal with this
            if (Artifact.SCOPE_COMPILE.equals(a.getScope()) || Artifact.SCOPE_RUNTIME.equals(a.getScope())) {
                addArtifactPath(a, list);
            }
        }
    }
    return list;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5209_ed651a4d,Minor,maven-core/src/main/java/org/apache/maven/project/MavenProject.java,715,734,"public List<String> getSystemClasspathElements() throws DependencyResolutionRequiredException {
    List<String> list = new ArrayList<String>(getArtifacts().size());
    list.add(getBuild().getOutputDirectory());
    for (Artifact a : getArtifacts()) {
        if (a.getArtifactHandler().isAddedToClasspath()) {
            // TODO: let the scope handler deal with this
            if (Artifact.SCOPE_SYSTEM.equals(a.getScope())) {
                addArtifactPath(a, list);
            }
        }
    }
    return list;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5212_712c4fff,Major,maven-core/src/main/java/org/apache/maven/plugin/DefaultPluginDescriptorCache.java,75,102,"protected static PluginDescriptor clone(PluginDescriptor original) {
    PluginDescriptor clone = null;
    if (original != null) {
        clone = new PluginDescriptor();
        clone.setGroupId(original.getGroupId());
        clone.setArtifactId(original.getArtifactId());
        clone.setVersion(original.getVersion());
        clone.setGoalPrefix(original.getGoalPrefix());
        clone.setInheritedByDefault(original.isInheritedByDefault());
        clone.setName(original.getName());
        clone.setDescription(original.getDescription());
        clone.setRequiredMavenVersion(original.getRequiredMavenVersion());
        clone.setPluginArtifact(ArtifactUtils.copyArtifactSafe(original.getPluginArtifact()));
        clone.setComponents(clone(original.getMojos(), clone));
        clone.setId(original.getId());
        clone.setIsolatedRealm(original.isIsolatedRealm());
        clone.setSource(original.getSource());
    }
    return clone;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5212_c53d95ce,Major,maven-core/src/main/java/org/apache/maven/plugin/DefaultPluginDescriptorCache.java,75,102,"protected static PluginDescriptor clone(PluginDescriptor original) {
    PluginDescriptor clone = null;
    if (original != null) {
        clone = new PluginDescriptor();
        clone.setGroupId(original.getGroupId());
        clone.setArtifactId(original.getArtifactId());
        clone.setVersion(original.getVersion());
        clone.setGoalPrefix(original.getGoalPrefix());
        clone.setInheritedByDefault(original.isInheritedByDefault());
        clone.setName(original.getName());
        clone.setDescription(original.getDescription());
        clone.setRequiredMavenVersion(original.getRequiredMavenVersion());
        clone.setPluginArtifact(ArtifactUtils.copyArtifactSafe(original.getPluginArtifact()));
        clone.setComponents(clone(original.getMojos(), clone));
        clone.setId(original.getId());
        clone.setIsolatedRealm(original.isIsolatedRealm());
        clone.setSource(original.getSource());
    }
    return clone;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5459_c225847e,Major,maven-aether-provider/src/main/java/org/apache/maven/repository/internal/DefaultArtifactDescriptorReader.java,269,391,"private Model loadPom(RepositorySystemSession session, ArtifactDescriptorRequest request, ArtifactDescriptorResult result) throws ArtifactDescriptorException {
    RequestTrace trace = RequestTrace.newChild(request.getTrace(), request);
    Set<String> visited = new LinkedHashSet<String>();
    for (Artifact artifact = request.getArtifact(); ; ) {
        try {
            VersionRequest versionRequest = new VersionRequest(artifact, request.getRepositories(), request.getRequestContext());
            versionRequest.setTrace(trace);
            VersionResult versionResult = versionResolver.resolveVersion(session, versionRequest);
            artifact = artifact.setVersion(versionResult.getVersion());
        } catch (VersionResolutionException e) {
            result.addException(e);
            throw new ArtifactDescriptorException(result);
        }
        if (!visited.add(artifact.getGroupId() + ':' + artifact.getArtifactId() + ':' + artifact.getBaseVersion())) {
            RepositoryException exception = new RepositoryException(""Artifact relocations form a cycle: "" + visited);
            invalidDescriptor(session, trace, artifact, exception);
            if ((getPolicy(session, artifact, request) & ArtifactDescriptorPolicy.IGNORE_INVALID) != 0) {
                return null;
            }
            result.addException(exception);
            throw new ArtifactDescriptorException(result);
        }
        Artifact pomArtifact = ArtifactDescriptorUtils.toPomArtifact(artifact);
        ArtifactResult resolveResult;
        try {
            ArtifactRequest resolveRequest = new ArtifactRequest(pomArtifact, request.getRepositories(), request.getRequestContext());
            resolveRequest.setTrace(trace);
            resolveResult = artifactResolver.resolveArtifact(session, resolveRequest);
            pomArtifact = resolveResult.getArtifact();
            result.setRepository(resolveResult.getRepository());
        } catch (ArtifactResolutionException e) {
            if (e.getCause() instanceof ArtifactNotFoundException) {
                missingDescriptor(session, trace, artifact, (Exception) e.getCause());
                if ((getPolicy(session, artifact, request) & ArtifactDescriptorPolicy.IGNORE_MISSING) != 0) {
                    return null;
                }
            }
            result.addException(e);
            throw new ArtifactDescriptorException(result);
        }
        Model model;
        try {
            ModelBuildingRequest modelRequest = new DefaultModelBuildingRequest();
            modelRequest.setValidationLevel(ModelBuildingRequest.VALIDATION_LEVEL_MINIMAL);
            modelRequest.setProcessPlugins(false);
            modelRequest.setTwoPhaseBuilding(false);
            modelRequest.setSystemProperties(toProperties(session.getUserProperties(), session.getSystemProperties()));
            modelRequest.setModelCache(DefaultModelCache.newInstance(session));
            modelRequest.setModelResolver(new DefaultModelResolver(session, trace.newChild(modelRequest), request.getRequestContext(), artifactResolver, remoteRepositoryManager, request.getRepositories()));
            if (resolveResult.getRepository() instanceof WorkspaceRepository) {
                modelRequest.setPomFile(pomArtifact.getFile());
            } else {
                modelRequest.setModelSource(new FileModelSource(pomArtifact.getFile()));
            }
            model = modelBuilder.build(modelRequest).getEffectiveModel();
        } catch (ModelBuildingException e) {
            for (ModelProblem problem : e.getProblems()) {
                if (problem.getException() instanceof UnresolvableModelException) {
                    result.addException(problem.getException());
                    throw new ArtifactDescriptorException(result);
                }
            }
            invalidDescriptor(session, trace, artifact, e);
            if ((getPolicy(session, artifact, request) & ArtifactDescriptorPolicy.IGNORE_INVALID) != 0) {
                return null;
            }
            result.addException(e);
            throw new ArtifactDescriptorException(result);
        }
        Relocation relocation = getRelocation(model);
        if (relocation != null) {
            result.addRelocation(artifact);
            artifact = new RelocatedArtifact(artifact, relocation.getGroupId(), relocation.getArtifactId(), relocation.getVersion());
            result.setArtifact(artifact);
        } else {
            return model;
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-5613_bef7fac6,Major,maven-core/src/main/java/org/apache/maven/DefaultMaven.java,207,382,"// 
// 1) Setup initial properties.
// 
// 2) Validate local repository directory is accessible.
// 
// 3) Create RepositorySystemSession.
// 
// 4) Create MavenSession.
// 
// 5) Execute AbstractLifecycleParticipant.afterSessionStart(session)
// 
// 6) Get reactor projects looking for general POM errors
// 
// 7) Create ProjectDependencyGraph using trimming which takes into account --projects and reactor mode. This ensures
// that the projects passed into the ReactorReader are only those specified.
// 
// 8) Create ReactorReader with the getProjectMap( projects ). NOTE that getProjectMap(projects) is the code that
// checks for duplicate projects definitions in the build. Ideally this type of duplicate checking should be part of
// getting the reactor projects in 6). The duplicate checking is conflated with getProjectMap(projects).
// 
// 9) Execute AbstractLifecycleParticipant.afterProjectsRead(session)
// 
// 10) Create ProjectDependencyGraph without trimming (as trimming was done in 7). A new topological sort is required after
// the execution of 9) as the AbstractLifecycleParticipants are free to mutate the MavenProject instances, which may change
// dependencies which can, in turn, affect the build order.
// 
// 11) Execute LifecycleStarter.start()
// 
private MavenExecutionResult doExecute(MavenExecutionRequest request) {
    if (request.getStartTime() != null) {
        request.getSystemProperties().put(""${build.timestamp}"", new SimpleDateFormat(""yyyyMMdd-hhmm"").format(request.getStartTime()));
    }
    request.setStartTime(new Date());
    MavenExecutionResult result = new DefaultMavenExecutionResult();
    try {
        validateLocalRepository(request);
    } catch (LocalRepositoryNotAccessibleException e) {
        return addExceptionToResult(result, e);
    }
    DefaultRepositorySystemSession repoSession = (DefaultRepositorySystemSession) newRepositorySession(request);
    MavenSession session = new MavenSession(container, repoSession, request, result);
    legacySupport.setSession(session);
    try {
        for (AbstractMavenLifecycleParticipant listener : getLifecycleParticipants(Collections.<MavenProject>emptyList())) {
            listener.afterSessionStart(session);
        }
    } catch (MavenExecutionException e) {
        return addExceptionToResult(result, e);
    }
    eventCatapult.fire(ExecutionEvent.Type.ProjectDiscoveryStarted, session, null);
    List<MavenProject> projects;
    try {
        projects = getProjectsForMavenReactor(session);
        // 
        // Capture the full set of projects before any potential constraining is performed by --projects
        // 
        session.setAllProjects(projects);
    } catch (ProjectBuildingException e) {
        return addExceptionToResult(result, e);
    }
    validateProjects(projects);
    // 
    // This creates the graph and trims the projects down based on the user request using something like:
    // 
    // -pl project0,project2 eclipse:eclipse
    // 
    ProjectDependencyGraph projectDependencyGraph = createProjectDependencyGraph(projects, request, result, true);
    session.setProjects(projectDependencyGraph.getSortedProjects());
    if (result.hasExceptions()) {
        return result;
    }
    try {
        session.setProjectMap(getProjectMap(session.getProjects()));
    } catch (DuplicateProjectException e) {
        return addExceptionToResult(result, e);
    }
    WorkspaceReader reactorWorkspace;
    sessionScope.enter();
    sessionScope.seed(MavenSession.class, session);
    try {
        reactorWorkspace = container.lookup(WorkspaceReader.class, ReactorReader.HINT);
    } catch (ComponentLookupException e) {
        return addExceptionToResult(result, e);
    }
    // 
    // Desired order of precedence for local artifact repositories
    // 
    // Reactor
    // Workspace
    // User Local Repository
    // 
    repoSession.setWorkspaceReader(ChainedWorkspaceReader.newInstance(reactorWorkspace, repoSession.getWorkspaceReader()));
    repoSession.setReadOnly();
    ClassLoader originalClassLoader = Thread.currentThread().getContextClassLoader();
    try {
        for (AbstractMavenLifecycleParticipant listener : getLifecycleParticipants(projects)) {
            Thread.currentThread().setContextClassLoader(listener.getClass().getClassLoader());
            listener.afterProjectsRead(session);
        }
    } catch (MavenExecutionException e) {
        return addExceptionToResult(result, e);
    } finally {
        Thread.currentThread().setContextClassLoader(originalClassLoader);
    }
    // 
    // The projects need to be topologically after the participants have run their afterProjectsRead(session)
    // because the participant is free to change the dependencies of a project which can potentially change the
    // topological order of the projects, and therefore can potentially change the build order.
    // 
    // Note that participants may affect the topological order of the projects but it is
    // not expected that a participant will add or remove projects from the session.
    // 
    projectDependencyGraph = createProjectDependencyGraph(session.getProjects(), request, result, false);
    if (result.hasExceptions()) {
        try {
            afterSessionEnd(projects, session);
        } catch (MavenExecutionException e) {
            return addExceptionToResult(result, e);
        }
        return result;
    }
    session.setProjects(projectDependencyGraph.getSortedProjects());
    session.setProjectDependencyGraph(projectDependencyGraph);
    result.setTopologicallySortedProjects(session.getProjects());
    result.setProject(session.getTopLevelProject());
    lifecycleStarter.execute(session);
    validateActivatedProfiles(session.getProjects(), request.getActiveProfiles());
    if (session.getResult().hasExceptions()) {
        return addExceptionToResult(result, session.getResult().getExceptions().get(0));
    }
    try {
        afterSessionEnd(projects, session);
    } catch (MavenExecutionException e) {
        return addExceptionToResult(result, e);
    }
    sessionScope.exit();
    return result;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5645_af1ecd5f,Trivial,maven-artifact/src/main/java/org/apache/maven/artifact/versioning/DefaultArtifactVersion.java,205,213,"private static Integer getNextIntegerToken(StringTokenizer tok) {
    String s = tok.nextToken();
    if ((s.length() > 1) && s.startsWith(""0"")) {
        throw new NumberFormatException(""Number part has a leading 0: '"" + s + ""'"");
    }
    return Integer.valueOf(s);
}"
maven,remotes/origin/bugs-dot-jar_MNG-5655_96337372,Major,maven-core/src/main/java/org/apache/maven/execution/scope/internal/MojoExecutionScope.java,177,187,"public void beforeMojoExecution(MojoExecutionEvent event) throws MojoExecutionException {
    for (Object provided : getScopeState().provided.values()) {
        if (provided instanceof WeakMojoExecutionListener) {
            ((WeakMojoExecutionListener) provided).beforeMojoExecution(event);
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-5655_96337372,Major,maven-core/src/main/java/org/apache/maven/execution/scope/internal/MojoExecutionScope.java,189,199,"public void afterMojoExecutionSuccess(MojoExecutionEvent event) throws MojoExecutionException {
    for (Object provided : getScopeState().provided.values()) {
        if (provided instanceof WeakMojoExecutionListener) {
            ((WeakMojoExecutionListener) provided).afterMojoExecutionSuccess(event);
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-5655_96337372,Major,maven-core/src/main/java/org/apache/maven/execution/scope/internal/MojoExecutionScope.java,201,210,"public void afterExecutionFailure(MojoExecutionEvent event) {
    for (Object provided : getScopeState().provided.values()) {
        if (provided instanceof WeakMojoExecutionListener) {
            ((WeakMojoExecutionListener) provided).afterExecutionFailure(event);
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-5687_3d2d8619,Major,maven-core/src/main/java/org/apache/maven/DefaultProjectDependencyGraph.java,61,73,"public List<MavenProject> getDownstreamProjects(MavenProject project, boolean transitive) {
    if (project == null) {
        throw new IllegalArgumentException(""project missing"");
    }
    Collection<String> projectIds = new HashSet<String>();
    getDownstreamProjects(ProjectSorter.getId(project), projectIds, transitive);
    return getProjects(projectIds);
}"
maven,remotes/origin/bugs-dot-jar_MNG-5687_3d2d8619,Major,maven-core/src/main/java/org/apache/maven/DefaultProjectDependencyGraph.java,75,84,"private void getDownstreamProjects(String projectId, Collection<String> projectIds, boolean transitive) {
    for (String id : sorter.getDependents(projectId)) {
        if (projectIds.add(id) && transitive) {
            getDownstreamProjects(id, projectIds, transitive);
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-5687_3d2d8619,Major,maven-core/src/main/java/org/apache/maven/DefaultProjectDependencyGraph.java,86,98,"public List<MavenProject> getUpstreamProjects(MavenProject project, boolean transitive) {
    if (project == null) {
        throw new IllegalArgumentException(""project missing"");
    }
    Collection<String> projectIds = new HashSet<String>();
    getUpstreamProjects(ProjectSorter.getId(project), projectIds, transitive);
    return getProjects(projectIds);
}"
maven,remotes/origin/bugs-dot-jar_MNG-5687_3d2d8619,Major,maven-core/src/main/java/org/apache/maven/DefaultProjectDependencyGraph.java,111,126,"private List<MavenProject> getProjects(Collection<String> projectIds) {
    List<MavenProject> projects = new ArrayList<MavenProject>(projectIds.size());
    for (String projectId : projectIds) {
        MavenProject project = sorter.getProjectMap().get(projectId);
        if (project != null) {
            projects.add(project);
        }
    }
    return projects;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5716_2d0ec942,Minor,maven-core/src/main/java/org/apache/maven/toolchain/DefaultToolchainManagerPrivate.java,50,112,"public ToolchainPrivate[] getToolchainsForType(String type, MavenSession context) throws MisconfiguredToolchainException {
    DefaultToolchainsBuildingRequest buildRequest = new DefaultToolchainsBuildingRequest();
    File globalToolchainsFile = context.getRequest().getGlobalToolchainsFile();
    if (globalToolchainsFile != null && globalToolchainsFile.isFile()) {
        buildRequest.setGlobalToolchainsSource(new FileSource(globalToolchainsFile));
    }
    File userToolchainsFile = context.getRequest().getUserToolchainsFile();
    if (userToolchainsFile != null && userToolchainsFile.isFile()) {
        buildRequest.setUserToolchainsSource(new FileSource(userToolchainsFile));
    }
    ToolchainsBuildingResult buildResult;
    try {
        buildResult = toolchainsBuilder.build(buildRequest);
    } catch (ToolchainsBuildingException e) {
        throw new MisconfiguredToolchainException(e.getMessage(), e);
    }
    PersistedToolchains pers = buildResult.getEffectiveToolchains();
    List<ToolchainPrivate> toRet = new ArrayList<ToolchainPrivate>();
    ToolchainFactory fact = factories.get(type);
    if (fact == null) {
        logger.error(""Missing toolchain factory for type: "" + type + "". Possibly caused by misconfigured project."");
    } else if (pers != null) {
        List<ToolchainModel> lst = pers.getToolchains();
        if (lst != null) {
            for (ToolchainModel toolchainModel : lst) {
                if (type.equals(toolchainModel.getType())) {
                    toRet.add(fact.createToolchain(toolchainModel));
                }
            }
        }
    }
    for (ToolchainFactory toolchainFactory : factories.values()) {
        ToolchainPrivate tool = toolchainFactory.createDefaultToolchain();
        if (tool != null) {
            toRet.add(tool);
        }
    }
    return toRet.toArray(new ToolchainPrivate[toRet.size()]);
}"
maven,remotes/origin/bugs-dot-jar_MNG-5727_ce6f0bfd,Major,maven-core/src/main/java/org/apache/maven/bridge/MavenRepositorySystem.java,108,142,"// DefaultProjectBuilder
public Artifact createDependencyArtifact(Dependency d) {
    VersionRange versionRange;
    try {
        versionRange = VersionRange.createFromVersionSpec(d.getVersion());
    } catch (InvalidVersionSpecificationException e) {
        return null;
    }
    Artifact artifact = XcreateDependencyArtifact(d.getGroupId(), d.getArtifactId(), versionRange, d.getType(), d.getClassifier(), d.getScope(), d.isOptional());
    if (Artifact.SCOPE_SYSTEM.equals(d.getScope()) && d.getSystemPath() != null) {
        artifact.setFile(new File(d.getSystemPath()));
    }
    if (!d.getExclusions().isEmpty()) {
        List<String> exclusions = new ArrayList<String>();
        for (Exclusion exclusion : d.getExclusions()) {
            exclusions.add(exclusion.getGroupId() + ':' + exclusion.getArtifactId());
        }
        artifact.setDependencyFilter(new ExcludesArtifactFilter(exclusions));
    }
    return artifact;
}"
maven,remotes/origin/bugs-dot-jar_MNG-5727_ce6f0bfd,Major,maven-core/src/main/java/org/apache/maven/project/DefaultProjectBuilder.java,642,869,"private void initProject(MavenProject project, Map<String, MavenProject> projects, ModelBuildingResult result, Map<File, Boolean> profilesXmls, ProjectBuildingRequest projectBuildingRequest) {
    Model model = result.getEffectiveModel();
    project.setModel(model);
    project.setOriginalModel(result.getRawModel());
    project.setFile(model.getPomFile());
    Parent p = model.getParent();
    if (p != null) {
        project.setParentArtifact(repositorySystem.createProjectArtifact(p.getGroupId(), p.getArtifactId(), p.getVersion()));
        // org.apache.maven.its.mng4834:parent:0.1
        String parentModelId = result.getModelIds().get(1);
        File parentPomFile = result.getRawModel(parentModelId).getPomFile();
        MavenProject parent = projects.get(parentModelId);
        if (parent == null) {
            // 
            // At this point the DefaultModelBuildingListener has fired and it populates the
            // remote repositories with those found in the pom.xml, along with the existing externally
            // defined repositories.
            // 
            projectBuildingRequest.setRemoteRepositories(project.getRemoteArtifactRepositories());
            if (parentPomFile != null) {
                project.setParentFile(parentPomFile);
                try {
                    parent = build(parentPomFile, projectBuildingRequest).getProject();
                } catch (ProjectBuildingException e) {
                    // MNG-4488 where let invalid parents slide on by
                    logger.warn(""Failed to build parent project for "" + project.getId());
                }
            } else {
                Artifact parentArtifact = project.getParentArtifact();
                try {
                    parent = build(parentArtifact, projectBuildingRequest).getProject();
                } catch (ProjectBuildingException e) {
                    // MNG-4488 where let invalid parents slide on by
                    logger.warn(""Failed to build parent project for "" + project.getId());
                }
            }
        }
        project.setParent(parent);
    }
    Artifact projectArtifact = repositorySystem.createArtifact(project.getGroupId(), project.getArtifactId(), project.getVersion(), null, project.getPackaging());
    project.setArtifact(projectArtifact);
    if (project.getFile() != null) {
        Build build = project.getBuild();
        project.addScriptSourceRoot(build.getScriptSourceDirectory());
        project.addCompileSourceRoot(build.getSourceDirectory());
        project.addTestCompileSourceRoot(build.getTestSourceDirectory());
    }
    List<Profile> activeProfiles = new ArrayList<Profile>();
    activeProfiles.addAll(result.getActivePomProfiles(result.getModelIds().get(0)));
    activeProfiles.addAll(result.getActiveExternalProfiles());
    project.setActiveProfiles(activeProfiles);
    project.setInjectedProfileIds(""external"", getProfileIds(result.getActiveExternalProfiles()));
    for (String modelId : result.getModelIds()) {
        project.setInjectedProfileIds(modelId, getProfileIds(result.getActivePomProfiles(modelId)));
    }
    String modelId = findProfilesXml(result, profilesXmls);
    if (modelId != null) {
        ModelProblem problem = new DefaultModelProblem(""Detected profiles.xml alongside "" + modelId + "", this file is no longer supported and was ignored"" + "", please use the settings.xml instead"", ModelProblem.Severity.WARNING, ModelProblem.Version.V30, model, -1, -1, null);
        result.getProblems().add(problem);
    }
    // 
    // All the parts that were taken out of MavenProject for Maven 4.0.0
    // 
    project.setProjectBuildingRequest(projectBuildingRequest);
    // pluginArtifacts
    Set<Artifact> pluginArtifacts = new HashSet<Artifact>();
    for (Plugin plugin : project.getBuildPlugins()) {
        Artifact artifact = repositorySystem.createPluginArtifact(plugin);
        if (artifact != null) {
            pluginArtifacts.add(artifact);
        }
    }
    project.setPluginArtifacts(pluginArtifacts);
    // reportArtifacts
    Set<Artifact> reportArtifacts = new HashSet<Artifact>();
    for (ReportPlugin report : project.getReportPlugins()) {
        Plugin pp = new Plugin();
        pp.setGroupId(report.getGroupId());
        pp.setArtifactId(report.getArtifactId());
        pp.setVersion(report.getVersion());
        Artifact artifact = repositorySystem.createPluginArtifact(pp);
        if (artifact != null) {
            reportArtifacts.add(artifact);
        }
    }
    project.setReportArtifacts(reportArtifacts);
    // extensionArtifacts
    Set<Artifact> extensionArtifacts = new HashSet<Artifact>();
    List<Extension> extensions = project.getBuildExtensions();
    if (extensions != null) {
        for (Extension ext : extensions) {
            String version;
            if (StringUtils.isEmpty(ext.getVersion())) {
                version = ""RELEASE"";
            } else {
                version = ext.getVersion();
            }
            Artifact artifact = repositorySystem.createArtifact(ext.getGroupId(), ext.getArtifactId(), version, null, ""jar"");
            if (artifact != null) {
                extensionArtifacts.add(artifact);
            }
        }
    }
    project.setExtensionArtifacts(extensionArtifacts);
    // managedVersionMap
    Map<String, Artifact> map = null;
    if (repositorySystem != null) {
        List<Dependency> deps;
        DependencyManagement dependencyManagement = project.getDependencyManagement();
        if ((dependencyManagement != null) && ((deps = dependencyManagement.getDependencies()) != null) && (deps.size() > 0)) {
            map = new HashMap<String, Artifact>();
            for (Dependency d : dependencyManagement.getDependencies()) {
                Artifact artifact = repositorySystem.createDependencyArtifact(d);
                if (artifact == null) {
                    map = Collections.emptyMap();
                }
                map.put(d.getManagementKey(), artifact);
            }
        } else {
            map = Collections.emptyMap();
        }
    }
    project.setManagedVersionMap(map);
    // release artifact repository
    if (project.getDistributionManagement() != null && project.getDistributionManagement().getRepository() != null) {
        try {
            DeploymentRepository r = project.getDistributionManagement().getRepository();
            if (!StringUtils.isEmpty(r.getId()) && !StringUtils.isEmpty(r.getUrl())) {
                ArtifactRepository repo = repositorySystem.buildArtifactRepository(project.getDistributionManagement().getRepository());
                repositorySystem.injectProxy(projectBuildingRequest.getRepositorySession(), Arrays.asList(repo));
                repositorySystem.injectAuthentication(projectBuildingRequest.getRepositorySession(), Arrays.asList(repo));
                project.setReleaseArtifactRepository(repo);
            }
        } catch (InvalidRepositoryException e) {
            throw new IllegalStateException(""Failed to create release distribution repository for "" + project.getId(), e);
        }
    }
    // snapshot artifact repository
    if (project.getDistributionManagement() != null && project.getDistributionManagement().getSnapshotRepository() != null) {
        try {
            DeploymentRepository r = project.getDistributionManagement().getSnapshotRepository();
            if (!StringUtils.isEmpty(r.getId()) && !StringUtils.isEmpty(r.getUrl())) {
                ArtifactRepository repo = repositorySystem.buildArtifactRepository(project.getDistributionManagement().getSnapshotRepository());
                repositorySystem.injectProxy(projectBuildingRequest.getRepositorySession(), Arrays.asList(repo));
                repositorySystem.injectAuthentication(projectBuildingRequest.getRepositorySession(), Arrays.asList(repo));
                project.setSnapshotArtifactRepository(repo);
            }
        } catch (InvalidRepositoryException e) {
            throw new IllegalStateException(""Failed to create snapshot distribution repository for "" + project.getId(), e);
        }
    }
}"
maven,remotes/origin/bugs-dot-jar_MNG-5742_6ab41ee8,Major,maven-core/src/main/java/org/apache/maven/plugin/internal/DefaultMavenPluginManager.java,367,434,"private void createPluginRealm(PluginDescriptor pluginDescriptor, MavenSession session, ClassLoader parent, Map<String, ClassLoader> foreignImports, DependencyFilter filter) throws PluginResolutionException, PluginContainerException {
    Plugin plugin = pluginDescriptor.getPlugin();
    if (plugin == null) {
        throw new IllegalArgumentException(""incomplete plugin descriptor, plugin missing"");
    }
    Artifact pluginArtifact = pluginDescriptor.getPluginArtifact();
    if (pluginArtifact == null) {
        throw new IllegalArgumentException(""incomplete plugin descriptor, plugin artifact missing"");
    }
    MavenProject project = session.getCurrentProject();
    final ClassRealm pluginRealm;
    final List<Artifact> pluginArtifacts;
    RepositorySystemSession repositorySession = session.getRepositorySession();
    if (plugin.isExtensions()) {
        // TODO discover components in #setupExtensionsRealm
        ExtensionRealmCache.CacheRecord extensionRecord;
        try {
            extensionRecord = setupExtensionsRealm(project, plugin, repositorySession);
        } catch (PluginManagerException e) {
            // any exception means a problem in maven code, not a user error
            throw new IllegalStateException(e);
        }
        pluginRealm = extensionRecord.realm;
        pluginArtifacts = extensionRecord.artifacts;
    } else {
        DependencyFilter dependencyFilter = project.getExtensionDependencyFilter();
        dependencyFilter = AndDependencyFilter.newInstance(dependencyFilter, filter);
        DependencyNode root = pluginDependenciesResolver.resolve(plugin, RepositoryUtils.toArtifact(pluginArtifact), dependencyFilter, project.getRemotePluginRepositories(), repositorySession);
        PreorderNodeListGenerator nlg = new PreorderNodeListGenerator();
        root.accept(nlg);
        pluginArtifacts = toMavenArtifacts(root, nlg);
        pluginRealm = classRealmManager.createPluginRealm(plugin, parent, null, foreignImports, toAetherArtifacts(pluginArtifacts));
        discoverPluginComponents(pluginRealm, plugin, pluginDescriptor);
    }
    pluginDescriptor.setClassRealm(pluginRealm);
    pluginDescriptor.setArtifacts(pluginArtifacts);
}"
maven,remotes/origin/bugs-dot-jar_MNG-5742_6ab41ee8,Major,maven-core/src/main/java/org/apache/maven/plugin/internal/DefaultMavenPluginManager.java,804,925,"public ExtensionRealmCache.CacheRecord setupExtensionsRealm(MavenProject project, Plugin plugin, RepositorySystemSession session) throws PluginManagerException {
    @SuppressWarnings(""unchecked"")
    Map<String, ExtensionRealmCache.CacheRecord> pluginRealms = (Map<String, ExtensionRealmCache.CacheRecord>) project.getContextValue(KEY_EXTENSIONS_REALMS);
    if (pluginRealms == null) {
        pluginRealms = new HashMap<String, ExtensionRealmCache.CacheRecord>();
        project.setContextValue(KEY_EXTENSIONS_REALMS, pluginRealms);
    }
    final String pluginKey = plugin.getId();
    ExtensionRealmCache.CacheRecord extensionRecord = pluginRealms.get(pluginKey);
    if (extensionRecord != null) {
        return extensionRecord;
    }
    final List<RemoteRepository> repositories = project.getRemotePluginRepositories();
    // resolve plugin version as necessary
    if (plugin.getVersion() == null) {
        PluginVersionRequest versionRequest = new DefaultPluginVersionRequest(plugin, session, repositories);
        try {
            plugin.setVersion(pluginVersionResolver.resolve(versionRequest).getVersion());
        } catch (PluginVersionResolutionException e) {
            throw new PluginManagerException(plugin, e.getMessage(), e);
        }
    }
    // resolve plugin artifacts
    List<Artifact> artifacts;
    PluginArtifactsCache.Key cacheKey = pluginArtifactsCache.createKey(plugin, null, repositories, session);
    PluginArtifactsCache.CacheRecord recordArtifacts;
    try {
        recordArtifacts = pluginArtifactsCache.get(cacheKey);
    } catch (PluginResolutionException e) {
        throw new PluginManagerException(plugin, e.getMessage(), e);
    }
    if (recordArtifacts != null) {
        artifacts = recordArtifacts.artifacts;
    } else {
        try {
            artifacts = resolveExtensionArtifacts(plugin, repositories, session);
            recordArtifacts = pluginArtifactsCache.put(cacheKey, artifacts);
        } catch (PluginResolutionException e) {
            pluginArtifactsCache.put(cacheKey, e);
            pluginArtifactsCache.register(project, cacheKey, recordArtifacts);
            throw new PluginManagerException(plugin, e.getMessage(), e);
        }
    }
    pluginArtifactsCache.register(project, cacheKey, recordArtifacts);
    // create and cache extensions realms
    final ExtensionRealmCache.Key extensionKey = extensionRealmCache.createKey(artifacts);
    extensionRecord = extensionRealmCache.get(extensionKey);
    if (extensionRecord == null) {
        ClassRealm extensionRealm = classRealmManager.createExtensionRealm(plugin, toAetherArtifacts(artifacts));
        PluginDescriptor pluginDescriptor = null;
        if (plugin.isExtensions() && !artifacts.isEmpty()) {
            // these errors will reported during calculation of project build execution plan
            try {
                pluginDescriptor = extractPluginDescriptor(artifacts.get(0), plugin);
            } catch (PluginDescriptorParsingException e) {
            // ignore, see above
            } catch (InvalidPluginDescriptorException e) {
            // ignore, see above
            }
        }
        discoverPluginComponents(extensionRealm, plugin, pluginDescriptor);
        ExtensionDescriptor extensionDescriptor = null;
        Artifact extensionArtifact = artifacts.get(0);
        try {
            extensionDescriptor = extensionDescriptorBuilder.build(extensionArtifact.getFile());
        } catch (IOException e) {
            String message = ""Invalid extension descriptor for "" + plugin.getId() + "": "" + e.getMessage();
            if (logger.isDebugEnabled()) {
                logger.error(message, e);
            } else {
                logger.error(message);
            }
        }
        extensionRecord = extensionRealmCache.put(extensionKey, extensionRealm, extensionDescriptor, artifacts);
    }
    extensionRealmCache.register(project, extensionKey, extensionRecord);
    pluginRealms.put(pluginKey, extensionRecord);
    return extensionRecord;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-128_7e1000dd,Major,wicket/src/main/java/wicket/Session.java,1013,1056,"/**
 *  Adds or replaces the attribute with the given name and value.
 *
 *  @param name
 *             The name of the attribute
 *  @param value
 *             The value of the attribute
 */
protected final void setAttribute(String name, Object value) {
    RequestCycle cycle = RequestCycle.get();
    if (cycle == null) {
        throw new WicketRuntimeException(""Can not set the attribute. No RequestCycle available"");
    }
    ISessionStore store = getSessionStore();
    Request request = cycle.getRequest();
    // extra check on session binding event
    if (value == this) {
        Object current = store.getAttribute(request, name);
        if (current == null) {
            String id = store.getSessionId(request, false);
            if (id != null) {
                // this is a new instance. wherever it came from, bind the
                // session now
                store.bind(request, (Session) value);
            }
        }
    }
    String valueTypeName = (value != null ? value.getClass().getName() : ""null"");
    try {
        final ByteArrayOutputStream out = new ByteArrayOutputStream();
        new ObjectOutputStream(out).writeObject(value);
        log.debug(""Stored attribute "" + name + ""{ "" + valueTypeName + ""} with size: "" + Bytes.bytes(out.size()));
    } catch (Exception e) {
        throw new WicketRuntimeException(""Internal error cloning object. Make sure all dependent objects implement Serializable. Class: "" + valueTypeName, e);
    }
    // Set the actual attribute
    store.setAttribute(request, name, value);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1619_b154d12f,Major,wicket/src/main/java/org/apache/wicket/markup/html/navigation/paging/PagingNavigation.java,339,351,"/**
 *  Factory method for creating page number links.
 *
 *  @param id
 *             the component id.
 *  @param pageable
 *             the pageable for the link
 *  @param pageIndex
 *             the page index the link points to
 *  @return the page navigation link.
 */
protected Link<?> newPagingNavigationLink(String id, IPageable pageable, int pageIndex) {
    return new PagingNavigationLink<Void>(id, pageable, pageIndex) {

        private static final long serialVersionUID = 1L;

        @Override
        public boolean isEnabled() {
            return PagingNavigation.this.isEnabled() && PagingNavigation.this.isEnableAllowed();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1619_b154d12f,Major,wicket/src/main/java/org/apache/wicket/markup/html/navigation/paging/PagingNavigation.java,345,349,"@Override
public boolean isEnabled() {
    return PagingNavigation.this.isEnabled() && PagingNavigation.this.isEnableAllowed();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1619_b154d12f,Major,wicket/src/main/java/org/apache/wicket/markup/html/navigation/paging/PagingNavigator.java,113,125,"/**
 *  Create a new increment link. May be subclassed to make use of specialized links, e.g. Ajaxian
 *  links.
 *
 *  @param id
 *             the link id
 *  @param pageable
 *             the pageable to control
 *  @param increment
 *             the increment
 *  @return the increment link
 */
protected Link<?> newPagingNavigationIncrementLink(String id, IPageable pageable, int increment) {
    return new PagingNavigationIncrementLink<Void>(id, pageable, increment) {

        private static final long serialVersionUID = 1L;

        @Override
        public boolean isEnabled() {
            return PagingNavigator.this.isEnabled() && PagingNavigator.this.isEnableAllowed();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1619_b154d12f,Major,wicket/src/main/java/org/apache/wicket/markup/html/navigation/paging/PagingNavigator.java,119,123,"@Override
public boolean isEnabled() {
    return PagingNavigator.this.isEnabled() && PagingNavigator.this.isEnableAllowed();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1619_b154d12f,Major,wicket/src/main/java/org/apache/wicket/markup/html/navigation/paging/PagingNavigator.java,139,151,"/**
 *  Create a new pagenumber link. May be subclassed to make use of specialized links, e.g.
 *  Ajaxian links.
 *
 *  @param id
 *             the link id
 *  @param pageable
 *             the pageable to control
 *  @param pageNumber
 *             the page to jump to
 *  @return the pagenumber link
 */
protected Link<?> newPagingNavigationLink(String id, IPageable pageable, int pageNumber) {
    return new PagingNavigationLink<Void>(id, pageable, pageNumber) {

        private static final long serialVersionUID = 1L;

        @Override
        public boolean isEnabled() {
            return PagingNavigator.this.isEnabled() && PagingNavigator.this.isEnableAllowed();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1619_b154d12f,Major,wicket/src/main/java/org/apache/wicket/markup/html/navigation/paging/PagingNavigator.java,145,149,"@Override
public boolean isEnabled() {
    return PagingNavigator.this.isEnabled() && PagingNavigator.this.isEnableAllowed();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1619_b154d12f,Major,wicket/src/main/java/org/apache/wicket/markup/html/navigation/paging/PagingNavigator.java,162,175,"/**
 *  Create a new PagingNavigation. May be subclassed to make us of specialized PagingNavigation.
 *
 *  @param pageable
 *             the pageable component
 *  @param labelProvider
 *             The label provider for the link text.
 *  @return the navigation object
 */
protected PagingNavigation newNavigation(final IPageable pageable, final IPagingLabelProvider labelProvider) {
    return new PagingNavigation(""navigation"", pageable, labelProvider) {

        private static final long serialVersionUID = 1L;

        @Override
        public boolean isEnabled() {
            return PagingNavigator.this.isEnabled() && PagingNavigator.this.isEnableAllowed();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1619_b154d12f,Major,wicket/src/main/java/org/apache/wicket/markup/html/navigation/paging/PagingNavigator.java,169,173,"@Override
public boolean isEnabled() {
    return PagingNavigator.this.isEnabled() && PagingNavigator.this.isEnableAllowed();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1677_01a3dd66,Major,wicket/src/main/java/org/apache/wicket/ajax/form/AjaxFormChoiceComponentUpdatingBehavior.java,59,82,"/**
 *  @see org.apache.wicket.ajax.AbstractDefaultAjaxBehavior#renderHead(org.apache.wicket.markup.html.IHeaderResponse)
 */
@Override
public void renderHead(IHeaderResponse response) {
    super.renderHead(response);
    AppendingStringBuffer asb = new AppendingStringBuffer();
    asb.append(""function attachChoiceHandlers(markupId, callbackScript) {\n"");
    asb.append("" var inputNodes = wicketGet(markupId).getElementsByTagName('input');\n"");
    asb.append("" for (var i = 0 ; i < inputNodes.length ; i ++) {\n"");
    asb.append("" var inputNode = inputNodes[i];\n"");
    asb.append("" if (!inputNode.type) continue;\n"");
    asb.append("" var inputType = inputNode.type.toLowerCase();\n"");
    asb.append("" if (inputType == 'checkbox' || inputType == 'radio') {\n"");
    asb.append("" Wicket.Event.add(inputNode, 'click', callbackScript);\n"");
    asb.append("" }\n"");
    asb.append("" }\n"");
    asb.append(""}\n"");
    response.renderJavascript(asb, ""attachChoice"");
    response.renderOnLoadJavascript(""attachChoiceHandlers('"" + getComponent().getMarkupId() + ""', function() {"" + getEventHandler() + ""});"");
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1677_01a3dd66,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/Check.java,121,215,"/**
 *  @see Component#onComponentTag(ComponentTag)
 *  @param tag
 *             the abstraction representing html tag of this component
 */
@Override
protected void onComponentTag(final ComponentTag tag) {
    // Default handling for component tag
    super.onComponentTag(tag);
    // must be attached to <input type=""checkbox"" .../> tag
    checkComponentTag(tag, ""input"");
    checkComponentTagAttribute(tag, ""type"", ""checkbox"");
    CheckGroup<?> group = this.group;
    if (group == null) {
        group = findParent(CheckGroup.class);
        if (group == null) {
            throw new WicketRuntimeException(""Check component ["" + getPath() + ""] cannot find its parent CheckGroup"");
        }
    }
    final String uuid = getValue();
    // assign name and value
    tag.put(""name"", group.getInputName());
    tag.put(""value"", uuid);
    // check if the model collection of the group contains the model object.
    // if it does check the check box.
    Collection<?> collection = (Collection<?>) group.getDefaultModelObject();
    // check for npe in group's model object
    if (collection == null) {
        throw new WicketRuntimeException(""CheckGroup ["" + group.getPath() + ""] contains a null model object, must be an object of type java.util.Collection"");
    }
    if (group.hasRawInput()) {
        final String[] input = group.getInputAsArray();
        if (input != null) {
            for (int i = 0; i < input.length; i++) {
                if (uuid.equals(input[i])) {
                    tag.put(""checked"", ""checked"");
                }
            }
        }
    } else if (collection.contains(getDefaultModelObject())) {
        tag.put(""checked"", ""checked"");
    }
    if (group.wantOnSelectionChangedNotifications()) {
        // url that points to this components IOnChangeListener method
        CharSequence url = group.urlFor(IOnChangeListener.INTERFACE);
        Form<?> form = group.findParent(Form.class);
        if (form != null) {
            RequestContext rc = RequestContext.get();
            if (rc.isPortletRequest()) {
                // restore url back to real wicket path as its going to be interpreted by the
                // form itself
                url = ((PortletRequestContext) rc).getLastEncodedPath();
            }
            tag.put(""onclick"", form.getJsForInterfaceUrl(url));
        } else {
            // TODO: following doesn't work with portlets, should be posted to a dynamic hidden
            // form
            // with an ActionURL or something
            // NOTE: do not encode the url as that would give invalid
            // JavaScript
            tag.put(""onclick"", ""window.location.href='"" + url + (url.toString().indexOf('?') > -1 ? ""&amp;"" : ""?"") + group.getInputName() + ""=' + this.value;"");
        }
    }
    if (!isActionAuthorized(ENABLE) || !isEnabled() || !group.isEnabled()) {
        tag.put(ATTR_DISABLED, ATTR_DISABLED);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1677_01a3dd66,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/CheckBoxMultipleChoice.java,371,457,"/**
 *  @see org.apache.wicket.Component#onComponentTagBody(org.apache.wicket.markup.MarkupStream,
 *       org.apache.wicket.markup.ComponentTag)
 */
@Override
protected final void onComponentTagBody(final MarkupStream markupStream, final ComponentTag openTag) {
    // Iterate through choices
    final List<? extends T> choices = getChoices();
    // Buffer to hold generated body
    final AppendingStringBuffer buffer = new AppendingStringBuffer(70 * (choices.size() + 1));
    // Value of this choice
    final String selected = getValue();
    // Loop through choices
    for (int index = 0; index < choices.size(); index++) {
        // Get next choice
        final T choice = choices.get(index);
        Object displayValue = getChoiceRenderer().getDisplayValue(choice);
        Class<?> objectClass = displayValue == null ? null : displayValue.getClass();
        // Get label for choice
        String label = """";
        if (objectClass != null && objectClass != String.class) {
            IConverter converter = getConverter(objectClass);
            label = converter.convertToString(displayValue, getLocale());
        } else if (displayValue != null) {
            label = displayValue.toString();
        }
        // location in the page markup!
        if (label != null) {
            // Append option suffix
            buffer.append(getPrefix());
            String id = getChoiceRenderer().getIdValue(choice, index);
            final String idAttr = getInputName() + ""_"" + id;
            // Add checkbox element
            buffer.append(""<input name=\"""").append(getInputName()).append(""\"""").append("" type=\""checkbox\"""").append((isSelected(choice, index, selected) ? "" checked=\""checked\"""" : """")).append((isEnabled() ? """" : "" disabled=\""disabled\"""")).append("" value=\"""").append(id).append(""\"" id=\"""").append(idAttr).append(""\""/>"");
            // Add label for checkbox
            String display = label;
            if (localizeDisplayValues()) {
                display = getLocalizer().getString(label, this, label);
            }
            CharSequence escaped;
            if (getEscapeModelStrings()) {
                escaped = Strings.escapeMarkup(display, false, true);
            } else {
                escaped = display;
            }
            buffer.append(""<label for=\"""");
            buffer.append(idAttr);
            buffer.append(""\"">"").append(escaped).append(""</label>"");
            // Append option suffix
            buffer.append(getSuffix());
        }
    }
    // Replace body
    replaceComponentTagBody(markupStream, openTag, buffer);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1677_01a3dd66,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/Radio.java,118,198,"/**
 *  @see Component#onComponentTag(ComponentTag)
 *  @param tag
 *             the abstraction representing html tag of this component
 */
@Override
protected void onComponentTag(final ComponentTag tag) {
    // Default handling for component tag
    super.onComponentTag(tag);
    // must be attached to <input type=""radio"" .../> tag
    checkComponentTag(tag, ""input"");
    checkComponentTagAttribute(tag, ""type"", ""radio"");
    final String value = getValue();
    RadioGroup<?> group = this.group;
    if (group == null) {
        group = findParent(RadioGroup.class);
        if (group == null) {
            throw new WicketRuntimeException(""Radio component ["" + getPath() + ""] cannot find its parent RadioGroup. All Radio components must be a child of or below in the hierarchy of a RadioGroup component."");
        }
    }
    // assign name and value
    tag.put(""name"", group.getInputName());
    tag.put(""value"", value);
    // checked attribute, first check if there was a raw input on the group.
    if (group.hasRawInput()) {
        String rawInput = group.getRawInput();
        if (rawInput != null && rawInput.equals(value)) {
            tag.put(""checked"", ""checked"");
        }
    } else if (Objects.equal(group.getDefaultModelObject(), getDefaultModelObject())) {
        tag.put(""checked"", ""checked"");
    }
    if (group.wantOnSelectionChangedNotifications()) {
        // url that points to this components IOnChangeListener method
        CharSequence url = group.urlFor(IOnChangeListener.INTERFACE);
        Form<?> form = group.findParent(Form.class);
        if (form != null) {
            RequestContext rc = RequestContext.get();
            if (rc.isPortletRequest()) {
                // restore url back to real wicket path as its going to be interpreted by the
                // form itself
                url = ((PortletRequestContext) rc).getLastEncodedPath();
            }
            tag.put(""onclick"", form.getJsForInterfaceUrl(url));
        } else {
            // TODO: following doesn't work with portlets, should be posted to a dynamic hidden
            // form
            // with an ActionURL or something
            // NOTE: do not encode the url as that would give invalid
            // JavaScript
            tag.put(""onclick"", ""window.location.href='"" + url + (url.toString().indexOf('?') > -1 ? ""&amp;"" : ""?"") + group.getInputName() + ""=' + this.value;"");
        }
    }
    if (!isEnabledInHierarchy()) {
        tag.put(ATTR_DISABLED, ATTR_DISABLED);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1677_01a3dd66,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/RadioChoice.java,408,533,"/**
 *  @see org.apache.wicket.Component#onComponentTagBody(MarkupStream, ComponentTag)
 */
@Override
protected final void onComponentTagBody(final MarkupStream markupStream, final ComponentTag openTag) {
    // Iterate through choices
    final List<? extends T> choices = getChoices();
    // Buffer to hold generated body
    final AppendingStringBuffer buffer = new AppendingStringBuffer((choices.size() + 1) * 70);
    // The selected value
    final String selected = getValue();
    // Loop through choices
    for (int index = 0; index < choices.size(); index++) {
        // Get next choice
        final T choice = choices.get(index);
        Object displayValue = getChoiceRenderer().getDisplayValue(choice);
        Class<?> objectClass = (displayValue == null ? null : displayValue.getClass());
        // Get label for choice
        String label = """";
        if (objectClass != null && objectClass != String.class) {
            final IConverter converter = getConverter(objectClass);
            label = converter.convertToString(displayValue, getLocale());
        } else if (displayValue != null) {
            label = displayValue.toString();
        }
        // location in the page markup!
        if (label != null) {
            // Append option suffix
            buffer.append(getPrefix());
            String id = getChoiceRenderer().getIdValue(choice, index);
            final String idAttr = getMarkupId() + ""_"" + id;
            boolean enabled = isEnabledInHierarchy() && !isDisabled(choice, index, selected);
            // Add radio tag
            buffer.append(""<input name=\"""").append(getInputName()).append(""\"""").append("" type=\""radio\"""").append((isSelected(choice, index, selected) ? "" checked=\""checked\"""" : """")).append((enabled ? """" : "" disabled=\""disabled\"""")).append("" value=\"""").append(id).append(""\"" id=\"""").append(idAttr).append(""\"""");
            // when the option is clicked?
            if (wantOnSelectionChangedNotifications()) {
                CharSequence url = urlFor(IOnChangeListener.INTERFACE);
                Form<?> form = findParent(Form.class);
                if (form != null) {
                    RequestContext rc = RequestContext.get();
                    if (rc.isPortletRequest()) {
                        // restore url back to real wicket path as its going to be interpreted
                        // by the form itself
                        url = ((PortletRequestContext) rc).getLastEncodedPath();
                    }
                    buffer.append("" onclick=\"""").append(form.getJsForInterfaceUrl(url)).append("";\"""");
                } else {
                    // TODO: following doesn't work with portlets, should be posted to a dynamic
                    // hidden form
                    // with an ActionURL or something
                    // NOTE: do not encode the url as that would give
                    // invalid JavaScript
                    buffer.append("" onclick=\""window.location.href='"").append(url).append((url.toString().indexOf('?') > -1 ? ""&amp;"" : ""?"") + getInputName()).append(""="").append(id).append(""';\"""");
                }
            }
            buffer.append(""/>"");
            // Add label for radio button
            String display = label;
            if (localizeDisplayValues()) {
                display = getLocalizer().getString(label, this, label);
            }
            final CharSequence escaped;
            if (getEscapeModelStrings()) {
                escaped = Strings.escapeMarkup(display, false, true);
            } else {
                escaped = display;
            }
            buffer.append(""<label for=\"""").append(idAttr).append(""\"">"").append(escaped).append(""</label>"");
            // Append option suffix
            buffer.append(getSuffix());
        }
    }
    // Replace body
    replaceComponentTagBody(markupStream, openTag, buffer);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-16_3431e60d,Major,wicket/src/main/java/wicket/protocol/http/request/AbstractWebRequestCodingStrategy.java,290,397,"/**
 *  Encode a page class target.
 *
 *  If you override this method to behave different then also
 *  {@link #addBookmarkablePageParameters(Request, RequestParameters)} should
 *  be overridden to by in sync with that behaviour.
 *
 *  @param requestCycle
 *             the current request cycle
 *  @param requestTarget
 *             the target to encode
 *  @return the encoded url
 */
protected CharSequence encode(RequestCycle requestCycle, IBookmarkablePageRequestTarget requestTarget) {
    // Begin encoding URL
    final AppendingStringBuffer url = new AppendingStringBuffer(64);
    url.append(urlPrefix(requestCycle));
    // Get page Class
    final Class pageClass = requestTarget.getPageClass();
    final Application application = Application.get();
    // Find pagemap name
    String pageMapName = requestTarget.getPageMapName();
    if (pageMapName == null) {
        IRequestTarget currentTarget = requestCycle.getRequestTarget();
        if (currentTarget instanceof IPageRequestTarget) {
            Page currentPage = ((IPageRequestTarget) currentTarget).getPage();
            final PageMap pageMap = currentPage.getPageMap();
            if (pageMap.isDefault()) {
                pageMapName = """";
            } else {
                pageMapName = pageMap.getName();
            }
        } else {
            pageMapName = """";
        }
    }
    boolean firstParameter = true;
    if (!application.getHomePage().equals(pageClass) || !"""".equals(pageMapName) || requestTarget instanceof BookmarkableListenerInterfaceRequestTarget) {
        firstParameter = false;
        url.append('?');
        url.append(WebRequestCodingStrategy.BOOKMARKABLE_PAGE_PARAMETER_NAME);
        url.append('=');
        // Add <page-map-name>:<bookmarkable-page-class>
        url.append(pageMapName + Component.PATH_SEPARATOR + pageClass.getName());
    }
    // Is it a bookmarkable interface listener?
    if (requestTarget instanceof BookmarkableListenerInterfaceRequestTarget) {
        BookmarkableListenerInterfaceRequestTarget listenerTarget = (BookmarkableListenerInterfaceRequestTarget) requestTarget;
        if (firstParameter == true) {
            url.append(""?"");
        } else {
            url.append(""&"");
        }
        firstParameter = false;
        url.append(INTERFACE_PARAMETER_NAME);
        url.append(""="");
        url.append(Component.PATH_SEPARATOR);
        url.append(listenerTarget.getComponentPath());
        url.append(Component.PATH_SEPARATOR);
        url.append(Component.PATH_SEPARATOR);
        url.append(listenerTarget.getInterfaceName());
    }
    // Get page parameters
    final PageParameters parameters = requestTarget.getPageParameters();
    if (parameters != null) {
        for (Object element : parameters.keySet()) {
            final String key = (String) element;
            final String value = parameters.getString(key);
            if (value != null) {
                String escapedValue = value;
                try {
                    escapedValue = URLEncoder.encode(escapedValue, application.getRequestCycleSettings().getResponseRequestEncoding());
                } catch (UnsupportedEncodingException ex) {
                    log.error(ex.getMessage(), ex);
                }
                if (!firstParameter) {
                    url.append('&');
                } else {
                    firstParameter = false;
                    url.append('?');
                }
                url.append(key);
                url.append('=');
                url.append(escapedValue);
            }
        }
    }
    return requestCycle.getOriginalResponse().encodeURL(url);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-16_6c5083b4,Major,wicket/src/main/java/wicket/protocol/http/request/WebRequestCodingStrategy.java,521,605,"/**
 *  Encode a page class target.
 *
 *  If you override this method to behave different then also
 *  {@link #addBookmarkablePageParameters(Request, RequestParameters)} should
 *  be overridden to by in sync with that behaviour.
 *
 *  @param requestCycle
 *             the current request cycle
 *  @param requestTarget
 *             the target to encode
 *  @return the encoded url
 */
protected CharSequence encode(RequestCycle requestCycle, IBookmarkablePageRequestTarget requestTarget) {
    // Begin encoding URL
    final AppendingStringBuffer url = new AppendingStringBuffer(64);
    url.append(urlPrefix(requestCycle));
    // Get page Class
    final Class pageClass = requestTarget.getPageClass();
    final Application application = Application.get();
    // Find pagemap name
    String pageMapName = requestTarget.getPageMapName();
    if (pageMapName == null) {
        IRequestTarget currentTarget = requestCycle.getRequestTarget();
        if (currentTarget instanceof IPageRequestTarget) {
            Page currentPage = ((IPageRequestTarget) currentTarget).getPage();
            final PageMap pageMap = currentPage.getPageMap();
            if (pageMap.isDefault()) {
                pageMapName = """";
            } else {
                pageMapName = pageMap.getName();
            }
        } else {
            pageMapName = """";
        }
    }
    boolean firstParameter = true;
    if (!application.getHomePage().equals(pageClass) || !"""".equals(pageMapName)) {
        firstParameter = false;
        url.append('?');
        url.append(WebRequestCodingStrategy.BOOKMARKABLE_PAGE_PARAMETER_NAME);
        url.append('=');
        // Add <page-map-name>:<bookmarkable-page-class>
        url.append(pageMapName + Component.PATH_SEPARATOR + pageClass.getName());
    }
    // Get page parameters
    final PageParameters parameters = requestTarget.getPageParameters();
    if (parameters != null) {
        for (final Iterator iterator = parameters.keySet().iterator(); iterator.hasNext(); ) {
            final String key = (String) iterator.next();
            final String value = parameters.getString(key);
            if (value != null) {
                String escapedValue = value;
                try {
                    escapedValue = URLEncoder.encode(escapedValue, application.getRequestCycleSettings().getResponseRequestEncoding());
                } catch (UnsupportedEncodingException ex) {
                    log.error(ex.getMessage(), ex);
                }
                if (!firstParameter) {
                    url.append('&');
                } else {
                    firstParameter = false;
                    url.append('?');
                }
                url.append(key);
                url.append('=');
                url.append(escapedValue);
            }
        }
    }
    return requestCycle.getOriginalResponse().encodeURL(url);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1718_bb7f9cf5,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/WebPage.java,213,223,"/**
 *  @see org.apache.wicket.Component#onAfterRender()
 */
@Override
protected void onAfterRender() {
    // only in development mode validate the headers
    if (getApplication().usesDevelopmentConfig()) {
        validateHeaders();
    }
    super.onAfterRender();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,169,200,"/**
 *  Adds a child component to this container.
 *  <p>
 *  Be careful when overriding this method, if not implemented properly it
 *  may lead to a java component hierarchy which no longer matches the
 *  template hierarchy, which in turn will lead to an error.
 *
 *  @param child
 *             The child
 *
 *  @throws IllegalArgumentException
 *              Thrown if a child with the same id is replaced by the add
 *              operation.
 *  @return This
 */
final MarkupContainer add(final Component<?> child) {
    if (child == null) {
        throw new IllegalArgumentException(""argument child may not be null"");
    }
    if (log.isDebugEnabled()) {
        log.debug(""Add "" + child.getId() + "" to component "" + this.getClass().getName() + "" with path "" + getPath());
    }
    // Add to map
    addedComponent(child);
    Component replaced = put(child);
    child.setFlag(FLAG_REMOVED_FROM_PARENT, false);
    if (replaced != null) {
        replaced.setFlag(FLAG_REMOVED_FROM_PARENT, true);
        removedComponent(replaced);
        // The position of the associated markup remains the same
        child.markupIndex = replaced.markupIndex;
        // The generated markup id remains the same
        String replacedId = (replaced.hasMarkupIdMetaData()) ? replaced.getMarkupId() : null;
        child.setMarkupIdMetaData(replacedId);
    }
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,232,267,"/**
 *  This method allows a component to be added by an auto-resolver such as
 *  AutoComponentResolver or AutoLinkResolver. While the component is being
 *  added, the component's FLAG_AUTO boolean is set. The isAuto() method of
 *  Component returns true if a component or any of its parents has this bit
 *  set. When a component is added via autoAdd(), the logic in Page that
 *  normally (a) checks for modifications during the rendering process, and
 *  (b) versions components, is bypassed if Component.isAuto() returns true.
 *  <p>
 *  The result of all this is that components added with autoAdd() are free
 *  from versioning and can add their own children without the usual
 *  exception that would normally be thrown when the component hierarchy is
 *  modified during rendering.
 *
 *  @param component
 *             The component to add
 */
// final void autoAdd(final Component component)
// {
// component.setAuto(true);
// add(component);
// }
/**
 *  @param component
 *             The component to check
 *  @param recurse
 *             True if all descendents should be considered
 *  @return True if the component is contained in this container
 */
public final boolean contains(final Component component, final boolean recurse) {
    if (component == null) {
        throw new IllegalArgumentException(""argument component may not be null"");
    }
    if (recurse) {
        // Start at component and continue while we're not out of parents
        for (Component current = component; current != null; ) {
            // Get parent
            final MarkupContainer parent = current.getParent();
            // recursively contained by this container
            if (parent == this) {
                // Found it!
                return true;
            }
            // Move up the chain to the next parent
            current = parent;
        }
        // Failed to find this container in component's ancestry
        return false;
    } else {
        // Is the component contained in this container?
        return component.getParent() == this;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,276,315,"/**
 *  Get a child component by looking it up with the given path.
 *
 *  @param path
 *             Path to component
 *  @return The component at the path
 */
@Override
public final Component get(final String path) {
    // Reference to this container
    if (path == null || path.trim().equals("""")) {
        return this;
    }
    // Get child's id, if any
    final String id = Strings.firstPathComponent(path, Component.PATH_SEPARATOR);
    // Get child by id
    Component child = children_get(id);
    // optimization.
    if ((child == null) && isTransparentResolver() && (getParent() != null)) {
        // IComponentResolver if they want to be transparent.
        if (path.startsWith(""_"") == false) {
            child = getParent().get(path);
        }
    }
    // Found child?
    final String path2 = Strings.afterFirstPathComponent(path, Component.PATH_SEPARATOR);
    if (child != null) {
        // Recurse on latter part of path
        return child.get(path2);
    }
    return child;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,344,354,"/**
 *  THIS METHOD IS NOT PART OF THE WICKET PUBLIC API. DO NOT USE IT.
 *
 *  Adds a child component to this container.
 *
 *  @param child
 *             The child
 *  @throws IllegalArgumentException
 *              Thrown if a child with the same id is replaced by the add
 *              operation.
 */
public void internalAdd(final Component child) {
    if (log.isDebugEnabled()) {
        log.debug(""internalAdd "" + child.getId() + "" to "" + this);
    }
    // Add to map
    addedComponent(child);
    put(child);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,362,397,"/**
 *  THIS METHOD IS NOT PART OF THE WICKET PUBLIC API. DO NOT CALL OR
 *  OVERRIDE.
 *
 *  Called when a request begins.
 */
@Override
public void internalAttach() {
    // Handle begin request for the container itself
    try {
        super.internalAttach();
        // Loop through child components
        final int size = children_size();
        for (int i = 0; i < size; i++) {
            // Get next child
            final Component child = children_get(i);
            // Ignore feedback as that was done in Page
            if (!(child instanceof IFeedback)) {
                // Call begin request on the child
                child.internalAttach();
            }
        }
    } catch (RuntimeException ex) {
        if (ex instanceof WicketRuntimeException) {
            throw ex;
        } else {
            throw new WicketRuntimeException(""Error attaching this container for rendering: "" + this, ex);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,405,417,"/**
 *  THIS METHOD IS NOT PART OF THE WICKET PUBLIC API. DO NOT CALL OR
 *  OVERRIDE.
 *
 *  Called when a request ends.
 */
@Override
public void internalDetach() {
    // Handle end request for the container itself
    super.internalDetach();
    // Loop through child components
    for (Component child : this) {
        // Call end request on the child
        child.internalDetach();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,423,444,"/**
 *  @return Iterator that iterates through children in the order they were
 *          added
 */
public final Iterator<Component> iterator() {
    return new Iterator<Component>() {

        int index = 0;

        public boolean hasNext() {
            return index < children_size();
        }

        public Component next() {
            return children_get(index++);
        }

        public void remove() {
            removedComponent(children_remove(--index));
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,434,437,"public Component next() {
    return children_get(index++);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,452,473,"/**
 *  @param comparator
 *             The comparator
 *  @return Iterator that iterates over children in the order specified by
 *          comparator
 */
public final Iterator<Component> iterator(Comparator<Component> comparator) {
    final List<Component> sorted;
    if (children == null) {
        sorted = Collections.emptyList();
    } else {
        if (children instanceof Component) {
            sorted = new ArrayList<Component>(1);
            sorted.add((Component) children);
        } else {
            sorted = Arrays.asList((Component[]) children);
        }
    }
    Collections.sort(sorted, comparator);
    return sorted.iterator();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,479,491,"/**
 *  @param component
 *             Component to remove from this container
 */
public void remove(final Component component) {
    if (component == null) {
        throw new IllegalArgumentException(""argument component may not be null"");
    }
    if (children_remove(component) != null) {
        component.setFlag(FLAG_REMOVED_FROM_PARENT, true);
        removedComponent(component);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,499,516,"/**
 *  Removes the given component
 *
 *  @param id
 *             The id of the component to remove
 */
public final void remove(final String id) {
    if (id == null) {
        throw new IllegalArgumentException(""argument id may not be null"");
    }
    final Component component = get(id);
    if (component != null) {
        remove(component);
    } else {
        throw new WicketRuntimeException(""Unable to find a component with id '"" + id + ""' to remove"");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,666,699,"/**
 *  @param detailed
 *             True if a detailed string is desired
 *  @return String representation of this container
 */
@Override
public String toString(final boolean detailed) {
    final StringBuffer buffer = new StringBuffer();
    buffer.append(""[MarkupContainer "");
    buffer.append(super.toString(true));
    if (detailed) {
        if (getMarkupStream() != null) {
            buffer.append("", markupStream = "" + getMarkupStream());
        }
        if (children_size() != 0) {
            buffer.append("", children = "");
            // Loop through child components
            final int size = children_size();
            for (int i = 0; i < size; i++) {
                // Get next child
                final Component child = children_get(i);
                if (i != 0) {
                    buffer.append(' ');
                }
                buffer.append(child.toString());
            }
        }
    }
    buffer.append(']');
    return buffer.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,712,757,"/**
 *  Traverses all child components of the given class in this container,
 *  calling the visitor's visit method at each one.
 *
 *  @param clazz
 *             The class of child to visit, or null to visit all children
 *  @param visitor
 *             The visitor to call back to
 *  @return The return value from a visitor which halted the traversal, or
 *          null if the entire traversal occurred
 */
public final Object visitChildren(final Class clazz, final IVisitor visitor) {
    if (visitor == null) {
        throw new IllegalArgumentException(""argument visitor may not be null"");
    }
    // Iterate through children of this container
    for (int i = 0; i < children_size(); i++) {
        // Get next child component
        final Component child = children_get(i);
        Object value = null;
        // Is the child of the correct class (or was no class specified)?
        if (clazz == null || clazz.isInstance(child)) {
            // Call visitor
            value = visitor.component(child);
            // If visitor returns a non-null value, it halts the traversal
            if ((value != IVisitor.CONTINUE_TRAVERSAL) && (value != IVisitor.CONTINUE_TRAVERSAL_BUT_DONT_GO_DEEPER)) {
                return value;
            }
        }
        // If child is a container
        if ((child instanceof MarkupContainer) && (value != IVisitor.CONTINUE_TRAVERSAL_BUT_DONT_GO_DEEPER)) {
            // visit the children in the container
            value = ((MarkupContainer<?>) child).visitChildren(clazz, visitor);
            // If visitor returns a non-null value, it halts the traversal
            if ((value != IVisitor.CONTINUE_TRAVERSAL) && (value != IVisitor.CONTINUE_TRAVERSAL_BUT_DONT_GO_DEEPER)) {
                return value;
            }
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,779,800,"/**
 *  Get the markup stream for this component.
 *
 *  @return The markup stream for this component, or if it doesn't have one,
 *          the markup stream for the nearest parent which does have one
 */
@Override
protected final MarkupStream findMarkupStream() {
    // Start here
    MarkupContainer c = this;
    // Walk up hierarchy until markup found
    while (c.getMarkupStream() == null) {
        // Check parent
        c = c.getParent();
        // Are we at the top of the hierarchy?
        if (c == null) {
            // Failed to find markup stream
            throw new WicketRuntimeException(exceptionMessage(""No markup found""));
        }
    }
    return c.getMarkupStream();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,1028,1054,"/**
 *  @param child
 *             Child to add
 */
private final void children_add(final Component child) {
    if (this.children == null) {
        this.children = child;
    } else {
        // Get current list size
        final int size = children_size();
        // Create array that holds size + 1 elements
        final Component[] children = new Component[size + 1];
        // Loop through existing children copying them
        for (int i = 0; i < size; i++) {
            children[i] = children_get(i);
        }
        // Add new child to the end
        children[size] = child;
        // Save new children
        this.children = children;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,1056,1073,"private final Component<?> children_get(int index) {
    if (index == 0) {
        if (children instanceof Component) {
            return (Component) children;
        } else {
            return ((Component[]) children)[index];
        }
    } else {
        return ((Component[]) children)[index];
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,1075,1100,"private final Component children_get(final String id) {
    if (children instanceof Component) {
        final Component component = (Component) children;
        if (component.getId().equals(id)) {
            return component;
        }
    } else {
        if (children != null) {
            final Component[] components = (Component[]) children;
            for (Component element : components) {
                if (element.getId().equals(id)) {
                    return element;
                }
            }
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,1102,1126,"private final int children_indexOf(Component<?> child) {
    if (children instanceof Component) {
        if (((Component) children).getId().equals(child.getId())) {
            return 0;
        }
    } else {
        if (children != null) {
            final Component[] components = (Component[]) children;
            for (int i = 0; i < components.length; i++) {
                if (components[i].getId().equals(child.getId())) {
                    return i;
                }
            }
        }
    }
    return -1;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,1128,1136,"private final Component children_remove(Component<?> component) {
    int index = children_indexOf(component);
    if (index != -1) {
        return children_remove(index);
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,1138,1187,"private final Component children_remove(int index) {
    if (children instanceof Component) {
        if (index == 0) {
            final Component removed = (Component) children;
            this.children = null;
            return removed;
        } else {
            throw new IndexOutOfBoundsException();
        }
    } else {
        Component[] c = ((Component[]) children);
        final Component removed = c[index];
        if (c.length == 2) {
            if (index == 0) {
                this.children = c[1];
            } else if (index == 1) {
                this.children = c[0];
            } else {
                throw new IndexOutOfBoundsException();
            }
        } else {
            Component[] newChildren = new Component[c.length - 1];
            int j = 0;
            for (int i = 0; i < c.length; i++) {
                if (i != index) {
                    newChildren[j++] = c[i];
                }
            }
            this.children = newChildren;
        }
        return removed;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,1189,1211,"private final Component children_set(int index, Component child) {
    final Component replaced;
    if (index < children_size()) {
        if (children == null || children instanceof Component) {
            replaced = (Component) children;
            children = child;
        } else {
            final Component[] children = (Component[]) this.children;
            replaced = children[index];
            children[index] = child;
        }
    } else {
        throw new IndexOutOfBoundsException();
    }
    return replaced != child ? replaced : null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,1237,1249,"/**
 *  Ensure that there is space in childForId map for a new entry before
 *  adding it.
 *
 *  @param child
 *             The child to put into the map
 *  @return Any component that was replaced
 */
private final Component put(final Component<?> child) {
    int index = children_indexOf(child);
    if (index == -1) {
        children_add(child);
        return null;
    } else {
        return children_set(index, child);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/MarkupContainer.java,1406,1418,"/**
 *  @see wicket.Component#renderHead(wicket.markup.html.IHeaderResponse)
 */
@Override
public void renderHead(final IHeaderResponse response) {
    if (isVisible()) {
        super.renderHead(response);
        for (Component child : this) {
            child.renderHead(response);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-172_99e22ce4,Major,wicket/src/main/java/wicket/markup/repeater/RefreshingView.java,171,191,"/**
 *  @return iterator over item instances that exist as children of this view
 */
public Iterator<Item<T>> getItems() {
    final Iterator<Component> iterator = iterator();
    return new Iterator<Item<T>>() {

        public boolean hasNext() {
            return iterator.hasNext();
        }

        public Item<T> next() {
            return (Item<T>) iterator.next();
        }

        public void remove() {
            iterator.remove();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1886_5226978a,Major,wicket/src/main/java/org/apache/wicket/protocol/http/MockWebApplication.java,619,636,"/**
 *  Reset the request and the response back to a starting state and recreate the necessary wicket
 *  request, response and session objects. The request and response objects can be accessed and
 *  Initialized at this point.
 *
 *  @param isAjax
 *             indicates whether the request should be initialized as an ajax request (ajax
 *             header ""Wicket-Ajax"" is set)
 *  @return the constructed {@link WebRequestCycle}
 */
public WebRequestCycle setupRequestAndResponse(boolean isAjax) {
    servletRequest.initialize();
    servletResponse.initialize();
    servletRequest.setParameters(parametersForNextRequest);
    if (isAjax) {
        servletRequest.addHeader(""Wicket-Ajax"", ""Yes"");
    }
    parametersForNextRequest.clear();
    wicketRequest = application.newWebRequest(servletRequest);
    wicketResponse = application.newWebResponse(servletResponse);
    WebRequestCycle requestCycle = createRequestCycle();
    if (!initializeHttpSessionAsTemporary())
        application.getSessionStore().bind(wicketRequest, wicketSession);
    wicketResponse.setAjax(wicketRequest.isAjax());
    return requestCycle;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1897_8ee095bf,Major,wicket/src/main/java/org/apache/wicket/request/target/component/BookmarkableListenerInterfaceRequestTarget.java,113,162,"@Override
public void processEvents(RequestCycle requestCycle) {
    Page page = getPage();
    if (page == null) {
        page = Session.get().getPage(getPageMapName(), componentPath, -1);
        if (page != null) {
            setPage(page);
        } else if (page == null) {
            page = getPage(requestCycle);
        }
    }
    if (page == null) {
        throw new PageExpiredException(""Request cannot be processed. The target page does not exist anymore."");
    }
    final String pageRelativeComponentPath = Strings.afterFirstPathComponent(componentPath, Component.PATH_SEPARATOR);
    Component component = page.get(pageRelativeComponentPath);
    if (component == null) {
        // this is quite a hack to get components in repeater work.
        // But it still can fail if the repeater is a paging one or on every render
        // it will generate new index for the items...
        page.prepareForRender(false);
        component = page.get(pageRelativeComponentPath);
        if (component == null) {
            throw new WicketRuntimeException(""unable to find component with path "" + pageRelativeComponentPath + "" on stateless page "" + page + "" it could be that the component is inside a repeater make your component return false in getStatelessHint()"");
        }
    }
    RequestListenerInterface listenerInterface = RequestListenerInterface.forName(interfaceName);
    if (listenerInterface == null) {
        throw new WicketRuntimeException(""unable to find listener interface "" + interfaceName);
    }
    listenerInterface.invoke(page, component);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1897_8ee095bf,Major,wicket/src/main/java/org/apache/wicket/request/target/component/BookmarkableListenerInterfaceRequestTarget.java,184,187,"/**
 *  @return The component path.
 */
public String getComponentPath() {
    return componentPath;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1897_8ee095bf,Major,wicket/src/main/java/org/apache/wicket/request/target/component/BookmarkableListenerInterfaceRequestTarget.java,192,195,"/**
 *  @return The interface name
 */
public String getInterfaceName() {
    return interfaceName;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1931_986848f7,Major,wicket/src/main/java/org/apache/wicket/protocol/http/MockHttpServletRequest.java,488,517,"/**
 *  Returns an input stream if there has been added some uploaded files. Use
 *  {@link #addFile(String, File, String)} to add some uploaded files.
 *
 *  @return The input stream
 *  @throws IOException
 *              If an I/O related problem occurs
 */
public ServletInputStream getInputStream() throws IOException {
    if (uploadedFiles != null && uploadedFiles.size() > 0) {
        byte[] request = buildRequest();
        // Ok lets make an input stream to return
        final ByteArrayInputStream bais = new ByteArrayInputStream(request);
        return new ServletInputStream() {

            @Override
            public int read() {
                return bais.read();
            }
        };
    } else {
        return new ServletInputStream() {

            @Override
            public int read() {
                return -1;
            }
        };
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-1931_986848f7,Major,wicket/src/main/java/org/apache/wicket/protocol/http/MockHttpServletRequest.java,510,514,"@Override
public int read() {
    return -1;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2033_420ac965,Minor,wicket/src/main/java/org/apache/wicket/ajax/AjaxEventBehavior.java,102,113,"/**
 *  @see org.apache.wicket.behavior.AbstractAjaxBehavior#onComponentTag(org.apache.wicket.markup.ComponentTag)
 */
@Override
protected void onComponentTag(final ComponentTag tag) {
    super.onComponentTag(tag);
    // only add the event handler when the component is enabled.
    Component myComponent = getComponent();
    if (myComponent.isEnabledInHierarchy()) {
        tag.put(event, getEventHandler());
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2033_420ac965,Minor,wicket/src/main/java/org/apache/wicket/ajax/form/AjaxFormSubmitBehavior.java,176,180,"/**
 *  @see org.apache.wicket.ajax.AbstractDefaultAjaxBehavior#getPreconditionScript()
 */
@Override
protected CharSequence getPreconditionScript() {
    return ""return Wicket.$$(this)&amp;&amp;Wicket.$$('"" + getForm().getMarkupId() + ""')"";
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2057_e2d88568,Major,wicket/src/main/java/org/apache/wicket/ajax/calldecorator/AjaxPreprocessingCallDecorator.java,50,54,"/**
 *  @see org.apache.wicket.ajax.IAjaxCallDecorator#decorateScript(CharSequence)
 */
public CharSequence decorateScript(CharSequence script) {
    CharSequence s = (delegate == null) ? script : delegate.decorateScript(script);
    return preDecorateScript(s);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2057_e2d88568,Major,wicket/src/main/java/org/apache/wicket/ajax/calldecorator/AjaxPreprocessingCallDecorator.java,59,63,"/**
 *  @see org.apache.wicket.ajax.IAjaxCallDecorator#decorateOnSuccessScript(CharSequence)
 */
public CharSequence decorateOnSuccessScript(CharSequence script) {
    CharSequence s = (delegate == null) ? script : delegate.decorateOnSuccessScript(script);
    return preDecorateOnSuccessScript(s);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2057_e2d88568,Major,wicket/src/main/java/org/apache/wicket/ajax/calldecorator/AjaxPreprocessingCallDecorator.java,68,72,"/**
 *  @see org.apache.wicket.ajax.IAjaxCallDecorator#decorateOnFailureScript(CharSequence)
 */
public CharSequence decorateOnFailureScript(CharSequence script) {
    CharSequence s = (delegate == null) ? script : delegate.decorateOnFailureScript(script);
    return preDecorateOnFailureScript(s);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2060_0578d6ee,Major,wicket/src/main/java/org/apache/wicket/util/string/JavascriptStripper.java,76,209,"/**
 *  Removes javascript comments and whitespace from specified string.
 *
 *  @param original
 *             Source string
 *  @return String with removed comments and whitespace
 */
public static String stripCommentsAndWhitespace(String original) {
    // let's be optimistic
    AppendingStringBuffer result = new AppendingStringBuffer(original.length() / 2);
    int state = REGULAR_TEXT;
    for (int i = 0; i < original.length(); ++i) {
        char c = original.charAt(i);
        char next = (i < original.length() - 1) ? original.charAt(i + 1) : 0;
        char prev = (i > 0) ? original.charAt(i - 1) : 0;
        if (state == WHITE_SPACE) {
            if (Character.isWhitespace(next) == false) {
                state = REGULAR_TEXT;
            }
            continue;
        }
        if (state == REGULAR_TEXT) {
            if (c == '/' && next == '/' && prev != '\\') {
                state = LINE_COMMENT;
                continue;
            } else if (c == '/' && next == '*') {
                state = MULTILINE_COMMENT;
                ++i;
                continue;
            } else if (c == '/') {
                // This might be a divide operator, or it might be a regular expression.
                // Work out if it's a regular expression by finding the previous non-whitespace
                // char, which
                // will be either '=' or '('. If it's not, it's just a divide operator.
                int idx = result.length() - 1;
                while (idx > 0) {
                    char tmp = result.charAt(idx);
                    if (Character.isWhitespace(tmp)) {
                        idx--;
                        continue;
                    }
                    if (tmp == '=' || tmp == '(' || tmp == '{' || tmp == ':' || tmp == ',' || tmp == '[') {
                        state = REG_EXP;
                        break;
                    }
                    break;
                }
            } else if (Character.isWhitespace(c) && Character.isWhitespace(next)) {
                // ignore all whitespace characters after this one
                state = WHITE_SPACE;
                c = '\n';
            } else if (c == '\'') {
                state = STRING_SINGLE_QUOTE;
            } else if (c == '""') {
                state = STRING_DOUBLE_QUOTES;
            }
            result.append(c);
            continue;
        }
        if (state == LINE_COMMENT) {
            if (c == '\n' || c == '\r') {
                state = REGULAR_TEXT;
                continue;
            }
        }
        if (state == MULTILINE_COMMENT) {
            if (c == '*' && next == '/') {
                state = REGULAR_TEXT;
                ++i;
                continue;
            }
        }
        if (state == STRING_SINGLE_QUOTE) {
            // to leave a string expression we need even (or zero) number of backslashes
            int count = getPrevCount(original, i, '\\');
            if (c == '\'' && count % 2 == 0) {
                state = REGULAR_TEXT;
            }
            result.append(c);
            continue;
        }
        if (state == STRING_DOUBLE_QUOTES) {
            // to leave a string expression we need even (or zero) number of backslashes
            int count = getPrevCount(original, i, '\\');
            if (c == '""' && count % 2 == 0) {
                state = REGULAR_TEXT;
            }
            result.append(c);
            continue;
        }
        if (state == REG_EXP) {
            // to leave regular expression we need even (or zero) number of backslashes
            int count = getPrevCount(original, i, '\\');
            if (c == '/' && count % 2 == 0) {
                state = REGULAR_TEXT;
            }
            result.append(c);
            continue;
        }
    }
    return result.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2065_9da430fb,Major,wicket/src/main/java/org/apache/wicket/request/target/coding/AbstractRequestTargetUrlCodingStrategy.java,111,122,"private void appendValue(AppendingStringBuffer url, String key, String value) {
    String escapedValue = urlEncodePathComponent(value);
    if (!Strings.isEmpty(escapedValue)) {
        if (!url.endsWith(""/"")) {
            url.append(""/"");
        }
        url.append(key).append(""/"").append(escapedValue).append(""/"");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2065_9da430fb,Major,wicket/src/main/java/org/apache/wicket/request/target/coding/IndexedHybridUrlCodingStrategy.java,48,81,"protected void appendParameters(AppendingStringBuffer url, Map parameters) {
    int i = 0;
    while (parameters.containsKey(String.valueOf(i))) {
        String value = (String) parameters.get(String.valueOf(i));
        if (!url.endsWith(""/"")) {
            url.append(""/"");
        }
        url.append(urlEncodePathComponent(value)).append(""/"");
        i++;
    }
    String pageMap = (String) parameters.get(WebRequestCodingStrategy.PAGEMAP);
    if (pageMap != null) {
        i++;
        pageMap = WebRequestCodingStrategy.encodePageMapName(pageMap);
        if (!url.endsWith(""/"")) {
            url.append(""/"");
        }
        url.append(WebRequestCodingStrategy.PAGEMAP).append(""/"").append(urlEncodePathComponent(pageMap)).append(""/"");
    }
    if (i != parameters.size()) {
        throw new WicketRuntimeException(""Not all parameters were encoded. Make sure all parameter names are integers in consecutive order starting with zero. Current parameter names are: "" + parameters.keySet().toString());
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2065_9da430fb,Major,wicket/src/main/java/org/apache/wicket/request/target/coding/IndexedHybridUrlCodingStrategy.java,83,114,"protected ValueMap decodeParameters(String urlFragment, Map urlParameters) {
    PageParameters params = new PageParameters();
    if (urlFragment == null) {
        return params;
    }
    if (urlFragment.startsWith(""/"")) {
        urlFragment = urlFragment.substring(1);
    }
    if (urlFragment.length() > 0 && urlFragment.endsWith(""/"")) {
        urlFragment = urlFragment.substring(0, urlFragment.length() - 1);
    }
    String[] parts = urlFragment.split(""/"");
    for (int i = 0; i < parts.length; i++) {
        if (WebRequestCodingStrategy.PAGEMAP.equals(parts[i])) {
            i++;
            params.put(WebRequestCodingStrategy.PAGEMAP, WebRequestCodingStrategy.decodePageMapName(urlDecodePathComponent(parts[i])));
        } else {
            params.put(String.valueOf(i), urlDecodePathComponent(parts[i]));
        }
    }
    return params;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2065_9da430fb,Major,wicket/src/main/java/org/apache/wicket/request/target/coding/IndexedParamUrlCodingStrategy.java,72,127,"@Override
protected void appendParameters(AppendingStringBuffer url, Map parameters) {
    int i = 0;
    while (parameters.containsKey(String.valueOf(i))) {
        String value = null;
        Object parameter = parameters.get(String.valueOf(i));
        if (parameter instanceof String[] && ((String[]) parameter).length > 0) {
            value = ((String[]) parameter)[0];
        } else {
            value = parameter.toString();
        }
        if (!url.endsWith(""/"")) {
            url.append(""/"");
        }
        url.append(urlEncodePathComponent(value)).append(""/"");
        i++;
    }
    String pageMap = (String) parameters.get(WebRequestCodingStrategy.PAGEMAP);
    if (pageMap != null) {
        i++;
        pageMap = WebRequestCodingStrategy.encodePageMapName(pageMap);
        if (!url.endsWith(""/"")) {
            url.append(""/"");
        }
        url.append(WebRequestCodingStrategy.PAGEMAP).append(""/"").append(urlEncodePathComponent(pageMap)).append(""/"");
    }
    String intface = (String) parameters.get(WebRequestCodingStrategy.INTERFACE_PARAMETER_NAME);
    if (intface != null) {
        i++;
        if (!url.endsWith(""/"")) {
            url.append(""/"");
        }
        url.append(WebRequestCodingStrategy.INTERFACE_PARAMETER_NAME).append(""/"").append(urlEncodePathComponent(intface)).append(""/"");
    }
    if (i != parameters.size()) {
        throw new WicketRuntimeException(""Not all parameters were encoded. Make sure all parameter names are integers in consecutive order starting with zero. Current parameter names are: "" + parameters.keySet().toString());
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2065_9da430fb,Major,wicket/src/main/java/org/apache/wicket/request/target/coding/MixedParamUrlCodingStrategy.java,104,152,"/**
 * {@inheritDoc}
 */
@Override
protected void appendParameters(AppendingStringBuffer url, Map parameters) {
    if (!url.endsWith(""/"")) {
        url.append(""/"");
    }
    Set parameterNamesToAdd = new HashSet(parameters.keySet());
    // Find index of last specified parameter
    boolean foundParameter = false;
    int lastSpecifiedParameter = parameterNames.length;
    while (lastSpecifiedParameter != 0 && !foundParameter) {
        foundParameter = parameters.containsKey(parameterNames[--lastSpecifiedParameter]);
    }
    if (foundParameter) {
        for (int i = 0; i <= lastSpecifiedParameter; i++) {
            String parameterName = parameterNames[i];
            final Object param = parameters.get(parameterName);
            String value = param instanceof String[] ? ((String[]) param)[0] : (String) param;
            if (value == null) {
                value = """";
            }
            url.append(urlEncodePathComponent(value)).append(""/"");
            parameterNamesToAdd.remove(parameterName);
        }
    }
    if (!parameterNamesToAdd.isEmpty()) {
        boolean first = true;
        final Iterator iterator = parameterNamesToAdd.iterator();
        while (iterator.hasNext()) {
            url.append(first ? '?' : '&');
            String parameterName = (String) iterator.next();
            final Object param = parameters.get(parameterName);
            String value = param instanceof String[] ? ((String[]) param)[0] : (String) param;
            url.append(urlEncodeQueryComponent(parameterName)).append(""="").append(urlEncodeQueryComponent(value));
            first = false;
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2065_9da430fb,Major,wicket/src/main/java/org/apache/wicket/request/target/coding/PackageRequestTargetUrlCodingStrategy.java,132,153,"/**
 *  @see org.apache.wicket.request.target.coding.IRequestTargetUrlCodingStrategy#encode(org.apache.wicket.IRequestTarget)
 */
public final CharSequence encode(IRequestTarget requestTarget) {
    if (!(requestTarget instanceof IBookmarkablePageRequestTarget)) {
        throw new IllegalArgumentException(""this encoder can only be used with instances of "" + IBookmarkablePageRequestTarget.class.getName());
    }
    AppendingStringBuffer url = new AppendingStringBuffer(40);
    url.append(getMountPath());
    IBookmarkablePageRequestTarget target = (IBookmarkablePageRequestTarget) requestTarget;
    url.append(""/"").append(Classes.simpleName(target.getPageClass())).append(""/"");
    PageParameters pageParameters = target.getPageParameters();
    if (target.getPageMapName() != null) {
        pageParameters.put(WebRequestCodingStrategy.PAGEMAP, WebRequestCodingStrategy.encodePageMapName(target.getPageMapName()));
    }
    appendParameters(url, pageParameters);
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2065_9da430fb,Major,wicket/src/main/java/org/apache/wicket/request/target/coding/PackageRequestTargetUrlCodingStrategy.java,174,177,"/**
 *  @see java.lang.Object#toString()
 */
public String toString() {
    return ""PackageEncoder[package="" + packageName + ""]"";
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2079_ceac38b1,Minor,wicket/src/main/java/org/apache/wicket/Page.java,1054,1150,"/**
 *  Throw an exception if not all components rendered.
 *
 *  @param renderedContainer
 *             The page itself if it was a full page render or the container that was rendered
 *             standalone
 */
private final void checkRendering(final MarkupContainer renderedContainer) {
    // If the application wants component uses checked and
    // the response is not a redirect
    final IDebugSettings debugSettings = Application.get().getDebugSettings();
    if (debugSettings.getComponentUseCheck() && !getResponse().isRedirect()) {
        final List<Component> unrenderedComponents = new ArrayList<Component>();
        final StringBuffer buffer = new StringBuffer();
        renderedContainer.visitChildren(new IVisitor<Component>() {

            public Object component(final Component component) {
                // If component never rendered
                if (renderedComponents == null || !renderedComponents.contains(component)) {
                    // If auto component ...
                    if (!component.isAuto() && component.isVisibleInHierarchy()) {
                        // Increase number of unrendered components
                        unrenderedComponents.add(component);
                        // Add to explanatory string to buffer
                        buffer.append(Integer.toString(unrenderedComponents.size()) + "". "" + component + ""\n"");
                        String metadata = component.getMetaData(Component.CONSTRUCTED_AT_KEY);
                        if (metadata != null) {
                            buffer.append(metadata);
                        }
                        metadata = component.getMetaData(Component.ADDED_AT_KEY);
                        if (metadata != null) {
                            buffer.append(metadata);
                        }
                    } else {
                        // not visible
                        return CONTINUE_TRAVERSAL_BUT_DONT_GO_DEEPER;
                    }
                }
                return CONTINUE_TRAVERSAL;
            }
        });
        // Throw exception if any errors were found
        if (unrenderedComponents.size() > 0) {
            // Get rid of set
            renderedComponents = null;
            Iterator<Component> iterator = unrenderedComponents.iterator();
            while (iterator.hasNext()) {
                Component component = iterator.next();
                // Now first test if the component has a sibling that is a transparent resolver.
                Iterator<? extends Component> iterator2 = component.getParent().iterator();
                while (iterator2.hasNext()) {
                    Component sibling = iterator2.next();
                    if (!sibling.isVisible()) {
                        boolean isTransparentMarkupContainer = sibling instanceof MarkupContainer && ((MarkupContainer) sibling).isTransparentResolver();
                        boolean isComponentResolver = sibling instanceof IComponentResolver;
                        if (isTransparentMarkupContainer || isComponentResolver) {
                            // we found a transparent container that isn't visible
                            // then ignore this component and only do a debug statement here.
                            log.debug(""Component {} wasn't rendered but most likely it has a transparent parent: {}"", component, sibling);
                            iterator.remove();
                            break;
                        }
                    }
                }
            }
            // if still > 0
            if (unrenderedComponents.size() > 0) {
                // Throw exception
                throw new WicketRuntimeException(""The component(s) below failed to render. A common problem is that you have added a component in code but forgot to reference it in the markup (thus the component will never be rendered).\n\n"" + buffer.toString());
            }
        }
    }
    // Get rid of set
    renderedComponents = null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-208_b224bad8,Minor,wicket/src/main/java/wicket/ajax/AbstractAjaxTimerBehavior.java,62,72,"/**
 *  @see wicket.behavior.AbstractAjaxBehavior#renderHead(wicket.markup.html.IHeaderResponse)
 */
public void renderHead(IHeaderResponse response) {
    super.renderHead(response);
    if (this.attachedBodyOnLoadModifier == false) {
        this.attachedBodyOnLoadModifier = true;
        ((WebPage) getComponent().getPage()).getBodyContainer().addOnLoadModifier(getJsTimeoutCall(updateInterval), getComponent());
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-208_b224bad8,Minor,wicket/src/main/java/wicket/ajax/AbstractAjaxTimerBehavior.java,79,83,"/**
 *  @param updateInterval
 *             Duration between AJAX callbacks
 *  @return JS script
 */
protected final String getJsTimeoutCall(final Duration updateInterval) {
    return ""setTimeout(function() { "" + getCallbackScript(false, true) + "" }, "" + updateInterval.getMilliseconds() + "");"";
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-208_b224bad8,Minor,wicket/src/main/java/wicket/ajax/AbstractAjaxTimerBehavior.java,89,101,"/**
 *  @see wicket.ajax.AbstractDefaultAjaxBehavior#respond(wicket.ajax.AjaxRequestTarget)
 */
protected final void respond(final AjaxRequestTarget target) {
    onTimer(target);
    if (!stopped) {
        // this might look strange, but it is necessary for IE not to leak
        String js = ""setTimeout(\"""" + getCallbackScript(false, true) + ""\"", "" + updateInterval.getMilliseconds() + "");"";
        target.appendJavascript(js);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/Resource.java,152,162,"/**
 *  THIS METHOD IS NOT PART OF THE WICKET PUBLIC API. DO NOT USE IT!
 *
 *  @param parameters
 *             Map of query parameters that parameterize this resource
 */
public final void setParameters(final Map<?, ?> parameters) {
    if (parameters == null) {
        Resource.parameters.set(null);
    } else {
        Resource.parameters.set(new ValueMap(parameters));
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,492,497,"/**
 *  @see java.util.Map#putAll(java.util.Map)
 */
@Override
public void putAll(final Map map) {
    checkMutability();
    super.putAll(map);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,534,564,"/**
 *  Generates a <code>String</code> representation of this object.
 *
 *  @return <code>String</code> representation of this <code>ValueMap</code> consistent with the
 *          tag-attribute style of markup elements. For example: <code>a=""x"" b=""y"" c=""z""</code>.
 */
@Override
public String toString() {
    final StringBuffer buffer = new StringBuffer();
    for (final Iterator iterator = entrySet().iterator(); iterator.hasNext(); ) {
        final Map.Entry entry = (Map.Entry) iterator.next();
        buffer.append(entry.getKey());
        buffer.append("" = \"""");
        final Object value = entry.getValue();
        if (value == null) {
            buffer.append(""null"");
        } else if (value.getClass().isArray()) {
            buffer.append(Arrays.asList((Object[]) value));
        } else {
            buffer.append(value);
        }
        buffer.append('\""');
        if (iterator.hasNext()) {
            buffer.append(' ');
        }
    }
    return buffer.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,585,598,"// //
// // getAs convenience methods
// //
/**
 *  @see IValueMap#getAsBoolean(String)
 */
public Boolean getAsBoolean(String key) {
    if (!containsKey(key))
        return null;
    try {
        return getBoolean(key);
    } catch (StringValueConversionException ignored) {
        return null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,619,632,"/**
 *  @see IValueMap#getAsInteger(String)
 */
public Integer getAsInteger(String key) {
    if (!containsKey(key))
        return null;
    try {
        return getInt(key);
    } catch (StringValueConversionException ignored) {
        return null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,652,665,"/**
 *  @see IValueMap#getAsLong(String)
 */
public Long getAsLong(String key) {
    if (!containsKey(key))
        return null;
    try {
        return getLong(key);
    } catch (StringValueConversionException ignored) {
        return null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,685,698,"/**
 *  @see IValueMap#getAsDouble(String)
 */
public Double getAsDouble(String key) {
    if (!containsKey(key))
        return null;
    try {
        return getDouble(key);
    } catch (StringValueConversionException ignored) {
        return null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,703,713,"/**
 *  @see IValueMap#getAsDouble(String, double)
 */
public double getAsDouble(String key, double defaultValue) {
    try {
        return getDouble(key, defaultValue);
    } catch (StringValueConversionException ignored) {
        return defaultValue;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,718,721,"/**
 *  @see IValueMap#getAsDuration(String)
 */
public Duration getAsDuration(String key) {
    return getAsDuration(key, null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,726,739,"/**
 *  @see IValueMap#getAsDuration(String, Duration)
 */
public Duration getAsDuration(String key, Duration defaultValue) {
    if (!containsKey(key))
        return defaultValue;
    try {
        return getDuration(key);
    } catch (StringValueConversionException ignored) {
        return defaultValue;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,744,747,"/**
 *  @see IValueMap#getAsTime(String)
 */
public Time getAsTime(String key) {
    return getAsTime(key, null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,752,765,"/**
 *  @see IValueMap#getAsTime(String, Time)
 */
public Time getAsTime(String key, Time defaultValue) {
    if (!containsKey(key))
        return defaultValue;
    try {
        return getTime(key);
    } catch (StringValueConversionException ignored) {
        return defaultValue;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,770,773,"/**
 *  @see IValueMap#getAsEnum(String, Class<T>)
 */
public <T extends Enum<T>> T getAsEnum(String key, Class<T> eClass) {
    return getEnumImpl(key, eClass, null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,778,783,"/**
 *  @see IValueMap#getAsEnum
 */
public <T extends Enum<T>> T getAsEnum(String key, T defaultValue) {
    if (defaultValue == null)
        throw new IllegalArgumentException(""Default value cannot be null"");
    return getEnumImpl(key, defaultValue.getClass(), defaultValue);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,788,791,"/**
 *  @see IValueMap#getAsEnum(String, Class<T>, T)
 */
public <T extends Enum<T>> T getAsEnum(String key, Class<T> eClass, T defaultValue) {
    return getEnumImpl(key, eClass, defaultValue);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2172_ea4a3f8a,Minor,wicket/src/main/java/org/apache/wicket/util/value/ValueMap.java,796,835,"/**
 *  get enum implementation
 */
@SuppressWarnings({ ""unchecked"" })
private <T extends Enum<T>> T getEnumImpl(String key, Class<?> eClass, T defaultValue) {
    if (eClass == null)
        throw new IllegalArgumentException(""eClass value cannot be null"");
    String value = getString(key);
    if (value == null)
        return defaultValue;
    Method valueOf = null;
    try {
        valueOf = eClass.getMethod(""valueOf"", String.class);
    } catch (NoSuchMethodException e) {
        throw new RuntimeException(""Could not find method valueOf(String s) for "" + eClass.getName(), e);
    }
    try {
        return (T) valueOf.invoke(eClass, value);
    } catch (IllegalAccessException e) {
        throw new RuntimeException(""Could not invoke method valueOf(String s) on "" + eClass.getName(), e);
    } catch (InvocationTargetException e) {
        // IllegalArgumentException thrown if enum isn't defined - just return default
        if (e.getCause() instanceof IllegalArgumentException) {
            return defaultValue;
        }
        // shouldn't happen
        throw new RuntimeException(e);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2181_d79d0192,Major,wicket/src/main/java/org/apache/wicket/markup/html/list/PageableListView.java,84,93,"/**
 *  Gets the index of the current page being displayed by this list view.
 *
 *  @return Returns the currentPage.
 */
public final int getCurrentPage() {
    // If first cell is out of range, bring page back into range
    while ((currentPage * rowsPerPage) >= getList().size()) {
        currentPage--;
    }
    return currentPage;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2202_24ac1a35,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/Form.java,1222,1271,"/**
 *  Find out whether there is any registered error for a form component.
 *
 *  @return whether there is any registered error for a form component
 */
private boolean anyFormComponentError() {
    final boolean[] error = new boolean[] { false };
    final IVisitor<Component> visitor = new IVisitor<Component>() {

        public Object component(final Component component) {
            if (component.hasErrorMessage()) {
                error[0] = true;
                return Component.IVisitor.STOP_TRAVERSAL;
            }
            // Traverse all children
            return Component.IVisitor.CONTINUE_TRAVERSAL;
        }
    };
    visitChildren(FormComponent.class, new IVisitor<Component>() {

        public Object component(final Component component) {
            return visitor.component(component);
        }
    });
    if (!error[0]) {
        if (getParent() instanceof Border) {
            MarkupContainer border = getParent();
            Iterator<? extends Component> iter = border.iterator();
            while (iter.hasNext()) {
                Component child = iter.next();
                if ((child != this) && (child instanceof FormComponent)) {
                    visitor.component(child);
                    if (error[0]) {
                        break;
                    }
                }
            }
        }
    }
    return error[0];
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2202_24ac1a35,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/Form.java,1243,1246,"public Object component(final Component component) {
    return visitor.component(component);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2261_089303f4,Major,wicket/src/main/java/org/apache/wicket/protocol/http/MockWebApplication.java,524,556,"/**
 *  @param cycle
 */
public final void postProcessRequestCycle(WebRequestCycle cycle) {
    previousRenderedPage = lastRenderedPage;
    if (cycle.getResponse() instanceof WebResponse) {
        // handle redirects which are usually managed by the browser
        // transparently
        final MockHttpServletResponse httpResponse = (MockHttpServletResponse) cycle.getWebResponse().getHttpServletResponse();
        if (httpResponse.isRedirect()) {
            lastRenderedPage = generateLastRenderedPage(cycle);
            MockHttpServletRequest newHttpRequest = new MockHttpServletRequest(application, servletSession, application.getServletContext());
            newHttpRequest.setRequestToRedirectString(httpResponse.getRedirectLocation());
            wicketRequest = application.newWebRequest(newHttpRequest);
            cycle = createRequestCycle();
            cycle.request();
        }
    }
    lastRenderedPage = generateLastRenderedPage(cycle);
    Session.set(getWicketSession());
    if (getLastRenderedPage() instanceof ExceptionErrorPage) {
        throw (RuntimeException) ((ExceptionErrorPage) getLastRenderedPage()).getThrowable();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2281_6e0b40bc,Major,wicket/src/main/java/org/apache/wicket/protocol/http/MockHttpServletRequest.java,1204,1295,"/**
 *  Initialize the request parameters to point to the given component.
 *
 *  @param component
 *             The component
 */
public void setRequestToComponent(final Component component) {
    final IPageMap pageMap = component.getPage().getPageMap();
    final String pageMapName = pageMap.isDefault() ? """" : pageMap.getName();
    if (component instanceof BookmarkablePageLink) {
        final Class<? extends Page> clazz = ((BookmarkablePageLink<?>) component).getPageClass();
        parameters.put(WebRequestCodingStrategy.BOOKMARKABLE_PAGE_PARAMETER_NAME, pageMapName + ':' + clazz.getName());
    } else {
        int version = component.getPage().getCurrentVersionNumber();
        Class<?> clazz = null;
        if (component instanceof IRedirectListener) {
            clazz = IRedirectListener.class;
        } else if (component instanceof IResourceListener) {
            clazz = IResourceListener.class;
        } else if (component instanceof IFormSubmitListener) {
            clazz = IFormSubmitListener.class;
        } else if (component instanceof ILinkListener) {
            clazz = ILinkListener.class;
        } else if (component instanceof IOnChangeListener) {
            clazz = IOnChangeListener.class;
        } else {
            throw new IllegalArgumentException(""The component class doesn't seem to implement any of the known *Listener interfaces: "" + component.getClass());
        }
        // manually create the url using default strategy and format
        parameters.put(WebRequestCodingStrategy.INTERFACE_PARAMETER_NAME, pageMapName + ':' + component.getPath() + ':' + (version == 0 ? """" : """" + version) + ':' + Classes.simpleName(clazz) + ""::"");
        try {
            RequestListenerInterface rli = (RequestListenerInterface) clazz.getField(""INTERFACE"").get(clazz);
            String auto = component.getRequestCycle().urlFor(component, rli).toString();
            int idx = auto.indexOf(WebRequestCodingStrategy.INTERFACE_PARAMETER_NAME);
            if (idx >= 0) {
                auto = auto.substring(idx + WebRequestCodingStrategy.INTERFACE_PARAMETER_NAME.length() + 1);
            } else {
                // additional check for crypted strategy
                idx = auto.indexOf(""x=6*"");
                if (idx >= 0) {
                    auto = auto.substring(idx + 4);
                }
            }
            idx = auto.indexOf(""&"");
            if (idx >= 0) {
                auto = auto.substring(0, idx);
            }
            parameters.put(WebRequestCodingStrategy.INTERFACE_PARAMETER_NAME, auto);
        } catch (Exception e) {
        // noop
        }
        if (component.isStateless() && component.getPage().isBookmarkable()) {
            parameters.put(WebRequestCodingStrategy.BOOKMARKABLE_PAGE_PARAMETER_NAME, pageMapName + ':' + component.getPage().getClass().getName());
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2334_96330447,Major,wicket-devutils/src/main/java/org/apache/wicket/devutils/debugbar/DebugBar.java,106,117,"@Override
protected void populateItem(ListItem<IDebugBarContributor> item) {
    IDebugBarContributor contrib = item.getModelObject();
    Component comp = contrib.createComponent(""contrib"", DebugBar.this);
    if (comp == null) {
        // some contributors only add information to the debug bar
        // and don't actually create a contributed component
        item.setVisibilityAllowed(false);
    } else {
        item.add(comp);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2334_96330447,Major,wicket-devutils/src/main/java/org/apache/wicket/devutils/debugbar/DebugBar.java,135,143,"/**
 *  Register your own custom contributor that will be part of the debug bar.
 *  You must have the context of an application for this thread at the time
 *  of calling this method.
 *
 *  @param contrib
 *             custom contributor - can not be null
 */
public static void registerContributor(IDebugBarContributor contrib) {
    if (contrib == null) {
        throw new IllegalArgumentException(""contrib can not be null"");
    }
    List<IDebugBarContributor> contributors = getContributors();
    contributors.add(contrib);
    Application.get().setMetaData(CONTRIBS_META_KEY, contributors);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2334_96330447,Major,wicket-devutils/src/main/java/org/apache/wicket/devutils/debugbar/DebugBar.java,145,149,"private static List<IDebugBarContributor> getContributors() {
    List<IDebugBarContributor> list = Application.get().getMetaData(CONTRIBS_META_KEY);
    return list == null ? new ArrayList<IDebugBarContributor>() : list;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2334_96330447,Major,wicket-devutils/src/main/java/org/apache/wicket/devutils/debugbar/DebugBar.java,151,155,"private static void registerStandardContributors() {
    registerContributor(VersionDebugContributor.DEBUG_BAR_CONTRIB);
    registerContributor(InspectorDebugPanel.DEBUG_BAR_CONTRIB);
    registerContributor(SessionSizeDebugPanel.DEBUG_BAR_CONTRIB);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2337_36a41358,Major,wicket/src/main/java/org/apache/wicket/util/lang/PropertyResolver.java,207,283,"private static ObjectAndGetSetter getObjectAndGetSetter(final String expression, final Object object, int tryToCreateNull) {
    final String expressionBracketsSeperated = Strings.replaceAll(expression, ""["", "".["").toString();
    int index = getNextDotIndex(expressionBracketsSeperated, 0);
    int lastIndex = 0;
    Object value = object;
    Class<?> clz = value.getClass();
    String exp = expressionBracketsSeperated;
    while (index != -1) {
        exp = expressionBracketsSeperated.substring(lastIndex, index);
        IGetAndSet getAndSetter = null;
        try {
            getAndSetter = getGetAndSetter(exp, clz);
        } catch (WicketRuntimeException ex) {
            // expression by it self can't be found. try to find a
            // setPropertyByIndex(int,value) method
            index = getNextDotIndex(expressionBracketsSeperated, index + 1);
            if (index != -1) {
                String indexExpression = expressionBracketsSeperated.substring(lastIndex, index);
                getAndSetter = getGetAndSetter(indexExpression, clz);
            } else {
                exp = expressionBracketsSeperated.substring(lastIndex);
                break;
            }
        }
        Object newValue = null;
        if (value != null) {
            newValue = getAndSetter.getValue(value);
        }
        if (newValue == null) {
            if (tryToCreateNull == CREATE_NEW_VALUE) {
                newValue = getAndSetter.newValue(value);
                if (newValue == null) {
                    return null;
                }
            } else if (tryToCreateNull == RESOLVE_CLASS) {
                clz = getAndSetter.getTargetClass();
            } else {
                return null;
            }
        }
        value = newValue;
        if (value != null) {
            // value can be null if we are in the RESOLVE_CLASS
            clz = value.getClass();
        }
        lastIndex = index + 1;
        index = getNextDotIndex(expressionBracketsSeperated, lastIndex);
        if (index == -1) {
            exp = expressionBracketsSeperated.substring(lastIndex);
            break;
        }
    }
    IGetAndSet getAndSetter = getGetAndSetter(exp, clz);
    return new ObjectAndGetSetter(getAndSetter, value);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2337_36a41358,Major,wicket/src/main/java/org/apache/wicket/util/lang/PropertyResolver.java,763,766,"/**
 *  @see org.apache.wicket.util.lang.PropertyResolver.IGetAndSet#getValue(java.lang.Object)
 */
public Object getValue(Object object) {
    return ((List<?>) object).get(index);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2337_36a41358,Major,wicket/src/main/java/org/apache/wicket/util/lang/PropertyResolver.java,820,823,"/**
 *  @see org.apache.wicket.util.lang.PropertyResolver.IGetAndSet#getValue(java.lang.Object)
 */
public Object getValue(Object object) {
    return Array.get(object, index);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2350_cd281092,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/FormComponent.java,147,194,"/**
 *  @see org.apache.wicket.validation.IErrorMessageSource#getMessage(java.lang.String)
 */
public String getMessage(String key) {
    final FormComponent<T> formComponent = FormComponent.this;
    // Use the following log4j config for detailed logging on the property resolution
    // process
    // log4j.logger.org.apache.wicket.resource.loader=DEBUG
    // log4j.logger.org.apache.wicket.Localizer=DEBUG
    final Localizer localizer = formComponent.getLocalizer();
    // retrieve prefix that will be used to construct message keys
    String prefix = formComponent.getValidatorKeyPrefix();
    String message = null;
    // first try the full form of key [prefix].[form-component-id].[key]
    String resource = prefix(prefix, getId() + ""."" + key);
    message = getString(localizer, resource, formComponent);
    // if not found, try a more general form (without prefix) [form-component-id].[key]
    if (Strings.isEmpty(message) && Strings.isEmpty(prefix)) {
        resource = getId() + ""."" + key;
        message = getString(localizer, resource, formComponent);
    }
    // If not found try a more general form [prefix].[key]
    if (Strings.isEmpty(message)) {
        resource = prefix(prefix, key);
        message = getString(localizer, key, formComponent);
    }
    // If not found try the most general form [key]
    if (Strings.isEmpty(message) && Strings.isEmpty(prefix)) {
        // Try a variation of the resource key
        message = getString(localizer, key, formComponent);
    }
    // returned from localizer
    if (Strings.isEmpty(message)) {
        message = null;
    }
    return message;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2368_fae1601b,Major,wicket/src/main/java/org/apache/wicket/Page.java,1054,1173,"/**
 *  Throw an exception if not all components rendered.
 *
 *  @param renderedContainer
 *             The page itself if it was a full page render or the container that was rendered
 *             standalone
 */
private final void checkRendering(final MarkupContainer renderedContainer) {
    // If the application wants component uses checked and
    // the response is not a redirect
    final IDebugSettings debugSettings = Application.get().getDebugSettings();
    if (debugSettings.getComponentUseCheck() && !getResponse().isRedirect()) {
        final List<Component> unrenderedComponents = new ArrayList<Component>();
        final StringBuffer buffer = new StringBuffer();
        renderedContainer.visitChildren(new IVisitor<Component>() {

            public Object component(final Component component) {
                // If component never rendered
                if (renderedComponents == null || !renderedComponents.contains(component)) {
                    // If auto component ...
                    if (!component.isAuto() && component.isVisibleInHierarchy()) {
                        // Increase number of unrendered components
                        unrenderedComponents.add(component);
                        // Add to explanatory string to buffer
                        buffer.append(Integer.toString(unrenderedComponents.size()) + "". "" + component + ""\n"");
                        String metadata = component.getMetaData(Component.CONSTRUCTED_AT_KEY);
                        if (metadata != null) {
                            buffer.append(metadata);
                        }
                        metadata = component.getMetaData(Component.ADDED_AT_KEY);
                        if (metadata != null) {
                            buffer.append(metadata);
                        }
                    } else {
                        // not visible
                        return CONTINUE_TRAVERSAL_BUT_DONT_GO_DEEPER;
                    }
                }
                return CONTINUE_TRAVERSAL;
            }
        });
        // Throw exception if any errors were found
        if (unrenderedComponents.size() > 0) {
            // Get rid of set
            renderedComponents = null;
            Iterator<Component> iterator = unrenderedComponents.iterator();
            while (iterator.hasNext()) {
                Component component = iterator.next();
                // Now first test if the component has a sibling that is a transparent resolver.
                Iterator<? extends Component> iterator2 = component.getParent().iterator();
                while (iterator2.hasNext()) {
                    Component sibling = iterator2.next();
                    if (!sibling.isVisible()) {
                        boolean isTransparentMarkupContainer = sibling instanceof MarkupContainer && ((MarkupContainer) sibling).isTransparentResolver();
                        boolean isComponentResolver = sibling instanceof IComponentResolver;
                        if (isTransparentMarkupContainer || isComponentResolver) {
                            // we found a transparent container that isn't visible
                            // then ignore this component and only do a debug statement here.
                            log.debug(""Component {} wasn't rendered but most likely it has a transparent parent: {}"", component, sibling);
                            iterator.remove();
                            break;
                        }
                    }
                }
                // Check if this component is a child of a border whose body is invisible and if
                // so ignore it
                Border border = component.findParent(Border.class);
                if (border != null && !border.getBodyContainer().isVisibleInHierarchy()) {
                    // Suppose:
                    // 
                    // <div wicket:id=""border""><div wicket:id=""label""></div> suppose
                    // border->label and border's body is hidden.
                    // 
                    // The label is added to border not to its hidden body so as far as wicket
                    // is concerned label is visible in hierarchy, but when rendering label wont
                    // be rendered because in the markup it is inside the border's hidden body.
                    // Thus component use check will fail even though it shouldnt - make sure it
                    // doesnt.
                    // 
                    // TODO it would be more accurate to determine that this component is inside
                    // the border parent's markup not the border's itself
                    iterator.remove();
                }
            }
            // if still > 0
            if (unrenderedComponents.size() > 0) {
                // Throw exception
                throw new WicketRuntimeException(""The component(s) below failed to render. A common problem is that you have added a component in code but forgot to reference it in the markup (thus the component will never be rendered).\n\n"" + buffer.toString());
            }
        }
    }
    // Get rid of set
    renderedComponents = null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2368_fae1601b,Major,wicket/src/main/java/org/apache/wicket/Page.java,1065,1099,"public Object component(final Component component) {
    // If component never rendered
    if (renderedComponents == null || !renderedComponents.contains(component)) {
        // If auto component ...
        if (!component.isAuto() && component.isVisibleInHierarchy()) {
            // Increase number of unrendered components
            unrenderedComponents.add(component);
            // Add to explanatory string to buffer
            buffer.append(Integer.toString(unrenderedComponents.size()) + "". "" + component + ""\n"");
            String metadata = component.getMetaData(Component.CONSTRUCTED_AT_KEY);
            if (metadata != null) {
                buffer.append(metadata);
            }
            metadata = component.getMetaData(Component.ADDED_AT_KEY);
            if (metadata != null) {
                buffer.append(metadata);
            }
        } else {
            // not visible
            return CONTINUE_TRAVERSAL_BUT_DONT_GO_DEEPER;
        }
    }
    return CONTINUE_TRAVERSAL;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2506_0f8a2990,Major,wicket/src/main/java/org/apache/wicket/markup/html/internal/Enclosure.java,183,196,"private void applyEnclosureVisibilityToChildren(final MarkupContainer container, final MarkupStream markupStream, ComponentTag enclosureOpenTag) {
    DirectChildTagIterator it = new DirectChildTagIterator(markupStream, enclosureOpenTag);
    while (it.hasNext()) {
        final ComponentTag tag = it.next();
        final Component child = container.get(tag.getId());
        // record original visiblity allowed value, will restore later
        changes.put(child, child.isVisibilityAllowed());
        child.setVisibilityAllowed(isVisible());
    }
    it.rewind();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2506_0f8a2990,Major,wicket/src/main/java/org/apache/wicket/markup/html/internal/Enclosure.java,198,210,"private void checkChildComponent(Component controller) {
    if (controller == null) {
        throw new WicketRuntimeException(""Could not find child with id: "" + childId + "" in the wicket:enclosure"");
    } else if (controller == this) {
        throw new WicketRuntimeException(""Programming error: childComponent == enclose component; endless loop"");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2506_0f8a2990,Major,wicket/src/main/java/org/apache/wicket/markup/html/internal/Enclosure.java,212,254,"private void ensureAllChildrenPresent(final MarkupContainer container, final MarkupStream markupStream, ComponentTag enclosureOpenTag) {
    DirectChildTagIterator it = new DirectChildTagIterator(markupStream, enclosureOpenTag);
    while (it.hasNext()) {
        final ComponentTag tag = it.next();
        Component child = container.get(tag.getId());
        if (child == null) {
            // component does not yet exist in the container, attempt to resolve it using
            // resolvers
            final int tagIndex = it.getCurrentIndex();
            // because the resolvers can auto-add and therefore immediately render the component
            // we have to buffer the output since we do not yet know the visibility of the
            // enclosure
            CharSequence buffer = new ResponseBufferZone(getRequestCycle(), markupStream) {

                @Override
                protected void executeInsideBufferedZone() {
                    markupStream.setCurrentIndex(tagIndex);
                    ComponentResolvers.resolve(container, markupStream, tag);
                }
            }.execute();
            child = container.get(tag.getId());
            checkChildComponent(child);
            if (buffer.length() > 0) {
                // we have already rendered this child component, insert a stub component that
                // will dump the markup during the normal render process if the enclosure is
                // visible
                final Component stub = new AutoMarkupLabel(child.getId(), buffer);
                // ok here because we are replacing auto with auto
                container.replace(stub);
            }
        }
    }
    it.rewind();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2506_0f8a2990,Major,wicket/src/main/java/org/apache/wicket/markup/html/internal/Enclosure.java,257,262,"@Override
protected void onDetach() {
    restoreOriginalChildVisibility();
    super.onDetach();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2506_0f8a2990,Major,wicket/src/main/java/org/apache/wicket/markup/html/internal/Enclosure.java,264,277,"private void restoreOriginalChildVisibility() {
    if (changes != null) {
        MarkupContainer container = getEnclosureParent();
        // restore original visibility statuses
        for (Map.Entry<Component, Boolean> entry : changes.entrySet()) {
            entry.getKey().setVisibilityAllowed(entry.getValue());
        }
        changes = null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2552_12e1f39b,Major,wicket/src/main/java/org/apache/wicket/validation/validator/CreditCardValidator.java,39,64,"/**
 *  @see AbstractValidator#onValidate(IValidatable)
 */
@Override
protected void onValidate(IValidatable<String> validatable) {
    String input = (validatable.getValue());
    String numberToCheck = input.replaceAll(""[ -]"", """");
    int nulOffset = '0';
    int sum = 0;
    for (int i = 1; i <= numberToCheck.length(); i++) {
        int currentDigit = numberToCheck.charAt(numberToCheck.length() - i) - nulOffset;
        if ((i % 2) == 0) {
            currentDigit *= 2;
            currentDigit = currentDigit > 9 ? currentDigit - 9 : currentDigit;
            sum += currentDigit;
        } else {
            sum += currentDigit;
        }
    }
    if (!((sum % 10) == 0)) {
        error(validatable);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2609_7da4ad17,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/EnumChoiceRenderer.java,95,98,"/**
 *  Translates the {@code object} into resource key that will be used to lookup the value shown
 *  to the user
 *
 *  @param object
 *  @return resource key
 */
protected String resourceKey(T object) {
    return object.getClass().getSimpleName() + ""."" + object.name();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2621_c849f986,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/Form.java,1052,1055,"/**
 *  Set to true to use enctype='multipart/form-data', and to process file uploads by default
 *  multiPart = false
 *
 *  @param multiPart
 *             whether this form should behave as a multipart form
 */
public void setMultiPart(boolean multiPart) {
    this.multiPart = multiPart;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2621_c849f986,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/Form.java,1400,1428,"private boolean isMultiPart() {
    if (multiPart) {
        return true;
    } else {
        final boolean[] anyEmbeddedMultipart = new boolean[] { false };
        visitChildren(Form.class, new IVisitor<Form<?>>() {

            public Object component(Form<?> form) {
                if (form.multiPart) {
                    anyEmbeddedMultipart[0] = true;
                    return STOP_TRAVERSAL;
                } else {
                    return CONTINUE_TRAVERSAL;
                }
            }
        });
        return anyEmbeddedMultipart[0];
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2621_c849f986,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/Form.java,1412,1423,"public Object component(Form<?> form) {
    if (form.multiPart) {
        anyEmbeddedMultipart[0] = true;
        return STOP_TRAVERSAL;
    } else {
        return CONTINUE_TRAVERSAL;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2621_c849f986,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/Form.java,1788,1805,"/**
 *  @see org.apache.wicket.Component#onRender()
 */
@Override
protected void onRender() {
    // Force multi-part on if any child form component is multi-part
    visitFormComponents(new FormComponent.AbstractVisitor() {

        @Override
        public void onFormComponent(FormComponent<?> formComponent) {
            if (formComponent.isVisible() && formComponent.isMultiPart()) {
                setMultiPart(true);
            }
        }
    });
    super.onRender();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2621_c849f986,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/Form.java,1794,1801,"@Override
public void onFormComponent(FormComponent<?> formComponent) {
    if (formComponent.isVisible() && formComponent.isMultiPart()) {
        setMultiPart(true);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2621_c849f986,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/upload/MultiFileUploadField.java,183,197,"/**
 *  @see org.apache.wicket.Component#onBeforeRender()
 */
@Override
protected void onBeforeRender() {
    super.onBeforeRender();
    // auto toggle form's multipart property
    Form<?> form = findParent(Form.class);
    if (form == null) {
        // woops
        throw new IllegalStateException(""Component "" + getClass().getName() + "" must have a "" + Form.class.getName() + "" component above in the hierarchy"");
    }
    form.setMultiPart(true);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2624_ef880545,Major,wicket/src/main/java/org/apache/wicket/util/convert/ConverterLocator.java,78,111,"/**
 *  @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,
 *       java.util.Locale)
 */
public Object convertToObject(String value, Locale locale) {
    if (value == null) {
        return null;
    }
    Class<?> theType = type.get();
    if ("""".equals(value)) {
        if (theType.equals(String.class)) {
            return theType.cast("""");
        }
        return null;
    }
    try {
        Object converted = Objects.convertValue(value, theType);
        if (theType.isAssignableFrom(converted.getClass())) {
            return theType.cast(converted);
        } else {
            throw new ConversionException(""Could not convert value: "" + value + "" to type: "" + theType.getName() + ""(Could not find compatible converter)."").setSourceValue(value);
        }
    } catch (Exception e) {
        throw new ConversionException(e.getMessage(), e).setSourceValue(value);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2624_ef880545,Major,wicket/src/main/java/org/apache/wicket/util/lang/PropertyResolver.java,1091,1160,"/**
 *  @param object
 *  @param value
 *  @param converter
 */
public final void setValue(final Object object, final Object value, PropertyResolverConverter converter) {
    Class type = null;
    if (setMethod != null) {
        type = getMethod.getReturnType();
    } else if (field != null) {
        type = field.getType();
    }
    Object converted = null;
    if (type != null) {
        converted = converter.convert(value, getMethod.getReturnType());
        if (converted == null) {
            if (value != null) {
                throw new ConversionException(""Can't convert value: "" + value + "" to class: "" + getMethod.getReturnType() + "" for setting it on "" + object);
            } else if (getMethod.getReturnType().isPrimitive()) {
                throw new ConversionException(""Can't convert null value to a primitive class: "" + getMethod.getReturnType() + "" for setting it on "" + object);
            }
        }
    }
    if (setMethod != null) {
        try {
            setMethod.invoke(object, new Object[] { converted });
        } catch (InvocationTargetException ex) {
            throw new WicketRuntimeException(""Error calling method: "" + setMethod + "" on object: "" + object, ex.getCause());
        } catch (Exception ex) {
            throw new WicketRuntimeException(""Error calling method: "" + setMethod + "" on object: "" + object, ex);
        }
    } else if (field != null) {
        try {
            field.set(object, converted);
        } catch (Exception ex) {
            throw new WicketRuntimeException(""Error setting field: "" + field + "" on object: "" + object, ex);
        }
    } else {
        throw new WicketRuntimeException(""no set method defined for value: "" + value + "" on object: "" + object + "" while respective getMethod being "" + getMethod.getName());
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2839_15477252,Major,wicket/src/main/java/org/apache/wicket/request/resource/AbstractResource.java,446,486,"/**
 *  Convenience method to write an {@link InputStream} to response.
 *
 *  @param attributes
 *  @param stream
 */
protected final void writeStream(Attributes attributes, InputStream stream) {
    final Response response = attributes.getResponse();
    OutputStream s = new OutputStream() {

        @Override
        public void write(int b) throws IOException {
            response.write(new byte[] { (byte) b });
        }

        @Override
        public void write(byte[] b) throws IOException {
            response.write(b);
        }

        @Override
        public void write(byte[] b, int off, int len) throws IOException {
            if (off == 0 || len == b.length) {
                write(b);
            } else {
                byte[] copy = new byte[len];
                System.arraycopy(b, off, copy, 0, len);
                write(copy);
            }
        }
    };
    try {
        Streams.copy(stream, s);
    } catch (IOException e) {
        throw new WicketRuntimeException(e);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2839_15477252,Major,wicket/src/main/java/org/apache/wicket/request/resource/AbstractResource.java,463,476,"@Override
public void write(byte[] b, int off, int len) throws IOException {
    if (off == 0 || len == b.length) {
        write(b);
    } else {
        byte[] copy = new byte[len];
        System.arraycopy(b, off, copy, 0, len);
        write(copy);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2839_15477252,Major,wicket/src/main/java/org/apache/wicket/util/resource/UrlResourceStream.java,193,249,"/**
 *  @see org.apache.wicket.util.watch.IModifiable#lastModifiedTime()
 *  @return The last time this resource was modified
 */
@Override
public Time lastModifiedTime() {
    if (file != null) {
        // in case the file has been removed by now
        if (file.exists() == false) {
            return null;
        }
        long lastModified = file.lastModified();
        // if last modified changed update content length and last modified date
        if (lastModified != this.lastModified) {
            this.lastModified = lastModified;
            contentLength = (int) file.length();
        }
    } else {
        try {
            long lastModified = Connections.getLastModified(url);
            // if last modified changed update content length and last modified date
            if (lastModified != this.lastModified) {
                this.lastModified = lastModified;
                URLConnection connection = url.openConnection();
                contentLength = connection.getContentLength();
                Connections.close(connection);
            }
        } catch (IOException e) {
            if (url.toString().indexOf("".jar!"") >= 0) {
                if (log.isDebugEnabled()) {
                    log.debug(""getLastModified for "" + url + "" failed: "" + e.getMessage());
                }
            } else {
                log.warn(""getLastModified for "" + url + "" failed: "" + e.getMessage());
            }
            // allow modification watcher to detect the problem
            return null;
        }
    }
    return Time.milliseconds(lastModified);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2882_ebe56869,Major,wicket/src/main/java/org/apache/wicket/MarkupContainer.java,132,193,"/**
 *  Adds a child component to this container.
 *
 *  @param childs
 *             The child(s)
 *  @throws IllegalArgumentException
 *              Thrown if a child with the same id is replaced by the add operation.
 *  @return This
 */
public MarkupContainer add(final Component... childs) {
    for (Component child : childs) {
        if (child == null) {
            throw new IllegalArgumentException(""argument child may not be null"");
        }
        checkHierarchyChange(child);
        if (log.isDebugEnabled()) {
            log.debug(""Add "" + child.getId() + "" to "" + this);
        }
        // Add to map
        addedComponent(child);
        if (put(child) != null) {
            throw new IllegalArgumentException(exceptionMessage(""A child with id '"" + child.getId() + ""' already exists""));
        }
        // Check if the markup is available after the child has been added to the parent
        try {
            // If not yet triggered, than do now (e.g. Pages)
            if (getMarkup() != null) {
                internalOnMarkupAttached();
            }
            if (child.getMarkup() != null) {
                child.internalOnMarkupAttached();
                // Tell all children of ""component"" as well
                if (child instanceof MarkupContainer) {
                    MarkupContainer container = (MarkupContainer) child;
                    container.visitChildren(new IVisitor<Component, Void>() {

                        public void component(final Component component, final IVisit<Void> visit) {
                            if (component.internalOnMarkupAttached()) {
                                visit.dontGoDeeper();
                            }
                        }
                    });
                }
            }
        } catch (WicketRuntimeException exception) {
        // ignore
        }
    }
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2882_ebe56869,Major,wicket/src/main/java/org/apache/wicket/MarkupContainer.java,929,972,"/**
 *  @param child
 *             Component being added
 */
private final void addedComponent(final Component child) {
    // Check for degenerate case
    if (child == this) {
        throw new IllegalArgumentException(""Component can't be added to itself"");
    }
    MarkupContainer parent = child.getParent();
    if (parent != null) {
        parent.remove(child);
    }
    // Set child's parent
    child.setParent(this);
    final IDebugSettings debugSettings = Application.get().getDebugSettings();
    if (debugSettings.isLinePreciseReportingOnAddComponentEnabled()) {
        child.setMetaData(ADDED_AT_KEY, ComponentStrings.toString(child, new MarkupException(""added"")));
    }
    final Page page = findPage();
    if (page != null) {
        child.initialize();
    }
    if (page != null) {
        // Tell the page a component has been added
        page.componentAdded(child);
    }
    // beforeRender on this component's children. So we need to initialize the newly added one
    if (isPreparedForRender()) {
        child.beforeRender();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2882_ebe56869,Major,wicket/src/main/java/org/apache/wicket/markup/html/internal/Enclosure.java,121,135,"/**
 *  Get the real parent container
 *
 *  @return enclosure's parent markup container
 */
private MarkupContainer getEnclosureParent() {
    MarkupContainer parent = getParent();
    while (parent.isAuto()) {
        parent = parent.getParent();
    }
    if (parent == null) {
        throw new WicketRuntimeException(""Unable to find parent component which is not a transparent resolver"");
    }
    return parent;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2882_ebe56869,Major,wicket/src/main/java/org/apache/wicket/markup/html/internal/Enclosure.java,141,186,"/**
 *  @see org.apache.wicket.MarkupContainer#onComponentTagBody(org.apache.wicket.markup.MarkupStream,
 *       org.apache.wicket.markup.ComponentTag)
 */
@Override
protected void onComponentTagBody(MarkupStream markupStream, ComponentTag openTag) {
    // enclosure's parent container
    MarkupContainer container = getEnclosureParent();
    Component controller = container.get(childId.toString());
    checkChildComponent(controller);
    // set the enclosure visibility
    boolean visible = controller.determineVisibility();
    // We want to know which components are rendered inside the enclosure
    final IComponentOnAfterRenderListener listener = new EnclosureListener(this);
    try {
        // register the listener
        getApplication().addComponentOnAfterRenderListener(listener);
        if (visible) {
            super.onComponentTagBody(markupStream, openTag);
        } else {
            RequestCycle cycle = getRequestCycle();
            Response response = cycle.getResponse();
            try {
                cycle.setResponse(NullResponse.getInstance());
                super.onComponentTagBody(markupStream, openTag);
            } finally {
                cycle.setResponse(response);
            }
        }
    } finally {
        // make sure we remove the listener
        getApplication().removeComponentOnAfterRenderListener(listener);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2882_ebe56869,Major,wicket/src/main/java/org/apache/wicket/markup/html/internal/Enclosure.java,221,233,"/**
 *  @see org.apache.wicket.application.IComponentOnBeforeRenderListener#onBeforeRender(org.apache.wicket.Component)
 */
public void onAfterRender(final Component component) {
    if (log.isWarnEnabled()) {
        if ((component instanceof FormComponent) || (component instanceof IFormSubmittingComponent) || (component instanceof Form)) {
            log.warn(""Please note that onBeforeRender() and validate() might be called on invisible components inside an Enclosure. "" + ""Please see EnclosureContainer for an alternative. Enclosure: "" + enclosure.toString());
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2882_ebe56869,Major,wicket/src/main/java/org/apache/wicket/markup/resolver/ComponentResolvers.java,49,83,"/**
 *  Attempts to resolve a component using resolvers. Tries resolvers in the component hierarchy
 *  as well as application-wide.
 *  <p>
 *  This method encapsulates the contract of resolving components and should be used any time a
 *  component needs to be resolved under normal circumstances.
 *  </p>
 *
 *  @param container
 *  @param markupStream
 *  @param tag
 *  @return <code>null</code> if a component was could not be found
 */
public static Component resolve(final MarkupContainer container, final MarkupStream markupStream, final ComponentTag tag) {
    // try to resolve using component hierarchy
    Component cursor = container;
    while (cursor != null) {
        if (cursor instanceof IComponentResolver) {
            IComponentResolver resolver = (IComponentResolver) cursor;
            Component component = resolver.resolve(container, markupStream, tag);
            if (component != null) {
                return component;
            }
        }
        cursor = cursor.getParent();
    }
    for (final IComponentResolver resolver : Application.get().getPageSettings().getComponentResolvers()) {
        Component component = resolver.resolve(container, markupStream, tag);
        if (component != null) {
            return component;
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2900_0e70ce39,Minor,wicket-spring/src/main/java/org/apache/wicket/spring/SpringBeanLocator.java,112,167,"/**
 *  Returns the name of the Bean as registered to Spring. Throws IllegalState exception if none
 *  or more than one beans are found.
 *
 *  @param ctx
 *             spring application context
 *  @param clazz
 *             bean class
 *  @throws IllegalStateException
 *  @return spring name of the bean
 */
private final String getBeanNameOfClass(final ApplicationContext ctx, final Class<?> clazz) {
    // get the list of all possible matching beans
    List<String> names = new ArrayList<String>(Arrays.asList(BeanFactoryUtils.beanNamesForTypeIncludingAncestors(ctx, clazz)));
    Iterator<String> it = names.iterator();
    // filter out beans that are not candidates for autowiring
    while (it.hasNext()) {
        final String possibility = it.next();
        BeanDefinition beanDef = ((AbstractApplicationContext) ctx).getBeanFactory().getBeanDefinition(possibility);
        if (BeanFactoryUtils.isFactoryDereference(possibility) || possibility.startsWith(""scopedTarget."") || !beanDef.isAutowireCandidate()) {
            it.remove();
        }
    }
    if (names.isEmpty()) {
        throw new IllegalStateException(""bean of type ["" + clazz.getName() + ""] not found"");
    } else if (names.size() > 1) {
        if (ctx instanceof AbstractApplicationContext) {
            for (String name : names) {
                BeanDefinition beanDef = ((AbstractApplicationContext) ctx).getBeanFactory().getBeanDefinition(name);
                if (beanDef instanceof AbstractBeanDefinition) {
                    if (((AbstractBeanDefinition) beanDef).isPrimary()) {
                        return name;
                    }
                }
            }
        }
        StringBuilder msg = new StringBuilder();
        msg.append(""More than one bean of type ["");
        msg.append(clazz.getName());
        msg.append(""] found, you have to specify the name of the bean "");
        msg.append(""(@SpringBean(name=\""foo\"")) in order to resolve this conflict. "");
        msg.append(""Matched beans: "");
        msg.append(Strings.join("","", names.toArray(new String[0])));
        throw new IllegalStateException(msg.toString());
    } else {
        return names.get(0);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2900_0e70ce39,Minor,wicket-spring/src/main/java/org/apache/wicket/spring/injection/annot/AnnotProxyFieldValueFactory.java,179,233,"/**
 *  Returns the name of the Bean as registered to Spring. Throws IllegalState exception if none
 *  or more than one beans are found.
 *
 *  @param ctx
 *             spring application context
 *  @param clazz
 *             bean class
 *  @throws IllegalStateException
 *  @return spring name of the bean
 */
private final String getBeanNameOfClass(ApplicationContext ctx, Class<?> clazz) {
    // get the list of all possible matching beans
    List<String> names = new ArrayList<String>(Arrays.asList(BeanFactoryUtils.beanNamesForTypeIncludingAncestors(ctx, clazz)));
    // filter out beans that are not candidates for autowiring
    Iterator<String> it = names.iterator();
    while (it.hasNext()) {
        final String possibility = it.next();
        BeanDefinition beanDef = ((AbstractApplicationContext) ctx).getBeanFactory().getBeanDefinition(possibility);
        if (BeanFactoryUtils.isFactoryDereference(possibility) || possibility.startsWith(""scopedTarget."") || !beanDef.isAutowireCandidate()) {
            it.remove();
        }
    }
    if (names.isEmpty()) {
        throw new IllegalStateException(""bean of type ["" + clazz.getName() + ""] not found"");
    } else if (names.size() > 1) {
        if (ctx instanceof AbstractApplicationContext) {
            for (String name : names) {
                BeanDefinition beanDef = ((AbstractApplicationContext) ctx).getBeanFactory().getBeanDefinition(name);
                if (beanDef instanceof AbstractBeanDefinition) {
                    if (((AbstractBeanDefinition) beanDef).isPrimary()) {
                        return name;
                    }
                }
            }
        }
        StringBuilder msg = new StringBuilder();
        msg.append(""More than one bean of type ["");
        msg.append(clazz.getName());
        msg.append(""] found, you have to specify the name of the bean "");
        msg.append(""(@SpringBean(name=\""foo\"")) in order to resolve this conflict. "");
        msg.append(""Matched beans: "");
        msg.append(Strings.join("","", names.toArray(new String[0])));
        throw new IllegalStateException(msg.toString());
    } else {
        return names.get(0);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-294_5c592d85,Major,jdk-1.4/wicket/src/main/java/wicket/protocol/http/request/WebRequestCodingStrategy.java,955,975,"/**
 *  Checks if the specified path matches any mount, and if so returns the
 *  coding strategy for that mount. Returns null if the path doesnt match
 *  any mounts.
 *
 *  NOTE: path here is not the mount - it is the full url path
 *
 *  @param path
 *             non-null url path
 *  @return coding strategy or null
 */
public IRequestTargetUrlCodingStrategy strategyForPath(String path) {
    if (path == null) {
        throw new IllegalArgumentException(""Argument [[path]] cannot be null"");
    }
    if (caseSensitiveMounts == false) {
        path = path.toLowerCase();
    }
    for (final Iterator it = map.entrySet().iterator(); it.hasNext(); ) {
        final Map.Entry entry = (Entry) it.next();
        final String key = (String) entry.getKey();
        if (path.startsWith(key)) {
            return (IRequestTargetUrlCodingStrategy) entry.getValue();
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-294_5c592d85,Major,jdk-1.4/wicket/src/main/java/wicket/request/target/coding/PackageRequestTargetUrlCodingStrategy.java,58,91,"/**
 *  @see wicket.request.target.coding.IRequestTargetUrlCodingStrategy#decode(wicket.request.RequestParameters)
 */
public IRequestTarget decode(RequestParameters requestParameters) {
    String remainder = requestParameters.getPath().substring(getMountPath().length());
    final String parametersFragment;
    int ix = remainder.indexOf('/', 1);
    if (ix == -1) {
        ix = remainder.length();
        parametersFragment = """";
    } else {
        parametersFragment = remainder.substring(ix);
    }
    if (remainder.startsWith(""/"")) {
        remainder = remainder.substring(1);
        ix--;
    }
    final String bookmarkablePageClassName = packageName + ""."" + remainder.substring(0, ix);
    Class bookmarkablePageClass = Session.get().getClassResolver().resolveClass(bookmarkablePageClassName);
    PageParameters parameters = new PageParameters(decodeParameters(parametersFragment, requestParameters.getParameters()));
    final String pageMapName = (String) parameters.remove(WebRequestCodingStrategy.PAGEMAP);
    requestParameters.setPageMapName(pageMapName);
    BookmarkablePageRequestTarget target = new BookmarkablePageRequestTarget(pageMapName, bookmarkablePageClass, parameters);
    return target;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2961_3d8c9d75,Major,wicket/src/main/java/org/apache/wicket/Component.java,966,973,"/**
 *  Used to call {@link #onInitialize()}
 */
void initialize() {
    if (!getFlag(FLAG_INITIALIZED)) {
        onInitialize();
        setFlag(FLAG_INITIALIZED, true);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-2993_0b4f78cc,Major,wicket/src/main/java/org/apache/wicket/request/mapper/BookmarkableMapper.java,91,117,"/**
 *  @see org.apache.wicket.request.mapper.AbstractBookmarkableMapper#parseRequest(org.apache.wicket.request.Request)
 */
@Override
protected UrlInfo parseRequest(Request request) {
    Url url = request.getUrl();
    if (url.getSegments().size() >= 3 && urlStartsWith(url, getContext().getNamespace(), getContext().getBookmarkableIdentifier())) {
        // try to extract page and component information from URL
        PageComponentInfo info = getPageComponentInfo(url);
        // load the page class
        String className = url.getSegments().get(2);
        Class<? extends IRequestablePage> pageClass = getPageClass(className);
        if (Page.class.isAssignableFrom(pageClass)) {
            // extract the PageParameters from URL if there are any
            PageParameters pageParameters = extractPageParameters(request, 3, pageParametersEncoder);
            return new UrlInfo(info, pageClass, pageParameters);
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3065_b293b75c,Major,wicket/src/main/java/org/apache/wicket/request/mapper/HomePageMapper.java,70,97,"public IRequestHandler mapRequest(Request request) {
    final Url url = request.getUrl();
    if (url.getSegments().size() == 0) {
        final Class<? extends IRequestablePage> homePageClass = getContext().getHomePageClass();
        final PageProvider pageProvider;
        if (url.getQueryParameters().size() > 0) {
            PageParameters pageParameters = extractPageParameters(request, 0, pageParametersEncoder);
            pageProvider = new PageProvider(homePageClass, pageParameters);
        } else {
            pageProvider = new PageProvider(homePageClass);
        }
        return new RenderPageRequestHandler(pageProvider);
    } else {
        return null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3076_d3dc9a50,Major,wicket/src/main/java/org/apache/wicket/util/string/UrlUtils.java,42,53,"/**
 *  Checks if the url is relative or absolute
 *
 *  @param url
 *  @return <code>true</code> if url is relative, <code>false</code> otherwise
 */
public static boolean isRelative(String url) {
    if ((url != null) && (url.startsWith(""/"") == false) && (url.indexOf(""://"") < 0) && !(url.startsWith(""#""))) {
        return true;
    } else {
        return false;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3098_1b7afefc,Major,wicket/src/main/java/org/apache/wicket/RequestListenerInterface.java,244,283,"/**
 *  Invokes a given interface on a component's behavior.
 *
 *  @param component
 *             The component
 *  @param behavior
 */
public final void invoke(final IRequestableComponent component, final IBehavior behavior) {
    if (!component.canCallListenerInterface()) {
        // just return so that we have a silent fail and just re-render the page
        log.warn(""component not enabled or visible; ignoring call. Component: "" + component);
        return;
    }
    // XXX a bit of an ugly cast here from IRequestableComponent to Component
    if (!behavior.isEnabled((Component) component)) {
        log.warn(""behavior not enabled; ignore call. Behavior {} at component {}"", behavior, component);
    }
    try {
        // Invoke the interface method on the component
        method.invoke(behavior, new Object[] {});
    } catch (InvocationTargetException e) {
        if (e.getTargetException() instanceof ReplaceHandlerException || e.getTargetException() instanceof AuthorizationException || e.getTargetException() instanceof WicketRuntimeException) {
            throw (RuntimeException) e.getTargetException();
        }
        throw new WicketRuntimeException(""Method "" + method.getName() + "" of "" + method.getDeclaringClass() + "" targeted at behavior "" + behavior + "" on component "" + component + "" threw an exception"", e);
    } catch (Exception e) {
        throw new WicketRuntimeException(""Method "" + method.getName() + "" of "" + method.getDeclaringClass() + "" targeted at behavior "" + behavior + "" on component "" + component + "" threw an exception"", e);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3166_4d7f7359,Major,wicket/src/main/java/org/apache/wicket/Component.java,2149,2166,"/**
 *  Checks if the component itself and all its parents are visible.
 *
 *  @return true if the component and all its parents are visible.
 */
public final boolean isVisibleInHierarchy() {
    Boolean state = getMetaData(VISIBLE_IN_HIERARCHY_CACHE_KEY);
    if (state == null) {
        Component parent = getParent();
        if (parent != null && !parent.isVisibleInHierarchy()) {
            state = false;
        } else {
            state = determineVisibility();
        }
        setMetaData(VISIBLE_IN_HIERARCHY_CACHE_KEY, state);
    }
    return state;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3196_f1c0f263,Minor,wicket/src/main/java/org/apache/wicket/validation/validator/UrlValidator.java,466,497,"/**
 *  Returns <code>true</code> if the path is valid. A <code>null</code> value is considered
 *  invalid.
 *
 *  @param path
 *             a path value to validate.
 *  @return <code>true</code> if path is valid.
 */
protected boolean isValidPath(String path) {
    if (path == null) {
        return false;
    }
    Matcher pathMatcher = Pattern.compile(PATH_PATTERN).matcher(path);
    if (!pathMatcher.matches()) {
        return false;
    }
    int slash2Count = countToken(""//"", path);
    if (isOff(ALLOW_2_SLASHES) && (slash2Count > 0)) {
        return false;
    }
    int slashCount = countToken(""/"", path);
    int dot2Count = countToken("".."", path);
    if (dot2Count > 0) {
        if ((slashCount - slash2Count - 1) <= dot2Count) {
            return false;
        }
    }
    return true;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3197_be70e608,Major,wicket/src/main/java/org/apache/wicket/MarkupContainer.java,773,811,"/**
 *  Replaces a child component of this container with another
 *
 *  @param child
 *             The child
 *  @throws IllegalArgumentException
 *              Thrown if there was no child with the same id.
 *  @return This
 */
public final MarkupContainer replace(final Component child) {
    checkHierarchyChange(child);
    if (child == null) {
        throw new IllegalArgumentException(""argument child must be not null"");
    }
    if (log.isDebugEnabled()) {
        log.debug(""Replacing "" + child.getId() + "" in "" + this);
    }
    if (child.getParent() != this) {
        // Add to map
        final Component replaced = put(child);
        // Look up to make sure it was already in the map
        if (replaced == null) {
            throw new WicketRuntimeException(exceptionMessage(""Cannot replace a component which has not been added: id='"" + child.getId() + ""', component="" + child));
        }
        // first remove the component.
        removedComponent(replaced);
        // then add the other one.
        addedComponent(child);
        // The generated markup id remains the same
        child.setMarkupIdImpl(replaced.getMarkupIdImpl());
    }
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3197_be70e608,Major,wicket/src/main/java/org/apache/wicket/markup/html/panel/Panel.java,98,110,"/**
 *  @see org.apache.wicket.Component#onComponentTag(org.apache.wicket.markup.ComponentTag)
 */
@Override
protected void onComponentTag(final ComponentTag tag) {
    if (tag.isOpenClose()) {
        wasOpenCloseTag = true;
        // Convert <span wicket:id=""myPanel"" /> into
        // <span wicket:id=""myPanel"">...</span>
        tag.setType(XmlTag.OPEN);
    }
    super.onComponentTag(tag);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3222_5729ed90,Major,wicket/src/main/java/org/apache/wicket/markup/AbstractMarkupParser.java,398,431,"/**
 *  Remove all comment sections (&lt;!-- .. --&gt;) from the raw markup.
 *
 *  @param rawMarkup
 *  @return raw markup
 */
private String removeComment(String rawMarkup) {
    // For reasons I don't understand, the following regex <code>""<!--(.|\n|\r)*?-->""<code>
    // causes a stack overflow in some circumstances (jdk 1.5)
    // See http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=5050507
    // See http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6337993
    int pos1 = rawMarkup.indexOf(""<!--"");
    while (pos1 != -1) {
        final int pos2 = rawMarkup.indexOf(""-->"", pos1 + 4);
        final AppendingStringBuffer buf = new AppendingStringBuffer(rawMarkup.length());
        if (pos2 != -1) {
            final String comment = rawMarkup.substring(pos1 + 4, pos2);
            // See http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6337993
            if (CONDITIONAL_COMMENT.matcher(comment).matches() == false) {
                buf.append(rawMarkup.substring(0, pos1));
                if (rawMarkup.length() >= pos2 + 3) {
                    buf.append(rawMarkup.substring(pos2 + 3));
                }
                rawMarkup = buf.toString();
            }
        }
        pos1 = rawMarkup.length() <= pos1 + 2 ? -1 : rawMarkup.indexOf(""<!--"", pos1 + 4);
    }
    return rawMarkup;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3253_71b6e905,Major,wicket/src/main/java/org/apache/wicket/model/AbstractPropertyModel.java,223,260,"/**
 *  @return model object class
 */
@SuppressWarnings(""unchecked"")
public Class<T> getObjectClass() {
    final String expression = propertyExpression();
    if (Strings.isEmpty(expression)) {
        // Return a meaningful value for an empty property expression
        Object target = getTarget();
        return (Class<T>) (target != null ? target.getClass() : null);
    }
    final Object target = getTarget();
    if (target != null) {
        try {
            return (Class<T>) PropertyResolver.getPropertyClass(expression, target);
        } catch (Exception e) {
        // ignore.
        }
    } else if (this.target instanceof IObjectClassAwareModel) {
        try {
            return PropertyResolver.getPropertyClass(expression, ((IObjectClassAwareModel<?>) this.target).getObjectClass());
        } catch (WicketRuntimeException e) {
        // it was just a try.
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3272_c86b972a,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/AbstractComponentMapper.java,83,98,"/**
 *  Extracts the {@link PageComponentInfo} from the URL. The {@link PageComponentInfo} is encoded
 *  as the very first query parameter and the parameter consists of name only (no value).
 *
 *  @param url
 *
 *  @return PageComponentInfo instance if one was encoded in URL, <code>null</code> otherwise.
 */
protected PageComponentInfo getPageComponentInfo(Url url) {
    if (url == null) {
        throw new IllegalStateException(""Argument 'url' may not be null."");
    }
    if (url.getQueryParameters().size() > 0) {
        QueryParameter param = url.getQueryParameters().get(0);
        if (Strings.isEmpty(param.getValue())) {
            return PageComponentInfo.parse(param.getName());
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3278_60d07288,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/AbstractSingleSelectChoice.java,159,169,"/**
 *  @see FormComponent#getModelValue()
 */
@Override
public String getModelValue() {
    final T object = getModelObject();
    if (object != null) {
        int index = getChoices().indexOf(object);
        return getChoiceRenderer().getIdValue(object, index);
    }
    return getNoSelectionValue().toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3278_60d07288,Major,wicket/src/main/java/org/apache/wicket/markup/html/form/AbstractSingleSelectChoice.java,269,318,"/**
 *  The localizer will be ask for the property to display Depending on if null is allowed or not
 *  it will ask for:
 *
 *  <ul>
 *  <li>nullValid: when null is valid and by default it will show an empty string as a choice.</li>
 *  <li>null: when null is not a valid choice and it will make a choice with ""Choose One""</li>
 *  </ul>
 *
 *  The choice for null is valid will always be returned. The choice when null is not valid will
 *  only be returned if the selected object is null.
 *
 *  @see org.apache.wicket.markup.html.form.AbstractChoice#getDefaultChoice(Object)
 */
@Override
protected CharSequence getDefaultChoice(final Object selected) {
    // Is null a valid selection value?
    if (isNullValid()) {
        // Null is valid, so look up the value for it
        String option = getLocalizer().getStringIgnoreSettings(getNullValidKey(), this, null, null);
        if (Strings.isEmpty(option)) {
            option = getLocalizer().getString(""nullValid"", this, """");
        }
        // The <option> tag buffer
        final AppendingStringBuffer buffer = new AppendingStringBuffer(64 + option.length());
        // Add option tag
        buffer.append(""\n<option"");
        // If null is selected, indicate that
        if (selected == null) {
            buffer.append("" selected=\""selected\"""");
        }
        // Add body of option tag
        buffer.append("" value=\""\"">"").append(option).append(""</option>"");
        return buffer;
    } else {
        // Null is not valid. Is it selected anyway?
        if ((selected == null) || getNoSelectionValue().equals(selected) || selected.equals(EMPTY_STRING)) {
            // Force the user to pick a non-null value
            String option = getLocalizer().getStringIgnoreSettings(getNullKey(), this, null, null);
            if (Strings.isEmpty(option)) {
                option = getLocalizer().getString(""null"", this, CHOOSE_ONE);
            }
            return ""\n<option selected=\""selected\"" value=\""\"">"" + option + ""</option>"";
        }
    }
    return """";
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3280_295e73bd,Major,wicket/src/main/java/org/apache/wicket/ajax/AjaxRequestTarget.java,567,648,"/**
 *  @see org.apache.wicket.request.handler.IPageRequestHandler#respond(org.apache.wicket.request.IRequestCycle)
 */
public final void respond(final IRequestCycle requestCycle) {
    // do not increment page id during ajax processing
    boolean frozen = page.setFreezePageId(true);
    try {
        RequestCycle rc = (RequestCycle) requestCycle;
        final WebResponse response = (WebResponse) requestCycle.getResponse();
        if (markupIdToComponent.values().contains(page)) {
            // the page itself has been added to the request target, we simply issue a redirect
            // back to the page
            IRequestHandler handler = new RenderPageRequestHandler(new PageProvider(page));
            final String url = rc.urlFor(handler).toString();
            response.sendRedirect(url);
            return;
        }
        for (ITargetRespondListener listener : respondListeners) {
            listener.onTargetRespond(this);
        }
        final Application app = Application.get();
        page.send(app, Broadcast.BREADTH, this);
        // Determine encoding
        final String encoding = app.getRequestCycleSettings().getResponseRequestEncoding();
        // Set content type based on markup type for page
        response.setContentType(""text/xml; charset="" + encoding);
        // Make sure it is not cached by a client
        response.disableCaching();
        response.write(""<?xml version=\""1.0\"" encoding=\"""");
        response.write(encoding);
        response.write(""\""?>"");
        response.write(""<ajax-response>"");
        // invoke onbeforerespond event on listeners
        fireOnBeforeRespondListeners();
        // normal behavior
        Iterator<CharSequence> it = prependJavaScripts.iterator();
        while (it.hasNext()) {
            CharSequence js = it.next();
            respondInvocation(response, js);
        }
        // process added components
        respondComponents(response);
        fireOnAfterRespondListeners(response);
        // execute the dom ready javascripts as first javascripts
        // after component replacement
        it = domReadyJavaScripts.iterator();
        while (it.hasNext()) {
            CharSequence js = it.next();
            respondInvocation(response, js);
        }
        it = appendJavaScripts.iterator();
        while (it.hasNext()) {
            CharSequence js = it.next();
            respondInvocation(response, js);
        }
        response.write(""</ajax-response>"");
    } finally {
        page.setFreezePageId(frozen);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3280_295e73bd,Major,wicket/src/main/java/org/apache/wicket/ajax/AjaxRequestTarget.java,670,692,"/**
 *  @param response
 */
private void fireOnAfterRespondListeners(final WebResponse response) {
    // invoke onafterresponse event on listeners
    if (listeners != null) {
        final Map<String, Component> components = Collections.unmodifiableMap(markupIdToComponent);
        // create response that will be used by listeners to append
        // javascript
        final IJavaScriptResponse jsresponse = new IJavaScriptResponse() {

            public void addJavaScript(String script) {
                respondInvocation(response, script);
            }
        };
        for (IListener listener : listeners) {
            listener.onAfterRespond(components, jsresponse);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3280_295e73bd,Major,wicket/src/main/java/org/apache/wicket/ajax/AjaxRequestTarget.java,700,738,"/**
 *  Processes components added to the target. This involves attaching components, rendering
 *  markup into a client side xml envelope, and detaching them
 *
 *  @param response
 */
private void respondComponents(WebResponse response) {
    // process component markup
    for (Map.Entry<String, Component> stringComponentEntry : markupIdToComponent.entrySet()) {
        final Component component = stringComponentEntry.getValue();
        if (!containsAncestorFor(component)) {
            respondComponent(response, getAjaxRegionMarkupId(component), component);
        }
    }
    if (header != null) {
        // some header responses buffer all calls to render*** until close is called.
        // when they are closed, they do something (i.e. aggregate all JS resource urls to a
        // single url), and then ""flush"" (by writing to the real response) before closing.
        // to support this, we need to allow header contributions to be written in the close
        // tag, which we do here:
        headerRendering = true;
        // save old response, set new
        Response oldResponse = RequestCycle.get().setResponse(encodingHeaderResponse);
        encodingHeaderResponse.reset();
        // now, close the response (which may render things)
        header.getHeaderResponse().close();
        // revert to old response
        RequestCycle.get().setResponse(oldResponse);
        // write the XML tags and we're done
        writeHeaderContribution(response);
        headerRendering = false;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3280_295e73bd,Major,wicket/src/main/java/org/apache/wicket/protocol/http/BufferedWebResponse.java,117,121,"@Override
protected void invoke(WebResponse response) {
    response.write(builder);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3297_71499e17,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/AbstractResourceReferenceMapper.java,35,62,"protected static String encodeResourceReferenceAttributes(ResourceReference.UrlAttributes attributes) {
    if (attributes == null || (attributes.getLocale() == null && attributes.getStyle() == null && attributes.getVariation() == null)) {
        return null;
    } else {
        StringBuilder res = new StringBuilder();
        if (attributes.getLocale() != null) {
            res.append(attributes.getLocale().toString());
        }
        if (!Strings.isEmpty(attributes.getStyle())) {
            res.append(""-"");
            res.append(attributes.getStyle());
        }
        if (!Strings.isEmpty(attributes.getVariation())) {
            res.append(""-"");
            res.append(attributes.getVariation());
        }
        return res.toString();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3304_7e7ab76c,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/form/AbstractTextComponent.java,115,122,"/**
 *  @see org.apache.wicket.markup.html.form.FormComponent#convertInput()
 */
@Override
protected void convertInput() {
    // Stateless forms don't have to be rendered first, convertInput could be called before
    // onBeforeRender calling resolve type here again to check if the type is correctly set.
    resolveType();
    super.convertInput();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3304_7e7ab76c,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/form/AbstractTextComponent.java,139,152,"/**
 */
private void resolveType() {
    if (!getFlag(TYPE_RESOLVED) && getType() == null) {
        // Set the type, but only if it's not a String (see WICKET-606).
        // Otherwise, getConvertEmptyInputStringToNull() won't work.
        Class<?> type = getModelType(getDefaultModel());
        if (!String.class.equals(type)) {
            setType(type);
        }
        setFlag(TYPE_RESOLVED, true);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3304_7e7ab76c,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/form/AbstractTextComponent.java,193,202,"/**
 *  @see org.apache.wicket.markup.html.form.FormComponent#convertValue(String[])
 */
@Override
protected T convertValue(String[] value) throws ConversionException {
    String tmp = value != null && value.length > 0 ? value[0] : null;
    if (getConvertEmptyInputStringToNull() && Strings.isEmpty(tmp)) {
        return null;
    }
    return super.convertValue(value);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3309_debca73b,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/tree/AbstractTree.java,811,876,"/**
 *  @see javax.swing.event.TreeModelListener#treeNodesInserted(javax.swing.event.TreeModelEvent)
 */
public final void treeNodesInserted(TreeModelEvent e) {
    if (dirtyAll) {
        return;
    }
    // get the parent node of inserted nodes
    Object parentNode = e.getTreePath().getLastPathComponent();
    TreeItem parentItem = nodeToItemMap.get(parentNode);
    if (parentItem != null && isNodeVisible(parentNode)) {
        List<?> eventChildren = Arrays.asList(e.getChildren());
        // parentNode was a leaf before this insertion event only if every one of
        // its current children is in the event's list of children
        boolean wasLeaf = true;
        int nodeChildCount = getChildCount(parentNode);
        for (int i = 0; wasLeaf && i < nodeChildCount; i++) {
            wasLeaf = eventChildren.contains(getChildAt(parentNode, i));
        }
        if (wasLeaf) {
            // parentNode now has children for the first time, so we need to invalidate
            // grandparent so that parentNode's junctionLink gets rebuilt with a plus/minus link
            Object grandparentNode = getParentNode(parentNode);
            invalidateNodeWithChildren(grandparentNode);
            getTreeState().expandNode(parentNode);
        } else {
            if (isNodeExpanded(parentNode)) {
                List<TreeItem> itemChildren = parentItem.getChildren();
                int childLevel = parentItem.getLevel() + 1;
                final int[] childIndices = e.getChildIndices();
                for (int i = 0; i < eventChildren.size(); ++i) {
                    TreeItem item = newTreeItem(parentItem, eventChildren.get(i), childLevel);
                    itemContainer.add(item);
                    if (itemChildren != null) {
                        itemChildren.add(childIndices[i], item);
                        markTheLastButOneChildDirty(parentItem, item);
                    }
                    if (!dirtyItems.contains(item)) {
                        dirtyItems.add(item);
                    }
                    if (!dirtyItemsCreateDOM.contains(item) && !item.hasParentWithChildrenMarkedToRecreation()) {
                        dirtyItemsCreateDOM.add(item);
                    }
                }
            }
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3333_ddf7e8a2,Critical,wicket-core/src/main/java/org/apache/wicket/markup/html/link/Link.java,347,417,"/**
 *  Handles this link's tag. OVERRIDES MUST CALL SUPER.
 *
 *  @param tag
 *             the component tag
 *  @see org.apache.wicket.Component#onComponentTag(ComponentTag)
 */
@Override
protected void onComponentTag(final ComponentTag tag) {
    // Default handling for tag
    super.onComponentTag(tag);
    // Set href to link to this link's linkClicked method
    CharSequence url = getURL();
    // append any anchor
    url = appendAnchor(tag, url);
    // If we're disabled
    if (!isLinkEnabled()) {
        disableLink(tag);
    } else {
        // if the tag is an anchor proper
        if (tag.getName().equalsIgnoreCase(""a"") || tag.getName().equalsIgnoreCase(""link"") || tag.getName().equalsIgnoreCase(""area"")) {
            // generate the href attribute
            tag.put(""href"", Strings.replaceAll(url, ""&"", ""&amp;""));
            // Add any popup script
            if (popupSettings != null) {
                // NOTE: don't encode to HTML as that is not valid
                // JavaScript
                tag.put(""onclick"", popupSettings.getPopupJavaScript());
            }
        } else if (tag.getName().equalsIgnoreCase(""script"") || tag.getName().equalsIgnoreCase(""style"")) {
            tag.put(""src"", Strings.replaceAll(url, ""&"", ""&amp;""));
        } else {
            // generate a popup script by asking popup settings for one
            if (popupSettings != null) {
                popupSettings.setTarget(""'"" + url + ""'"");
                String popupScript = popupSettings.getPopupJavaScript();
                tag.put(""onclick"", popupScript);
            } else {
                // or generate an onclick JS handler directly
                // in firefox when the element is quickly clicked 3 times a second request is
                // generated during page load. This check ensures that the click is ignored
                tag.put(""onclick"", ""var win = this.ownerDocument.defaultView || this.ownerDocument.parentWindow; "" + ""if (win == window) { window.location.href='"" + Strings.replaceAll(url, ""&"", ""&amp;"") + ""'; } ;return false"");
            }
        }
        // If the subclass specified javascript, use that
        final CharSequence onClickJavaScript = getOnClickScript(url);
        if (onClickJavaScript != null) {
            tag.put(""onclick"", onClickJavaScript);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3413_499a9c6b,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,2952,2974,"/**
 *  @param model
 */
void setModelImpl(IModel<?> model) {
    if (getFlag(FLAG_MODEL_SET)) {
        if (model != null) {
            data_set(0, model);
        } else {
            data_remove(0);
            setFlag(FLAG_MODEL_SET, false);
        }
    } else {
        if (model != null) {
            data_insert(0, model);
            setFlag(FLAG_MODEL_SET, true);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3420_be97d017,Minor,wicket-core/src/main/java/org/apache/wicket/pageStore/DefaultPageStore.java,272,295,"/**
 *  @see org.apache.wicket.pageStore.IPageStore#restoreAfterSerialization(java.io.Serializable)
 */
public Object restoreAfterSerialization(final Serializable serializable) {
    if (serializable == null) {
        return null;
    } else if (!storeAfterSessionReplication() || serializable instanceof Page) {
        return serializable;
    } else if (serializable instanceof SerializedPage) {
        SerializedPage page = (SerializedPage) serializable;
        if (page.getData() != null) {
            storePageData(page.getSessionId(), page.getPageId(), page.getData());
            return new SerializedPage(page.getSessionId(), page.getPageId(), null);
        }
        return page;
    }
    String type = serializable.getClass().getName();
    throw new IllegalArgumentException(""Unknown object type "" + type);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3428_ffc0cae9,Major,wicket-core/src/main/java/org/apache/wicket/request/cycle/RequestCycle.java,197,232,"/**
 *  Processes the request.
 *
 *  @return <code>true</code> if the request resolved to a Wicket request, <code>false</code>
 *          otherwise.
 */
public boolean processRequest() {
    try {
        set(this);
        IRequestHandler handler = resolveRequestHandler();
        if (handler != null) {
            executeRequestHandler(handler);
            return true;
        }
        // Did not find any suitable handler, thus not executing the request
        log.debug(""No suitable handler found for URL {}, falling back to container to process this request"", request.getUrl());
    } catch (Exception e) {
        IRequestHandler handler = handleException(e);
        if (handler != null) {
            executeExceptionRequestHandler(handler, getExceptionRetryCount());
        } else {
            log.error(""Error during request processing. URL="" + request.getUrl(), e);
        }
        return true;
    } finally {
        set(null);
    }
    return false;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3428_ffc0cae9,Major,wicket-core/src/main/java/org/apache/wicket/request/cycle/RequestCycle.java,240,254,"/**
 *  Convenience method that processes the request and detaches the {@link RequestCycle}.
 *
 *  @return <code>true</code> if the request resolved to a Wicket request, <code>false</code>
 *          otherwise.
 */
public boolean processRequestAndDetach() {
    boolean result;
    try {
        listeners.onBeginRequest(this);
        onBeginRequest();
        result = processRequest();
    } finally {
        detach();
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3454_f1e854b3,Major,wicket-core/src/main/java/org/apache/wicket/markup/resolver/WicketMessageResolver.java,332,386,"/**
 *  If the tag is of form <wicket:message>{foo}</wicket:message> then scan for any child
 *  wicket component and save their tag index
 *
 *  @param markupStream
 *  @param openTag
 *  @return map of child components
 */
private Map<String, CharSequence> findAndRenderChildWicketTags(final MarkupStream markupStream, final ComponentTag openTag) {
    Map<String, CharSequence> childTags = new HashMap<String, CharSequence>();
    // get original tag from markup because we modified openTag to always be open
    ComponentTag tag = markupStream.getPreviousTag();
    // child component and save their tag index
    if (!tag.isOpenClose()) {
        while (markupStream.hasMore() && !markupStream.get().closes(openTag)) {
            MarkupElement element = markupStream.get();
            // If it a tag like <wicket..> or <span wicket:id=""..."" >
            if ((element instanceof ComponentTag) && !markupStream.atCloseTag()) {
                String id = ((ComponentTag) element).getId();
                // Temporarily replace the web response with a String response
                final Response webResponse = getResponse();
                try {
                    final StringResponse response = new StringResponse();
                    getRequestCycle().setResponse(response);
                    Component component = getParent().get(id);
                    if (component != null) {
                        component.render();
                        markupStream.skipComponent();
                    } else {
                        markupStream.next();
                    }
                    childTags.put(id, response.getBuffer());
                } finally {
                    // Restore the original response
                    getRequestCycle().setResponse(webResponse);
                }
            } else {
                markupStream.next();
            }
        }
    }
    return childTags;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3455_f30bd1cb,Major,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,616,641,"/**
 *  Removes all children from this container.
 *  <p>
 *  Note: implementation does not call {@link MarkupContainer#remove(Component) } for each
 *  component.
 */
public final void removeAll() {
    if (children != null) {
        addStateChange();
        // Loop through child components
        int size = children_size();
        for (int i = 0; i < size; i++) {
            Object childObject = children_get(i, false);
            if (childObject instanceof Component) {
                // Get next child
                final Component child = (Component) childObject;
                // Do not call remove() because the state change would than be
                // recorded twice.
                child.detachModel();
                child.setParent(null);
            }
        }
        children = null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3510_292a2582,Major,wicket-datetime/src/main/java/org/apache/wicket/datetime/markup/html/form/DateTextField.java,133,136,"/**
 *  Creates a new DateTextField defaulting to using a short date pattern
 *
 *  @param id
 *             The id of the text field
 *  @return DateTextField
 */
public static DateTextField forShortStyle(String id) {
    return forShortStyle(id, null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3510_292a2582,Major,wicket-datetime/src/main/java/org/apache/wicket/datetime/markup/html/form/DateTextField.java,147,150,"/**
 *  Creates a new DateTextField defaulting to using a short date pattern
 *
 *  @param id
 *             The id of the text field
 *  @param model
 *             The model
 *  @return DateTextField
 */
public static DateTextField forShortStyle(String id, IModel<Date> model) {
    return new DateTextField(id, model, new StyleDateConverter(true));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3510_292a2582,Major,wicket-datetime/src/main/java/org/apache/wicket/extensions/yui/calendar/DateTimeField.java,378,381,"/**
 *  create a new {@link DateTextField} instance to be added to this panel.
 *
 *  @param id
 *             the component id
 *  @param dateFieldModel
 *             model that should be used by the {@link DateTextField}
 *  @return a new date text field instance
 */
protected DateTextField newDateTextField(String id, PropertyModel<Date> dateFieldModel) {
    return DateTextField.forShortStyle(id, dateFieldModel);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3511_4a875f46,Major,wicket-core/src/main/java/org/apache/wicket/util/resource/locator/CachingResourceStreamLocator.java,52,52,String getReference();
wicket,remotes/origin/bugs-dot-jar_WICKET-3511_4a875f46,Major,wicket-core/src/main/java/org/apache/wicket/util/resource/locator/CachingResourceStreamLocator.java,64,67,"public String getReference() {
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3511_4a875f46,Major,wicket-core/src/main/java/org/apache/wicket/util/resource/locator/CachingResourceStreamLocator.java,82,85,"public String getReference() {
    return fileName;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3511_4a875f46,Major,wicket-core/src/main/java/org/apache/wicket/util/resource/locator/CachingResourceStreamLocator.java,100,103,"public String getReference() {
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3511_4a875f46,Major,wicket-core/src/main/java/org/apache/wicket/util/resource/locator/CachingResourceStreamLocator.java,133,146,"/**
 *  {@inheritDoc}
 *
 *  Checks for {@link IResourceStreamReference} in the cache and returns <code>null</code> if the
 *  result is {@link NullResourceStreamReference#INSTANCE}, or {@link FileResourceStream} /
 *  {@link UrlResourceStream} if there is an entry in the cache. Otherwise asks the delegate to
 *  find one and puts it in the cache.
 */
public IResourceStream locate(Class<?> clazz, String path) {
    Key key = new Key(clazz.getName(), path, null, null, null);
    IResourceStream resourceStream = getCopyFromCache(key);
    if (resourceStream == null) {
        resourceStream = delegate.locate(clazz, path);
        updateCache(key, resourceStream);
    }
    return resourceStream;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3511_4a875f46,Major,wicket-core/src/main/java/org/apache/wicket/util/resource/locator/CachingResourceStreamLocator.java,175,205,"/**
 *  Make a copy before returning an item from the cache as resource streams are not thread-safe.
 *
 *  @param key
 *             the cache key
 *  @return the cached File or Url resource stream
 */
private IResourceStream getCopyFromCache(Key key) {
    final IResourceStreamReference orig = cache.get(key);
    if (NullResourceStreamReference.INSTANCE == orig) {
        return null;
    }
    if (orig instanceof UrlResourceStreamReference) {
        UrlResourceStreamReference resourceStreamReference = (UrlResourceStreamReference) orig;
        String url = resourceStreamReference.getReference();
        try {
            return new UrlResourceStream(new URL(url));
        } catch (MalformedURLException e) {
            return null;
        }
    }
    if (orig instanceof FileResourceStreamReference) {
        FileResourceStreamReference resourceStreamReference = (FileResourceStreamReference) orig;
        String absolutePath = resourceStreamReference.getReference();
        return new FileResourceStream(new File(absolutePath));
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3511_4a875f46,Major,wicket-core/src/main/java/org/apache/wicket/util/resource/locator/CachingResourceStreamLocator.java,207,222,"public IResourceStream locate(Class<?> scope, String path, String style, String variation, Locale locale, String extension, boolean strict) {
    Key key = new Key(scope.getName(), path, locale, style, variation);
    IResourceStream resourceStream = getCopyFromCache(key);
    if (resourceStream == null) {
        resourceStream = delegate.locate(scope, path, style, variation, locale, extension, strict);
        updateCache(key, resourceStream);
    }
    return resourceStream;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3514_2b6da516,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/CryptoMapper.java,116,150,"private Url encryptUrl(final Url url) {
    if (url.getSegments().isEmpty() && url.getQueryParameters().isEmpty()) {
        return url;
    }
    String encryptedUrlString = getCrypt().encryptUrlSafe(url.toString());
    Url encryptedUrl = new Url(url.getCharset());
    encryptedUrl.getSegments().add(encryptedUrlString);
    int numberOfSegments = url.getSegments().size();
    if (numberOfSegments == 0 && !url.getQueryParameters().isEmpty()) {
        numberOfSegments = 1;
    }
    char[] encryptedChars = encryptedUrlString.toCharArray();
    int hash = 0;
    for (int segNo = 0; segNo < numberOfSegments; segNo++) {
        char a = encryptedChars[Math.abs(hash % encryptedChars.length)];
        hash++;
        char b = encryptedChars[Math.abs(hash % encryptedChars.length)];
        hash++;
        char c = encryptedChars[Math.abs(hash % encryptedChars.length)];
        String segment = """" + a + b + c;
        hash = hashString(segment);
        segment += String.format(""%02x"", Math.abs(hash % 256));
        encryptedUrl.getSegments().add(segment);
        hash = hashString(segment);
    }
    return encryptedUrl;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3514_2b6da516,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/CryptoMapper.java,152,223,"private Url decryptUrl(final Request request, final Url encryptedUrl) {
    if (encryptedUrl.getSegments().isEmpty() && encryptedUrl.getQueryParameters().isEmpty()) {
        return encryptedUrl;
    }
    List<String> segments = encryptedUrl.getSegments();
    if (segments.size() < 2) {
        return null;
    }
    Url url = new Url(request.getCharset());
    try {
        String encryptedUrlString = segments.get(0);
        if (Strings.isEmpty(encryptedUrlString)) {
            return null;
        }
        String decryptedUrl = getCrypt().decryptUrlSafe(encryptedUrlString);
        Url originalUrl = Url.parse(decryptedUrl, request.getCharset());
        int originalNumberOfSegments = originalUrl.getSegments().size();
        if (originalNumberOfSegments == 0 && originalUrl.getQueryParameters().isEmpty() == false) {
            originalNumberOfSegments = 1;
        }
        int numberOfSegments = encryptedUrl.getSegments().size();
        char[] encryptedChars = encryptedUrlString.toCharArray();
        int hash = 0;
        int segNo;
        for (segNo = 1; segNo < numberOfSegments && segNo < originalNumberOfSegments + 1; segNo++) {
            char a = encryptedChars[Math.abs(hash % encryptedChars.length)];
            hash++;
            char b = encryptedChars[Math.abs(hash % encryptedChars.length)];
            hash++;
            char c = encryptedChars[Math.abs(hash % encryptedChars.length)];
            String segment = """" + a + b + c;
            hash = hashString(segment);
            segment += String.format(""%02x"", Math.abs(hash % 256));
            hash = hashString(segment);
            if (segment.equals(segments.get(segNo)) && originalUrl.getSegments().size() >= segNo) {
                url.getSegments().add(originalUrl.getSegments().get(segNo - 1));
            } else {
                break;
            }
        }
        url.getQueryParameters().addAll(originalUrl.getQueryParameters());
    } catch (Exception e) {
        log.error(""Error decrypting URL"", e);
        url = null;
    }
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3520_d1b62639,Major,wicket-core/src/main/java/org/apache/wicket/DefaultExceptionMapper.java,64,127,"private IRequestHandler internalMap(Exception e) {
    final Application application = Application.get();
    // check if we are processing an Ajax request and if we want to invoke the failure handler
    if (isProcessingAjaxRequest()) {
        switch(application.getExceptionSettings().getAjaxErrorHandlingStrategy()) {
            case INVOKE_FAILURE_HANDLER:
                return new ErrorCodeRequestHandler(500);
        }
    }
    if (e instanceof StalePageException) {
        // (the url should always be updated by an redirect in that case)
        return new RenderPageRequestHandler(new PageProvider(((StalePageException) e).getPage()));
    } else if (e instanceof PageExpiredException) {
        return createPageRequestHandler(new PageProvider(Application.get().getApplicationSettings().getPageExpiredErrorPage()));
    } else if (e instanceof AuthorizationException || e instanceof ListenerInvocationNotAllowedException) {
        return createPageRequestHandler(new PageProvider(Application.get().getApplicationSettings().getAccessDeniedPage()));
    } else if (e instanceof ResponseIOException) {
        logger.error(""Connection lost, give up responding."", e);
        return new EmptyRequestHandler();
    } else {
        final UnexpectedExceptionDisplay unexpectedExceptionDisplay = application.getExceptionSettings().getUnexpectedExceptionDisplay();
        logger.error(""Unexpected error occurred"", e);
        if (IExceptionSettings.SHOW_EXCEPTION_PAGE.equals(unexpectedExceptionDisplay)) {
            Page currentPage = extractCurrentPage();
            return createPageRequestHandler(new PageProvider(new ExceptionErrorPage(e, currentPage)));
        } else if (IExceptionSettings.SHOW_INTERNAL_ERROR_PAGE.equals(unexpectedExceptionDisplay)) {
            return createPageRequestHandler(new PageProvider(application.getApplicationSettings().getInternalErrorPage()));
        } else {
            // IExceptionSettings.SHOW_NO_EXCEPTION_PAGE
            return new EmptyRequestHandler();
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3539_a4459ef4,Major,wicket-core/src/main/java/org/apache/wicket/ComponentEventSender.java,146,191,"/**
 *  Depth broadcast
 *
 *  @param event
 *             event
 */
private void depth(final ComponentEvent<?> event) {
    IEventSink sink = event.getSink();
    boolean targetsApplication = sink instanceof Application;
    boolean targetsSession = targetsApplication || sink instanceof Session;
    boolean targetsCycle = targetsSession || sink instanceof RequestCycle;
    boolean targetsComponnet = sink instanceof Component;
    if (!targetsComponnet && !targetsCycle) {
        dispatcher.dispatchEvent(sink, event);
        return;
    }
    Component cursor = (targetsCycle) ? source.getPage() : (Component) sink;
    if (cursor instanceof MarkupContainer) {
        Visits.visitPostOrder(cursor, new ComponentEventVisitor(event, dispatcher));
    }
    if (event.isStop()) {
        return;
    }
    if (targetsCycle) {
        dispatcher.dispatchEvent(source.getRequestCycle(), event);
    }
    if (event.isStop()) {
        return;
    }
    if (targetsSession) {
        dispatcher.dispatchEvent(source.getSession(), event);
    }
    if (event.isStop()) {
        return;
    }
    if (targetsApplication) {
        dispatcher.dispatchEvent(source.getApplication(), event);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3563_c62b66c1,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,2455,2474,"/**
 *  Renders a placeholder tag for the component when it is invisible and
 *  {@link #setOutputMarkupPlaceholderTag(boolean)} has been called with <code>true</code>.
 *
 *  @param tag
 *             component tag
 *  @param response
 *             response
 */
protected void renderPlaceholderTag(final ComponentTag tag, final Response response) {
    String ns = Strings.isEmpty(tag.getNamespace()) ? null : tag.getNamespace() + "":"";
    response.write(""<"");
    if (ns != null) {
        response.write(ns);
    }
    response.write(tag.getName());
    response.write("" id=\"""");
    response.write(getMarkupId());
    response.write(""\"" style=\""display:none\""></"");
    if (ns != null) {
        response.write(ns);
    }
    response.write(tag.getName());
    response.write("">"");
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3563_c62b66c1,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AjaxRequestTarget.java,744,782,"/**
 *  Processes components added to the target. This involves attaching components, rendering
 *  markup into a client side xml envelope, and detaching them
 *
 *  @param response
 */
private void respondComponents(Response response) {
    // process component markup
    for (Map.Entry<String, Component> stringComponentEntry : markupIdToComponent.entrySet()) {
        final Component component = stringComponentEntry.getValue();
        if (!containsAncestorFor(component)) {
            respondComponent(response, getAjaxRegionMarkupId(component), component);
        }
    }
    if (header != null) {
        // some header responses buffer all calls to render*** until close is called.
        // when they are closed, they do something (i.e. aggregate all JS resource urls to a
        // single url), and then ""flush"" (by writing to the real response) before closing.
        // to support this, we need to allow header contributions to be written in the close
        // tag, which we do here:
        headerRendering = true;
        // save old response, set new
        Response oldResponse = RequestCycle.get().setResponse(encodingHeaderResponse);
        encodingHeaderResponse.reset();
        // now, close the response (which may render things)
        header.getHeaderResponse().close();
        // revert to old response
        RequestCycle.get().setResponse(oldResponse);
        // write the XML tags and we're done
        writeHeaderContribution(response);
        headerRendering = false;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3563_c62b66c1,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AjaxRequestTarget.java,806,828,"private String getAjaxRegionMarkupId(Component component) {
    String markupId = null;
    for (Behavior behavior : component.getBehaviors()) {
        if (behavior instanceof IAjaxRegionMarkupIdProvider) {
            markupId = ((IAjaxRegionMarkupIdProvider) behavior).getAjaxRegionMarkupId(component);
        }
    }
    if (markupId == null) {
        if (component instanceof IAjaxRegionMarkupIdProvider) {
            markupId = ((IAjaxRegionMarkupIdProvider) component).getAjaxRegionMarkupId(component);
        }
    }
    if (markupId == null) {
        markupId = component.getMarkupId();
    }
    return markupId;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3598_7c364566,Major,wicket-datetime/src/main/java/org/apache/wicket/datetime/StyleDateConverter.java,119,123,"/**
 *  @return formatter The formatter for the current conversion
 */
@Override
protected DateTimeFormatter getFormat(Locale locale) {
    return DateTimeFormat.forPattern(getDatePattern(locale)).withPivotYear(2000);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3603_aa1d177a,Major,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/repeater/data/table/DataTable.java,323,331,"private void addToolbar(final AbstractToolbar toolbar, final RepeatingView container) {
    if (toolbar == null) {
        throw new IllegalArgumentException(""argument [toolbar] cannot be null"");
    }
    container.add(toolbar);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3617_7ae109a6,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/render/WebPageRenderer.java,142,267,"/*
	 * TODO: simplify the code below. See WICKET-3347
	 */
@Override
public void respond(RequestCycle requestCycle) {
    Url currentUrl = requestCycle.getUrlRenderer().getBaseUrl();
    Url targetUrl = requestCycle.mapUrlFor(getRenderPageRequestHandler());
    // 
    // the code below is little hairy but we have to handle 3 redirect policies,
    // 3 rendering strategies and two kind of requests (ajax and normal)
    // 
    // try to get an already rendered buffered response for current URL
    BufferedWebResponse bufferedResponse = getAndRemoveBufferedResponse(currentUrl);
    boolean isAjax = isAjax(requestCycle);
    boolean shouldPreserveClientUrl = ((WebRequest) requestCycle.getRequest()).shouldPreserveClientUrl();
    if (bufferedResponse != null) {
        logger.warn(""The Buffered response should be handled by BufferedResponseRequestHandler"");
        // if there is saved response for this URL render it
        bufferedResponse.writeTo((WebResponse) requestCycle.getResponse());
    } else if (// 
    getRedirectPolicy() == RedirectPolicy.NEVER_REDIRECT || isOnePassRender() || (// 
    !isAjax && // 
    (targetUrl.equals(currentUrl) && !getPageProvider().isNewPageInstance() && !getPage().isPageStateless()) || // 
    (targetUrl.equals(currentUrl) && isRedirectToRender())) || // 
    shouldPreserveClientUrl) {
        // if the policy is never to redirect
        // or one pass render mode is on
        // or the targetUrl matches current url and the page is not stateless
        // or the targetUrl matches current url, page is stateless but it's redirect-to-render
        // or the request determines that the current url should be preserved
        // just render the page
        BufferedWebResponse response = renderPage(currentUrl, requestCycle);
        if (response != null) {
            response.writeTo((WebResponse) requestCycle.getResponse());
        }
    } else if (// 
    (!targetUrl.equals(currentUrl) && getRedirectPolicy() == RedirectPolicy.ALWAYS_REDIRECT) || // 
    isRedirectToRender() || (isAjax && targetUrl.equals(currentUrl))) {
        // if target URL is different
        // and render policy is always-redirect or it's redirect-to-render
        redirectTo(targetUrl, requestCycle);
    } else if (// 
    !targetUrl.equals(currentUrl) && (getPageProvider().isNewPageInstance() || (isSessionTemporary() && getPage().isPageStateless()))) {
        // if target URL is different and session is temporary and page is stateless
        // this is special case when page is stateless but there is no session so we can't
        // render it to buffer
        // alternatively if URLs are different and we have a page class and not an instance we
        // can redirect to the url which will instantiate the instance of us
        // note: if we had session here we would render the page to buffer and then redirect to
        // URL generated *after* page has been rendered (the statelessness may change during
        // render). this would save one redirect because now we have to render to URL generated
        // *before* page is rendered, render the page, get URL after render and if the URL is
        // different (meaning page is not stateless), save the buffer and redirect again (which
        // is pretty much what the next step does)
        redirectTo(targetUrl, requestCycle);
    } else if (isRedirectToBuffer()) {
        // redirect to buffer
        BufferedWebResponse response = renderPage(targetUrl, requestCycle);
        if (response == null) {
            return;
        }
        // check if the url hasn't changed after page has been rendered
        // (i.e. the stateless flag might have changed which could result in different page url)
        Url targetUrl2 = requestCycle.mapUrlFor(getRenderPageRequestHandler());
        if (targetUrl.getSegments().equals(targetUrl2.getSegments()) == false) {
            // the amount of segments is different - generated relative URLs will not work, we
            // need to rerender the page. This shouldn't happen, but in theory it can - with
            // RequestHandlerEncoders that produce different URLs with different amount of
            // segments for stateless and stateful pages
            response = renderPage(targetUrl2, requestCycle);
        }
        if (currentUrl.equals(targetUrl2)) {
            // no need to redirect when both urls are exactly the same
            response.writeTo((WebResponse) requestCycle.getResponse());
        } else // if page is still stateless after render
        if (getPage().isPageStateless() && !enableRedirectForStatelessPage()) {
            // we don't want the redirect to happen for stateless page
            // example:
            // when a normal mounted stateful page is hit at /mount/point
            // wicket renders the page to buffer and redirects to /mount/point?12
            // but for stateless page the redirect is not necessary
            // also for listener interface on stateful page we want to redirect
            // after the listener is invoked, but on stateless page the user
            // must ask for redirect explicitly
            response.writeTo((WebResponse) requestCycle.getResponse());
        } else {
            storeBufferedResponse(targetUrl2, response);
            redirectTo(targetUrl2, requestCycle);
        }
    } else {
        throw new IllegalStateException(""Unknown RenderStrategy."");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3618_fbfd17e6,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/BufferedWebResponse.java,481,489,"/**
 *  Writes the content of the buffer to the specified response. Also sets the properties and and
 *  headers.
 *
 *  @param response
 */
public void writeTo(final WebResponse response) {
    Args.notNull(response, ""response"");
    for (Action action : actions) {
        action.invoke(response);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3620_1a2bc1bc,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AjaxRequestTarget.java,561,616,"/**
 *  @see org.apache.wicket.request.handler.IPageRequestHandler#respond(org.apache.wicket.request.IRequestCycle)
 */
public final void respond(final IRequestCycle requestCycle) {
    // do not increment page id during ajax processing
    boolean frozen = page.setFreezePageId(true);
    try {
        final RequestCycle rc = (RequestCycle) requestCycle;
        final WebResponse response = (WebResponse) requestCycle.getResponse();
        if (markupIdToComponent.values().contains(page)) {
            // the page itself has been added to the request target, we simply issue a redirect
            // back to the page
            IRequestHandler handler = new RenderPageRequestHandler(new PageProvider(page));
            final String url = rc.urlFor(handler).toString();
            response.sendRedirect(url);
            return;
        }
        for (ITargetRespondListener listener : respondListeners) {
            listener.onTargetRespond(this);
        }
        final Application app = Application.get();
        page.send(app, Broadcast.BREADTH, this);
        // Determine encoding
        final String encoding = app.getRequestCycleSettings().getResponseRequestEncoding();
        // Set content type based on markup type for page
        response.setContentType(""text/xml; charset="" + encoding);
        // Make sure it is not cached by a client
        response.disableCaching();
        try {
            final StringResponse bodyResponse = new StringResponse();
            contructResponseBody(bodyResponse, encoding);
            invokeResponseFilters(bodyResponse);
            response.write(bodyResponse.getBuffer());
        } finally {
            // restore the original response
            RequestCycle.get().setResponse(response);
        }
    } finally {
        page.setFreezePageId(frozen);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3620_1a2bc1bc,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AjaxRequestTarget.java,674,690,"/**
 *  Runs the configured {@link IResponseFilter}s over the constructed Ajax response
 *
 *  @param contentResponse
 *             the Ajax {@link Response} body
 */
private void invokeResponseFilters(final StringResponse contentResponse) {
    AppendingStringBuffer responseBuffer = new AppendingStringBuffer(contentResponse.getBuffer());
    List<IResponseFilter> responseFilters = Application.get().getRequestCycleSettings().getResponseFilters();
    if (responseFilters != null) {
        for (IResponseFilter filter : responseFilters) {
            filter.filter(responseBuffer);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3620_1a2bc1bc,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/BufferedWebResponse.java,131,149,"@Override
protected void invoke(WebResponse response) {
    AppendingStringBuffer responseBuffer = new AppendingStringBuffer(builder);
    List<IResponseFilter> responseFilters = Application.get().getRequestCycleSettings().getResponseFilters();
    if (responseFilters != null) {
        for (IResponseFilter filter : responseFilters) {
            filter.filter(responseBuffer);
        }
    }
    response.write(builder);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3644_ab1856db,Major,wicket-core/src/main/java/org/apache/wicket/request/cycle/RequestCycleListenerCollection.java,60,89,"public IRequestHandler onException(final RequestCycle cycle, final Exception ex) {
    final List<IRequestHandler> handlers = new ArrayList<IRequestHandler>();
    notify(new INotifier<IRequestCycleListener>() {

        public void notify(IRequestCycleListener listener) {
            IRequestHandler handler = listener.onException(cycle, ex);
            if (handler != null) {
                handlers.add(handler);
            }
        }
    });
    if (handlers.isEmpty()) {
        return null;
    }
    if (handlers.size() > 1) {
        throw new WicketRuntimeException(""More than one request cycle listener returned a request handler while handling the exception."", ex);
    }
    return handlers.get(0);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3646_12124902,Minor,wicket-core/src/main/java/org/apache/wicket/request/cycle/RequestCycle.java,667,672,"/**
 *  {@inheritDoc}
 */
public void scheduleRequestHandlerAfterCurrent(IRequestHandler handler) {
    // just delegating the call to {@link IRequestHandlerExecutor} and invoking listeners
    requestHandlerExecutor.schedule(handler);
    listeners.onRequestHandlerScheduled(handler);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3647_1b57b51c,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,1500,1514,"/**
 *  Get the markupId
 *
 *  @return MarkupId
 */
public final Object getMarkupIdImpl() {
    String id = getMarkupIdFromMarkup();
    if (id != null) {
        return id;
    }
    if (generatedMarkupId != -1) {
        return generatedMarkupId;
    }
    return getMetaData(MARKUP_ID_KEY);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3713_e1168a57,Minor,wicket-core/src/main/java/org/apache/wicket/protocol/http/request/UserAgent.java,84,111,"/**
 *  @param userAgent
 *             The user agent string
 *  @return Whether the user agent matches this enum or not
 */
public boolean matches(String userAgent) {
    if (notAllowedList != null) {
        for (String value : notAllowedList) {
            if (userAgent.contains(value)) {
                return false;
            }
        }
    }
    for (List<String> detectionGroup : detectionStrings) {
        for (String detectionString : detectionGroup) {
            if (!userAgent.contains(detectionString)) {
                return false;
            }
        }
        return true;
    }
    return false;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3715_557de7bc,Trivial,wicket-core/src/main/java/org/apache/wicket/markup/html/form/upload/FileUpload.java,248,254,"/**
 *  Convenience method that copies the input stream returned by {@link #getInputStream()} into a
 *  temporary file.
 *  <p>
 *  Only use this if you actually need a {@link File} to work with, in all other cases use
 *  {@link #getInputStream()} or {@link #getBytes()}
 *
 *  @since 1.2
 *
 *  @return temporary file containing the contents of the uploaded file
 *  @throws IOException
 */
public final File writeToTempFile() throws IOException {
    File temp = File.createTempFile(Session.get().getId(), Files.cleanupFilename(item.getFieldName()));
    writeTo(temp);
    return temp;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3719_5ad32df9,Major,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,128,213,"/**
 *  Adds a child component to this container.
 *
 *  @param childs
 *             The child(s)
 *  @throws IllegalArgumentException
 *              Thrown if a child with the same id is replaced by the add operation.
 *  @return This
 */
public final MarkupContainer add(final Component... childs) {
    for (Component child : childs) {
        if (child == null) {
            throw new IllegalArgumentException(""argument child may not be null"");
        }
        MarkupContainer parent = getParent();
        while (parent != null) {
            if (child == parent) {
                String msg = ""You can not add a component's parent as child to the component (loop): Component: "" + this.toString(false) + ""; parent == child: "" + parent.toString(false);
                if (child instanceof Border.BorderBodyContainer) {
                    msg += "". Please consider using Border.addToBorder(new "" + this.getClass().getSimpleName() + ""(\"""" + this.getId() + ""\"", ...) instead of add(...)"";
                }
                throw new WicketRuntimeException(msg);
            }
            parent = parent.getParent();
        }
        checkHierarchyChange(child);
        if (log.isDebugEnabled()) {
            log.debug(""Add "" + child.getId() + "" to "" + this);
        }
        // Add to map
        addedComponent(child);
        if (put(child) != null) {
            throw new IllegalArgumentException(exceptionMessage(""A child with id '"" + child.getId() + ""' already exists""));
        }
        // Page.
        if (getMarkupType() != null) {
            // Check if the markup is available after the child has been added to the parent
            try {
                // If not yet triggered, than do now (e.g. Pages)
                if (getMarkup() != null) {
                    internalOnMarkupAttached();
                }
                if (child.getMarkup() != null) {
                    child.internalOnMarkupAttached();
                    // Tell all children of ""component"" as well
                    if (child instanceof MarkupContainer) {
                        MarkupContainer container = (MarkupContainer) child;
                        container.visitChildren(new IVisitor<Component, Void>() {

                            public void component(final Component component, final IVisit<Void> visit) {
                                if (component.internalOnMarkupAttached()) {
                                    visit.dontGoDeeper();
                                }
                            }
                        });
                    }
                }
            } catch (WicketRuntimeException exception) {
            // ignore
            }
        }
    }
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3719_5ad32df9,Major,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,899,942,"/**
 *  @param child
 *             Component being added
 */
private final void addedComponent(final Component child) {
    // Check for degenerate case
    if (child == this) {
        throw new IllegalArgumentException(""Component can't be added to itself"");
    }
    MarkupContainer parent = child.getParent();
    if (parent != null) {
        parent.remove(child);
    }
    // Set child's parent
    child.setParent(this);
    final IDebugSettings debugSettings = Application.get().getDebugSettings();
    if (debugSettings.isLinePreciseReportingOnAddComponentEnabled()) {
        child.setMetaData(ADDED_AT_KEY, ComponentStrings.toString(child, new MarkupException(""added"")));
    }
    final Page page = findPage();
    if (page != null) {
        // tell the page a component has been added first, to allow it to initialize
        page.componentAdded(child);
        // initialize the component
        if (page.isInitialized()) {
            child.internalInitialize();
        }
    }
    // beforeRender on this component's children. So we need to initialize the newly added one
    if (isPreparedForRender()) {
        child.beforeRender();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3719_5ad32df9,Major,wicket-core/src/main/java/org/apache/wicket/markup/Markup.java,188,221,"public final IMarkupFragment find(final String id) {
    if (Strings.isEmpty(id)) {
        throw new IllegalArgumentException(""Parameter 'id' must not be null or empty"");
    }
    MarkupStream stream = new MarkupStream(this);
    stream.setCurrentIndex(0);
    while (stream.hasMore()) {
        MarkupElement elem = stream.get();
        if (elem instanceof ComponentTag) {
            ComponentTag tag = stream.getTag();
            if (tag.isOpen() || tag.isOpenClose()) {
                if (tag.getId().equals(id)) {
                    return stream.getMarkupFragment();
                }
                if (tag.isOpen() && !tag.hasNoCloseTag() && !(tag instanceof WicketTag) && !""head"".equals(tag.getName()) && !tag.isAutoComponentTag()) {
                    stream.skipToMatchingCloseTag(tag);
                }
            }
        }
        stream.next();
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3719_5ad32df9,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/DefaultMarkupSourcingStrategy.java,76,135,"/**
 *  {@inheritDoc}
 */
public IMarkupFragment getMarkup(final MarkupContainer container, final Component child) {
    // If the sourcing strategy did not provide one, than ask the component.
    // Get the markup for the container
    IMarkupFragment markup = container.getMarkup();
    if (markup == null) {
        return null;
    }
    if (child == null) {
        return markup;
    }
    // Find the child's markup
    markup = markup.find(child.getId());
    if (markup != null) {
        return markup;
    }
    // This is to make migration for Items from 1.4 to 1.5 more easy
    if (Character.isDigit(child.getId().charAt(0))) {
        String id = child.getId();
        boolean miss = false;
        for (int i = 1; i < id.length(); i++) {
            if (Character.isDigit(id.charAt(i)) == false) {
                miss = true;
                break;
            }
        }
        if (miss == false) {
            // The LoopItems markup is equal to the Loops markup
            markup = container.getMarkup();
            if (!(child instanceof AbstractItem) && log.isWarnEnabled()) {
                log.warn(""1.4 to 1.5 migration issue: the childs wicket-id contains decimals only. "" + ""By convention that +"" + ""is only the case for children (Items) of Loop, ListView, "" + ""Tree etc.. To avoid the warning, the childs container should implement:\n"" + ""@Override public IMarkupFragment getMarkup(Component child) {\n"" + ""// The childs markup is always equal to the parents markup.\n"" + ""return getMarkup(); }\n"" + ""Child: "" + child.toString() + ""\nContainer: "" + container.toString());
            }
        }
    }
    return markup;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3764_48454f4d,Major,wicket-core/src/main/java/org/apache/wicket/Behaviors.java,70,77,"private void internalAdd(final Behavior behavior) {
    component.data_add(behavior);
    if (behavior.isStateless(component)) {
        getBehaviorId(behavior);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3764_48454f4d,Major,wicket-core/src/main/java/org/apache/wicket/behavior/Behavior.java,192,195,"/**
 *  Returns whether or not this behavior is stateless. Most behaviors should either not override
 *  this method or return {@code false} because most behavior are not stateless.
 *
 *  A small subset of behaviors are made specifically to be stateless and as such should override
 *  this method and return {@code true}. One sideeffect of this method is that the behavior id
 *  will be generated eagerly when the behavior is added to the component instead of before
 *  render when a method to create the url is called - this allows for stateless callback urls.
 *
 *  @param component
 *  @return whether or not this behavior is stateless
 */
public boolean isStateless(Component component) {
    return false;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3767_84c3baac,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/FormComponent.java,1395,1427,"/**
 *  Validates this component using the component's validators.
 */
@SuppressWarnings(""unchecked"")
protected final void validateValidators() {
    final IValidatable<T> validatable = newValidatable();
    boolean isNull = getConvertedInput() == null;
    IValidator<T> validator = null;
    try {
        for (Behavior behavior : getBehaviors()) {
            if (behavior instanceof IValidator) {
                validator = (IValidator<T>) behavior;
                if (isNull == false || validator instanceof INullAcceptingValidator<?>) {
                    validator.validate(validatable);
                }
                if (!isValid()) {
                    break;
                }
            }
        }
    } catch (Exception e) {
        throw new WicketRuntimeException(""Exception '"" + e + ""' occurred during validation "" + validator.getClass().getName() + "" on component "" + getPath(), e);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3769_b4e9d426,Major,wicket-core/src/main/java/org/apache/wicket/mock/MockSessionStore.java,87,95,"public void invalidate(Request request) {
    for (UnboundListener l : unboundListeners) {
        l.sessionUnbound(sessionId);
    }
    cleanup();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3834_30255f11,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,122,186,"/**
 *  Parses the given URL string.
 *
 *  @param url
 *  @param charset
 *  @return Url object
 */
public static Url parse(final String url, Charset charset) {
    Args.notNull(url, ""url"");
    Url result = new Url(charset);
    // the url object resolved the charset, use that
    charset = result.getCharset();
    String segments;
    String query;
    int qIndex = url.indexOf('?');
    if (qIndex == -1) {
        segments = url;
        query = """";
    } else {
        segments = url.substring(0, qIndex);
        query = url.substring(qIndex + 1);
    }
    if (segments.length() > 0) {
        boolean removeLast = false;
        if (segments.endsWith(""/"")) {
            // we need to append something and remove it after splitting
            // because otherwise the
            // trailing slashes will be lost
            segments += ""/x"";
            removeLast = true;
        }
        String[] segmentArray = Strings.split(segments, '/');
        if (removeLast) {
            segmentArray[segmentArray.length - 1] = null;
        }
        for (String s : segmentArray) {
            if (s != null) {
                result.segments.add(decodeSegment(s, charset));
            }
        }
    }
    if (query.length() > 0) {
        String[] queryArray = Strings.split(query, '&');
        for (String s : queryArray) {
            result.parameters.add(parseQueryParameter(s, charset));
        }
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3834_747bccb5,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,110,113,"/**
 *  Parses the given URL string.
 *
 *  @param url
 *  @return Url object
 */
public static Url parse(final String url) {
    return parse(url, null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3834_747bccb5,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,123,230,"/**
 *  Parses the given URL string.
 *
 *  @param url
 *            full absolute or relative url with query string
 *  @param charset
 *  @return Url object
 */
public static Url parse(String url, Charset charset) {
    Args.notNull(url, ""url"");
    Url result = new Url(charset);
    // the url object resolved the charset, use that
    charset = result.getCharset();
    // extract query string part
    final String queryString;
    final String absoluteUrl;
    int queryAt = url.indexOf('?');
    if (queryAt == -1) {
        queryString = """";
        absoluteUrl = url;
    } else {
        absoluteUrl = url.substring(0, queryAt);
        queryString = url.substring(queryAt + 1);
    }
    // get absolute / relative part of url
    String relativeUrl;
    // absolute urls contain a scheme://
    final int protocolAt = absoluteUrl.indexOf(""://"");
    if (protocolAt != -1) {
        result.protocol = absoluteUrl.substring(0, protocolAt);
        final String afterProto = absoluteUrl.substring(protocolAt + 3);
        final String hostAndPort;
        int relativeAt = afterProto.indexOf('/');
        if (relativeAt == -1) {
            relativeUrl = """";
            hostAndPort = afterProto;
        } else {
            relativeUrl = afterProto.substring(relativeAt);
            hostAndPort = afterProto.substring(0, relativeAt);
        }
        int portAt = hostAndPort.indexOf(':');
        if (portAt == -1) {
            result.host = hostAndPort;
            result.port = null;
        } else {
            result.host = hostAndPort.substring(0, portAt);
            result.port = Integer.parseInt(hostAndPort.substring(portAt + 1));
        }
    } else {
        relativeUrl = absoluteUrl;
    }
    if (relativeUrl.length() > 0) {
        boolean removeLast = false;
        if (relativeUrl.endsWith(""/"")) {
            // we need to append something and remove it after splitting
            // because otherwise the
            // trailing slashes will be lost
            relativeUrl += ""/x"";
            removeLast = true;
        }
        String[] segmentArray = Strings.split(relativeUrl, '/');
        if (removeLast) {
            segmentArray[segmentArray.length - 1] = null;
        }
        for (String s : segmentArray) {
            if (s != null) {
                result.segments.add(decodeSegment(s, charset));
            }
        }
    }
    if (queryString.length() > 0) {
        String[] queryArray = Strings.split(queryString, '&');
        for (String s : queryArray) {
            result.parameters.add(parseQueryParameter(s, charset));
        }
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3838_97514205,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/PackageMapper.java,95,108,"/**
 *  @see org.apache.wicket.request.mapper.AbstractBookmarkableMapper#buildUrl(org.apache.wicket.request.mapper.AbstractBookmarkableMapper.UrlInfo)
 */
@Override
protected Url buildUrl(UrlInfo info) {
    Class<? extends IRequestablePage> pageClass = info.getPageClass();
    if (PackageName.forClass(pageClass).equals(packageName)) {
        Url url = new Url();
        url.getSegments().add(pageClass.getSimpleName());
        encodePageComponentInfo(url, info.getPageComponentInfo());
        return encodePageParameters(url, info.getPageParameters(), pageParametersEncoder);
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3845_afc7034d,Major,wicket-request/src/main/java/org/apache/wicket/request/HttpHeaderCollection.java,99,105,"/**
 *  add header value
 *
 *  @param name
 *           header name
 *  @param value
 *           header value
 */
public void addHeader(String name, String value) {
    // be lenient and strip leading / trailing blanks
    value = Args.notEmpty(value, ""value"").trim();
    internalAdd(name, value);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3861_d1e0e411,Minor,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,1810,1824,"@Override
protected void onAfterRenderChildren() {
    // Loop through child components
    final Iterator<? extends Component> iter = iterator();
    while (iter.hasNext()) {
        // Get next child
        final Component child = iter.next();
        // Call end request on the child
        child.afterRender();
    }
    super.onAfterRenderChildren();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3861_d1e0e411,Minor,wicket-core/src/main/java/org/apache/wicket/markup/transformer/AbstractTransformerBehavior.java,61,65,"@Override
public void onComponentTag(final Component component, final ComponentTag tag) {
    tag.put(""xmlns:wicket"", ""http://wicket.apache.org"");
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3861_d1e0e411,Minor,wicket-core/src/main/java/org/apache/wicket/markup/transformer/XsltTransformerBehavior.java,69,77,"@Override
public void onComponentTag(final Component component, final ComponentTag tag) {
    tag.put(""xmlns:wicket"", ""http://wicket.apache.org/dtds.data/wicket-xhtml1.3-strict.dtd"");
    // Make the XSLT processor happy and allow it to handle the wicket tags
    // and attributes that are in the wicket namespace
    super.onComponentTag(component, tag);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3872_3feb0e3a,Major,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,628,656,"/**
 *  Removes all children from this container.
 *  <p>
 *  Note: implementation does not call {@link MarkupContainer#remove(Component) } for each
 *  component.
 *
 *  @return {@code this} for method chaining
 */
public MarkupContainer removeAll() {
    if (children != null) {
        addStateChange();
        // Loop through child components
        int size = children_size();
        for (int i = 0; i < size; i++) {
            Object childObject = children_get(i, false);
            if (childObject instanceof Component) {
                // Get next child
                final Component child = (Component) childObject;
                // Do not call remove() because the state change would than be
                // recorded twice.
                child.internalOnRemove();
                child.detachModel();
                child.setParent(null);
            }
        }
        children = null;
    }
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3884_b772ff87,Trivial,wicket-core/src/main/java/org/apache/wicket/behavior/AttributeAppender.java,150,163,"@Override
protected String newValue(String currentValue, String appendValue) {
    // Short circuit when one of the values is empty: return the other value.
    if (Strings.isEmpty(currentValue))
        return appendValue != null ? appendValue : """";
    else if (Strings.isEmpty(appendValue))
        return currentValue != null ? currentValue : """";
    StringBuilder sb = new StringBuilder(currentValue);
    sb.append((getSeparator() == null ? """" : getSeparator()));
    sb.append(appendValue);
    return sb.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3885_beb9086d,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/servlet/ServletWebResponse.java,238,275,"@Override
public void sendRedirect(String url) {
    try {
        redirect = true;
        url = getAbsoluteURL(url);
        url = encodeRedirectURL(url);
        // wicket redirects should never be cached
        disableCaching();
        if (webRequest.isAjax()) {
            httpServletResponse.addHeader(""Ajax-Location"", url);
            /*
				 * usually the Ajax-Location header is enough and we do not need to the redirect url
				 * into the response, but sometimes the response is processed via an iframe (eg
				 * using multipart ajax handling) and the headers are not available because XHR is
				 * not used and that is the only way javascript has access to response headers.
				 */
            httpServletResponse.getWriter().write(""<ajax-response><redirect><![CDATA["" + url + ""]]></redirect></ajax-response>"");
            setContentType(""text/xml;charset="" + webRequest.getContainerRequest().getCharacterEncoding());
        } else {
            httpServletResponse.sendRedirect(url);
        }
    } catch (IOException e) {
        throw new WicketRuntimeException(e);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3906_aadaa4e9,Major,wicket-request/src/main/java/org/apache/wicket/request/mapper/parameter/PageParameters.java,484,488,"/**
 *  @see org.apache.wicket.request.mapper.parameter.INamedParameters#set(java.lang.String,
 *       java.lang.Object)
 */
public PageParameters set(final String name, final Object value) {
    set(name, value, -1);
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3931_8fbdc68f,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,1133,1180,"/**
 *  Detaches the component. This is called at the end of the request for all the pages that are
 *  touched in that request.
 */
public final void detach() {
    // if the component has been previously attached via attach()
    // detach it now
    setFlag(FLAG_DETACHING, true);
    onDetach();
    if (getFlag(FLAG_DETACHING)) {
        throw new IllegalStateException(Component.class.getName() + "" has not been properly detached. Something in the hierarchy of "" + getClass().getName() + "" has not called super.onDetach() in the override of onDetach() method"");
    }
    // always detach models because they can be attached without the
    // component. eg component has a compoundpropertymodel and one of its
    // children component's getmodelobject is called
    detachModels();
    // detach any behaviors
    new Behaviors(this).detach();
    // always detach children because components can be attached
    // independently of their parents
    detachChildren();
    // The model will be created next time.
    if (getFlag(FLAG_INHERITABLE_MODEL)) {
        setModelImpl(null);
        setFlag(FLAG_INHERITABLE_MODEL, false);
    }
    clearEnabledInHierarchyCache();
    clearVisibleInHierarchyCache();
    requestFlags = 0;
    // notify any detach listener
    IDetachListener detachListener = getApplication().getFrameworkSettings().getDetachListener();
    if (detachListener != null) {
        detachListener.onDetach(this);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3931_8fbdc68f,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,3055,3072,"/**
 *  Render a placeholder tag when the component is not visible. The tag is of form:
 *  &lt;componenttag style=""display:none;"" id=""markupid""/&gt;. This method will also call
 *  <code>setOutputMarkupId(true)</code>.
 *
 *  This is useful, for example, in ajax situations where the component starts out invisible and
 *  then becomes visible through an ajax update. With a placeholder tag already in the markup you
 *  do not need to repaint this component's parent, instead you can repaint the component
 *  directly.
 *
 *  When this method is called with parameter <code>false</code> the outputmarkupid flag is not
 *  reverted to false.
 *
 *  @param outputTag
 *  @return this for chaining
 */
public final Component setOutputMarkupPlaceholderTag(final boolean outputTag) {
    if (outputTag != getFlag(FLAG_PLACEHOLDER)) {
        if (outputTag) {
            setOutputMarkupId(true);
            setFlag(FLAG_PLACEHOLDER, true);
        } else {
            setFlag(FLAG_PLACEHOLDER, false);
        // I think it's better to not setOutputMarkupId to false...
        // user can do it if we want
        }
    }
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3965_6051019b,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,3284,3299,"/**
 *  Gets a URL for the listener interface on a behavior (e.g. IBehaviorListener on
 *  AjaxPagingNavigationBehavior).
 *
 *  @param behaviour
 *             The behavior that the URL should point to
 *  @param listener
 *             The listener interface that the URL should call
 *  @return The URL
 */
public final CharSequence urlFor(final Behavior behaviour, final RequestListenerInterface listener) {
    PageAndComponentProvider provider = new PageAndComponentProvider(getPage(), this);
    int id = getBehaviorId(behaviour);
    IRequestHandler handler;
    if (getPage().isPageStateless()) {
        handler = new BookmarkableListenerInterfaceRequestHandler(provider, listener, id);
    } else {
        handler = new ListenerInterfaceRequestHandler(provider, listener, id);
    }
    return getRequestCycle().urlFor(handler);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3965_6051019b,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,3325,3338,"/**
 *  Gets a URL for the listener interface (e.g. ILinkListener).
 *
 *  @see RequestCycle#urlFor(IRequestHandler)
 *
 *  @param listener
 *             The listener interface that the URL should call
 *  @return The URL
 */
public final CharSequence urlFor(final RequestListenerInterface listener) {
    PageAndComponentProvider provider = new PageAndComponentProvider(getPage(), this);
    IRequestHandler handler;
    if (getPage().isPageStateless()) {
        handler = new BookmarkableListenerInterfaceRequestHandler(provider, listener);
    } else {
        handler = new ListenerInterfaceRequestHandler(provider, listener);
    }
    return getRequestCycle().urlFor(handler);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3965_6051019b,Major,wicket-core/src/main/java/org/apache/wicket/mock/MockPageManager.java,79,82,"public void touchPage(IManageablePage page) {
    pages.put(page.getPageId(), page);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3989_6a8fc1cc,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/AssociatedMarkupSourcingStrategy.java,89,123,"/**
 *  Search for the child's markup in the associated markup file.
 *
 *  @param parent
 *             The container expected to contain the markup for child
 *  @param child
 *             The child component to find the markup for
 *  @return The markup associated with the child
 */
@Override
public IMarkupFragment getMarkup(final MarkupContainer parent, final Component child) {
    Args.notNull(tagName, ""tagName"");
    IMarkupFragment associatedMarkup = parent.getAssociatedMarkup();
    if (associatedMarkup == null) {
        throw new MarkupNotFoundException(""Failed to find markup file associated. "" + parent.getClass().getSimpleName() + "": "" + parent.toString());
    }
    // Find <wicket:panel>
    IMarkupFragment markup = findStartTag(associatedMarkup);
    if (markup == null) {
        throw new MarkupNotFoundException(""Expected to find <wicket:"" + tagName + ""> in associated markup file. Markup: "" + associatedMarkup.toString());
    }
    // If child == null, than return the markup fragment starting with <wicket:panel>
    if (child == null) {
        return markup;
    }
    // Find the markup for the child component
    associatedMarkup = markup.find(child.getId());
    if (associatedMarkup != null) {
        return associatedMarkup;
    }
    return findMarkupInAssociatedFileHeader(parent, child);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3989_6a8fc1cc,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/DefaultMarkupSourcingStrategy.java,61,63,"/**
 *  Nothing to add to the response by default
 */
public void onComponentTag(final Component component, final ComponentTag tag) {
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3989_6a8fc1cc,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/DefaultMarkupSourcingStrategy.java,68,72,"/**
 *  Invoke the component's onComponentTagBody().
 */
public void onComponentTagBody(final Component component, final MarkupStream markupStream, final ComponentTag openTag) {
    component.onComponentTagBody(markupStream, openTag);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3989_6a8fc1cc,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/DefaultMarkupSourcingStrategy.java,77,154,"/**
 *  Get the markup for the child component, which is assumed to be a child of 'container'.
 */
public IMarkupFragment getMarkup(final MarkupContainer container, final Component child) {
    // If the sourcing strategy did not provide one, than ask the component.
    // Get the markup for the container
    IMarkupFragment markup = container.getMarkup();
    if (markup == null) {
        return null;
    }
    if (child == null) {
        return markup;
    }
    // Find the child's markup
    markup = markup.find(child.getId());
    if (markup != null) {
        return markup;
    }
    // ""synchronous"" search possible.
    for (Component ch : container) {
        if ((ch != child) && (ch instanceof MarkupContainer) && (ch instanceof IComponentResolver)) {
            markup = ((MarkupContainer) ch).getMarkup(child);
            if (markup != null) {
                return markup;
            }
        }
    }
    // This is to make migration for Items from 1.4 to 1.5 more easy
    if (Character.isDigit(child.getId().charAt(0))) {
        String id = child.getId();
        boolean miss = false;
        for (int i = 1; i < id.length(); i++) {
            if (Character.isDigit(id.charAt(i)) == false) {
                miss = true;
                break;
            }
        }
        if (miss == false) {
            // The LoopItems markup is equal to the Loops markup
            markup = container.getMarkup();
            if (!(child instanceof AbstractItem) && log.isWarnEnabled()) {
                log.warn(""1.4 to 1.5 migration issue: the childs wicket-id contains decimals only. "" + ""By convention that "" + ""is only the case for children (Items) of Loop, ListView, "" + ""Tree etc.. To avoid the warning, the childs container should implement:\n"" + ""@Override public IMarkupFragment getMarkup(Component child) {\n"" + ""// The childs markup is always equal to the parents markup.\n"" + ""return getMarkup(); }\n"" + ""Child: "" + child.toString() + ""\nContainer: "" + container.toString());
            }
        }
    }
    return markup;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3989_6a8fc1cc,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/DefaultMarkupSourcingStrategy.java,159,161,"/**
 *  Empty: nothing will be added to the header by default
 */
public void renderHead(final Component component, HtmlHeaderContainer container) {
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-3989_6a8fc1cc,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/IMarkupSourcingStrategy.java,87,87,"/**
 *  Will <b>replace</b> the respective component's method. However by returning null, the
 *  component's method will be called.
 *
 *  @see MarkupContainer#getMarkup(Component)
 *
 *  @param container
 *             The parent containing the child. (@TODO Is container ever != child.getParent()??)
 *  @param child
 *             The component to find the markup for.
 *  @return markup fragment
 */
IMarkupFragment getMarkup(final MarkupContainer container, final Component child);"
wicket,remotes/origin/bugs-dot-jar_WICKET-3998_b76f9c44,Minor,wicket-core/src/main/java/org/apache/wicket/validation/validator/CreditCardValidator.java,536,547,"/**
 *  Check if the credit card is a Visa. A Visa number has to start with a 4 and has to have a
 *  length of 13 or 16 digits. The number has to be validated with the Luhn algorithm.
 *
 *  @param creditCardNumber
 *             the credit card number as a string
 *  @return The credit card id of the issuer
 */
private CreditCard isVisa(String creditCardNumber) {
    if (creditCardNumber.length() == 13 || creditCardNumber.length() == 16) {
        if (creditCardNumber.startsWith(""4"")) {
            return CreditCard.SWITCH;
        }
    }
    return CreditCard.INVALID;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4000_38e928c1,Major,wicket-core/src/main/java/org/apache/wicket/markup/renderStrategy/ChildFirstHeaderRenderStrategy.java,69,93,"/**
 *  Render the child hierarchy headers.
 *
 *  @param headerContainer
 *  @param rootComponent
 */
@Override
protected void renderChildHeaders(final HtmlHeaderContainer headerContainer, final Component rootComponent) {
    Args.notNull(headerContainer, ""headerContainer"");
    Args.notNull(rootComponent, ""rootComponent"");
    if (rootComponent instanceof MarkupContainer) {
        new DeepChildFirstVisitor() {

            @Override
            public void component(final Component component, final IVisit<Void> visit) {
                component.renderHead(headerContainer);
            }

            @Override
            public boolean preCheck(Component component) {
                return component.isVisibleInHierarchy();
            }
        }.visit(rootComponent);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4000_38e928c1,Major,wicket-core/src/main/java/org/apache/wicket/markup/renderStrategy/ChildFirstHeaderRenderStrategy.java,80,84,"@Override
public void component(final Component component, final IVisit<Void> visit) {
    component.renderHead(headerContainer);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4016_f1c9cef2,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,3206,3252,"/**
 *  @param detailed
 *             True if a detailed string is desired
 *  @return The string
 */
public String toString(final boolean detailed) {
    try {
        if (detailed) {
            final Page page = findPage();
            if (page == null) {
                return new StringBuilder(""[Component id = "").append(getId()).append("", page = <No Page>, path = "").append(getPath()).append('.').append(Classes.simpleName(getClass())).append(']').toString();
            } else {
                return new StringBuilder(""[Component id = "").append(getId()).append("", page = "").append(getPage().getClass().getName()).append("", path = "").append(getPath()).append('.').append(Classes.simpleName(getClass())).append("", isVisible = "").append((determineVisibility())).append("", isVersioned = "").append(isVersioned()).append(']').toString();
            }
        } else {
            return ""[Component id = "" + getId() + ']';
        }
    } catch (Exception e) {
        log.warn(""Error while building toString()"", e);
        return String.format(""[Component id = %s <attributes are not available because exception %s was thrown during toString()>]"", getId(), e.getClass().getName());
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4016_f1c9cef2,Major,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,859,892,"/**
 *  @param detailed
 *             True if a detailed string is desired
 *  @return String representation of this container
 */
@Override
public String toString(final boolean detailed) {
    final StringBuilder buffer = new StringBuilder();
    buffer.append(""["").append(this.getClass().getSimpleName()).append("" "");
    buffer.append(super.toString(detailed));
    if (detailed) {
        if (getMarkup() != null) {
            buffer.append("", markup = "").append(new MarkupStream(getMarkup()).toString());
        }
        if (children_size() != 0) {
            buffer.append("", children = "");
            // Loop through child components
            final int size = children_size();
            for (int i = 0; i < size; i++) {
                // Get next child
                final Component child = children_get(i);
                if (i != 0) {
                    buffer.append(' ');
                }
                buffer.append(child.toString());
            }
        }
    }
    buffer.append(']');
    return buffer.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4020_081cdeb2,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/ResourceMapper.java,234,252,"protected void removeCachingDecoration(Url url, PageParameters parameters) {
    final List<String> segments = url.getSegments();
    if (segments.isEmpty() == false) {
        final int lastSegmentAt = segments.size() - 1;
        final ResourceUrl resourceUrl = new ResourceUrl(segments.get(lastSegmentAt), parameters);
        getCachingStrategy().undecorateUrl(resourceUrl);
        if (Strings.isEmpty(resourceUrl.getFileName())) {
            throw new IllegalStateException(""caching strategy returned empty name for "" + resourceUrl);
        }
        segments.set(lastSegmentAt, resourceUrl.getFileName());
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4030_5f69685d,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/internal/HeaderResponse.java,385,397,"/**
 *  @param location
 *  @return relative path
 */
private String relative(final String location) {
    Args.notEmpty(location, ""location"");
    if (location.startsWith(""http://"") || location.startsWith(""https://"") || location.startsWith(""/"")) {
        return location;
    }
    RequestCycle rc = RequestCycle.get();
    return rc.getUrlRenderer().renderUrl(Url.parse(location, rc.getRequest().getCharset()));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4038_f3d7565c,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/AbstractBookmarkableMapper.java,89,99,"/**
 *  Cleans the original parameters from entries used by Wicket internals.
 *
 *  @param originalParameters
 *             the current request's non-modified parameters
 *  @return all parameters but Wicket internal ones
 */
private PageParameters cleanPageParameters(final PageParameters originalParameters) {
    PageParameters cleanParameters = new PageParameters(originalParameters);
    // WICKET-4038: Ajax related parameters are set by wicket-ajax.js when needed.
    // They shouldn't be propagated to the next requests
    cleanParameters.remove(WebRequest.PARAM_AJAX);
    cleanParameters.remove(WebRequest.PARAM_AJAX_BASE_URL);
    return cleanParameters;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4066_4d3d1f85,Major,wicket-core/src/main/java/org/apache/wicket/RestartResponseAtInterceptPageException.java,166,169,"public int getCompatibilityScore(Request request) {
    return 0;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4066_4d3d1f85,Major,wicket-core/src/main/java/org/apache/wicket/RestartResponseAtInterceptPageException.java,176,197,"public IRequestHandler mapRequest(Request request) {
    InterceptData data = InterceptData.get();
    if (data != null) {
        if (data.originalUrl.equals(request.getOriginalUrl())) {
            if (data.postParameters.isEmpty() == false && request.getPostParameters() instanceof IWritableRequestParameters) {
                IWritableRequestParameters parameters = (IWritableRequestParameters) request.getPostParameters();
                parameters.reset();
                for (String s : data.postParameters.keySet()) {
                    parameters.setParameterValues(s, data.postParameters.get(s));
                }
            }
            InterceptData.clear();
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4070_d450acb0,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Form.java,757,825,"/**
 *  Process the form. Though you can override this method to provide your own algorithm, it is
 *  not recommended to do so.
 *
 *  <p>
 *  See the class documentation for further details on the form processing
 *  </p>
 *
 *  @param submittingComponent
 *             component responsible for submitting the form, or <code>null</code> if none (eg
 *             the form has been submitted via the enter key or javascript calling
 *             form.onsubmit())
 *
 *  @see #delegateSubmit(IFormSubmitter) for an easy way to process submitting component in the
 *       default manner
 */
public void process(IFormSubmitter submittingComponent) {
    // save the page in case the component is removed during submit
    final Page page = getPage();
    String hiddenFieldId = getHiddenFieldId();
    if (!isEnabledInHierarchy() || !isVisibleInHierarchy()) {
        // FIXME throw listener exception
        return;
    }
    // run validation
    validate();
    // If a validation error occurred
    if (hasError()) {
        // mark all children as invalid
        markFormComponentsInvalid();
        // let subclass handle error
        callOnError(submittingComponent);
    } else {
        // mark all children as valid
        markFormComponentsValid();
        // before updating, call the interception method for clients
        beforeUpdateFormComponentModels();
        // Update model using form data
        updateFormComponentModels();
        // validate model objects after input values have been bound
        onValidateModelObjects();
        if (hasError()) {
            callOnError(submittingComponent);
        }
        // Form has no error
        delegateSubmit(submittingComponent);
    }
    // If the form is stateless page parameters contain all form component
    // values. We need to remove those otherwise they get appended to action URL
    final PageParameters parameters = page.getPageParameters();
    if (parameters != null) {
        visitFormComponents(new IVisitor<FormComponent<?>, Void>() {

            public void component(final FormComponent<?> formComponent, final IVisit<Void> visit) {
                parameters.remove(formComponent.getInputName());
            }
        });
        parameters.remove(hiddenFieldId);
        if (submittingComponent instanceof AbstractSubmitLink) {
            AbstractSubmitLink submitLink = (AbstractSubmitLink) submittingComponent;
            parameters.remove(submitLink.getInputName());
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4072_7d5b8645,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,112,115,"/**
 *  Parses the given URL string.
 *
 *  @param url
 *            absolute or relative url with query string
 *  @return Url object
 */
public static Url parse(final String url) {
    return parse(url, null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4072_7d5b8645,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,125,233,"/**
 *  Parses the given URL string.
 *
 *  @param url
 *            absolute or relative url with query string
 *  @param charset
 *  @return Url object
 */
public static Url parse(String url, Charset charset) {
    Args.notNull(url, ""url"");
    final Url result = new Url(charset);
    // the url object resolved the charset, use that
    charset = result.getCharset();
    // extract query string part
    final String queryString;
    final String absoluteUrl;
    final int queryAt = url.indexOf('?');
    if (queryAt == -1) {
        queryString = """";
        absoluteUrl = url;
    } else {
        absoluteUrl = url.substring(0, queryAt);
        queryString = url.substring(queryAt + 1);
    }
    // get absolute / relative part of url
    String relativeUrl;
    // absolute urls contain a scheme://
    final int protocolAt = absoluteUrl.indexOf(""://"");
    if (protocolAt != -1) {
        result.protocol = absoluteUrl.substring(0, protocolAt).toLowerCase(Locale.US);
        final String afterProto = absoluteUrl.substring(protocolAt + 3);
        final String hostAndPort;
        final int relativeAt = afterProto.indexOf('/');
        if (relativeAt == -1) {
            relativeUrl = """";
            hostAndPort = afterProto;
        } else {
            relativeUrl = afterProto.substring(relativeAt);
            hostAndPort = afterProto.substring(0, relativeAt);
        }
        final int portAt = hostAndPort.lastIndexOf(':');
        if (portAt == -1) {
            result.host = hostAndPort;
            result.port = getDefaultPortForProtocol(result.protocol);
        } else {
            result.host = hostAndPort.substring(0, portAt);
            result.port = Integer.parseInt(hostAndPort.substring(portAt + 1));
        }
    } else {
        relativeUrl = absoluteUrl;
    }
    if (relativeUrl.length() > 0) {
        boolean removeLast = false;
        if (relativeUrl.endsWith(""/"")) {
            // we need to append something and remove it after splitting
            // because otherwise the
            // trailing slashes will be lost
            relativeUrl += ""/x"";
            removeLast = true;
        }
        String[] segmentArray = Strings.split(relativeUrl, '/');
        if (removeLast) {
            segmentArray[segmentArray.length - 1] = null;
        }
        for (String s : segmentArray) {
            if (s != null) {
                result.segments.add(decodeSegment(s, charset));
            }
        }
    }
    if (queryString.length() > 0) {
        String[] queryArray = Strings.split(queryString, '&');
        for (String s : queryArray) {
            result.parameters.add(parseQueryParameter(s, charset));
        }
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4072_7d5b8645,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,242,260,"/**
 *  get default port number for protocol
 *
 *  @param protocol
 *            name of protocol
 *  @return default port for protocol or <code>null</code> if unknown
 */
private static Integer getDefaultPortForProtocol(String protocol) {
    if (""http"".equals(protocol)) {
        return 80;
    } else if (""https"".equals(protocol)) {
        return 443;
    } else if (""ftp"".equals(protocol)) {
        return 21;
    } else {
        return null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4072_7d5b8645,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,598,601,"/**
 *  render full representation of url (including protocol, host and port)
 *  into string representation
 */
public String toAbsoluteString() {
    return toAbsoluteString(getCharset());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4072_7d5b8645,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,611,633,"/**
 *  render full representation of url (including protocol, host and port)
 *  into string representation
 *
 *  @param charset
 *
 *  @return see toStringRepresentation
 */
public String toAbsoluteString(final Charset charset) {
    StringBuilder result = new StringBuilder();
    // output scheme://host:port if specified
    if (protocol != null && Strings.isEmpty(host) == false) {
        result.append(protocol);
        result.append(""://"");
        result.append(host);
        if (port != null && port.equals(getDefaultPortForProtocol(protocol)) == false) {
            result.append(':');
            result.append(port);
        }
    }
    // append relative part
    result.append(this.toString());
    // return url string
    return result.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4072_7d5b8645,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,881,905,"/**
 *  Makes this url the result of resolving the {@code relative} url against this url.
 *  <p>
 *  Segments will be properly resolved, handling any {@code ..} references, while the query
 *  parameters will be completely replaced with {@code relative}'s query parameters.
 *  </p>
 *  <p>
 *  For example:
 *
 *  <pre>
 *  wicket/page/render?foo=bar
 *  </pre>
 *
 *  resolved with
 *
 *  <pre>
 *  ../component/render?a=b
 *  </pre>
 *
 *  will become
 *
 *  <pre>
 *  wicket/component/render?a=b
 *  </pre>
 *
 *  </p>
 *
 *  @param relative
 *             relative url
 */
public void resolveRelative(final Url relative) {
    // strip the first non-folder segment
    getSegments().remove(getSegments().size() - 1);
    // remove all './' (current folder) from the relative url
    if (!relative.getSegments().isEmpty() && ""."".equals(relative.getSegments().get(0))) {
        relative.getSegments().remove(0);
    }
    // process any ../ segments in the relative url
    while (!relative.getSegments().isEmpty() && "".."".equals(relative.getSegments().get(0))) {
        relative.getSegments().remove(0);
        getSegments().remove(getSegments().size() - 1);
    }
    // append the remaining relative segments
    getSegments().addAll(relative.getSegments());
    // replace query params with the ones from relative
    parameters.clear();
    parameters.addAll(relative.getQueryParameters());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4072_7d5b8645,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,975,992,"/**
 *  return path for current url in given encoding
 *
 *  @param charset
 *            character set for encoding
 *
 *  @return path string
 */
public String getPath(Charset charset) {
    Args.notNull(charset, ""charset"");
    StringBuilder path = new StringBuilder();
    boolean slash = false;
    for (String segment : getSegments()) {
        if (slash) {
            path.append('/');
        }
        path.append(encodeSegment(segment, charset));
        slash = true;
    }
    return path.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4072_7d5b8645,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,999,1002,"/**
 *  return path for current url in original encoding
 *
 *  @return path string
 */
public String getPath() {
    return getPath(getCharset());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4072_7d5b8645,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,1012,1024,"/**
 *  return query string part of url in given encoding
 *
 *  @param charset
 *           character set for encoding
 *
 *  @return query string
 */
public String getQueryString(Charset charset) {
    Args.notNull(charset, ""charset"");
    StringBuilder query = new StringBuilder();
    for (QueryParameter parameter : getQueryParameters()) {
        query.append(query.length() == 0 ? '?' : '&');
        query.append(parameter.toString(charset));
    }
    return query.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4099_1dcaec98,Minor,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/basic/LinkParser.java,57,80,"/**
 *  @see ILinkParser#parse(String)
 */
public String parse(final String text) {
    if (Strings.isEmpty(text)) {
        return text;
    }
    String work = text;
    for (String pattern : renderStrategies.keySet()) {
        ILinkRenderStrategy strategy = renderStrategies.get(pattern);
        Matcher matcher = Pattern.compile(pattern, Pattern.DOTALL).matcher(work);
        StringBuffer buffer = new StringBuffer();
        while (matcher.find()) {
            String str = matcher.group();
            matcher.appendReplacement(buffer, strategy.buildLink(str));
        }
        matcher.appendTail(buffer);
        work = buffer.toString();
    }
    return work;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4102_e743fd7e,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/AutoLabelTextResolver.java,130,203,"@Override
public void onComponentTagBody(final MarkupStream markupStream, final ComponentTag openTag) {
    boolean storeLabelText = false;
    // try and find some form of label content...
    String labelText = null;
    if (labeled instanceof ILabelProvider) {
        ILabelProvider<String> provider = (ILabelProvider<String>) labeled;
        if (provider.getLabel() != null) {
            String text = provider.getLabel().getObject();
            if (!Strings.isEmpty(text)) {
                labelText = text;
            }
        }
    }
    if (labelText == null && labeled instanceof FormComponent) {
        String text = ((FormComponent<?>) labeled).getDefaultLabel(""wicket:unknown"");
        if (!""wicket:unknown"".equals(text) && !Strings.isEmpty(text)) {
            labelText = text;
        }
    }
    // check if wicket:label tag has a message key
    if (labelText == null && openTag.getAttribute(""key"") != null) {
        String text = labeled.getString(openTag.getAttribute(""key""));
        if (!Strings.isEmpty(text)) {
            labelText = text;
            storeLabelText = true;
        }
    }
    // as last resort use the tag body
    if (labelText == null) {
        String text = new ResponseBufferZone(RequestCycle.get(), markupStream) {

            @Override
            protected void executeInsideBufferedZone() {
                TextLabel.super.onComponentTagBody(markupStream, openTag);
            }
        }.execute().toString();
        if (!Strings.isEmpty(text)) {
            labelText = text;
            storeLabelText = true;
        }
    }
    // print the label text
    replaceComponentTagBody(markupStream, openTag, labelText);
    // store the label text in FormComponent's label model so its available to errors
    if (labeled instanceof FormComponent) {
        FormComponent<?> fc = (FormComponent<?>) labeled;
        fc.setLabel(Model.of(labelText));
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4102_e743fd7e,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/AutoLabelTextResolver.java,180,184,"@Override
protected void executeInsideBufferedZone() {
    TextLabel.super.onComponentTagBody(markupStream, openTag);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4105_64656c98,Major,wicket-core/src/main/java/org/apache/wicket/markup/transformer/AbstractTransformerBehavior.java,55,58,"/**
 *  Create a new response object which is used to store the markup generated by the child
 *  objects.
 *
 *  @param originalResponse
 *
 *  @return Response object. Must not be null
 */
protected BufferedWebResponse newResponse(final WebResponse originalResponse) {
    return new BufferedWebResponse(originalResponse);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4105_64656c98,Major,wicket-core/src/main/java/org/apache/wicket/markup/transformer/AbstractTransformerBehavior.java,60,79,"@Override
public void beforeRender(Component component) {
    super.beforeRender(component);
    final RequestCycle requestCycle = RequestCycle.get();
    // Temporarily replace the web response with a String response
    webResponse = (WebResponse) requestCycle.getResponse();
    // Create a new response object
    final BufferedWebResponse response = newResponse(webResponse);
    if (response == null) {
        throw new IllegalStateException(""newResponse() must not return null"");
    }
    // and make it the current one
    requestCycle.setResponse(response);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4105_64656c98,Major,wicket-core/src/main/java/org/apache/wicket/markup/transformer/AbstractTransformerBehavior.java,81,104,"@Override
public void afterRender(final Component component) {
    final RequestCycle requestCycle = RequestCycle.get();
    try {
        BufferedWebResponse response = (BufferedWebResponse) requestCycle.getResponse();
        // Transform the data
        CharSequence output = transform(component, response.getText());
        response.setText(output);
        response.writeTo(webResponse);
    } catch (Exception ex) {
        throw new WicketRuntimeException(""Error while transforming the output: "" + this, ex);
    } finally {
        // Restore the original response object
        requestCycle.setResponse(webResponse);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4105_64656c98,Major,wicket-core/src/main/java/org/apache/wicket/markup/transformer/AbstractTransformerBehavior.java,106,111,"@Override
public void detach(Component component) {
    webResponse = null;
    super.detach(component);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4109_8f7805f8,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/PageProvider.java,288,303,"/**
 *  Looks up a page by id from the {@link IPageStore}. <br/>
 *  If {@linkplain #pageClass} is specified then compares it against the stored instance class
 *  and returns the found instance only if they match.
 *
 *  @param pageId
 *             the id of the page to look for.
 *  @return the found page instance by id.
 */
private IRequestablePage getStoredPage(final int pageId) {
    IRequestablePage storedPageInstance = getPageSource().getPageInstance(pageId);
    if (storedPageInstance != null && (pageClass == null || pageClass.equals(storedPageInstance.getClass()))) {
        pageInstance = storedPageInstance;
        if (pageParameters != null) {
            storedPageInstance.getPageParameters().overwriteWith(pageParameters);
        }
    }
    return storedPageInstance;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4116_4624ab3d,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/ListenerInterfaceRequestHandler.java,147,174,"/**
 *  @see org.apache.wicket.request.IRequestHandler#respond(org.apache.wicket.request.IRequestCycle)
 */
public void respond(final IRequestCycle requestCycle) {
    final IRequestablePage page = getPage();
    if (getComponent().getPage() == page) {
        boolean isAjax = ((WebRequest) requestCycle.getRequest()).isAjax();
        if (isAjax == false && listenerInterface.isRenderPageAfterInvocation()) {
            // schedule page render after current request handler is done. this can be
            // overridden during invocation of listener
            // method (i.e. by calling RequestCycle#setResponsePage)
            final IPageProvider pageProvider = new PageProvider(page);
            final RedirectPolicy policy = page.isPageStateless() ? RedirectPolicy.NEVER_REDIRECT : RedirectPolicy.AUTO_REDIRECT;
            requestCycle.scheduleRequestHandlerAfterCurrent(new RenderPageRequestHandler(pageProvider, policy));
        }
        invokeListener();
    } else {
        throw new WicketRuntimeException(""Component "" + getComponent() + "" has been removed from page."");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4116_4624ab3d,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/PageProvider.java,199,212,"/**
 *  The page instance is new only if there is no cached instance or the data stores doesn't have
 *  a page with that id with the same {@linkplain #pageClass}.
 *
 *  @see org.apache.wicket.request.handler.IPageProvider#isNewPageInstance()
 */
public boolean isNewPageInstance() {
    boolean isNew = pageInstance == null;
    if (isNew && pageId != null) {
        IRequestablePage storedPageInstance = getStoredPage(pageId);
        if (storedPageInstance != null) {
            pageInstance = storedPageInstance;
            isNew = false;
        }
    }
    return isNew;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4116_4624ab3d,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/PageProvider.java,288,297,"/**
 *  Looks up a page by id from the {@link IPageStore}. <br/>
 *  If {@linkplain #pageClass} is specified then compares it against the stored instance class
 *  and returns the found instance only if they match.
 *
 *  @param pageId
 *             the id of the page to look for.
 *  @return the found page instance by id.
 */
private IRequestablePage getStoredPage(final int pageId) {
    IRequestablePage storedPageInstance = getPageSource().getPageInstance(pageId);
    if (storedPageInstance != null && (pageClass == null || pageClass.equals(storedPageInstance.getClass()))) {
        pageInstance = storedPageInstance;
    }
    return storedPageInstance;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4119_bb7a6995,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/ByteArrayResource.java,93,133,"/**
 *  @see org.apache.wicket.request.resource.AbstractResource#newResourceResponse(org.apache.wicket.request.resource.IResource.Attributes)
 */
@Override
protected ResourceResponse newResourceResponse(final Attributes attributes) {
    final ResourceResponse response = new ResourceResponse();
    response.setContentType(contentType);
    response.setLastModified(lastModified);
    final byte[] data = getData(attributes);
    if (data == null) {
        throw new WicketRuntimeException(""ByteArrayResource's data cannot be 'null'."");
    }
    response.setContentLength(data.length);
    if (response.dataNeedsToBeWritten(attributes)) {
        if (filename != null) {
            response.setFileName(filename);
            response.setContentDisposition(ContentDisposition.ATTACHMENT);
        } else {
            response.setContentDisposition(ContentDisposition.INLINE);
        }
        response.setWriteCallback(new WriteCallback() {

            @Override
            public void writeData(final Attributes attributes) {
                attributes.getResponse().write(data);
            }
        });
        configureResponse(response, attributes);
    }
    return response;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4119_bb7a6995,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/PackageResource.java,240,311,"/**
 *  creates a new resource response based on the request attributes
 *
 *  @param attributes
 *             current request attributes from client
 *  @return resource response for answering request
 */
@Override
protected ResourceResponse newResourceResponse(Attributes attributes) {
    final ResourceResponse resourceResponse = new ResourceResponse();
    if (resourceResponse.dataNeedsToBeWritten(attributes)) {
        // get resource stream
        final IResourceStream resourceStream = getResourceStream();
        // bail out if resource stream could not be found
        if (resourceStream == null)
            return sendResourceError(resourceResponse, HttpServletResponse.SC_NOT_FOUND, ""Unable to find resource"");
        String contentType = resourceStream.getContentType();
        if (contentType == null && Application.exists()) {
            contentType = Application.get().getMimeType(path);
        }
        // set Content-Type (may be null)
        resourceResponse.setContentType(contentType);
        // add Last-Modified header (to support HEAD requests and If-Modified-Since)
        final Time lastModified = resourceStream.lastModifiedTime();
        if (lastModified != null)
            resourceResponse.setLastModified(lastModified);
        try {
            // read resource data
            final byte[] bytes;
            try {
                bytes = IOUtils.toByteArray(resourceStream.getInputStream());
            } finally {
                resourceStream.close();
            }
            final byte[] processed = processResponse(attributes, bytes);
            // send Content-Length header
            resourceResponse.setContentLength(processed.length);
            // send response body with resource data
            resourceResponse.setWriteCallback(new WriteCallback() {

                @Override
                public void writeData(Attributes attributes) {
                    attributes.getResponse().write(processed);
                }
            });
        } catch (IOException e) {
            log.debug(e.getMessage(), e);
            return sendResourceError(resourceResponse, 500, ""Unable to read resource stream"");
        } catch (ResourceStreamNotFoundException e) {
            log.debug(e.getMessage(), e);
            return sendResourceError(resourceResponse, 500, ""Unable to open resource stream"");
        }
    }
    return resourceResponse;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4119_bb7a6995,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/ResourceStreamResource.java,91,168,"@Override
protected ResourceResponse newResourceResponse(Attributes attributes) {
    ResourceResponse data = new ResourceResponse();
    Time lastModifiedTime = stream.lastModifiedTime();
    if (lastModifiedTime != null) {
        data.setLastModified(lastModifiedTime);
    }
    // performance check; don't bother to do anything if the resource is still cached by client
    if (data.dataNeedsToBeWritten(attributes)) {
        InputStream inputStream = null;
        if (stream instanceof IResourceStreamWriter == false) {
            try {
                inputStream = stream.getInputStream();
            } catch (ResourceStreamNotFoundException e) {
                data.setError(HttpServletResponse.SC_NOT_FOUND);
                close();
            }
        }
        data.setContentDisposition(contentDisposition);
        Bytes length = stream.length();
        if (length != null) {
            data.setContentLength(length.bytes());
        }
        data.setFileName(fileName);
        String contentType = stream.getContentType();
        if (contentType == null && fileName != null && Application.exists()) {
            contentType = Application.get().getMimeType(fileName);
        }
        data.setContentType(contentType);
        data.setTextEncoding(textEncoding);
        if (stream instanceof IResourceStreamWriter) {
            data.setWriteCallback(new WriteCallback() {

                @Override
                public void writeData(Attributes attributes) {
                    ((IResourceStreamWriter) stream).write(attributes.getResponse());
                    close();
                }
            });
        } else {
            final InputStream s = inputStream;
            data.setWriteCallback(new WriteCallback() {

                @Override
                public void writeData(Attributes attributes) {
                    try {
                        writeStream(attributes, s);
                    } finally {
                        close();
                    }
                }
            });
        }
    }
    return data;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4121_8967eb2b,Major,wicket-extensions/src/main/java/org/apache/wicket/extensions/wizard/Wizard.java,258,290,"/**
 *  Initialize this wizard with a transition model.
 *  <p>
 *  If you constructed this wizard using a constructor without the transitions model argument,
 *  <strong>you must</strong> call this method prior to actually using it.
 *  </p>
 *
 *  @param wizardModel
 */
protected void init(final IWizardModel wizardModel) {
    if (wizardModel == null) {
        throw new IllegalArgumentException(""argument wizardModel must be not null"");
    }
    this.wizardModel = wizardModel;
    form = newForm(FORM_ID);
    addOrReplace(form);
    // dummy view to be replaced
    form.addOrReplace(new WebMarkupContainer(HEADER_ID));
    form.addOrReplace(newFeedbackPanel(FEEDBACK_ID));
    // add dummy view; will be replaced on initialization
    form.addOrReplace(new WebMarkupContainer(VIEW_ID));
    form.addOrReplace(newButtonBar(BUTTONS_ID));
    form.addOrReplace(newOverviewBar(OVERVIEW_ID));
    wizardModel.addListener(this);
    Iterator<IWizardStep> stepsIterator = wizardModel.stepIterator();
    if (stepsIterator != null) {
        while (stepsIterator.hasNext()) {
            (stepsIterator.next()).init(wizardModel);
        }
    }
    // reset model to prepare for action
    wizardModel.reset();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4121_8967eb2b,Major,wicket-extensions/src/main/java/org/apache/wicket/extensions/wizard/WizardModel.java,216,221,"/**
 *  @see org.apache.wicket.extensions.wizard.IWizardModel#reset()
 */
public void reset() {
    history.clear();
    activeStep = null;
    setActiveStep(findNextVisibleStep());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4138_7c89598a,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/servlet/ServletWebRequest.java,123,151,"/**
 *  Returns base url without context or filter mapping.
 *  <p>
 *  Example: if current url is
 *
 *  <pre>
 *  http://localhost:8080/context/filter/mapping/wicket/bookmarkable/com.foo.Page?1&id=2
 *  </pre>
 *
 *  the base url is <em>wicket/bookmarkable/com.foo.Page</em>
 *  </p>
 *
 *  @see org.apache.wicket.request.Request#getClientUrl()
 */
@Override
public Url getClientUrl() {
    if (errorAttributes != null && !Strings.isEmpty(errorAttributes.getRequestUri())) {
        String problematicURI = Url.parse(errorAttributes.getRequestUri(), getCharset()).toString();
        return getContextRelativeUrl(problematicURI, filterPrefix);
    } else if (!isAjax()) {
        return getContextRelativeUrl(httpServletRequest.getRequestURI(), filterPrefix);
    } else {
        String base = null;
        base = getHeader(HEADER_AJAX_BASE_URL);
        if (base == null) {
            base = getRequestParameters().getParameterValue(PARAM_AJAX_BASE_URL).toString(null);
        }
        Checks.notNull(base, ""Current ajax request is missing the base url header or parameter"");
        return setParameters(Url.parse(base, getCharset()));
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4138_7c89598a,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/servlet/ServletWebRequest.java,456,460,"@Override
public boolean shouldPreserveClientUrl() {
    return errorAttributes != null && !Strings.isEmpty(errorAttributes.getRequestUri());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4153_2737d7c7,Trivial,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/repeater/data/table/DataTable.java,205,208,"/**
 *  Create the MarkupContainer for the <tbody> tag. Users may subclass it to provide their own
 *  (modified) implementation.
 *
 *  @param id
 *  @return A new markup container
 */
protected WebMarkupContainer newBodyContainer(final String id) {
    return new WebMarkupContainer(id);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4173_84bbbf68,Major,wicket-core/src/main/java/org/apache/wicket/request/cycle/RequestCycle.java,600,605,"/**
 *  Convenience method for setting next page to be rendered.
 *
 *  @param pageClass
 */
public void setResponsePage(Class<? extends IRequestablePage> pageClass) {
    IPageProvider provider = new PageProvider(pageClass, null);
    scheduleRequestHandlerAfterCurrent(new RenderPageRequestHandler(provider, RenderPageRequestHandler.RedirectPolicy.AUTO_REDIRECT));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4173_84bbbf68,Major,wicket-core/src/main/java/org/apache/wicket/request/cycle/RequestCycle.java,614,620,"/**
 *  Convenience method for setting next page to be rendered.
 *
 *  @param pageClass
 *  @param parameters
 */
public void setResponsePage(Class<? extends IRequestablePage> pageClass, PageParameters parameters) {
    IPageProvider provider = new PageProvider(pageClass, parameters);
    scheduleRequestHandlerAfterCurrent(new RenderPageRequestHandler(provider, RenderPageRequestHandler.RedirectPolicy.AUTO_REDIRECT));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4173_84bbbf68,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/render/WebPageRenderer.java,142,269,"/*
	 * TODO: simplify the code below. See WICKET-3347
	 */
@Override
public void respond(RequestCycle requestCycle) {
    Url currentUrl = requestCycle.getUrlRenderer().getBaseUrl();
    Url targetUrl = requestCycle.mapUrlFor(getRenderPageRequestHandler());
    // 
    // the code below is little hairy but we have to handle 3 redirect policies,
    // 3 rendering strategies and two kind of requests (ajax and normal)
    // 
    // try to get an already rendered buffered response for current URL
    BufferedWebResponse bufferedResponse = getAndRemoveBufferedResponse(currentUrl);
    boolean isAjax = isAjax(requestCycle);
    boolean shouldPreserveClientUrl = ((WebRequest) requestCycle.getRequest()).shouldPreserveClientUrl();
    if (bufferedResponse != null) {
        logger.warn(""The Buffered response should be handled by BufferedResponseRequestHandler"");
        // if there is saved response for this URL render it
        bufferedResponse.writeTo((WebResponse) requestCycle.getResponse());
    } else if (getRedirectPolicy() == RedirectPolicy.NEVER_REDIRECT || // 
    (isOnePassRender() && isAjax == false) || (// 
    !isAjax && // 
    (targetUrl.equals(currentUrl) && !getPageProvider().isNewPageInstance() && !getPage().isPageStateless()) || // 
    (targetUrl.equals(currentUrl) && isRedirectToRender())) || // 
    shouldPreserveClientUrl) {
        // if the policy is never to redirect
        // or one pass render mode is on
        // or the targetUrl matches current url and the page is not stateless
        // or the targetUrl matches current url, page is stateless but it's redirect-to-render
        // or the request determines that the current url should be preserved
        // just render the page
        BufferedWebResponse response = renderPage(currentUrl, requestCycle);
        if (response != null) {
            response.writeTo((WebResponse) requestCycle.getResponse());
        }
    } else if (// 
    getRedirectPolicy() == RedirectPolicy.ALWAYS_REDIRECT || // 
    isRedirectToRender() || (isAjax && targetUrl.equals(currentUrl))) {
        // if target URL is different
        // and render policy is always-redirect or it's redirect-to-render
        redirectTo(targetUrl, requestCycle);
    } else if (// 
    !targetUrl.equals(currentUrl) && (getPageProvider().isNewPageInstance() || (isSessionTemporary() && getPage().isPageStateless()))) {
        // if target URL is different and session is temporary and page is stateless
        // this is special case when page is stateless but there is no session so we can't
        // render it to buffer
        // alternatively if URLs are different and we have a page class and not an instance we
        // can redirect to the url which will instantiate the instance of us
        // note: if we had session here we would render the page to buffer and then redirect to
        // URL generated *after* page has been rendered (the statelessness may change during
        // render). this would save one redirect because now we have to render to URL generated
        // *before* page is rendered, render the page, get URL after render and if the URL is
        // different (meaning page is not stateless), save the buffer and redirect again (which
        // is pretty much what the next step does)
        redirectTo(targetUrl, requestCycle);
    } else {
        if (isRedirectToBuffer() == false && logger.isWarnEnabled()) {
            logger.warn(""Falling back to Redirect_To_Buffer render strategy because none of the conditions matched."");
        }
        // redirect to buffer
        BufferedWebResponse response = renderPage(targetUrl, requestCycle);
        if (response == null) {
            return;
        }
        // check if the url hasn't changed after page has been rendered
        // (i.e. the stateless flag might have changed which could result in different page url)
        Url targetUrl2 = requestCycle.mapUrlFor(getRenderPageRequestHandler());
        if (targetUrl.getSegments().equals(targetUrl2.getSegments()) == false) {
            // the amount of segments is different - generated relative URLs will not work, we
            // need to rerender the page. This shouldn't happen, but in theory it can - with
            // RequestHandlerEncoders that produce different URLs with different amount of
            // segments for stateless and stateful pages
            response = renderPage(targetUrl2, requestCycle);
        }
        if (currentUrl.equals(targetUrl2)) {
            // no need to redirect when both urls are exactly the same
            response.writeTo((WebResponse) requestCycle.getResponse());
        } else // if page is still stateless after render
        if (getPage().isPageStateless() && !enableRedirectForStatelessPage()) {
            // we don't want the redirect to happen for stateless page
            // example:
            // when a normal mounted stateful page is hit at /mount/point
            // wicket renders the page to buffer and redirects to /mount/point?12
            // but for stateless page the redirect is not necessary
            // also for listener interface on stateful page we want to redirect
            // after the listener is invoked, but on stateless page the user
            // must ask for redirect explicitly
            response.writeTo((WebResponse) requestCycle.getResponse());
        } else {
            storeBufferedResponse(targetUrl2, response);
            redirectTo(targetUrl2, requestCycle);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4184_a0150366,Major,wicket-util/src/main/java/org/apache/wicket/util/string/AppendingStringBuffer.java,941,953,"/**
 *  Inserts the string representation of the <code>Object</code> argument into this string
 *  buffer.
 *  <p>
 *  The second argument is converted to a string as if by the method <code>String.valueOf</code>,
 *  and the characters of that string are then inserted into this string buffer at the indicated
 *  offset.
 *  <p>
 *  The offset argument must be greater than or equal to <code>0</code>, and less than or equal
 *  to the length of this string buffer.
 *
 *  @param offset
 *             the offset.
 *  @param obj
 *             an <code>Object</code>.
 *  @return a reference to this <code>AppendingStringBuffer</code> object.
 *  @exception StringIndexOutOfBoundsException
 *                 if the offset is invalid.
 *  @see java.lang.String#valueOf(java.lang.Object)
 *  @see AppendingStringBuffer#insert(int, java.lang.String)
 *  @see AppendingStringBuffer#length()
 */
public AppendingStringBuffer insert(final int offset, final Object obj) {
    if (obj instanceof AppendingStringBuffer) {
        AppendingStringBuffer asb = (AppendingStringBuffer) obj;
        return insert(offset, asb.value, 0, asb.count);
    } else if (obj instanceof StringBuffer) {
        return insert(offset, obj);
    }
    return insert(offset, String.valueOf(obj));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4184_a0150366,Major,wicket-util/src/main/java/org/apache/wicket/util/string/AppendingStringBuffer.java,1042,1063,"/**
 *  Inserts the string into this string buffer.
 *  <p>
 *  The characters of the <code>String</code> argument are inserted, in order, into this string
 *  buffer at the indicated offset, moving up any characters originally above that position and
 *  increasing the length of this string buffer by the length of the argument. If
 *  <code>str</code> is <code>null</code>, then the four characters <code>""null""</code> are
 *  inserted into this string buffer.
 *  <p>
 *  The character at index <i>k</i> in the new character sequence is equal to:
 *  <ul>
 *  <li>the character at index <i>k</i> in the old character sequence, if <i>k</i> is less than
 *  <code>offset</code>
 *  <li>the character at index <i>k</i><code>-offset</code> in the argument <code>str</code>, if
 *  <i>k</i> is not less than <code>offset</code> but is less than
 *  <code>offset+str.length()</code>
 *  <li>the character at index <i>k</i><code>-str.length()</code> in the old character sequence,
 *  if <i>k</i> is not less than <code>offset+str.length()</code>
 *  </ul>
 *  <p>
 *  The offset argument must be greater than or equal to <code>0</code>, and less than or equal
 *  to the length of this string buffer.
 *
 *  @param offset
 *             the offset.
 *  @param str
 *             a string.
 *  @return a reference to this <code>AppendingStringBuffer</code> object.
 *  @exception StringIndexOutOfBoundsException
 *                 if the offset is invalid.
 *  @see java.lang.StringBuffer#length()
 */
public AppendingStringBuffer insert(final int offset, StringBuilder str) {
    if ((offset < 0) || (offset > count)) {
        throw new StringIndexOutOfBoundsException();
    }
    if (str == null) {
        str = SB_NULL;
    }
    int len = str.length();
    int newcount = count + len;
    if (newcount > value.length) {
        expandCapacity(newcount);
    }
    System.arraycopy(value, offset, value, offset + len, count - offset);
    str.getChars(0, len, value, offset);
    count = newcount;
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4185_5fd03973,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/ListenerInterfaceRequestHandler.java,250,254,"public final boolean isPageInstanceCreated() {
    // this request handler always operates on a created page instance
    return true;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4251_53bcb78d,Major,wicket-core/src/main/java/org/apache/wicket/RestartResponseAtInterceptPageException.java,106,121,"public static void set() {
    Session session = Session.get();
    session.bind();
    InterceptData data = new InterceptData();
    Request request = RequestCycle.get().getRequest();
    data.originalUrl = request.getOriginalUrl();
    data.postParameters = new HashMap<String, List<StringValue>>();
    for (String s : request.getPostParameters().getParameterNames()) {
        data.postParameters.put(s, new ArrayList<StringValue>(request.getPostParameters().getParameterValues(s)));
    }
    data.continueOk = false;
    session.setMetaData(key, data);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4255_c250db9c,Major,wicket-core/src/main/java/org/apache/wicket/validation/validator/UrlValidator.java,341,467,"/**
 *  Returns <code>true</code> if the authority is properly formatted. An authority is the
 *  combination of host name and port. A <code>null</code> authority value is considered invalid.
 *
 *  @param authority
 *             an authority value to validate
 *  @return true if authority (host name and port) is valid.
 */
protected boolean isValidAuthority(String authority) {
    if (authority == null) {
        return false;
    }
    Matcher authorityMatcher = Pattern.compile(AUTHORITY_PATTERN).matcher(authority);
    if (!authorityMatcher.matches()) {
        return false;
    }
    boolean ipV4Address = false;
    boolean hostname = false;
    // check if authority is IP address or hostname
    String hostIP = authorityMatcher.group(PARSE_AUTHORITY_HOST_IP);
    Matcher matchIPV4Pat = Pattern.compile(IP_V4_DOMAIN_PATTERN).matcher(hostIP);
    ipV4Address = matchIPV4Pat.matches();
    if (ipV4Address) {
        // this is an IP address so check components
        for (int i = 1; i <= 4; i++) {
            String ipSegment = matchIPV4Pat.group(i);
            if (ipSegment == null || ipSegment.length() <= 0) {
                return false;
            }
            try {
                if (Integer.parseInt(ipSegment) > 255) {
                    return false;
                }
            } catch (NumberFormatException e) {
                return false;
            }
        }
    } else {
        // Domain is hostname name
        hostname = Pattern.compile(DOMAIN_PATTERN).matcher(hostIP).matches();
    }
    // rightmost hostname will never start with a digit.
    if (hostname) {
        // LOW-TECH FIX FOR VALIDATOR-202
        // TODO: Rewrite to use ArrayList and .add semantics: see
        // VALIDATOR-203
        char[] chars = hostIP.toCharArray();
        int size = 1;
        for (char ch : chars) {
            if (ch == '.') {
                size++;
            }
        }
        String[] domainSegment = new String[size];
        boolean match = true;
        int segmentCount = 0;
        int segmentLength = 0;
        while (match) {
            Matcher atomMatcher = Pattern.compile(ATOM_PATTERN).matcher(hostIP);
            match = atomMatcher.find();
            if (match) {
                domainSegment[segmentCount] = atomMatcher.group(1);
                segmentLength = domainSegment[segmentCount].length() + 1;
                hostIP = (segmentLength >= hostIP.length()) ? """" : hostIP.substring(segmentLength);
                segmentCount++;
            }
        }
        if (segmentCount > 1) {
            String topLevel = domainSegment[segmentCount - 1];
            if (topLevel.length() < 2 || topLevel.length() > 4) {
                return false;
            }
            // First letter of top level must be a alpha
            Matcher alphaMatcher = Pattern.compile(ALPHA_PATTERN).matcher(topLevel.substring(0, 1));
            if (!alphaMatcher.matches()) {
                return false;
            }
        }
    }
    if (!hostname && !ipV4Address) {
        return false;
    }
    String port = authorityMatcher.group(PARSE_AUTHORITY_PORT);
    if (port != null) {
        Matcher portMatcher = Pattern.compile(PORT_PATTERN).matcher(port);
        if (!portMatcher.matches()) {
            return false;
        }
    }
    String extra = authorityMatcher.group(PARSE_AUTHORITY_EXTRA);
    if (!isBlankOrNull(extra)) {
        return false;
    }
    return true;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4256_09166ea8,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,970,992,"/**
 */
private final void internalBeforeRender() {
    configure();
    if ((determineVisibility()) && !getFlag(FLAG_RENDERING) && !getFlag(FLAG_PREPARED_FOR_RENDER)) {
        setRequestFlag(RFLAG_BEFORE_RENDER_SUPER_CALL_VERIFIED, false);
        getApplication().getComponentPreOnBeforeRenderListeners().onBeforeRender(this);
        onBeforeRender();
        getApplication().getComponentPostOnBeforeRenderListeners().onBeforeRender(this);
        if (!getRequestFlag(RFLAG_BEFORE_RENDER_SUPER_CALL_VERIFIED)) {
            throw new IllegalStateException(Component.class.getName() + "" has not been properly rendered. Something in the hierarchy of "" + getClass().getName() + "" has not called super.onBeforeRender() in the override of onBeforeRender() method"");
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4256_09166ea8,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,2189,2218,"/**
 *  THIS METHOD IS NOT PART OF THE WICKET PUBLIC API. DO NOT USE IT!
 *  <p>
 *  Prepares the component and it's children for rendering. On whole page render this method must
 *  be called on the page. On AJAX request, this method must be called on the updated component.
 *
 *  @param setRenderingFlag
 *             Whether to set the rendering flag. This must be true if the page is about to be
 *             rendered. However, there are usecases to call this method without an immediate
 *             render (e.g. on stateless listener request target to build the component
 *             hierarchy), in that case setRenderingFlag should be false.
 */
public void internalPrepareForRender(boolean setRenderingFlag) {
    beforeRender();
    if (setRenderingFlag) {
        // only process feedback panel when we are about to be rendered.
        // setRenderingFlag is false in case prepareForRender is called only to build component
        // hierarchy (i.e. in BookmarkableListenerInterfaceRequestTarget).
        // prepareForRender(true) is always called before the actual rendering is done so
        // that's where feedback panels gather the messages
        List<Component> feedbacks = getRequestCycle().getMetaData(FEEDBACK_LIST);
        if (feedbacks != null) {
            for (Component feedback : feedbacks) {
                feedback.internalBeforeRender();
            }
        }
        getRequestCycle().setMetaData(FEEDBACK_LIST, null);
    }
    markRendering(setRenderingFlag);
    // check authorization
    // first the component itself
    // (after attach as otherwise list views etc wont work)
    setRenderAllowed();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4259_1f128536,Minor,wicket-extensions/src/main/java/org/apache/wicket/extensions/ajax/markup/html/AjaxEditableLabel.java,390,397,"/**
 *  Gets the editor component.
 *
 *  @return The editor component
 */
protected final FormComponent<T> getEditor() {
    if (editor == null) {
        initLabelAndEditor(getDelegatingParentModel());
    }
    return editor;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4259_1f128536,Minor,wicket-extensions/src/main/java/org/apache/wicket/extensions/ajax/markup/html/AjaxEditableLabel.java,404,411,"/**
 *  Gets the label component.
 *
 *  @return The label component
 */
protected final Component getLabel() {
    if (label == null) {
        initLabelAndEditor(getDelegatingParentModel());
    }
    return label;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4259_1f128536,Minor,wicket-extensions/src/main/java/org/apache/wicket/extensions/ajax/markup/html/AjaxEditableLabel.java,416,427,"/**
 *  {@inheritDoc}
 */
@Override
protected void onBeforeRender() {
    super.onBeforeRender();
    // lazily add label and editor
    if (editor == null) {
        initLabelAndEditor(getDelegatingParentModel());
    }
// obsolete with WICKET-1919
// label.setEnabled(isEnabledInHierarchy());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4259_1f128536,Minor,wicket-extensions/src/main/java/org/apache/wicket/extensions/ajax/markup/html/AjaxEditableLabel.java,518,539,"/**
 *  get a model that accesses the parent model lazily. this is required since we eventually
 *  request the parents model before the component is added to the parent.
 *
 *  @return model
 */
private IModel<T> getDelegatingParentModel() {
    return new IModel<T>() {

        private static final long serialVersionUID = 1L;

        public T getObject() {
            return getParentModel().getObject();
        }

        public void setObject(final T object) {
            getParentModel().setObject(object);
        }

        public void detach() {
            getParentModel().detach();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4260_925cae5c,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/servlet/ServletWebResponse.java,200,237,"@Override
public void sendRedirect(String url) {
    try {
        redirect = true;
        url = encodeRedirectURL(url);
        // wicket redirects should never be cached
        disableCaching();
        if (webRequest.isAjax()) {
            httpServletResponse.addHeader(""Ajax-Location"", url);
            /*
				 * usually the Ajax-Location header is enough and we do not need to the redirect url
				 * into the response, but sometimes the response is processed via an iframe (eg
				 * using multipart ajax handling) and the headers are not available because XHR is
				 * not used and that is the only way javascript has access to response headers.
				 */
            httpServletResponse.getWriter().write(""<ajax-response><redirect><![CDATA["" + url + ""]]></redirect></ajax-response>"");
            setContentType(""text/xml;charset="" + webRequest.getContainerRequest().getCharacterEncoding());
            disableCaching();
        } else {
            httpServletResponse.sendRedirect(url);
        }
    } catch (IOException e) {
        throw new WicketRuntimeException(e);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4276_32c76c4a,Major,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/form/select/Select.java,219,241,"/**
 *  Checks if the specified option is selected based on raw input
 *
 *  @param option
 *  @return true} iff the option is selected
 */
boolean isSelected(final SelectOption<?> option) {
    Args.notNull(option, ""option"");
    // if the raw input is specified use that, otherwise use model
    if (hasRawInput()) {
        String[] paths = getInputAsArray();
        if ((paths != null) && (paths.length > 0)) {
            for (String path : paths) {
                if (path.equals(option.getPath())) {
                    return true;
                }
            }
            return false;
        }
    }
    return compareModels(getDefaultModelObject(), option.getDefaultModelObject());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_4a6a573b,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MiniMap.java,222,265,"/**
 *  @see java.util.Map#keySet()
 */
public Set keySet() {
    return new AbstractSet() {

        public Iterator iterator() {
            return new Iterator() {

                public boolean hasNext() {
                    return i < size;
                }

                public Object next() {
                    // Find next key
                    i = nextKey(nextIndex(i));
                    // Just in case... (WICKET-428)
                    if (!hasNext()) {
                        throw new NoSuchElementException();
                    }
                    // Get key
                    return keys[i];
                }

                public void remove() {
                    keys[i] = null;
                    values[i] = null;
                    size--;
                }

                int i = -1;
            };
        }

        public int size() {
            return size;
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_4a6a573b,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MiniMap.java,226,258,"public Iterator iterator() {
    return new Iterator() {

        public boolean hasNext() {
            return i < size;
        }

        public Object next() {
            // Find next key
            i = nextKey(nextIndex(i));
            // Just in case... (WICKET-428)
            if (!hasNext()) {
                throw new NoSuchElementException();
            }
            // Get key
            return keys[i];
        }

        public void remove() {
            keys[i] = null;
            values[i] = null;
            size--;
        }

        int i = -1;
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_4a6a573b,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MiniMap.java,230,233,"public boolean hasNext() {
    return i < size;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_4a6a573b,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MiniMap.java,235,247,"public Object next() {
    // Find next key
    i = nextKey(nextIndex(i));
    // Just in case... (WICKET-428)
    if (!hasNext()) {
        throw new NoSuchElementException();
    }
    // Get key
    return keys[i];
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_4a6a573b,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MiniMap.java,270,291,"/**
 *  @see java.util.Map#values()
 */
public Collection values() {
    return new AbstractList() {

        public Object get(final int index) {
            int keyIndex = nextKey(0);
            for (int i = 0; i < index; i++) {
                keyIndex = nextKey(keyIndex + 1);
            }
            return values[keyIndex];
        }

        public int size() {
            return size;
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_4a6a573b,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MiniMap.java,274,284,"public Object get(final int index) {
    int keyIndex = nextKey(0);
    for (int i = 0; i < index; i++) {
        keyIndex = nextKey(keyIndex + 1);
    }
    return values[keyIndex];
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_d906576c,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MicroMap.java,199,233,"/**
 *  @see java.util.Map#keySet()
 */
public Set keySet() {
    return new AbstractSet() {

        public Iterator iterator() {
            return new Iterator() {

                public boolean hasNext() {
                    return index < MicroMap.this.size();
                }

                public Object next() {
                    index++;
                    return key;
                }

                public void remove() {
                    MicroMap.this.clear();
                }

                int index;
            };
        }

        public int size() {
            return MicroMap.this.size();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_d906576c,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MicroMap.java,203,226,"public Iterator iterator() {
    return new Iterator() {

        public boolean hasNext() {
            return index < MicroMap.this.size();
        }

        public Object next() {
            index++;
            return key;
        }

        public void remove() {
            MicroMap.this.clear();
        }

        int index;
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_d906576c,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MicroMap.java,212,217,"public Object next() {
    index++;
    return key;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_d906576c,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MicroMap.java,238,252,"/**
 *  @see java.util.Map#values()
 */
public Collection values() {
    return new AbstractList() {

        public Object get(final int index) {
            return value;
        }

        public int size() {
            return MicroMap.this.size();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_d906576c,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MicroMap.java,242,245,"public Object get(final int index) {
    return value;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_d906576c,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MicroMap.java,257,311,"/**
 *  @see java.util.Map#entrySet()
 */
public Set entrySet() {
    return new AbstractSet() {

        public Iterator iterator() {
            return new Iterator() {

                public boolean hasNext() {
                    return index < MicroMap.this.size();
                }

                public Object next() {
                    index++;
                    return new Map.Entry() {

                        public Object getKey() {
                            return key;
                        }

                        public Object getValue() {
                            return value;
                        }

                        public Object setValue(final Object value) {
                            final Object oldValue = MicroMap.this.value;
                            MicroMap.this.value = value;
                            return oldValue;
                        }
                    };
                }

                public void remove() {
                    clear();
                }

                int index = 0;
            };
        }

        public int size() {
            return MicroMap.this.size();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_d906576c,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MicroMap.java,261,304,"public Iterator iterator() {
    return new Iterator() {

        public boolean hasNext() {
            return index < MicroMap.this.size();
        }

        public Object next() {
            index++;
            return new Map.Entry() {

                public Object getKey() {
                    return key;
                }

                public Object getValue() {
                    return value;
                }

                public Object setValue(final Object value) {
                    final Object oldValue = MicroMap.this.value;
                    MicroMap.this.value = value;
                    return oldValue;
                }
            };
        }

        public void remove() {
            clear();
        }

        int index = 0;
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-428_d906576c,Trivial,jdk-1.4/wicket/src/main/java/wicket/util/collections/MicroMap.java,270,295,"public Object next() {
    index++;
    return new Map.Entry() {

        public Object getKey() {
            return key;
        }

        public Object getValue() {
            return value;
        }

        public Object setValue(final Object value) {
            final Object oldValue = MicroMap.this.value;
            MicroMap.this.value = value;
            return oldValue;
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4290_e1953357,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/MountedMapper.java,362,394,"@Override
public Url mapHandler(IRequestHandler requestHandler) {
    Url url = super.mapHandler(requestHandler);
    if (url == null && requestHandler instanceof ListenerInterfaceRequestHandler) {
        ListenerInterfaceRequestHandler handler = (ListenerInterfaceRequestHandler) requestHandler;
        IRequestablePage page = handler.getPage();
        if (checkPageInstance(page)) {
            String componentPath = handler.getComponentPath();
            RequestListenerInterface listenerInterface = handler.getListenerInterface();
            Integer renderCount = null;
            if (listenerInterface.isIncludeRenderCount()) {
                renderCount = page.getRenderCount();
            }
            PageInfo pageInfo = new PageInfo(page.getPageId());
            ComponentInfo componentInfo = new ComponentInfo(renderCount, requestListenerInterfaceToString(listenerInterface), componentPath, handler.getBehaviorIndex());
            PageComponentInfo pageComponentInfo = new PageComponentInfo(pageInfo, componentInfo);
            UrlInfo urlInfo = new UrlInfo(pageComponentInfo, page.getClass(), handler.getPageParameters());
            url = buildUrl(urlInfo);
        }
    }
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4292_9cb617ae,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/mock/MockHttpServletResponse.java,101,107,"/**
 *  Add a cookie to the response.
 *
 *  @param cookie
 *             The cookie to add
 */
@Override
public void addCookie(final Cookie cookie) {
    // remove any potential duplicates
    cookies.remove(cookie);
    cookies.add(cookie);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4301_50b52742,Minor,wicket-core/src/main/java/org/apache/wicket/request/resource/ByteArrayResource.java,95,151,"/**
 *  @see org.apache.wicket.request.resource.AbstractResource#newResourceResponse(org.apache.wicket.request.resource.IResource.Attributes)
 */
@Override
protected ResourceResponse newResourceResponse(final Attributes attributes) {
    final ResourceResponse response = new ResourceResponse();
    String contentType = this.contentType;
    if (contentType == null) {
        if (filename != null) {
            contentType = URLConnection.getFileNameMap().getContentTypeFor(filename);
        }
        if (contentType == null) {
            contentType = ""application/octet-stream"";
        }
    }
    response.setContentType(contentType);
    response.setLastModified(lastModified);
    final byte[] data = getData(attributes);
    if (data == null) {
        throw new WicketRuntimeException(""ByteArrayResource's data cannot be 'null'."");
    }
    response.setContentLength(data.length);
    if (response.dataNeedsToBeWritten(attributes)) {
        if (filename != null) {
            response.setFileName(filename);
            response.setContentDisposition(ContentDisposition.ATTACHMENT);
        } else {
            response.setContentDisposition(ContentDisposition.INLINE);
        }
        response.setWriteCallback(new WriteCallback() {

            @Override
            public void writeData(final Attributes attributes) {
                attributes.getResponse().write(data);
            }
        });
        configureResponse(response, attributes);
    }
    return response;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4301_50b52742,Minor,wicket-core/src/main/java/org/apache/wicket/request/resource/DynamicImageResource.java,135,175,"@Override
protected ResourceResponse newResourceResponse(final Attributes attributes) {
    final ResourceResponse response = new ResourceResponse();
    if (lastModifiedTime != null) {
        response.setLastModified(lastModifiedTime);
    } else {
        response.setLastModified(Time.now());
    }
    if (response.dataNeedsToBeWritten(attributes)) {
        response.setContentType(""image/"" + getFormat());
        response.setContentDisposition(ContentDisposition.INLINE);
        final byte[] imageData = getImageData(attributes);
        if (imageData == null) {
            response.setError(HttpServletResponse.SC_NOT_FOUND);
        } else {
            response.setWriteCallback(new WriteCallback() {

                @Override
                public void writeData(final Attributes attributes) {
                    attributes.getResponse().write(imageData);
                }
            });
        }
        configureResponse(response, attributes);
    }
    return response;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4309_b4274415,Major,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,600,603,"/**
 *  Convert to object types, returning null if text is null.
 *
 *  @return converted
 *  @throws StringValueConversionException
 */
public final Boolean toOptionalBoolean() throws StringValueConversionException {
    return (text == null) ? null : toBooleanObject();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4309_b4274415,Major,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,611,614,"/**
 *  Convert to object types, returning null if text is null.
 *
 *  @return converted
 *  @throws StringValueConversionException
 */
public final Character toOptionalCharacter() throws StringValueConversionException {
    return (text == null) ? null : toCharacter();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4309_b4274415,Major,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,622,625,"/**
 *  Convert to object types, returning null if text is null.
 *
 *  @return converted
 *  @throws StringValueConversionException
 */
public final Double toOptionalDouble() throws StringValueConversionException {
    return (text == null) ? null : toDoubleObject();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4309_b4274415,Major,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,633,636,"/**
 *  Convert to object types, returning null if text is null.
 *
 *  @return converted
 *  @throws StringValueConversionException
 */
public final Duration toOptionalDuration() throws StringValueConversionException {
    return (text == null) ? null : toDuration();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4309_b4274415,Major,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,644,647,"/**
 *  Convert to object types, returning null if text is null.
 *
 *  @return converted
 *  @throws StringValueConversionException
 */
public final Integer toOptionalInteger() throws StringValueConversionException {
    return (text == null) ? null : toInteger();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4309_b4274415,Major,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,655,658,"/**
 *  Convert to object types, returning null if text is null.
 *
 *  @return converted
 *  @throws StringValueConversionException
 */
public final Long toOptionalLong() throws StringValueConversionException {
    return (text == null) ? null : toLongObject();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4309_b4274415,Major,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,676,679,"/**
 *  Convert to object types, returning null if text is null.
 *
 *  @return converted
 *  @throws StringValueConversionException
 */
public final Time toOptionalTime() throws StringValueConversionException {
    return (text == null) ? null : toTime();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4323_e24874da,Minor,wicket-core/src/main/java/org/apache/wicket/model/StringResourceModel.java,582,602,"/**
 *  @see org.apache.wicket.model.IDetachable#detach()
 */
@Override
protected final void onDetach() {
    // detach any model
    if (model != null) {
        model.detach();
    }
    // some parameters can be detachable
    if (parameters != null) {
        for (Object parameter : parameters) {
            if (parameter instanceof IDetachable) {
                ((IDetachable) parameter).detach();
            }
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4338_9decad35,Minor,wicket-request/src/main/java/org/apache/wicket/request/mapper/parameter/PageParametersEncoder.java,40,57,"/**
 *  @see org.apache.wicket.request.mapper.parameter.IPageParametersEncoder#decodePageParameters(org.apache.wicket.request.Request)
 */
public PageParameters decodePageParameters(final Request request) {
    PageParameters parameters = new PageParameters();
    int i = 0;
    for (String s : request.getUrl().getSegments()) {
        parameters.set(i, s);
        ++i;
    }
    for (QueryParameter p : request.getUrl().getQueryParameters()) {
        parameters.add(p.getName(), p.getValue());
    }
    return parameters.isEmpty() ? null : parameters;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4338_9decad35,Minor,wicket-request/src/main/java/org/apache/wicket/request/parameter/CombinedRequestParametersAdapter.java,54,62,"/**
 *  @see org.apache.wicket.request.IRequestParameters#getParameterNames()
 */
public Set<String> getParameterNames() {
    Set<String> result = new HashSet<String>();
    for (IRequestParameters p : parameters) {
        result.addAll(p.getParameterNames());
    }
    return Collections.unmodifiableSet(result);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4338_9decad35,Minor,wicket-request/src/main/java/org/apache/wicket/request/parameter/UrlRequestParametersAdapter.java,56,64,"/**
 *  @see org.apache.wicket.request.IRequestParameters#getParameterNames()
 */
public Set<String> getParameterNames() {
    Set<String> result = new HashSet<String>();
    for (QueryParameter parameter : url.getQueryParameters()) {
        result.add(parameter.getName());
    }
    return Collections.unmodifiableSet(result);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4345_4f08e6f2,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/CryptoMapper.java,153,213,"private Url decryptUrl(final Request request, final Url encryptedUrl) {
    if (encryptedUrl.getSegments().isEmpty() && encryptedUrl.getQueryParameters().isEmpty()) {
        return encryptedUrl;
    }
    List<String> encryptedSegments = encryptedUrl.getSegments();
    if (encryptedSegments.size() < 1) {
        return null;
    }
    Url url = new Url(request.getCharset());
    try {
        String encryptedUrlString = encryptedSegments.get(0);
        if (Strings.isEmpty(encryptedUrlString)) {
            return null;
        }
        String decryptedUrl = getCrypt().decryptUrlSafe(encryptedUrlString);
        if (decryptedUrl == null) {
            return null;
        }
        Url originalUrl = Url.parse(decryptedUrl, request.getCharset());
        int originalNumberOfSegments = originalUrl.getSegments().size();
        int encryptedNumberOfSegments = encryptedUrl.getSegments().size();
        HashedSegmentGenerator generator = new HashedSegmentGenerator(encryptedUrlString);
        int segNo = 1;
        for (; segNo < encryptedNumberOfSegments; segNo++) {
            if (segNo > originalNumberOfSegments || !generator.next().equals(encryptedSegments.get(segNo))) {
                break;
            }
            // unmodified segment
            url.getSegments().add(originalUrl.getSegments().get(segNo - 1));
        }
        for (; segNo < encryptedNumberOfSegments; segNo++) {
            // modified or additional segment
            url.getSegments().add(encryptedUrl.getSegments().get(segNo));
        }
        url.getQueryParameters().addAll(originalUrl.getQueryParameters());
    } catch (Exception e) {
        log.error(""Error decrypting URL"", e);
        url = null;
    }
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4358_02ebc8ae,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/render/WebPageRenderer.java,89,125,"/**
 *  Renders page to a {@link BufferedWebResponse}. All URLs in page will be rendered relative to
 *  <code>targetUrl</code>
 *
 *  @param targetUrl
 *  @param requestCycle
 *  @return BufferedWebResponse containing page body
 */
protected BufferedWebResponse renderPage(Url targetUrl, RequestCycle requestCycle) {
    IRequestHandler scheduled = requestCycle.getRequestHandlerScheduledAfterCurrent();
    // keep the original response
    final Response originalResponse = requestCycle.getResponse();
    // buffered web response for page
    BufferedWebResponse response = new BufferedWebResponse((WebResponse) originalResponse);
    // keep the original base URL
    Url originalBaseUrl = requestCycle.getUrlRenderer().setBaseUrl(targetUrl);
    try {
        requestCycle.setResponse(response);
        getPage().renderPage();
        if (scheduled == null && requestCycle.getRequestHandlerScheduledAfterCurrent() != null) {
            // will want to overwrite the response, so we need to let it
            return null;
        } else {
            return response;
        }
    } finally {
        // restore original response and base URL
        requestCycle.setResponse(originalResponse);
        requestCycle.getUrlRenderer().setBaseUrl(originalBaseUrl);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4365_1485a856,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Form.java,797,846,"/**
 *  Process the form. Though you can override this method to provide your own algorithm, it is
 *  not recommended to do so.
 *
 *  <p>
 *  See the class documentation for further details on the form processing
 *  </p>
 *
 *  @param submittingComponent
 *             component responsible for submitting the form, or <code>null</code> if none (eg
 *             the form has been submitted via the enter key or javascript calling
 *             form.onsubmit())
 *
 *  @see #delegateSubmit(IFormSubmitter) for an easy way to process submitting component in the
 *       default manner
 */
public void process(IFormSubmitter submittingComponent) {
    // save the page in case the component is removed during submit
    final Page page = getPage();
    String hiddenFieldId = getHiddenFieldId();
    if (!isEnabledInHierarchy() || !isVisibleInHierarchy()) {
        // FIXME throw listener exception
        return;
    }
    // run validation
    validate();
    // If a validation error occurred
    if (hasError()) {
        // mark all children as invalid
        markFormComponentsInvalid();
        // let subclass handle error
        callOnError(submittingComponent);
    } else {
        // mark all children as valid
        markFormComponentsValid();
        // before updating, call the interception method for clients
        beforeUpdateFormComponentModels();
        // Update model using form data
        updateFormComponentModels();
        // validate model objects after input values have been bound
        onValidateModelObjects();
        if (hasError()) {
            callOnError(submittingComponent);
            return;
        }
        // Form has no error
        delegateSubmit(submittingComponent);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4370_7ca927c1,Minor,wicket-core/src/main/java/org/apache/wicket/protocol/http/mock/MockHttpServletRequest.java,1068,1076,"/**
 *  Get the sessions.
 *
 *  @return The session
 */
@Override
public HttpSession getSession() {
    if (session instanceof MockHttpSession && ((MockHttpSession) session).isTemporary()) {
        return null;
    }
    return session;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4370_7ca927c1,Minor,wicket-core/src/main/java/org/apache/wicket/protocol/http/mock/MockHttpServletRequest.java,1085,1093,"/**
 *  Get the session.
 *
 *  @param b
 *             Ignored, there is always a session
 *  @return The session
 */
@Override
public HttpSession getSession(boolean b) {
    if (b && session instanceof MockHttpSession) {
        ((MockHttpSession) session).setTemporary(false);
    }
    return getSession();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4379_7a162f77,Minor,wicket-core/src/main/java/org/apache/wicket/resource/loader/ValidatorStringResourceLoader.java,72,94,"/**
 *  @see org.apache.wicket.resource.loader.ComponentStringResourceLoader#loadStringResource(org.apache.wicket.Component,
 *       java.lang.String, java.util.Locale, java.lang.String, java.lang.String)
 */
@Override
public String loadStringResource(final Component component, final String key, final Locale locale, final String style, final String variation) {
    if (component == null || !(component instanceof FormComponent)) {
        return null;
    }
    FormComponent<?> fc = (FormComponent<?>) component;
    for (IValidator<?> validator : fc.getValidators()) {
        String resource = loadStringResource(validator.getClass(), key, locale, style, variation);
        if (resource != null) {
            return resource;
        }
    }
    // not found
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4384_614e3b50,Major,wicket-core/src/main/java/org/apache/wicket/request/mapper/AbstractBookmarkableMapper.java,89,103,"/**
 *  Cleans the original parameters from entries used by Wicket internals.
 *
 *  @param originalParameters
 *             the current request's non-modified parameters
 *  @return all parameters but Wicket internal ones
 */
private PageParameters cleanPageParameters(final PageParameters originalParameters) {
    PageParameters cleanParameters = null;
    if (originalParameters != null) {
        cleanParameters = new PageParameters(originalParameters);
        // WICKET-4038: Ajax related parameters are set by wicket-ajax.js when needed.
        // They shouldn't be propagated to the next requests
        cleanParameters.remove(WebRequest.PARAM_AJAX);
        cleanParameters.remove(WebRequest.PARAM_AJAX_BASE_URL);
        cleanParameters.remove(WebRequest.PARAM_AJAX_REQUEST_ANTI_CACHE);
    }
    return cleanParameters;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4391_5d64196a,Minor,wicket-core/src/main/java/org/apache/wicket/markup/transformer/XsltOutputTransformerContainer.java,107,111,"@Override
public MarkupType getMarkupType() {
    return new MarkupType(""xsl"", null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4398_f88721fd,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,193,306,"/**
 *  Parses the given URL string.
 *
 *  @param url
 *             absolute or relative url with query string
 *  @param charset
 *  @return Url object
 */
public static Url parse(String url, Charset charset) {
    Args.notNull(url, ""url"");
    final Url result = new Url(charset);
    // the url object resolved the charset, use that
    charset = result.getCharset();
    // extract query string part
    final String queryString;
    final String absoluteUrl;
    final int queryAt = url.indexOf('?');
    if (queryAt == -1) {
        queryString = """";
        absoluteUrl = url;
    } else {
        absoluteUrl = url.substring(0, queryAt);
        queryString = url.substring(queryAt + 1);
    }
    // get absolute / relative part of url
    String relativeUrl;
    // absolute urls contain a scheme://
    final int protocolAt = absoluteUrl.indexOf(""://"");
    if (protocolAt != -1) {
        result.protocol = absoluteUrl.substring(0, protocolAt).toLowerCase(Locale.US);
        final String afterProto = absoluteUrl.substring(protocolAt + 3);
        final String hostAndPort;
        final int relativeAt = afterProto.indexOf('/');
        if (relativeAt == -1) {
            relativeUrl = """";
            hostAndPort = afterProto;
        } else {
            relativeUrl = afterProto.substring(relativeAt);
            hostAndPort = afterProto.substring(0, relativeAt);
        }
        final int portAt = hostAndPort.lastIndexOf(':');
        if (portAt == -1) {
            result.host = hostAndPort;
            result.port = getDefaultPortForProtocol(result.protocol);
        } else {
            result.host = hostAndPort.substring(0, portAt);
            result.port = Integer.parseInt(hostAndPort.substring(portAt + 1));
        }
        if (relativeAt < 0) {
            relativeUrl = ""/"";
        }
    } else {
        relativeUrl = absoluteUrl;
    }
    if (relativeUrl.length() > 0) {
        boolean removeLast = false;
        if (relativeUrl.endsWith(""/"")) {
            // we need to append something and remove it after splitting
            // because otherwise the
            // trailing slashes will be lost
            relativeUrl += ""/x"";
            removeLast = true;
        }
        String[] segmentArray = Strings.split(relativeUrl, '/');
        if (removeLast) {
            segmentArray[segmentArray.length - 1] = null;
        }
        for (String s : segmentArray) {
            if (s != null) {
                result.segments.add(decodeSegment(s, charset));
            }
        }
    }
    if (queryString.length() > 0) {
        String[] queryArray = Strings.split(queryString, '&');
        for (String s : queryArray) {
            result.parameters.add(parseQueryParameter(s, charset));
        }
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4398_f88721fd,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,314,334,"/**
 *  @param qp
 *  @param charset
 *  @return query parameters
 */
private static QueryParameter parseQueryParameter(final String qp, final Charset charset) {
    if (qp.indexOf('=') == -1) {
        return new QueryParameter(decodeParameter(qp, charset), """");
    }
    String[] parts = Strings.split(qp, '=');
    if (parts.length == 0) {
        return new QueryParameter("""", """");
    } else if (parts.length == 1) {
        return new QueryParameter("""", decodeParameter(parts[0], charset));
    } else {
        return new QueryParameter(decodeParameter(parts[0], charset), decodeParameter(parts[1], charset));
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Component.java,663,666,"/**
 *  Registers a debug feedback message for this component
 *
 *  @param message
 *             The feedback message
 */
public final void debug(final String message) {
    getPage().getFeedbackMessages().debug(this, message);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Component.java,686,689,"/**
 *  Registers an error feedback message for this component
 *
 *  @param message
 *             The feedback message
 */
public final void error(final Serializable message) {
    getPage().getFeedbackMessages().error(this, message);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Component.java,697,700,"/**
 *  Registers an fatal error feedback message for this component
 *
 *  @param message
 *             The feedback message
 */
public final void fatal(final String message) {
    getPage().getFeedbackMessages().fatal(this, message);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Component.java,826,829,"/**
 *  @return Any feedback message for this component
 */
public final FeedbackMessage getFeedbackMessage() {
    return getPage().getFeedbackMessages().messageForComponent(this);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Component.java,1217,1220,"/**
 *  @return True if this component has an error message
 */
public final boolean hasErrorMessage() {
    return getPage().getFeedbackMessages().hasErrorMessageFor(this);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Component.java,1225,1228,"/**
 *  @return True if this component has some kind of feedback message
 */
public final boolean hasFeedbackMessage() {
    return getPage().getFeedbackMessages().hasMessageFor(this);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Component.java,1236,1239,"/**
 *  Registers an informational feedback message for this component
 *
 *  @param message
 *             The feedback message
 */
public final void info(final String message) {
    getPage().getFeedbackMessages().info(this, message);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Component.java,2377,2380,"/**
 *  Registers a warning feedback message for this component.
 *
 *  @param message
 *             The feedback message
 */
public final void warn(final String message) {
    getPage().getFeedbackMessages().warn(this, message);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Page.java,289,310,"/**
 *  Detaches any attached models referenced by this page.
 */
public void detachModels() {
    // // visit all this page's children to detach the models
    // visitChildren(new IVisitor()
    // {
    // public Object component(Component component)
    // {
    // try
    // {
    // // detach any models of the component
    // component.detachModels();
    // }
    // catch (Exception e) // catch anything; we MUST detach all models
    // {
    // log.error(""detaching models of component "" + component + "" failed:"", e);
    // }
    // return IVisitor.CONTINUE_TRAVERSAL;
    // }
    // });
    super.detachModels();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Page.java,460,463,"/**
 *  @return The current ajax version number of this page.
 */
public final int getAjaxVersionNumber() {
    return versionManager == null ? 0 : versionManager.getAjaxVersionNumber();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Page.java,474,479,"/**
 *  This returns a page instance that is rollbacked the number of versions
 *  that is specified compared to the current page.
 *
 *  This is a rollback including ajax versions.
 *
 *  @param numberOfVersions to rollback
 *  @return
 */
public final Page rollbackPage(int numberOfVersions) {
    Page page = versionManager == null ? this : versionManager.rollbackPage(numberOfVersions);
    getSession().touch(page);
    return page;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Page.java,484,491,"/**
 *  @return Returns feedback messages from all components in this page
 *          (including the page itself).
 */
public final FeedbackMessages getFeedbackMessages() {
    if (feedbackMessages == null) {
        feedbackMessages = new FeedbackMessages();
    }
    return feedbackMessages;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Page.java,1374,1384,"/**
 *  Call this method when the current (ajax) request shouldn't merge
 *  the changes that are happening to the page with the previous version.
 *
 *  This is for example needed when you want to redirect to this
 *  page in an ajax request and then you do want to version normally..
 *
 *  This method doesn't do anything if the getRequest().mergeVersion
 *  doesn't return true.
 */
public final void ignoreVersionMerge() {
    if (getRequest().mergeVersion()) {
        mayTrackChangesFor(this, null);
        if (versionManager != null) {
            versionManager.ignoreVersionMerge();
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/RequestCycle.java,865,965,"/**
 *  Clean up the request cycle.
 */
private void detach() {
    // furthermore, the targets will be cg-ed with this cycle too
    for (Iterator iter = requestTargets.iterator(); iter.hasNext(); ) {
        IRequestTarget target = (IRequestTarget) iter.next();
        if (target != null) {
            try {
                target.detach(this);
            } catch (RuntimeException e) {
                log.error(""there was an error cleaning up target "" + target + ""."", e);
            }
        }
    }
    // remove any rendered feedback messages from the session
    try {
        session.cleanupFeedbackMessages();
    } catch (RuntimeException re) {
        log.error(""there was an error cleaning up the feedback messages"", re);
    }
    if (updateSession) {
        // attributes that might be required to update the cluster
        try {
            session.update();
        } catch (RuntimeException re) {
            log.error(""there was an error updating the session "" + session + ""."", re);
        }
    }
    try {
        IRequestLogger requestLogger = getApplication().getRequestLogger();
        if (requestLogger != null) {
            requestLogger.requestTime((System.currentTimeMillis() - startTime));
        }
    } catch (RuntimeException re) {
        log.error(""there was an error in the RequestLogger ending."", re);
    }
    // clear the used pagemap for this thread,
    try {
        session.requestDetached();
    } catch (RuntimeException re) {
        log.error(""there was an error detaching the request from the session "" + session + ""."", re);
    }
    if (getResponse() instanceof BufferedWebResponse) {
        try {
            ((BufferedWebResponse) getResponse()).filter();
        } catch (RuntimeException re) {
            log.error(""there was an error filtering the response."", re);
        }
    }
    try {
        onEndRequest();
    } catch (RuntimeException e) {
        log.error(""Exception occurred during onEndRequest"", e);
    }
    // Release thread local resources
    try {
        threadDetach();
    } catch (RuntimeException re) {
        log.error(""Exception occurred during threadDetach"", re);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Session.java,913,922,"/**
 *  Gets the converter instance. This method returns the cached converter for
 *  the current locale. Whenever the locale is changed, the cached value is
 *  cleared and the converter will be recreated for the new locale on a next
 *  request.
 *
 *  @param type
 *             TODO
 *
 *  @return the converter
 */
public final IConverter getConverter(Class type) {
    if (converterSupplier == null) {
        // Let the factory create a new converter
        converterSupplier = getApplication().getApplicationSettings().getConverterLocatorFactory().newConverterLocator();
    }
    return converterSupplier.getConverter(type);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/Session.java,1136,1146,"/**
 *  Removes any rendered feedback messages as well as compacts memory. This
 *  method is usually called at the end of the request cycle processing.
 */
final void cleanupFeedbackMessages() {
    int size = feedbackMessages.size();
    feedbackMessages.clearRendered();
    // the session is dirty when the list of feedback messages was changed
    if (size != feedbackMessages.size()) {
        dirty();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/feedback/FeedbackMessages.java,304,306,"/**
 *  Adds a message
 *  @param reporter
 *  @param message
 *  @param level
 */
public final void add(Component reporter, String message, int level) {
    add(new FeedbackMessage(reporter, message, level));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/feedback/FeedbackMessagesModel.java,102,129,"/**
 *  @see wicket.model.IModel#getObject()
 */
public final Object getObject() {
    if (messages == null) {
        // Get filtered messages from page where component lives
        List pageMessages = component.getPage().getFeedbackMessages().messages(filter);
        List sessionMessages = component.getSession().getFeedbackMessages().messages(filter);
        messages = new ArrayList(pageMessages.size() + sessionMessages.size());
        messages.addAll(pageMessages);
        messages.addAll(sessionMessages);
        // Sort the list before returning it
        if (sortingComparator != null) {
            Collections.sort(messages, sortingComparator);
        }
        // Let subclass do any extra processing it wants to on the messages.
        // It may want to do something special, such as removing a given
        // message under some special condition or perhaps eliminate
        // duplicate messages. It could even add a message under certain
        // conditions.
        messages = processMessages(messages);
    }
    return messages;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/markup/html/form/validation/FormComponentFeedbackBorder.java,87,91,"/**
 *  @see wicket.feedback.IFeedback#updateFeedback()
 */
public void updateFeedback() {
    // Get the messages for the current page
    visible = getPage().getFeedbackMessages().messages(getMessagesFilter()).size() != 0;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/markup/html/form/validation/FormComponentFeedbackIndicator.java,74,78,"/**
 *  @see wicket.feedback.IFeedback#updateFeedback()
 */
public void updateFeedback() {
    // Get the messages for the current page
    setVisible(getPage().getFeedbackMessages().hasMessage(getFeedbackMessageFilter()));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-442_246d53c5,Major,jdk-1.4/wicket/src/main/java/wicket/request/target/component/listener/AbstractListenerInterfaceRequestTarget.java,185,203,"/**
 *  Common functionality to be called by processEvents()
 *
 *  @param requestCycle
 *             The request cycle
 */
protected void onProcessEvents(final RequestCycle requestCycle) {
    // Assume cluster needs to be updated now, unless listener
    // invocation changes this
    requestCycle.setUpdateSession(true);
    // Clear all feedback messages if it isn't a redirect
    getPage().getFeedbackMessages().clear();
    getPage().startComponentRender(getTarget());
    final Application application = requestCycle.getApplication();
    // and see if we have to redirect the render part by default
    IRequestCycleSettings.RenderStrategy strategy = application.getRequestCycleSettings().getRenderStrategy();
    boolean issueRedirect = (strategy == IRequestCycleSettings.REDIRECT_TO_RENDER || strategy == IRequestCycleSettings.REDIRECT_TO_BUFFER);
    requestCycle.setRedirect(issueRedirect);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4441_54c86ebb,Major,wicket-core/src/main/java/org/apache/wicket/core/request/handler/PageProvider.java,294,315,"/**
 *  Looks up a page by id from the {@link IPageStore}. <br/>
 *  If {@linkplain #pageClass} is specified then compares it against the stored instance class
 *  and returns the found instance only if they match.
 *
 *  @param pageId
 *             the id of the page to look for.
 *  @return the found page instance by id.
 */
private IRequestablePage getStoredPage(final int pageId) {
    IRequestablePage storedPageInstance = getPageSource().getPageInstance(pageId);
    if (storedPageInstance != null) {
        if (pageClass == null || pageClass.equals(storedPageInstance.getClass())) {
            pageInstance = storedPageInstance;
            pageInstanceIsFresh = false;
            if (renderCount != null && pageInstance.getRenderCount() != renderCount) {
                throw new StalePageException(pageInstance);
            }
        } else {
            // the found page class doesn't match the requested one
            storedPageInstance = null;
        }
    }
    return storedPageInstance;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4483_53442bb4,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,2970,2998,"/**
 *  Sets the given model.
 *  <p>
 *  WARNING: DO NOT OVERRIDE THIS METHOD UNLESS YOU HAVE A VERY GOOD REASON FOR IT. OVERRIDING
 *  THIS MIGHT OPEN UP SECURITY LEAKS AND BREAK BACK-BUTTON SUPPORT.
 *  </p>
 *
 *  @param model
 *             The model
 *  @return This
 */
public Component setDefaultModel(final IModel<?> model) {
    IModel<?> prevModel = getModelImpl();
    // Detach current model
    if (prevModel != null) {
        prevModel.detach();
    }
    IModel<?> wrappedModel = prevModel;
    if (prevModel instanceof IWrapModel) {
        wrappedModel = ((IWrapModel<?>) prevModel).getWrappedModel();
    }
    // Change model
    if (wrappedModel != model) {
        if (wrappedModel != null) {
            addStateChange();
        }
        setModelImpl(wrap(model));
    }
    modelChanged();
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4488_e6582c52,Major,wicket-core/src/main/java/org/apache/wicket/core/request/handler/PageProvider.java,294,311,"/**
 *  Looks up a page by id from the {@link IPageStore}. <br/>
 *  If {@linkplain #pageClass} is specified then compares it against the stored instance class
 *  and returns the found instance only if they match.
 *
 *  @param pageId
 *             the id of the page to look for.
 *  @return the found page instance by id.
 */
private IRequestablePage getStoredPage(final int pageId) {
    IRequestablePage storedPageInstance = getPageSource().getPageInstance(pageId);
    if (storedPageInstance != null && (pageClass == null || pageClass.equals(storedPageInstance.getClass()))) {
        pageInstance = storedPageInstance;
        pageInstanceIsFresh = false;
        if (pageInstance != null) {
            if (renderCount != null && pageInstance.getRenderCount() != renderCount) {
                throw new StalePageException(pageInstance);
            }
        }
    }
    return storedPageInstance;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4494_35843c19,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/HtmlHandler.java,70,87,"@Override
public void postProcess(final Markup markup) {
    // If there's still a non-simple tag left, it's an error
    while (stack.size() > 0) {
        final ComponentTag top = stack.peek();
        if (!requiresCloseTag(top.getName())) {
            stack.pop();
        } else {
            throw new MarkupException(markup, ""Tag does not have a close tag"", null);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4505_a4caaa57,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/TagAttributes.java,53,58,"@Override
public final Object put(String key, Object value) {
    return super.put(key, unescapeHtml(value));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4505_a4caaa57,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/XmlPullParser.java,622,690,"/**
 *  Parses the text between tags. For example, ""a href=foo.html"".
 *
 *  @param tag
 *  @param tagText
 *             The text between tags
 *  @return false in case of an error
 *  @throws ParseException
 */
private boolean parseTagText(final XmlTag tag, final String tagText) throws ParseException {
    // Get the length of the tagtext
    final int tagTextLength = tagText.length();
    // If we match tagname pattern
    final TagNameParser tagnameParser = new TagNameParser(tagText);
    if (tagnameParser.matcher().lookingAt()) {
        // Extract the tag from the pattern matcher
        tag.name = tagnameParser.getName();
        tag.namespace = tagnameParser.getNamespace();
        // Are we at the end? Then there are no attributes, so we just
        // return the tag
        int pos = tagnameParser.matcher().end(0);
        if (pos == tagTextLength) {
            return true;
        }
        // Extract attributes
        final VariableAssignmentParser attributeParser = new VariableAssignmentParser(tagText);
        while (attributeParser.matcher().find(pos)) {
            // Get key and value using attribute pattern
            String value = attributeParser.getValue();
            // In case like <html xmlns:wicket> will the value be null
            if (value == null) {
                value = """";
            }
            // Set new position to end of attribute
            pos = attributeParser.matcher().end(0);
            // Chop off double quotes or single quotes
            if (value.startsWith(""\"""") || value.startsWith(""\'"")) {
                value = value.substring(1, value.length() - 1);
            }
            // Trim trailing whitespace
            value = value.trim();
            // Get key
            final String key = attributeParser.getKey();
            // Put the attribute in the attributes hash
            if (null != tag.getAttributes().put(key, value)) {
                throw new ParseException(""Same attribute found twice: "" + key + getLineAndColumnText(), input.getPosition());
            }
            // attributes)
            if (pos == tagTextLength) {
                return true;
            }
        }
        return true;
    }
    return false;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4509_b672cb2d,Major,wicket-util/src/main/java/org/apache/wicket/util/file/Files.java,364,367,"/**
 *  for urls that point to local files (e.g. 'file:' or 'jar:file:') this methods returns a
 *  reference to the local file
 *
 *  @param url
 *             url of the resource
 *
 *  @return reference to a local file if url contains one, <code>null</code> otherwise
 *
 *  @see #getLocalFileFromUrl(String)
 */
public static File getLocalFileFromUrl(URL url) {
    return getLocalFileFromUrl(Args.notNull(url, ""url"").toExternalForm());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4511_4ee5ad1f,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/HtmlHeaderSectionHandler.java,66,114,"@Override
protected final MarkupElement onComponentTag(ComponentTag tag) throws ParseException {
    // Whatever there is left in the markup, ignore it
    if (ignoreTheRest == true) {
        return tag;
    }
    // if it is <head> or </head>
    if (HEAD.equalsIgnoreCase(tag.getName())) {
        if (tag.getNamespace() == null) {
            // we found <head>
            if (tag.isClose()) {
                foundHead = true;
            } else if (tag.getId() == null) {
                tag.setId(HEADER_ID);
                tag.setAutoComponentTag(true);
                tag.setModified(true);
            }
            return tag;
        } else {
            // we found <wicket:head>
            foundHead = true;
        }
    } else if (BODY.equalsIgnoreCase(tag.getName()) && (tag.getNamespace() == null)) {
        // We found <body>
        if (foundHead == false) {
            insertHeadTag();
        }
        // <head> must always be before <body>
        ignoreTheRest = true;
        return tag;
    }
    return tag;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4518_a88882f7,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,985,1011,"/**
 *  Makes this url the result of resolving the {@code relative} url against this url.
 *  <p>
 *  Segments will be properly resolved, handling any {@code ..} references, while the query
 *  parameters will be completely replaced with {@code relative}'s query parameters.
 *  </p>
 *  <p>
 *  For example:
 *
 *  <pre>
 *  wicket/page/render?foo=bar
 *  </pre>
 *
 *  resolved with
 *
 *  <pre>
 *  ../component/render?a=b
 *  </pre>
 *
 *  will become
 *
 *  <pre>
 *  wicket/component/render?a=b
 *  </pre>
 *
 *  </p>
 *
 *  @param relative
 *             relative url
 */
public void resolveRelative(final Url relative) {
    if (getSegments().size() > 0) {
        // strip the first non-folder segment
        getSegments().remove(getSegments().size() - 1);
    }
    // remove all './' (current folder) from the relative url
    if (!relative.getSegments().isEmpty() && ""."".equals(relative.getSegments().get(0))) {
        relative.getSegments().remove(0);
    }
    // process any ../ segments in the relative url
    while (!relative.getSegments().isEmpty() && "".."".equals(relative.getSegments().get(0))) {
        relative.getSegments().remove(0);
        getSegments().remove(getSegments().size() - 1);
    }
    // append the remaining relative segments
    getSegments().addAll(relative.getSegments());
    // replace query params with the ones from relative
    parameters.clear();
    parameters.addAll(relative.getQueryParameters());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4519_e62ded51,Minor,wicket-util/src/main/java/org/apache/wicket/util/visit/ClassVisitFilter.java,46,49,"/**
 * {@inheritDoc}
 */
public boolean visitObject(final Object object) {
    return clazz.isAssignableFrom(object.getClass());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4520_b91154ea,Major,wicket-core/src/main/java/org/apache/wicket/Application.java,678,719,"/**
 *  THIS METHOD IS NOT PART OF THE WICKET PUBLIC API. DO NOT OVERRIDE OR CALL.
 *
 *  Internal initialization.
 */
protected void internalInit() {
    settingsAccessible = true;
    IPageSettings pageSettings = getPageSettings();
    // Install default component resolvers
    pageSettings.addComponentResolver(new MarkupInheritanceResolver());
    pageSettings.addComponentResolver(new HtmlHeaderResolver());
    pageSettings.addComponentResolver(new WicketLinkTagHandler());
    pageSettings.addComponentResolver(new WicketMessageResolver());
    pageSettings.addComponentResolver(new WicketMessageTagHandler());
    pageSettings.addComponentResolver(new FragmentResolver());
    pageSettings.addComponentResolver(new RelativePathPrefixHandler());
    pageSettings.addComponentResolver(new EnclosureHandler());
    pageSettings.addComponentResolver(new InlineEnclosureHandler());
    pageSettings.addComponentResolver(new WicketContainerResolver());
    // Install button image resource factory
    getResourceSettings().addResourceFactory(""buttonFactory"", new DefaultButtonImageResourceFactory());
    String applicationKey = getApplicationKey();
    applicationKeyToApplication.put(applicationKey, this);
    converterLocator = newConverterLocator();
    setPageManagerProvider(new DefaultPageManagerProvider(this));
    resourceReferenceRegistry = newResourceReferenceRegistry();
    sharedResources = newSharedResources(resourceReferenceRegistry);
    resourceBundles = newResourceBundles(resourceReferenceRegistry);
    // set up default request mapper
    setRootRequestMapper(new SystemMapper(this));
    pageFactory = newPageFactory();
    requestCycleProvider = new DefaultRequestCycleProvider();
    exceptionMapperProvider = new DefaultExceptionMapperProvider();
    // add a request cycle listener that logs each request for the requestlogger.
    getRequestCycleListeners().add(new RequestLoggerRequestCycleListener());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4520_b91154ea,Major,wicket-core/src/main/java/org/apache/wicket/markup/MarkupParser.java,139,182,"/**
 *  Initialize Wicket's MarkupParser with all necessary markup filters. You may subclass this
 *  method, to add your own filters to the list.
 *
 *  @param markup
 *  @return The list of markup filter
 */
@Override
protected MarkupFilterList initializeMarkupFilters(final Markup markup) {
    // MarkupFilterList is a simple extension of ArrayList providing few additional helpers
    final MarkupFilterList filters = new MarkupFilterList();
    MarkupResourceStream markupResourceStream = markup.getMarkupResourceStream();
    filters.add(new WicketTagIdentifier(markupResourceStream));
    filters.add(new HtmlHandler());
    filters.add(new WicketRemoveTagHandler());
    filters.add(new WicketLinkTagHandler());
    filters.add(new AutoLabelTagHandler());
    filters.add(new WicketNamespaceHandler(markupResourceStream));
    // Provided the wicket component requesting the markup is known ...
    if ((markupResourceStream != null) && (markupResourceStream.getResource() != null)) {
        final ContainerInfo containerInfo = markupResourceStream.getContainerInfo();
        if (containerInfo != null) {
            filters.add(new WicketMessageTagHandler(markupResourceStream));
            // Pages require additional handlers
            if (Page.class.isAssignableFrom(containerInfo.getContainerClass())) {
                filters.add(new HtmlHeaderSectionHandler(markup));
            }
            filters.add(new HeadForceTagIdHandler(containerInfo.getContainerClass()));
        }
    }
    filters.add(new OpenCloseTagExpander());
    filters.add(new RelativePathPrefixHandler(markupResourceStream));
    filters.add(new EnclosureHandler());
    filters.add(new InlineEnclosureHandler());
    // Append it. See WICKET-4390
    filters.add(new StyleAndScriptIdentifier(), StyleAndScriptIdentifier.class);
    filters.add(new ConditionalCommentFilter());
    return filters;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4520_b91154ea,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/InlineEnclosureHandler.java,74,162,"@Override
protected MarkupElement onComponentTag(final ComponentTag tag) throws ParseException {
    // We only need ComponentTags
    if (tag instanceof WicketTag) {
        return tag;
    }
    // Has wicket:enclosure attribute?
    String enclosureAttr = getInlineEnclosureAttribute(tag);
    if (enclosureAttr != null) {
        if (tag.isOpen()) {
            // Make sure 'wicket:id' and 'id' are consistent
            String htmlId = tag.getAttribute(""id"");
            if ((tag.getId() != null) && !Strings.isEmpty(htmlId) && !htmlId.equals(tag.getId())) {
                throw new ParseException(""Make sure that 'id' and 'wicket:id' are the same if both are provided. Tag:"" + tag.toString(), tag.getPos());
            }
            // if it doesn't have a wicket-id already, than assign one now.
            if (Strings.isEmpty(tag.getId())) {
                if (Strings.isEmpty(htmlId)) {
                    tag.setId(INLINE_ENCLOSURE_ID_PREFIX);
                } else {
                    tag.setId(htmlId);
                }
                tag.setAutoComponentTag(true);
                tag.setModified(true);
            }
            // Put the enclosure on the stack. The most current one will be on top
            if (enclosures == null) {
                enclosures = new Stack<ComponentTag>();
            }
            enclosures.push(tag);
        } else {
            throw new ParseException(""Open-close tags don't make sense for InlineEnclosure. Tag:"" + tag.toString(), tag.getPos());
        }
    } else // Are we within an enclosure?
    if ((enclosures != null) && (enclosures.size() > 0)) {
        // first ComponentTag's id found as the controlling child to the enclosure.
        if (tag.isOpen() && (tag.getId() != null) && !(tag instanceof WicketTag) && !tag.isAutoComponentTag()) {
            for (int i = enclosures.size() - 1; i >= 0; i--) {
                ComponentTag lastEnclosure = enclosures.get(i);
                String attr = getInlineEnclosureAttribute(lastEnclosure);
                if (Strings.isEmpty(attr) == true) {
                    lastEnclosure.getAttributes().put(INLINE_ENCLOSURE_ATTRIBUTE_NAME, tag.getId());
                    lastEnclosure.setModified(true);
                }
            }
        } else if (tag.isClose() && tag.closes(enclosures.peek())) {
            ComponentTag lastEnclosure = enclosures.pop();
            String attr = getInlineEnclosureAttribute(lastEnclosure);
            if (Strings.isEmpty(attr) == true) {
                throw new ParseException(""Did not find any child for InlineEnclosure. Tag:"" + lastEnclosure.toString(), tag.getPos());
            }
        }
    }
    return tag;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4520_b91154ea,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/WicketMessageTagHandler.java,75,102,"@Override
protected final MarkupElement onComponentTag(ComponentTag tag) throws ParseException {
    if (tag.isClose()) {
        return tag;
    }
    final String wicketMessageAttribute = tag.getAttributes().getString(getWicketMessageAttrName());
    if ((wicketMessageAttribute != null) && (wicketMessageAttribute.trim().length() > 0)) {
        // check if this tag is raw markup
        if (tag.getId() == null) {
            // if this is a raw tag we need to set the id to something so
            // that wicket will not merge this as raw markup and instead
            // pass it on to a resolver
            tag.setId(WICKET_MESSAGE_CONTAINER_ID);
            tag.setAutoComponentTag(true);
            tag.setModified(true);
        }
        tag.addBehavior(new AttributeLocalizer(getWicketMessageAttrName()));
    }
    return tag;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4520_b91154ea,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/WicketMessageTagHandler.java,162,184,"@Override
public Component resolve(MarkupContainer container, MarkupStream markupStream, ComponentTag tag) {
    // localize any raw markup that has wicket:message attrs
    if ((tag != null) && (tag.getId().startsWith(WICKET_MESSAGE_CONTAINER_ID))) {
        Component wc = null;
        int autoIndex = container.getPage().getAutoIndex();
        String id = WICKET_MESSAGE_CONTAINER_ID + autoIndex;
        if (tag.isOpenClose()) {
            wc = new WebComponent(id);
        } else {
            wc = new TransparentWebMarkupContainer(id);
        }
        return wc;
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4520_ccb8fc9e,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/InlineEnclosureHandler.java,172,190,"@Override
public Component resolve(final MarkupContainer container, final MarkupStream markupStream, final ComponentTag tag) {
    String inlineEnclosureChildId = getInlineEnclosureAttribute(tag);
    if (Strings.isEmpty(inlineEnclosureChildId) == false) {
        String id = tag.getId();
        if (id.equals(INLINE_ENCLOSURE_ID_PREFIX)) {
            id = id + container.getPage().getAutoIndex();
        }
        // Yes, we handled the tag
        return new InlineEnclosure(id, inlineEnclosureChildId);
    }
    // We were not able to handle the tag
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4548_9a6a06be,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/ValidationErrorFeedback.java,78,84,"@Override
public String toString() {
    return ""ValidationErrorFeedback{"" + ""message="" + message + '}';
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4572_dfc56674,Critical,wicket-core/src/main/java/org/apache/wicket/pageStore/PageWindowManager.java,83,89,"/**
 *  @param pageId
 *  @param windowIndex
 */
private void putWindowIndex(int pageId, int windowIndex) {
    if (idToWindowIndex != null && pageId != -1 && windowIndex != -1) {
        idToWindowIndex.put(pageId, windowIndex);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4572_dfc56674,Critical,wicket-core/src/main/java/org/apache/wicket/pageStore/PageWindowManager.java,95,98,"/**
 *  @param pageId
 */
private void removeWindowIndex(int pageId) {
    idToWindowIndex.remove(pageId);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4572_dfc56674,Critical,wicket-core/src/main/java/org/apache/wicket/pageStore/PageWindowManager.java,103,112,"/**
 */
private void rebuildIndices() {
    idToWindowIndex = null;
    idToWindowIndex = new IntHashMap<Integer>();
    for (int i = 0; i < windows.size(); ++i) {
        PageWindowInternal window = windows.get(i);
        putWindowIndex(window.pageId, i);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4572_dfc56674,Critical,wicket-core/src/main/java/org/apache/wicket/pageStore/PageWindowManager.java,174,198,"/**
 *  Splits the window with given index to two windows. First of those will have size specified by
 *  the argument, the other one will fill up the rest of the original window.
 *
 *  @param index
 *  @param size
 */
private void splitWindow(int index, int size) {
    PageWindowInternal window = windows.get(index);
    int delta = window.filePartSize - size;
    if (index == windows.size() - 1) {
        // if this is last window
        totalSize -= delta;
        window.filePartSize = size;
    } else if (window.filePartSize != size) {
        PageWindowInternal newWindow = new PageWindowInternal();
        newWindow.pageId = -1;
        window.filePartSize = size;
        windows.add(index + 1, newWindow);
        newWindow.filePartOffset = getWindowFileOffset(index + 1);
        newWindow.filePartSize = delta;
    }
    idToWindowIndex = null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4572_dfc56674,Critical,wicket-core/src/main/java/org/apache/wicket/pageStore/PageWindowManager.java,206,217,"/**
 *  Merges the window with given index with the next window. The resulting window will have size
 *  of the two windows summed together.
 *
 *  @param index
 */
private void mergeWindowWithNext(int index) {
    if (index < windows.size() - 1) {
        PageWindowInternal window = windows.get(index);
        PageWindowInternal next = windows.get(index + 1);
        window.filePartSize += next.filePartSize;
        windows.remove(index + 1);
        // reset index
        idToWindowIndex = null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4572_dfc56674,Critical,wicket-core/src/main/java/org/apache/wicket/pageStore/PageWindowManager.java,355,379,"/**
 *  Creates and returns a new page window for given page.
 *
 *  @param pageId
 *  @param size
 *  @return page window
 */
public PageWindow createPageWindow(int pageId, int size) {
    int index = getWindowIndex(pageId);
    // if we found the page window, mark it as invalid
    if (index != -1) {
        removeWindowIndex(pageId);
        (windows.get(index)).pageId = -1;
    }
    // indexPointer
    if (index == -1 || index != indexPointer) {
        index = incrementIndexPointer();
    }
    PageWindowInternal window = allocatePageWindow(index, size);
    window.pageId = pageId;
    putWindowIndex(pageId, index);
    return new PageWindow(window);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4578_c66cf607,Minor,wicket-core/src/main/java/org/apache/wicket/Component.java,2081,2108,"/**
 *  Returns if the component is stateless or not. It checks the stateless hint if that is false
 *  it returns directly false. If that is still true it checks all its behaviors if they can be
 *  stateless.
 *
 *  @return whether the component is stateless.
 */
public final boolean isStateless() {
    if (!getStatelessHint()) {
        return false;
    }
    if (// the component is either invisible or disabled
    (isVisibleInHierarchy() && isEnabledInHierarchy()) == false && // and it can't call listener interfaces
    canCallListenerInterface(null) == false) {
        // then pretend the component is stateless
        return true;
    }
    for (Behavior behavior : getBehaviors()) {
        if (!behavior.getStatelessHint(this)) {
            return false;
        }
    }
    return true;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4594_556a2236,Major,wicket-core/src/main/java/org/apache/wicket/core/request/handler/PageProvider.java,252,283,"private void resolvePageInstance(Integer pageId, Class<? extends IRequestablePage> pageClass, PageParameters pageParameters, Integer renderCount) {
    IRequestablePage page = null;
    boolean freshCreated = false;
    if (pageId != null) {
        page = getStoredPage(pageId);
    }
    if (page == null) {
        if (pageClass != null) {
            page = getPageSource().newPageInstance(pageClass, pageParameters);
            freshCreated = true;
        }
    }
    if (page != null && !freshCreated) {
        if (renderCount != null && page.getRenderCount() != renderCount) {
            throw new StalePageException(page);
        }
    }
    pageInstanceIsFresh = freshCreated;
    pageInstance = page;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4594_5e1bf8d8,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,233,275,"/**
 *  Creates a {@code IRequestHandler} that processes a listener request.
 *
 *  @param pageComponentInfo
 *  @param pageClass
 *  @param pageParameters
 *  @return a {@code IRequestHandler} that invokes the listener interface
 */
protected IRequestHandler processListener(PageComponentInfo pageComponentInfo, Class<? extends IRequestablePage> pageClass, PageParameters pageParameters) {
    PageInfo pageInfo = pageComponentInfo.getPageInfo();
    ComponentInfo componentInfo = pageComponentInfo.getComponentInfo();
    Integer renderCount = null;
    RequestListenerInterface listenerInterface = null;
    if (componentInfo != null) {
        renderCount = componentInfo.getRenderCount();
        listenerInterface = requestListenerInterfaceFromString(componentInfo.getListenerInterface());
    }
    if (listenerInterface != null) {
        // WICKET-4594 - ignore the parsed parameters as they have nothing to do with the page
        PageAndComponentProvider provider = new PageAndComponentProvider(pageInfo.getPageId(), pageClass, null, renderCount, componentInfo.getComponentPath());
        provider.setPageSource(getContext());
        return new ListenerInterfaceRequestHandler(provider, listenerInterface, componentInfo.getBehaviorId());
    } else {
        if (logger.isWarnEnabled()) {
            if (componentInfo != null) {
                logger.warn(""Unknown listener interface '{}'"", componentInfo.getListenerInterface());
            } else {
                logger.warn(""Cannot extract the listener interface for PageComponentInfo: '{}'"" + pageComponentInfo);
            }
        }
        return null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4597_9dab1bb5,Major,wicket-util/src/main/java/org/apache/wicket/util/time/Duration.java,505,535,"/**
 *  Retrieves the <code>String</code> representation of this <code>Duration</code> in days,
 *  hours, minutes, seconds or milliseconds, as appropriate.
 *
 *  @param locale
 *             a <code>Locale</code>
 *  @return a <code>String</code> representation
 */
public String toString(final Locale locale) {
    if (getMilliseconds() >= 0) {
        if (days() >= 1.0) {
            return unitString(days(), ""day"", locale);
        }
        if (hours() >= 1.0) {
            return unitString(hours(), ""hour"", locale);
        }
        if (minutes() >= 1.0) {
            return unitString(minutes(), ""minute"", locale);
        }
        if (seconds() >= 1.0) {
            return unitString(seconds(), ""second"", locale);
        }
        return unitString(seconds(), ""millisecond"", locale);
    } else {
        return ""N/A"";
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4610_b19a3d69,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/mock/MockHttpServletResponse.java,603,607,"/**
 *  Indicate sending of a redirectLocation to a particular named resource. This implementation
 *  just keeps hold of the redirectLocation info and makes it available for query.
 *
 *  @param location
 *             The location to redirectLocation to
 *  @throws IOException
 *              Not used
 */
@Override
public void sendRedirect(String location) throws IOException {
    redirectLocation = location;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4616_dd1df04b,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Form.java,929,954,"/**
 *  Calls onError on this {@link Form} and any enabled and visible nested form, if the respective
 *  {@link Form} actually has errors.
 *
 *  @param submitter
 */
protected void callOnError(IFormSubmitter submitter) {
    if (submitter != null) {
        submitter.onError();
    }
    onError();
    // call onError on nested forms
    visitChildren(Form.class, new IVisitor<Component, Void>() {

        @Override
        public void component(final Component component, final IVisit<Void> visit) {
            final Form<?> form = (Form<?>) component;
            if (!form.isEnabledInHierarchy() || !form.isVisibleInHierarchy()) {
                visit.dontGoDeeper();
                return;
            }
            if (form.hasError()) {
                form.onError();
            }
        }
    });
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4616_dd1df04b,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Form.java,939,952,"@Override
public void component(final Component component, final IVisit<Void> visit) {
    final Form<?> form = (Form<?>) component;
    if (!form.isEnabledInHierarchy() || !form.isVisibleInHierarchy()) {
        visit.dontGoDeeper();
        return;
    }
    if (form.hasError()) {
        form.onError();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4616_dd1df04b,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Form.java,1224,1253,"/**
 *  Called (by the default implementation of 'process') when all fields validated, the form was
 *  updated and it's data was allowed to be persisted. It is meant for delegating further
 *  processing to clients.
 *  <p>
 *  This implementation first finds out whether the form processing was triggered by a nested
 *  IFormSubmittingComponent of this form. If that is the case, that component's onSubmit is
 *  called first.
 *  </p>
 *  <p>
 *  Regardless of whether a submitting component was found, the form's onSubmit method is called
 *  next.
 *  </p>
 *
 *  @param submittingComponent
 *             the component that triggered this form processing, or null if the processing was
 *             triggered by something else (like a non-Wicket submit button or a javascript
 *             execution)
 */
protected void delegateSubmit(IFormSubmitter submittingComponent) {
    final Form<?> processingForm = findFormToProcess(submittingComponent);
    // process submitting component (if specified)
    if (submittingComponent != null) {
        // invoke submit on component
        submittingComponent.onSubmitBeforeForm();
    }
    // invoke Form#onSubmit(..) going from innermost to outermost
    Visits.visitPostOrder(processingForm, new IVisitor<Form<?>, Void>() {

        @Override
        public void component(Form<?> form, IVisit<Void> visit) {
            if (form.isEnabledInHierarchy() && form.isVisibleInHierarchy()) {
                form.onSubmit();
            }
        }
    }, new ClassVisitFilter(Form.class));
    if (submittingComponent != null) {
        submittingComponent.onSubmitAfterForm();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4658_ef3adb12,Trivial,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/tabs/TabbedPanel.java,200,234,"/**
 *  Generates a loop item used to represent a specific tab's <code>li</code> element.
 *
 *  @param tabIndex
 *  @return new loop item
 */
protected LoopItem newTabContainer(final int tabIndex) {
    return new LoopItem(tabIndex) {

        private static final long serialVersionUID = 1L;

        @Override
        protected void onComponentTag(final ComponentTag tag) {
            super.onComponentTag(tag);
            String cssClass = tag.getAttribute(""class"");
            if (cssClass == null) {
                cssClass = "" "";
            }
            cssClass += "" tab"" + getIndex();
            if (getIndex() == getSelectedTab()) {
                cssClass += ' ' + getSelectedTabCssClass();
            }
            if (getIndex() == getTabs().size() - 1) {
                cssClass += ' ' + getLastTabCssClass();
            }
            tag.put(""class"", cssClass.trim());
        }

        @Override
        public boolean isVisible() {
            return getTabs().get(tabIndex).isVisible();
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4658_ef3adb12,Trivial,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/tabs/TabbedPanel.java,206,226,"@Override
protected void onComponentTag(final ComponentTag tag) {
    super.onComponentTag(tag);
    String cssClass = tag.getAttribute(""class"");
    if (cssClass == null) {
        cssClass = "" "";
    }
    cssClass += "" tab"" + getIndex();
    if (getIndex() == getSelectedTab()) {
        cssClass += ' ' + getSelectedTabCssClass();
    }
    if (getIndex() == getTabs().size() - 1) {
        cssClass += ' ' + getLastTabCssClass();
    }
    tag.put(""class"", cssClass.trim());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4658_ef3adb12,Trivial,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/tabs/TabbedPanel.java,228,232,"@Override
public boolean isVisible() {
    return getTabs().get(tabIndex).isVisible();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4658_ef3adb12,Trivial,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/tabs/TabbedPanel.java,236,266,"@Override
protected void onBeforeRender() {
    int index = getSelectedTab();
    if ((index == -1) || (isTabVisible(index) == false)) {
        // find first visible tab
        index = -1;
        for (int i = 0; i < tabs.size(); i++) {
            if (isTabVisible(i)) {
                index = i;
                break;
            }
        }
        if (index != -1) {
            /*
				 * found a visible tab, so select it
				 */
            setSelectedTab(index);
        }
    }
    setCurrentTab(index);
    super.onBeforeRender();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4658_ef3adb12,Trivial,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/tabs/TabbedPanel.java,393,431,"private void setCurrentTab(int index) {
    if (this.currentTab == index) {
        // already current
        return;
    }
    this.currentTab = index;
    final Component component;
    if (currentTab == -1 || (tabs.size() == 0) || !isTabVisible(currentTab)) {
        // no tabs or the current tab is not visible
        component = newPanel();
    } else {
        // show panel from selected tab
        T tab = tabs.get(currentTab);
        component = tab.getPanel(TAB_PANEL_ID);
        if (component == null) {
            throw new WicketRuntimeException(""ITab.getPanel() returned null. TabbedPanel ["" + getPath() + ""] ITab index ["" + currentTab + ""]"");
        }
    }
    if (!component.getId().equals(TAB_PANEL_ID)) {
        throw new WicketRuntimeException(""ITab.getPanel() returned a panel with invalid id ["" + component.getId() + ""]. You must always return a panel with id equal to the provided panelId parameter. TabbedPanel ["" + getPath() + ""] ITab index ["" + currentTab + ""]"");
    }
    addOrReplace(component);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4658_ef3adb12,Trivial,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/tabs/TabbedPanel.java,451,479,"/**
 *  @param tabIndex
 *  @return visible
 */
private boolean isTabVisible(final int tabIndex) {
    if (tabsVisibilityCache == null) {
        tabsVisibilityCache = new Boolean[tabs.size()];
    }
    if (tabsVisibilityCache.length < tabIndex + 1) {
        Boolean[] resized = new Boolean[tabIndex + 1];
        System.arraycopy(tabsVisibilityCache, 0, resized, 0, tabsVisibilityCache.length);
        tabsVisibilityCache = resized;
    }
    if (tabsVisibilityCache.length > 0) {
        Boolean visible = tabsVisibilityCache[tabIndex];
        if (visible == null) {
            visible = tabs.get(tabIndex).isVisible();
            tabsVisibilityCache[tabIndex] = visible;
        }
        return visible;
    } else {
        return false;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4658_ef3adb12,Trivial,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/tabs/TabbedPanel.java,481,486,"@Override
protected void onDetach() {
    tabsVisibilityCache = null;
    super.onDetach();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4659_ccd74641,Major,wicket-core/src/main/java/org/apache/wicket/DefaultExceptionMapper.java,49,69,"@Override
public IRequestHandler map(Exception e) {
    try {
        return internalMap(e);
    } catch (RuntimeException e2) {
        if (logger.isDebugEnabled()) {
            logger.error(""An error occurred while handling a previous error: "" + e2.getMessage(), e2);
        }
        // hmmm, we were already handling an exception! give up
        logger.error(""unexpected exception when handling another exception: "" + e.getMessage(), e);
        return new ErrorCodeRequestHandler(500);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4664_2fcb3417,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,672,719,"/**
 *  Stringizes this url
 *
 *  @param mode
 *             {@link StringMode} that determins how to stringize the url
 *  @param charset
 *             charset
 *  @return sringized version of this url
 */
public String toString(StringMode mode, Charset charset) {
    StringBuilder result = new StringBuilder();
    final String path = getPath(charset);
    if (StringMode.FULL == mode) {
        if (Strings.isEmpty(host)) {
            throw new IllegalStateException(""Cannot render this url in "" + StringMode.FULL.name() + "" mode because it does not have a host set."");
        }
        if (Strings.isEmpty(protocol) == false) {
            result.append(protocol);
            result.append(""://"");
        } else if (Strings.isEmpty(protocol) && Strings.isEmpty(host) == false) {
            result.append(""//"");
        }
        result.append(host);
        if (port != null && port.equals(getDefaultPortForProtocol(protocol)) == false) {
            result.append(':');
            result.append(port);
        }
        if (segments.contains("".."")) {
            throw new IllegalStateException(""Cannot render this url in "" + StringMode.FULL.name() + "" mode because it has a `..` segment: "" + toString());
        }
        if (!path.startsWith(""/"")) {
            result.append('/');
        }
    }
    result.append(path);
    result.append(getQueryString(charset));
    return result.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4686_89184b79,Major,wicket-core/src/main/java/org/apache/wicket/core/request/handler/PageProvider.java,252,289,"private void resolvePageInstance(Integer pageId, Class<? extends IRequestablePage> pageClass, PageParameters pageParameters, Integer renderCount) {
    IRequestablePage page = null;
    boolean freshCreated = false;
    if (pageId != null) {
        page = getStoredPage(pageId);
        if (page == null) {
            // WICKET-4594 - ignore the parsed parameters for stateful pages
            pageParameters = null;
        }
    }
    if (page == null) {
        if (pageClass != null) {
            page = getPageSource().newPageInstance(pageClass, pageParameters);
            freshCreated = true;
        }
    }
    if (page != null && !freshCreated) {
        if (renderCount != null && page.getRenderCount() != renderCount) {
            throw new StalePageException(page);
        }
    }
    pageInstanceIsFresh = freshCreated;
    pageInstance = page;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4686_89184b79,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,258,305,"/**
 *  Creates a {@code IRequestHandler} that processes a listener request.
 *
 *  @param pageComponentInfo
 *  @param pageClass
 *  @param pageParameters
 *  @return a {@code IRequestHandler} that invokes the listener interface
 */
protected IRequestHandler processListener(PageComponentInfo pageComponentInfo, Class<? extends IRequestablePage> pageClass, PageParameters pageParameters) {
    PageInfo pageInfo = pageComponentInfo.getPageInfo();
    ComponentInfo componentInfo = pageComponentInfo.getComponentInfo();
    Integer renderCount = null;
    RequestListenerInterface listenerInterface = null;
    if (componentInfo != null) {
        renderCount = componentInfo.getRenderCount();
        listenerInterface = requestListenerInterfaceFromString(componentInfo.getListenerInterface());
    }
    if (listenerInterface != null) {
        // if (pageInfo.getPageId() != null)
        // {
        // // WICKET-4594 - ignore the parsed parameters for stateful pages
        // pageParameters = null;
        // }
        PageAndComponentProvider provider = new PageAndComponentProvider(pageInfo.getPageId(), pageClass, pageParameters, renderCount, componentInfo.getComponentPath());
        provider.setPageSource(getContext());
        return new ListenerInterfaceRequestHandler(provider, listenerInterface, componentInfo.getBehaviorId());
    } else {
        if (logger.isWarnEnabled()) {
            if (componentInfo != null) {
                logger.warn(""Unknown listener interface '{}'"", componentInfo.getListenerInterface());
            } else {
                logger.warn(""Cannot extract the listener interface for PageComponentInfo: '{}'"" + pageComponentInfo);
            }
        }
        return null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4696_f5f802c5,Major,wicket-util/src/main/java/org/apache/wicket/util/lang/Numbers.java,44,78,"/**
 *  Returns the minimum value for the numberType's type
 *
 *  @param numberType
 *             the type of the number for which the minimum value will be returned
 *  @return the minimum value of the numberType or {@value Double#MIN_VALUE} if the numberType
 *          itself is either {@code null} or has no minimum value
 */
public static Number getMinValue(Class<? extends Number> numberType) {
    Number result;
    if (Integer.class == numberType || int.class == numberType) {
        result = Integer.MIN_VALUE;
    } else if (Long.class == numberType || long.class == numberType) {
        result = Long.MIN_VALUE;
    } else if (Float.class == numberType || float.class == numberType) {
        result = Float.MIN_VALUE;
    } else if (Double.class == numberType || double.class == numberType) {
        result = Double.MIN_VALUE;
    } else if (Byte.class == numberType || byte.class == numberType) {
        result = Byte.MIN_VALUE;
    } else if (Short.class == numberType || short.class == numberType) {
        result = Short.MIN_VALUE;
    } else {
        // null of any other Number
        LOG.debug(""'{}' has no minimum value. Falling back to Double.MIN_VALUE."", numberType);
        result = Double.MIN_VALUE;
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4715_4fc82e35,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Form.java,1507,1573,"/**
 *  @see org.apache.wicket.Component#onComponentTag(ComponentTag)
 */
@Override
protected void onComponentTag(final ComponentTag tag) {
    super.onComponentTag(tag);
    checkComponentTag(tag, ""form"");
    if (isRootForm()) {
        String method = getMethod().toLowerCase(Locale.ENGLISH);
        tag.put(""method"", method);
        String url = getActionUrl().toString();
        if (encodeUrlInHiddenFields()) {
            int i = url.indexOf('?');
            String action = (i > -1) ? url.substring(0, i) : """";
            tag.put(""action"", action);
        // alternatively, we could just put an empty string here, so
        // that mounted paths stay in good order. I decided against this
        // as I'm not sure whether that could have side effects with
        // other encoders
        } else {
            tag.put(""action"", url);
        }
        if (isMultiPart()) {
            if (METHOD_GET.equalsIgnoreCase(method)) {
                log.warn(""Form with id '{}' is multipart. It should use method 'POST'!"", getId());
                tag.put(""method"", METHOD_POST.toLowerCase(Locale.ENGLISH));
            }
            tag.put(""enctype"", ""multipart/form-data"");
            // 
            // require the application-encoding for multipart/form-data to be sure to
            // get multipart-uploaded characters with the proper encoding on the following
            // request.
            // 
            // for details see: http://stackoverflow.com/questions/546365
            // 
            tag.put(""accept-charset"", getApplication().getRequestCycleSettings().getResponseRequestEncoding());
        } else {
            // sanity check
            String enctype = (String) tag.getAttributes().get(""enctype"");
            if (""multipart/form-data"".equalsIgnoreCase(enctype)) {
                // though not set explicitly in Java, this is a multipart
                // form
                setMultiPart(true);
            }
        }
    } else {
        tag.setName(""div"");
        tag.remove(""method"");
        tag.remove(""action"");
        tag.remove(""enctype"");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4715_4fc82e35,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/WebApplication.java,455,490,"/**
 *  Pre- and post- configures the {@link WebRequest} created by user override-able
 *  {@link #newWebRequest(HttpServletRequest, String)}
 *
 *  @param servletRequest
 *             the current HTTP Sservlet request
 *  @param filterPath
 *             the filter mapping read from web.xml
 *  @return a WebRequest object
 */
WebRequest createWebRequest(HttpServletRequest servletRequest, final String filterPath) {
    if (servletRequest.getCharacterEncoding() == null) {
        try {
            String wicketAjaxHeader = servletRequest.getHeader(WebRequest.HEADER_AJAX);
            if (Strings.isTrue(wicketAjaxHeader)) {
                // WICKET-3908, WICKET-1816: Forms submitted with Ajax are always UTF-8 encoded
                servletRequest.setCharacterEncoding(CharEncoding.UTF_8);
            } else {
                String requestEncoding = getRequestCycleSettings().getResponseRequestEncoding();
                servletRequest.setCharacterEncoding(requestEncoding);
            }
        } catch (UnsupportedEncodingException e) {
            throw new WicketRuntimeException(e);
        }
    }
    if (hasFilterFactoryManager()) {
        for (AbstractRequestWrapperFactory factory : getFilterFactoryManager()) {
            servletRequest = factory.getWrapper(servletRequest);
        }
    }
    WebRequest webRequest = newWebRequest(servletRequest, filterPath);
    return webRequest;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4717_6a1b2f61,Minor,wicket-core/src/main/java/org/apache/wicket/validation/validator/AbstractRangeValidator.java,104,123,"@Override
public void validate(IValidatable<V> validatable) {
    R value = getValue(validatable);
    final R min = getMinimum();
    final R max = getMaximum();
    if ((min != null && value.compareTo(min) < 0) || (max != null && value.compareTo(max) > 0)) {
        ValidationError error = new ValidationError(this, getMode().getVariation());
        if (min != null) {
            error.setVariable(""minimum"", min);
        }
        if (max != null) {
            error.setVariable(""maximum"", max);
        }
        validatable.error(decorate(error, validatable));
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4753_21a47387,Major,wicket-core/src/main/java/org/apache/wicket/markup/head/ResourceAggregator.java,376,396,"/**
 *  Resolves the actual item that needs to be rendered for the given item. This can be a
 *  {@link NoHeaderItem} when the item was already rendered. It can also be a bundle or the item
 *  itself, when it is not part of a bundle.
 *
 *  @param item
 *  @return The item to be rendered
 */
private HeaderItem getItemToBeRendered(HeaderItem item) {
    if (getRealResponse().wasRendered(item)) {
        return NoHeaderItem.get();
    }
    getRealResponse().markRendered(item);
    HeaderItem bundle = Application.get().getResourceBundles().findBundle(item);
    if (bundle == null) {
        return item;
    }
    for (HeaderItem curProvided : bundle.getProvidedResources()) {
        getRealResponse().markRendered(curProvided);
    }
    return bundle;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4755_87ae870f,Major,wicket-core/src/main/java/org/apache/wicket/ConverterLocator.java,84,118,"/**
 *  @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,
 *       java.util.Locale)
 */
@Override
public C convertToObject(String value, Locale locale) {
    if (value == null) {
        return null;
    }
    Class<C> theType = type.get();
    if ("""".equals(value)) {
        if (String.class.equals(theType)) {
            return theType.cast("""");
        }
        return null;
    }
    try {
        C converted = Objects.convertValue(value, theType);
        if (converted != null) {
            return converted;
        } else {
            throw new ConversionException(""Could not convert value: "" + value + "" to type: "" + theType.getName() + "". Could not find compatible converter."").setSourceValue(value);
        }
    } catch (Exception e) {
        throw new ConversionException(e.getMessage(), e).setSourceValue(value);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4757_fd910746,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Form.java,161,182,"@Override
public void component(final FormComponent<?> formComponent, final IVisit<Void> visit) {
    Form<?> form = formComponent.getForm();
    if (!form.isVisibleInHierarchy() || !form.isEnabledInHierarchy()) {
        // do not validate formComponent or any of formComponent's children
        visit.dontGoDeeper();
        return;
    }
    if (formComponent.isVisibleInHierarchy() && formComponent.isValid() && formComponent.isEnabledInHierarchy()) {
        validate(formComponent);
    }
    if (formComponent.processChildren() == false) {
        visit.dontGoDeeper();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4760_2f1ece4b,Major,wicket-core/src/main/java/org/apache/wicket/core/util/string/JavaScriptStripper.java,78,227,"/**
 *  Removes javascript comments and whitespace from specified string.
 *
 *  @param original
 *             Source string
 *  @return String with removed comments and whitespace
 */
public String stripCommentsAndWhitespace(String original) {
    // let's be optimistic
    AppendingStringBuffer result = new AppendingStringBuffer(original.length() / 2);
    int state = REGULAR_TEXT;
    boolean wasNewLineInWhitespace = false;
    for (int i = 0; i < original.length(); ++i) {
        char c = original.charAt(i);
        char next = (i < original.length() - 1) ? original.charAt(i + 1) : 0;
        char prev = (i > 0) ? original.charAt(i - 1) : 0;
        if (state == WHITE_SPACE) {
            // WICKET 2060
            if (c == '\n' && !wasNewLineInWhitespace) {
                result.append(""\n"");
                wasNewLineInWhitespace = true;
            }
            if (Character.isWhitespace(next) == false) {
                state = REGULAR_TEXT;
            }
            continue;
        }
        if (state == REGULAR_TEXT) {
            if (c == '/' && next == '/' && prev != '\\') {
                state = LINE_COMMENT;
                continue;
            } else if (c == '/' && next == '*') {
                state = MULTILINE_COMMENT;
                ++i;
                continue;
            } else if (c == '/') {
                // This might be a divide operator, or it might be a regular expression.
                // Work out if it's a regular expression by finding the previous non-whitespace
                // char, which
                // will be either '=' or '('. If it's not, it's just a divide operator.
                int idx = result.length() - 1;
                while (idx > 0) {
                    char tmp = result.charAt(idx);
                    if (Character.isWhitespace(tmp)) {
                        idx--;
                        continue;
                    }
                    if (tmp == '=' || tmp == '(' || tmp == '{' || tmp == ':' || tmp == ',' || tmp == '[' || tmp == ';' || tmp == '!') {
                        state = REG_EXP;
                        break;
                    }
                    break;
                }
            } else if (Character.isWhitespace(c) && Character.isWhitespace(next)) {
                // WICKET-2060
                if (c == '\n' || next == '\n') {
                    c = '\n';
                    wasNewLineInWhitespace = true;
                } else {
                    c = ' ';
                    wasNewLineInWhitespace = false;
                }
                // ignore all whitespace characters after this one
                state = WHITE_SPACE;
            } else if (c == '\'') {
                state = STRING_SINGLE_QUOTE;
            } else if (c == '""') {
                state = STRING_DOUBLE_QUOTES;
            }
            result.append(c);
            continue;
        }
        if (state == LINE_COMMENT) {
            if (c == '\n' || c == '\r') {
                state = REGULAR_TEXT;
                continue;
            }
        }
        if (state == MULTILINE_COMMENT) {
            if (c == '*' && next == '/') {
                state = REGULAR_TEXT;
                ++i;
                continue;
            }
        }
        if (state == STRING_SINGLE_QUOTE) {
            // to leave a string expression we need even (or zero) number of backslashes
            int count = getPrevCount(original, i, '\\');
            if (c == '\'' && count % 2 == 0) {
                state = REGULAR_TEXT;
            }
            result.append(c);
            continue;
        }
        if (state == STRING_DOUBLE_QUOTES) {
            // to leave a string expression we need even (or zero) number of backslashes
            int count = getPrevCount(original, i, '\\');
            if (c == '""' && count % 2 == 0) {
                state = REGULAR_TEXT;
            }
            result.append(c);
            continue;
        }
        if (state == REG_EXP) {
            // to leave regular expression we need even (or zero) number of backslashes
            int count = getPrevCount(original, i, '\\');
            if (c == '/' && count % 2 == 0) {
                state = REGULAR_TEXT;
            }
            result.append(c);
        }
    }
    return result.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4766_cda34428,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/internal/HtmlHeaderContainer.java,212,237,"/**
 *  Renders the content of the &lt;head&gt; section of the page, including &lt;wicket:head&gt;
 *  sections in subclasses of the page. For every child-component, the content is rendered to a
 *  string and passed to {@link IHeaderResponse}.
 *
 *  @param headerStreamState
 */
public void renderHeaderTagBody(HeaderStreamState headerStreamState) {
    if (headerStreamState == null)
        return;
    final Response oldResponse = getRequestCycle().getResponse();
    try {
        // Create a separate (string) response for the header container itself
        final StringResponse bodyResponse = new StringResponse();
        getRequestCycle().setResponse(bodyResponse);
        // render the header section directly associated with the markup
        super.onComponentTagBody(headerStreamState.getMarkupStream(), headerStreamState.getOpenTag());
        CharSequence bodyOutput = getCleanResponse(bodyResponse);
        if (bodyOutput.length() > 0) {
            getHeaderResponse().render(StringHeaderItem.forString(bodyOutput));
        }
    } finally {
        getRequestCycle().setResponse(oldResponse);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4766_cda34428,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/internal/HtmlHeaderContainer.java,365,381,"/**
 *  THIS METHOD IS NOT PART OF THE WICKET PUBLIC API. DO NOT USE IT.
 *
 *  Temporarily replaces the response with a StringResponse to capture the header output for this
 *  part of the stream and pass it to {@link IHeaderResponse}.
 *
 *  @see org.apache.wicket.MarkupContainer#renderNext(org.apache.wicket.markup.MarkupStream)
 */
@Override
protected final boolean renderNext(MarkupStream markupStream) {
    StringResponse markupHeaderResponse = new StringResponse();
    Response oldResponse = getResponse();
    RequestCycle.get().setResponse(markupHeaderResponse);
    try {
        boolean ret = super.renderNext(markupStream);
        getHeaderResponse().render(new PageHeaderItem(markupHeaderResponse.getBuffer()));
        return ret;
    } finally {
        RequestCycle.get().setResponse(oldResponse);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4775_1ac05533,Major,wicket-request/src/main/java/org/apache/wicket/request/mapper/parameter/PageParameters.java,454,464,"/**
 *  Merges the page parameters into this, overwriting existing values
 *
 *  @param other
 *  @return this
 */
public PageParameters mergeWith(final PageParameters other) {
    if (this != other) {
        for (int index = 0; index < other.getIndexedCount(); index++) set(index, other.get(index));
        for (NamedPair curNamed : other.getAllNamed()) set(curNamed.getKey(), curNamed.getValue());
    }
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4777_eccb3b11,Minor,wicket-core/src/main/java/org/apache/wicket/core/util/string/JavaScriptUtils.java,129,149,"/**
 *  Write a reference to a javascript file to the response object
 *
 *  @param response
 *             The HTTP response
 *  @param url
 *             The javascript file URL
 *  @param id
 *             Unique identifier of element
 *  @param defer
 *             specifies that the execution of a script should be deferred (delayed) until after
 *             the page has been loaded.
 *  @param charset
 *             a non null value specifies the charset attribute of the script tag
 */
public static void writeJavaScriptUrl(final Response response, final CharSequence url, final String id, boolean defer, String charset) {
    response.write(""<script type=\""text/javascript\"" "");
    if (id != null) {
        response.write(""id=\"""" + Strings.escapeMarkup(id) + ""\"" "");
    }
    if (defer) {
        response.write(""defer=\""defer\"" "");
    }
    if (charset != null) {
        response.write(""charset=\"""" + Strings.escapeMarkup(charset) + ""\"" "");
    }
    response.write(""src=\"""");
    response.write(Strings.escapeMarkup(url));
    response.write(""\""></script>"");
    response.write(""\n"");
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4777_eccb3b11,Minor,wicket-core/src/main/java/org/apache/wicket/core/util/string/JavaScriptUtils.java,199,208,"/**
 *  @param response
 *  @param id
 */
public static void writeOpenTag(final Response response, String id) {
    response.write(""<script type=\""text/javascript\"" "");
    if (id != null) {
        response.write(""id=\"""" + id + ""\"""");
    }
    response.write("">"");
    response.write(SCRIPT_CONTENT_PREFIX);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4789_6f0863f4,Critical,wicket-request/src/main/java/org/apache/wicket/request/Url.java,937,977,"/**
 *  Makes this url the result of resolving the {@code relative} url against this url.
 *  <p>
 *  Segments will be properly resolved, handling any {@code ..} references, while the query
 *  parameters will be completely replaced with {@code relative}'s query parameters.
 *  </p>
 *  <p>
 *  For example:
 *
 *  <pre>
 *  wicket/page/render?foo=bar
 *  </pre>
 *
 *  resolved with
 *
 *  <pre>
 *  ../component/render?a=b
 *  </pre>
 *
 *  will become
 *
 *  <pre>
 *  wicket/component/render?a=b
 *  </pre>
 *
 *  </p>
 *
 *  @param relative
 *             relative url
 */
public void resolveRelative(final Url relative) {
    if (getSegments().size() > 0) {
        // strip the first non-folder segment
        getSegments().remove(getSegments().size() - 1);
    }
    // relative url
    while (!relative.getSegments().isEmpty()) {
        if (""."".equals(relative.getSegments().get(0))) {
            relative.getSegments().remove(0);
        } else if ("""".equals(relative.getSegments().get(0))) {
            relative.getSegments().remove(0);
        } else if ("".."".equals(relative.getSegments().get(0))) {
            relative.getSegments().remove(0);
            if (getSegments().isEmpty() == false) {
                getSegments().remove(getSegments().size() - 1);
            }
        } else {
            break;
        }
    }
    // append the remaining relative segments
    getSegments().addAll(relative.getSegments());
    // replace query params with the ones from relative
    parameters.clear();
    parameters.addAll(relative.getQueryParameters());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4789_6f0863f4,Critical,wicket-request/src/main/java/org/apache/wicket/request/Url.java,1139,1164,"/**
 *  Try to reduce url by eliminating '..' and '.' from the path where appropriate
 *  (this is somehow similar to {@link java.io.File#getCanonicalPath()}).
 *  Either by different / unexpected browser behavior or by malicious attacks it
 *  can happen that these kind of redundant urls are processed by wicket. These urls
 *  can cause some trouble when mapping the request.
 *  <p/>
 *  <strong>example:</strong>
 *
 *  the url
 *
 *  <pre>  /example/..;jsessionid=234792?0</pre>
 *
 *  will not get normalized by the browser due to the ';jsessionid' string that
 *  gets appended by the servlet container. After wicket strips the
 *  jsessionid part the resulting internal url will be
 *
 *  <pre>  /example/..</pre>
 *
 *  instead of
 *
 *  <pre>  /</pre>
 *
 *  <p/>
 *
 *  This code correlates to
 *  <a href=""https://issues.apache.org/jira/browse/WICKET-4303"">WICKET-4303</a>
 *
 *  @return canonical url
 */
public Url canonical() {
    Url url = new Url(this);
    url.segments.clear();
    for (int i = 0; i < this.segments.size(); i++) {
        final String segment = this.segments.get(i);
        // drop '.' from path
        if (""."".equals(segment)) {
            continue;
        }
        // skip segment if following segment is a '..'
        if ((i + 1) < this.segments.size() && "".."".equals(this.segments.get(i + 1))) {
            i++;
            continue;
        }
        url.segments.add(segment);
    }
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4816_66bfc885,Major,wicket-util/src/main/java/org/apache/wicket/util/string/Strings.java,907,936,"/**
 *  Strip any jsessionid and possibly other redundant info that might be in our way.
 *
 *  @param url
 *             The url to strip
 *  @return The stripped url
 */
public static String stripJSessionId(final String url) {
    if (url == null) {
        return null;
    }
    // http://.../abc;jsessionid=...?param=...
    int ixSemiColon = url.indexOf("";"");
    if (ixSemiColon == -1) {
        return url;
    }
    int ixQuestionMark = url.indexOf(""?"");
    if (ixQuestionMark == -1) {
        // http://.../abc;jsession=...
        return url.substring(0, ixSemiColon);
    }
    if (ixQuestionMark <= ixSemiColon) {
        // ? is before ; - no jsessionid in the url
        return url;
    }
    return url.substring(0, ixSemiColon) + url.substring(ixQuestionMark);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4824_ad849602,Major,wicket-core/src/main/java/org/apache/wicket/protocol/https/HttpsMapper.java,162,179,"/**
 *  Creates a url for the handler. Modifies it with the correct {@link Scheme} if necessary.
 *
 *  @param handler
 *  @param request
 *  @return url
 */
final Url mapHandler(IRequestHandler handler, Request request) {
    Url url = delegate.mapHandler(handler);
    Scheme desired = getDesiredSchemeFor(handler);
    Scheme current = getSchemeOf(request);
    if (!desired.isCompatibleWith(current)) {
        // the generated url does not have the correct scheme, set it (which in turn will cause
        // the url to be rendered in its full representation)
        url.setProtocol(desired.urlName());
        if (url.getPort() != null || !desired.usesStandardPort(config)) {
            url.setPort(desired.getPort(config));
        }
    }
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4839_8b294488,Major,wicket-core/src/main/java/org/apache/wicket/ConverterLocator.java,189,221,"/**
 *  Gets the type converter that is registered for class c.
 *
 *  @param <C>
 *             The object to convert from and to String
 *  @param c
 *             The class to get the type converter for
 *  @return The type converter that is registered for class c or null if no type converter was
 *          registered for class c
 */
public final <C> IConverter<C> get(Class<C> c) {
    @SuppressWarnings(""unchecked"")
    final IConverter<C> converter;
    // a new instance should be created for each usage
    if (Date.class.equals(c)) {
        converter = (IConverter<C>) new DateConverter();
    } else if (java.sql.Date.class.equals(c)) {
        converter = (IConverter<C>) new SqlDateConverter();
    } else if (java.sql.Time.class.equals(c)) {
        converter = (IConverter<C>) new SqlTimeConverter();
    } else if (java.sql.Timestamp.class.equals(c)) {
        converter = (IConverter<C>) new SqlTimestampConverter();
    } else if (Calendar.class.equals(c)) {
        converter = (IConverter<C>) new CalendarConverter();
    } else {
        converter = (IConverter<C>) classToConverter.get(c.getName());
    }
    return converter;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4841_ce172da8,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/servlet/ServletWebRequest.java,143,175,"/**
 *  Returns base url without context or filter mapping.
 *  <p>
 *  Example: if current url is
 *
 *  <pre>
 *  http://localhost:8080/context/filter/mapping/wicket/bookmarkable/com.foo.Page?1&id=2
 *  </pre>
 *
 *  the base url is <em>wicket/bookmarkable/com.foo.Page</em>
 *  </p>
 *
 *  @see org.apache.wicket.request.Request#getClientUrl()
 */
@Override
public Url getClientUrl() {
    if (errorAttributes != null && !Strings.isEmpty(errorAttributes.getRequestUri())) {
        String problematicURI = Url.parse(errorAttributes.getRequestUri(), getCharset()).toString();
        return getContextRelativeUrl(problematicURI, filterPrefix);
    } else if (forwardAttributes != null && !Strings.isEmpty(forwardAttributes.getRequestUri())) {
        String forwardURI = Url.parse(forwardAttributes.getRequestUri(), getCharset()).toString();
        return getContextRelativeUrl(forwardURI, filterPrefix);
    } else if (!isAjax()) {
        return getContextRelativeUrl(httpServletRequest.getRequestURI(), filterPrefix);
    } else {
        String base = getHeader(HEADER_AJAX_BASE_URL);
        if (base == null) {
            base = getRequestParameters().getParameterValue(PARAM_AJAX_BASE_URL).toString(null);
        }
        Checks.notNull(base, ""Current ajax request is missing the base url header or parameter"");
        return setParameters(Url.parse(base, getCharset()));
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4877_6470c3f7,Minor,wicket-request/src/main/java/org/apache/wicket/request/Url.java,194,312,"/**
 *  Parses the given URL string.
 *
 *  @param _url
 *             absolute or relative url with query string
 *  @param charset
 *  @return Url object
 */
public static Url parse(CharSequence _url, Charset charset) {
    Args.notNull(_url, ""_url"");
    final Url result = new Url(charset);
    // the url object resolved the charset, use that
    charset = result.getCharset();
    String url = _url.toString();
    // extract query string part
    final String queryString;
    final String absoluteUrl;
    final int queryAt = url.indexOf('?');
    if (queryAt == -1) {
        queryString = """";
        absoluteUrl = url;
    } else {
        absoluteUrl = url.substring(0, queryAt);
        queryString = url.substring(queryAt + 1);
    }
    // get absolute / relative part of url
    String relativeUrl;
    // absolute urls contain a scheme://
    final int idxOfFirstSlash = absoluteUrl.indexOf('/');
    final int protocolAt = absoluteUrl.indexOf(""://"");
    if (protocolAt > -1 && (protocolAt < idxOfFirstSlash)) {
        result.protocol = absoluteUrl.substring(0, protocolAt).toLowerCase(Locale.US);
        final String afterProto = absoluteUrl.substring(protocolAt + 3);
        final String hostAndPort;
        final int relativeAt = afterProto.indexOf('/');
        if (relativeAt == -1) {
            relativeUrl = """";
            hostAndPort = afterProto;
        } else {
            relativeUrl = afterProto.substring(relativeAt);
            hostAndPort = afterProto.substring(0, relativeAt);
        }
        final int portAt = hostAndPort.lastIndexOf(':');
        if (portAt == -1) {
            result.host = hostAndPort;
            result.port = getDefaultPortForProtocol(result.protocol);
        } else {
            result.host = hostAndPort.substring(0, portAt);
            result.port = Integer.parseInt(hostAndPort.substring(portAt + 1));
        }
        if (relativeAt < 0) {
            relativeUrl = ""/"";
        }
    } else {
        relativeUrl = absoluteUrl;
    }
    if (relativeUrl.length() > 0) {
        boolean removeLast = false;
        if (relativeUrl.endsWith(""/"")) {
            // we need to append something and remove it after splitting
            // because otherwise the
            // trailing slashes will be lost
            relativeUrl += ""/x"";
            removeLast = true;
        }
        String[] segmentArray = Strings.split(relativeUrl, '/');
        if (removeLast) {
            segmentArray[segmentArray.length - 1] = null;
        }
        for (String s : segmentArray) {
            if (s != null) {
                result.segments.add(decodeSegment(s, charset));
            }
        }
    }
    if (queryString.length() > 0) {
        String[] queryArray = Strings.split(queryString, '&');
        for (String s : queryArray) {
            if (Strings.isEmpty(s) == false) {
                result.parameters.add(parseQueryParameter(s, charset));
            }
        }
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4923_d78132be,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/CryptoMapper.java,163,245,"private Url decryptUrl(final Request request, final Url encryptedUrl) {
    /*
		 * If the encrypted URL has no segments it is the home page URL,
		 * and does not need decrypting.
		 */
    if (encryptedUrl.getSegments().isEmpty()) {
        return encryptedUrl;
    }
    List<String> encryptedSegments = encryptedUrl.getSegments();
    Url url = new Url(request.getCharset());
    try {
        /*
			 * The first encrypted segment contains an encrypted version of the
			 * entire plain text url.
			 */
        String encryptedUrlString = encryptedSegments.get(0);
        if (Strings.isEmpty(encryptedUrlString)) {
            return null;
        }
        String decryptedUrl = getCrypt().decryptUrlSafe(encryptedUrlString);
        if (decryptedUrl == null) {
            return null;
        }
        Url originalUrl = Url.parse(decryptedUrl, request.getCharset());
        int originalNumberOfSegments = originalUrl.getSegments().size();
        int encryptedNumberOfSegments = encryptedUrl.getSegments().size();
        HashedSegmentGenerator generator = new HashedSegmentGenerator(encryptedUrlString);
        int segNo = 1;
        for (; segNo < encryptedNumberOfSegments; segNo++) {
            if (segNo > originalNumberOfSegments) {
                break;
            }
            String next = generator.next();
            String encryptedSegment = encryptedSegments.get(segNo);
            if (!next.equals(encryptedSegment)) {
                /*
					 * This segment received from the browser is not the same as the
					 * expected segment generated by the HashSegmentGenerator. Hence it,
					 * and all subsequent segments are considered plain text siblings of the
					 * original encrypted url.
					 */
                break;
            }
            /*
				 * This segments matches the expected checksum, so we add the corresponding
				 * segment from the original URL.
				 */
            url.getSegments().add(originalUrl.getSegments().get(segNo - 1));
        }
        /*
			 * Add all remaining segments from the encrypted url as plain text segments.
			 */
        for (; segNo < encryptedNumberOfSegments; segNo++) {
            // modified or additional segment
            url.getSegments().add(encryptedUrl.getSegments().get(segNo));
        }
        url.getQueryParameters().addAll(originalUrl.getQueryParameters());
    } catch (Exception e) {
        log.error(""Error decrypting URL"", e);
        url = null;
    }
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,51,58,"private void writeBuffered() {
    if (!bufferedWritten) {
        bufferedResponse.writeTo(originalResponse);
        bufferedWritten = true;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,60,66,"private void checkHeader() {
    if (bufferedWritten) {
        throw new IllegalStateException(""Header was already written to response!"");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,68,73,"@Override
public void addCookie(Cookie cookie) {
    checkHeader();
    bufferedResponse.addCookie(cookie);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,75,80,"@Override
public void clearCookie(Cookie cookie) {
    checkHeader();
    bufferedResponse.clearCookie(cookie);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,84,94,"@Override
public void flush() {
    if (!bufferedWritten) {
        bufferedResponse.writeTo(originalResponse);
        bufferedResponse.reset();
    }
    originalResponse.flush();
    flushed = true;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,96,100,"@Override
public boolean isRedirect() {
    return bufferedResponse.isRedirect();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,102,107,"@Override
public void sendError(int sc, String msg) {
    checkHeader();
    bufferedResponse.sendError(sc, msg);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,109,114,"@Override
public void sendRedirect(String url) {
    checkHeader();
    bufferedResponse.sendRedirect(url);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,116,121,"@Override
public void setContentLength(long length) {
    checkHeader();
    bufferedResponse.setContentLength(length);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,123,128,"@Override
public void setContentType(String mimeType) {
    checkHeader();
    bufferedResponse.setContentType(mimeType);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,130,136,"@Override
public void setDateHeader(String name, Time date) {
    Args.notNull(date, ""date"");
    checkHeader();
    bufferedResponse.setDateHeader(name, date);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,138,143,"@Override
public void setHeader(String name, String value) {
    checkHeader();
    bufferedResponse.setHeader(name, value);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,145,150,"@Override
public void addHeader(String name, String value) {
    checkHeader();
    bufferedResponse.addHeader(name, value);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,152,156,"@Override
public void setStatus(int sc) {
    bufferedResponse.setStatus(sc);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,170,175,"@Override
public void write(CharSequence sequence) {
    writeBuffered();
    originalResponse.write(sequence);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,177,182,"@Override
public void write(byte[] array) {
    writeBuffered();
    originalResponse.write(array);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,185,190,"@Override
public void write(byte[] array, int offset, int length) {
    writeBuffered();
    originalResponse.write(array, offset, length);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4927_8c827e33,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/HeaderBufferingWebResponse.java,192,201,"@Override
public void reset() {
    if (flushed) {
        throw new IllegalStateException(""Response has already been flushed!"");
    }
    bufferedResponse.reset();
    bufferedWritten = false;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4932_f20b2d70,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,90,109,"/**
 *  Cleans the original parameters from entries used by Wicket internals.
 *
 *  @param originalParameters
 *             the current request's non-modified parameters
 *  @return all parameters but Wicket internal ones
 */
private PageParameters cleanPageParameters(final PageParameters originalParameters) {
    PageParameters cleanParameters = null;
    if (originalParameters != null) {
        cleanParameters = new PageParameters(originalParameters);
        // WICKET-4038: Ajax related parameters are set by wicket-ajax.js when needed.
        // They shouldn't be propagated to the next requests
        cleanParameters.remove(WebRequest.PARAM_AJAX);
        cleanParameters.remove(WebRequest.PARAM_AJAX_BASE_URL);
        cleanParameters.remove(WebRequest.PARAM_AJAX_REQUEST_ANTI_CACHE);
        if (cleanParameters.isEmpty()) {
            cleanParameters = null;
        }
    }
    return cleanParameters;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4932_f20b2d70,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,149,149,"/**
 *  Parse the given request to an {@link UrlInfo} instance.
 *
 *  @param request
 *  @return UrlInfo instance or <code>null</code> if this encoder can not handle the request
 */
protected abstract UrlInfo parseRequest(Request request);"
wicket,remotes/origin/bugs-dot-jar_WICKET-4932_f20b2d70,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,158,158,"/**
 *  Builds URL for the given {@link UrlInfo} instance. The URL this method produces must be
 *  parseable by the {@link #parseRequest(Request)} method.
 *
 *  @param info
 *  @return Url result URL
 */
protected abstract Url buildUrl(UrlInfo info);"
wicket,remotes/origin/bugs-dot-jar_WICKET-4932_f20b2d70,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,170,170,"/**
 *  Indicates whether hybrid {@link RenderPageRequestHandler} URL for page will be generated only
 *  if page has been created with bookmarkable URL.
 *  <p>
 *  For generic bookmarkable encoders this method should return <code>true</code>. For explicit
 *  (mounted) encoders this method should return <code>false</code>
 *
 *  @return <code>true</code> if hybrid URL requires page created bookmarkable,
 *          <code>false</code> otherwise.
 */
protected abstract boolean pageMustHaveBeenCreatedBookmarkable();"
wicket,remotes/origin/bugs-dot-jar_WICKET-4932_f20b2d70,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,185,191,"/**
 *  Creates a {@code IRequestHandler} that processes a bookmarkable request.
 *
 *  @param pageClass
 *  @param pageParameters
 *  @return a {@code IRequestHandler} capable of processing the bookmarkable request.
 */
protected IRequestHandler processBookmarkable(Class<? extends IRequestablePage> pageClass, PageParameters pageParameters) {
    PageProvider provider = new PageProvider(pageClass, pageParameters);
    provider.setPageSource(getContext());
    return new RenderPageRequestHandler(provider);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4932_f20b2d70,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,204,212,"/**
 *  Creates a {@code IRequestHandler} that processes a hybrid request. When the page identified
 *  by {@code pageInfo} was not available, the request should be treated as a bookmarkable
 *  request.
 *
 *  @param pageInfo
 *  @param pageClass
 *  @param pageParameters
 *  @param renderCount
 *  @return a {@code IRequestHandler} capable of processing the hybrid request.
 */
protected IRequestHandler processHybrid(PageInfo pageInfo, Class<? extends IRequestablePage> pageClass, PageParameters pageParameters, Integer renderCount) {
    PageProvider provider = new PageProvider(pageInfo.getPageId(), pageClass, pageParameters, renderCount);
    provider.setPageSource(getContext());
    return new RenderPageRequestHandler(provider);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4932_f20b2d70,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,222,263,"/**
 *  Creates a {@code IRequestHandler} that processes a listener request.
 *
 *  @param pageComponentInfo
 *  @param pageClass
 *  @param pageParameters
 *  @return a {@code IRequestHandler} that invokes the listener interface
 */
protected IRequestHandler processListener(PageComponentInfo pageComponentInfo, Class<? extends IRequestablePage> pageClass, PageParameters pageParameters) {
    PageInfo pageInfo = pageComponentInfo.getPageInfo();
    ComponentInfo componentInfo = pageComponentInfo.getComponentInfo();
    Integer renderCount = null;
    RequestListenerInterface listenerInterface = null;
    if (componentInfo != null) {
        renderCount = componentInfo.getRenderCount();
        listenerInterface = requestListenerInterfaceFromString(componentInfo.getListenerInterface());
    }
    if (listenerInterface != null) {
        PageAndComponentProvider provider = new PageAndComponentProvider(pageInfo.getPageId(), pageClass, pageParameters, renderCount, componentInfo.getComponentPath());
        provider.setPageSource(getContext());
        return new ListenerInterfaceRequestHandler(provider, listenerInterface, componentInfo.getBehaviorId());
    } else {
        if (logger.isWarnEnabled()) {
            if (componentInfo != null) {
                logger.warn(""Unknown listener interface '{}'"", componentInfo.getListenerInterface());
            } else {
                logger.warn(""Cannot extract the listener interface for PageComponentInfo: '{}'"" + pageComponentInfo);
            }
        }
        return null;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4988_a4a3a9a6,Major,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/AbstractNumberConverter.java,55,95,"/**
 *  Parses a value as a String and returns a Number.
 *
 *  @param value
 *             The object to parse (after converting with toString())
 *  @param min
 *             The minimum allowed value
 *  @param max
 *             The maximum allowed value
 *  @param locale
 *  @return The number
 *  @throws ConversionException
 *              if value is unparsable or out of range
 */
protected N parse(Object value, final double min, final double max, Locale locale) {
    if (locale == null) {
        locale = Locale.getDefault();
    }
    if (value == null) {
        return null;
    } else if (value instanceof String) {
        // Convert spaces to no-break space (U+00A0) to fix problems with
        // browser conversions.
        // Space is not valid thousands-separator, but no-br space is.
        value = ((String) value).replace(' ', '\u00A0');
    }
    final NumberFormat numberFormat = getNumberFormat(locale);
    final N number = parse(numberFormat, value, locale);
    if (number == null) {
        return null;
    }
    if (number.doubleValue() < min) {
        throw newConversionException(""Value cannot be less than "" + min, value, locale).setFormat(numberFormat);
    }
    if (number.doubleValue() > max) {
        throw newConversionException(""Value cannot be greater than "" + max, value, locale).setFormat(numberFormat);
    }
    return number;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4997_ee02c883,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,3330,3346,"/**
 *  Gets a URL for the listener interface on a behavior (e.g. IBehaviorListener on
 *  AjaxPagingNavigationBehavior).
 *
 *  @param behaviour
 *             The behavior that the URL should point to
 *  @param listener
 *             The listener interface that the URL should call
 *  @param parameters
 *             The parameters that should be rendered into the urls
 *  @return The URL
 */
public final CharSequence urlFor(final Behavior behaviour, final RequestListenerInterface listener, final PageParameters parameters) {
    int id = getBehaviorId(behaviour);
    Page page = getPage();
    PageAndComponentProvider provider = new PageAndComponentProvider(page, this, parameters);
    IRequestHandler handler;
    if (page.isBookmarkable()) {
        handler = new BookmarkableListenerInterfaceRequestHandler(provider, listener, id);
    } else {
        handler = new ListenerInterfaceRequestHandler(provider, listener, id);
    }
    return getRequestCycle().urlFor(handler);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-4997_ee02c883,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,3374,3389,"/**
 *  Gets a URL for the listener interface (e.g. ILinkListener).
 *
 *  @see RequestCycle#urlFor(IRequestHandler)
 *
 *  @param listener
 *             The listener interface that the URL should call
 *  @param parameters
 *             The parameters that should be rendered into the urls
 *  @return The URL
 */
public final CharSequence urlFor(final RequestListenerInterface listener, final PageParameters parameters) {
    Page page = getPage();
    PageAndComponentProvider provider = new PageAndComponentProvider(page, this, parameters);
    IRequestHandler handler;
    if (page.isBookmarkable()) {
        handler = new BookmarkableListenerInterfaceRequestHandler(provider, listener);
    } else {
        handler = new ListenerInterfaceRequestHandler(provider, listener);
    }
    return getRequestCycle().urlFor(handler);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5019_917dd2b5,Minor,wicket-core/src/main/java/org/apache/wicket/request/resource/PackageResourceReference.java,173,197,"/**
 *  Initializes the cache for the existence of the minified resource.
 *  @return the name of the minified resource or the special constant {@link #NO_MINIFIED_NAME}
 *  if there is no minified version
 */
private String internalGetMinifiedName() {
    String minifiedName = MINIFIED_NAMES_CACHE.get(this);
    if (minifiedName != null && minifiedName != NO_MINIFIED_NAME) {
        return minifiedName;
    }
    String name = getMinifiedName();
    IResourceStreamLocator locator = Application.get().getResourceSettings().getResourceStreamLocator();
    String absolutePath = Packages.absolutePath(getScope(), name);
    IResourceStream stream = locator.locate(getScope(), absolutePath, getStyle(), getVariation(), getLocale(), null, true);
    minifiedName = stream != null ? name : NO_MINIFIED_NAME;
    MINIFIED_NAMES_CACHE.put(this, minifiedName);
    if (minifiedName == NO_MINIFIED_NAME && log.isDebugEnabled()) {
        log.debug(""No minified version of '"" + super.getName() + ""' found, expected a file with the name '"" + name + ""', using full version"");
    }
    return minifiedName;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5043_2b1ce91d,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/PackageMapper.java,216,220,"/**
 *  @see org.apache.wicket.core.request.mapper.AbstractBookmarkableMapper#pageMustHaveBeenCreatedBookmarkable()
 */
@Override
protected boolean pageMustHaveBeenCreatedBookmarkable() {
    return true;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5056_56169634,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/MountedMapper.java,493,504,"/**
 *  @see AbstractBookmarkableMapper#getCompatibilityScore(org.apache.wicket.request.Request)
 */
@Override
public int getCompatibilityScore(Request request) {
    if (urlStartsWith(request.getUrl(), mountSegments)) {
        return mountSegments.length;
    } else {
        return 0;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5060_8e6a6ec5,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/FragmentMarkupSourcingStrategy.java,115,166,"/**
 *  Search for the child's markup in the fragment markup.
 */
@Override
public IMarkupFragment getMarkup(final MarkupContainer container, final Component child) {
    // Get the markup to search for the fragment markup
    IMarkupFragment markup = chooseMarkup(container);
    if (markup == null) {
        throw new MarkupException(""The fragments markup provider has no associated markup. "" + ""No markup to search for fragment markup with id: "" + markupId);
    }
    // Search for the fragment markup
    IMarkupFragment childMarkup = markup.find(markupId);
    if (childMarkup == null) {
        // There is one more option if the markup provider has associated markup
        MarkupContainer markupProvider = getMarkupProvider(container);
        Markup associatedMarkup = markupProvider.getAssociatedMarkup();
        if (associatedMarkup != null) {
            markup = associatedMarkup;
            if (markup != null) {
                childMarkup = markup.find(markupId);
            }
        }
    }
    if (childMarkup == null) {
        throw new MarkupNotFoundException(""No Markup found for Fragment "" + markupId + "" in providing markup container "" + getMarkupProvider(container));
    } else {
        MarkupElement fragmentTag = childMarkup.get(0);
        if ((fragmentTag instanceof WicketTag && ((WicketTag) fragmentTag).isFragementTag()) == false) {
            throw new MarkupNotFoundException(""Markup found for Fragment '"" + markupId + ""' in providing markup container "" + getMarkupProvider(container) + "" is not a fragment tag"");
        }
    }
    if (child == null) {
        return childMarkup;
    }
    // search for the child inside the fragment markup
    return childMarkup.find(child.getId());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_6e794ad0,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/BookmarkableMapper.java,93,136,"/**
 *  @see AbstractBookmarkableMapper#parseRequest(org.apache.wicket.request.Request)
 */
@Override
protected UrlInfo parseRequest(Request request) {
    Url url = request.getUrl();
    if (matches(url)) {
        // try to extract page and component information from URL
        PageComponentInfo info = getPageComponentInfo(url);
        // load the page class
        String className = url.getSegments().get(2);
        Class<? extends IRequestablePage> pageClass = getPageClass(className);
        if (pageClass != null && IRequestablePage.class.isAssignableFrom(pageClass)) {
            if (Application.exists()) {
                Application application = Application.get();
                if (application.getSecuritySettings().getEnforceMounts()) {
                    // we make an excepion if the homepage itself was mounted, see WICKET-1898
                    if (!pageClass.equals(application.getHomePage())) {
                        // WICKET-5094 only enforce mount if page is mounted
                        Url reverseUrl = application.getRootRequestMapper().mapHandler(new RenderPageRequestHandler(new PageProvider(pageClass)));
                        if (!matches(reverseUrl)) {
                            return null;
                        }
                    }
                }
            }
            // extract the PageParameters from URL if there are any
            PageParameters pageParameters = extractPageParameters(request, 3, pageParametersEncoder);
            return new UrlInfo(info, pageClass, pageParameters);
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_6e794ad0,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/BookmarkableMapper.java,150,160,"/**
 *  @see AbstractBookmarkableMapper#getCompatibilityScore(org.apache.wicket.request.Request)
 */
@Override
public int getCompatibilityScore(Request request) {
    int score = 0;
    Url url = request.getUrl();
    if (matches(url)) {
        score = Integer.MAX_VALUE;
    }
    return score;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_6e794ad0,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/BookmarkableMapper.java,162,166,"private boolean matches(final Url url) {
    return (url.getSegments().size() >= 3 && urlStartsWith(url, getContext().getNamespace(), getContext().getBookmarkableIdentifier()));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_a2f848f2,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/PageInstanceMapper.java,59,98,"/**
 *  @see org.apache.wicket.request.IRequestMapper#mapRequest(org.apache.wicket.request.Request)
 */
@Override
public IRequestHandler mapRequest(Request request) {
    Url url = request.getUrl();
    if (matches(url)) {
        PageComponentInfo info = getPageComponentInfo(url);
        if (info != null && info.getPageInfo().getPageId() != null) {
            Integer renderCount = info.getComponentInfo() != null ? info.getComponentInfo().getRenderCount() : null;
            if (info.getComponentInfo() == null) {
                PageProvider provider = new PageProvider(info.getPageInfo().getPageId(), renderCount);
                provider.setPageSource(getContext());
                // render page
                return new RenderPageRequestHandler(provider);
            } else {
                ComponentInfo componentInfo = info.getComponentInfo();
                PageAndComponentProvider provider = new PageAndComponentProvider(info.getPageInfo().getPageId(), renderCount, componentInfo.getComponentPath());
                provider.setPageSource(getContext());
                // listener interface
                RequestListenerInterface listenerInterface = requestListenerInterfaceFromString(componentInfo.getListenerInterface());
                return new ListenerInterfaceRequestHandler(provider, listenerInterface, componentInfo.getBehaviorId());
            }
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_a2f848f2,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/PageInstanceMapper.java,152,162,"/**
 *  @see org.apache.wicket.request.IRequestMapper#getCompatibilityScore(org.apache.wicket.request.Request)
 */
@Override
public int getCompatibilityScore(final Request request) {
    int score = 0;
    Url url = request.getUrl();
    if (matches(url)) {
        score = Integer.MAX_VALUE;
    }
    return score;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_a2f848f2,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/PageInstanceMapper.java,164,167,"private boolean matches(final Url url) {
    return urlStartsWith(url, getContext().getNamespace(), getContext().getPageIdentifier());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_d3d42d42,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/BookmarkableMapper.java,175,200,"private boolean matches(final Request request) {
    boolean matches = false;
    Url url = request.getUrl();
    Url baseUrl = request.getClientUrl();
    String namespace = getContext().getNamespace();
    String bookmarkableIdentifier = getContext().getBookmarkableIdentifier();
    String pageIdentifier = getContext().getPageIdentifier();
    if (url.getSegments().size() >= 3 && urlStartsWith(url, namespace, bookmarkableIdentifier)) {
        matches = true;
    } else // baseUrl = 'wicket/bookmarkable/com.example.SomePage[?...]', requestUrl = 'bookmarkable/com.example.SomePage'
    if (baseUrl.getSegments().size() == 3 && urlStartsWith(baseUrl, namespace, bookmarkableIdentifier) && url.getSegments().size() >= 2 && urlStartsWith(url, bookmarkableIdentifier)) {
        matches = true;
    } else // baseUrl = 'wicket/page[?...]', requestUrl = 'bookmarkable/com.example.SomePage'
    if (baseUrl.getSegments().size() == 2 && urlStartsWith(baseUrl, namespace, pageIdentifier) && url.getSegments().size() >= 2 && urlStartsWith(url, bookmarkableIdentifier)) {
        matches = true;
    }
    return matches;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_d3d42d42,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/PageInstanceMapper.java,174,194,"/**
 *  Matches when the request url starts with
 *  {@link org.apache.wicket.core.request.mapper.IMapperContext#getNamespace()}/{@link org.apache.wicket.core.request.mapper.IMapperContext#getPageIdentifier()}
 *  or when the base url starts with
 *  {@link org.apache.wicket.core.request.mapper.IMapperContext#getNamespace()}/{@link org.apache.wicket.core.request.mapper.IMapperContext#getPageIdentifier()}
 *  and the request url with {@link org.apache.wicket.core.request.mapper.IMapperContext#getPageIdentifier()}
 *
 *  @param request
 *       the request to check
 *  @return {@code true} if the conditions match
 */
private boolean matches(final Request request) {
    boolean matches = false;
    Url url = request.getUrl();
    String namespace = getContext().getNamespace();
    String pageIdentifier = getContext().getPageIdentifier();
    if (urlStartsWith(url, namespace, pageIdentifier)) {
        matches = true;
    } else if (urlStartsWith(request.getClientUrl(), namespace, pageIdentifier) && urlStartsWith(url, pageIdentifier)) {
        matches = true;
    } else if (urlStartsWith(request.getClientUrl(), pageIdentifier) && urlStartsWith(url, pageIdentifier)) {
        matches = true;
    }
    return matches;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_faaae8d3,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/BookmarkableMapper.java,175,200,"private boolean matches(final Request request) {
    boolean matches = false;
    Url url = request.getUrl();
    Url baseUrl = request.getClientUrl();
    String namespace = getContext().getNamespace();
    String bookmarkableIdentifier = getContext().getBookmarkableIdentifier();
    String pageIdentifier = getContext().getPageIdentifier();
    if (url.getSegments().size() >= 3 && urlStartsWith(url, namespace, bookmarkableIdentifier)) {
        matches = true;
    } else // baseUrl = 'wicket/bookmarkable/com.example.SomePage[?...]', requestUrl = 'bookmarkable/com.example.SomePage'
    if (baseUrl.getSegments().size() == 3 && urlStartsWith(baseUrl, namespace, bookmarkableIdentifier) && url.getSegments().size() >= 2 && urlStartsWith(url, bookmarkableIdentifier)) {
        matches = true;
    } else // baseUrl = 'wicket/page[?...]', requestUrl = 'bookmarkable/com.example.SomePage'
    if (baseUrl.getSegments().size() == 2 && urlStartsWith(baseUrl, namespace, pageIdentifier) && url.getSegments().size() >= 2 && urlStartsWith(url, bookmarkableIdentifier)) {
        matches = true;
    }
    return matches;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5071_faaae8d3,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/PageInstanceMapper.java,174,194,"/**
 *  Matches when the request url starts with
 *  {@link org.apache.wicket.core.request.mapper.IMapperContext#getNamespace()}/{@link org.apache.wicket.core.request.mapper.IMapperContext#getPageIdentifier()}
 *  or when the base url starts with
 *  {@link org.apache.wicket.core.request.mapper.IMapperContext#getNamespace()}/{@link org.apache.wicket.core.request.mapper.IMapperContext#getPageIdentifier()}
 *  and the request url with {@link org.apache.wicket.core.request.mapper.IMapperContext#getPageIdentifier()}
 *
 *  @param request
 *       the request to check
 *  @return {@code true} if the conditions match
 */
private boolean matches(final Request request) {
    boolean matches = false;
    Url url = request.getUrl();
    String namespace = getContext().getNamespace();
    String pageIdentifier = getContext().getPageIdentifier();
    if (urlStartsWith(url, namespace, pageIdentifier)) {
        matches = true;
    } else if (urlStartsWith(request.getClientUrl(), namespace, pageIdentifier) && urlStartsWith(url, pageIdentifier)) {
        matches = true;
    } else if (urlStartsWith(request.getClientUrl(), pageIdentifier) && urlStartsWith(url, pageIdentifier)) {
        matches = true;
    }
    return matches;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5072_381b90fd,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/mock/Cookies.java,56,64,"/**
 *  Checks whether two cookies are equal.
 *  See http://www.ietf.org/rfc/rfc2109.txt, p.4.3.3
 *
 *  @param c1
 *       the first cookie
 *  @param c2
 *       the second cookie
 *  @return {@code true} only if the cookies have the same name, path and domain
 */
public static boolean isEqual(Cookie c1, Cookie c2) {
    Args.notNull(c1, ""c1"");
    Args.notNull(c2, ""c2"");
    return c1.getName().equals(c2.getName()) && ((c1.getPath() == null && c2.getPath() == null) || (c1.getPath().equals(c2.getPath()))) && ((c1.getDomain() == null && c2.getDomain() == null) || (c1.getDomain().equals(c2.getDomain())));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5082_217fbb3b,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AbstractAjaxResponse.java,443,493,"/**
 *  @param response
 *       the response to write to
 *  @param component
 *       to component which will contribute to the header
 */
protected void writeHeaderContribution(final Response response, final Component component) {
    headerRendering = true;
    // create the htmlheadercontainer if needed
    if (header == null) {
        header = new AjaxHtmlHeaderContainer(this);
        final Page parentPage = component.getPage();
        parentPage.addOrReplace(header);
    }
    RequestCycle requestCycle = component.getRequestCycle();
    // save old response, set new
    Response oldResponse = requestCycle.setResponse(encodingHeaderResponse);
    try {
        encodingHeaderResponse.reset();
        // render the head of component and all it's children
        component.renderHead(header);
        if (component instanceof MarkupContainer) {
            ((MarkupContainer) component).visitChildren(new IVisitor<Component, Void>() {

                @Override
                public void component(final Component component, final IVisit<Void> visit) {
                    if (component.isVisibleInHierarchy()) {
                        component.renderHead(header);
                    } else {
                        visit.dontGoDeeper();
                    }
                }
            });
        }
    } finally {
        // revert to old response
        requestCycle.setResponse(oldResponse);
    }
    writeHeaderContribution(response);
    headerRendering = false;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5082_217fbb3b,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AbstractAjaxResponse.java,471,482,"@Override
public void component(final Component component, final IVisit<Void> visit) {
    if (component.isVisibleInHierarchy()) {
        component.renderHead(header);
    } else {
        visit.dontGoDeeper();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5082_217fbb3b,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AjaxEventBehavior.java,76,95,"@Override
public void renderHead(final Component component, final IHeaderResponse response) {
    super.renderHead(component, response);
    if (component.isEnabledInHierarchy()) {
        CharSequence js = getCallbackScript(component);
        AjaxRequestTarget target = component.getRequestCycle().find(AjaxRequestTarget.class);
        if (target == null) {
            response.render(OnDomReadyHeaderItem.forScript(js.toString()));
        } else {
            target.appendJavaScript(js);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5085_581c7306,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/internal/InlineEnclosure.java,97,116,"/**
 *  {@link InlineEnclosure}s keep their own cache of their markup because Component#markup is
 *  detached and later during Ajax request it is hard to re-lookup {@link InlineEnclosure}'s
 *  markup from its parent.
 *
 *  @see org.apache.wicket.Component#getMarkup()
 */
@Override
public IMarkupFragment getMarkup() {
    IMarkupFragment enclosureMarkup = null;
    if (enclosureMarkupAsString == null) {
        IMarkupFragment markup = super.getMarkup();
        if (markup != null && markup != Markup.NO_MARKUP) {
            enclosureMarkup = markup;
            enclosureMarkupAsString = markup.toString(true);
        }
    } else {
        enclosureMarkup = Markup.of(enclosureMarkupAsString, getWicketNamespace());
    }
    return enclosureMarkup;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5085_581c7306,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/InlineEnclosureHandler.java,80,169,"@Override
protected MarkupElement onComponentTag(final ComponentTag tag) throws ParseException {
    // We only need ComponentTags
    if (tag instanceof WicketTag) {
        return tag;
    }
    // Has wicket:enclosure attribute?
    String enclosureAttr = getAttribute(tag, null);
    if (enclosureAttr != null) {
        if (tag.isOpen()) {
            // Make sure 'wicket:id' and 'id' are consistent
            String htmlId = tag.getAttribute(""id"");
            if ((tag.getId() != null) && !Strings.isEmpty(htmlId) && !htmlId.equals(tag.getId())) {
                throw new ParseException(""Make sure that 'id' and 'wicket:id' are the same if both are provided. Tag:"" + tag.toString(), tag.getPos());
            }
            // if it doesn't have a wicket-id already, then assign one now.
            if (Strings.isEmpty(tag.getId())) {
                if (Strings.isEmpty(htmlId)) {
                    String id = getWicketNamespace() + ""_"" + INLINE_ENCLOSURE_ID_PREFIX;
                    tag.setId(id);
                } else {
                    tag.setId(htmlId);
                }
                tag.setAutoComponentTag(true);
                tag.setModified(true);
            }
            // Put the enclosure on the stack. The most current one will be on top
            if (enclosures == null) {
                enclosures = new Stack<ComponentTag>();
            }
            enclosures.push(tag);
        } else {
            throw new ParseException(""Open-close tags don't make sense for InlineEnclosure. Tag:"" + tag.toString(), tag.getPos());
        }
    } else // Are we within an enclosure?
    if ((enclosures != null) && (enclosures.size() > 0)) {
        // first ComponentTag's id found as the controlling child to the enclosure.
        if (tag.isOpen() && (tag.getId() != null) && !(tag instanceof WicketTag) && !tag.isAutoComponentTag()) {
            for (int i = enclosures.size() - 1; i >= 0; i--) {
                ComponentTag lastEnclosure = enclosures.get(i);
                String attr = getAttribute(lastEnclosure, null);
                if (Strings.isEmpty(attr) == true) {
                    lastEnclosure.getAttributes().put(getInlineEnclosureAttributeName(null), tag.getId());
                    lastEnclosure.setModified(true);
                }
            }
        } else if (tag.isClose() && tag.closes(enclosures.peek())) {
            ComponentTag lastEnclosure = enclosures.pop();
            String attr = getAttribute(lastEnclosure, null);
            if (Strings.isEmpty(attr) == true) {
                throw new ParseException(""Did not find any child for InlineEnclosure. Tag:"" + lastEnclosure.toString(), tag.getPos());
            }
        }
    }
    return tag;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5085_581c7306,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/InlineEnclosureHandler.java,193,211,"@Override
public Component resolve(final MarkupContainer container, final MarkupStream markupStream, final ComponentTag tag) {
    String inlineEnclosureChildId = getAttribute(tag, markupStream);
    if (Strings.isEmpty(inlineEnclosureChildId) == false) {
        String id = tag.getId();
        if (id.startsWith(getWicketNamespace(markupStream))) {
            id = id + container.getPage().getAutoIndex();
        }
        // Yes, we handled the tag
        return new InlineEnclosure(id, inlineEnclosureChildId);
    }
    // We were not able to handle the tag
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5094_74e77676,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/BookmarkableMapper.java,91,123,"/**
 *  @see AbstractBookmarkableMapper#parseRequest(org.apache.wicket.request.Request)
 */
@Override
protected UrlInfo parseRequest(Request request) {
    if (Application.exists()) {
        if (Application.get().getSecuritySettings().getEnforceMounts()) {
            return null;
        }
    }
    Url url = request.getUrl();
    if (matches(url)) {
        // try to extract page and component information from URL
        PageComponentInfo info = getPageComponentInfo(url);
        // load the page class
        String className = url.getSegments().get(2);
        Class<? extends IRequestablePage> pageClass = getPageClass(className);
        if (pageClass != null && IRequestablePage.class.isAssignableFrom(pageClass)) {
            // extract the PageParameters from URL if there are any
            PageParameters pageParameters = extractPageParameters(request, 3, pageParametersEncoder);
            return new UrlInfo(info, pageClass, pageParameters);
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5102_d110e307,Major,wicket-experimental/wicket-bean-validation/src/main/java/org/apache/wicket/bean/validation/DefaultPropertyResolver.java,21,48,"@Override
public Property resolveProperty(FormComponent<?> component) {
    IModel<?> model = component.getModel();
    if (!(model instanceof IPropertyReflectionAwareModel)) {
        return null;
    }
    IPropertyReflectionAwareModel<?> delegate = (IPropertyReflectionAwareModel<?>) model;
    Field field = delegate.getPropertyField();
    if (field != null) {
        return new Property(field.getDeclaringClass(), field.getName());
    }
    Method getter = delegate.getPropertyGetter();
    if (getter != null) {
        String name = getter.getName().substring(3, 1).toLowerCase() + getter.getName().substring(4);
        return new Property(getter.getDeclaringClass(), name);
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5114_518c933b,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,647,694,"/**
 *  Stringizes this url
 *
 *  @param mode
 *             {@link StringMode} that determins how to stringize the url
 *  @param charset
 *             charset
 *  @return sringized version of this url
 */
public String toString(StringMode mode, Charset charset) {
    StringBuilder result = new StringBuilder();
    final String path = getPath(charset);
    if (StringMode.FULL == mode) {
        if (Strings.isEmpty(host)) {
            throw new IllegalStateException(""Cannot render this url in "" + StringMode.FULL.name() + "" mode because it does not have a host set."");
        }
        if (Strings.isEmpty(protocol) == false) {
            result.append(protocol);
            result.append(""://"");
        } else if (Strings.isEmpty(protocol) && Strings.isEmpty(host) == false) {
            result.append(""//"");
        }
        result.append(host);
        if (port != null && port.equals(getDefaultPortForProtocol(protocol)) == false) {
            result.append(':');
            result.append(port);
        }
        if (path.contains("".."")) {
            throw new IllegalStateException(""Cannot render this url in "" + StringMode.FULL.name() + "" mode because it has a `..` segment: "" + toString());
        }
        if (!path.startsWith(""/"")) {
            result.append('/');
        }
    }
    result.append(path);
    result.append(getQueryString(charset));
    return result.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5131_4b7367ef,Major,wicket-request/src/main/java/org/apache/wicket/request/http/handler/RedirectRequestHandler.java,92,120,"/**
 * {@inheritDoc}
 */
public void respond(final IRequestCycle requestCycle) {
    final String location;
    if (redirectUrl.startsWith(""/"")) {
        // context-absolute url
        location = requestCycle.getUrlRenderer().renderContextRelativeUrl(redirectUrl);
    } else {
        // if relative url, servlet container will translate to absolute as
        // per the servlet spec
        // if absolute url still do the same
        location = redirectUrl;
    }
    WebResponse response = (WebResponse) requestCycle.getResponse();
    if (status == HttpServletResponse.SC_MOVED_TEMPORARILY) {
        response.sendRedirect(location);
    } else {
        response.setStatus(HttpServletResponse.SC_MOVED_PERMANENTLY);
        response.setHeader(""Location"", location);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5138_e8dab4a0,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/WicketFilter.java,138,237,"/**
 *  This is Wicket's main method to execute a request
 *
 *  @param request
 *  @param response
 *  @param chain
 *  @return false, if the request could not be processed
 *  @throws IOException
 *  @throws ServletException
 */
boolean processRequest(ServletRequest request, final ServletResponse response, final FilterChain chain) throws IOException, ServletException {
    final ThreadContext previousThreadContext = ThreadContext.detach();
    // Assume we are able to handle the request
    boolean res = true;
    final ClassLoader previousClassLoader = Thread.currentThread().getContextClassLoader();
    final ClassLoader newClassLoader = getClassLoader();
    try {
        if (previousClassLoader != newClassLoader) {
            Thread.currentThread().setContextClassLoader(newClassLoader);
        }
        HttpServletRequest httpServletRequest = (HttpServletRequest) request;
        HttpServletResponse httpServletResponse = (HttpServletResponse) response;
        // Make sure getFilterPath() gets called before checkIfRedirectRequired()
        String filterPath = getFilterPath(httpServletRequest);
        if (filterPath == null) {
            throw new IllegalStateException(""filter path was not configured"");
        }
        if (shouldIgnorePath(httpServletRequest)) {
            log.debug(""Ignoring request {}"", httpServletRequest.getRequestURL());
            if (chain != null) {
                chain.doFilter(request, response);
            }
            return false;
        }
        if (""OPTIONS"".equals(httpServletRequest.getMethod())) {
            // handle the OPTIONS request outside of normal request processing.
            // wicket pages normally only support GET and POST methods, but resources and
            // special pages acting like REST clients can also support other methods, so
            // we include them all.
            httpServletResponse.setStatus(HttpServletResponse.SC_OK);
            httpServletResponse.setHeader(""Allow"", ""GET,POST,OPTIONS,PUT,HEAD,PATCH,DELETE,TRACE"");
            httpServletResponse.setHeader(""Content-Length"", ""0"");
            return true;
        }
        String redirectURL = checkIfRedirectRequired(httpServletRequest);
        if (redirectURL == null) {
            // No redirect; process the request
            ThreadContext.setApplication(application);
            WebRequest webRequest = application.createWebRequest(httpServletRequest, filterPath);
            WebResponse webResponse = application.createWebResponse(webRequest, httpServletResponse);
            RequestCycle requestCycle = application.createRequestCycle(webRequest, webResponse);
            res = processRequestCycle(requestCycle, webResponse, httpServletRequest, httpServletResponse, chain);
        } else {
            if (Strings.isEmpty(httpServletRequest.getQueryString()) == false) {
                redirectURL += ""?"" + httpServletRequest.getQueryString();
            }
            try {
                // send redirect - this will discard POST parameters if the request is POST
                // - still better than getting an error because of lacking trailing slash
                httpServletResponse.sendRedirect(httpServletResponse.encodeRedirectURL(redirectURL));
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
        }
    } finally {
        ThreadContext.restore(previousThreadContext);
        if (newClassLoader != previousClassLoader) {
            Thread.currentThread().setContextClassLoader(previousClassLoader);
        }
        if (response.isCommitted()) {
            response.flushBuffer();
        }
    }
    return res;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5138_e8dab4a0,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/WicketFilter.java,251,270,"/**
 *  Process the request cycle
 *
 *  @param requestCycle
 *  @param webResponse
 *  @param httpServletRequest
 *  @param httpServletResponse
 *  @param chain
 *  @return false, if the request could not be processed
 *  @throws IOException
 *  @throws ServletException
 */
protected boolean processRequestCycle(RequestCycle requestCycle, WebResponse webResponse, HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, final FilterChain chain) throws IOException, ServletException {
    // Assume we are able to handle the request
    boolean res = true;
    if (!requestCycle.processRequestAndDetach()) {
        if (chain != null) {
            chain.doFilter(httpServletRequest, httpServletResponse);
        }
        res = false;
    } else {
        webResponse.flush();
    }
    return res;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5138_e8dab4a0,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/WicketFilter.java,523,526,"/**
 *  Provide a standard getter for filterPath.
 *  @return The configured filterPath.
 */
protected String getFilterPath() {
    return filterPath;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5138_e8dab4a0,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/WicketFilter.java,782,827,"/**
 *  A filterPath should have all leading slashes removed and exactly one trailing slash. A
 *  wildcard asterisk character has no special meaning. If your intention is to mean the top
 *  level ""/"" then an empty string should be used instead.
 *
 *  @param filterPath
 *  @return
 */
static String canonicaliseFilterPath(String filterPath) {
    if (Strings.isEmpty(filterPath)) {
        return filterPath;
    }
    int beginIndex = 0;
    int endIndex = filterPath.length();
    while (beginIndex < endIndex) {
        char c = filterPath.charAt(beginIndex);
        if (c != '/') {
            break;
        }
        beginIndex++;
    }
    int o;
    int i = o = beginIndex;
    while (i < endIndex) {
        char c = filterPath.charAt(i);
        i++;
        if (c != '/') {
            o = i;
        }
    }
    if (o < endIndex) {
        // include exactly one trailing slash
        o++;
        filterPath = filterPath.substring(beginIndex, o);
    } else {
        // ensure to append trailing slash
        filterPath = filterPath.substring(beginIndex) + '/';
    }
    if (filterPath.equals(""/"")) {
        return """";
    }
    return filterPath;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5147_184e51e9,Major,wicket-core/src/main/java/org/apache/wicket/DefaultExceptionMapper.java,51,77,"@Override
public IRequestHandler map(Exception e) {
    try {
        Response response = RequestCycle.get().getResponse();
        if (response instanceof WebResponse) {
            // we don't wan't to cache an exceptional reply in the browser
            ((WebResponse) response).disableCaching();
        }
        return internalMap(e);
    } catch (RuntimeException e2) {
        if (logger.isDebugEnabled()) {
            logger.error(""An error occurred while handling a previous error: "" + e2.getMessage(), e2);
        }
        // hmmm, we were already handling an exception! give up
        logger.error(""unexpected exception when handling another exception: "" + e.getMessage(), e);
        return new ErrorCodeRequestHandler(500);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5147_184e51e9,Major,wicket-core/src/main/java/org/apache/wicket/DefaultExceptionMapper.java,79,142,"private IRequestHandler internalMap(Exception e) {
    final Application application = Application.get();
    // check if we are processing an Ajax request and if we want to invoke the failure handler
    if (isProcessingAjaxRequest()) {
        switch(application.getExceptionSettings().getAjaxErrorHandlingStrategy()) {
            case INVOKE_FAILURE_HANDLER:
                return new ErrorCodeRequestHandler(500);
        }
    }
    if (e instanceof StalePageException) {
        // (the url should always be updated by an redirect in that case)
        return new RenderPageRequestHandler(new PageProvider(((StalePageException) e).getPage()));
    } else if (e instanceof PageExpiredException) {
        return createPageRequestHandler(new PageProvider(Application.get().getApplicationSettings().getPageExpiredErrorPage()));
    } else if (e instanceof AuthorizationException || e instanceof ListenerInvocationNotAllowedException) {
        return createPageRequestHandler(new PageProvider(Application.get().getApplicationSettings().getAccessDeniedPage()));
    } else if (e instanceof ResponseIOException) {
        logger.error(""Connection lost, give up responding."", e);
        return new EmptyRequestHandler();
    } else {
        final UnexpectedExceptionDisplay unexpectedExceptionDisplay = application.getExceptionSettings().getUnexpectedExceptionDisplay();
        logger.error(""Unexpected error occurred"", e);
        if (IExceptionSettings.SHOW_EXCEPTION_PAGE.equals(unexpectedExceptionDisplay)) {
            Page currentPage = extractCurrentPage();
            return createPageRequestHandler(new PageProvider(new ExceptionErrorPage(e, currentPage)));
        } else if (IExceptionSettings.SHOW_INTERNAL_ERROR_PAGE.equals(unexpectedExceptionDisplay)) {
            return createPageRequestHandler(new PageProvider(application.getApplicationSettings().getInternalErrorPage()));
        } else {
            // IExceptionSettings.SHOW_NO_EXCEPTION_PAGE
            return new ErrorCodeRequestHandler(500);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5147_184e51e9,Major,wicket-core/src/main/java/org/apache/wicket/Page.java,433,485,"/**
 *  Gets whether the page is stateless. Components on stateless page must not render any stateful
 *  urls, and components on stateful page must not render any stateless urls. Stateful urls are
 *  urls, which refer to a certain (current) page instance.
 *
 *  @return Whether this page is stateless
 */
@Override
public final boolean isPageStateless() {
    if (isBookmarkable() == false) {
        stateless = Boolean.FALSE;
        if (getStatelessHint()) {
            log.warn(""Page '"" + this + ""' is not stateless because it is not bookmarkable, "" + ""but the stateless hint is set to true!"");
        }
    }
    if (getStatelessHint() == false) {
        return false;
    }
    if (stateless == null) {
        if (isStateless() == false) {
            stateless = Boolean.FALSE;
        }
    }
    if (stateless == null) {
        Component statefulComponent = visitChildren(Component.class, new IVisitor<Component, Component>() {

            @Override
            public void component(final Component component, final IVisit<Component> visit) {
                if (!component.isStateless()) {
                    visit.stop(component);
                }
            }
        });
        stateless = statefulComponent == null;
        if (log.isDebugEnabled() && !stateless.booleanValue() && getStatelessHint()) {
            log.debug(""Page '{}' is not stateless because of component with path '{}'."", this, statefulComponent.getPageRelativePath());
        }
    }
    return stateless;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5147_184e51e9,Major,wicket-core/src/main/java/org/apache/wicket/page/AbstractPageManager.java,127,135,"/**
 *  @see org.apache.wicket.page.IPageManager#touchPage(org.apache.wicket.page.IManageablePage)
 */
@Override
public void touchPage(IManageablePage page) {
    if (!page.isPageStateless()) {
        getContext().bind();
    }
    getRequestAdapter().touch(page);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5147_184e51e9,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/WicketFilter.java,365,441,"/**
 *  Servlets and Filters are treated essentially the same with Wicket. This is the entry point
 *  for both of them.
 *
 *  @see #init(FilterConfig)
 *
 *  @param isServlet
 *             True if Servlet, false if Filter
 *  @param filterConfig
 *  @throws ServletException
 */
public void init(final boolean isServlet, final FilterConfig filterConfig) throws ServletException {
    this.filterConfig = filterConfig;
    this.isServlet = isServlet;
    initIgnorePaths(filterConfig);
    final ClassLoader previousClassLoader = Thread.currentThread().getContextClassLoader();
    final ClassLoader newClassLoader = getClassLoader();
    try {
        if (previousClassLoader != newClassLoader) {
            Thread.currentThread().setContextClassLoader(newClassLoader);
        }
        // locate application instance unless it was already specified during construction
        if (application == null) {
            applicationFactory = getApplicationFactory();
            application = applicationFactory.createApplication(this);
        }
        application.setName(filterConfig.getFilterName());
        application.setWicketFilter(this);
        // Allow the filterPath to be preset via setFilterPath()
        String configureFilterPath = getFilterPath();
        if (configureFilterPath == null) {
            configureFilterPath = getFilterPathFromConfig(filterConfig);
            if (configureFilterPath == null) {
                configureFilterPath = getFilterPathFromWebXml(isServlet, filterConfig);
                if (configureFilterPath == null) {
                    configureFilterPath = getFilterPathFromAnnotation(isServlet);
                }
            }
            if (configureFilterPath != null) {
                setFilterPath(configureFilterPath);
            }
        }
        if (getFilterPath() == null) {
            log.warn(""Unable to determine filter path from filter init-param, web.xml, "" + ""or servlet 3.0 annotations. Assuming user will set filter path "" + ""manually by calling setFilterPath(String)"");
        }
        ThreadContext.setApplication(application);
        try {
            application.initApplication();
            // Give the application the option to log that it is started
            application.logStarted();
        } finally {
            ThreadContext.detach();
        }
    } finally {
        if (newClassLoader != previousClassLoader) {
            Thread.currentThread().setContextClassLoader(previousClassLoader);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5147_184e51e9,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/WicketFilter.java,562,583,"/**
 *  @see javax.servlet.Filter#destroy()
 */
@Override
public void destroy() {
    if (application != null) {
        try {
            ThreadContext.setApplication(application);
            application.internalDestroy();
        } finally {
            ThreadContext.detach();
            application = null;
        }
    }
    if (applicationFactory != null) {
        applicationFactory.destroy(this);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5147_184e51e9,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/WicketFilter.java,786,831,"/**
 *  A filterPath should have all leading slashes removed and exactly one trailing slash. A
 *  wildcard asterisk character has no special meaning. If your intention is to mean the top
 *  level ""/"" then an empty string should be used instead.
 *
 *  @param filterPath
 *  @return
 */
static String canonicaliseFilterPath(String filterPath) {
    if (Strings.isEmpty(filterPath)) {
        return filterPath;
    }
    int beginIndex = 0;
    int endIndex = filterPath.length();
    while (beginIndex < endIndex) {
        char c = filterPath.charAt(beginIndex);
        if (c != '/') {
            break;
        }
        beginIndex++;
    }
    int o;
    int i = o = beginIndex;
    while (i < endIndex) {
        char c = filterPath.charAt(i);
        i++;
        if (c != '/') {
            o = i;
        }
    }
    if (o < endIndex) {
        // include exactly one trailing slash
        o++;
        filterPath = filterPath.substring(beginIndex, o);
    } else {
        // ensure to append trailing slash
        filterPath = filterPath.substring(beginIndex) + '/';
    }
    if (filterPath.equals(""/"")) {
        return """";
    }
    return filterPath;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5157_961f2477,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,338,349,"/**
 *  @param qp
 *  @param charset
 *  @return query parameters
 */
private static QueryParameter parseQueryParameter(final String qp, final Charset charset) {
    if (qp.indexOf('=') == -1) {
        // name => empty value
        return new QueryParameter(decodeParameter(qp, charset), """");
    }
    String[] parts = Strings.split(qp, '=');
    return new QueryParameter(decodeParameter(parts[0], charset), decodeParameter(parts[1], charset));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5165_0d4d1df7,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/render/WebPageRenderer.java,146,151,"/**
 *  @param url
 *  @param requestCycle
 */
protected void redirectTo(Url url, RequestCycle requestCycle) {
    WebResponse response = (WebResponse) requestCycle.getResponse();
    String relativeUrl = requestCycle.getUrlRenderer().renderUrl(url);
    response.sendRedirect(relativeUrl);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5176_34634266,Minor,wicket-core/src/main/java/org/apache/wicket/model/StringResourceModel.java,596,623,"/**
 *  @see org.apache.wicket.model.IDetachable#detach()
 */
@Override
protected final void onDetach() {
    super.onDetach();
    // detach any model
    if (model != null) {
        model.detach();
    }
    // some parameters can be detachable
    if (parameters != null) {
        for (Object parameter : parameters) {
            if (parameter instanceof IDetachable) {
                ((IDetachable) parameter).detach();
            }
        }
    }
    if (defaultValue != null) {
        defaultValue.detach();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5204_9e6efa61,Major,wicket-datetime/src/main/java/org/apache/wicket/extensions/yui/calendar/DateTimeField.java,419,467,"/**
 *  @see org.apache.wicket.Component#onBeforeRender()
 */
@Override
protected void onBeforeRender() {
    dateField.setRequired(isRequired());
    hoursField.setRequired(isRequired());
    minutesField.setRequired(isRequired());
    boolean use12HourFormat = use12HourFormat();
    amOrPmChoice.setVisible(use12HourFormat);
    Date modelObject = (Date) getDefaultModelObject();
    if (modelObject == null) {
        date = null;
        hours = null;
        minutes = null;
    } else {
        MutableDateTime mDate;
        // convert date to the client's time zone if we have that info
        TimeZone zone = getClientTimeZone();
        if (zone != null) {
            mDate = new MutableDateTime(modelObject, DateTimeZone.forTimeZone(zone));
        } else {
            mDate = new MutableDateTime(modelObject);
        }
        date = mDate.toDate();
        if (use12HourFormat) {
            int hourOfHalfDay = mDate.get(DateTimeFieldType.hourOfHalfday());
            hours = hourOfHalfDay == 0 ? 12 : hourOfHalfDay;
        } else {
            hours = mDate.get(DateTimeFieldType.hourOfDay());
        }
        amOrPm = (mDate.get(DateTimeFieldType.halfdayOfDay()) == 0) ? AM_PM.AM : AM_PM.PM;
        minutes = mDate.getMinuteOfHour();
    }
    super.onBeforeRender();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5209_55eb5212,Major,wicket-core/src/main/java/org/apache/wicket/core/util/string/ComponentRenderer.java,90,112,"/**
 *  Collects the html generated by the rendering of a component.
 *
 *  @param component
 *             the component to render.
 *  @return the html rendered by the component
 */
public static CharSequence renderComponent(final Component component) {
    RequestCycle requestCycle = RequestCycle.get();
    final Response originalResponse = requestCycle.getResponse();
    BufferedWebResponse tempResponse = new BufferedWebResponse(null);
    try {
        requestCycle.setResponse(tempResponse);
        RenderPage page = new RenderPage();
        page.add(component);
        component.render();
    } finally {
        requestCycle.setResponse(originalResponse);
    }
    return tempResponse.getText();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5226_8e518d88,Major,wicket-cdi/src/main/java/org/apache/wicket/cdi/ComponentInjector.java,46,59,"@Override
public void onInstantiation(Component component) {
    Class<? extends Component> componentClass = component.getClass();
    if (componentClass.isMemberClass() && Modifier.isStatic(componentClass.getModifiers()) == false) {
        LOG.debug(""Skipping non-static inner class '{}' "", componentClass);
    } else {
        inject(component);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5230_9c8f658a,Major,wicket-core/src/main/java/org/apache/wicket/ajax/form/AjaxFormComponentUpdatingBehavior.java,128,164,"/**
 *  @see org.apache.wicket.ajax.AjaxEventBehavior#onEvent(org.apache.wicket.ajax.AjaxRequestTarget)
 */
@Override
protected final void onEvent(final AjaxRequestTarget target) {
    final FormComponent<?> formComponent = getFormComponent();
    if (""blur"".equals(getEvent().toLowerCase()) && disableFocusOnBlur()) {
        target.focusComponent(null);
    }
    try {
        formComponent.inputChanged();
        formComponent.validate();
        if (formComponent.hasErrorMessage()) {
            formComponent.invalid();
            onError(target, null);
        } else {
            formComponent.valid();
            if (getUpdateModel()) {
                formComponent.updateModel();
            }
            onUpdate(target);
        }
    } catch (RuntimeException e) {
        onError(target, e);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5247_44a4132f,Minor,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/MountedMapper.java,408,446,"/**
 *  @see AbstractBookmarkableMapper#buildUrl(AbstractBookmarkableMapper.UrlInfo)
 */
@Override
protected Url buildUrl(UrlInfo info) {
    Url url = new Url();
    for (String s : mountSegments) {
        url.getSegments().add(s);
    }
    encodePageComponentInfo(url, info.getPageComponentInfo());
    PageParameters copy = new PageParameters(info.getPageParameters());
    int dropped = 0;
    for (int i = 0; i < mountSegments.length; ++i) {
        String placeholder = getPlaceholder(mountSegments[i]);
        String optionalPlaceholder = getOptionalPlaceholder(mountSegments[i]);
        if (placeholder != null) {
            url.getSegments().set(i - dropped, copy.get(placeholder).toString(""""));
            copy.remove(placeholder);
        } else if (optionalPlaceholder != null) {
            if (copy.getNamedKeys().contains(optionalPlaceholder)) {
                url.getSegments().set(i - dropped, copy.get(optionalPlaceholder).toString(""""));
                copy.remove(optionalPlaceholder);
            } else {
                url.getSegments().remove(i - dropped);
                dropped++;
            }
        }
    }
    return encodePageParameters(url, copy, pageParametersEncoder);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5250_6122df49,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/CssResourceReference.java,76,81,"@Override
public CssPackageResource getResource() {
    return new CssPackageResource(getScope(), getName(), getLocale(), getStyle(), getVariation());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5250_6122df49,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/JavaScriptResourceReference.java,78,83,"@Override
public JavaScriptPackageResource getResource() {
    return new JavaScriptPackageResource(getScope(), getName(), getLocale(), getStyle(), getVariation());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5250_6122df49,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/PackageResourceReference.java,109,139,"/**
 *  @see org.apache.wicket.request.resource.ResourceReference#getResource()
 */
@Override
public PackageResource getResource() {
    final String extension = getExtension();
    final PackageResource resource;
    if (CSS_EXTENSION.equals(extension)) {
        resource = new CssPackageResource(getScope(), getName(), getLocale(), getStyle(), getVariation());
    } else if (JAVASCRIPT_EXTENSION.equals(extension)) {
        resource = new JavaScriptPackageResource(getScope(), getName(), getLocale(), getStyle(), getVariation());
    } else {
        resource = new PackageResource(getScope(), getName(), getLocale(), getStyle(), getVariation());
    }
    String minifiedName = MINIFIED_NAMES_CACHE.get(this);
    if (minifiedName != null && minifiedName != NO_MINIFIED_NAME) {
        resource.setCompress(false);
    }
    return resource;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5251_3d2393c7,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/PackageResourceReference.java,202,216,"/**
 *  @return How the minified file should be named.
 */
protected String getMinifiedName() {
    String name = super.getName();
    String minifiedName;
    int idxOfExtension = name.lastIndexOf('.');
    if (idxOfExtension > -1) {
        String extension = name.substring(idxOfExtension);
        minifiedName = name.substring(0, name.length() - extension.length() + 1) + ""min"" + extension;
    } else {
        minifiedName = name + "".min"";
    }
    return minifiedName;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5251_6ce34ccf,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/PackageResourceReference.java,202,216,"/**
 *  @return How the minified file should be named.
 */
protected String getMinifiedName() {
    String name = super.getName();
    String minifiedName;
    int idxOfExtension = name.lastIndexOf('.');
    if (idxOfExtension > -1) {
        String extension = name.substring(idxOfExtension);
        minifiedName = name.substring(0, name.length() - extension.length() + 1) + ""min"" + extension;
    } else {
        minifiedName = name + "".min"";
    }
    return minifiedName;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5259_a9e56e1e,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,203,330,"/**
 *  Parses the given URL string.
 *
 *  @param _url
 *             absolute or relative url with query string
 *  @param charset
 *  @return Url object
 */
public static Url parse(CharSequence _url, Charset charset) {
    Args.notNull(_url, ""_url"");
    final Url result = new Url(charset);
    // the url object resolved the charset, use that
    charset = result.getCharset();
    String url = _url.toString();
    // extract query string part
    final String queryString;
    final String absoluteUrl;
    final int queryAt = url.indexOf('?');
    if (queryAt == -1) {
        queryString = """";
        absoluteUrl = url;
    } else {
        absoluteUrl = url.substring(0, queryAt);
        queryString = url.substring(queryAt + 1);
    }
    // get absolute / relative part of url
    String relativeUrl;
    final int idxOfFirstSlash = absoluteUrl.indexOf('/');
    final int protocolAt = absoluteUrl.indexOf(""://"");
    // full urls start either with a ""scheme://"" or with ""//""
    boolean protocolLess = absoluteUrl.startsWith(""//"");
    final boolean isFull = (protocolAt > 1 && (protocolAt < idxOfFirstSlash)) || protocolLess;
    if (isFull) {
        if (protocolLess == false) {
            result.protocol = absoluteUrl.substring(0, protocolAt).toLowerCase(Locale.US);
        }
        final String afterProto = absoluteUrl.substring(protocolAt + 3);
        final String hostAndPort;
        int relativeAt = afterProto.indexOf('/');
        if (relativeAt == -1) {
            relativeAt = afterProto.indexOf(';');
        }
        if (relativeAt == -1) {
            relativeUrl = """";
            hostAndPort = afterProto;
        } else {
            relativeUrl = afterProto.substring(relativeAt);
            hostAndPort = afterProto.substring(0, relativeAt);
        }
        final int portAt = hostAndPort.lastIndexOf(':');
        if (portAt == -1) {
            result.host = hostAndPort;
            result.port = getDefaultPortForProtocol(result.protocol);
        } else {
            result.host = hostAndPort.substring(0, portAt);
            result.port = Integer.parseInt(hostAndPort.substring(portAt + 1));
        }
        if (relativeAt < 0) {
            relativeUrl = ""/"";
        }
    } else {
        relativeUrl = absoluteUrl;
    }
    if (relativeUrl.length() > 0) {
        boolean removeLast = false;
        if (relativeUrl.endsWith(""/"")) {
            // we need to append something and remove it after splitting
            // because otherwise the
            // trailing slashes will be lost
            relativeUrl += ""/x"";
            removeLast = true;
        }
        String[] segmentArray = Strings.split(relativeUrl, '/');
        if (removeLast) {
            segmentArray[segmentArray.length - 1] = null;
        }
        for (String s : segmentArray) {
            if (s != null) {
                result.segments.add(decodeSegment(s, charset));
            }
        }
    }
    if (queryString.length() > 0) {
        String[] queryArray = Strings.split(queryString, '&');
        for (String s : queryArray) {
            if (Strings.isEmpty(s) == false) {
                result.parameters.add(parseQueryParameter(s, charset));
            }
        }
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5265_0eb596df,Major,wicket-core/src/main/java/org/apache/wicket/feedback/FencedFeedbackPanel.java,146,158,"@Override
protected void onRemove() {
    super.onRemove();
    if (fence != null) {
        // decrement the fence count
        Integer count = fence.getMetaData(FENCE_KEY);
        count = (count == null || count == 1) ? null : count - 1;
        fence.setMetaData(FENCE_KEY, count);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5265_0eb596df,Major,wicket-core/src/main/java/org/apache/wicket/feedback/FencedFeedbackPanel.java,160,201,"@Override
protected FeedbackMessagesModel newFeedbackMessagesModel() {
    return new FeedbackMessagesModel(this) {

        private static final long serialVersionUID = 1L;

        @Override
        protected List<FeedbackMessage> collectMessages(Component panel, IFeedbackMessageFilter filter) {
            if (fence == null) {
                return new FeedbackCollector(panel.getPage()) {

                    @Override
                    protected boolean shouldRecurseInto(Component component) {
                        return component.getMetaData(FENCE_KEY) == null;
                    }
                }.collect(filter);
            } else {
                return new FeedbackCollector(fence) {

                    @Override
                    protected boolean shouldRecurseInto(Component component) {
                        return component.getMetaData(FENCE_KEY) == null;
                    }
                }.setIncludeSession(false).collect(filter);
            }
        }
    };
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5265_0eb596df,Major,wicket-core/src/main/java/org/apache/wicket/feedback/FencedFeedbackPanel.java,167,199,"@Override
protected List<FeedbackMessage> collectMessages(Component panel, IFeedbackMessageFilter filter) {
    if (fence == null) {
        return new FeedbackCollector(panel.getPage()) {

            @Override
            protected boolean shouldRecurseInto(Component component) {
                return component.getMetaData(FENCE_KEY) == null;
            }
        }.collect(filter);
    } else {
        return new FeedbackCollector(fence) {

            @Override
            protected boolean shouldRecurseInto(Component component) {
                return component.getMetaData(FENCE_KEY) == null;
            }
        }.setIncludeSession(false).collect(filter);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5265_0eb596df,Major,wicket-core/src/main/java/org/apache/wicket/feedback/FencedFeedbackPanel.java,177,181,"@Override
protected boolean shouldRecurseInto(Component component) {
    return component.getMetaData(FENCE_KEY) == null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5265_0eb596df,Major,wicket-core/src/main/java/org/apache/wicket/feedback/FencedFeedbackPanel.java,190,196,"@Override
protected boolean shouldRecurseInto(Component component) {
    return component.getMetaData(FENCE_KEY) == null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5319_c863b032,Minor,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/CryptoMapper.java,91,102,"@Override
public Url mapHandler(final IRequestHandler requestHandler) {
    final Url url = wrappedMapper.mapHandler(requestHandler);
    if (url == null) {
        return null;
    }
    return encryptUrl(url);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5319_c863b032,Minor,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/CryptoMapper.java,163,247,"protected Url decryptUrl(final Request request, final Url encryptedUrl) {
    /*
		 * If the encrypted URL has no segments it is the home page URL,
		 * and does not need decrypting.
		 */
    if (encryptedUrl.getSegments().isEmpty()) {
        return encryptedUrl;
    }
    List<String> encryptedSegments = encryptedUrl.getSegments();
    Url url = new Url(request.getCharset());
    try {
        /*
			 * The first encrypted segment contains an encrypted version of the
			 * entire plain text url.
			 */
        String encryptedUrlString = encryptedSegments.get(0);
        if (Strings.isEmpty(encryptedUrlString)) {
            return null;
        }
        String decryptedUrl = getCrypt().decryptUrlSafe(encryptedUrlString);
        if (decryptedUrl == null) {
            return null;
        }
        Url originalUrl = Url.parse(decryptedUrl, request.getCharset());
        int originalNumberOfSegments = originalUrl.getSegments().size();
        int encryptedNumberOfSegments = encryptedUrl.getSegments().size();
        HashedSegmentGenerator generator = new HashedSegmentGenerator(encryptedUrlString);
        int segNo = 1;
        for (; segNo < encryptedNumberOfSegments; segNo++) {
            if (segNo > originalNumberOfSegments) {
                break;
            }
            String next = generator.next();
            String encryptedSegment = encryptedSegments.get(segNo);
            if (!next.equals(encryptedSegment)) {
                /*
					 * This segment received from the browser is not the same as the
					 * expected segment generated by the HashSegmentGenerator. Hence it,
					 * and all subsequent segments are considered plain text siblings of the
					 * original encrypted url.
					 */
                break;
            }
            /*
				 * This segments matches the expected checksum, so we add the corresponding
				 * segment from the original URL.
				 */
            url.getSegments().add(originalUrl.getSegments().get(segNo - 1));
        }
        /*
			 * Add all remaining segments from the encrypted url as plain text segments.
			 */
        for (; segNo < encryptedNumberOfSegments; segNo++) {
            // modified or additional segment
            url.getSegments().add(encryptedUrl.getSegments().get(segNo));
        }
        url.getQueryParameters().addAll(originalUrl.getQueryParameters());
        // WICKET-4923 additional parameters
        url.getQueryParameters().addAll(encryptedUrl.getQueryParameters());
    } catch (Exception e) {
        log.error(""Error decrypting URL"", e);
        url = null;
    }
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5319_c863b032,Minor,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/CryptoMapper.java,284,299,"/**
 *  Generate the next segment
 *
 *  @return segment
 */
public String next() {
    char a = characters[Math.abs(hash % characters.length)];
    hash++;
    char b = characters[Math.abs(hash % characters.length)];
    hash++;
    char c = characters[Math.abs(hash % characters.length)];
    String segment = """" + a + b + c;
    hash = hashString(segment);
    segment += String.format(""%02x"", Math.abs(hash % 256));
    hash = hashString(segment);
    return segment;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5326_ded3c583,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/CryptoMapper.java,90,94,"@Override
public int getCompatibilityScore(final Request request) {
    return wrappedMapper.getCompatibilityScore(request);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5326_ded3c583,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/CryptoMapper.java,96,113,"@Override
public Url mapHandler(final IRequestHandler requestHandler) {
    final Url url = wrappedMapper.mapHandler(requestHandler);
    if (url == null) {
        return null;
    }
    if (url.isFull()) {
        // do not encrypt full urls
        return url;
    }
    return encryptUrl(url);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5326_ded3c583,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/CryptoMapper.java,115,135,"@Override
public IRequestHandler mapRequest(final Request request) {
    Url url = decryptUrl(request, request.getUrl());
    if (url == null) {
        return wrappedMapper.mapRequest(request);
    }
    Request decryptedRequest = request.cloneWithUrl(url);
    IRequestHandler handler = wrappedMapper.mapRequest(decryptedRequest);
    if (handler != null) {
        handler = new RequestSettingRequestHandler(decryptedRequest, handler);
    }
    return handler;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5326_ded3c583,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/CryptoMapper.java,155,173,"protected Url encryptUrl(final Url url) {
    if (url.getSegments().isEmpty()) {
        return url;
    }
    String encryptedUrlString = getCrypt().encryptUrlSafe(url.toString());
    Url encryptedUrl = new Url(url.getCharset());
    encryptedUrl.getSegments().add(encryptedUrlString);
    int numberOfSegments = url.getSegments().size();
    HashedSegmentGenerator generator = new HashedSegmentGenerator(encryptedUrlString);
    for (int segNo = 0; segNo < numberOfSegments; segNo++) {
        encryptedUrl.getSegments().add(generator.next());
    }
    return encryptedUrl;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5326_ded3c583,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/CryptoMapper.java,175,258,"protected Url decryptUrl(final Request request, final Url encryptedUrl) {
    /*
		 * If the encrypted URL has no segments it is the home page URL, and does not need
		 * decrypting.
		 */
    if (encryptedUrl.getSegments().isEmpty()) {
        return encryptedUrl;
    }
    List<String> encryptedSegments = encryptedUrl.getSegments();
    Url url = new Url(request.getCharset());
    try {
        /*
			 * The first encrypted segment contains an encrypted version of the entire plain text
			 * url.
			 */
        String encryptedUrlString = encryptedSegments.get(0);
        if (Strings.isEmpty(encryptedUrlString)) {
            return null;
        }
        String decryptedUrl = getCrypt().decryptUrlSafe(encryptedUrlString);
        if (decryptedUrl == null) {
            return null;
        }
        Url originalUrl = Url.parse(decryptedUrl, request.getCharset());
        int originalNumberOfSegments = originalUrl.getSegments().size();
        int encryptedNumberOfSegments = encryptedUrl.getSegments().size();
        HashedSegmentGenerator generator = new HashedSegmentGenerator(encryptedUrlString);
        int segNo = 1;
        for (; segNo < encryptedNumberOfSegments; segNo++) {
            if (segNo > originalNumberOfSegments) {
                break;
            }
            String next = generator.next();
            String encryptedSegment = encryptedSegments.get(segNo);
            if (!next.equals(encryptedSegment)) {
                /*
					 * This segment received from the browser is not the same as the expected
					 * segment generated by the HashSegmentGenerator. Hence it, and all subsequent
					 * segments are considered plain text siblings of the original encrypted url.
					 */
                break;
            }
            /*
				 * This segments matches the expected checksum, so we add the corresponding segment
				 * from the original URL.
				 */
            url.getSegments().add(originalUrl.getSegments().get(segNo - 1));
        }
        /*
			 * Add all remaining segments from the encrypted url as plain text segments.
			 */
        for (; segNo < encryptedNumberOfSegments; segNo++) {
            // modified or additional segment
            url.getSegments().add(encryptedUrl.getSegments().get(segNo));
        }
        url.getQueryParameters().addAll(originalUrl.getQueryParameters());
        // WICKET-4923 additional parameters
        url.getQueryParameters().addAll(encryptedUrl.getQueryParameters());
    } catch (Exception e) {
        log.error(""Error decrypting URL"", e);
        url = null;
    }
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5345_3fc7234e,Major,wicket-request/src/main/java/org/apache/wicket/request/Url.java,1210,1235,"/**
 *  Try to reduce url by eliminating '..' and '.' from the path where appropriate (this is
 *  somehow similar to {@link java.io.File#getCanonicalPath()}). Either by different / unexpected
 *  browser behavior or by malicious attacks it can happen that these kind of redundant urls are
 *  processed by wicket. These urls can cause some trouble when mapping the request.
 *  <p/>
 *  <strong>example:</strong>
 *
 *  the url
 *
 *  <pre>
 *  /example/..;jsessionid=234792?0
 *  </pre>
 *
 *  will not get normalized by the browser due to the ';jsessionid' string that gets appended by
 *  the servlet container. After wicket strips the jsessionid part the resulting internal url
 *  will be
 *
 *  <pre>
 *  /example/..
 *  </pre>
 *
 *  instead of
 *
 *  <pre>
 *  /
 *  </pre>
 *
 *  <p/>
 *
 *  This code correlates to <a
 *  href=""https://issues.apache.org/jira/browse/WICKET-4303"">WICKET-4303</a>
 *
 *  @return canonical url
 */
public Url canonical() {
    Url url = new Url(this);
    url.segments.clear();
    for (int i = 0; i < segments.size(); i++) {
        final String segment = segments.get(i);
        // drop '.' from path
        if (""."".equals(segment)) {
            continue;
        }
        // skip segment if following segment is a '..'
        if ((i + 1) < segments.size() && "".."".equals(segments.get(i + 1))) {
            i++;
            continue;
        }
        url.segments.add(segment);
    }
    return url;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,376,379,"/**
 *  Converts this StringValue to a given type or {@code null} if the value is empty.
 *
 *  @param type
 *             The type to convert to
 *  @return The converted value
 *  @throws StringValueConversionException
 */
public final <T> T toOptional(final Class<T> type) throws StringValueConversionException {
    return Strings.isEmpty(text) ? null : to(type);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,400,418,"/**
 *  Convert to boolean, returning default value if text is inconvertible.
 *
 *  @param defaultValue
 *             the default value
 *  @return the converted text as a boolean or the default value if text is empty or inconvertible
 *  @see Strings#isTrue(String)
 */
public final boolean toBoolean(final boolean defaultValue) {
    if (text != null) {
        try {
            return toBoolean();
        } catch (StringValueConversionException x) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(String.format(""An error occurred while converting '%s' to a boolean: %s"", text, x.getMessage()), x);
            }
        }
    }
    return defaultValue;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,449,467,"/**
 *  Convert to character, returning default value if text is inconvertible.
 *
 *  @param defaultValue
 *             the default value
 *  @return the converted text as a primitive char or the default value if text is not a single character
 */
public final char toChar(final char defaultValue) {
    if (text != null) {
        try {
            return toChar();
        } catch (StringValueConversionException x) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(String.format(""An error occurred while converting '%s' to a character: %s"", text, x.getMessage()), x);
            }
        }
    }
    return defaultValue;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,544,547,"/**
 *  Convert this text to a Duration instance.
 *
 *  @return Converted text
 *  @throws StringValueConversionException
 *  @see Duration#valueOf(String, java.util.Locale)
 */
public final Duration toDuration() throws StringValueConversionException {
    return Duration.valueOf(text, locale);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,557,575,"/**
 *  Convert to duration, returning default value if text is inconvertible.
 *
 *  @param defaultValue
 *             the default value
 *  @return the converted text as a duration or the default value if text is empty or inconvertible
 *  @see Duration#valueOf(String, java.util.Locale)
 */
public final Duration toDuration(final Duration defaultValue) {
    if (text != null) {
        try {
            return toDuration();
        } catch (Exception x) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(String.format(""An error occurred while converting '%s' to a Duration: %s"", text, x.getMessage()), x);
            }
        }
    }
    return defaultValue;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,668,686,"/**
 *  Convert to long integer, returning default value if text is inconvertible.
 *
 *  @param defaultValue
 *             the default value
 *  @return the converted text as a long integer or the default value if text is empty or inconvertible
 */
public final long toLong(final long defaultValue) {
    if (text != null) {
        try {
            return toLong();
        } catch (StringValueConversionException x) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(String.format(""An error occurred while converting '%s' to a long: %s"", text, x.getMessage()), x);
            }
        }
    }
    return defaultValue;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,869,873,"/**
 *  Convert this text to an enum.
 *
 *  @param eClass
 *             enum type
 *  @return The value as an enum
 *  @throws StringValueConversionException
 */
public final <T extends Enum<T>> T toEnum(Class<T> eClass) throws StringValueConversionException {
    return Strings.toEnum(text, eClass);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,882,886,"/**
 *  Convert this text to an enum.
 *
 *  @param defaultValue
 *             This will be returned if there is an error converting the value
 *  @return The value as an enum
 */
public final <T extends Enum<T>> T toEnum(final T defaultValue) {
    Args.notNull(defaultValue, ""defaultValue"");
    return toEnum((Class<T>) defaultValue.getClass(), defaultValue);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,897,915,"/**
 *  Convert this text to an enum.
 *
 *  @param eClass
 *             enum type
 *  @param defaultValue
 *             This will be returned if there is an error converting the value
 *  @return The value as an enum
 */
public final <T extends Enum<T>> T toEnum(Class<T> eClass, final T defaultValue) {
    if (text != null) {
        try {
            return toEnum(eClass);
        } catch (StringValueConversionException x) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(String.format(""An error occurred while converting '%s' to a %s: %s"", text, eClass, x.getMessage()), x);
            }
        }
    }
    return defaultValue;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,926,930,"/**
 *  Convert to enum, returning null if text is null or empty.
 *
 *  @param eClass
 *             enum type
 *
 *  @return converted
 *  @throws StringValueConversionException
 */
public final <T extends Enum<T>> T toOptionalEnum(Class<T> eClass) throws StringValueConversionException {
    return Strings.isEmpty(text) ? null : toEnum(eClass);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5359_61122bab,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/StringValue.java,965,978,"/**
 *  {@inheritDoc}
 */
@Override
public boolean equals(final Object obj) {
    if (obj instanceof StringValue) {
        StringValue stringValue = (StringValue) obj;
        return Objects.isEqual(text, stringValue.text) && Objects.isEqual(locale, stringValue.locale);
    } else {
        return false;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5398_19e7c1cd,Minor,wicket-core/src/main/java/org/apache/wicket/markup/parser/XmlPullParser.java,84,88,"@Override
public final String getEncoding() {
    return xmlReader.getEncoding();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5398_19e7c1cd,Minor,wicket-core/src/main/java/org/apache/wicket/markup/parser/XmlPullParser.java,544,548,"/**
 *  Parse the given string.
 *  <p>
 *  Note: xml character encoding is NOT applied. It is assumed the input provided does have the
 *  correct encoding already.
 *
 *  @param string
 *             The input string
 *  @throws IOException
 *              Error while reading the resource
 */
@Override
public void parse(final CharSequence string) throws IOException {
    parse(new ByteArrayInputStream(string.toString().getBytes()), null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5398_19e7c1cd,Minor,wicket-core/src/main/java/org/apache/wicket/markup/parser/XmlPullParser.java,558,563,"/**
 *  Reads and parses markup from an input stream, using UTF-8 encoding by default when not
 *  specified in XML declaration.
 *
 *  @param in
 *             The input stream to read and parse
 *  @throws IOException
 */
@Override
public void parse(final InputStream in) throws IOException {
    // When XML declaration does not specify encoding, it defaults to UTF-8
    parse(in, ""UTF-8"");
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5398_19e7c1cd,Minor,wicket-core/src/main/java/org/apache/wicket/markup/parser/XmlPullParser.java,574,589,"/**
 *  Reads and parses markup from an input stream
 *
 *  @param inputStream
 *             The input stream to read and parse
 *  @param encoding
 *             The default character encoding of the input
 *  @throws IOException
 */
@Override
public void parse(final InputStream inputStream, final String encoding) throws IOException {
    Args.notNull(inputStream, ""inputStream"");
    try {
        xmlReader = new XmlReader(new BufferedInputStream(inputStream, 4000), encoding);
        input = new FullyBufferedReader(xmlReader);
    } finally {
        IOUtils.closeQuietly(inputStream);
        IOUtils.closeQuietly(xmlReader);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5400_6cefb9f8,Minor,wicket-core/src/main/java/org/apache/wicket/Behaviors.java,63,70,"private void internalAdd(final Behavior behavior) {
    component.data_add(behavior);
    if (behavior.getStatelessHint(component)) {
        getBehaviorId(behavior);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5418_e350f19e,Major,wicket-experimental/wicket-bean-validation/src/main/java/org/apache/wicket/bean/validation/PropertyValidator.java,118,139,"@SuppressWarnings(""unchecked"")
@Override
public void bind(Component component) {
    if (this.component != null) {
        throw new // 
        IllegalStateException(""This validator has already been added to component: "" + this.component + "". This validator does not support reusing instances, please create a new one"");
    }
    if (!(component instanceof FormComponent)) {
        throw new IllegalStateException(getClass().getSimpleName() + "" can only be added to FormComponents"");
    }
    // TODO add a validation key that appends the type so we can have different messages for
    // @Size on String vs Collection - done but need to add a key for each superclass/interface
    this.component = (FormComponent<T>) component;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5418_e350f19e,Major,wicket-experimental/wicket-bean-validation/src/main/java/org/apache/wicket/bean/validation/PropertyValidator.java,141,152,"@Override
public void onConfigure(Component component) {
    super.onConfigure(component);
    if (requiredFlagSet == false) {
        // ""Required"" flag is calculated upon component's model property, so we must ensure,
        // that model object is accessible (i.e. component is already added in a page).
        requiredFlagSet = true;
        setComponentRequiredFlag();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5418_e350f19e,Major,wicket-experimental/wicket-bean-validation/src/main/java/org/apache/wicket/bean/validation/PropertyValidator.java,167,185,"/**
 *  Marks the form component required if necessary
 */
private void setComponentRequiredFlag() {
    BeanValidationContext config = BeanValidationConfiguration.get();
    Validator validator = config.getValidator();
    Property property = getProperty();
    // if the property has a NotNull constraint mark the form component required
    Iterator<ConstraintDescriptor<?>> it = new ConstraintIterator(validator, property);
    while (it.hasNext()) {
        ConstraintDescriptor<?> desc = it.next();
        if (desc.getAnnotation().annotationType().equals(NotNull.class)) {
            component.setRequired(true);
            break;
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5418_e350f19e,Major,wicket-experimental/wicket-bean-validation/src/main/java/org/apache/wicket/bean/validation/PropertyValidator.java,187,214,"@Override
@SuppressWarnings({ ""rawtypes"", ""unchecked"" })
public void onComponentTag(Component component, ComponentTag tag) {
    super.onComponentTag(component, tag);
    BeanValidationContext config = BeanValidationConfiguration.get();
    Validator validator = config.getValidator();
    Property property = getProperty();
    // find any tag modifiers that apply to the constraints of the property being validated
    // and allow them to modify the component tag
    Iterator<ConstraintDescriptor<?>> it = new ConstraintIterator(validator, property, getGroups());
    while (it.hasNext()) {
        ConstraintDescriptor<?> desc = it.next();
        ITagModifier modifier = config.getTagModifier(desc.getAnnotation().annotationType());
        if (modifier != null) {
            modifier.modify((FormComponent<?>) component, tag, desc.getAnnotation());
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5426_fb45a781,Minor,wicket-core/src/main/java/org/apache/wicket/Page.java,798,819,"/**
 *  @see org.apache.wicket.Component#onBeforeRender()
 */
@Override
protected void onBeforeRender() {
    // Make sure it is really empty
    renderedComponents = null;
    // if the page is stateless, reset the flag so that it is tested again
    if (Boolean.TRUE.equals(stateless)) {
        stateless = null;
    }
    super.onBeforeRender();
    // for links rendered before first stateful component
    if (getSession().isTemporary() && !peekPageStateless()) {
        getSession().bind();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5426_fb45a781,Minor,wicket-core/src/main/java/org/apache/wicket/Page.java,1014,1028,"/**
 *  @see org.apache.wicket.request.component.IRequestablePage#renderPage()
 */
@Override
public void renderPage() {
    // page id is frozen during the render
    final boolean frozen = setFreezePageId(true);
    try {
        ++renderCount;
        render();
    } finally {
        setFreezePageId(frozen);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5441_8ccb1f6d,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/caching/FilenameWithVersionResourceCachingStrategy.java,196,201,"/**
 *  set resource caching to maximum and set cache-visibility to 'public'
 *
 *  @param response
 */
@Override
public void decorateResponse(AbstractResource.ResourceResponse response, IStaticCacheableResource resource) {
    response.setCacheDurationToMaximum();
    response.setCacheScope(WebResponse.CacheScope.PUBLIC);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5441_8ccb1f6d,Major,wicket-core/src/main/java/org/apache/wicket/request/resource/caching/QueryStringWithVersionResourceCachingStrategy.java,127,132,"@Override
public void decorateResponse(AbstractResource.ResourceResponse response, IStaticCacheableResource resource) {
    response.setCacheDurationToMaximum();
    response.setCacheScope(WebResponse.CacheScope.PUBLIC);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5442_a382917f,Major,wicket-util/src/main/java/org/apache/wicket/util/time/Time.java,350,353,"/**
 *  Retrieves the hour field of the given <code>Calendar</code>.
 *
 *  @param calendar
 *             the <code>Calendar</code> to get the field value from
 *  @return the hour field value
 */
public int getHour(final Calendar calendar) {
    return get(calendar, Calendar.HOUR);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5447_2abc18f1,Minor,wicket-extensions/src/main/java/org/apache/wicket/extensions/markup/html/repeater/tree/table/NodeBorder.java,79,88,"@Override
public void afterRender(Component component) {
    Response response = component.getResponse();
    for (int i = 0; i < branches.length; i++) {
        response.write(""</div>"");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5460_a3a5a40f,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,4201,4212,"/**
 *  @param setRenderingFlag
 *             rendering flag
 */
void internalMarkRendering(boolean setRenderingFlag) {
    if (setRenderingFlag) {
        setFlag(FLAG_PREPARED_FOR_RENDER, false);
        setFlag(FLAG_RENDERING, true);
    } else {
        setFlag(FLAG_RENDERING, false);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5466_c1c1f794,Major,wicket-core/src/main/java/org/apache/wicket/core/request/handler/ListenerInterfaceRequestHandler.java,154,234,"/**
 *  @see org.apache.wicket.request.IRequestHandler#respond(org.apache.wicket.request.IRequestCycle)
 */
@Override
public void respond(final IRequestCycle requestCycle) {
    final IRequestablePage page = getPage();
    final boolean freshPage = pageComponentProvider.isPageInstanceFresh();
    final boolean isAjax = ((WebRequest) requestCycle.getRequest()).isAjax();
    IRequestableComponent component;
    try {
        component = getComponent();
    } catch (ComponentNotFoundException e) {
        // either the page is stateless and the component we are looking for is not added in the
        // constructor
        // or the page is stateful+stale and a new instances was created by pageprovider
        // we denote this by setting component to null
        component = null;
    }
    if ((component == null && freshPage) || (component != null && getComponent().getPage() == page)) {
        if (page instanceof Page) {
            // initialize the page to be able to check whether it is stateless
            ((Page) page).internalInitialize();
        }
        final boolean isStateless = page.isPageStateless();
        RedirectPolicy policy = isStateless ? RedirectPolicy.NEVER_REDIRECT : RedirectPolicy.AUTO_REDIRECT;
        final IPageProvider pageProvider = new PageProvider(page);
        if (freshPage && (isStateless == false || component == null)) {
            if (LOG.isDebugEnabled()) {
                LOG.debug(""A ListenerInterface '{}' assigned to '{}' is executed on an expired stateful page. "" + ""Scheduling re-create of the page and ignoring the listener interface..."", listenerInterface, getComponentPath());
            }
            if (isAjax) {
                policy = RedirectPolicy.ALWAYS_REDIRECT;
            }
            requestCycle.scheduleRequestHandlerAfterCurrent(new RenderPageRequestHandler(pageProvider, policy));
            return;
        }
        if (isAjax == false && listenerInterface.isRenderPageAfterInvocation()) {
            // schedule page render after current request handler is done. this can be
            // overridden during invocation of listener
            // method (i.e. by calling RequestCycle#setResponsePage)
            requestCycle.scheduleRequestHandlerAfterCurrent(new RenderPageRequestHandler(pageProvider, policy));
        }
        invokeListener();
    } else {
        throw new WicketRuntimeException(""Component "" + getComponent() + "" has been removed from page."");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5476_813d8bee,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Check.java,149,235,"/**
 *  @see Component#onComponentTag(ComponentTag)
 *  @param tag
 *             the abstraction representing html tag of this component
 */
@Override
protected void onComponentTag(final ComponentTag tag) {
    // Default handling for component tag
    super.onComponentTag(tag);
    // must be attached to <input type=""checkbox"" .../> tag
    checkComponentTag(tag, ""input"");
    checkComponentTagAttribute(tag, ""type"", ""checkbox"");
    CheckGroup<?> group = getGroup();
    final String uuid = getValue();
    // assign name and value
    tag.put(""name"", group.getInputName());
    tag.put(""value"", uuid);
    // check if the model collection of the group contains the model object.
    // if it does check the check box.
    Collection<?> collection = (Collection<?>) group.getDefaultModelObject();
    // check for npe in group's model object
    if (collection == null) {
        throw new WicketRuntimeException(""CheckGroup ["" + group.getPath() + ""] contains a null model object, must be an object of type java.util.Collection"");
    }
    if (group.hasRawInput()) {
        final String raw = group.getRawInput();
        if (!Strings.isEmpty(raw)) {
            final String[] values = raw.split(FormComponent.VALUE_SEPARATOR);
            for (String value : values) {
                if (uuid.equals(value)) {
                    tag.put(""checked"", ""checked"");
                }
            }
        }
    } else if (collection.contains(getDefaultModelObject())) {
        tag.put(""checked"", ""checked"");
    }
    if (group.wantOnSelectionChangedNotifications()) {
        // url that points to this components IOnChangeListener method
        CharSequence url = group.urlFor(IOnChangeListener.INTERFACE, new PageParameters());
        Form<?> form = group.findParent(Form.class);
        if (form != null) {
            tag.put(""onclick"", form.getJsForInterfaceUrl(url));
        } else {
            // NOTE: do not encode the url as that would give invalid JavaScript
            tag.put(""onclick"", ""window.location.href='"" + url + (url.toString().indexOf('?') > -1 ? ""&"" : ""?"") + group.getInputName() + ""=' + this.value;"");
        }
    }
    if (!isActionAuthorized(ENABLE) || !isEnabledInHierarchy() || !group.isEnabledInHierarchy()) {
        tag.put(ATTR_DISABLED, ATTR_DISABLED);
    }
    // put group id into the class so we can easily identify all radios belonging to the group
    final String marker = ""wicket-"" + getGroup().getMarkupId();
    String clazz = tag.getAttribute(""class"");
    if (Strings.isEmpty(clazz)) {
        clazz = marker;
    } else {
        clazz = clazz + "" "" + marker;
    }
    tag.put(""class"", clazz);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5476_813d8bee,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Radio.java,151,221,"/**
 *  @see Component#onComponentTag(ComponentTag)
 *  @param tag
 *             the abstraction representing html tag of this component
 */
@Override
protected void onComponentTag(final ComponentTag tag) {
    // Default handling for component tag
    super.onComponentTag(tag);
    // must be attached to <input type=""radio"" .../> tag
    checkComponentTag(tag, ""input"");
    checkComponentTagAttribute(tag, ""type"", ""radio"");
    final String value = getValue();
    RadioGroup<?> group = getGroup();
    // assign name and value
    tag.put(""name"", group.getInputName());
    tag.put(""value"", value);
    // checked attribute, first check if there was a raw input on the group.
    if (group.hasRawInput()) {
        String rawInput = group.getRawInput();
        if (rawInput != null && rawInput.equals(value)) {
            tag.put(""checked"", ""checked"");
        }
    } else if (group.getModelComparator().compare(group, getDefaultModelObject())) {
        tag.put(""checked"", ""checked"");
    }
    if (group.wantOnSelectionChangedNotifications()) {
        // url that points to this components IOnChangeListener method
        CharSequence url = group.urlFor(IOnChangeListener.INTERFACE, new PageParameters());
        Form<?> form = group.findParent(Form.class);
        if (form != null) {
            tag.put(""onclick"", form.getJsForInterfaceUrl(url));
        } else {
            // NOTE: do not encode the url as that would give invalid JavaScript
            tag.put(""onclick"", ""window.location.href='"" + url + (url.toString().indexOf('?') > -1 ? ""&"" : ""?"") + group.getInputName() + ""=' + this.value;"");
        }
    }
    if (!isEnabledInHierarchy()) {
        tag.put(ATTR_DISABLED, ATTR_DISABLED);
    }
    // put group id into the class so we can easily identify all radios belonging to the group
    final String marker = ""wicket-"" + getGroup().getMarkupId();
    String clazz = tag.getAttribute(""class"");
    if (Strings.isEmpty(clazz)) {
        clazz = marker;
    } else {
        clazz = clazz + "" "" + marker;
    }
    tag.put(""class"", clazz);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5484_ecdfc124,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/render/WebPageRenderer.java,332,340,"/**
 *  Should the page be rendered immediately.
 */
protected boolean shouldRenderPageAndWriteResponse(RequestCycle cycle, Url currentUrl, Url targetUrl) {
    return neverRedirect(getRedirectPolicy()) || (!isAjax(cycle) && ((isOnePassRender() && notForcedRedirect(getRedirectPolicy())) || (targetUrl.equals(currentUrl) && notNewAndNotStatelessPage(isNewPageInstance(), isPageStateless())))) || (targetUrl.equals(currentUrl) && isRedirectToRender()) || shouldPreserveClientUrl(cycle);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5486_a79ed51e,Minor,wicket-core/src/main/java/org/apache/wicket/request/handler/render/WebPageRenderer.java,332,346,"/**
 *  Should the page be rendered immediately.
 */
protected boolean shouldRenderPageAndWriteResponse(RequestCycle cycle, Url currentUrl, Url targetUrl) {
    // WICKET-5484 never render and write for Ajax requests
    if (isAjax(cycle)) {
        return false;
    }
    return neverRedirect(getRedirectPolicy()) || ((isOnePassRender() && notForcedRedirect(getRedirectPolicy())) || (targetUrl.equals(currentUrl) && notNewAndNotStatelessPage(isNewPageInstance(), isPageStateless()))) || (targetUrl.equals(currentUrl) && isRedirectToRender()) || shouldPreserveClientUrl(cycle);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5497_724066f4,Major,wicket-core/src/main/java/org/apache/wicket/ajax/json/JsonUtils.java,38,89,"/**
 *  Converts a Map to JSONArray suitable for jQuery#param().
 *
 *  @param map
 *       the map with key/value(s)
 *  @return a JSONArray that contains JSONObject's with name/value pairs
 *  @throws JSONException
 */
public static JSONArray asArray(Map<String, Object> map) throws JSONException {
    JSONArray jsonArray = new JSONArray();
    if (map != null) {
        for (Map.Entry<String, Object> entry : map.entrySet()) {
            String name = entry.getKey();
            Object value = entry.getValue();
            if (value instanceof List) {
                List<?> values = (List<?>) value;
                for (Object v : values) {
                    if (v != null) {
                        JSONObject object = new JSONObject();
                        object.put(""name"", name);
                        object.put(""value"", v);
                        jsonArray.put(object);
                    }
                }
            } else if (value.getClass().isArray()) {
                Object[] array = (Object[]) value;
                for (Object v : array) {
                    if (v != null) {
                        JSONObject object = new JSONObject();
                        object.put(""name"", name);
                        object.put(""value"", v);
                        jsonArray.put(object);
                    }
                }
            } else {
                if (value != null) {
                    JSONObject object = new JSONObject();
                    object.put(""name"", name);
                    object.put(""value"", value);
                    jsonArray.put(object);
                }
            }
        }
    }
    return jsonArray;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5500_825da305,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractComponentMapper.java,131,136,"/**
 *  Loads page class with given name.
 *
 *  @param name
 *  @return class
 */
protected Class<? extends IRequestablePage> getPageClass(String name) {
    Args.notEmpty(name, ""name"");
    return WicketObjects.resolveClass(name);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5500_825da305,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/PackageMapper.java,132,166,"@Override
protected UrlInfo parseRequest(Request request) {
    Url url = request.getUrl();
    if (url.getSegments().size() > mountSegments.length) {
        // try to extract page and component information from URL
        PageComponentInfo info = getPageComponentInfo(url);
        // load the page class
        String className = url.getSegments().get(mountSegments.length);
        if (isValidClassName(className) == false) {
            return null;
        }
        className = transformFromUrl(className);
        String fullyQualifiedClassName = packageName.getName() + '.' + className;
        Class<? extends IRequestablePage> pageClass = getPageClass(fullyQualifiedClassName);
        if (pageClass != null && Modifier.isAbstract(pageClass.getModifiers()) == false && IRequestablePage.class.isAssignableFrom(pageClass)) {
            // extract the PageParameters from URL if there are any
            Url urlWithoutPageSegment = new Url(url);
            urlWithoutPageSegment.getSegments().remove(mountSegments.length);
            Request requestWithoutPageSegment = request.cloneWithUrl(urlWithoutPageSegment);
            PageParameters pageParameters = extractPageParameters(requestWithoutPageSegment, urlWithoutPageSegment);
            return new UrlInfo(info, pageClass, pageParameters);
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5505_6cceff44,Minor,wicket-bean-validation/src/main/java/org/apache/wicket/bean/validation/DefaultPropertyResolver.java,22,62,"@Override
public Property resolveProperty(FormComponent<?> component) {
    IModel<?> model = component.getModel();
    while (true) {
        if (model == null) {
            return null;
        }
        if (model instanceof IPropertyReflectionAwareModel) {
            break;
        }
        if (model instanceof IWrapModel<?>) {
            model = ((IWrapModel<?>) model).getWrappedModel();
            continue;
        }
        return null;
    }
    IPropertyReflectionAwareModel<?> delegate = (IPropertyReflectionAwareModel<?>) model;
    Field field = delegate.getPropertyField();
    if (field != null) {
        return new Property(field.getDeclaringClass(), field.getName());
    }
    Method getter = delegate.getPropertyGetter();
    if (getter != null) {
        String name = getter.getName().substring(3, 4).toLowerCase() + getter.getName().substring(4);
        return new Property(getter.getDeclaringClass(), name);
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5518_c2e12216,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/form/FormComponent.java,1616,1647,"/**
 *  Update the model of a {@link FormComponent} containing a {@link Collection}.
 *
 *  If the model object does not yet exists, a new {@link ArrayList} is filled with the converted
 *  input and used as the new model object. Otherwise the existing collection is modified
 *  in-place, then {@link Model#setObject(Object)} is called with the same instance: it allows
 *  the Model to be notified of changes even when {@link Model#getObject()} returns a different
 *  {@link Collection} at every invocation.
 *
 *  @param <S>
 *             collection type
 *  @param formComponent
 *             the form component to update
 *  @see FormComponent#updateModel()
 *  @throws UnsupportedOperationException
 *              if the existing model object Collection cannot be modified
 */
public static <S> void updateCollectionModel(FormComponent<Collection<S>> formComponent) {
    Collection<S> convertedInput = formComponent.getConvertedInput();
    Collection<S> collection = formComponent.getModelObject();
    if (collection == null) {
        collection = new ArrayList<>(convertedInput);
        formComponent.setDefaultModelObject(collection);
    } else {
        formComponent.modelChanging();
        collection.clear();
        if (convertedInput != null) {
            collection.addAll(convertedInput);
        }
        formComponent.modelChanged();
        try {
            formComponent.getModel().setObject(collection);
        } catch (Exception e) {
            // ignore this exception because it could be that there
            // is not setter for this collection.
            logger.info(""An error occurred while trying to set the new value for the property attached to "" + formComponent, e);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5522_5b730c0b,Major,wicket-core/src/main/java/org/apache/wicket/request/handler/render/WebPageRenderer.java,332,346,"/**
 *  Should the page be rendered immediately.
 */
protected boolean shouldRenderPageAndWriteResponse(RequestCycle cycle, Url currentUrl, Url targetUrl) {
    // WICKET-5484 never render and write for Ajax requests
    if (isAjax(cycle)) {
        return false;
    }
    return neverRedirect(getRedirectPolicy()) || ((isOnePassRender() && notForcedRedirect(getRedirectPolicy())) || (targetUrl.equals(currentUrl) && notNewAndNotStatelessPage(isNewPageInstance(), isPageStateless()))) || (targetUrl.equals(currentUrl) && isRedirectToRender()) || (shouldPreserveClientUrl(cycle) && notForcedRedirect(getRedirectPolicy()));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5546_f1af9e03,Minor,wicket-core/src/main/java/org/apache/wicket/Page.java,706,722,"/**
 *  Initializes Page by adding it to the Session and initializing it.
 */
private void init() {
    if (isBookmarkable() == false) {
        setStatelessHint(false);
    }
    // Set versioning of page based on default
    setVersioned(getApplication().getPageSettings().getVersionPagesByDefault());
    // All Pages are born dirty so they get clustered right away
    dirty(true);
    // this is a bit of a dirty hack, but calling dirty(true) results in isStateless called
    // which is bound to set the stateless cache to true as there are no components yet
    stateless = null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5560_aa82ccfc,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/BookmarkableMapper.java,84,139,"@Override
protected UrlInfo parseRequest(Request request) {
    if (matches(request)) {
        Url url = request.getUrl();
        // try to extract page and component information from URL
        PageComponentInfo info = getPageComponentInfo(url);
        List<String> segments = url.getSegments();
        // load the page class
        String className;
        if (segments.size() >= 3) {
            className = segments.get(2);
        } else {
            className = segments.get(1);
        }
        Class<? extends IRequestablePage> pageClass = getPageClass(className);
        if (pageClass != null && IRequestablePage.class.isAssignableFrom(pageClass)) {
            if (Application.exists()) {
                Application application = Application.get();
                if (application.getSecuritySettings().getEnforceMounts()) {
                    // we make an exception if the homepage itself was mounted, see WICKET-1898
                    if (!pageClass.equals(application.getHomePage())) {
                        // WICKET-5094 only enforce mount if page is mounted
                        Url reverseUrl = application.getRootRequestMapper().mapHandler(new RenderPageRequestHandler(new PageProvider(pageClass)));
                        if (!matches(request.cloneWithUrl(reverseUrl))) {
                            return null;
                        }
                    }
                }
            }
            // extract the PageParameters from URL if there are any
            PageParameters pageParameters = extractPageParameters(request, 3, pageParametersEncoder);
            return new UrlInfo(info, pageClass, pageParameters);
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5565_204849bc,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,206,207,"/**
 *  @see IRequestMapper#getCompatibilityScore(Request)
 */
@Override
public abstract int getCompatibilityScore(Request request);"
wicket,remotes/origin/bugs-dot-jar_WICKET-5565_204849bc,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/MountedMapper.java,273,292,"/**
 *  @see AbstractBookmarkableMapper#getCompatibilityScore(org.apache.wicket.request.Request)
 */
@Override
public int getCompatibilityScore(Request request) {
    if (urlStartsWith(request.getUrl(), mountSegments)) {
        /* see WICKET-5056 - alter score with pathSegment type */
        int countOptional = 0;
        int fixedSegments = 0;
        for (MountPathSegment pathSegment : pathSegments) {
            fixedSegments += pathSegment.getFixedPartSize();
            countOptional += pathSegment.getOptionalParameters();
        }
        return mountSegments.length - countOptional + fixedSegments;
    } else {
        return 0;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5565_204849bc,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/PackageMapper.java,225,236,"@Override
public int getCompatibilityScore(Request request) {
    if (urlStartsWith(request.getUrl(), mountSegments)) {
        return mountSegments.length;
    } else {
        return 0;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5565_44f4782a,Major,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/PackageMapper.java,225,230,"@Override
public int getCompatibilityScore(Request request) {
    // always return 0 here so that the mounts have higher priority
    return 0;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5569_5efb8091,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/AbstractMarkupSourcingStrategy.java,60,79,"/**
 *  If the child has not been directly added to the container, but via a
 *  TransparentWebMarkupContainer, then we are in trouble. In general Wicket iterates over the
 *  markup elements and searches for associated components, not the other way around. Because of
 *  TransparentWebMarkupContainer (or more generally resolvers), there is no ""synchronous"" search
 *  possible.
 *
 *  @param container
 *             the parent container.
 *  @param child
 *             The component to find the markup for.
 *  @return the markup fragment for the child, or {@code null}.
 */
protected IMarkupFragment searchMarkupInTransparentResolvers(final MarkupContainer container, final Component child) {
    IMarkupFragment markup = null;
    for (Component ch : container) {
        if ((ch != child) && (ch instanceof MarkupContainer) && (ch instanceof IComponentResolver)) {
            markup = ((MarkupContainer) ch).getMarkup(child);
            if (markup != null) {
                break;
            }
        }
    }
    return markup;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5570_57d8f051,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AbstractAjaxTimerBehavior.java,86,105,"@Override
public void renderHead(Component component, IHeaderResponse response) {
    super.renderHead(component, response);
    response.render(JavaScriptHeaderItem.forScript(""if (typeof(Wicket.TimerHandles) === 'undefined') {Wicket.TimerHandles = {}}"", WICKET_TIMERS_ID));
    if (component.getRequestCycle().find(AjaxRequestTarget.class) == null) {
        // complete page is rendered, so timeout has to be rendered again
        hasTimeout = false;
    }
    if (isStopped() == false) {
        addTimeout(response);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5570_57d8f051,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AbstractAjaxTimerBehavior.java,112,121,"/**
 *  @param updateInterval
 *             Duration between AJAX callbacks
 *  @return JS script
 */
protected final String getJsTimeoutCall(final Duration updateInterval) {
    CharSequence js = getCallbackScript();
    js = JavaScriptUtils.escapeQuotes(js);
    String timeoutHandle = getTimeoutHandle();
    // this might look strange, but it is necessary for IE not to leak :(
    return timeoutHandle + "" = setTimeout('"" + js + ""', "" + updateInterval.getMilliseconds() + ')';
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5570_57d8f051,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AbstractAjaxTimerBehavior.java,126,128,"/**
 *  @return the name of the handle that is used to stop any scheduled timer
 */
private String getTimeoutHandle() {
    return ""Wicket.TimerHandles['"" + getComponent().getMarkupId() + ""']"";
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5570_57d8f051,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AbstractAjaxTimerBehavior.java,215,225,"private void clearTimeout(IHeaderResponse headerResponse) {
    if (hasTimeout) {
        hasTimeout = false;
        String timeoutHandle = getTimeoutHandle();
        headerResponse.render(OnLoadHeaderItem.forScript(""clearTimeout("" + timeoutHandle + ""); delete "" + timeoutHandle + "";""));
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5572_cd414fa5,Major,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,2163,2187,"/**
 *  Checks if this container can dequeue a child represented by the specified tag. This method
 *  should be overridden when containers can dequeue components represented by non-standard tags.
 *  For example, borders override this method and dequeue their body container when processing
 *  the body tag.
 *
 *  By default all {@link ComponentTag}s are supported as well as {@link WicketTag}s that return
 *  a non-null value from {@link WicketTag#getAutoComponentFactory()} method.
 *
 *  @param tag
 */
protected DequeueTagAction canDequeueTag(ComponentTag tag) {
    if (tag instanceof WicketTag) {
        WicketTag wicketTag = (WicketTag) tag;
        if (wicketTag.isContainerTag()) {
            return DequeueTagAction.DEQUEUE;
        } else if (wicketTag.getAutoComponentFactory() != null) {
            return DequeueTagAction.DEQUEUE;
        } else if (wicketTag.isFragmentTag()) {
            return DequeueTagAction.SKIP;
        } else {
            // dont know
            return null;
        }
    }
    return DequeueTagAction.DEQUEUE;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5578_5cdc1c8d,Major,wicket-core/src/main/java/org/apache/wicket/Component.java,4544,4548,"@Override
public boolean canCallListenerInterfaceAfterExpiry() {
    return getApplication().getPageSettings().getCallListenerInterfaceAfterExpiry();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5582_1fb66533,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/servlet/ServletWebResponse.java,171,199,"@Override
public String encodeURL(CharSequence url) {
    Args.notNull(url, ""url"");
    /*
		  WICKET-4645 - always pass absolute url to the web container for encoding
		  because when REDIRECT_TO_BUFFER is in use Wicket may render PageB when
		  PageA is actually the requested one and the web container cannot resolve
		  the base url properly
		 */
    UrlRenderer urlRenderer = RequestCycle.get().getUrlRenderer();
    Url relativeUrl = Url.parse(url);
    String fullUrl = urlRenderer.renderFullUrl(relativeUrl);
    String encodedFullUrl = httpServletResponse.encodeURL(fullUrl);
    final String encodedRelativeUrl;
    if (fullUrl.equals(encodedFullUrl)) {
        // no encoding happened so just reuse the relative url
        encodedRelativeUrl = url.toString();
    } else {
        // get the relative url with the jsessionid encoded in it
        Url _encoded = Url.parse(encodedFullUrl);
        encodedRelativeUrl = urlRenderer.renderRelativeUrl(_encoded);
    }
    return encodedRelativeUrl;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5582_1fb66533,Major,wicket-core/src/main/java/org/apache/wicket/protocol/http/servlet/ServletWebResponse.java,201,229,"@Override
public String encodeRedirectURL(CharSequence url) {
    Args.notNull(url, ""url"");
    /*
		  WICKET-4854 - always pass absolute url to the web container for encoding
		  because when REDIRECT_TO_BUFFER is in use Wicket may render PageB when
		  PageA is actually the requested one and the web container cannot resolve
		  the base url properly
		 */
    UrlRenderer urlRenderer = new UrlRenderer(webRequest);
    Url relativeUrl = Url.parse(url);
    String fullUrl = urlRenderer.renderFullUrl(relativeUrl);
    String encodedFullUrl = httpServletResponse.encodeRedirectURL(fullUrl);
    final String encodedRelativeUrl;
    if (fullUrl.equals(encodedFullUrl)) {
        // no encoding happened so just reuse the relative url
        encodedRelativeUrl = url.toString();
    } else {
        // get the relative url with the jsessionid encoded in it
        Url _encoded = Url.parse(encodedFullUrl);
        encodedRelativeUrl = urlRenderer.renderRelativeUrl(_encoded);
    }
    return encodedRelativeUrl;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5655_d558004b,Minor,wicket-core/src/main/java/org/apache/wicket/Component.java,2958,2983,"/**
 *  Sets the given model.
 *  <p>
 *  WARNING: DO NOT OVERRIDE THIS METHOD UNLESS YOU HAVE A VERY GOOD REASON FOR IT. OVERRIDING
 *  THIS MIGHT OPEN UP SECURITY LEAKS AND BREAK BACK-BUTTON SUPPORT.
 *  </p>
 *
 *  @param model
 *             The model
 *  @return This
 */
public Component setDefaultModel(final IModel<?> model) {
    IModel<?> prevModel = getModelImpl();
    IModel<?> wrappedModel = prevModel;
    if (prevModel instanceof IWrapModel) {
        wrappedModel = ((IWrapModel<?>) prevModel).getWrappedModel();
    }
    // Change model
    if (wrappedModel != model) {
        // Detach the old/current model
        if (prevModel != null) {
            prevModel.detach();
        }
        modelChanging();
        setModelImpl(wrap(model));
        modelChanged();
    }
    return this;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5655_d558004b,Minor,wicket-core/src/main/java/org/apache/wicket/Component.java,3001,3029,"/**
 *  @param model
 */
void setModelImpl(IModel<?> model) {
    if (getFlag(FLAG_MODEL_SET)) {
        if (model != null) {
            data_set(0, model);
            // and a new one is not IComponentInheritedModel
            if (getFlag(FLAG_INHERITABLE_MODEL) && !(model instanceof IComponentInheritedModel)) {
                setFlag(FLAG_INHERITABLE_MODEL, false);
            }
        } else {
            data_remove(0);
            setFlag(FLAG_MODEL_SET, false);
        }
    } else {
        if (model != null) {
            data_insert(0, model);
            setFlag(FLAG_MODEL_SET, true);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5656_f539c18c,Major,wicket-bean-validation/src/main/java/org/apache/wicket/bean/validation/PropertyValidator.java,197,226,"boolean isRequired() {
    List<NotNull> constraints = findNotNullConstraints();
    if (constraints.isEmpty()) {
        return false;
    }
    HashSet<Class<?>> validatorGroups = new HashSet<Class<?>>();
    validatorGroups.addAll(Arrays.asList(getGroups()));
    for (NotNull constraint : constraints) {
        if (constraint.groups().length == 0 && validatorGroups.isEmpty()) {
            return true;
        }
        for (Class<?> constraintGroup : constraint.groups()) {
            if (validatorGroups.contains(constraintGroup)) {
                return true;
            }
        }
    }
    return false;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5662_9aec4f33,Major,wicket-spring/src/main/java/org/apache/wicket/spring/SpringBeanLocator.java,128,134,"/**
 *  @see org.apache.wicket.proxy.IProxyTargetLocator#locateProxyTarget()
 */
@Override
public Object locateProxyTarget() {
    final ApplicationContext context = getSpringContext();
    return lookupSpringBean(context, beanName, getBeanType());
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5662_9aec4f33,Major,wicket-spring/src/main/java/org/apache/wicket/spring/SpringBeanLocator.java,180,199,"/**
 *  Looks up a bean by its name and class. Throws IllegalState exception if bean not found.
 *
 *  @param ctx
 *             spring application context
 *
 *  @param name
 *             bean name
 *  @param clazz
 *             bean class
 *  @throws IllegalStateException
 *  @return found bean
 */
private static Object lookupSpringBean(final ApplicationContext ctx, final String name, final Class<?> clazz) {
    try {
        if (name == null) {
            return ctx.getBean(clazz);
        } else {
            return ctx.getBean(name, clazz);
        }
    } catch (NoSuchBeanDefinitionException e) {
        throw new IllegalStateException(""bean with name ["" + name + ""] and class ["" + clazz.getName() + ""] not found"");
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5662_9aec4f33,Major,wicket-spring/src/main/java/org/apache/wicket/spring/injection/annot/AnnotProxyFieldValueFactory.java,108,152,"@Override
public Object getFieldValue(final Field field, final Object fieldOwner) {
    if (supportsField(field)) {
        String beanName = getBeanName(field);
        if (beanName == null) {
            return null;
        }
        SpringBeanLocator locator = new SpringBeanLocator(beanName, field.getType(), contextLocator);
        // only check the cache if the bean is a singleton
        Object cachedValue = cache.get(locator);
        if (cachedValue != null) {
            return cachedValue;
        }
        Object target;
        if (wrapInProxies) {
            target = LazyInitProxyFactory.createProxy(field.getType(), locator);
        } else {
            target = locator.locateProxyTarget();
        }
        // only put the proxy into the cache if the bean is a singleton
        if (locator.isSingletonBean()) {
            Object tmpTarget = cache.putIfAbsent(locator, target);
            if (tmpTarget != null) {
                target = tmpTarget;
            }
        }
        return target;
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5662_9aec4f33,Major,wicket-spring/src/main/java/org/apache/wicket/spring/injection/annot/AnnotProxyFieldValueFactory.java,159,192,"/**
 *  @param field
 *  @return bean name
 */
private String getBeanName(final Field field) {
    SpringBean annot = field.getAnnotation(SpringBean.class);
    String name;
    boolean required;
    if (annot != null) {
        name = annot.name();
        required = annot.required();
    } else {
        Named named = field.getAnnotation(Named.class);
        name = named != null ? named.value() : """";
        required = false;
    }
    if (Strings.isEmpty(name)) {
        name = beanNameCache.get(field.getType());
        if (name == null) {
            name = getBeanNameOfClass(contextLocator.getSpringContext(), field.getType(), required);
            if (name != null) {
                String tmpName = beanNameCache.putIfAbsent(field.getType(), name);
                if (tmpName != null) {
                    name = tmpName;
                }
            }
        }
    }
    return name;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5686_8e794fc4,Major,wicket-spring/src/main/java/org/apache/wicket/spring/injection/annot/AnnotProxyFieldValueFactory.java,108,181,"@Override
public Object getFieldValue(final Field field, final Object fieldOwner) {
    if (supportsField(field)) {
        SpringBean annot = field.getAnnotation(SpringBean.class);
        String name;
        boolean required;
        if (annot != null) {
            name = annot.name();
            required = annot.required();
        } else {
            Named named = field.getAnnotation(Named.class);
            name = named != null ? named.value() : """";
            required = false;
        }
        String beanName = getBeanName(field, name, required);
        if (beanName == null) {
            return null;
        }
        SpringBeanLocator locator = new SpringBeanLocator(beanName, field.getType(), contextLocator);
        // only check the cache if the bean is a singleton
        Object cachedValue = cache.get(locator);
        if (cachedValue != null) {
            return cachedValue;
        }
        Object target;
        try {
            // check whether there is a bean with the provided properties
            target = locator.locateProxyTarget();
        } catch (IllegalStateException isx) {
            if (required) {
                throw isx;
            } else {
                return null;
            }
        }
        if (wrapInProxies) {
            target = LazyInitProxyFactory.createProxy(field.getType(), locator);
        }
        // only put the proxy into the cache if the bean is a singleton
        if (locator.isSingletonBean()) {
            Object tmpTarget = cache.putIfAbsent(locator, target);
            if (tmpTarget != null) {
                target = tmpTarget;
            }
        }
        return target;
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5689_2ac29d30,Minor,wicket-core/src/main/java/org/apache/wicket/protocol/http/WebApplication.java,884,888,"/**
 *  @param sessionId
 *  @param url
 *  @return buffered response
 */
public BufferedWebResponse getAndRemoveBufferedResponse(String sessionId, Url url) {
    String key = sessionId + url.toString();
    return storedResponses.remove(key);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5689_2ac29d30,Minor,wicket-core/src/main/java/org/apache/wicket/request/handler/render/WebPageRenderer.java,90,93,"protected BufferedWebResponse getAndRemoveBufferedResponse(Url url) {
    return WebApplication.get().getAndRemoveBufferedResponse(getSessionId(), url);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5689_2ac29d30,Minor,wicket-core/src/main/java/org/apache/wicket/request/handler/render/WebPageRenderer.java,187,298,"/*
	 * TODO: simplify the code below. See WICKET-3347
	 */
@Override
public void respond(RequestCycle requestCycle) {
    Url currentUrl = requestCycle.getUrlRenderer().getBaseUrl();
    Url targetUrl = requestCycle.mapUrlFor(getRenderPageRequestHandler());
    // 
    // the code below is little hairy but we have to handle 3 redirect policies,
    // 3 rendering strategies and two kind of requests (ajax and normal)
    // 
    // try to get an already rendered buffered response for current URL
    BufferedWebResponse bufferedResponse = getAndRemoveBufferedResponse(currentUrl);
    if (bufferedResponse != null) {
        logger.warn(""The Buffered response should be handled by BufferedResponseRequestHandler"");
        // if there is saved response for this URL render it
        bufferedResponse.writeTo((WebResponse) requestCycle.getResponse());
    } else if (shouldRenderPageAndWriteResponse(requestCycle, currentUrl, targetUrl)) {
        BufferedWebResponse response = renderPage(currentUrl, requestCycle);
        if (response != null) {
            response.writeTo((WebResponse) requestCycle.getResponse());
        }
    } else if (shouldRedirectToTargetUrl(requestCycle, currentUrl, targetUrl)) {
        redirectTo(targetUrl, requestCycle);
    // note: if we had session here we would render the page to buffer and then
    // redirect to URL generated *after* page has been rendered (the statelessness
    // may change during render). this would save one redirect because now we have
    // to render to URL generated *before* page is rendered, render the page, get
    // URL after render and if the URL is different (meaning page is not stateless),
    // save the buffer and redirect again (which is pretty much what the next step
    // does)
    } else {
        if (isRedirectToBuffer() == false && logger.isDebugEnabled()) {
            String details = String.format(""redirect strategy: '%s', isAjax: '%s', redirect policy: '%s', "" + ""current url: '%s', target url: '%s', is new: '%s', is stateless: '%s', is temporary: '%s'"", Application.get().getRequestCycleSettings().getRenderStrategy(), isAjax(requestCycle), getRedirectPolicy(), currentUrl, targetUrl, isNewPageInstance(), isPageStateless(), isSessionTemporary());
            logger.debug(""Falling back to Redirect_To_Buffer render strategy because none of the conditions "" + ""matched. Details: "" + details);
        }
        // force creation of possible stateful page to get the final target url
        getPage();
        Url beforeRenderUrl = requestCycle.mapUrlFor(getRenderPageRequestHandler());
        // redirect to buffer
        BufferedWebResponse response = renderPage(beforeRenderUrl, requestCycle);
        if (response == null) {
            return;
        }
        // the url might have changed after page has been rendered (e.g. the
        // stateless flag might have changed because stateful components
        // were added)
        final Url afterRenderUrl = requestCycle.mapUrlFor(getRenderPageRequestHandler());
        if (beforeRenderUrl.getSegments().equals(afterRenderUrl.getSegments()) == false) {
            // the amount of segments is different - generated relative URLs
            // will not work, we need to rerender the page. This can happen
            // with IRequestHandlers that produce different URLs with
            // different amount of segments for stateless and stateful pages
            response = renderPage(afterRenderUrl, requestCycle);
        }
        if (currentUrl.equals(afterRenderUrl)) {
            // no need to redirect when both urls are exactly the same
            response.writeTo((WebResponse) requestCycle.getResponse());
        } else // if page is still stateless after render
        if (isPageStateless() && !enableRedirectForStatelessPage()) {
            // we don't want the redirect to happen for stateless page
            // example:
            // when a normal mounted stateful page is hit at /mount/point
            // wicket renders the page to buffer and redirects to /mount/point?12
            // but for stateless page the redirect is not necessary
            // also for listener interface on stateful page we want to redirect
            // after the listener is invoked, but on stateless page the user
            // must ask for redirect explicitly
            response.writeTo((WebResponse) requestCycle.getResponse());
        } else {
            storeBufferedResponse(afterRenderUrl, response);
            redirectTo(afterRenderUrl, requestCycle);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5698_f45ce896,Major,wicket-request/src/main/java/org/apache/wicket/request/mapper/CompoundRequestMapper.java,246,259,"@Override
public void unmount(String path) {
    final Url url = Url.parse(path);
    final Request request = createRequest(url);
    for (IRequestMapper mapper : this) {
        if (mapper.mapRequest(request) != null) {
            remove(mapper);
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5701_087c0a26,Major,wicket-native-websocket/wicket-native-websocket-core/src/main/java/org/apache/wicket/protocol/ws/api/AbstractWebSocketProcessor.java,176,262,"/**
 *  Exports the Wicket thread locals and broadcasts the received message from the client to all
 *  interested components and behaviors in the page with id {@code #pageId}
 *  <p>
 *      Note: ConnectedMessage and ClosedMessage messages are notification-only. I.e. whatever the
 *      components/behaviors write in the WebSocketRequestHandler will be ignored because the protocol
 *      doesn't expect response from the user.
 *  </p>
 *
 *  @param message
 *       the message to broadcast
 */
public final void broadcastMessage(final IWebSocketMessage message) {
    IKey key = getRegistryKey();
    IWebSocketConnection connection = connectionRegistry.getConnection(application, sessionId, key);
    if (connection != null && connection.isOpen()) {
        Application oldApplication = ThreadContext.getApplication();
        Session oldSession = ThreadContext.getSession();
        RequestCycle oldRequestCycle = ThreadContext.getRequestCycle();
        WebSocketResponse webResponse = new WebSocketResponse(connection);
        try {
            RequestCycle requestCycle;
            if (oldRequestCycle == null || message instanceof IWebSocketPushMessage) {
                RequestCycleContext context = new RequestCycleContext(webRequest, webResponse, application.getRootRequestMapper(), application.getExceptionMapperProvider().get());
                requestCycle = application.getRequestCycleProvider().get(context);
                requestCycle.getUrlRenderer().setBaseUrl(baseUrl);
                ThreadContext.setRequestCycle(requestCycle);
            } else {
                requestCycle = oldRequestCycle;
            }
            ThreadContext.setApplication(application);
            Session session;
            if (oldSession == null || message instanceof IWebSocketPushMessage) {
                ISessionStore sessionStore = application.getSessionStore();
                session = sessionStore.lookup(webRequest);
                ThreadContext.setSession(session);
            } else {
                session = oldSession;
            }
            IPageManager pageManager = session.getPageManager();
            try {
                Page page = getPage(pageManager);
                WebSocketRequestHandler requestHandler = new WebSocketRequestHandler(page, connection);
                WebSocketPayload payload = createEventPayload(message, requestHandler);
                sendPayload(payload, page);
                if (!(message instanceof ConnectedMessage || message instanceof ClosedMessage)) {
                    requestHandler.respond(requestCycle);
                }
            } finally {
                pageManager.commitRequest();
            }
        } catch (Exception x) {
            LOG.error(""An error occurred during processing of a WebSocket message"", x);
        } finally {
            try {
                webResponse.close();
            } finally {
                ThreadContext.setApplication(oldApplication);
                ThreadContext.setRequestCycle(oldRequestCycle);
                ThreadContext.setSession(oldSession);
            }
        }
    } else {
        LOG.debug(""Either there is no connection({}) or it is closed."", connection);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5701_087c0a26,Major,wicket-native-websocket/wicket-native-websocket-core/src/main/java/org/apache/wicket/protocol/ws/api/AbstractWebSocketProcessor.java,273,304,"/**
 *  Sends the payload either to the page (and its WebSocketBehavior)
 *  or to the WebSocketResource with name {@linkplain #resourceName}
 *
 *  @param payload
 *           The payload with the web socket message
 *  @param page
 *           The page that owns the WebSocketBehavior, in case of behavior usage
 */
private void sendPayload(final WebSocketPayload payload, final Page page) {
    final Runnable action = new Runnable() {

        @Override
        public void run() {
            if (pageId != NO_PAGE_ID) {
                page.send(application, Broadcast.BREADTH, payload);
            } else {
                ResourceReference reference = new SharedResourceReference(resourceName);
                IResource resource = reference.getResource();
                if (resource instanceof WebSocketResource) {
                    WebSocketResource wsResource = (WebSocketResource) resource;
                    wsResource.onPayload(payload);
                } else {
                    throw new IllegalStateException(String.format(""Shared resource with name '%s' is not a %s but %s"", resourceName, WebSocketResource.class.getSimpleName(), Classes.name(resource.getClass())));
                }
            }
        }
    };
    WebSocketSettings webSocketSettings = WebSocketSettings.Holder.get(application);
    webSocketSettings.getSendPayloadExecutor().run(action);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5701_087c0a26,Major,wicket-native-websocket/wicket-native-websocket-core/src/main/java/org/apache/wicket/protocol/ws/api/AbstractWebSocketProcessor.java,277,299,"@Override
public void run() {
    if (pageId != NO_PAGE_ID) {
        page.send(application, Broadcast.BREADTH, payload);
    } else {
        ResourceReference reference = new SharedResourceReference(resourceName);
        IResource resource = reference.getResource();
        if (resource instanceof WebSocketResource) {
            WebSocketResource wsResource = (WebSocketResource) resource;
            wsResource.onPayload(payload);
        } else {
            throw new IllegalStateException(String.format(""Shared resource with name '%s' is not a %s but %s"", resourceName, WebSocketResource.class.getSimpleName(), Classes.name(resource.getClass())));
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5706_0f8a6d75,Major,wicket-util/src/main/java/org/apache/wicket/util/resource/ResourceUtils.java,56,108,"/**
 *  Extract the locale from the filename
 *
 *  @param path
 *             The file path
 *  @return The updated path, without the locale
 */
public static PathLocale getLocaleFromFilename(String path) {
    String extension = """";
    int pos = path.indexOf('.');
    if (pos != -1) {
        extension = path.substring(pos);
        path = path.substring(0, pos);
    }
    String filename = Strings.lastPathComponent(path, '/');
    Matcher matcher = LOCALE_PATTERN.matcher(filename);
    if (matcher.find()) {
        String language = matcher.group(1);
        String country = matcher.group(3);
        String variant = matcher.group(5);
        // did we find a language?
        if (language != null) {
            if (isoLanguages.contains(language) == false) {
                language = null;
                country = null;
                variant = null;
            }
        }
        // did we find a country?
        if ((language != null) && (country != null)) {
            if (isoCountries.contains(country) == false) {
                country = null;
                variant = null;
            }
        }
        if (language != null) {
            pos = path.length() - filename.length() + matcher.start();
            String basePath = path.substring(0, pos) + extension;
            Locale locale = new Locale(language, country != null ? country : """", variant != null ? variant : """");
            return new PathLocale(basePath, locale);
        }
    }
    return new PathLocale(path, null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5711_5837817c,Major,wicket-core/src/main/java/org/apache/wicket/ajax/form/OnChangeAjaxBehavior.java,61,78,"@Override
protected void updateAjaxAttributes(AjaxRequestAttributes attributes) {
    super.updateAjaxAttributes(attributes);
    Component component = getComponent();
    // while all the other components will use 'change'
    if (component instanceof TextField || component instanceof TextArea) {
        attributes.setEventNames(EVENT_INPUTCHANGE);
    } else {
        attributes.setEventNames(EVENT_CHANGE);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5712_145da021,Minor,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/BookmarkableMapper.java,85,138,"@Override
protected UrlInfo parseRequest(Request request) {
    if (matches(request)) {
        Url url = request.getUrl();
        // try to extract page and component information from URL
        PageComponentInfo info = getPageComponentInfo(url);
        List<String> segments = url.getSegments();
        // load the page class
        String className;
        if (segments.size() >= 3) {
            className = segments.get(2);
        } else {
            className = segments.get(1);
        }
        Class<? extends IRequestablePage> pageClass = getPageClass(className);
        if (pageClass != null && IRequestablePage.class.isAssignableFrom(pageClass)) {
            if (Application.exists()) {
                Application application = Application.get();
                if (application.getSecuritySettings().getEnforceMounts()) {
                    // we make an exception if the homepage itself was mounted, see WICKET-1898
                    if (!pageClass.equals(application.getHomePage())) {
                        // WICKET-5094 only enforce mount if page is mounted
                        if (isPageMounted(pageClass, application)) {
                            return null;
                        }
                    }
                }
            }
            // extract the PageParameters from URL if there are any
            PageParameters pageParameters = extractPageParameters(request, 3, pageParametersEncoder);
            return new UrlInfo(info, pageClass, pageParameters);
        }
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5712_145da021,Minor,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/BookmarkableMapper.java,140,158,"private boolean isPageMounted(Class<? extends IRequestablePage> pageClass, Application application) {
    ICompoundRequestMapper applicationMappers = application.getRootRequestMapperAsCompound();
    for (IRequestMapper requestMapper : applicationMappers) {
        if (requestMapper instanceof AbstractBookmarkableMapper && requestMapper != this) {
            AbstractBookmarkableMapper mapper = (AbstractBookmarkableMapper) requestMapper;
            if (mapper.checkPageClass(pageClass)) {
                return true;
            }
        }
    }
    return false;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5720_2fc6a395,Minor,wicket-util/src/main/java/org/apache/wicket/util/string/Strings.java,653,700,"/**
 *  Joins string fragments using the specified separator
 *
 *  @param separator
 *  @param fragments
 *  @return combined fragments
 */
public static String join(final String separator, final String... fragments) {
    if ((fragments == null) || (fragments.length < 1)) {
        // no elements
        return """";
    } else if (fragments.length < 2) {
        // single element
        return fragments[0];
    } else {
        // two or more elements
        StringBuilder buff = new StringBuilder(128);
        if (fragments[0] != null) {
            buff.append(fragments[0]);
        }
        for (int i = 1; i < fragments.length; i++) {
            String fragment = fragments[i];
            if ((fragments[i - 1] != null) || (fragment != null)) {
                boolean lhsClosed = fragments[i - 1].endsWith(separator);
                boolean rhsClosed = fragment.startsWith(separator);
                if (lhsClosed && rhsClosed) {
                    buff.append(fragment.substring(1));
                } else if (!lhsClosed && !rhsClosed) {
                    if (!Strings.isEmpty(fragment)) {
                        buff.append(separator);
                    }
                    buff.append(fragment);
                } else {
                    buff.append(fragment);
                }
            }
        }
        return buff.toString();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5724_b92591f6,Major,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,1527,1542,"private void dequeueAutoComponents() {
    // dequeue auto components
    DequeueContext context = newDequeueContext();
    if (context != null && context.peekTag() != null) {
        for (ComponentTag tag = context.takeTag(); tag != null; tag = context.takeTag()) {
            ComponentTag.IAutoComponentFactory autoComponentFactory = tag.getAutoComponentFactory();
            if (autoComponentFactory != null) {
                queue(autoComponentFactory.newComponent(tag));
            }
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5724_b92591f6,Major,wicket-core/src/main/java/org/apache/wicket/markup/ComponentTag.java,68,68,"/**
 *  Creates a new instance of auto component to be queued
 */
Component newComponent(ComponentTag tag);"
wicket,remotes/origin/bugs-dot-jar_WICKET-5724_b92591f6,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/EnclosureHandler.java,58,63,"@Override
public Component newComponent(ComponentTag tag) {
    return new Enclosure(tag.getId(), tag.getAttribute(EnclosureHandler.CHILD_ATTRIBUTE));
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5724_b92591f6,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/InlineEnclosureHandler.java,88,188,"@Override
protected MarkupElement onComponentTag(final ComponentTag tag) throws ParseException {
    // We only need ComponentTags
    if (tag instanceof WicketTag) {
        return tag;
    }
    // Has wicket:enclosure attribute?
    String enclosureAttr = getAttribute(tag, null);
    if (enclosureAttr != null) {
        if (tag.isOpen()) {
            // Make sure 'wicket:id' and 'id' are consistent
            String htmlId = tag.getAttribute(""id"");
            if ((tag.getId() != null) && !Strings.isEmpty(htmlId) && !htmlId.equals(tag.getId())) {
                throw new ParseException(""Make sure that 'id' and 'wicket:id' are the same if both are provided. Tag:"" + tag.toString(), tag.getPos());
            }
            // if it doesn't have a wicket-id already, then assign one now.
            if (Strings.isEmpty(tag.getId())) {
                if (Strings.isEmpty(htmlId)) {
                    String id = getWicketNamespace() + ""_"" + INLINE_ENCLOSURE_ID_PREFIX + (counter++);
                    tag.setId(id);
                } else {
                    tag.setId(htmlId);
                }
                tag.setAutoComponentTag(true);
                tag.setAutoComponentFactory(new ComponentTag.IAutoComponentFactory() {

                    @Override
                    public Component newComponent(ComponentTag tag) {
                        String attributeName = getInlineEnclosureAttributeName(null);
                        String childId = tag.getAttribute(attributeName);
                        return new InlineEnclosure(tag.getId(), childId);
                    }
                });
                tag.setModified(true);
            }
            // Put the enclosure on the stack. The most current one will be on top
            if (enclosures == null) {
                enclosures = new ArrayDeque<>();
            }
            enclosures.push(tag);
        } else {
            throw new ParseException(""Open-close tags don't make sense for InlineEnclosure. Tag:"" + tag.toString(), tag.getPos());
        }
    } else // Are we within an enclosure?
    if ((enclosures != null) && (enclosures.size() > 0)) {
        // first ComponentTag's id found as the controlling child to the enclosure.
        if (tag.isOpen() && (tag.getId() != null) && !(tag instanceof WicketTag) && !tag.isAutoComponentTag()) {
            Iterator<ComponentTag> componentTagIterator = enclosures.descendingIterator();
            while (componentTagIterator.hasNext()) {
                ComponentTag lastEnclosure = componentTagIterator.next();
                String attr = getAttribute(lastEnclosure, null);
                if (Strings.isEmpty(attr) == true) {
                    lastEnclosure.getAttributes().put(getInlineEnclosureAttributeName(null), tag.getId());
                    lastEnclosure.setModified(true);
                }
            }
        } else if (tag.isClose() && tag.closes(enclosures.peek())) {
            ComponentTag lastEnclosure = enclosures.pop();
            String attr = getAttribute(lastEnclosure, null);
            if (Strings.isEmpty(attr) == true) {
                throw new ParseException(""Did not find any child for InlineEnclosure. Tag:"" + lastEnclosure.toString(), tag.getPos());
            }
        }
    }
    return tag;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5724_b92591f6,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/InlineEnclosureHandler.java,129,135,"@Override
public Component newComponent(ComponentTag tag) {
    String attributeName = getInlineEnclosureAttributeName(null);
    String childId = tag.getAttribute(attributeName);
    return new InlineEnclosure(tag.getId(), childId);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5724_b92591f6,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/RelativePathPrefixHandler.java,117,154,"@Override
protected final MarkupElement onComponentTag(ComponentTag tag) throws ParseException {
    if (tag.isClose()) {
        return tag;
    }
    String wicketIdAttr = getWicketNamespace() + "":"" + ""id"";
    // Don't touch any wicket:id component and any auto-components
    if ((tag instanceof WicketTag) || (tag.isAutolinkEnabled() == true) || (tag.getAttributes().get(wicketIdAttr) != null)) {
        return tag;
    }
    // behavior that prepends the relative path.
    for (String attrName : attributeNames) {
        String attrValue = tag.getAttributes().getString(attrName);
        if ((attrValue != null) && (attrValue.startsWith(""/"") == false) && (!attrValue.contains("":"")) && !(attrValue.startsWith(""#""))) {
            if (tag.getId() == null) {
                tag.setId(getWicketRelativePathPrefix(null));
                tag.setAutoComponentTag(true);
            }
            tag.addBehavior(RELATIVE_PATH_BEHAVIOR);
            tag.setModified(true);
            break;
        }
    }
    return tag;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5728_3cc3fe95,Major,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,2069,2137,"/**
 *  Dequeues components. The default implementation iterates direct children of this container
 *  found in its markup and tries to find matching
 *  components in queues filled by a call to {@link #queue(Component...)}. It then delegates the
 *  dequeueing to these children.
 *
 *  The provided {@link DequeueContext} is used to maintain the place in markup as well as the
 *  stack of components whose queues will be searched. For example, before delegating the call to
 *  a child the container will push the child onto the stack of components.
 *
 *  Certain components that implement custom markup behaviors (such as repeaters and borders)
 *  override this method to bring dequeueing in line with their custom markup handling.
 *
 *  @param dequeue
 */
public void dequeue(DequeueContext dequeue) {
    while (dequeue.isAtOpenOrOpenCloseTag()) {
        ComponentTag tag = dequeue.takeTag();
        // see if child is already added to parent
        Component child = get(tag.getId());
        if (child == null) {
            // the container does not yet have a child with this id, see if we can
            // dequeue
            child = dequeue.findComponentToDequeue(tag);
            if (child != null) {
                addDequeuedComponent(child, tag);
                if (child instanceof IQueueRegion) {
                    ((MarkupContainer) child).dequeue();
                }
            }
        }
        if (child == null || !(child instanceof MarkupContainer)) {
            if (tag.isOpen()) {
                dequeue.skipToCloseTag();
            }
        } else {
            MarkupContainer container = (MarkupContainer) child;
            if (container instanceof IQueueRegion) {
                // itself when it is dequeued for the first time
                if (tag.isOpen()) {
                    dequeue.skipToCloseTag();
                }
            } else if (tag.isOpen()) {
                // this component has more markup and possibly more children to dequeue
                dequeue.pushContainer(container);
                container.dequeue(dequeue);
                dequeue.popContainer();
            }
        }
        if (tag.isOpen() && !tag.hasNoCloseTag()) {
            // pull the close tag off
            ComponentTag close = dequeue.takeTag();
            if (!close.closes(tag)) {
                // sanity check
                throw new IllegalStateException(String.format(""Tag '%s' should be the closing one for '%s'"", close, tag));
            }
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5734_71674df5,Minor,wicket-core/src/main/java/org/apache/wicket/core/request/mapper/AbstractBookmarkableMapper.java,254,277,"/**
 *  Creates a {@code IRequestHandler} that processes a hybrid request. When the page identified
 *  by {@code pageInfo} was not available, the request should be treated as a bookmarkable
 *  request.
 *
 *  @param pageInfo
 *  @param pageClass
 *  @param pageParameters
 *  @param renderCount
 *  @return a {@code IRequestHandler} capable of processing the hybrid request.
 */
protected IRequestHandler processHybrid(PageInfo pageInfo, Class<? extends IRequestablePage> pageClass, PageParameters pageParameters, Integer renderCount) {
    PageProvider provider = new PageProvider(pageInfo.getPageId(), pageClass, pageParameters, renderCount);
    provider.setPageSource(getContext());
    if (provider.isNewPageInstance() && !getRecreateMountedPagesAfterExpiry()) {
        throw new PageExpiredException(String.format(""Bookmarkable page id '%d' has expired."", pageInfo.getPageId()));
    } else {
        PageParameters constructionPageParameters = provider.getPageInstance().getPageParameters();
        if (PageParameters.equals(constructionPageParameters, pageParameters) == false) {
            // when the resolved page by id has been created
            return new RenderPageRequestHandler(new PageProvider(pageClass, pageParameters));
        }
        return new RenderPageRequestHandler(provider);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5751_bcea89fc,Major,wicket-util/src/main/java/org/apache/wicket/util/collections/IntHashMap.java,1144,1167,"/**
 *  Reconstitute the <tt>HashMap</tt> instance from a stream (i.e., deserialize it).
 *
 *  @param s
 *  @throws IOException
 *  @throws ClassNotFoundException
 */
@SuppressWarnings(""unchecked"")
private void readObject(final java.io.ObjectInputStream s) throws IOException, ClassNotFoundException {
    // Read in the threshold, loadfactor, and any hidden stuff
    s.defaultReadObject();
    // Read in number of buckets and allocate the bucket array;
    int numBuckets = s.readInt();
    table = new Entry[numBuckets];
    // Give subclass a chance to do its thing.
    init();
    // Read in size (number of Mappings)
    int size = s.readInt();
    // Read the keys and values, and put the mappings in the HashMap
    for (int i = 0; i < size; i++) {
        int key = s.readInt();
        V value = (V) s.readObject();
        putForCreate(key, value);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5759_0374c040,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AbstractDefaultAjaxBehavior.java,498,533,"/**
 *  Generates the body the {@linkplain #getCallbackFunction(CallbackParameter...) callback
 *  function}. To embed this code directly into a piece of javascript, make sure any context
 *  parameters are available as local variables, global variables or within the closure.
 *
 *  @param extraParameters
 *  @return The body of the {@linkplain #getCallbackFunction(CallbackParameter...) callback
 *          function}.
 */
public CharSequence getCallbackFunctionBody(CallbackParameter... extraParameters) {
    AjaxRequestAttributes attributes = getAttributes();
    attributes.setEventNames();
    CharSequence attrsJson = renderAjaxAttributes(getComponent(), attributes);
    StringBuilder sb = new StringBuilder();
    sb.append(""var attrs = "");
    sb.append(attrsJson);
    sb.append("";\n"");
    sb.append(""var params = {"");
    boolean first = true;
    for (CallbackParameter curExtraParameter : extraParameters) {
        if (curExtraParameter.getAjaxParameterName() != null) {
            if (!first)
                sb.append(',');
            else
                first = false;
            sb.append('\'').append(curExtraParameter.getAjaxParameterName()).append(""': "").append(curExtraParameter.getAjaxParameterCode());
        }
    }
    sb.append(""};\n"");
    if (attributes.getExtraParameters().isEmpty()) {
        sb.append(""attrs."").append(AjaxAttributeName.EXTRA_PARAMETERS).append("" = params;\n"");
    } else {
        sb.append(""attrs."").append(AjaxAttributeName.EXTRA_PARAMETERS).append("" = Wicket.merge(attrs."").append(AjaxAttributeName.EXTRA_PARAMETERS).append("", params);\n"");
    }
    sb.append(""Wicket.Ajax.ajax(attrs);\n"");
    return sb;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5770_cf6172bd,Major,wicket-request/src/main/java/org/apache/wicket/request/mapper/parameter/PageParametersEncoder.java,36,54,"@Override
public PageParameters decodePageParameters(final Url url) {
    PageParameters parameters = new PageParameters();
    int i = 0;
    for (String s : url.getSegments()) {
        parameters.set(i, s);
        ++i;
    }
    for (QueryParameter p : url.getQueryParameters()) {
        parameters.add(p.getName(), p.getValue(), INamedParameters.Type.QUERY_STRING);
    }
    return parameters.isEmpty() ? null : parameters;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5783_7b8b6767,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AjaxEventBehavior.java,100,106,"@Override
protected void updateAjaxAttributes(AjaxRequestAttributes attributes) {
    super.updateAjaxAttributes(attributes);
    attributes.setEventNames(event);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5783_7b8b6767,Major,wicket-core/src/main/java/org/apache/wicket/ajax/AjaxEventBehavior.java,122,125,"/**
 *  @return event
 *       the event this behavior is attached to
 */
public final String getEvent() {
    return event;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5784_b6259e5f,Minor,wicket-core/src/main/java/org/apache/wicket/protocol/http/AbstractRequestLogger.java,161,177,"/**
 *  Copies all request data into {@code copy} such that the oldest request is in slot 0 and the
 *  most recent request is in slot {@code copy.length}
 *
 *  @param copy
 *             the target, has to have a capacity of at least {@code requestWindow.length}
 */
private void copyRequestsInOrder(RequestData[] copy) {
    if (hasBufferRolledOver()) {
        // first copy the oldest requests stored behind the cursor into the copy
        int oldestPos = indexInWindow + 1;
        if (oldestPos < requestWindow.length)
            arraycopy(requestWindow, oldestPos, copy, 0, requestWindow.length - oldestPos);
        // then append the newer requests stored from index 0 til the cursor position.
        arraycopy(requestWindow, 0, copy, requestWindow.length - oldestPos, indexInWindow);
    } else {
        arraycopy(requestWindow, 0, copy, 0, indexInWindow);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5809_b1f4e6a3,Minor,wicket-request/src/main/java/org/apache/wicket/request/Url.java,220,357,"/**
 *  Parses the given URL string.
 *
 *  @param _url
 *             absolute or relative url with query string
 *  @param charset
 *  @param isFullHint
 *             a hint whether to try to parse the protocol, host and port part of the url
 *  @return Url object
 */
public static Url parse(CharSequence _url, Charset charset, boolean isFullHint) {
    Args.notNull(_url, ""_url"");
    final Url result = new Url(charset);
    // the url object resolved the charset, use that
    charset = result.getCharset();
    String url = _url.toString();
    // extract query string part
    final String queryString;
    final String absoluteUrl;
    final int fragmentAt = url.indexOf('#');
    // matches url fragment, but doesn't match optional path parameter (e.g. .../#{optional}/...)
    if (fragmentAt > -1 && url.length() > fragmentAt + 1 && url.charAt(fragmentAt + 1) != '{') {
        result.fragment = url.substring(fragmentAt + 1);
        url = url.substring(0, fragmentAt);
    }
    final int queryAt = url.indexOf('?');
    if (queryAt == -1) {
        queryString = """";
        absoluteUrl = url;
    } else {
        absoluteUrl = url.substring(0, queryAt);
        queryString = url.substring(queryAt + 1);
    }
    // get absolute / relative part of url
    String relativeUrl;
    final int idxOfFirstSlash = absoluteUrl.indexOf('/');
    final int protocolAt = absoluteUrl.indexOf(""://"");
    // full urls start either with a ""scheme://"" or with ""//""
    boolean protocolLess = absoluteUrl.startsWith(""//"");
    final boolean isFull = (protocolAt > 1 && (protocolAt < idxOfFirstSlash)) || protocolLess;
    if (isFull && isFullHint) {
        if (protocolLess == false) {
            result.protocol = absoluteUrl.substring(0, protocolAt).toLowerCase(Locale.US);
        }
        final String afterProto = absoluteUrl.substring(protocolAt + 3);
        final String hostAndPort;
        int relativeAt = afterProto.indexOf('/');
        if (relativeAt == -1) {
            relativeAt = afterProto.indexOf(';');
        }
        if (relativeAt == -1) {
            relativeUrl = """";
            hostAndPort = afterProto;
        } else {
            relativeUrl = afterProto.substring(relativeAt);
            hostAndPort = afterProto.substring(0, relativeAt);
        }
        final int credentialsAt = hostAndPort.lastIndexOf('@') + 1;
        final int portAt = hostAndPort.substring(credentialsAt).lastIndexOf(':');
        if (portAt == -1) {
            result.host = hostAndPort;
            result.port = getDefaultPortForProtocol(result.protocol);
        } else {
            result.host = hostAndPort.substring(0, portAt + credentialsAt);
            result.port = Integer.parseInt(hostAndPort.substring(portAt + credentialsAt + 1));
        }
        if (relativeAt < 0) {
            relativeUrl = ""/"";
        }
    } else {
        relativeUrl = absoluteUrl;
    }
    if (relativeUrl.length() > 0) {
        boolean removeLast = false;
        if (relativeUrl.endsWith(""/"")) {
            // we need to append something and remove it after splitting
            // because otherwise the
            // trailing slashes will be lost
            relativeUrl += ""/x"";
            removeLast = true;
        }
        String[] segmentArray = Strings.split(relativeUrl, '/');
        if (removeLast) {
            segmentArray[segmentArray.length - 1] = null;
        }
        for (String s : segmentArray) {
            if (s != null) {
                result.segments.add(decodeSegment(s, charset));
            }
        }
    }
    if (queryString.length() > 0) {
        String[] queryArray = Strings.split(queryString, '&');
        for (String s : queryArray) {
            if (Strings.isEmpty(s) == false) {
                result.parameters.add(parseQueryParameter(s, charset));
            }
        }
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5838_e93fdd5a,Major,wicket-util/src/main/java/org/apache/wicket/util/io/Connections.java,47,95,"/**
 *  Gets last modified date of the given {@link URL}
 *
 *  @param url
 *  @return last modified timestamp or <code>null</code> if not available
 *  @throws IOException
 */
public static Time getLastModified(final URL url) throws IOException {
    // check if url points to a local file
    final File file = Files.getLocalFileFromUrl(url);
    if (file != null) {
        // in that case we can get the timestamp faster
        return Files.getLastModified(file);
    }
    // otherwise open the url and proceed
    URLConnection connection = url.openConnection();
    connection.setDoInput(false);
    final long milliseconds;
    try {
        if (connection instanceof JarURLConnection) {
            JarURLConnection jarUrlConnection = (JarURLConnection) connection;
            URL jarFileUrl = jarUrlConnection.getJarFileURL();
            URLConnection jarFileConnection = jarFileUrl.openConnection();
            jarFileConnection.setDoInput(false);
            // get timestamp from JAR
            milliseconds = jarFileConnection.getLastModified();
        } else {
            // get timestamp from URL
            milliseconds = connection.getLastModified();
        }
        // return null if timestamp is unavailable
        if (milliseconds == 0) {
            return null;
        }
        // return UNIX timestamp
        return Time.millis(milliseconds);
    } finally {
        closeQuietly(connection);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/AbstractDecimalConverter.java,42,52,"/**
 *  @param locale
 *  @return Returns the numberFormat.
 */
@Override
public NumberFormat getNumberFormat(final Locale locale) {
    NumberFormat numberFormat = numberFormats.get(locale);
    if (numberFormat == null) {
        numberFormat = newNumberFormat(locale);
        setNumberFormat(locale, numberFormat);
    }
    return (NumberFormat) numberFormat.clone();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/AbstractDecimalConverter.java,61,64,"/**
 *  Creates a new {@link NumberFormat} for the given locale. The instance is later cached and is
 *  accessible through {@link #getNumberFormat(Locale)}
 *
 *  @param locale
 *  @return number format
 */
protected NumberFormat newNumberFormat(final Locale locale) {
    return NumberFormat.getInstance(locale);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/AbstractDecimalConverter.java,72,80,"/**
 *  @param locale
 *             The Locale that was used for this NumberFormat
 *  @param numberFormat
 *             The numberFormat to set.
 */
public final void setNumberFormat(final Locale locale, final NumberFormat numberFormat) {
    if (numberFormat instanceof DecimalFormat) {
        ((DecimalFormat) numberFormat).setParseBigDecimal(true);
    }
    numberFormats.put(locale, numberFormat);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/AbstractIntegerConverter.java,41,57,"/**
 *  @param locale
 *             The locale
 *  @return Returns the numberFormat.
 */
@Override
public NumberFormat getNumberFormat(final Locale locale) {
    NumberFormat numberFormat = numberFormats.get(locale);
    if (numberFormat == null) {
        numberFormat = NumberFormat.getIntegerInstance(locale);
        numberFormat.setParseIntegerOnly(true);
        numberFormat.setGroupingUsed(false);
        NumberFormat tmpNumberFormat = numberFormats.putIfAbsent(locale, numberFormat);
        if (tmpNumberFormat != null) {
            numberFormat = tmpNumberFormat;
        }
    }
    return (NumberFormat) numberFormat.clone();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/AbstractNumberConverter.java,39,39,"/**
 *  @param locale
 *  @return Returns the numberFormat.
 */
public abstract NumberFormat getNumberFormat(Locale locale);"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/AbstractNumberConverter.java,55,94,"/**
 *  Parses a value as a String and returns a Number.
 *
 *  @param value
 *             The object to parse (after converting with toString())
 *  @param min
 *             The minimum allowed value
 *  @param max
 *             The maximum allowed value
 *  @param locale
 *  @return The number
 *  @throws ConversionException
 *              if value is unparsable or out of range
 */
protected N parse(Object value, final double min, final double max, Locale locale) {
    if (locale == null) {
        locale = Locale.getDefault();
    }
    if (value == null) {
        return null;
    } else if (value instanceof String) {
        // Convert spaces to no-break space (U+00A0) as required by Java formats:
        // http://bugs.sun.com/view_bug.do?bug_id=4510618
        value = ((String) value).replaceAll(""(\\d+)\\s(?=\\d)"", ""$1\u00A0"");
    }
    final NumberFormat numberFormat = getNumberFormat(locale);
    final N number = parse(numberFormat, value, locale);
    if (number == null) {
        return null;
    }
    if (number.doubleValue() < min) {
        throw newConversionException(""Value cannot be less than "" + min, value, locale).setFormat(numberFormat);
    }
    if (number.doubleValue() > max) {
        throw newConversionException(""Value cannot be greater than "" + max, value, locale).setFormat(numberFormat);
    }
    return number;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/BigDecimalConverter.java,39,75,"@Override
public BigDecimal convertToObject(final String value, final Locale locale) {
    if (Strings.isEmpty(value)) {
        return null;
    }
    final Number number = parse(value, -Double.MAX_VALUE, Double.MAX_VALUE, locale);
    if (number instanceof BigDecimal) {
        return (BigDecimal) number;
    } else if (number instanceof Double) {
        // http://java.sun.com/j2se/1.4.2/docs/api/java/math/BigDecimal.html#BigDecimal%28double%29
        return new BigDecimal(Double.toString(number.doubleValue()));
    } else if (number instanceof Long) {
        return new BigDecimal(number.longValue());
    } else if (number instanceof Float) {
        return new BigDecimal(number.floatValue());
    } else if (number instanceof Integer) {
        return new BigDecimal(number.intValue());
    } else {
        return new BigDecimal(value);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/BigIntegerConverter.java,39,65,"@Override
public BigInteger convertToObject(final String value, final Locale locale) {
    if (Strings.isEmpty(value)) {
        return null;
    }
    final Number number = parse(value, -Double.MAX_VALUE, Double.MAX_VALUE, locale);
    if (number instanceof BigInteger) {
        return (BigInteger) number;
    } else if (number instanceof Long) {
        return BigInteger.valueOf(number.longValue());
    } else if (number instanceof Integer) {
        return BigInteger.valueOf(number.intValue());
    } else {
        return new BigInteger(value);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/ByteConverter.java,42,53,"/**
 *  @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,Locale)
 */
@Override
public Byte convertToObject(final String value, final Locale locale) {
    final Number number = parse(value, Byte.MIN_VALUE, Byte.MAX_VALUE, locale);
    if (number == null) {
        return null;
    }
    return number.byteValue();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/DoubleConverter.java,42,55,"/**
 *  @see org.apache.wicket.util.convert.IConverter#convertToObject(String, java.util.Locale)
 */
@Override
public Double convertToObject(final String value, final Locale locale) {
    final Number number = parse(value, -Double.MAX_VALUE, Double.MAX_VALUE, locale);
    if (number == null) {
        return null;
    }
    return number.doubleValue();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/FloatConverter.java,42,53,"/**
 *  @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,Locale)
 */
@Override
public Float convertToObject(final String value, final Locale locale) {
    final Number number = parse(value, -Float.MAX_VALUE, Float.MAX_VALUE, locale);
    if (number == null) {
        return null;
    }
    return number.floatValue();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/IntegerConverter.java,42,53,"/**
 *  @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,Locale)
 */
@Override
public Integer convertToObject(final String value, final Locale locale) {
    final Number number = parse(value, Integer.MIN_VALUE, Integer.MAX_VALUE, locale);
    if (number == null) {
        return null;
    }
    return number.intValue();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/LongConverter.java,42,53,"/**
 *  @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,Locale)
 */
@Override
public Long convertToObject(final String value, final Locale locale) {
    final Number number = parse(value, Long.MIN_VALUE, Long.MAX_VALUE, locale);
    if (number == null) {
        return null;
    }
    return number.longValue();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/ShortConverter.java,42,53,"/**
 *  @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,Locale)
 */
@Override
public Short convertToObject(final String value, final Locale locale) {
    final Number number = parse(value, Short.MIN_VALUE, Short.MAX_VALUE, locale);
    if (number == null) {
        return null;
    }
    return number.shortValue();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/ZeroPaddingIntegerConverter.java,65,76,"/**
 *  @see org.apache.wicket.util.convert.IConverter#convertToObject(java.lang.String,Locale)
 */
@Override
public Integer convertToObject(final String value, final Locale locale) {
    final Number number = parse(value, Integer.MIN_VALUE, Integer.MAX_VALUE, locale);
    if (number == null) {
        return null;
    }
    return number.intValue();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5853_b80f6640,Minor,wicket-util/src/main/java/org/apache/wicket/util/convert/converter/ZeroPaddingIntegerConverter.java,81,85,"/**
 *  @see org.apache.wicket.util.convert.converter.AbstractConverter#getTargetType()
 */
@Override
protected Class<Integer> getTargetType() {
    return Integer.class;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5881_8c83c5c5,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/form/FormComponent.java,1613,1669,"/**
 *  Update the model of a {@link FormComponent} containing a {@link Collection}.
 *
 *  If the model object does not yet exists, a new {@link ArrayList} is filled with the converted
 *  input and used as the new model object. Otherwise the existing collection is modified
 *  in-place, then {@link Model#setObject(Object)} is called with the same instance: it allows
 *  the Model to be notified of changes even when {@link Model#getObject()} returns a different
 *  {@link Collection} at every invocation.
 *
 *  @param <S>
 *             collection type
 *  @param formComponent
 *             the form component to update
 *  @see FormComponent#updateModel()
 *  @throws WicketRuntimeException
 *              if the existing model object collection is unmodifiable and no setter exists
 */
public static <S> void updateCollectionModel(FormComponent<Collection<S>> formComponent) {
    Collection<S> convertedInput = formComponent.getConvertedInput();
    Collection<S> collection = formComponent.getModelObject();
    if (collection == null) {
        collection = new ArrayList<>(convertedInput);
        formComponent.setModelObject(collection);
    } else {
        boolean modified = false;
        formComponent.modelChanging();
        try {
            collection.clear();
            if (convertedInput != null) {
                collection.addAll(convertedInput);
            }
            modified = true;
        } catch (UnsupportedOperationException unmodifiable) {
            if (logger.isDebugEnabled()) {
                logger.debug(""An error occurred while trying to modify the collection attached to "" + formComponent, unmodifiable);
            }
            collection = new ArrayList<>(convertedInput);
        }
        try {
            formComponent.getModel().setObject(collection);
        } catch (Exception noSetter) {
            if (!modified) {
                throw new WicketRuntimeException(""An error occurred while trying to set the collection attached to "" + formComponent, noSetter);
            } else if (logger.isDebugEnabled()) {
                logger.debug(""An error occurred while trying to set the collection attached to "" + formComponent, noSetter);
            }
        }
        formComponent.modelChanged();
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5883_cd3b9234,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Form.java,1140,1156,"/**
 *  Find out whether there is any registered error for a form component.
 *
 *  @return whether there is any registered error for a form component
 */
private boolean anyFormComponentError() {
    // Check ALL children for error messages irrespective of FormComponents or not
    Boolean error = visitChildren(Component.class, new IVisitor<Component, Boolean>() {

        @Override
        public void component(final Component component, final IVisit<Boolean> visit) {
            if (component.hasErrorMessage()) {
                visit.stop(true);
            }
        }
    });
    return (error != null) && error;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5883_cd3b9234,Minor,wicket-core/src/main/java/org/apache/wicket/markup/html/form/Form.java,1145,1152,"@Override
public void component(final Component component, final IVisit<Boolean> visit) {
    if (component.hasErrorMessage()) {
        visit.stop(true);
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5891_2d9ebf9a,Major,wicket-core/src/main/java/org/apache/wicket/validation/validator/CreditCardValidator.java,320,333,"/**
 *  Check if the credit card is a China UnionPay. A China UnionPay number has to start with 622
 *  (622126-622925) and has to have a length between 16 and 19. No further validation takes
 *  place.<br/>
 *  <br/>
 *
 *  @param creditCardNumber
 *             the credit card number as a string
 *  @return The credit card id of the issuer
 */
private CreditCard isChinaUnionPay(String creditCardNumber) {
    if ((creditCardNumber.length() >= 16 && creditCardNumber.length() <= 19) && (creditCardNumber.startsWith(""622""))) {
        int firstDigits = Integer.parseInt(creditCardNumber.substring(0, 5));
        if (firstDigits >= 622126 && firstDigits <= 622925) {
            return CreditCard.CHINA_UNIONPAY;
        }
    }
    return CreditCard.INVALID;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5898_b00920f3,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/DefaultMarkupSourcingStrategy.java,76,102,"/**
 *  Get the markup for the child component, which is assumed to be a child of 'container'.
 */
@Override
public IMarkupFragment getMarkup(final MarkupContainer container, final Component child) {
    // If the sourcing strategy did not provide one, than ask the component.
    // Get the markup for the container
    IMarkupFragment markup = container.getMarkup();
    if (markup == null) {
        return null;
    }
    if (child == null) {
        return markup;
    }
    // Find the child's markup
    markup = markup.find(child.getId());
    if (markup != null) {
        return markup;
    }
    markup = searchMarkupInTransparentResolvers(container, child);
    return markup;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5898_ffdd0864,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/AbstractMarkupSourcingStrategy.java,62,105,"/**
 *  If the child has not been directly added to the container, but via a
 *  TransparentWebMarkupContainer, then we are in trouble. In general Wicket iterates over the
 *  markup elements and searches for associated components, not the other way around. Because of
 *  TransparentWebMarkupContainer (or more generally resolvers), there is no ""synchronous"" search
 *  possible.
 *
 *  @param container
 *             the parent container.
 *  @param child
 *             The component to find the markup for.
 *  @return the markup fragment for the child, or {@code null}.
 */
protected IMarkupFragment searchMarkupInTransparentResolvers(final MarkupContainer container, final Component child) {
    return container.visitChildren(MarkupContainer.class, new IVisitor<MarkupContainer, IMarkupFragment>() {

        @Override
        public void component(MarkupContainer resolvingContainer, IVisit<IMarkupFragment> visit) {
            // prevents possible searching loops
            if (child == resolvingContainer) {
                visit.dontGoDeeper();
                return;
            }
            if (resolvingContainer instanceof IComponentResolver) {
                visit.dontGoDeeper();
                IMarkupFragment childMarkup = resolvingContainer.getMarkup(child);
                if (childMarkup != null && childMarkup.size() > 0) {
                    IComponentResolver componentResolver = (IComponentResolver) resolvingContainer;
                    MarkupStream stream = new MarkupStream(childMarkup);
                    ComponentTag tag = stream.getTag();
                    Component resolvedComponent = resolvingContainer.get(tag.getId());
                    if (resolvedComponent == null) {
                        resolvedComponent = componentResolver.resolve(resolvingContainer, stream, tag);
                    }
                    if (child == resolvedComponent) {
                        visit.stop(childMarkup);
                    }
                }
            }
        }
    });
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5898_ffdd0864,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/AbstractMarkupSourcingStrategy.java,67,103,"@Override
public void component(MarkupContainer resolvingContainer, IVisit<IMarkupFragment> visit) {
    // prevents possible searching loops
    if (child == resolvingContainer) {
        visit.dontGoDeeper();
        return;
    }
    if (resolvingContainer instanceof IComponentResolver) {
        visit.dontGoDeeper();
        IMarkupFragment childMarkup = resolvingContainer.getMarkup(child);
        if (childMarkup != null && childMarkup.size() > 0) {
            IComponentResolver componentResolver = (IComponentResolver) resolvingContainer;
            MarkupStream stream = new MarkupStream(childMarkup);
            ComponentTag tag = stream.getTag();
            Component resolvedComponent = resolvingContainer.get(tag.getId());
            if (resolvedComponent == null) {
                resolvedComponent = componentResolver.resolve(resolvingContainer, stream, tag);
            }
            if (child == resolvedComponent) {
                visit.stop(childMarkup);
            }
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5898_ffdd0864,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/AssociatedMarkupSourcingStrategy.java,90,130,"/**
 *  Search for the child's markup in the associated markup file.
 *
 *  @param parent
 *             The container expected to contain the markup for child
 *  @param child
 *             The child component to find the markup for
 *  @return The markup associated with the child
 */
@Override
public IMarkupFragment getMarkup(final MarkupContainer parent, final Component child) {
    Args.notNull(tagName, ""tagName"");
    IMarkupFragment associatedMarkup = parent.getAssociatedMarkup();
    if (associatedMarkup == null) {
        throw new MarkupNotFoundException(""Failed to find markup file associated. "" + Classes.simpleName(parent.getClass()) + "": "" + parent.toString());
    }
    // Find <wicket:panel>
    IMarkupFragment markup = MarkupUtil.findStartTag(associatedMarkup, tagName);
    if (markup == null) {
        throw new MarkupNotFoundException(""Expected to find <wicket:"" + tagName + ""> in associated markup file. Markup: "" + associatedMarkup.toString());
    }
    // If child == null, than return the markup fragment starting with <wicket:panel>
    if (child == null) {
        return markup;
    }
    // Find the markup for the child component
    associatedMarkup = markup.find(child.getId());
    if (associatedMarkup != null) {
        return associatedMarkup;
    }
    associatedMarkup = searchMarkupInTransparentResolvers(parent, child);
    if (associatedMarkup != null) {
        return associatedMarkup;
    }
    return findMarkupInAssociatedFileHeader(parent, child);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5898_ffdd0864,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/panel/DefaultMarkupSourcingStrategy.java,76,102,"/**
 *  Get the markup for the child component, which is assumed to be a child of 'container'.
 */
@Override
public IMarkupFragment getMarkup(final MarkupContainer container, final Component child) {
    // If the sourcing strategy did not provide one, than ask the component.
    // Get the markup for the container
    IMarkupFragment markup = container.getMarkup();
    if (markup == null) {
        return null;
    }
    if (child == null) {
        return markup;
    }
    // Find the child's markup
    markup = markup.find(child.getId());
    if (markup != null) {
        return markup;
    }
    markup = searchMarkupInTransparentResolvers(container, child);
    return markup;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5916_def03add,Major,wicket-core/src/main/java/org/apache/wicket/model/LoadableDetachableModel.java,92,110,"/**
 *  @see org.apache.wicket.model.IDetachable#detach()
 */
@Override
public void detach() {
    if (attached) {
        try {
            onDetach();
        } finally {
            attached = false;
            transientModelObject = null;
            log.debug(""removed transient object for {}, requestCycle {}"", this, RequestCycle.get());
        }
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5916_def03add,Major,wicket-core/src/main/java/org/apache/wicket/model/LoadableDetachableModel.java,115,132,"/**
 *  @see org.apache.wicket.model.IModel#getObject()
 */
@Override
public final T getObject() {
    if (!attached) {
        transientModelObject = load();
        if (log.isDebugEnabled()) {
            log.debug(""loaded transient object "" + transientModelObject + "" for "" + this + "", requestCycle "" + RequestCycle.get());
        }
        attached = true;
        onAttach();
    }
    return transientModelObject;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5916_def03add,Major,wicket-core/src/main/java/org/apache/wicket/model/LoadableDetachableModel.java,139,142,"/**
 *  Gets the attached status of this model instance
 *
 *  @return true if the model is attached, false otherwise
 */
public final boolean isAttached() {
    return attached;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5916_def03add,Major,wicket-core/src/main/java/org/apache/wicket/model/LoadableDetachableModel.java,147,154,"/**
 *  @see java.lang.Object#toString()
 */
@Override
public String toString() {
    StringBuilder sb = new StringBuilder(super.toString());
    sb.append("":attached="").append(attached).append("":tempModelObject=["").append(this.transientModelObject).append(""]"");
    return sb.toString();
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5916_def03add,Major,wicket-core/src/main/java/org/apache/wicket/model/LoadableDetachableModel.java,187,192,"/**
 *  Manually loads the model with the specified object. Subsequent calls to {@link #getObject()}
 *  will return {@code object} until {@link #detach()} is called.
 *
 *  @param object
 *             The object to set into the model
 */
@Override
public void setObject(final T object) {
    attached = true;
    transientModelObject = object;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5960_03663750,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/internal/HtmlHeaderContainer.java,316,323,"@Override
protected void onDetach() {
    super.onDetach();
    renderedComponentsPerScope = null;
    headerResponse = null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5964_86066852,Major,wicket-core/src/main/java/org/apache/wicket/markup/html/internal/Enclosure.java,123,136,"protected final Component getChild() {
    if (childComponent == null) {
        // try to find child when queued
        childComponent = get(childId);
    }
    if (childComponent == null) {
        // try to find child when resolved
        childComponent = getChildComponent(new MarkupStream(getMarkup()), getEnclosureParent());
    }
    return childComponent;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5965_31c88569,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/HtmlHeaderSectionHandler.java,150,167,"/**
 *  Handle tag &lt;wicket:header-items&gt;
 *
 *  @param tag
 */
private void handleHeaderItemsTag(ComponentTag tag) {
    if (foundHeaderItemsTag) {
        throw new MarkupException(new MarkupStream(markup), ""More than one <wicket:header-items/> detected in the <head> element. Only one is allowed."");
    } else if (foundClosingHead) {
        throw new MarkupException(new MarkupStream(markup), ""Detected <wicket:header-items/> after the closing </head> element."");
    }
    foundHeaderItemsTag = true;
    tag.setId(HEADER_ID);
    tag.setAutoComponentTag(true);
    tag.setModified(true);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5965_31c88569,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/HtmlHeaderSectionHandler.java,173,208,"/**
 *  Handle tag &lt;head&gt;
 *  @param tag
 */
private void handleHeadTag(ComponentTag tag) {
    // we found <head>
    if (tag.isOpen()) {
        if (foundHead) {
            throw new MarkupException(new MarkupStream(markup), ""Tag <head> is not allowed at this position (do you have multiple <head> tags in your markup?)."");
        }
        foundHead = true;
        if (tag.getId() == null) {
            tag.setId(HEADER_ID);
            tag.setAutoComponentTag(true);
            tag.setModified(true);
        }
    } else if (tag.isClose()) {
        if (foundHeaderItemsTag) {
            // revert the settings from above
            ComponentTag headOpenTag = tag.getOpenTag();
            // change the id because it is special. See HtmlHeaderResolver
            headOpenTag.setId(HEADER_ID + ""-Ignored"");
            headOpenTag.setAutoComponentTag(false);
            headOpenTag.setModified(false);
            headOpenTag.setFlag(ComponentTag.RENDER_RAW, true);
        }
        foundClosingHead = true;
    }
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5965_31c88569,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/HtmlHeaderSectionHandler.java,213,228,"/**
 *  Insert &lt;head&gt; open and close tag (with empty body) to the current position.
 */
private void insertHeadTag() {
    // Note: only the open-tag must be a AutoComponentTag
    final ComponentTag openTag = new ComponentTag(HEAD, TagType.OPEN);
    openTag.setId(HEADER_ID);
    openTag.setAutoComponentTag(true);
    openTag.setModified(true);
    final ComponentTag closeTag = new ComponentTag(HEAD, TagType.CLOSE);
    closeTag.setOpenTag(openTag);
    closeTag.setModified(true);
    // insert the tags into the markup stream
    markup.addMarkupElement(openTag);
    markup.addMarkupElement(closeTag);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5966_d547fcd4,Major,wicket-util/src/main/java/org/apache/wicket/util/resource/ResourceUtils.java,86,138,"/**
 *  Extract the locale from the filename
 *
 *  @param path
 *             The file path
 *  @return The updated path, without the locale
 */
public static PathLocale getLocaleFromFilename(String path) {
    String extension = """";
    int pos = path.lastIndexOf('.');
    if (pos != -1) {
        extension = path.substring(pos);
        path = path.substring(0, pos);
    }
    String filename = Strings.lastPathComponent(path, '/');
    Matcher matcher = LOCALE_PATTERN.matcher(filename);
    if (matcher.find()) {
        String language = matcher.group(1);
        String country = matcher.group(3);
        String variant = matcher.group(5);
        // did we find a language?
        if (language != null) {
            if (isoLanguages.contains(language) == false) {
                language = null;
                country = null;
                variant = null;
            }
        }
        // did we find a country?
        if ((language != null) && (country != null)) {
            if (isoCountries.contains(country) == false) {
                country = null;
                variant = null;
            }
        }
        if (language != null) {
            pos = path.length() - filename.length() + matcher.start();
            String basePath = path.substring(0, pos) + extension;
            Locale locale = new Locale(language, country != null ? country : """", variant != null ? variant : """");
            return new PathLocale(basePath, locale);
        }
    }
    return new PathLocale(path + extension, null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5968_8b7946d8,Major,wicket-core/src/main/java/org/apache/wicket/core/util/resource/locator/caching/CachingResourceStreamLocator.java,73,92,"/**
 *  {@inheritDoc}
 *
 *  Checks for {@link IResourceStreamReference} in the cache and returns <code>null</code> if the
 *  result is {@link NullResourceStreamReference#INSTANCE}, or {@link FileResourceStream} /
 *  {@link UrlResourceStream} if there is an entry in the cache. Otherwise asks the delegate to
 *  find one and puts it in the cache.
 */
@Override
public IResourceStream locate(Class<?> clazz, String path) {
    CacheKey key = new CacheKey(clazz.getName(), path, null, null, null, null);
    IResourceStreamReference resourceStreamReference = cache.get(key);
    final IResourceStream result;
    if (resourceStreamReference == null) {
        result = delegate.locate(clazz, path);
        updateCache(key, result);
    } else {
        result = resourceStreamReference.getReference();
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5968_8b7946d8,Major,wicket-core/src/main/java/org/apache/wicket/core/util/resource/locator/caching/CachingResourceStreamLocator.java,112,132,"@Override
public IResourceStream locate(Class<?> scope, String path, String style, String variation, Locale locale, String extension, boolean strict) {
    CacheKey key = new CacheKey(scope.getName(), path, extension, locale, style, variation);
    IResourceStreamReference resourceStreamReference = cache.get(key);
    final IResourceStream result;
    if (resourceStreamReference == null) {
        result = delegate.locate(scope, path, style, variation, locale, extension, strict);
        updateCache(key, result);
    } else {
        result = resourceStreamReference.getReference();
    }
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5968_8b7946d8,Major,wicket-core/src/main/java/org/apache/wicket/core/util/resource/locator/caching/CachingResourceStreamLocator.java,169,180,"@Override
public boolean equals(Object o) {
    if (this == o)
        return true;
    if (o == null || getClass() != o.getClass())
        return false;
    if (!super.equals(o))
        return false;
    CacheKey cacheKey = (CacheKey) o;
    return !(extension != null ? !extension.equals(cacheKey.extension) : cacheKey.extension != null);
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5968_8b7946d8,Major,wicket-core/src/main/java/org/apache/wicket/core/util/resource/locator/caching/CachingResourceStreamLocator.java,182,188,"@Override
public int hashCode() {
    int result = super.hashCode();
    result = 31 * result + (extension != null ? extension.hashCode() : 0);
    return result;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5980_294b0b2f,Minor,wicket-core/src/main/java/org/apache/wicket/protocol/http/WicketFilter.java,472,525,"/**
 *  Stub method that lets subclasses configure filter path from annotations.
 *
 *  @param isServlet
 *  @return Filter path from annotation
 */
protected String getFilterPathFromAnnotation(boolean isServlet) {
    String[] patterns = null;
    if (isServlet) {
        WebServlet servlet = getClass().getAnnotation(WebServlet.class);
        if (servlet != null) {
            if (servlet.urlPatterns().length > 0) {
                patterns = servlet.urlPatterns();
            } else {
                patterns = servlet.value();
            }
        }
    } else {
        WebFilter filter = getClass().getAnnotation(WebFilter.class);
        if (filter != null) {
            if (filter.urlPatterns().length > 0) {
                patterns = filter.urlPatterns();
            } else {
                patterns = filter.value();
            }
        }
    }
    if (patterns != null && patterns.length > 0) {
        String pattern = patterns[0];
        if (patterns.length > 1) {
            log.warn(""Multiple url patterns defined for Wicket filter/servlet, using the first: {}"", pattern);
        }
        if (""/*"".equals(pattern)) {
            pattern = """";
        }
        return pattern;
    }
    return null;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5981_eb125865,Major,wicket-core/src/main/java/org/apache/wicket/MarkupContainer.java,1016,1030,"/**
 *  Returns child component at the specified index. Note that this method has O(n) complexity on
 *  the number of children.
 *
 *  @param index
 *             the index of the child in this container
 *  @throws ArrayIndexOutOfBoundsException
 *              when {@code index} exceeds {@code size()}
 *  @return child component at the specified index
 *  @deprecated this method is marked for deletion for WICKET8
 */
@Deprecated
public final Component get(int index) {
    Component childAtIndex = null;
    Iterator<Component> childIterator = iterator();
    while (index-- >= 0 && childIterator.hasNext()) {
        childAtIndex = childIterator.next();
    }
    if (childAtIndex == null) {
        throw new ArrayIndexOutOfBoundsException(Integer.toString(index));
    }
    return childAtIndex;
}"
wicket,remotes/origin/bugs-dot-jar_WICKET-5989_a255bbca,Major,wicket-core/src/main/java/org/apache/wicket/markup/parser/filter/HtmlHeaderSectionHandler.java,173,191,"/**
 *  Handle tag &lt;wicket:header-items&gt;
 *
 *  @param tag
 */
private void handleHeaderItemsTag(ComponentTag tag) {
    if (foundHeaderItemsTag) {
        throw new MarkupException(new MarkupStream(markup), ""More than one <wicket:header-items/> detected in the <head> element. Only one is allowed."");
    } else if (foundClosingHead) {
        throw new MarkupException(new MarkupStream(markup), ""Detected <wicket:header-items/> after the closing </head> element."");
    }
    foundHeaderItemsTag = true;
    tag.setId(HEADER_ID);
    tag.setAutoComponentTag(true);
    tag.setModified(true);
    tag.setAutoComponentFactory(HTML_HEADER_ITEMS_FACTORY);
}"
